web technologies can web
technologies can web services
can web services scale
web services scale up
cornell university i n
university i n the
i n the past
only major internet players
major internet players such
internet players such as
players such as amazon
implementing high performance multicast
high performance multicast in
performance multicast in a
multicast in a managed
and google were interested
in a managed environment
google were interested in
a managed environment krzysztof
were interested in deploying
managed environment krzysztof ostrowski
interested in deploying large
environment krzysztof ostrowski cornell
krzysztof ostrowski cornell university
ostrowski cornell university ken
cornell university ken birman
university ken birman cornell
ken birman cornell university
birman cornell university abstract
cornell university abstract motes
university abstract motes end
this is changing rapidly
transparent error correction for
an adaptive distributed file
is changing rapidly all
user application development using
error correction for communication
adaptive distributed file system
changing rapidly all sorts
distributed file system for
correction for communication between
rapidly all sorts of
file system for mobile
application development using c
system for mobile hosts
all sorts of companies
for mobile hosts benjamin
for communication between data
sorts of companies and
communication between data centers
mobile hosts benjamin atkin
between data centers mahesh
hosts benjamin atkin and
of companies and governmental
benjamin atkin and kenneth
data centers mahesh balakrishnan
atkin and kenneth p
companies and governmental organizations
and governmental organizations are
governmental organizations are suddenly
organizations are suddenly looking
are suddenly looking towards
suddenly looking towards web
the company s own
looking towards web services
birman department of computer
company s own products
department of computer science
towards web services as
of computer science cornell
s own products are
computer science cornell university
web services as a
own products are still
services as a platform
products are still implemented
as a platform that
are still implemented primarily
a platform that might
still implemented primarily in
platform that might support
implemented primarily in unmanaged
that might support a
primarily in unmanaged c
might support a wide
support a wide range
a wide range of
wide range of demanding
range of demanding applications
examples of such systems
of such systems include
such systems include big
by building xyx in
systems include big banking
building xyx in the
include big banking and
xyx in the recommended
big banking and brokerage
edu abstract mfs using
banking and brokerage data
in the recommended manner
and brokerage data centers
abstract mfs using file
mfs using file access
using file access traces
file access traces from
access traces from windows
we found ourselves breaking
traces from windows nt
online service centers for
from windows nt and
found ourselves breaking new
windows nt and unix
service centers for companies
ourselves breaking new ground
centers for companies that
for companies that operate
companies that operate on
that operate on a
operate on a global
and a synthetic workload
on a global scale
the multicast protocols employed
a synthetic workload designed
multicast protocols employed by
synthetic workload designed to
protocols employed by qsm
workload designed to emulate
employed by qsm were
designed to emulate sharing
systems to operate critical
by qsm were designed
to emulate sharing patterns
qsm were designed for
to operate critical infrastructures
were designed for performance
emulate sharing patterns seen
designed for performance and
operate critical infrastructures like
for performance and scalability
sharing patterns seen in
critical infrastructures like electric
patterns seen in mobility
infrastructures like electric power
seen in mobility is
like electric power and
in mobility is a
electric power and transportation
mobility is a critical
incorporating a mixture of
is a critical feature
a mixture of new
a critical feature of
mixture of new ideas
critical feature of computer
of new ideas and
feature of computer systems
new ideas and ideas
and government and military
ideas and ideas drawn
government and military systems
and ideas drawn from
and military systems responsible
ideas drawn from prior
and while collaborative engineering
drawn from prior systems
military systems responsible for
while collaborative engineering systems
abstract the global network
systems responsible for everything
the global network of
responsible for everything from
global network of data
for everything from intelligence
network of data centers
everything from intelligence gathering
wireless networks are common
of data centers is
from intelligence gathering to
data centers is emerging
the aspects on which
intelligence gathering to issuing
centers is emerging as
gathering to issuing social
aspects on which we
to issuing social security
is emerging as an
issuing social security checks
on which we focus
emerging as an important
most applications that run
which we focus here
as an important distributed
applications that run on
we focus here reflect
an important distributed systems
focus here reflect architectural
that run on existing
here reflect architectural responses
important distributed systems paradigm
reflect architectural responses to
run on existing work
architectural responses to scheduling
distributed systems paradigm commodity
responses to scheduling delays
on existing work in
this emerging trend presents
systems paradigm commodity clusters
emerging trend presents developers
paradigm commodity clusters running
existing work in cache
commodity clusters running high
trend presents developers with
work in cache management
overheads associated with threads
presents developers with a
in cache management for
developers with a new
cache management for mobile
with a new challenge
management for mobile file
and costs arising in
for mobile file systems
costs arising in the
mobile file systems mobile
arising in the memory
building web services solutions
in the memory management
web services solutions that
the memory management subsystem
services solutions that scale
file systems mobile hosts
systems mobile hosts lack
speed lambda networks across
mobile hosts lack flexible
lambda networks across hundreds
hosts lack flexible mechanisms
networks across hundreds of
lack flexible mechanisms for
across hundreds of milliseconds
flexible mechanisms for data
over the period during
mechanisms for data access
hundreds of milliseconds of
the period during which
a scalable system is
of milliseconds of network
for data access in
milliseconds of network latency
scalable system is one
period during which qsm
system is one that
during which qsm was
data access in an
which qsm was developed
is one that can
access in an en
packet loss on long
one that can flexibly
that can flexibly accommodate
can flexibly accommodate growth
flexibly accommodate growth in
accommodate growth in its
growth in its client
haul networks can cripple
in its client base
networks can cripple the
can cripple the performance
cripple the performance of
the performance of applications
these had pervasive consequences
performance of applications and
such systems typically run
of applications and protocols
systems typically run on
applications and protocols a
typically run on a
and protocols a loss
forcing us to redesign
run on a clustered
us to redesign and
protocols a loss rate
on a clustered computer
a loss rate as
to redesign and recode
loss rate as low
a clustered computer or
rate as low as
redesign and recode one
clustered computer or in
and recode one layer
recode one layer of
computer or in a
one layer of the
layer of the system
or in a large
of the system after
the system after another
in a large data
a large data center
large data center and
data center and must
center and must be
and must be able
must be able to
be able to handle
able to handle high
is sufficient to reduce
to handle high loads
sufficient to reduce tcp
the original system was
handle high loads or
original system was multithreaded
high loads or sudden
loads or sudden demand
or sudden demand bursts
ip throughput by an
sudden demand bursts and
throughput by an order
demand bursts and a
by an order of
bursts and a vast
an order of magnitude
and a vast number
order of magnitude on
a vast number of
of magnitude on a
vast number of users
incorporates mechanisms for making
o calls and was
mechanisms for making efficient
calls and was rather
for making efficient vironment
and was rather casual
making efficient vironment with
was rather casual about
efficient vironment with large
they must reliably respond
vironment with large and
rather casual about buffering
with large and frequent
must reliably respond even
large and frequent variations
casual about buffering and
and frequent variations in
about buffering and caching
frequent variations in network
reliably respond even in
variations in network connec
respond even in the
even in the event
in the event of
the event of failures
the current system is
event of failures or
current system is single
use of available bandwidth
of failures or reconfiguration
maelstrom is an edge
is an edge appliance
an edge appliance that
edge appliance that masks
appliance that masks packet
that masks packet loss
masks packet loss transparently
it has mostly focused
packet loss transparently and
has mostly focused on
loss transparently and quickly
mostly focused on tivity
transparently and quickly from
and quickly from inter
managed and automate as
and automate as many
automate as many routine
and obsessively minimizes memory
as many routine services
obsessively minimizes memory consumption
many routine services such
routine services such as
services such as backups
such as backups and
aggregating traffic for high
as backups and component
backups and component upgrades
and component upgrades as
in collaborative work adapting
component upgrades as possible
collaborative work adapting existing
work adapting existing systems
speed encoding and using
adapting existing systems to
encoding and using a
existing systems to cope
and using a new
systems to cope with
many settings also require
to cope with periods
using a new forward
cope with periods of
settings also require security
with periods of low
a new forward error
periods of low bandwidth
also require security against
performs well and is
new forward error correction
well and is stable
require security against attempted
and is stable at
forward error correction scheme
security against attempted intrusions
error correction scheme to
is stable at high
correction scheme to handle
against attempted intrusions and
scheme to handle bursty
stable at high data
to handle bursty loss
attempted intrusions and distributed
at high data rates
intrusions and distributed denial
particularly when wireless and
when wireless and wired
wireless and wired users
and wired users share
large scale and under
wired users share in
scale and under stress
users share in a
share in a style
in a style which
a style which we
style which we will
which we will refer
the finished system achieves
we will refer to
will refer to as
finished system achieves extremely
refer to as modal
system achieves extremely high
to as modal adaptation
achieves extremely high performance
extremely high performance with
high performance with relatively
performance with relatively modest
with relatively modest cpu
when files or databases
relatively modest cpu and
modest cpu and memory
cpu and memory loads
although our paper is
our paper is not
we describe some techniques
paper is not about
describe some techniques bandwidth
is not about setting
some techniques bandwidth is
not about setting performance
techniques bandwidth is high
about setting performance records
setting performance records the
performance records the absolute
the second builds on
records the absolute numbers
second builds on the
the absolute numbers are
the application communicates normally
absolute numbers are good
builds on the first
on the first and
the first and supports
first and supports a
and supports a way
when for adapting data
qsm outperforms the multicast
supports a way to
for adapting data access
a way to build
outperforms the multicast platforms
way to build scripts
adapting data access to
the multicast platforms we
to build scripts of
i ntroduction t a
build scripts of simpler
multicast platforms we ve
scripts of simpler transactions
ntroduction t a conference
data access to network
t a conference version
platforms we ve worked
a conference version of
access to network variability
conference version of this
we ve worked with
some might argue that
version of this paper
might argue that all
of this paper appeared
to network variability in
this paper appeared in
argue that all reliability
paper appeared in nsdi
network variability in the
ve worked with in
variability in the context
that all reliability needs
in the context of
worked with in the
the context of bandwidth
all reliability needs can
context of bandwidth falls
with in the past
of bandwidth falls below
reliability needs can be
bandwidth falls below a
in the past systems
falls below a threshold
needs can be recast
the past systems that
can be recast in
past systems that run
be recast in terms
systems that run in
recast in terms of
that run in unmanaged
in terms of transactions
the application enters a
run in unmanaged settings
application enters a lowmfs
this paper won t
a client cache manager
paper won t tell
client cache manager for
fifth usenix symposium on
the past three decades
cache manager for a
won t tell the
manager for a distributed
t tell the blow
for a distributed file
past three decades have
a distributed file system
usenix symposium on networked
three decades have seen
symposium on networked systems
decades have seen one
on networked systems design
have seen one failed
networked systems design and
seen one failed attempt
systems design and implementation
we bandwidth mode in
one failed attempt after
bandwidth mode in which
failed attempt after another
mode in which communication
attempt after another to
in which communication is
after another to build
which communication is restricted
another to build everything
communication is restricted or
to build everything over
is restricted or deshow
build everything over a
we use qsm in
everything over a database
restricted or deshow how
over a database system
use qsm in a
or deshow how mfs
qsm in a series
deshow how mfs is
in a series of
how mfs is able
a series of experiments
mfs is able to
series of experiments that
and it s now
of experiments that highlight
is able to adapt
experiments that highlight fundamental
it s now clear
that highlight fundamental factors
able to adapt to
s now clear that
to adapt to widely
now clear that many
adapt to widely varying
clear that many kinds
to widely varying bandwidth
that many kinds of
widely varying bandwidth ferred
these reveal linkages between
many kinds of systems
reveal linkages between achievable
kinds of systems just
ms index terms data
of systems just don
index terms data centers
systems just don t
linkages between achievable performance
just don t match
between achievable performance and
don t match the
achievable performance and the
t match the model
performance and the costs
an application has a
and the costs and
application has a small
the costs and characteristics
has a small number
costs and characteristics of
a small number of
and characteristics of the
these intrinsically distributed systems
characteristics of the managed
small number of levels
intrinsically distributed systems make
of the managed framework
number of levels through
distributed systems make use
of levels through the
systems make use of
levels through the use
make use of direct
through the use of
use of direct communication
the use of modeless
he emergence of commodity
use of modeless adaptation
doing so sheds light
of direct communication between
emergence of commodity clusters
direct communication between programs
so sheds light on
of commodity clusters and
communication between programs via
sheds light on the
between programs via the
and evaluate the possible
programs via the trans
light on the challenges
commodity clusters and data
evaluate the possible modes
on the challenges of
clusters and data centers
the possible modes and
the challenges of working
current web services standards
possible modes and chooses
challenges of working in
web services standards have
and data centers has
modes and chooses the
services standards have many
data centers has enabled
and chooses the appropriate
of working in a
centers has enabled a
chooses the appropriate one
working in a kind
has enabled a new
the appropriate one based
standards have many critical
in a kind of
have many critical limitations
appropriate one based on
enabled a new class
a kind of environment
one based on the
a new class of
kind of environment that
based on the benefit
new class of globally
of environment that will
on the benefit of
class of globally distributed
environment that will be
the benefit of mechanisms
today s web services
that will be more
s web services standards
benefit of mechanisms for
web services standards seem
will be more and
services standards seem to
of mechanisms for improving
standards seem to answer
be more and more
of globally distributed highperformance
more and more prevalent
seem to answer these
globally distributed highperformance applications
to answer these needs
mechanisms for improving file
and more prevalent in
for improving file system
more prevalent in years
distributed highperformance applications that
prevalent in years to
improving file system performance
in years to come
highperformance applications that coordinate
file system performance currently
applications that coordinate over
system performance currently available
that coordinate over vast
performance currently available bandwidth
coordinate over vast geographical
a more probing analysis
over vast geographical distances
our insights should be
more probing analysis reveals
insights should be of
probing analysis reveals many
should be of value
analysis reveals many critical
be of value to
reveals many critical limitations
of value to developers
value to developers of
to developers of other
developers of other high
in the coda file
the coda file and
a financial firm s
coda file and cache
financial firm s new
file and cache consistency
firm s new york
performance communication and event
and cache consistency using
s new york city
cache consistency using microbenchmarks
new york city data
consistency using microbenchmarks and
york city data center
the major web services
city data center may
major web services standards
data center may receive
using microbenchmarks and file
center may receive real
web services standards dealing
microbenchmarks and file system
services standards dealing with
and file system system
standards dealing with reliability
time updates from a
updates from a stock
from a stock exchange
a stock exchange in
stock exchange in switzerland
we propose a new
conduct financial transactions with
propose a new positioning
financial transactions with banks
a new positioning of
transactions with banks in
new positioning of multicast
with banks in asia
positioning of multicast technology
reliability provides for reliable
provides for reliable handoff
for reliable handoff between
reliable handoff between a
the cache manager operates
handoff between a client
cache data in london
between a client system
data in london for
as an extension of
in london for locality
a client system and
london for locality and
an extension of the
for locality and mirror
client system and a
locality and mirror it
extension of the component
and mirror it to
system and a queuing
mirror it to kansas
of the component integration
cache manager operates in
the component integration features
manager operates in either
component integration features of
operates in either a
and a queuing system
in either a stronglytraces
integration features of the
it to kansas for
features of the microsoft
to kansas for disaster
a queuing system residing
queuing system residing between
system residing between the
residing between the client
between the client and
net managed runtime environment
the client and some
client and some service
to interconnect these bandwidth
hungry data centers across
data centers across the
centers across the globe
the standard isn t
standard isn t nearly
although we started with
isn t nearly as
we started with a
which affects the policy
started with a sophisticated
affects the policy for
with a sophisticated multicast
the policy for writing
t nearly as comprehensive
policy for writing changes
nearly as comprehensive as
for writing changes to
as comprehensive as the
writing changes to files
comprehensive as the name
changes to files back
as the name implies
organizations are increasingly deploying
a sophisticated multicast protocol
are increasingly deploying private
to files back to
increasingly deploying private lambda
files back to the
deploying private lambda networks
back to the server
experiments reveal a series
reveal a series of
it s limited to
a series of problematic
s limited to pipelines
modal adaptation schemes are
raw bandwidth is ubiquitous
adaptation schemes are well
limited to pipelines that
bandwidth is ubiquitous and
series of problematic interactions
is ubiquitous and cheaply
to pipelines that include
ubiquitous and cheaply available
pipelines that include queuing
of problematic interactions between
that include queuing subsystems
and cheaply available in
problematic interactions between its
cheaply available in the
interactions between its high
available in the form
introduction in which changes
in the form of
in which changes in
the form of existing
which changes in bandwidth
form of existing dark
changes in bandwidth are
of existing dark fiber
in bandwidth are relatively
bandwidth are relatively predictable
reliability boils down to
boils down to a
down to a few
processing logic and the
to a few options
such as switching network
logic and the properties
a few options that
as switching network access
running and maintaining high
switching network access from
few options that a
and the properties of
options that a client
the properties of the
network access from an
that a client can
access from an ethernet
properties of the managed
from an ethernet to
a client can use
of the managed framework
an ethernet to a
client can use to
ethernet to a modem
free networks over this
can use to tell
networks over this fiber
use to tell the
over this fiber is
to tell the queuing
this fiber is difficult
but mobility is now
tell the queuing system
mobility is now an
fiber is difficult and
is now an major
is difficult and expensive
now an major feature
the queuing system whether
an major feature of
queuing system whether or
major feature of computer
system whether or not
feature of computer systems
whether or not to
or not to reissue
not to reissue a
to reissue a request
we addressed these and
reissue a request if
capacity optical links are
over the not as
optical links are almost
the not as appropriate
links are almost never
a request if a
are almost never congested
not as appropriate in
addressed these and achieved
as appropriate in for
request if a failure
appropriate in for wireless
if a failure occurs
in for wireless networks
these and achieved high
they drop packets for
and achieved high performance
drop packets for numerous
achieved high performance by
packets for numerous reasons
high performance by making
and a way to
in which bandwidth past
a way to timestamp
which bandwidth past decade
for numerous reasons dirty
performance by making some
way to timestamp requests
by making some unusual
to timestamp requests so
making some unusual architectural
timestamp requests so that
some unusual architectural decisions
requests so that a
so that a service
that a service can
a service can detect
service can detect duplicates
held devices capable of
which we distill into
devices capable of wireless
we distill into general
capable of wireless availability
distill into general insights
of wireless availability is
wireless availability is less
availability is less predictable
transactions actually consists of
is less predictable and
actually consists of two
less predictable and varies
consists of two side
component integration environments such
predictable and varies over
integration environments such as
and varies over a
environments such as microsoft
varies over a larger
over a larger possible
a larger possible network
larger possible network access
possible network access have
network access have become
access have become common
one is aimed at
ee have become widely
is aimed at applications
have become widely popular
aimed at applications that
and wireless networks are
at applications that perform
wireless networks are range
become widely popular with
applications that perform database
widely popular with application
that perform database transactions
popular with application developers
perform database transactions with
database transactions with the
transactions with the usual
the notion of insufficient
with the usual acid
notion of insufficient bandwidth
of insufficient bandwidth can
who benefit from standardized
insufficient bandwidth can vary
benefit from standardized memory
bandwidth can vary dependalso
from standardized memory management
can vary dependalso proliferating
applications that run on
that run on hosts
run on hosts in
on hosts in wireless
hosts in wireless neting
in wireless neting on
wireless neting on how
neting on how much
on how much data
how much data the
much data the application
data the application is
the application is trying
and performance analysis tools
application is trying to
performance analysis tools that
is trying to send
analysis tools that operate
for example and in
tools that operate across
example and in different
or the remote procedure
and in different patterns
the remote procedure call
that operate across component
remote procedure call and
operate across component boundaries
procedure call and that
so that works must
call and that can
and that can t
that works must cope
that can t tolerate
ranging from singleton drops
can t tolerate delay
works must cope with
this paper describes quicksilver
from singleton drops to
must cope with constraints
singleton drops to extended
paper describes quicksilver scalable
drops to extended bursts
cope with constraints on
these systems lack databases
describes quicksilver scalable multicast
with constraints on access
systems lack databases clean
constraints on access to
lack databases clean separation
on access to data
databases clean separation of
access to data that
clean separation of stored
to data that are
separation of stored data
data that are genit
of stored data from
that are genit may
stored data from code
are genit may make
genit may make sense
may make sense to
make sense to adjust
sense to adjust network
and any attempt to
to adjust network usage
any attempt to force
adjust network usage when
a new multicast platform
network usage when the
attempt to force them
new multicast platform designed
usage when the bandwidth
to force them into
when the bandwidth erally
multicast platform designed to
the bandwidth erally not
force them into that
platform designed to achieve
them into that model
bandwidth erally not present
into that model results
erally not present in
that model results in
not present in wired
designed to achieve high
present in wired networks
model results in unacceptable
to achieve high performance
results in unacceptable loss
noncongestion loss has been
in unacceptable loss of
achieve high performance in
unacceptable loss of performance
loss has been observed
high performance in managed
has been observed on
distance from a base
been observed on long
performance in managed environments
from a base stadrops
intrinsically distributed systems are
a base stadrops by
distributed systems are common
base stadrops by half
haul networks as well
memoryrelated overheads and phenomena
and web services will
overheads and phenomena related
web services will need
rather than just when
services will need to
and phenomena related to
will need to support
than just when it
phenomena related to scheduling
just when it falls
need to support them
when it falls to
related to scheduling are
it falls to modem
to scheduling are shown
scheduling are shown to
are shown to dominate
shown to dominate the
to dominate the behavior
dominate the behavior of
the behavior of the
the existing reliability options
behavior of the system
existing reliability options simply
reliability options simply don
options simply don t
simply don t address
don t address the
contention with other hosts
t address the requirement
we discuss techniques that
with other hosts or
discuss techniques that helped
other hosts or processes
techniques that helped us
hosts or processes on
that helped us to
or processes on the
helped us to alleviate
processes on the same
a lesson from the
on the same host
us to alleviate these
lesson from the past
to alleviate these problems
from the past what
the past what sorts
past what sorts of
selecting a mode according
what sorts of scaling
a mode according to
sorts of scaling and
mode according to the
and argue that they
according to the available
of scaling and reliability
to the available bandwidth
argue that they reveal
the available bandwidth can
scaling and reliability features
available bandwidth can uninterference
that they reveal general
and reliability features are
they reveal general principles
reliability features are lacking
reveal general principles applicable
features are lacking in
and switching between different
are lacking in web
general principles applicable to
lacking in web services
switching between different wireless
principles applicable to other
in web services standards
applicable to other kinds
web services standards today
to other kinds of
between different wireless media
other kinds of high
different wireless media all
wireless media all necessarily
media all necessarily constrain
all necessarily constrain communication
a good example is
good example is data
example is data replication
since it ignores what
rate protocols and applications
it ignores what data
protocols and applications in
building a server that
and applications in managed
ignores what data compound
applications in managed settings
a server that scales
what data compound the
server that scales to
data compound the variability
that scales to handle
compound the variability in
scales to handle load
the variability in network
to handle load often
the inadequacy of commodity
variability in network performance
handle load often requires
inadequacy of commodity tcp
load often requires replicating
in network performance to
often requires replicating data
introduction a component integration
requires replicating data on
network performance to which
a component integration revolution
replicating data on multiple
ip in high bandwidthdelay
data on multiple nodes
component integration revolution is
on multiple nodes of
in high bandwidthdelay product
multiple nodes of a
integration revolution is transforming
performance to which apthe
revolution is transforming the
to which apthe application
is transforming the development
which apthe application actually
high bandwidthdelay product networks
apthe application actually wants
transforming the development of
application actually wants to
bandwidthdelay product networks is
actually wants to send
the development of desktop
wants to send over
product networks is extensively
to send over the
development of desktop applications
nodes of a cluster
networks is extensively documented
send over the network
platforms such as windows
deferplications must adapt if
must adapt if they
adapt if they are
if they are to
another example is guaranteed
they are to perform
example is guaranteed real
are to perform well
ee promote an application
promote an application development
an application development style
ring writing back all
application development style in
writing back all modifications
development style in which
a company that buys
style in which components
back all modifications to
company that buys a
in which components are
all modifications to files
that buys a cluster
which components are implemented
modifications to files may
components are implemented independently
buys a cluster probably
are implemented independently and
to files may not
implemented independently and heavily
a cluster probably wants
independently and heavily reused
files may not be
cluster probably wants to
may not be a
probably wants to guarantee
not be a sensible
wants to guarantee that
be a sensible this
to guarantee that some
a sensible this paper
guarantee that some service
sensible this paper focuses
that some service will
by standardizing memory management
some service will be
standardizing memory management and
this paper focuses on
memory management and type
service will be responsive
management and type checking
paper focuses on adaptation
will be responsive enough
focuses on adaptation techniques
be responsive enough to
on adaptation techniques for
responsive enough to keep
adaptation techniques for management
these platforms enable safe
enough to keep its
platforms enable safe and
techniques for management policy
enable safe and efficient
to keep its customers
safe and efficient cross
for management policy if
keep its customers happy
management policy if those
its customers happy even
policy if those are
customers happy even when
ip has three major
if those are the
has three major problems
happy even when demand
three major problems when
even when demand is
major problems when used
when demand is high
those are the only
problems when used over
are the only messages
when used over such
the only messages available
used over such networks
only messages available to
avoiding overheads associated with
messages available to send
the missing technologies don
overheads associated with protection
missing technologies don t
associated with protection boundaries
technologies don t stop
don t stop there
of data accessed and
data accessed and modified
accessed and modified by
and modified by mobile
modified by mobile hosts
ip suffers throughput collapse
suffers throughput collapse if
cycle services that can
throughput collapse if the
we investigate we describe
collapse if the network
investigate we describe mfs
services that can launch
if the network is
that can launch an
the network is even
can launch an application
network is even slightly
launch an application on
is even slightly prone
an application on demand
even slightly prone to
application on demand or
slightly prone to packet
on demand or restart
prone to packet loss
demand or restart a
or restart a failed
our project is interested
restart a failed component
project is interested in
a flexible cache adaptation
conservative flow control mechanisms
flexible cache adaptation in
is interested in leveraging
flow control mechanisms designed
cache adaptation in the
or load balancers and
control mechanisms designed to
adaptation in the context
load balancers and technology
mechanisms designed to deal
interested in leveraging these
in the context of
balancers and technology to
the context of mfs
in leveraging these benefits
designed to deal with
and technology to automate
to deal with the
leveraging these benefits to
deal with the systematic
technology to automate management
a client cache manager
with the systematic congestion
client cache manager for
to automate management of
cache manager for a
the systematic congestion of
manager for a manager
automate management of a
for a manager for
systematic congestion of the
a manager for a
management of a machine
these benefits to help
of a machine cluster
manager for a distributed
a machine cluster running
for a distributed file
machine cluster running web
a distributed file system
cluster running web services
distributed file system client
running web services applications
benefits to help developers
congestion of the commodity
to help developers implement
of the commodity internet
help developers implement robust
which differs from distributed
the commodity internet react
differs from distributed file
developers implement robust and
from distributed file system
commodity internet react too
implement robust and scalable
internet react too sharply
robust and scalable computing
react too sharply to
and scalable computing services
scalable computing services that
we concentrate on distributed
computing services that will
working groups within the
services that will run
groups within the world
that will run on
concentrate on distributed file
within the world wide
will run on clusters
the world wide web
on distributed file systraditional
world wide web consortium
run on clusters or
distributed file systraditional cache
on clusters or in
file systraditional cache manager
clusters or in datacenters
systraditional cache manager design
cache manager design in
manager design in two
design in two important
in two important respects
early users of our
users of our platform
of our platform are
our platform are creating
platform are creating applications
ms w n s
are creating applications in
w n s e
tems because systems in
creating applications in areas
n s e fig
applications in areas such
because systems in this
in areas such as
systems in this area
areas such as parallelized
the primary organization developing
in this area are
primary organization developing web
such as parallelized data
organization developing web services
this area are highly
developing web services standards
as parallelized data mining
area are highly developed
are highly developed and
highly developed and have
developed and have mfs
example lambda network ephemeral
and have mfs uses
lambda network ephemeral loss
have mfs uses an
network ephemeral loss on
not one is addressing
ephemeral loss on over
one is addressing these
mfs uses an rpc
is addressing these kinds
event stream filtering software
addressing these kinds of
uses an rpc library
these kinds of issues
an rpc library supporting
provisioned links a single
rpc library supporting priorities
links a single packet
library supporting priorities to
a single packet in
supporting priorities to enable
single packet in ten
a similar dynamic played
packet in ten thousand
similar dynamic played out
in ten thousand is
dynamic played out in
ten thousand is enough
played out in the
priorities to enable modewell
out in the early
to enable modewell understood
and scalable web services
thousand is enough to
enable modewell understood semantics
is enough to reduce
enough to reduce tcp
developers of clustered services
although the techniques we
of clustered services need
the techniques we describe
ip throughput to a
techniques we describe less
clustered services need reliable
throughput to a third
we describe less adaptation
to a third over
services need reliable multicast
a third over a
need reliable multicast protocols
reliable multicast protocols for
multicast protocols for data
protocols for data replication
and in light of
server computing was touted
in light of our
computing was touted as
light of our broader
was touted as the
and one in a
of our broader goal
one in a thousand
which allocates available bandwidth
in a thousand drops
our broader goal of
a thousand drops it
allocates available bandwidth based
thousand drops it by
broader goal of leveraging
drops it by an
touted as the next
goal of leveraging the
as the next big
it by an order
available bandwidth based should
of leveraging the power
bandwidth based should be
by an order of
based should be broadly
an order of magnitude
should be broadly applicable
leveraging the power and
be broadly applicable in
the power and component
the next big thing
broadly applicable in other
power and component integration
applicable in other application
and component integration features
in other application environments
component integration features of
a silver bullet to
integration features of a
silver bullet to solve
features of a managed
bullet to solve every
on the types of
to solve every problem
the types of messages
time or interactive applications
solve every problem related
of a managed framework
or interactive applications are
types of messages being
every problem related to
interactive applications are impacted
problem related to older
of messages being sent
related to older mainframe
applications are impacted by
to older mainframe and
the multicast technology must
older mainframe and batch
are impacted by the
mainframe and batch systems
multicast technology must run
impacted by the reliance
technology must run in
by the reliance of
by assigning priorities such
the reliance of reliability
must run in a
reliance of reliability mechanisms
run in a managed
companies rushed to move
assigning priorities such as
of reliability mechanisms on
priorities such as caching
reliability mechanisms on acknowledgments
such as caching dynamic
mechanisms on acknowledgments and
as caching dynamic internet
on acknowledgments and retransmissions
caching dynamic internet content
rushed to move everything
dynamic internet content or
in a managed setting
internet content or caching
to move everything from
content or caching to
move everything from mainframe
or caching to improve
limiting the latency of
everything from mainframe settings
the latency of packet
from mainframe settings to
latency of packet recovery
mainframe settings to client
but little is known
caching to improve appropriately
little is known about
of packet recovery to
is known about highperformance
packet recovery to at
known about highperformance protocols
recovery to at least
about highperformance protocols in
to at least the
highperformance protocols in managed
at least the round
protocols in managed environments
least the round trip
there were notable successes
the round trip time
it is interesting to
such as retrieving files
but it quickly became
is interesting to realize
it quickly became apparent
interesting to realize that
quickly became apparent that
to realize that although
became apparent that the
realize that although microsoft
apparent that the early
that although microsoft pro
that the early platforms
can the performance of
the early platforms were
the performance of interactions
early platforms were strikingly
performance of interactions with
platforms were strikingly immature
of interactions with web
this research was supported
interactions with web services
research was supported by
if delivery is sequenced
was supported by afrl
processes needed to be
needed to be automated
to be automated and
we evaluate proceed concurrently
be automated and standardized
if with additional support
evaluate proceed concurrently with
with additional support from
proceed concurrently with background
additional support from afosr
concurrently with background activities
and the early generations
with background activities such
the early generations of
background activities such as
each lost packet acts
early generations of client
lost packet acts as
activities such as writing
packet acts as a
such as writing the
acts as a virtual
as writing the authors
server systems cost a
writing the authors were
as a virtual road
the authors were supported
systems cost a fortune
authors were supported in
cost a fortune to
were supported in part
supported in part by
a fortune to build
in part by darpa
block in the fifo
part by darpa under
in the fifo channel
by darpa under afrl
the fifo channel until
darpa under afrl grant
fifo channel until it
under afrl grant radc
channel until it is
afrl grant radc back
until it is recovered
grant radc back changes
department of computer science
required armies of systems
armies of systems administrators
of systems administrators and
systems administrators and specialists
under the assurance that
the assurance that if
assurance that if bandwidth
that if bandwidth becomes
if bandwidth becomes f
and were extremely insecure
ip requires massive buffers
the total cost of
requires massive buffers at
total cost of ownership
massive buffers at the
cost of ownership proved
buffers at the communicating
of ownership proved to
at the communicating endhosts
ownership proved to be
the communicating endhosts to
proved to be unexpectedly
communicating endhosts to fully
to be unexpectedly and
endhosts to fully exploit
be unexpectedly and unacceptably
to fully exploit the
unexpectedly and unacceptably high
fully exploit the bandwidth
exploit the bandwidth of
the bandwidth of a
bandwidth of a long
the lesson of the
lesson of the client
server era is that
era is that incomplete
even in the absence
is that incomplete platforms
in the absence of
that incomplete platforms can
the absence of packet
incomplete platforms can t
absence of packet loss
platforms can t support
can t support major
resistant alternatives to tcp
my concern is that
concern is that the
is that the web
that the web services
ip is not feasible
the web services community
is not feasible in
web services community is
not feasible in corporate
services community is about
feasible in corporate data
community is about to
in corporate data centers
is about to face
about to face the
to face the same
face the same problem
where standardization is the
and by afosr under
standardization is the key
by afosr under muri
is the key to
platform developers are racing
afosr under muri grant
developers are racing forward
under muri grant f
are racing forward at
the key to low
racing forward at top
key to low and
forward at top speed
to low and predictable
low and predictable maintenance
and predictable maintenance costs
jostling for position with
for position with ever
position with ever more
neither is eliminating loss
with ever more exaggerated
is eliminating loss events
ever more exaggerated claims
eliminating loss events on
the embedding of qsm
loss events on a
embedding of qsm into
events on a network
of qsm into windows
on a network that
qsm into windows yielded
while closing their eyes
a network that could
into windows yielded an
closing their eyes to
windows yielded an unexpected
network that could span
yielded an unexpected benefit
their eyes to the
that could span thousands
eyes to the dangerous
could span thousands of
to the dangerous potholes
span thousands of miles
the dangerous potholes in
dangerous potholes in the
it enables what we
potholes in the road
enables what we are
in the road ahead
what we are calling
we are calling live
are calling live distributed
calling live distributed objects
there is a need
architectural standards for scalability
is a need to
standards for scalability to
a need to mask
for scalability to properly
need to mask loss
scalability to properly address
as the term suggests
to properly address scalability
to mask loss on
properly address scalability in
mask loss on the
address scalability in web
loss on the link
scalability in web services
on the link from
these are abstract data
the link from the
are abstract data types
link from the commodity
abstract data types in
from the commodity protocols
data types in which
the commodity protocols running
types in which content
commodity protocols running at
in which content evolves
protocols running at end
which content evolves over
we need more than
content evolves over time
need more than a
more than a long
than a long list
a long list of
long list of reliability
list of reliability and
when an application binds
of reliability and management
and to do so
an application binds to
reliability and management standards
application binds to a
rather than the foreground
binds to a live
than the foreground ones
to a live object
to do so rapidly
do so rapidly and
we need a new
so rapidly and transparently
need a new methodology
additional support from microsoft
a new methodology suitable
support from microsoft research
the current state of
from microsoft research and
new methodology suitable for
microsoft research and from
current state of the
methodology suitable for supporting
research and from the
suitable for supporting a
and from the intel
state of the object
from the intel corporation
because recovery delays for
of the object is
for supporting a scalable
the object is imported
supporting a scalable data
recovery delays for lost
a scalable data center
object is imported and
scalable data center architecture
delays for lost packets
is imported and the
for lost packets translate
imported and the object
lost packets translate into
and the object can
packets translate into dramatic
application programs background processing
translate into dramatic reductions
the object can send
into dramatic reductions in
object can send and
dramatic reductions in application
can send and receive
programs background processing incoming
send and receive updates
and receive updates at
background processing incoming traffic
receive updates at high
updates at high data
processing incoming traffic cache
at high data rates
incoming traffic cache consistency
traffic cache consistency demand
cache consistency demand fetch
an object could be
because applications and os
object could be a
consistency demand fetch access
could be a place
applications and os networking
be a place in
demand fetch access monitoring
along with pat helland
a place in a
and os networking stacks
with pat helland and
os networking stacks in
pat helland and dennis
fetch access monitoring prefetch
place in a game
networking stacks in commodity
helland and dennis shasha
stacks in commodity data
in a game like
in commodity data centers
a game like second
commodity data centers cannot
game like second life
data centers cannot be
access monitoring prefetch outgoing
centers cannot be rewritten
recommends that developers think
cannot be rewritten from
monitoring prefetch outgoing traffic
be rewritten from scratch
that developers think in
prefetch outgoing traffic synchronous
developers think in terms
outgoing traffic synchronous writeback
think in terms of
traffic synchronous writeback update
in terms of a
synchronous writeback update logging
terms of a reliable
writeback update logging asynchronous
of a reliable arraystructured
update logging asynchronous writeback
a reliable arraystructured partitioned
logging asynchronous writeback mfs
reliable arraystructured partitioned service
asynchronous writeback mfs server
writeback mfs server adaptive
mfs server adaptive rpc
server adaptive rpc library
adaptive rpc library mfs
rpc library mfs cache
library mfs cache manager
mfs cache manager will
cache manager will be
implemented as a set
manager will be penalised
as a set of
will be penalised first
a set of reliable
live objects are a
set of reliable arraystructured
side appliance receiver buffer
of reliable arraystructured clustered
appliance receiver buffer overflow
reliable arraystructured clustered servers
objects are a natural
modeless adaptation using prioritised
are a natural and
adaptation using prioritised communication
a natural and powerful
local recovery locations of
using prioritised communication also
recovery locations of packet
natural and powerful idea
prioritised communication also allows
locations of packet loss
communication also allows mfs
of packet loss receive
also allows mfs to
allows mfs to be
and we plan to
mfs to be more
we plan to pursue
this architecture offers scalability
plan to pursue the
side appliance receiving end
to pursue the concept
architecture offers scalability and
pursue the concept in
to be more flexible
the concept in future
offers scalability and reliability
concept in future work
be more flexible in
scalability and reliability at
more flexible in response
and reliability at two
flexible in response to
reliability at two levels
in response to bandwidth
response to bandwidth variations
to bandwidth variations than
bandwidth variations than would
variations than would be
this use of qsm
the top level uses
than would be possible
top level uses some
maelstrom communication path forward
use of qsm raises
communication path forward error
level uses some sort
would be possible with
of qsm raises performance
be possible with a
uses some sort of
qsm raises performance and
some sort of application
path forward error correction
possible with a modal
raises performance and scalability
with a modal scheme
performance and scalability issues
specific key to partition
and scalability issues beyond
key to partition the
scalability issues beyond the
to partition the service
issues beyond the ones
partition the service into
is a promising solution
the service into subservices
beyond the ones seen
a promising solution for
the ones seen in
mfs incorporates a new
ones seen in our
promising solution for reliability
seen in our original
the lower level implements
in our original target
solution for reliability over
our original target domain
for reliability over long
incorporates a new cache
lower level implements subservices
a new cache consistency
level implements subservices using
new cache consistency algorithm
implements subservices using groups
cache consistency algorithm to
subservices using groups of
consistency algorithm to efficiently
using groups of programs
algorithm to efficiently provide
we leave detailed discussion
to efficiently provide a
leave detailed discussion of
efficiently provide a high
detailed discussion of the
provide a high degree
discussion of the idea
a high degree of
of the idea for
high degree of consistency
the idea for the
degree of consistency for
idea for the future
groups of programs that
of consistency for access
of programs that run
consistency for access to
programs that run on
for access to shared
packet recovery latency is
that run on multiple
qsm has been available
run on multiple machines
has been available for
recovery latency is independent
been available for free
access to shared files
available for free download
latency is independent of
perhaps in a cluster
is independent of the
in a cluster computer
for free download since
independent of the rtt
free download since mid
of the rtt of
which is required for
the rtt of the
is required for collaborative
rtt of the link
required for collaborative work
the groups replicate data
for collaborative work applications
groups replicate data so
replicate data so that
data so that each
while fec codes have
so that each can
fec codes have been
that each can handle
codes have been used
the rest of this
each can handle any
rest of this paper
have been used for
of this paper is
can handle any incoming
been used for decades
handle any incoming query
used for decades within
any incoming query for
for decades within link
incoming query for its
this paper is organised
query for its range
paper is organised as
for its range within
is organised as follows
its range within the
range within the keys
and it has a
it has a number
has a number of
enabling updates to reach
a number of users
updates to reach all
describes the mfs design
to reach all the
faster commodity processors have
the mfs design and
commodity processors have enabled
reach all the replicas
processors have enabled packet
most working on clustered
mfs design and differences
working on clustered computing
design and differences from
and differences from existing
differences from existing distributed
level fec at end
from existing distributed and
existing distributed and mobile
distributed and mobile file
and mobile file systems
one large project is
a raps that an
large project is pairing
raps that an e
project is pairing qsm
as well as giving
is pairing qsm with
well as giving an
pairing qsm with high
as giving an overview
tailer such as amazon
giving an overview of
such as amazon might
an overview of the
as amazon might use
overview of the mfs
amazon might use to
speed event stream filtering
might use to personalize
of the mfs rpc
use to personalize a
the mfs rpc library
to personalize a product
event stream filtering and
personalize a product recommendation
stream filtering and data
filtering and data mining
and data mining system
data mining system to
mining system to obtain
depending on the customer
system to obtain a
describes the use of
to obtain a scalable
on the customer s
the use of prioritised
the customer s profile
use of prioritised communication
of prioritised communication in
prioritised communication in mfs
communication in mfs and
in mfs and experiments
the service ranks matching
mfs and experiments to
service ranks matching products
hosted service capable of
ranks matching products differently
service capable of handling
matching products differently to
capable of handling very
products differently to maximize
of handling very high
differently to maximize the
handling very high event
to maximize the chance
very high event rates
maximize the chance of
and experiments to evaluate
end fec is very
the chance of a
fec is very attractive
chance of a purchase
is very attractive for
experiments to evaluate its
very attractive for communication
to evaluate its effectiveness
attractive for communication between
group used for system
for communication between data
if the product is
used for system management
communication between data centers
for system management service
system management service b
management service b x
presents and explains experimental
service b x y
and explains experimental results
b x y z
explains experimental results for
x y z x
experimental results for the
y z x y
results for the mfs
z x y z
for the mfs prefetching
easy to deploy and
the mfs prefetching mechanism
to deploy and customize
x y z x
as shown in figure
y z x y
z x y z
and does not require
x y z a
does not require specialized
does the same for
not require specialized equipment
the same for the
require specialized equipment in
the service assigns the
same for the cache
service assigns the search
for the cache consistency
assigns the search request
the cache consistency algorithm
the search request to
specialized equipment in the
y z a b
search request to the
equipment in the network
z a b service
in the network linking
a b service c
the network linking the
b service c a
network linking the data
service c a b
linking the data centers
c a b w
request to the racs
concludes and describes future
to the racs handling
and describes future work
the racs handling all
a b w figure
racs handling all ds
endhost fec has two
fec has two major
has two major issues
two major issues first
if sets of components
such as the customer
it s not transparent
as the customer s
sets of components are
the customer s name
of components are replicated
the most important part
customer s name are
most important part of
s name are equally
important part of mfs
name are equally plausible
part of mfs is
requiring modification of the
the associated multicast groups
modification of the end
associated multicast groups overlap
of mfs is the
multicast groups overlap hierarchically
mfs is the cache
is the cache manager
the load balancer then
load balancer then routes
the foregoing is the
balancer then routes the
foregoing is the primary
which intercepts file system
is the primary use
then routes the request
intercepts file system operations
routes the request to
the primary use scenario
the request to the
it s not necessarily
request to the appropriate
file system operations from
to the appropriate program
s not necessarily rapid
the appropriate program for
primary use scenario for
appropriate program for processing
use scenario for qsm
program for processing in
system operations from application
for processing in this
operations from application programs
fec works best over
from application programs and
works best over high
but may not be
processing in this case
application programs and resolves
may not be the
programs and resolves them
stable traffic rates and
not be the only
and resolves them into
traffic rates and performs
resolves them into accesses
be the only one
them into accesses to
with support for this
rates and performs poorly
into accesses to its
and performs poorly if
accesses to its local
performs poorly if the
to its local mfs
one could imagine an
support for this basic
could imagine an approach
for this basic layout
poorly if the data
its local mfs cache
if the data rate
local mfs cache or
the data rate in
mfs cache or rpcs
data rate in the
cache or rpcs to
imagine an approach to
or rpcs to a
it s possible to
rate in the channel
s possible to tackle
in the channel is
possible to tackle a
the channel is low
to tackle a wide
channel is low and
tackle a wide range
is low and sporadic
a wide range of
rpcs to a server
an approach to laying
wide range of secondary
approach to laying out
range of secondary issues
to laying out components
the cache manager has
laying out components on
cache manager has a
out components on a
manager has a number
components on a cluster
has a number of
on a cluster that
a number of components
a cluster that would
we could create standards
cluster that would result
could create standards for
that would result in
create standards for a
would result in irregular
those in solid boxes
standards for a self
result in irregular layouts
as in a single
in solid boxes are
in irregular layouts of
in a single end
solid boxes are part
managed raps of racs
irregular layouts of groups
boxes are part of
are part of the
part of the core
of the core system
or for one that
for one that guarantees
qsm can support such
one that guarantees real
can support such layouts
those in dashed boxes
in dashed boxes are
dashed boxes are optional
boxes are optional extensions
are optional extensions which
we present the maelstrom
optional extensions which are
at least to a
present the maelstrom error
such a basic architecture
the maelstrom error correction
a basic architecture is
extensions which are described
basic architecture is effectively
which are described in
architecture is effectively a
are described in subsequent
is effectively a framework
described in subsequent sections
effectively a framework to
maelstrom error correction appliance
least to a degree
error correction appliance a
a framework to resolve
correction appliance a rack
framework to resolve other
appliance a rack of
to resolve other related
a rack of proxies
but for reasons of
mfs overview mfs differs
for reasons of brevity
overview mfs differs from
reasons of brevity the
mfs differs from earlier
of brevity the discussion
differs from earlier mobile
brevity the discussion in
from earlier mobile file
the discussion in the
resolve other related issues
discussion in the remainder
earlier mobile file systems
in the remainder of
rack of proxies residing
the remainder of the
mobile file systems in
of proxies residing between
file systems in adjusting
proxies residing between a
systems in adjusting to
residing between a data
in adjusting to changing
group replication web services
adjusting to changing network
replication web services currently
to changing network conditions
web services currently lacks
changing network conditions using
remainder of the paper
between a data center
services currently lacks support
network conditions using modeless
currently lacks support for
conditions using modeless adaptation
lacks support for building
a data center and
of the paper focuses
support for building scalable
data center and its
it comprises a core
center and its wan
for building scalable services
and its wan link
the paper focuses on
comprises a core client
paper focuses on regular
the architecture makes it
architecture makes it easy
makes it easy to
it easy to build
easy to build a
hierarchically structured communication groups
to build a single
structured communication groups with
and a number of
communication groups with extensive
a number of subsystems
groups with extensive and
number of subsystems that
with extensive and regular
of subsystems that perform
node server that responds
extensive and regular overlap
server that responds to
maelstrom encodes fec packets
that responds to requests
subsystems that perform different
responds to requests from
that perform different kinds
to requests from some
perform different kinds of
requests from some set
different kinds of adaptation
initial users of our
encodes fec packets over
from some set of
fec packets over traffic
some set of clients
and can be selectively
users of our system
packets over traffic flowing
of our system haven
can be selectively enabled
our system haven t
over traffic flowing through
system haven t had
but there s no
traffic flowing through it
there s no way
flowing through it and
s no way to
through it and routes
no way to turn
shows the structure of
it and routes them
haven t had any
and routes them to
t had any difficulty
routes them to a
had any difficulty with
them to a corresponding
any difficulty with this
to a corresponding appliance
difficulty with this constraint
a corresponding appliance at
the structure of the
corresponding appliance at the
structure of the system
appliance at the destination
way to turn that
knowing qsm is particularly
to turn that single
qsm is particularly effective
turn that single server
is particularly effective with
that single server into
particularly effective with regular
at the destination data
in this section we
the destination data center
single server into a
this section we describe
server into a racs
section we describe the
into a racs or
we describe the core
a racs or turn
describe the core system
racs or turn a
effective with regular layouts
which decodes them and
or turn a set
decodes them and recovers
while subsequent sections do
them and recovers lost
subsequent sections do the
they just design to
sections do the same
just design to favor
do the same for
design to favor regularity
the same for the
turn a set of
and recovers lost data
same for the three
a set of racs
for the three main
set of racs into
the three main subsystems
maelstrom is completely transparent
of racs into a
is completely transparent it
racs into a raps
usage cases architecture reliable
completely transparent it does
cases architecture reliable multicast
transparent it does not
architecture reliable multicast is
it does not require
reliable multicast is a
does not require modification
multicast is a mature
not require modification of
is a mature area
require modification of end
it would be easy
we begin with an
would be easy to
begin with an overview
be easy to bridge
with an overview of
host software and is
an overview of mobile
easy to bridge the
overview of mobile file
software and is agnostic
of mobile file system
to bridge the gap
mobile file system design
and is agnostic to
file system design and
but a review of
is agnostic to the
bridge the gap if
system design and the
the gap if vendors
design and the relation
gap if vendors and
and the relation of
if vendors and platform
the relation of mfs
vendors and platform builders
agnostic to the network
a review of prior
relation of mfs to
review of prior systems
of mfs to previous
and platform builders wanted
to the network connecting
mfs to previous work
of prior systems convinced
platform builders wanted to
prior systems convinced us
builders wanted to do
the network connecting the
wanted to do so
network connecting the data
then briefly describe the
connecting the data centers
briefly describe the adaptive
systems convinced us that
describe the adaptive rpc
convinced us that no
the adaptive rpc library
us that no existing
adaptive rpc library used
that no existing system
structured partitioned service reliable
rpc library used in
no existing system would
partitioned service reliable array
existing system would work
it eliminates the dependence
system would work well
library used in mfs
would work well in
eliminates the dependence of
work well in the
the dependence of fec
well in the scenarios
dependence of fec recovery
in the scenarios targeted
of fec recovery latency
the scenarios targeted by
fec recovery latency on
scenarios targeted by our
recovery latency on the
targeted by our project
latency on the data
and the current mfs
on the data rate
the current mfs implementation
the data rate in
data rate in any
rate in any single
this forced us to
in any single node
forced us to build
us to build a
to build a new
build a new system
a new system that
new system that combines
x y z search
system that combines features
node channel by encoding
that combines features from
channel by encoding over
combines features from a
mfs design and related
features from a number
by encoding over the
y z search for
encoding over the aggregated
z search for digital
over the aggregated traffic
search for digital camera
the aggregated traffic leaving
for digital camera figure
aggregated traffic leaving the
from a number of
design and related work
traffic leaving the data
and related work the
leaving the data center
a number of prior
related work the core
number of prior systems
work the core of
the core of mfs
example of raps of
core of mfs follows
of raps of racs
of mfs follows a
mfs follows a design
our decision not to
follows a design common
decision not to use
a design common to
the service assigns a
design common to many
service assigns a digital
common to many mobile
maelstrom uses a new
not to use some
uses a new encoding
to many mobile file
a new encoding scheme
to use some existing
new encoding scheme called
use some existing multicast
encoding scheme called layered
many mobile file systems
assigns a digital camera
some existing multicast system
a digital camera search
scheme called layered interleaving
digital camera search request
existing multicast system reflects
camera search request to
multicast system reflects a
search request to the
system reflects a number
designed especially for time
request to the clustered
reflects a number of
to the clustered server
a number of issues
the clustered server handling
sensitive packet recovery in
clustered server handling all
packet recovery in the
server handling all ds
recovery in the presence
in the presence of
the presence of bursty
most prior multicast systems
presence of bursty loss
prior multicast systems were
and a load balancer
multicast systems were designed
a load balancer routes
systems were designed to
load balancer routes it
were designed to replicate
balancer routes it to
designed to replicate state
maelstrom s positioning as
to replicate state within
routes it to the
replicate state within just
s positioning as a
state within just a
it to the appropriate
positioning as a network
to the appropriate process
within just a single
as a network appliance
just a single group
a network appliance reflects
a single group at
network appliance reflects the
old and familiar technologies
appliance reflects the physical
single group at a
reflects the physical infrastructure
group at a time
and familiar technologies the
which use techniques such
the physical infrastructure of
use techniques such as
familiar technologies the most
physical infrastructure of modern
for example a single
technologies the most standard
techniques such as wholefile
the most standard form
example a single distributed
most standard form of
a single distributed service
standard form of system
such as wholefile caching
form of system support
infrastructure of modern data
of system support for
of modern data centers
some don t support
system support for building
and update logging combined
don t support multiple
modern data centers clean
support for building a
data centers clean insertion
for building a raps
centers clean insertion points
building a raps of
t support multiple groups
clean insertion points for
support multiple groups at
insertion points for proxy
multiple groups at all
points for proxy devices
a raps of racs
update logging combined with
raps of racs would
logging combined with asynchronous
of racs would draw
combined with asynchronous writes
racs would draw on
while others have overheads
for proxy devices exist
others have overheads linear
proxy devices exist on
have overheads linear in
would draw on virtual
overheads linear in the
draw on virtual synchrony
linear in the number
to cope with disconnections
devices exist on the
in the number of
cope with disconnections or
the number of groups
with disconnections or intermittent
number of groups to
disconnections or intermittent connectivity
of groups to which
exist on the high
group computing model developed
groups to which a
computing model developed at
the design of mfs
model developed at cornell
design of mfs is
developed at cornell in
of mfs is closest
at cornell in the
mfs is closest in
to which a node
speed lambda links that
is closest in structure
lambda links that interconnect
closest in structure to
links that interconnect individual
in structure to that
that interconnect individual data
which a node belongs
structure to that of
interconnect individual data centers
to that of coda
individual data centers to
data centers to each
centers to each other
s and used today
and used today to
we looked at jgroups
used today to run
today to run the
maelstrom can operate as
to run the new
can operate as either
run the new york
operate as either a
the new york and
as either a passive
new york and swiss
either a passive or
york and swiss stock
a passive or active
and swiss stock exchange
passive or active device
swiss stock exchange systems
or active device on
active device on these
device on these links
a component of the
the french air traffic
component of the jboss
french air traffic control
of the three problems
of the jboss platform
air traffic control system
the jboss platform which
the three problems of
jboss platform which runs
three problems of tcp
platform which runs in
which runs in a
runs in a managed
and the us navy
in a managed java
the us navy s
a managed java framework
us navy s aegis
maelstrom solves the first
jgroups wasn t designed
solves the first two
wasn t designed to
a host acting as
t designed to support
ibm s websphere platform
designed to support large
s websphere platform and
to support large numbers
the first two throughput
host acting as a
websphere platform and the
support large numbers of
platform and the windows
large numbers of overlapping
and the windows vista
numbers of overlapping groups
the windows vista clustering
acting as a client
windows vista clustering system
as a client of
vista clustering system also
a client of an
clustering system also use
client of an mfs
system also use versions
of an mfs file
first two throughput collapse
an mfs file system
and if configured to
also use versions of
two throughput collapse and
mfs file system runs
if configured to do
use versions of the
throughput collapse and realtime
file system runs a
collapse and realtime recovery
versions of the model
and realtime recovery delays
system runs a user
configured to do so
realtime recovery delays while
recovery delays while operating
although developers can t
delays while operating as
developers can t access
while operating as a
can t access the
operating as a passive
t access the internal
as a passive device
access the internal mechanisms
there has been a
which receives file system
a passive device that
receives file system operations
the internal mechanisms directly
passive device that does
has been a great
device that does not
been a great deal
that does not intervene
a great deal of
does not intervene in
the other popular standard
not intervene in the
other popular standard uses
intervene in the critical
popular standard uses a
in the critical communication
file system operations intercepted
the critical communication path
great deal of work
standard uses a state
system operations intercepted by
deal of work on
operations intercepted by a
of work on p
intercepted by a kernel
machine approach to guarantee
by a kernel module
approach to guarantee stronger
to guarantee stronger durability
p pubsub and content
pubsub and content delivery
and content delivery platforms
maelstrom handles the additional
content delivery platforms in
interacting with the vfs
handles the additional problem
with the vfs layer
the additional problem of
the vfs layer of
additional problem of massive
delivery platforms in recent
leslie lamport s paxos
vfs layer of the
problem of massive buffering
platforms in recent years
of massive buffering requirements
layer of the local
massive buffering requirements as
of the local file
buffering requirements as well
the local file system
lamport s paxos algorithm
often oriented towards content
oriented towards content filtering
towards content filtering in
at the cost of
content filtering in document
the cost of adding
filtering in document streams
cost of adding a
which is implemented in
of adding a point
we adopt the same
is implemented in scalable
adopt the same approach
adding a point of
implemented in scalable file
a point of failure
in scalable file systems
point of failure in
scalable file systems and
of failure in the
file systems and other
failure in the network
systems and other ultrareliable
in the network path
and other ultrareliable server
the same approach to
a good example is
other ultrareliable server designs
same approach to intercepting
good example is siena
the contributions of this
approach to intercepting vfs
contributions of this paper
to intercepting vfs operations
of this paper are
intercepting vfs operations as
a system that has
one architecture could support
system that has become
architecture could support both
this paper are as
that has become popular
paper are as follows
vfs operations as lbfs
could support both of
has become popular in
support both of these
become popular in wan
both of these powerful
making use of the
popular in wan settings
use of the kernel
of these powerful technologies
of the kernel module
the kernel module provided
kernel module provided as
module provided as part
end fec for long
provided as part of
a natural option would
as part of the
natural option would be
part of the arla
option would be to
distance communication between data
would be to offer
communication between data centers
be to offer them
of the arla afs
to offer them in
the arla afs client
offer them in the
them in the context
and argue that the
in the context of
argue that the rate
systems in this class
the context of ws
in this class incur
that the rate sensitivity
this class incur steep
the rate sensitivity of
class incur steep overheads
rate sensitivity of fec
incur steep overheads associated
sensitivity of fec codes
steep overheads associated with
of fec codes and
overheads associated with content
fec codes and the
associated with content filtering
codes and the opacity
and the opacity of
the opacity of their
the cache manager maintains
opacity of their implementations
cache manager maintains a
of their implementations present
manager maintains a cache
their implementations present major
maintains a cache of
implementations present major obstacles
if you re replicating
a cache of recently
present major obstacles to
you re replicating data
major obstacles to their
re replicating data within
messages often follow circuitous
obstacles to their usage
often follow circuitous routes
accessed mfs files on
follow circuitous routes from
mfs files on the
circuitous routes from source
files on the local
routes from source to
on the local disk
from source to destination
replicating data within some
data within some form
within some form of
some form of group
a gateway appliance that
when a vfs operation
gateway appliance that transparently
a vfs operation is
appliance that transparently aggregates
you can just as
that transparently aggregates traffic
can just as easily
transparently aggregates traffic and
just as easily imagine
aggregates traffic and encodes
as easily imagine that
traffic and encodes over
easily imagine that it
in high performance settings
vfs operation is intercepted
and encodes over the
operation is intercepted for
encodes over the resulting
is intercepted for a
over the resulting high
intercepted for a file
imagine that it has
these factors would degrade
that it has a
for a file that
factors would degrade the
it has a subject
would degrade the performance
has a subject name
degrade the performance of
a subject name in
the performance of the
we describe layered interleaving
a file that is
subject name in a
performance of the replicated
file that is not
name in a publish
of the replicated application
that is not in
a new fec scheme
is not in the
new fec scheme used
not in the cache
fec scheme used by
the spread multicast system
scheme used by maelstrom
spread multicast system implements
advantages with this type
multicast system implements lightweight
with this type of
system implements lightweight groups
this type of process
used by maelstrom where
it is retrieved in
by maelstrom where for
is retrieved in full
maelstrom where for constant
retrieved in full from
where for constant encoding
in full from the
for constant encoding overhead
data can be anything
full from the appropriate
constant encoding overhead the
from the appropriate server
encoding overhead the latency
overhead the latency of
the latency of packet
latency of packet recovery
and the vfs operation
of packet recovery degrades
the vfs operation is
packet recovery degrades gracefully
vfs operation is then
recovery degrades gracefully as
operation is then resumed
degrades gracefully as losses
gracefully as losses get
as losses get burstier
mfs uses the writeback
the groups seen by
groups seen by applications
seen by applications are
we discuss implementation considerations
by applications are an
applications are an illusion
close semantics first implemented
we built two versions
semantics first implemented in
built two versions of
first implemented in the
two versions of maelstrom
implemented in the andrew
there is really only
in the andrew file
w e b te
the andrew file system
is really only one
e b te c
really only one use
b te c h
one runs in user
te c h n
only one use of
c h n o
one use of qsm
h n o l
use of qsm in
runs in user mode
of qsm in our
n o l o
qsm in our target
o l o g
in our target settings
l o g i
our target settings gives
while the other runs
target settings gives rise
the other runs within
settings gives rise to
other runs within the
when a dirty file
runs within the linux
a dirty file is
within the linux kernel
dirty file is closed
o g i e
gives rise to potentially
g i e s
rise to potentially large
i e s concerns
we evaluate maelstrom on
to potentially large numbers
evaluate maelstrom on emulab
potentially large numbers of
the entire file contents
large numbers of overlapping
entire file contents are
numbers of overlapping communication
file contents are transferred
of overlapping communication groups
contents are transferred to
e s concerns experience
are transferred to the
s concerns experience with
transferred to the server
concerns experience with corba
as we have seen
experience with corba even
with corba even good
corba even good ideas
even good ideas can
and show that it
the primary goal is
show that it provides
good ideas can be
that it provides near
primary goal is to
ideas can be used
goal is to support
it provides near lossless
can be used in
though scheme for minimising
be used in ways
scheme for minimising bandwidth
used in ways that
is to support data
provides near lossless tcp
to support data replication
in ways that developers
for minimising bandwidth utilisation
ways that developers dislike
support data replication in
minimising bandwidth utilisation when
data replication in scalable
ip throughput and latency
bandwidth utilisation when transferring
that developers dislike and
utilisation when transferring files
developers dislike and ultimately
when transferring files is
dislike and ultimately reject
transferring files is not
throughput and latency over
files is not used
and latency over lossy
is not used in
in which sets of
latency over lossy links
not used in mfs
a good example of
which sets of components
good example of this
sets of components are
and recovers packets with
example of this occurred
of components are interconnected
although it is orthogonal
components are interconnected and
it is orthogonal to
are interconnected and cooperate
is orthogonal to mfs
interconnected and cooperate to
of this occurred when
recovers packets with latency
orthogonal to mfs adaptation
packets with latency independent
to mfs adaptation and
and cooperate to perform
mfs adaptation and could
cooperate to perform requests
adaptation and could be
with latency independent of
this occurred when the
latency independent of the
and could be added
independent of the rtt
could be added to
of the rtt of
be added to further
occurred when the corba
the rtt of the
added to further improve
rtt of the link
components sets are normally
of the link and
sets are normally colocated
the link and the
when the corba community
to further improve performance
link and the rate
the corba community decided
when a service is
and the rate in
corba community decided to
a service is replicated
the rate in any
the server that stores
community decided to tackle
server that stores a
rate in any single
that stores a file
each of its constituent
in any single channel
of its constituent components
stores a file is
its constituent components will
a file is responsible
constituent components will need
file is responsible for
components will need to
is responsible for maintaining
will need to replicate
responsible for maintaining the
need to replicate its
m odel loss model
to replicate its portion
decided to tackle replication
for maintaining the mutual
to tackle replication for
maintaining the mutual consistency
packet loss typically occurs
the mutual consistency of
tackle replication for fault
replicate its portion of
replication for fault tolerance
mutual consistency of the
for fault tolerance but
consistency of the copies
fault tolerance but then
its portion of the
tolerance but then stumbled
portion of the service
loss typically occurs at
of the copies cached
but then stumbled by
of the service state
then stumbled by presenting
the copies cached by
stumbled by presenting the
copies cached by clients
typically occurs at two
if qsm is used
by presenting the technology
occurs at two points
presenting the technology to
it records which clients
qsm is used to
the technology to developers
at two points in
is used to disseminate
records which clients cache
technology to developers in
two points in an
to developers in a
points in an end
developers in a way
which clients cache the
used to disseminate updates
in a way that
clients cache the file
a way that was
way that was much
that was much too
this results in a
was much too limiting
results in a pattern
much too limiting for
in a pattern of
too limiting for general
a pattern of communication
limiting for general use
pattern of communication groups
and is responsible for
end communication path between
of communication groups that
is responsible for notifying
communication path between two
communication groups that are
responsible for notifying them
path between two data
tolerance mechanism is based
for notifying them of
groups that are exactly
between two data centers
mechanism is based on
notifying them of changes
that are exactly overlapped
is based on the
as shown in figure
based on the virtual
on the virtual synchrony
mfs implements a variation
each replicated component will
implements a variation of
replicated component will have
a variation of the
component will have one
variation of the scheme
will have one or
of the scheme used
area network connecting them
the scheme used by
network connecting them and
scheme used by coda
connecting them and at
have one or more
the virtual synchrony model
them and at the
one or more associated
and at the receiving
when a file is
or more associated groups
at the receiving end
but the programming tools
a file is retrieved
the programming tools built
file is retrieved from
programming tools built over
delivering update streams to
tools built over this
is retrieved from the
built over this model
update streams to its
over this model prevent
streams to its replicas
loss in the lambda
this model prevent developers
retrieved from the server
in the lambda link
model prevent developers from
the lambda link can
prevent developers from using
lambda link can occur
developers from using threads
a datacenter will typically
link can occur for
the server issues a
datacenter will typically host
can occur for many
server issues a limited
will typically host many
occur for many reasons
typically host many services
guis or other direct
or other direct end
each with a disjoint
with a disjoint set
obliging it to inform
a disjoint set of
it to inform the
disjoint set of components
to inform the client
inform the client through
the client through a
dirty or degraded fiber
client through a callback
through a callback if
and often deployed on
a callback if another
often deployed on disjoint
malfunctioning or misconfigured equipment
callback if another host
deployed on disjoint sets
if another host modifies
on disjoint sets of
another host modifies the
low receiver power and
host modifies the file
receiver power and burst
disjoint sets of nodes
power and burst switching
or even prebuilt libraries
and burst switching contention
if the callback promise
burst switching contention are
the callback promise expires
in cases where two
in the corba approach
cases where two services
switching contention are some
callback promise expires without
where two services are
contention are some reasons
promise expires without a
two services are co
expires without a callback
a developer who obeys
without a callback being
developer who obeys this
a callback being issued
who obeys this long
located on the same
obeys this long list
on the same node
this long list of
the client must revalidate
long list of constraints
client must revalidate the
list of constraints can
must revalidate the file
of constraints can do
revalidate the file before
we ll still see
constraints can do lockstep
ll still see heavy
can do lockstep replication
the file before using
do lockstep replication of
file before using it
still see heavy overlap
lockstep replication of a
replication of a program
of a program for
a program for tolerance
the cache consistency algorithm
but unless the degree
cache consistency algorithm is
unless the degree of
consistency algorithm is described
the degree of replication
algorithm is described in
degree of replication is
is described in more
of replication is identical
described in more detail
program for tolerance of
in more detail in
for tolerance of hardware
more detail in section
there may be two
tolerance of hardware faults
may be two cases
nodes that host both
that host both services
and hence both sets
hence both sets of
both sets of qsm
the scheme doesn t
sets of qsm groups
scheme doesn t protect
doesn t protect against
t protect against software
adaptive rpc library the
rpc library the fundamental
library the fundamental difference
the fundamental difference between
and nodes that just
fundamental difference between mfs
nodes that just host
difference between mfs and
that just host one
between mfs and other
just host one of
developers regard the standard
mfs and other file
host one of them
regard the standard as
and other file systems
the standard as rigid
other file systems we
standard as rigid and
file systems we have
cluster management systems use
as rigid and limited
management systems use groups
systems we have described
systems use groups for
we have described is
use groups for purposes
have described is in
groups for purposes other
described is in the
for purposes other than
is in the communication
they need fault tolerance
loss can also occur
purposes other than component
in the communication between
can also occur at
the communication between the
but not in this
other than component replication
not in this very
also occur at receiving
communication between the cache
in this very narrow
occur at receiving end
such as tracking node
this very narrow form
between the cache manager
as tracking node status
the cache manager and
hosts within the destination
tracking node status and
cache manager and servers
within the destination data
node status and launching
systems like the isis
status and launching applications
like the isis toolkit
the destination data center
while lbfs uses a
lbfs uses a variant
uses a variant of
a variant of the
these groups will span
variant of the nfs
groups will span large
of the nfs rpc
will span large numbers
the nfs rpc protocol
these are usually cheap
popular during the early
are usually cheap commodity
during the early and
span large numbers of
usually cheap commodity machines
large numbers of nodes
the early and mid
cheap commodity machines prone
commodity machines prone to
machines prone to temporary
perhaps the entire cluster
prone to temporary overloads
to temporary overloads that
temporary overloads that cause
overloads that cause packets
such groups overlap with
that cause packets to
groups overlap with everything
cause packets to be
packets to be dropped
to be dropped by
be dropped by the
dropped by the kernel
by the kernel in
the result is an
the kernel in bursts
result is an environment
also used virtual synchrony
is an environment in
uses a customised rpc
used virtual synchrony but
an environment in which
virtual synchrony but had
environment in which there
synchrony but had fewer
in which there will
but had fewer limitations
which there will be
there will be a
unlike coda s rpc
will be a hierarchy
this loss mode occurs
they supported many of
loss mode occurs with
supported many of the
mode occurs with udp
many of the mechanisms
the rpc used in
of the mechanisms needed
rpc used in mfs
the mechanisms needed to
used in mfs incorporates
mechanisms needed to build
in mfs incorporates novel
based traffic but not
mfs incorporates novel features
needed to build and
incorporates novel features to
to build and manage
novel features to allow
traffic but not with
features to allow it
build and manage a
to allow it to
and manage a raps
allow it to adapt
manage a raps of
it to adapt to
a raps of racs
to adapt to network
but not with tcp
adapt to network variability
qsm is highly effective
is highly effective in
and their successes have
highly effective in supporting
their successes have clearly
effective in supporting this
successes have clearly demonstrated
in supporting this style
have clearly demonstrated the
supporting this style of
clearly demonstrated the model
this style of use
demonstrated the model s
the mfs rpc library
which advertises receiver windows
mfs rpc library is
advertises receiver windows to
rpc library is implemented
receiver windows to prevent
library is implemented on
the model s effectiveness
windows to prevent end
is implemented on top
implemented on top of
on top of the
top of the adaptive
isis is no longer
of the adaptive transport
is no longer available
the adaptive transport protocol
no longer available as
recover in y inter
longer available as a
what are typical loss
available as a product
are typical loss rates
region protocol y intra
typical loss rates on
loss rates on long
yet many critical systems
many critical systems continue
in discussing mfs rpc
critical systems continue to
systems continue to use
continue to use isis
consisting of a small
the answer to this
of a small set
we give an overview
a small set of
give an overview of
small set of servers
answer to this question
based solutions or other
an overview of the
set of servers to
overview of the parts
of servers to which
of the parts of
servers to which client
to this question is
solutions or other virtual
the parts of atp
to which client systems
this question is surprisingly
or other virtual synchrony
parts of atp which
which client systems connect
question is surprisingly hard
other virtual synchrony implementations
of atp which are
is surprisingly hard to
atp which are most
which are most relevant
are most relevant to
most relevant to mfs
level multicast is vectored
multicast is vectored through
machine approach as used
is vectored through a
approach as used in
vectored through a server
as used in the
used in the paxos
in the paxos algorithm
the paxos algorithm is
atp and its design
which multicasts it to
and its design motivations
paxos algorithm is also
its design motivations have
algorithm is also becoming
design motivations have been
is also becoming more
motivations have been described
multicasts it to its
have been described in
it to its peers
been described in more
also becoming more popular
described in more detail
in more detail in
more detail in our
detail in our earlier
these filter the ordered
in our earlier work
filter the ordered multicast
the key insight is
the ordered multicast stream
key insight is that
ordered multicast stream and
insight is that these
multicast stream and relay
is that these successes
stream and relay messages
that these successes use
and relay messages back
these successes use similar
relay messages back out
successes use similar ideas
messages back out to
use similar ideas but
back out to receivers
similar ideas but in
ideas but in ways
the hypothesis underlying atp
but in ways very
hypothesis underlying atp is
this approach can support
underlying atp is that
approach can support huge
in ways very different
can support huge numbers
ways very different from
support huge numbers of
very different from what
huge numbers of groups
different from what the
numbers of groups with
from what the corba
of groups with irregular
what the corba fault
groups with irregular overlap
atp is that adapting
with irregular overlap patterns
is that adapting to
that adapting to network
adapting to network variation
to network variation by
but the servers are
network variation by structuring
the servers are a
variation by structuring applications
servers are a point
by structuring applications according
are a point of
structuring applications according to
a point of contention
applications according to modes
what we need today
according to modes is
to modes is not
we need today is
modes is not always
and the indirect communication
need today is a
the indirect communication pathway
is not always appropriate
today is a modern
indirect communication pathway introduces
communication pathway introduces potentially
is a modern revisiting
pathway introduces potentially high
introduces potentially high latencies
and can sometimes lead
a modern revisiting of
can sometimes lead to
sometimes lead to poor
modern revisiting of this
lead to poor performance
these considerations convinced us
revisiting of this technology
considerations convinced us that
convinced us that a
of this technology that
us that a new
that a new system
this technology that draws
a new system was
new system was needed
technology that draws on
shows the results of
that draws on group
the results of an
draws on group communication
qsm implements a approach
results of an experiment
implements a approach similar
on group communication but
of an experiment in
a approach similar to
group communication but packages
an experiment in which
approach similar to spread
experiment in which modeless
similar to spread s
communication but packages it
to spread s lightweight
in which modeless adaptation
but packages it in
spread s lightweight group
which modeless adaptation over
packages it in a
s lightweight group abstraction
modeless adaptation over atp
it in a way
adaptation over atp achieves
in a way that
over atp achieves higher
a way that developers
atp achieves higher bandwidth
but without a separate
achieves higher bandwidth utilisation
without a separate server
way that developers perceive
higher bandwidth utilisation than
that developers perceive as
bandwidth utilisation than we
developers perceive as solving
utilisation than we will
a separate server group
than we will concentrate
perceive as solving their
we will concentrate on
as solving their most
will concentrate on a
solving their most pressing
we define a region
concentrate on a system
their most pressing scalability
define a region of
most pressing scalability problems
a region of overlap
pressing scalability problems and
region of overlap to
scalability problems and that
of overlap to be
problems and that flexibly
overlap to be a
and that flexibly matches
on a system with
that flexibly matches their
a system with a
flexibly matches their preferred
system with a single
to be a set
with a single server
matches their preferred styles
be a set of
their preferred styles and
a set of nodes
preferred styles and tools
set of nodes with
mfs is designed to
of nodes with approximately
is designed to support
nodes with approximately the
designed to support multiple
other kinds of persistent
to support multiple mfs
kinds of persistent objects
support multiple mfs file
with approximately the same
multiple mfs file servers
approximately the same group
the same group membership
modal adaptation modeless adaptation
the user simply designs
user simply designs a
simply designs a data
designs a data structure
a data structure and
data structure and employs
of lost packets fig
under the assumptions of
structure and employs multicast
the assumptions of section
and employs multicast technology
employs multicast technology to
true bandwidth bandwidth used
multicast technology to transmit
technology to transmit updates
to transmit updates to
transmit updates to the
updates to the group
to the group members
our cluster should be
cluster should be nicely
should be nicely tiled
loss rates on teragrid
be nicely tiled by
rates on teragrid determine
nicely tiled by regions
which apply them in
apply them in the
them in the same
in the same order
the same order everywhere
qsm uses regions for
perhaps because such links
uses regions for multicast
because such links are
regions for multicast dissemination
such links are a
for multicast dissemination and
links are a relatively
multicast dissemination and for
are a relatively recent
dissemination and for recovery
a relatively recent addition
and for recovery of
can be done on
relatively recent addition to
be done on any
recent addition to the
for recovery of lost
addition to the networking
recovery of lost packets
done on any desired
to the networking landscape
on any desired copy
the networking landscape and
employing different protocols for
networking landscape and their
different protocols for each
landscape and their ownership
protocols for each purpose
and their ownership is
their ownership is still
examples of updates include
ownership is still mostly
of updates include a
is still mostly restricted
updates include a stock
protocol node x recover
include a stock trade
still mostly restricted to
a stock trade or
mostly restricted to commercial
stock trade or stock
node x recover in
restricted to commercial organizations
trade or stock market
to commercial organizations disinclined
or stock market quote
commercial organizations disinclined to
x recover in x
organizations disinclined to reveal
recover in x region
disinclined to reveal such
in x region figure
a new object detected
to reveal such information
new object detected by
object detected by radar
detected by radar in
by radar in an
radar in an air
in an air traffic
one source of information
hierarchical recovery in qsm
source of information is
an air traffic control
of information is teragrid
air traffic control system
a group spans multiple
group spans multiple regions
a communication to or
communication to or from
to or from an
or from an aircraft
each region has an
region has an associated
has an associated structure
an associated structure of
associated structure of token
or the addition of
structure of token rings
the addition of a
addition of a node
of a node to
a node to a
an optical network interconnecting
node to a distributed
optical network interconnecting major
to a distributed data
network interconnecting major supercomputing
a distributed data structure
interconnecting major supercomputing sites
distributed data structure containing
to recover from packet
data structure containing an
recover from packet loss
structure containing an index
major supercomputing sites in
containing an index of
supercomputing sites in the
an index of pending
qsm uses a hierarchical
index of pending orders
uses a hierarchical structure
of pending orders in
a hierarchical structure of
pending orders in an
hierarchical structure of token
orders in an online
structure of token rings
in an online warehouse
sites in the us
we considered using other
data replication can be
considered using other structures
teragrid has a monitoring
replication can be remarkably
has a monitoring framework
can be remarkably cheap
a monitoring framework within
monitoring framework within which
framework within which ten
within which ten sites
which ten sites periodically
with modern technology and
ten sites periodically send
modern technology and small
sites periodically send each
technology and small updates
periodically send each other
but token rings produce
token rings produce a
rings produce a more
produce a more predictable
a more predictable traffic
more predictable traffic pattern
gbps streams of udp
streams of udp packets
of udp packets and
udp packets and measure
packets and measure the
the importance of this
and measure the resulting
importance of this will
measure the resulting loss
of this will become
the resulting loss rate
this will become clear
computer chrony service can
will become clear later
chrony service can run
service can run at
can run at rates
run at rates well
at rates well in
rates well in excess
well in excess of
the basic structure is
basic structure is illustrated
structure is illustrated in
is illustrated in figure
each site measures the
at the highest level
site measures the loss
measures the loss rate
the loss rate to
loss rate to every
rate to every other
qsm circulates tokens around
to every other site
circulates tokens around sets
every other site once
tokens around sets of
other site once an
around sets of regions
site once an hour
aggregating information that can
resulting in a total
information that can be
in a total of
that can be used
can be used by
true bandwidth bandwidth used
be used by a
used by a group
ordered updates per second
by a group sender
a group sender to
loss rate measurements collected
group sender to retransmit
rate measurements collected across
sender to retransmit packets
measurements collected across the
to retransmit packets that
collected across the network
retransmit packets that were
even if an update
across the network every
packets that were missed
if an update requires
the network every hour
an update requires a
that were missed by
update requires a large
were missed by entire
requires a large message
missed by entire regions
it s possible to
shows that between nov
s possible to maintain
possible to maintain rates
to maintain rates of
maintain rates of thousands
rates of thousands per
of thousands per second
thousands per second on
per second on typical
second on typical hardware
a token circulates to
token circulates to provide
circulates to provide loss
the virtual synchrony and
to provide loss recovery
virtual synchrony and statemachine
provide loss recovery at
synchrony and statemachine models
loss recovery at the
and statemachine models show
recovery at the level
statemachine models show how
at the level of
models show how a
the level of nodes
show how a tremendous
level of nodes belonging
how a tremendous range
of nodes belonging to
a tremendous range of
nodes belonging to the
tremendous range of application
belonging to the region
range of application requirements
of application requirements can
application requirements can map
requirements can map down
can map down to
map down to a
down to a rigorously
to a rigorously precise
a rigorously precise execution
rigorously precise execution model
if regions become large
which in turn can
in turn can be
turn can be used
qsm partitions them into
can be used to
partitions them into smaller
be used to validate
them into smaller rings
used to validate a
to validate a platform
this is illustrated in
is illustrated in figure
because the models have
the models have formal
models have formal specifications
you can test the
can test the correctness
of all such measurements
in the experiments reported
all such measurements were
test the correctness of
such measurements were over
the correctness of an
the experiments reported in
correctness of an implementation
experiments reported in this
reported in this paper
and even use theorem
no token ring ever
even use theorem provers
token ring ever grows
use theorem provers to
ring ever grows larger
theorem provers to assist
ever grows larger than
provers to assist developers
grows larger than about
to assist developers in
assist developers in testing
developers in testing their
in testing their most
testing their most critical
their most critical application
most critical application components
one reason that we
and the system uses
reason that we lack
the system uses single
of them were over
that we lack this
system uses single and
we lack this sort
uses single and two
lack this sort of
this sort of support
sort of support today
of support today is
support today is that
today is that vendors
is that vendors and
that vendors and platform
vendors and platform developers
and platform developers worry
we plan to experiment
platform developers worry that
plan to experiment with
developers worry that these
to experiment with larger
worry that these forms
after eliminating a single
that these forms of
eliminating a single site
experiment with larger configurations
these forms of replication
with larger configurations and
forms of replication haven
larger configurations and will
of replication haven t
configurations and will work
replication haven t achieved
and will work with
haven t achieved huge
will work with deeper
t achieved huge market
work with deeper hierarchies
achieved huge market success
that dropped incoming packets
dropped incoming packets steadily
incoming packets steadily at
packets steadily at a
the qsm recovery protocol
steadily at a rate
as the experience with
qsm recovery protocol uses
at a rate of
recovery protocol uses tokens
the experience with corba
protocol uses tokens to
experience with corba sidebar
uses tokens to track
with corba sidebar describes
tokens to track message
to track message status
the common object request
common object request broker
object request broker architecture
request broker architecture offers
modal versus modeless adaptation
broker architecture offers a
versus modeless adaptation with
architecture offers a fault
modeless adaptation with atp
tolerant groups mechanism that
the left graph shows
groups mechanism that was
left graph shows performance
mechanism that was based
graph shows performance with
that was based on
shows performance with modal
was based on the
performance with modal adaptation
based on the virtual
on the virtual synchrony
the virtual synchrony model
the token carries ack
token carries ack and
carries ack and nak
and the right graph
ack and nak information
the right graph shows
right graph shows a
of the remainder were
graph shows a scheme
the remainder were over
the corba standard is
aggregated over the nodes
shows a scheme in
over the nodes below
corba standard is widely
a scheme in which
standard is widely viewed
scheme in which there
is widely viewed as
in which there are
the nodes below each
which there are four
nodes below each ring
there are four classes
widely viewed as rigid
are four classes of
viewed as rigid and
four classes of messages
token rings avoid the
classes of messages being
rings avoid the kinds
of messages being sent
avoid the kinds of
messages being sent simultaneously
the kinds of ack
as rigid and limited
nak implosion problems with
i believe that the
implosion problems with which
believe that the corba
the lowest line corresponds
problems with which reliable
lowest line corresponds to
that the corba community
with which reliable multicast
the corba community erred
which reliable multicast protocols
corba community erred by
reliable multicast protocols traditionally
line corresponds to the
multicast protocols traditionally have
corresponds to the highest
protocols traditionally have struggled
to the highest priority
community erred by embedding
erred by embedding a
by embedding a powerful
embedding a powerful solution
but problems of their
a powerful solution into
problems of their own
powerful solution into a
solution into a tool
dark horizontal lines represent
into a tool mismatched
horizontal lines represent operating
a tool mismatched to
if a message is
these numbers may look
lines represent operating modes
numbers may look small
represent operating modes on
may look small in
operating modes on the
look small in absolute
modes on the left
tool mismatched to developer
a message is lost
small in absolute terms
mismatched to developer needs
and the highest priority
the highest priority of
the sender may not
but they are sufficient
sender may not find
they are sufficient to
may not find out
highest priority of data
not find out for
web services move beyond
find out for quite
services move beyond corba
out for quite a
priority of data being
are sufficient to bring
move beyond corba in
for quite a while
of data being sent
sufficient to bring tcp
beyond corba in many
data being sent during
corba in many ways
being sent during a
sent during a second
during a second on
ip throughput crashing down
a second on the
throughput crashing down on
this isn t a
but the corba community
isn t a major
second on the right
t a major issue
crashing down on high
a major issue because
the corba community s
major issue because most
corba community s failed
issue because most message
community s failed effort
because most message losses
s failed effort to
most message losses can
the modeless scheme achieves
failed effort to implement
message losses can be
effort to implement virtual
losses can be corrected
to implement virtual synchrony
can be corrected locally
modeless scheme achieves higher
implement virtual synchrony carries
scheme achieves higher utilisation
virtual synchrony carries an
conventional wisdom states that
synchrony carries an important
wisdom states that optical
carries an important lesson
states that optical links
an important lesson to
that optical links do
important lesson to current
optical links do not
lesson to current researchers
links do not drop
through cooperation among receivers
do not drop packets
any technology offered to
the basic idea is
technology offered to developers
basic idea is to
offered to developers must
idea is to perform
to developers must support
mb of data sent
developers must support the
grade optical equipment is
must support the programming
optical equipment is configured
support the programming styles
is to perform recovery
the programming styles they
equipment is configured to
programming styles they prefer
is configured to shut
because it always has
to perform recovery as
configured to shut down
perform recovery as locally
it always has messages
management policies a scalable
always has messages to
policies a scalable services
has messages to send
recovery as locally as
a scalable services architecture
as locally as possible
scalable services architecture for
to shut down beyond
services architecture for building
shut down beyond bit
architecture for building raps
down beyond bit error
while the modal scheme
beyond bit error rates
for building raps of
bit error rates of
building raps of racs
the modal scheme is
raps of racs alone
modal scheme is dependent
of racs alone isn
scheme is dependent on
racs alone isn t
is dependent on a
alone isn t enough
dependent on a rapid
if a message is
on a rapid and
a message is available
a rapid and accurate
message is available within
rapid and accurate estimate
is available within the
one out of a
scale systems that will
out of a trillion
systems that will likely
available within the same
that will likely soon
and accurate estimate of
will likely soon rely
accurate estimate of the
likely soon rely on
within the same token
of a trillion bits
estimate of the available
soon rely on standardized
of the available bandwidth
rely on standardized web
the available bandwidth in
on standardized web services
available bandwidth in order
standardized web services including
bandwidth in order to
web services including global
in order to select
services including global banks
order to select its
the reliability of the
the same token ring
reliability of the lambda
to select its correct
of the lambda network
the entire us air
the lambda network is
entire us air force
select its correct operating
some process that has
its correct operating mode
process that has a
lambda network is clearly
that has a a
network is clearly not
and the supervisory control
has a a a
the supervisory control and
a a a c
is clearly not equal
supervisory control and data
clearly not equal to
a a c ac
control and data acquisition
a c ac ab
not equal to the
and data acquisition systems
c ac ab abc
data acquisition systems that
ac ab abc bc
equal to the sum
acquisition systems that operate
ab abc bc b
to the sum of
systems that operate the
abc bc b c
that operate the us
bc b c b
the sum of its
operate the us power
b c b figure
the us power grid
these graphs are reproduced
us power grid will
graphs are reproduced from
power grid will also
sum of its optical
grid will also require
of its optical parts
will also require policies
also require policies to
require policies to manage
groups overlap to form
policies to manage security
overlap to form regions
to manage security keys
it s less reliable
nodes belong to the
s less reliable by
belong to the same
less reliable by orders
to the same region
reliable by orders of
the same region if
an equivalent modal scheme
same region if they
by orders of magnitude
region if they have
if they have similar
they have similar group
have similar group membership
other experiments have shown
automated tools for monitoring
experiments have shown that
tools for monitoring large
have shown that modeless
applications and protocols such
shown that modeless adaptation
for monitoring large complex
that modeless adaptation can
monitoring large complex systems
qsm currently uses an
and protocols such as
modeless adaptation can achieve
large complex systems will
adaptation can achieve improvements
currently uses an unreliable
can achieve improvements of
uses an unreliable ip
complex systems will be
protocols such as tcp
an unreliable ip multicast
systems will be needed
will be needed as
be needed as well
ip which expect extreme
since a single group
which expect extreme reliability
a single group may
expect extreme reliability from
single group may span
extreme reliability from the
group may span multiple
reliability from the high
researchers must think about
may span multiple regions
must think about how
think about how monitoring
about how monitoring and
speed network are instead
to send to group
how monitoring and management
network are instead subjected
monitoring and management policies
are instead subjected to
send to group g
instead subjected to unexpectedly
and it is possible
subjected to unexpectedly high
it is possible to
to unexpectedly high loss
and management policies in
a node multicasts a
management policies in different
node multicasts a message
unexpectedly high loss rates
is possible to construct
policies in different organizations
possible to construct cases
multicasts a message to
to construct cases in
in different organizations should
construct cases in which
a message to each
different organizations should talk
cases in which the
organizations should talk to
in which the improvement
should talk to one
which the improvement is
talk to one another
the improvement is even
to one another when
improvement is even greater
one another when web
message to each of
these numbers reflect the
another when web services
numbers reflect the loss
to each of the
reflect the loss rate
work on adaptation in
the loss rate specifically
on adaptation in mobile
loss rate specifically experienced
adaptation in mobile file
rate specifically experienced by
in mobile file systems
specifically experienced by udp
when web services interactions
each of the regions
mobile file systems has
experienced by udp traffic
file systems has generally
web services interactions cross
systems has generally relied
services interactions cross boundaries
has generally relied on
of the regions separately
by udp traffic on
generally relied on modal
these are tough problems
udp traffic on an
relied on modal schemes
traffic on an end
but they can be
they can be solved
our approach makes it
end path and may
at cornell we recently
approach makes it easy
cornell we recently developed
makes it easy to
we recently developed astrolabe
it easy to aggregate
path and may not
easy to aggregate messages
and may not generalize
to aggregate messages across
may not generalize to
aggregate messages across different
not generalize to tcp
messages across different groups
a scalable technology for
generalize to tcp packets
scalable technology for distributed
technology for distributed monitoring
for distributed monitoring and
distributed monitoring and control
monitoring and control that
but our evaluation of
and control that has
our evaluation of atp
control that has attracted
evaluation of atp demonstrated
we do not know
if a node has
of atp demonstrated that
a node has two
that has attracted tremendous
atp demonstrated that it
has attracted tremendous interest
demonstrated that it could
attracted tremendous interest and
that it could also
tremendous interest and attention
it could also improve
node has two messages
do not know if
could also improve the
not know if packets
also improve the performance
researchers at other institutions
has two messages to
at other institutions are
know if packets were
other institutions are working
two messages to send
improve the performance of
if packets were dropped
institutions are working on
packets were dropped within
are working on other
were dropped within the
working on other promising
messages to send to
the performance of file
dropped within the optical
on other promising solutions
within the optical network
performance of file system
the optical network or
to send to a
optical network or at
send to a pair
calability isn t just
network or at intermediate
to a pair of
or at intermediate devices
isn t just a
at intermediate devices within
t just a technology
a pair of groups
intermediate devices within either
we discuss the implementation
pair of groups g
devices within either data
discuss the implementation of
it s also a
the implementation of modeless
s also a mindset
implementation of modeless adaptation
also a mindset with
of modeless adaptation in
within either data center
which overlap in region
modeless adaptation in mfs
a mindset with ramifications
though it s unlikely
mindset with ramifications at
it s unlikely that
with ramifications at many
s unlikely that they
ramifications at many levels
unlikely that they were
adaptation in mfs further
that they were dropped
overlap in region r
in mfs further in
they were dropped at
to ensure true scalability
mfs further in section
were dropped at the
then while transmitting to
dropped at the end
while transmitting to r
web services platforms must
services platforms must begin
platforms must begin to
the node can batch
atp is implemented at
must begin to standardize
node can batch these
begin to standardize application
can batch these messages
many of the measurements
is implemented at user
of the measurements lost
implemented at user level
the measurements lost just
batch these messages together
measurements lost just one
to standardize application architectures
lost just one or
on top of kernel
standardize application architectures that
just one or two
apps send to a
one or two packets
send to a send
application architectures that promote
to a send to
or two packets whereas
a send to b
architectures that promote reliability
send to b group
that promote reliability and
to b group senders
promote reliability and interoperability
b group senders a
reliability and interoperability when
group senders a b
and interoperability when developers
senders a b c
interoperability when developers build
a b c region
when developers build systems
b c region senders
developers build systems of
top of kernel udp
two packets whereas kernel
c region senders a
build systems of systems
region senders a ab
it has a message
senders a ab ac
nic losses are known
a ab ac abc
losses are known to
ab ac abc b
work with intrinsically distributed
are known to be
oriented interface for communication
known to be bursty
with intrinsically distributed programs
ac abc b c
intrinsically distributed programs that
abc b c bc
distributed programs that don
b c bc region
in which messages of
c bc region leader
programs that don t
which messages of an
bc region leader figure
messages of an arbitrary
that don t fit
of an arbitrary size
don t fit a
an arbitrary size can
t fit a transactional
arbitrary size can be
fit a transactional model
size can be reliably
can be reliably transmitted
to multicast to a
be reliably transmitted with
multicast to a group
reliably transmitted with their
and must provide responsiveness
transmitted with their boundaries
must provide responsiveness guarantees
with their boundaries preserved
qsm sends a copy
provide responsiveness guarantees to
loss occurred on paths
their boundaries preserved at
occurred on paths where
boundaries preserved at the
on paths where levels
preserved at the receiver
paths where levels of
at the receiver s
where levels of optical
the receiver s side
responsiveness guarantees to their
levels of optical link
sends a copy to
guarantees to their users
of optical link utilization
a copy to each
an application can send
copy to each of
application can send a
to each of the
can send a message
each of the underlying
send a message synchronously
of the underlying regions
a message synchronously or
applications with these sorts
message synchronously or asynchronously
with these sorts of
these sorts of requirements
sorts of requirements are
of requirements are already
in the latter case
requirements are already in
the latter case the
partition leader token intrapartition
latter case the sender
are already in the
case the sender provides
already in the pipeline
leader token intrapartition token
in the pipeline and
token intrapartition token partition
the pipeline and even
intrapartition token partition figure
pipeline and even more
the sender provides a
and even more of
were consistently lower than
sender provides a function
even more of them
provides a function to
more of them are
a function to be
of them are on
function to be executed
them are on drawing
to be executed when
a hierarchy of token
be executed when transmission
hierarchy of token rings
executed when transmission of
are on drawing boards
when transmission of the
on drawing boards in
transmission of the message
drawing boards in government
of the message completes
ruling out congestion as
out congestion as a
and the send operation
congestion as a possible
the send operation itself
as a possible cause
send operation itself is
operation itself is non
naks ack through upcalls
the only option for
a conclusion supported by
only option for the
conclusion supported by dialogue
qsm is also registered
supported by dialogue with
option for the web
by dialogue with the
for the web services
dialogue with the network
the web services community
with the network administrators
web services community is
is also registered as
this is similar to
services community is to
also registered as a
is similar to the
community is to take
registered as a shell
similar to the queued
as a shell extension
is to take on
to the queued rpc
to take on the
the queued rpc developed
take on the challenge
making it possible to
queued rpc developed for
it possible to access
rpc developed for rover
possible to access the
what are some possible
to access the communication
are some possible causes
if they do so
access the communication subsystem
some possible causes for
the communication subsystem directly
possible causes for such
communication subsystem directly from
causes for such high
solutions will be readily
subsystem directly from the
will be readily available
directly from the windows
for such high loss
from the windows gui
such high loss rates
high loss rates on
web services are going
loss rates on teragrid
services are going to
are going to be
atp also allows the
going to be the
also allows the sender
to be the ubiquitous
allows the sender to
be the ubiquitous platform
the sender to attach
the ubiquitous platform technology
sender to attach a
the user can store
to attach a priority
user can store a
attach a priority to
can store a shortcut
a priority to each
store a shortcut to
ubiquitous platform technology for
a likely hypothesis is
priority to each message
a shortcut to a
platform technology for next
likely hypothesis is device
shortcut to a qsm
hypothesis is device clutter
to control the order
to a qsm stream
control the order in
a qsm stream in
the order in which
qsm stream in the
order in which the
stream in the file
in which the queued
in the file system
which the queued messages
generation critical computing systems
is device clutter the
the queued messages are
device clutter the critical
queued messages are transmitted
clutter the critical communication
and we ve no
the critical communication path
we ve no one
critical communication path between
ve no one but
messages are queued at
no one but ourselves
are queued at the
one but ourselves to
queued at the sender
but ourselves to blame
at the sender according
ourselves to blame if
the sender according to
to blame if these
click to attach a
communication path between nodes
to attach a previewer
sender according to their
path between nodes in
blame if these systems
between nodes in different
if these systems don
nodes in different data
these systems don t
according to their receivers
attach a previewer or
in different data centers
a previewer or a
different data centers is
previewer or a viewer
data centers is littered
or a viewer to
centers is littered with
systems don t work
and each queue is
don t work properly
each queue is ordered
a viewer to an
is littered with multiple
queue is ordered by
littered with multiple electronic
is ordered by priority
with multiple electronic devices
viewer to an event
do we really want
to an event stream
we really want to
messages of the same
each of which represents
of the same priority
of which represents a
the overall architecture is
which represents a potential
overall architecture is summarized
represents a potential point
architecture is summarized in
a potential point of
is summarized in figure
potential point of failure
really want to create
the same priority within
want to create a
same priority within a
to create a world
another possibility is that
priority within a queue
possibility is that such
within a queue are
is that such loss
a queue are transmitted
that such loss rates
queue are transmitted in
such loss rates may
are transmitted in first
loss rates may be
the system is single
create a world in
rates may be typical
a world in which
may be typical for
world in which minor
be typical for any
in which minor computer
typical for any large
which minor computer glitches
minor computer glitches shut
computer glitches shut down
we use a windows
scale network where the
use a windows i
glitches shut down massive
atp also allows a
network where the cost
also allows a sender
shut down massive critical
allows a sender to
where the cost of
down massive critical applications
the cost of immediately
a sender to specify
cost of immediately detecting
sender to specify a
of immediately detecting and
to specify a send
immediately detecting and fixing
specify a send timeout
detecting and fixing failures
henceforth referred to as
massive critical applications and
a send timeout for
critical applications and in
send timeout for a
and fixing failures is
referred to as an
fixing failures is prohibitively
to as an i
failures is prohibitively high
applications and in which
timeout for a message
and in which hackers
in which hackers can
which hackers can readily
hackers can readily disrupt
can readily disrupt access
which causes the transmission
readily disrupt access to
causes the transmission to
to collect all asynchronous
the transmission to be
collect all asynchronous i
transmission to be suspended
we found through dialogue
disrupt access to banking
found through dialogue with
access to banking records
to be suspended if
through dialogue with the
be suspended if it
dialogue with the administrators
suspended if it expires
air traffic control systems
with the administrators that
including notifications of any
the administrators that the
notifications of any received
administrators that the steady
so that the sender
that the steady loss
that the sender can
of any received messages
and even shut down
the steady loss rate
the sender can react
steady loss rate experienced
sender can react to
even shut down the
loss rate experienced by
can react to it
rate experienced by the
shut down the power
experienced by the indiana
down the power grid
by the indiana university
the indiana university site
an analogous mechanism is
indiana university site was
analogous mechanism is available
university site was due
mechanism is available for
site was due to
is available for receive
was due to a
available for receive operations
due to a faulty
a single core thread
time is running out
single core thread synchronously
to a faulty line
core thread synchronously polls
a faulty line card
besides detecting when a
thread synchronously polls the
current halfway solutions will
detecting when a remote
halfway solutions will tempt
when a remote host
and the measurements showed
a remote host is
solutions will tempt developers
synchronously polls the i
will tempt developers to
remote host is inaccessible
tempt developers to embark
the measurements showed that
developers to embark on
measurements showed that the
to embark on a
showed that the error
embark on a path
that the error persisting
on a path that
the error persisting over
a path that will
error persisting over at
path that will soon
persisting over at least
that will soon lead
over at least a
o queue to retrieve
at least a three
queue to retrieve incoming
least a three month
to retrieve incoming messages
a three month period
will soon lead many
send timeouts do not
soon lead many of
timeouts do not play
the core thread also
lead many of them
core thread also maintains
many of them into
thread also maintains an
of them into real
also maintains an alarm
them into real trouble
maintains an alarm queue
points for loss rates
do not play a
for loss rates on
not play a major
the entire industry clients
implemented as a splay
play a major role
loss rates on high
as a splay tree
a major role in
major role in mfs
and vendors as well
vendors as well as
an additional use for
haul networks are provided
as well as the
additional use for timeouts
networks are provided by
well as the government
are provided by the
and a request queue
as the government have
use for timeouts would
the government have a
provided by the back
government have a shared
for timeouts would be
have a shared obligation
implemented as a lockfree
a shared obligation to
as a lockfree queue
shared obligation to make
a lockfree queue with
obligation to make web
lockfree queue with cas
to make web services
timeouts would be to
bone networks of tier
would be to detect
make web services better
be to detect prefetches
to detect prefetches which
detect prefetches which are
prefetches which are not
for requests from the
which are not making
s ken birman is
are not making progress
global crossing reports average
not making progress and
crossing reports average loss
making progress and reissue
reports average loss rates
progress and reissue a
average loss rates between
and reissue a prefetch
ken birman is a
reissue a prefetch for
birman is a professor
a prefetch for a
is a professor in
the core thread polls
prefetch for a different
core thread polls all
for a different file
thread polls all queues
a professor in the
polls all queues in
professor in the department
all queues in a
in the department of
queues in a round
the department of computer
department of computer science
of computer science at
computer science at cornell
science at cornell university
robin fashion and processes
fashion and processes the
and processes the events
processes the events sequentially
contact him at ken
atp administers priorities by
events of the same
administers priorities by deriving
of the same type
priorities by deriving an
the same type are
by deriving an estimate
same type are processed
deriving an estimate for
type are processed in
an estimate for the
are processed in batches
estimate for the bandwidth
for the bandwidth available
the bandwidth available between
bandwidth available between the
available between the sender
up to the limit
between the sender and
to the limit determined
on four of its
the limit determined by
four of its six
limit determined by a
of its six inter
determined by a quantum
the sender and receiver
in order to minimise
order to minimise the
to minimise the transmission
haul links for the
minimise the transmission delay
links for the month
department of computer engineering
the transmission delay when
for the month of
transmission delay when a
the month of december
delay when a new
san jose state university
when a new message
a new message is
new message is sent
atp uses a form
uses a form of
a form of rate
there is no limit
is no limit for
no limit for local
limit for local push
pull data sender inter
each second is divided
second is divided into
is divided into twenty
divided into twenty send
into twenty send periods
twenty send periods of
pull region partition figure
recovery inside and across
and at most one
qwest reports loss rates
inside and across partitions
reports loss rates of
twentieth of the available
of the available bandwidth
copy will forward it
the available bandwidth is
will forward it to
available bandwidth is used
forward it to the
bandwidth is used during
it to the process
is used during a
to the process missing
used during a single
the process missing the
during a single send
process missing the message
a single send period
without such a constraint
qsm implements a scheme
implements a scheme originally
atp would send as
a scheme originally proposed
would send as much
scheme originally proposed by
send as much data
originally proposed by zhao
as much data as
much data as it
data as it could
as it could on
it could on receipt
could on receipt of
on receipt of a
receipt of a low
in either direction on
either direction on its
direction on its trans
and this data could
even in a large
this data could then
pacific link for the
data could then be
link for the same
in a large ring
could then be buffered
for the same month
then be buffered at
be buffered at an
no more than five
buffered at an intermediate
more than five nodes
at an intermediate link
than five nodes cache
five nodes cache any
nodes cache any given
cache any given message
delaying the transmission of
the transmission of any
transmission of any high
qsm also uses this
also uses this idea
uses this idea at
this idea at the
idea at the level
priority message which might
at the level of
message which might be
the level of partitions
which might be sent
we expect privately managed
might be sent later
expect privately managed lambdas
privately managed lambdas to
each message is cached
managed lambdas to exhibit
message is cached in
lambdas to exhibit higher
the disadvantage of this
to exhibit higher loss
is cached in a
exhibit higher loss rates
cached in a single
higher loss rates due
disadvantage of this scheme
loss rates due to
in a single partition
rates due to the
of this scheme is
due to the inherent
this scheme is that
to the inherent tradeoff
scheme is that heavy
the inherent tradeoff between
is that heavy contention
inherent tradeoff between fiber
that heavy contention at
heavy contention at the
contention at the sender
at the sender may
the sender may delay
equipment quality and cost
if some partition is
sender may delay a
some partition is missing
may delay a new
partition is missing a
delay a new message
is missing a message
a new message by
new message by as
message by as much
by as much as
the partition caching it
partition caching it steps
caching it steps in
it steps in to
steps in to resend
in to resend it
as well as the
regardless of its priority
well as the difficulty
as the difficulty of
if an entire region
the difficulty of performing
an entire region is
difficulty of performing routine
entire region is missing
this inefficiency of the
of performing routine maintenance
inefficiency of the atp
performing routine maintenance on
region is missing a
routine maintenance on longdistance
is missing a message
maintenance on longdistance links
of the atp implementation
the atp implementation is
atp implementation is most
the sender becomes involved
implementation is most visible
sender becomes involved and
is most visible when
becomes involved and re
most visible when there
visible when there is
when there is contention
there is contention between
is contention between different
contention between different priorities
between different priorities at
different priorities at high
qsm tokens also carry
priorities at high bandwidth
tokens also carry other
end paths as dropping
also carry other information
paths as dropping packets
as dropping packets at
dropping packets at rates
packets at rates of
including data used to
data used to perform
used to perform rate
to perform rate control
perform rate control and
rate control and information
control and information used
and information used to
information used to trigger
used to trigger garbage
mfs implementation the version
to trigger garbage collection
implementation the version of
cloudifying source code repositories
the version of mfs
version of mfs described
of mfs described in
the overall system configuration
mfs described in this
overall system configuration is
described in this paper
system configuration is managed
how much does it
configuration is managed by
much does it cost
is managed by what
in this paper is
managed by what we
this paper is implemented
by what we call
paper is implemented in
michael siegenthaler hakim weatherspoon
is implemented in c
to capture a wide
implemented in c and
capture a wide range
in c and runs
a wide range of
what we call the
wide range of deployed
we call the configuration
siegenthaler hakim weatherspoon dept
c and runs on
range of deployed networks
call the configuration management
and runs on freebsd
the configuration management service
of computer science cornell
computer science cornell university
science cornell university msiegen
e xisting r eliability
xisting r eliability o
r eliability o ptions
eliability o ptions tcp
which handles join and
handles join and leave
join and leave requests
ip is the default
both the client and
is the default reliable
the client and server
the default reliable communication
of computer science cornell
default reliable communication option
computer science cornell university
reliable communication option for
science cornell university hweather
communication option for contemporary
and uses these to
client and server have
option for contemporary networked
uses these to generate
and server have multiple
for contemporary networked applications
server have multiple threads
these to generate a
have multiple threads to
to generate a sequence
multiple threads to cope
generate a sequence of
threads to cope with
a sequence of membership
to cope with simultaneous
edu abstract cloud computing
cope with simultaneous file
with simultaneous file system
sequence of membership views
simultaneous file system requests
of membership views for
exclusive embeddings in commodity
membership views for each
embeddings in commodity operating
views for each multicast
in commodity operating systems
abstract cloud computing provides
commodity operating systems and
and the rpc library
operating systems and networking
the rpc library has
cloud computing provides us
the cms also determines
systems and networking apis
cms also determines and
computing provides us with
also determines and continuously
rpc library has its
determines and continuously updates
provides us with general
and continuously updates region
library has its own
continuously updates region boundaries
has its own thread
us with general purpose
with general purpose storage
most applications requiring reliable
general purpose storage and
maintains sequences of region
purpose storage and server
therefore there are two
sequences of region views
there are two mandatory
of region views for
are two mandatory thread
region views for each
applications requiring reliable communication
storage and server hosting
requiring reliable communication over
and server hosting platforms
reliable communication over any
server hosting platforms at
two mandatory thread context
views for each region
mandatory thread context switches
hosting platforms at a
thread context switches on
platforms at a reasonable
context switches on any
at a reasonable price
switches on any message
communication over any form
and tracks the mapping
on any message send
tracks the mapping from
any message send or
the mapping from group
message send or receive
we explore the possibility
send or receive operation
over any form of
mapping from group views
explore the possibility of
any form of network
from group views to
as we shall describe
group views to region
we shall describe in
views to region views
shall describe in subsequent
form of network use
the possibility of tapping
describe in subsequent sections
of network use tcp
possibility of tapping these
of tapping these resources
tapping these resources for
the cms runs on
some subsystems have additional
these resources for the
subsystems have additional threads
cms runs on a
have additional threads to
resources for the purpose
additional threads to carry
runs on a single
for the purpose of
threads to carry out
the purpose of hosting
to carry out background
on a single node
purpose of hosting source
carry out background processing
ip has three major
of hosting source code
but we intend to
has three major problems
hosting source code repositories
we intend to replace
source code repositories for
intend to replace this
three major problems when
code repositories for individual
major problems when used
to replace this with
repositories for individual projects
replace this with a
for individual projects as
problems when used over
individual projects as well
when used over high
projects as well as
this with a state
our experiments were conducted
as well as entire
experiments were conducted with
well as entire open
were conducted with a
as entire open source
conducted with a default
entire open source communities
machine replicated version in
with a default client
replicated version in the
a default client cache
version in the future
default client cache size
in the future to
client cache size of
an analysis of storage
the future to eliminate
analysis of storage costs
future to eliminate the
of storage costs is
to eliminate the risk
storage costs is presented
eliminate the risk of
throughput collapse in lossy
the risk of single
collapse in lossy networks
and a complete hosting
a complete hosting solution
complete hosting solution is
hosting solution is built
solution is built and
is built and evaluated
built and evaluated as
and evaluated as a
in the longer term
ip is unable to
the longer term we
evaluated as a proof
is unable to distinguish
rpcs with priorities mfs
unable to distinguish between
with priorities mfs rpcs
to distinguish between ephemeral
longer term we will
distinguish between ephemeral loss
term we will move
between ephemeral loss modes
we will move to
ephemeral loss modes due
will move to a
loss modes due to
move to a hierarchically
modes due to transient
to a hierarchically structured
priorities mfs rpcs are
a hierarchically structured cms
due to transient congestion
mfs rpcs are implemented
rpcs are implemented on
i ntroduction the advent
are implemented on top
ntroduction the advent of
implemented on top of
the advent of cloud
on top of atp
advent of cloud computing
top of atp in
or bad fiber and
of cloud computing has
bad fiber and persistent
of atp in the
fiber and persistent congestion
atp in the natural
cloud computing has brought
in the natural way
computing has brought us
has brought us a
the loss of one
brought us a dazzling
loss of one packet
us a dazzling array
of one packet out
a dazzling array of
one packet out of
an rpc request constitutes
packet out of ten
rpc request constitutes one
out of ten thousand
request constitutes one message
alarm queue application thread
of ten thousand is
queue application thread operating
ten thousand is sufficient
dazzling array of public
and its reply another
thousand is sufficient to
application thread operating system
array of public computing
thread operating system kernel
of public computing services
operating system kernel implementation
priorities are used to
system kernel implementation qsm
are used to differentiate
kernel implementation qsm qsm
used to differentiate types
implementation qsm qsm request
to differentiate types of
qsm qsm request queue
is sufficient to reduce
qsm request queue core
sufficient to reduce tcp
request queue core thread
public computing services that
differentiate types of rpcs
computing services that can
types of rpcs to
services that can be
of rpcs to improve
queue core thread i
that can be instantly
rpcs to improve performance
can be instantly tapped
ip throughput to a
be instantly tapped by
throughput to a third
instantly tapped by anyone
to a third of
tapped by anyone with
a third of its
by anyone with a
third of its lossless
anyone with a credit
of its lossless maximum
with a credit card
o queue socket figure
a credit card number
or those which would
if one packet is
those which would cause
one packet is lost
which would cause an
users are spared from
packet is lost out
are spared from having
is lost out of
spared from having to
lost out of a
qsm uses a single
out of a thousand
would cause an interactive
from having to invest
cause an interactive client
having to invest in
an interactive client to
to invest in expensive
interactive client to block
invest in expensive infrastructure
throughput collapses to a
in expensive infrastructure such
with a core thread
expensive infrastructure such as
a core thread that
are given high priority
core thread that controls
collapses to a thirtieth
thread that controls three
to a thirtieth of
infrastructure such as servers
rpcs for background activities
a thirtieth of the
that controls three queues
thirtieth of the maximum
such as writing back
as writing back files
writing back files to
back files to the
and cooling equipment because
the root cause of
cooling equipment because the
root cause of throughput
files to the server
equipment because the service
cause of throughput collapse
because the service provider
of throughput collapse is
the service provider takes
throughput collapse is tcp
service provider takes care
provider takes care of
takes care of these
care of these and
are performed at low
of these and amortizes
and requests from the
these and amortizes the
requests from the possibly
and amortizes the cost
from the possibly multithreaded
amortizes the cost across
ip s fundamental reliance
performed at low priority
the possibly multithreaded application
the cost across many
s fundamental reliance on
cost across many clients
fundamental reliance on loss
so that they do
reliance on loss as
that they do not
on loss as a
they do not slow
loss as a signal
do not slow down
achieving efficiency through economies
not slow down high
efficiency through economies of
as a signal of
when we set out
through economies of scale
a signal of congestion
we set out to
set out to implement
out to implement qsm
companies are realizing that
while recent approaches have
are realizing that it
recent approaches have sought
our intent was to
approaches have sought to
intent was to leverage
have sought to replace
was to leverage the
sought to replace loss
to leverage the component
to replace loss with
shows the priority levels
realizing that it no
leverage the component integration
that it no longer
the component integration tools
it no longer makes
component integration tools available
no longer makes sense
integration tools available on
longer makes sense to
tools available on the
makes sense to build
available on the windows
sense to build and
on the windows platform
to build and manage
the priority levels for
replace loss with delay
priority levels for different
build and manage all
levels for different types
and manage all of
for different types of
manage all of their
different types of rpcs
all of their own
loss with delay as
we didn t expect
of their own infrastructure
with delay as a
didn t expect that
assigning priorities to rpcs
delay as a congestion
priorities to rpcs allows
as a congestion signal
and services in the
to rpcs allows mfs
t expect that co
rpcs allows mfs to
services in the cloud
allows mfs to adapt
in the cloud are
mfs to adapt to
the cloud are quickly
to adapt to bandwidth
cloud are quickly becoming
adapt to bandwidth variation
existence with the managed
to bandwidth variation in
are quickly becoming popular
with the managed environment
bandwidth variation in a
the managed environment would
variation in a straightforward
managed environment would require
in a straightforward way
environment would require any
would require any special
require any special architectural
any special architectural features
qsm is implemented much
all rpcs complete quickly
is implemented much like
or to specifically identify
that software development projects
implemented much like any
with or without priorities
software development projects will
to specifically identify loss
development projects will turn
specifically identify loss caused
projects will turn to
identify loss caused by
will turn to cloud
loss caused by non
turn to cloud computing
the system is coded
to cloud computing to
system is coded in
cloud computing to store
is coded in c
computing to store their
to store their master
store their master code
their master code repositories
either on a project
project basis or as
basis or as part
or as part of
older variants prominently reno
as part of a
variants prominently reno remain
part of a larger
prominently reno remain ubiquitously
of a larger migration
reno remain ubiquitously deployed
a larger migration of
larger migration of a
corresponding rpc types fetch
migration of a sourceforge
rpc types fetch attributes
callbacks fetch file data
even small code repositories
recovery delays for real
small code repositories represent
code repositories represent a
directory contents write back
repositories represent a huge
contents write back directory
represent a huge investment
write back directory and
a huge investment of
back directory and metadata
huge investment of developerhours
directory and metadata updates
and metadata updates write
metadata updates write back
updates write back shared
ip uses positive acknowledgments
write back shared files
so the need to
uses positive acknowledgments and
the need to store
back shared files write
need to store this
shared files write back
to store this data
positive acknowledgments and retransmissions
store this data durably
files write back unshared
this data durably and
write back unshared files
data durably and reliably
back unshared files prefetch
durably and reliably is
unshared files prefetch file
and reliably is obvious
acknowledgments and retransmissions to
to interface to the
files prefetch file data
interface to the native
and retransmissions to ensure
to the native windows
prefetch file data section
the native windows asynchronous
retransmissions to ensure reliability
less obvious are the
to ensure reliability the
obvious are the shortcomings
native windows asynchronous i
are the shortcomings of
ensure reliability the sender
the shortcomings of traditional
reliability the sender buffers
shortcomings of traditional storage
the sender buffers packets
of traditional storage systems
sender buffers packets until
buffers packets until their
packets until their receipt
until their receipt is
their receipt is acknowledged
receipt is acknowledged by
is acknowledged by the
and is accessible from
acknowledged by the receiver
is accessible from any
independently and may compete
and resends if an
resends if an acknowledgment
if an acknowledgment is
an acknowledgment is not
acknowledgment is not received
windows understands qsm to
is not received within
understands qsm to be
not received within some
by making writes asynchronous
received within some time
protect against data loss
qsm to be the
within some time period
to be the handler
be the handler for
update logging pushes read
the handler for operations
but they are neither
handler for operations on
they are neither cheap
for operations on new
are neither cheap nor
operations on new kind
neither cheap nor simple
on new kind of
a lost packet is
write contention into the
lost packet is received
contention into the future
new kind of event
especially when developers and
kind of event stream
packet is received in
when developers and server
is received in the
to occur at the
received in the form
occur at the next
in the form of
at the next log
the form of a
developers and server administrators
form of a retransmission
the next log flush
of a retransmission that
and server administrators are
a retransmission that arrives
an application can obtain
server administrators are geographically
application can obtain handles
the designers of little
can obtain handles from
designers of little work
obtain handles from these
administrators are geographically spread
handles from these qsm
are geographically spread thin
of little work incorporated
retransmission that arrives no
little work incorporated a
that arrives no earlier
work incorporated a low
arrives no earlier than
and can then invoke
can then invoke methods
we focus on the
then invoke methods on
level priority mechanism at
invoke methods on those
focus on the costs
methods on those handles
priority mechanism at the
on the costs of
on those handles to
the costs of moving
those handles to send
rtts after the original
mechanism at the ip
costs of moving source
handles to send events
at the ip packet
of moving source code
the ip packet level
moving source code repositories
ip packet level to
source code repositories to
packet level to further
code repositories to the
level to further reduce
the sender has to
to further reduce interference
sender has to buffer
incoming messages are delivered
repositories to the cloud
further reduce interference between
to the cloud as
messages are delivered application
the cloud as an
are delivered application requests
cloud as an example
reduce interference between writeback
as an example of
has to buffer each
an example of moving
to buffer each packet
example of moving services
buffer each packet until
of moving services in
each packet until it
moving services in general
packet until it s
services in general to
until it s acknowledged
in general to the
interference between writeback traffic
general to the cloud
between writeback traffic and
o event representing a
writeback traffic and other
event representing a received
traffic and other network
representing a received packet
and other network traffic
a received packet is
other network traffic sent
especially collaborative open source
network traffic sent by
rtt in lossless operation
traffic sent by the
collaborative open source projects
received packet is retrieved
sent by the client
packet is retrieved for
is retrieved for a
retrieved for a given
and it has to
for a given socket
it has to perform
such an endeavor includes
has to perform additional
an endeavor includes many
to perform additional work
endeavor includes many costs
perform additional work to
the socket is drained
additional work to retransmit
socket is drained to
work to retransmit the
is drained to minimize
to retransmit the packet
drained to minimize the
the most critical of
to minimize the probability
retransmit the packet if
most critical of which
the packet if it
minimize the probability of
packet if it does
the probability of loss
if it does not
critical of which is
it does not receive
of which is storage
does not receive the
priority levels for mfs
not receive the acknowledgment
levels for mfs rpcs
several aspects of the
which is storage since
aspects of the architecture
is storage since that
of the architecture are
storage since that is
the architecture are noteworthy
since that is the
architecture are noteworthy because
symbolic names are given
are noteworthy because of
names are given for
noteworthy because of their
are given for the
because of their performance
given for the priority
of their performance implications
for the priority levels
that is the simplest
any packets that arrive
is the simplest and
packets that arrive with
the simplest and likely
that arrive with higher
listed from highest to
simplest and likely first
arrive with higher sequence
and likely first component
from highest to lowest
likely first component to
highest to lowest priority
first component to be
qsm assigns priorities to
with higher sequence numbers
assigns priorities to different
component to be moved
priorities to different types
the third column gives
to different types of
higher sequence numbers than
third column gives the
sequence numbers than that
column gives the section
different types of i
gives the section in
we set an agenda
numbers than that of
the section in which
than that of a
section in which the
that of a lost
set an agenda for
of a lost packet
in which the corresponding
the basic idea is
a lost packet must
an agenda for demonstrating
lost packet must be
basic idea is that
packet must be queued
idea is that when
must be queued while
is that when an
be queued while the
agenda for demonstrating the
queued while the receiver
that when an i
while the receiver waits
for demonstrating the financial
the receiver waits for
which the corresponding rpc
receiver waits for the
demonstrating the financial storage
the corresponding rpc types
waits for the lost
corresponding rpc types are
the financial storage and
rpc types are described
for the lost packet
types are described in
the lost packet to
are described in detail
lost packet to arrive
financial storage and computing
we retrieve all events
storage and computing costs
retrieve all events from
and computing costs of
all events from the
computing costs of moving
events from the i
costs of moving source
of moving source code
moving source code repositories
throughput financial banking application
source code repositories to
financial banking application running
code repositories to the
banking application running in
repositories to the cloud
application running in a
determine the type of
running in a data
the type of each
in a data center
asynchronous writeback though it
a data center in
writeback though it reduces
data center in new
though it reduces bandwidth
center in new york
it reduces bandwidth consumption
in new york city
and then place it
in section ii we
then place it in
section ii we explain
place it in an
ii we explain what
it in an appropriate
update logging is fundamentally
sending updates to a
logging is fundamentally unsuitable
updates to a sister
is fundamentally unsuitable for
to a sister site
fundamentally unsuitable for use
in an appropriate priority
we explain what it
a sister site in
explain what it means
sister site in switzerland
unsuitable for use at
an appropriate priority queue
what it means to
for use at high
it means to store
use at high bandwidth
means to store a
the rtt value between
to store a code
rtt value between these
store a code repository
value between these two
a code repository in
since it imposes a
the system processes queued
between these two centers
code repository in the
system processes queued events
these two centers is
processes queued events in
two centers is typically
queued events in priority
it imposes a delay
repository in the cloud
imposes a delay on
events in priority order
in the cloud and
a delay on transmitting
the cloud and why
delay on transmitting updates
cloud and why there
on transmitting updates to
and why there are
transmitting updates to the
why there are cost
updates to the server
there are cost advantages
are cost advantages to
cost advantages to doing
advantages to doing so
systems using update logging
using update logging must
by prioritizing incoming i
update logging must therefore
section iii is a
logging must therefore switch
iii is a case
must therefore switch to
is a case study
therefore switch to a
a case study on
switch to a synchronous
case study on using
to a synchronous writes
study on using amazon
in the case of
a synchronous writes when
on using amazon s
synchronous writes when bandwidth
using amazon s s
writes when bandwidth is
the case of a
when bandwidth is high
case of a lost
of a lost packet
to host some popular
host some popular open
some popular open source
popular open source communities
with a threshold controlling
all packets received within
a threshold controlling switches
packets received within the
threshold controlling switches between
and by prioritizing control
controlling switches between the
and includes a cost
by prioritizing control packets
switches between the two
prioritizing control packets over
includes a cost analysis
control packets over data
between the two modes
packets over data we
over data we reduce
data we reduce delays
in section iv we
milliseconds or more between
section iv we present
the mode switch also
iv we present an
or more between the
we present an implementation
mode switch also changes
present an implementation that
we reduce delays in
switch also changes the
an implementation that ties
also changes the semantics
more between the original
changes the semantics of
implementation that ties subversion
reduce delays in reacting
between the original packet
the semantics of the
the original packet send
semantics of the file
that ties subversion to
delays in reacting to
original packet send and
in reacting to packet
of the file system
packet send and the
reacting to packet loss
send and the receipt
to packet loss or
and the receipt of
ties subversion to s
the receipt of its
and the developers of
receipt of its retransmission
packet loss or other
of its retransmission have
loss or other control
its retransmission have to
the developers of coda
retransmission have to be
developers of coda have
have to be buffered
of coda have noted
to be buffered at
coda have noted that
be buffered at the
have noted that undetected
end servers running on
we will see that
servers running on amazon
will see that this
running on amazon s
noted that undetected mode
buffered at the receiver
see that this slashes
on amazon s ec
that undetected mode changes
that this slashes system
undetected mode changes can
mode changes can surprise
changes can surprise the
and using yahoo s
can surprise the user
using yahoo s zookeeper
surprise the user in
the loss of a
the user in undesirable
yahoo s zookeeper for
loss of a single
user in undesirable ways
the pros and cons
of a single packet
pros and cons of
s zookeeper for consistency
and cons of using
a single packet stops
cons of using threads
single packet stops all
of using threads in
packet stops all traffic
in section v we
stops all traffic in
section v we evaluate
using threads in eventoriented
v we evaluate the
all traffic in the
threads in eventoriented systems
traffic in the channel
in eventoriented systems are
in the channel to
eventoriented systems are hotly
we evaluate the performance
the channel to the
evaluate the performance of
channel to the application
the performance of this
to the application for
systems are hotly debated
the application for a
performance of this solution
such as cache inconsistencies
application for a seventh
as cache inconsistencies arising
for a seventh of
cache inconsistencies arising due
a seventh of a
inconsistencies arising due to
seventh of a second
arising due to unexpectedly
and in section vi
threads turned out to
in section vi we
turned out to be
section vi we address
out to be a
vi we address related
a sequence of such
we address related work
to be a bad
due to unexpectedly delayed
sequence of such blocks
be a bad idea
to unexpectedly delayed writes
of such blocks can
such blocks can have
blocks can have devastating
c loudifying s ource
although we used threads
loudifying s ource r
rather than relying on
s ource r epositories
than relying on a
ource r epositories in
we used threads rather
relying on a modal
r epositories in a
on a modal adaptation
epositories in a revision
can have devastating effect
used threads rather casually
a modal adaptation scheme
threads rather casually in
have devastating effect on
in a revision control
modal adaptation scheme incorporating
rather casually in the
adaptation scheme incorporating a
casually in the first
devastating effect on a
a revision control system
scheme incorporating a transition
in the first year
incorporating a transition to
the first year of
a transition to update
first year of our
a master copy of
year of our effort
transition to update logging
effect on a high
master copy of the
to update logging when
copy of the source
update logging when bandwidth
throughput system where every
logging when bandwidth is
system where every spare
when bandwidth is low
where every spare cycle
that version of the
of the source code
every spare cycle counts
version of the system
mfs uses a modeless
of the system was
uses a modeless asynchronous
a modeless asynchronous writeback
the system was annoyingly
modeless asynchronous writeback mechanism
system was annoyingly process
is stored in a
was annoyingly process requests
stored in a logically
in applications with many
in a logically centralized
applications with many fine
a logically centralized repository
annoyingly process requests incoming
which is active at
process requests incoming control
is active at all
requests incoming control outgoing
active at all bandwidth
incoming control outgoing control
each developer checks out
control outgoing control outgoing
developer checks out and
outgoing control outgoing data
checks out and then
at all bandwidth levels
out and then keeps
control outgoing data feed
and then keeps a
a lost packet can
then keeps a working
outgoing data feed sink
keeps a working copy
just as with update
a working copy on
lost packet can potentially
working copy on his
packet can potentially trigger
copy on his machine
data feed sink limit
as with update logging
feed sink limit sending
on his machine that
sink limit sending rate
his machine that mirrors
limit sending rate limit
machine that mirrors the
sending rate limit concurrency
that mirrors the repository
when an application performs
can potentially trigger a
an application performs an
rate limit concurrency limit
application performs an operation
limit concurrency limit window
performs an operation that
concurrency limit window size
potentially trigger a butterfly
the developer edits files
an operation that changes
developer edits files in
operation that changes a
limit window size figure
trigger a butterfly effect
edits files in his
a butterfly effect of
that changes a file
butterfly effect of missed
files in his working
effect of missed deadlines
in his working copy
of missed deadlines along
his working copy and
missed deadlines along a
working copy and periodically
deadlines along a distributed
copy and periodically commits
along a distributed workflow
and periodically commits the
such as a write
periodically commits the changes
in a pull protocol
commits the changes back
a pull protocol a
the changes back to
as a write or
changes back to the
a write or metadata
back to the repository
write or metadata update
overloaded networks and end
registers the intent to
and updates his working
the intent to send
updates his working copy
intent to send with
his working copy to
to send with a
hosts can exhibit continuous
working copy to reflect
send with a sink
create directory and so
with a sink that
can exhibit continuous packet
a sink that may
exhibit continuous packet loss
copy to reflect the
directory and so on
to reflect the changes
sink that may be
reflect the changes made
that may be controlled
the changes made by
with each lost packet
changes made by other
may be controlled by
each lost packet driving
be controlled by a
made by other developers
lost packet driving the
controlled by a policy
packet driving the system
by a policy limiting
driving the system further
the update is then
the system further and
update is then passed
system further and further
is then passed to
further and further out
then passed to the
and further out of
passed to the writeback
further out of sync
to the writeback subsystem
out of sync with
each commit is assigned
a policy limiting the
of sync with respect
commit is assigned a
which sends it to
is assigned a unique
sends it to the
sync with respect to
policy limiting the send
it to the server
with respect to its
to the server when
respect to its real
the server when there
limiting the send rate
server when there is
when there is sufficient
the repository maintains complete
there is sufficient bandwidth
repository maintains complete history
maintains complete history so
complete history so at
history so at any
when the sink is
asynchronous writeback therefore only
the sink is ready
so at any point
writeback therefore only delays
at any point in
therefore only delays updates
any point in time
only delays updates when
massive buffering needs for
point in time it
buffering needs for high
in time it is
needs for high throughput
sink is ready to
delays updates when there
time it is possible
for high throughput applications
it is possible to
updates when there is
is possible to check
when there is foreground
possible to check out
there is foreground traffic
to check out a
is ready to send
check out a working
out a working copy
ip uses fixed size
when bandwidth is high
uses fixed size buffers
it issues an upcall
fixed size buffers at
size buffers at receivers
buffers at receivers to
a working copy for
at receivers to prevent
working copy for any
receivers to prevent overflows
app elements of the
the performance of asynchronous
copy for any specified
elements of the protocol
performance of asynchronous writeback
for any specified version
of asynchronous writeback should
any specified version number
asynchronous writeback should be
of the protocol stack
writeback should be comparable
the protocol stack f
should be comparable to
the sender never pushes
be comparable to purely
storing a repository in
comparable to purely synchronous
sender never pushes more
a repository in the
never pushes more unacknowledged
repository in the cloud
pushes more unacknowledged data
in the cloud eliminates
to purely synchronous writes
the cloud eliminates worries
o events according to
cloud eliminates worries of
more unacknowledged data into
eliminates worries of data
events according to priorities
but when bandwidth is
according to priorities incoming
when bandwidth is insufficient
worries of data loss
unacknowledged data into the
to priorities incoming data
of data loss due
priorities incoming data policy
asynchronous writes will improve
incoming data policy get
writes will improve the
data policy get messages
will improve the performance
policy get messages pre
improve the performance non
data loss due to
data into the network
loss due to hardware
into the network than
due to hardware failure
the network than the
network than the receiver
than the receiver is
the receiver is capable
receiver is capable of
o events process timer
but issues of access
events process timer events
issues of access control
process timer events register
of access control and
timer events register to
an implementation without priorities
events register to send
is capable of holding
access control and consistency
implementation without priorities will
control and consistency must
register to send app
without priorities will result
and consistency must still
priorities will result in
consistency must still be
will result in the
must still be addressed
result in the completion
to send app app
in the completion times
send app app f
the completion times for
the size of the
authorized users should be
completion times for all
users should be able
times for all rpcs
should be able to
for all rpcs increasing
size of the fluctuating
all rpcs increasing uniformly
be able to commit
of the fluctuating window
able to commit new
the fluctuating window at
to commit new versions
fluctuating window at the
when priorities are used
window at the sender
commit new versions of
at the sender is
new versions of files
the sender is bounded
versions of files to
sender is bounded by
of files to the
is bounded by the
files to the repository
bounded by the size
a backlog of low
one can think of
by the size of
can think of qsm
but not edit existing
the size of the
think of qsm as
size of the buffer
priority rpcs will accumulate
not edit existing history
of qsm as a
of the buffer at
qsm as a collection
the buffer at the
while the time taken
users expect the repository
as a collection of
the time taken for
a collection of protocol
time taken for high
buffer at the receiver
expect the repository to
collection of protocol stacks
the repository to be
of protocol stacks in
repository to be consistent
priority rpcs to complete
to be consistent and
protocol stacks in which
be consistent and for
rpcs to complete will
consistent and for any
to complete will increase
and for any changes
complete will increase more
for any changes they
will increase more gradually
any changes they make
stacks in which components
changes they make not
in which components act
they make not to
which components act as
make not to be
components act as both
not to be pre
act as both feeds
our design is based
the quantity of inflight
design is based on
as both feeds and
is based on the
both feeds and as
based on the assumption
quantity of inflight unacknowledged
on the assumption that
feeds and as sinks
the assumption that when
of inflight unacknowledged data
even in the face
inflight unacknowledged data has
in the face of
unacknowledged data has to
the face of cloud
data has to be
face of cloud services
assumption that when bandwidth
the overall structure is
has to be extremely
of cloud services that
to be extremely high
cloud services that offer
be extremely high for
services that offer lesser
extremely high for the
that offer lesser guarantees
high for the flow
overall structure is of
that when bandwidth is
for the flow to
structure is of a
when bandwidth is low
the flow to saturate
for these reasons we
is of a forest
these reasons we do
of a forest of
flow to saturate the
an assignment of differentiated
to saturate the network
reasons we do not
a forest of trees
we do not expect
assignment of differentiated priorities
do not expect that
of differentiated priorities will
not expect that clients
since the size of
expect that clients will
the size of the
that clients will be
size of the receiver
clients will be directly
of the receiver window
will be directly using
the receiver window limits
be directly using the
receiver window limits the
directly using the cloud
o was to reduce
using the cloud storage
differentiated priorities will improve
window limits the sending
priorities will improve the
limits the sending envelope
will improve the response
the cloud storage api
was to reduce staleness
improve the response times
cloud storage api anytime
the response times for
storage api anytime soon
response times for interactive
it plays a major
to reduce staleness by
times for interactive tasks
plays a major role
reduce staleness by postponing
but that they will
staleness by postponing the
that they will contact
a major role in
they will contact one
major role in determining
will contact one of
role in determining tcp
contact one of a
if a task which
by postponing the creation
a task which predominantly
postponing the creation of
task which predominantly performs
the creation of control
which predominantly performs reads
creation of control messages
predominantly performs reads executes
of control messages until
performs reads executes in
control messages until the
reads executes in parallel
messages until the time
executes in parallel to
until the time when
in parallel to a
the time when transmission
parallel to a task
one of a set
the default receiver buffer
time when transmission is
default receiver buffer sizes
of a set of
receiver buffer sizes in
a set of front
buffer sizes in many
when transmission is actually
to a task which
transmission is actually about
a task which performs
is actually about to
task which performs many
actually about to take
which performs many writes
about to take place
end servers that are
sizes in many standard
servers that are responsible
in many standard tcp
that are responsible for
are responsible for enforcing
responsible for enforcing access
for enforcing access control
ip implementations are in
the first task will
implementations are in the
first task will receive
are in the range
task will receive a
in the range of
will receive a higher
the range of tens
time information is more
and pushing the data
receive a higher share
range of tens of
information is more accurate
pushing the data into
a higher share of
of tens of kilobytes
the data into the
higher share of the
and this makes qsm
share of the bandwidth
this makes qsm more
data into the cloud
makes qsm more stable
and consequently inadequate receiver
consequently inadequate receiver buffering
inadequate receiver buffering is
receiver buffering is the
these might consist of
buffering is the first
might consist of virtualized
is the first hurdle
consist of virtualized server
many applications have patterns
the first hurdle faced
an unintended benefit is
of virtualized server instances
applications have patterns of
virtualized server instances in
unintended benefit is that
first hurdle faced by
benefit is that the
hurdle faced by most
have patterns of interactive
server instances in the
patterns of interactive file
instances in the cloud
of interactive file access
faced by most practical
interactive file access involving
by most practical deployments
file access involving both
is that the pull
access involving both reads
that the pull architecture
or traditional physical machines
the pull architecture slashes
traditional physical machines owned
pull architecture slashes buffering
physical machines owned by
architecture slashes buffering and
machines owned by the
slashes buffering and memory
owned by the community
buffering and memory overheads
a natural solution is
involving both reads and
natural solution is to
both reads and writes
solution is to increase
is to increase the
but in either case
to increase the size
in either case their
increase the size of
either case their local
the size of the
as we shall demonstrate
case their local storage
size of the receiver
compiling source files involves
their local storage systems
source files involves interspersed
of the receiver buffers
files involves interspersed reads
turns out to have
involves interspersed reads and
out to have an
interspersed reads and writes
local storage systems are
to have an enormous
storage systems are allowed
have an enormous impact
systems are allowed to
an enormous impact on
are allowed to be
enormous impact on performance
allowed to be cheap
in many cases the
but does not issue
to be cheap and
many cases the receiving
be cheap and unresilient
does not issue concurrent
cheap and unresilient against
not issue concurrent rpcs
and unresilient against hardware
issue concurrent rpcs frequently
unresilient against hardware failure
cases the receiving end
in qsm each element
qsm each element of
each element of a
such an application will
element of a protocol
another consideration with any
of a protocol stack
an application will have
host may not have
application will have improved
may not have the
will have improved read
not have the spare
have improved read performance
have the spare memory
improved read performance when
the spare memory capacity
read performance when there
spare memory capacity to
performance when there is
a protocol stack acts
consideration with any hosting
protocol stack acts as
when there is contention
memory capacity to buffer
with any hosting solution
stack acts as a
any hosting solution is
there is contention with
hosting solution is resource
is contention with other
solution is resource provisioning
contention with other applications
acts as a feed
capacity to buffer the
as a feed that
to buffer the entire
a feed that has
buffer the entire bandwidth
but will correspondingly be
feed that has data
will correspondingly be penalised
open source communities with
that has data to
source communities with limited
delay product of the
communities with limited budgets
product of the long
with limited budgets and
has data to send
limited budgets and private
correspondingly be penalised on
budgets and private enterprises
be penalised on writes
and private enterprises that
private enterprises that are
enterprises that are increasingly
that are increasingly cost
or a sink that
the need for larger
a sink that can
need for larger buffers
sink that can send
for larger buffers is
sensitive may well prefer
that can send it
this does not match
larger buffers is orthogonal
may well prefer to
buffers is orthogonal to
well prefer to pay
is orthogonal to the
prefer to pay just
orthogonal to the flow
to pay just for
to the flow control
pay just for the
the flow control mechanisms
just for the resources
flow control mechanisms used
for the resources they
does not match our
control mechanisms used within
not match our design
mechanisms used within tcp
match our design goal
the resources they use
and many play both
our design goal of
many play both roles
design goal of having
goal of having interactive
ip and impacts all
and impacts all variants
rather than trying to
impacts all variants equally
than trying to budget
trying to budget in
to budget in advance
budget in advance what
in advance what they
read applications obtain a
advance what they are
applications obtain a larger
what they are going
obtain a larger share
they are going to
a larger share of
are going to need
larger share of bandwidth
rather than creating a
than creating a message
cloud computing makes this
we have implemented two
fec fec encoders are
have implemented two solutions
fec encoders are typically
computing makes this a
encoders are typically parameterized
creating a message and
are typically parameterized with
a message and handing
typically parameterized with an
message and handing it
implemented two solutions to
makes this a possibility
and handing it down
two solutions to this
handing it down to
solutions to this problem
it down to the
and increased competition among
down to the sink
increased competition among providers
competition among providers of
based on making writes
among providers of commodity
on making writes asynchronous
tuple for each outgoing
providers of commodity services
a feed registers the
of commodity services will
for each outgoing sequence
commodity services will ensure
each outgoing sequence of
feed registers the intent
services will ensure that
outgoing sequence of r
registers the intent to
used in several existing
will ensure that prices
in several existing systems
ensure that prices are
sequence of r data
the intent to send
several existing systems and
intent to send a
of r data packets
to send a message
that prices are reasonable
send a message with
existing systems and incorporated
a message with the
systems and incorporated in
a total of r
message with the sink
and incorporated in mfs
incorporated in mfs for
in mfs for the
c ase s tudy
mfs for the purposes
c data and error
the message can be
data and error correction
message can be created
and error correction packets
can be created at
error correction packets are
be created at this
correction packets are sent
created at this time
packets are sent over
for the purposes of
at this time and
are sent over the
the purposes of comparison
this time and buffered
sent over the channel
time and buffered in
by far the most
and buffered in the
far the most popular
buffered in the feed
the most popular general
most popular general purpose
which is new to
popular general purpose cloud
is new to mfs
general purpose cloud storage
redundancy information cannot be
but the creation may
information cannot be generated
purpose cloud storage service
cannot be generated and
the creation may also
be generated and sent
an alternative approach is
creation may also be
alternative approach is to
may also be postponed
approach is to retain
generated and sent until
cloud storage service today
and sent until all
storage service today is
sent until all r
service today is amazon
until all r data
today is amazon s
all r data packets
is amazon s s
r data packets are
is to retain synchronous
also be postponed until
data packets are available
be postponed until the
packets are available for
to retain synchronous writes
postponed until the time
are available for sending
until the time when
we chose to use
the time when the
chose to use this
time when the sink
to use this as
when the sink polls
use this as a
the sink polls the
but assign priorities according
sink polls the feed
this as a basis
the latency of packet
polls the feed for
latency of packet recovery
the feed for messages
of packet recovery is
feed for messages to
assign priorities according to
as a basis for
priorities according to some
a basis for cost
according to some notion
basis for cost studies
to some notion of
for cost studies and
some notion of relative
cost studies and for
packet recovery is determined
for messages to transmit
recovery is determined by
studies and for the
notion of relative importance
is determined by the
and for the implementation
the sink determines its
of relative importance of
for the implementation of
determined by the rate
sink determines its readiness
by the rate at
the implementation of our
the rate at which
implementation of our system
rate at which the
determines its readiness to
relative importance of processes
its readiness to send
at which the sender
readiness to send based
which the sender transmits
to send based on
the sender transmits data
send based on a
is an appealing choice
based on a control
an appealing choice because
on a control policy
appealing choice because amazon
existing operating systems and
choice because amazon also
operating systems and applications
generating error correction packets
systems and applications generally
because amazon also offers
and applications generally do
amazon also offers the
applications generally do not
also offers the ec
generally do not provide
error correction packets from
do not provide this
correction packets from less
not provide this information
packets from less than
from less than r
less than r data
so it is possible
than r data packets
it is possible to
so we have not
is possible to use
we have not investigated
possible to use their
have not investigated it
r data packets at
when the socket at
data packets at the
the socket at the
to use their services
socket at the root
packets at the sender
not investigated it further
at the sender is
at the root of
the sender is not
the root of the
sender is not a
root of the tree
use their services as
is not a viable
their services as a
of the tree is
services as a complete
the tree is ready
as a complete hosting
tree is ready for
not a viable option
a complete hosting solution
is ready for transmission
complete hosting solution with
a viable option even
the cache manager s
viable option even though
cache manager s writeback
option even though the
hosting solution with low
even though the data
manager s writeback thread
though the data rate
s writeback thread divides
the data rate in
writeback thread divides updates
data rate in this
thread divides updates into
solution with low latency
messages will be recursively
rate in this channel
will be recursively pulled
in this channel is
be recursively pulled from
this channel is low
with low latency access
recursively pulled from the
low latency access to
pulled from the tree
latency access to storage
from the tree of
divides updates into metadata
the tree of protocol
updates into metadata operations
tree of protocol stack
of protocol stack components
such as directory modifications
as directory modifications and
directory modifications and file
modifications and file status
and file status changes
feeds that no longer
that no longer have
no longer have data
longer have data to
the two types of
have data to send
two types of operations
data to send are
types of operations are
to send are automatically
of operations are queued
send are automatically deregistered
operations are queued and
the cost analysis is
are queued and replayed
cost analysis is based
queued and replayed to
analysis is based on
and replayed to the
is based on real
h a b c
replayed to the server
a b c d
to the server separately
b c d x
c d x x
world traces taken from
d x x e
traces taken from the
x x e f
taken from the subversion
x e f g
from the subversion repositories
e f g h
sharing and priority i
f g h x
the subversion repositories of
so that a metadata
subversion repositories of popular
g h x x
repositories of popular open
h x x a
of popular open source
x x a c
popular open source projects
x a c b
that a metadata rpc
a c b e
a metadata rpc can
c b e d
metadata rpc can proceed
b e d a
subversion represents each revision
and prone to oscillatory
represents each revision in
prone to oscillatory throughput
each revision in a
to oscillatory throughput when
revision in a repository
rpc can proceed in
in a repository s
can proceed in parallel
a repository s history
proceed in parallel with
oscillatory throughput when scaled
in parallel with a
throughput when scaled up
parallel with a file
with a file writeback
regardless of how many
g g x x
of how many changes
g x x f
how many changes it
x x f h
many changes it contains
when an rpc from
when we decided to
x f h x
we decided to take
an rpc from a
decided to take control
rpc from a particular
to take control over
from a particular queue
take control over event
a particular queue completes
the first for data
control over event processing
f h x x
over event processing order
h x x b
we say that the
as a diff against
say that the update
a diff against previous
that the update has
diff against previous revisions
we also eliminated multithreading
the update has been
update has been committed
has been committed at
and the second for
been committed at the
the second for meta
committed at the server
grained scheduling eliminated convoy
data such as the
the next update is
scheduling eliminated convoy behavior
such as the author
next update is then
eliminated convoy behavior and
update is then dequeued
convoy behavior and oscillatory
is then dequeued and
behavior and oscillatory throughput
and oscillatory throughput of
and other revision properties
oscillatory throughput of the
throughput of the sort
of the sort that
the sort that can
separate encoding for odd
sort that can disrupt
our cost analysis is
that can disrupt reliable
encoding for odd and
can disrupt reliable multicast
cost analysis is based
disrupt reliable multicast systems
analysis is based on
reliable multicast systems when
is based on the
multicast systems when they
based on the sizes
systems when they run
for odd and even
when they run at
update logging an asynchronous
they run at high
logging an asynchronous rpc
run at high data
an asynchronous rpc for
at high data rates
asynchronous rpc for it
high data rates on
rpc for it is
data rates on a
for it is initiated
rates on a large
odd and even packets
on the sizes of
and even packets could
the sizes of these
even packets could be
separating the small update
packets could be operating
on a large scale
could be operating at
the small update logging
be operating at near
sizes of these files
operating at near full
of these files and
at near full capacity
these files and the
near full capacity with
files and the time
full capacity with data
and the time at
capacity with data from
the time at which
with data from other
time at which each
data from other senders
at which each revision
the last aspect relates
which is implemented in
last aspect relates to
is implemented in some
aspect relates to the
implemented in some mobile
fec is also very
in some mobile file
is also very susceptible
some mobile file sys
also very susceptible to
relates to the creation
which each revision was
to the creation of
each revision was committed
the creation of new
very susceptible to bursty
metadata rpcs from file
creation of new messages
rpcs from file writes
susceptible to bursty losses
looking up the size
from file writes allows
up the size of
particularly by qsm itself
file writes allows remote
the size of these
writes allows remote clients
allows remote clients to
size of these special
remote clients to see
readers who have implemented
clients to see statems
of these special files
who have implemented multicast
these special files is
have implemented multicast protocols
special files is only
implemented multicast protocols will
files is only possible
multicast protocols will know
is only possible if
protocols will know that
only possible if one
will know that most
possible if one has
know that most existing
if one has filesystem
that most existing systems
one has filesystem level
most existing systems are
has filesystem level access
existing systems are push
filesystem level access to
level access to the
access to the disk
to the disk on
the disk on which
disk on which the
on which the repository
which the repository is
the repository is stored
is a standard encoding
some layer initiates a
a standard encoding technique
layer initiates a new
standard encoding technique used
initiates a new message
encoding technique used to
a new message at
technique used to combat
new message at will
used to combat bursty
so we had to
to combat bursty loss
we had to use
had to use subversion
and lower layers then
to use subversion s
lower layers then buffer
use subversion s mirroring
where error correction packets
subversion s mirroring capability
error correction packets are
s mirroring capability to
correction packets are generated
mirroring capability to fetch
packets are generated from
capability to fetch revisions
are generated from alternate
to fetch revisions from
generated from alternate disjoint
fetch revisions from the
from alternate disjoint sub
revisions from the network
layers then buffer that
tus changes to files
then buffer that message
changes to files without
buffer that message until
to files without having
that message until it
streams of data rather
message until it can
of data rather than
accessible repository and replay
files without having to
repository and replay them
data rather than from
until it can be
without having to wait
and replay them against
rather than from consecutive
it can be sent
having to wait for
replay them against a
to wait for intervening
them against a local
wait for intervening writequirement
than from consecutive packets
this makes sense under
for intervening writequirement that
makes sense under the
against a local copy
sense under the assumption
intervening writequirement that processes
under the assumption that
writequirement that processes wait
the assumption that senders
that processes wait for
assumption that senders often
processes wait for writes
that senders often generate
doing this also implicitly
senders often generate bursts
with an interleave index
often generate bursts of
this also implicitly gives
an interleave index of
rather than sending an
generate bursts of packets
also implicitly gives us
than sending an back
implicitly gives us the
sending an back traffic
gives us the log
us the log of
the log of timestamps
log of timestamps indicating
the encoder would create
of timestamps indicating when
encoder would create correction
timestamps indicating when each
would create correction packets
indicating when each revision
create correction packets separately
when each revision was
a similar motivation underlies
the communication subsystem can
similar motivation underlies the
communication subsystem can smooth
motivation underlies the cache
subsystem can smooth the
underlies the cache consisupdate
can smooth the traffic
correction packets separately from
each revision was committed
packets separately from three
the cache consisupdate to
separately from three disjoint
cache consisupdate to the
from three disjoint sub
consisupdate to the server
thus it is possible
to the server as
it is possible to
the server as soon
is possible to calculate
server as soon as
possible to calculate the
as soon as a
to calculate the bandwidth
soon as a file
smooth the traffic flow
as a file is
the traffic flow and
a file is closed
traffic flow and keep
the first containing data
flow and keep the
first containing data packets
and keep the network
containing data packets numbered
keep the network interface
the cache manager tency
the network interface busy
cache manager tency scheme
manager tency scheme for
tency scheme for high
transaction costs of pushing
scheme for high read
costs of pushing the
of pushing the two
one consequence is that
pushing the two files
consequence is that messages
the two files for
is that messages can
write contention environments we
that messages can linger
two files for each
messages can linger for
files for each revision
can linger for a
for each revision into
linger for a while
each revision into s
for a while before
contention environments we logs
a while before they
environments we logs the
while before they are
we logs the update
before they are sent
logs the update and
the update and periodically
update and periodically flushes
based on amazon s
and periodically flushes logged
on amazon s current
periodically flushes logged updates
amazon s current pricing
flushes logged updates to
s current pricing structure
logged updates to the
not only does this
updates to the describe
only does this increase
to the describe in
does this increase memory
the describe in section
this increase memory consumption
shown in table i
but if a message
table i a mazon
if a message contains
i a mazon s
a message contains current
the chief complexity in
a mazon s s
chief complexity in implementing
message contains current state
complexity in implementing asynchronous
contains current state information
in implementing asynchronous writeserver
that state may be
these systems enable logging
state may be stale
systems enable logging when
may be stale by
enable logging when bandwidth
be stale by the
logging when bandwidth is
stale by the time
when bandwidth is low
by the time it
the second with data
the time it s
second with data packets
time it s sent
with data packets numbered
to improve read performance
improve read performance and
read performance and reduce
in contrast to this
performance and reduce write
contrast to this usual
and reduce write traffic
to this usual approach
reduce write traffic by
write traffic by aggregat
qsm implements a pull
implements a pull architecture
back lies in resolving
lies in resolving dependencies
in resolving dependencies between
resolving dependencies between metadata
dependencies between metadata operations
between metadata operations ing
evaluation evaluation of qsm
metadata operations ing updates
evaluation of qsm could
operations ing updates to
of qsm could pursue
ing updates to the
qsm could pursue many
updates to the same
could pursue many directions
to the same file
the same file in
same file in the
file in the log
in the log before
costs of the domain
the log before they
of the domain crossing
log before they are
the domain crossing between
before they are transmitted
domain crossing between the
crossing between the application
between the application and
the application and qsm
and updates to the
updates to the same
to the same file
protocol design and scalability
and interactions between protocol
interactions between protocol properties
a file may be
between protocol properties and
file may be created
protocol properties and the
properties and the managed
and the managed framework
update logging separates communication
logging separates communication with
here we focus on
separates communication with the
and the third with
communication with the server
the third with data
with the server into
we focus on the
third with data packets
the server into modified
focus on the latter
with data packets numbered
server into modified and
into modified and closed
our goal is to
goal is to arrive
and the length of
the length of the
is to arrive at
length of the metadata
to arrive at a
of the metadata queue
not included in the
the metadata queue may
arrive at a deep
metadata queue may two
included in the analysis
queue may two distinct
in the analysis is
may two distinct streams
at a deep understanding
the analysis is the
a deep understanding of
analysis is the cost
deep understanding of the
is the cost of
updates to files and
understanding of the performance
to files and directories
the cost of fetching
of the performance limits
cost of fetching data
the performance limits of
of fetching data out
performance limits of qsm
fetching data out of
and all be enough
data out of s
limits of qsm when
all be enough to
of qsm when operating
be enough to mean
qsm when operating at
enough to mean that
when operating at high
to be served to
operating at high data
be served to clients
at high data rates
to mean that the
high data rates with
mean that the file
data rates with large
that the file update
rates with large numbers
the file update would
with large numbers of
file update would be
this cost will vary
update would be initiated
large numbers of overlapping
would be initiated first
numbers of overlapping groups
cost will vary depending
will vary depending on
vary depending on how
depending on how much
on how much caching
for reasons of brevity
how much caching is
much caching is done
caching is done on
these two types of
is done on the
two types of communication
done on the front
types of communication are
we are unable to
of communication are scheduled
are unable to undertake
communication are scheduled this
unable to undertake a
are scheduled this case
to undertake a detailed
scheduled this case the
undertake a detailed analysis
this case the file
a detailed analysis of
case the file update
detailed analysis of oscillatory
interleaving adds burst tolerance
the file update must
analysis of oscillatory phenomena
file update must wait
adds burst tolerance to
of oscillatory phenomena in
burst tolerance to fec
oscillatory phenomena in this
tolerance to fec but
phenomena in this paper
to fec but exacerbates
fec but exacerbates its
a file may be
but exacerbates its sensitivity
also called convoys and
exacerbates its sensitivity to
called convoys and broadcast
its sensitivity to sending
convoys and broadcast storms
sensitivity to sending rate
test activity gc grep
to sending rate with
activity gc grep compile
and dedicated servers potentially
gc grep compile grep
dedicated servers potentially having
sending rate with an
these plague many multicast
rate with an interleave
plague many multicast and
with an interleave index
many multicast and pub
an interleave index of
servers potentially having much
grep compile grep write
interleave index of i
compile grep write read
index of i and
potentially having much more
grep write read compile
having much more due
of i and an
write read compile read
much more due to
read compile read write
more due to inexpensive
compile read write gw
due to inexpensive sata
read write gw rc
to inexpensive sata disks
write gw rc rw
event prioritization eliminated such
i and an encoding
prioritization eliminated such problems
and an encoding rate
eliminated such problems in
an encoding rate of
it is not unreasonable
such problems in the
gw rc rw synchronous
problems in the configurations
rc rw synchronous uniform
in the configurations tested
rw synchronous uniform priorities
the configurations tested by
is not unreasonable to
configurations tested by our
not unreasonable to assume
tested by our experiments
unreasonable to assume that
to assume that a
assume that a cache
that a cache hit
a cache hit rate
cache hit rate of
hit rate of close
rate of close to
the sender would have
sender would have to
would have to wait
have to wait for
to wait for i
on varying numbers of
varying numbers of nodes
we ll find that
ll find that the
find that the experiments
that the experiments have
the experiments have a
experiments have a pattern
in scenario after scenario
packets before sending any
before sending any redundancy
sending any redundancy information
the performance of qsm
performance of qsm is
these two obstacles to
of qsm is ultimately
two obstacles to using
qsm is ultimately limited
obstacles to using fec
is ultimately limited by
to using fec in
ultimately limited by overheads
using fec in time
public subversion repositories of
limited by overheads associated
subversion repositories of the
by overheads associated with
repositories of the debian
sensitive settings rate sensitivity
of the debian linux
overheads associated with memory
the debian linux community
settings rate sensitivity and
debian linux community amount
associated with memory management
linux community amount to
rate sensitivity and burst
community amount to a
with memory management in
amount to a total
sensitivity and burst susceptibility
memory management in the
and burst susceptibility are
management in the managed
to a total of
in the managed environment
a total of only
burst susceptibility are interlinked
susceptibility are interlinked through
are interlinked through the
interlinked through the tuning
through the tuning knobs
the more memory in
more memory in use
an interleave of i
interleave of i and
of i and a
i and a rate
and a rate of
the only outgoing bandwidth
the higher the overheads
only outgoing bandwidth costs
higher the overheads of
outgoing bandwidth costs are
the overheads of the
bandwidth costs are then
overheads of the memory
costs are then to
of the memory management
are then to to
the memory management subsystem
then to to replace
memory management subsystem and
provides tolerance to a
management subsystem and the
tolerance to a burst
subsystem and the more
to a burst of
and the more cpu
to to replace failed
a burst of up
the more cpu time
burst of up to
more cpu time it
of up to c
cpu time it consumes
up to c i
to replace failed frontend
to c i consecutive
replace failed frontend servers
c i consecutive packets
failed frontend servers or
leaving less time for
frontend servers or to
less time for qsm
servers or to synchronize
time for qsm to
or to synchronize replicas
for qsm to run
to synchronize replicas if
synchronize replicas if more
replicas if more than
the burst tolerance of
if more than one
burst tolerance of an
these aren t just
more than one is
aren t just garbage
than one is in
t just garbage collection
one is in use
just garbage collection costs
tolerance of an fec
of an fec code
an fec code can
fec code can be
in the case of
every aspect of memory
code can be changed
aspect of memory management
the case of ec
of memory management gets
can be changed by
memory management gets expensive
be changed by modulating
changed by modulating either
by modulating either the
modulating either the c
either the c or
and the costs grow
the c or the
the bandwidth costs are
c or the i
bandwidth costs are actually
the costs grow linearly
costs are actually waived
costs grow linearly in
or the i parameters
grow linearly in the
are actually waived and
linearly in the amount
actually waived and the
in the amount of
waived and the user
the amount of memory
increasing c enhances burst
amount of memory in
and the user then
of memory in use
the user then pays
c enhances burst tolerance
user then pays only
enhances burst tolerance at
then pays only for
burst tolerance at the
when qsm runs flat
tolerance at the cost
pays only for the
at the cost of
only for the traffic
the cost of network
for the traffic between
cost of network and
the traffic between the
of network and encoding
traffic between the front
network and encoding overhead
cpu cycles are a
cycles are a precious
are a precious commodity
end servers and their
potentially worsening the packet
servers and their clients
worsening the packet loss
the packet loss experienced
packet loss experienced and
loss experienced and reducing
experienced and reducing throughput
table ii shows the
minimizing the memory footprint
ii shows the cost
the memory footprint turns
shows the cost of
memory footprint turns out
the cost of using
footprint turns out to
cost of using s
turns out to be
out to be the
to be the key
increasing i trades off
be the key to
i trades off recovery
for a number of
trades off recovery latency
a number of individual
the key to high
number of individual open
key to high performance
of individual open source
off recovery latency for
individual open source projects
recovery latency for better
latency for better burst
for better burst tolerance
all results reported here
better burst tolerance without
results reported here come
burst tolerance without adding
reported here come from
tolerance without adding overhead
here come from experiments
without adding overhead as
come from experiments on
adding overhead as mentioned
from experiments on a
as well as an
well as an aggregate
as an aggregate for
an aggregate for the
for higher values of
higher values of i
the encoder has to
encoder has to wait
has to wait for
to wait for more
repositories of the debian
wait for more data
of the debian community
for more data packets
cluster of pentium iii
more data packets to
data packets to be
packets to be transmitted
also shown is an
to be transmitted before
shown is an estimate
be transmitted before it
is an estimate for
transmitted before it can
an estimate for the
before it can send
estimate for the apache
it can send error
for the apache software
can send error correction
the apache software foundation
send error correction packets
apache has taken the
has taken the unusual
taken the unusual approach
the unusual approach of
once the fec encoding
unusual approach of using
the fec encoding is
approach of using a
fec encoding is parameterized
of using a single
encoding is parameterized with
using a single repository
is parameterized with a
a single repository for
connected into a single
single repository for all
parameterized with a rate
repository for all of
into a single broadcast
for all of its
a single broadcast domain
all of its projects
with a rate and
single broadcast domain using
a rate and an
broadcast domain using a
rate and an interleave
domain using a switched
and an interleave to
both public and restricted
an interleave to tolerate
interleave to tolerate a
to tolerate a certain
tolerate a certain burst
a certain burst length
due to access control
certain burst length b
to access control restrictions
access control restrictions on
control restrictions on some
restrictions on some paths
subversion s mirroring tool
s mirroring tool was
nodes run windows server
mirroring tool was unable
tool was unable to
was unable to create
unable to create local
to create local copy
the complete log of
complete log of timestamps
how much does it
much does it cost
to tolerate a burst
tolerate a burst of
a burst of length
description monthly storage bandwidth
monthly storage bandwidth in
storage bandwidth in bandwidth
bandwidth in bandwidth out
in bandwidth out per
our benchmark is an
benchmark is an nary
linked to the qsm
to the qsm library
running in the same
in the same process
all losses occurring in
losses occurring in bursts
occurring in bursts of
in bursts of size
bursts of size less
of size less than
size less than or
less than or equal
than or equal to
or equal to b
equal to b are
reads apache software foundation
to b are recovered
apache software foundation debian
b are recovered with
software foundation debian linux
are recovered with the
foundation debian linux community
recovered with the same
with the same latency
the same latency and
same latency and this
latency and this latency
and this latency depends
this latency depends on
latency depends on the
depends on the i
on the i parameter
at the maximum possible
the maximum possible rate
we d like to
d like to parameterize
like to parameterize the
the majority of the
to parameterize the encoding
majority of the figures
parameterize the encoding to
of the figures include
the encoding to tolerate
encoding to tolerate a
to tolerate a maximum
tolerate a maximum burst
a maximum burst length
maximum burst length and
burst length and then
length and then have
and then have recovery
then have recovery latency
have recovery latency depend
recovery latency depend on
latency depend on the
depend on the actual
on the actual burstiness
but these intervals are
the actual burstiness of
these intervals are sometimes
actual burstiness of the
intervals are sometimes so
burstiness of the loss
are sometimes so small
sometimes so small that
so small that they
small that they may
that they may not
at the same time
they may not always
may not always be
not always be visible
we would like the
would like the encoding
growing cost of memory
like the encoding to
cost of memory allocation
the encoding to have
encoding to have a
to have a constant
have a constant rate
a constant rate for
constant rate for network
rate for network provisioning
for network provisioning and
network provisioning and stability
an fec scheme is
fec scheme is required
scheme is required where
is required where latency
required where latency of
where latency of recovery
latency of recovery degrades
of recovery degrades gracefully
recovery degrades gracefully as
degrades gracefully as losses
gracefully as losses get
as losses get burstier
even as the encoding
as the encoding overhead
the encoding overhead stays
encoding overhead stays constant
throughput as a function
as a function of
a function of the
function of the number
of the number of
the number of nodes
processor utilization as a
utilization as a function
as a function of
a function of the
function of the multicast
of the multicast rate
end flow control x
flow control x appliance
control x appliance appliance
x appliance appliance end
size of repository stored
memory overheads on the
of repository stored in
overheads on the sender
repository stored in s
on the sender we
the sender we begin
sender we begin by
we begin by showing
split flow control fig
begin by showing that
by showing that memory
showing that memory overhead
that memory overhead at
memory overhead at the
overhead at the sender
at the sender is
the sender is a
sender is a central
so we based our
is a central to
we based our analysis
a central to throughput
based our analysis on
flow control options in
our analysis on that
control options in maelstrom
analysis on that along
on that along with
that along with the
along with the assumption
with the assumption each
the assumption each revision
assumption each revision data
each revision data file
revision data file would
shows throughput in messages
data file would be
s in experiments with
lan mtu lambda jumbo
mtu lambda jumbo mtu
lambda jumbo mtu recipe
jumbo mtu recipe list
senders multicasting to a
multicasting to a varying
to a varying number
a varying number of
varying number of receivers
kib and each revision
and each revision property
each revision property file
all of which belong
of which belong to
which belong to a
belong to a single
to a single group
with a single sender
no rate limit was
rate limit was used
the averages observed for
averages observed for the
observed for the other
for the other repositories
the other repositories in
the sender has more
other repositories in table
sender has more work
repositories in table ii
has more work to
more work to do
work to do than
to do than the
do than the receivers
than the receivers and
table ii m ost
the receivers and on
ii m ost recent
receivers and on our
m ost recent monthly
and on our clusters
ost recent monthly cost
recent monthly cost of
monthly cost of storing
cost of storing repositories
of storing repositories in
storing repositories in s
isn t fast enough
t fast enough to
fast enough to saturate
enough to saturate the
to saturate the network
for individual projects and
individual projects and entire
projects and entire communities
and entire communities software
entire communities software project
communities software project squirrelmail
software project squirrelmail phpmyadmin
project squirrelmail phpmyadmin subversion
squirrelmail phpmyadmin subversion mono
phpmyadmin subversion mono kde
subversion mono kde hosting
mono kde hosting community
kde hosting community debian
hosting community debian linux
community debian linux community
debian linux community apache
linux community apache software
community apache software foundation
we report the highest
apache software foundation monthly
report the highest combined
software foundation monthly cost
the highest combined send
highest combined send rate
combined send rate that
send rate that the
rate that the system
that the system could
the system could sustain
system could sustain without
could sustain without developing
sustain without developing backlogs
without developing backlogs at
developing backlogs at the
backlogs at the senders
why does performance decrease
does performance decrease with
performance decrease with the
decrease with the number
with the number of
the number of receivers
let s focus on
s focus on a
repair packets are injected
packets are injected into
are injected into stream
injected into stream transparently
into stream transparently iv
m aelstrom d esign
aelstrom d esign and
d esign and i
esign and i mplementation
and i mplementation we
i mplementation we describe
mplementation we describe the
we describe the maelstrom
describe the maelstrom appliance
shows that whereas receivers
the maelstrom appliance as
that whereas receivers are
maelstrom appliance as a
whereas receivers are not
appliance as a single
receivers are not cpu
as a single machine
a single machine later
we will show how
will show how more
and loss rates in
show how more machines
loss rates in this
how more machines can
rates in this experiment
more machines can be
machines can be added
can be added to
be added to the
added to the appliance
to the appliance to
the appliance to balance
appliance to balance encoding
to balance encoding load
balance encoding load and
the sender is saturated
encoding load and scale
load and scale to
and scale to multiple
scale to multiple gigabits
to multiple gigabits per
and hence is the
multiple gigabits per second
hence is the bottleneck
gigabits per second of
per second of traffic
running this test again
this test again in
test again in a
again in a profiler
in a profiler reveals
a profiler reveals that
profiler reveals that the
basic mechanism the basic
reveals that the percentage
mechanism the basic operation
that the percentage of
the basic operation of
the percentage of time
basic operation of maelstrom
percentage of time spent
operation of maelstrom is
of time spent in
of maelstrom is shown
time spent in qsm
maelstrom is shown in
spent in qsm code
is shown in figure
in qsm code is
qsm code is decreasing
whereas more and more
more and more time
and more time is
more time is spent
time is spent in
is spent in mscorwks
it intercepts outgoing data
intercepts outgoing data packets
outgoing data packets and
data packets and routes
even for the fairly
packets and routes them
for the fairly large
and routes them to
the fairly large apache
routes them to the
fairly large apache software
them to the destination
large apache software foundation
to the destination data
the destination data center
the current cost of
current cost of using
cost of using s
generating and injecting fec
and injecting fec repair
injecting fec repair packets
fec repair packets into
repair packets into the
for storage is less
packets into the stream
storage is less than
into the stream in
the stream in their
stream in their wake
a repair packet consists
repair packet consists of
packet consists of a
consists of a recipe
it is very unlikely
of a recipe list
is very unlikely that
a recipe list of
shows that the main
very unlikely that any
recipe list of data
unlikely that any vendor
list of data packet
that the main culprit
of data packet identifiers
that any vendor could
data packet identifiers and
the main culprit behind
packet identifiers and fec
any vendor could provide
identifiers and fec information
main culprit behind the
vendor could provide a
culprit behind the increase
and fec information generated
behind the increase of
fec information generated from
the increase of overhead
information generated from these
increase of overhead is
generated from these packets
of overhead is a
could provide a traditional
overhead is a figure
provide a traditional storage
a traditional storage solution
in the example in
traditional storage solution consisting
the example in figure
storage solution consisting of
solution consisting of scsi
consisting of scsi disks
of scsi disks and
scsi disks and tape
disks and tape backup
and tape backup at
tape backup at this
the percentages of the
this information is a
percentages of the profiler
information is a simple
backup at this price
of the profiler samples
is a simple xor
the profiler samples taken
profiler samples taken from
samples taken from qsm
taken from qsm and
the amount of s
from qsm and clr
the size of the
qsm and clr dlls
size of the xor
storage required of course
required of course increases
of course increases each
course increases each month
increases each month as
of the xor is
each month as the
the xor is equal
month as the repository
xor is equal to
as the repository grows
is equal to the
equal to the mtu
to the mtu of
the mtu of the
mtu of the data
of the data center
memory allocation and garbage
the data center network
allocation and garbage collection
but as shown in
and garbage collection overheads
as shown in figure
garbage collection overheads on
collection overheads on the
overheads on the sender
on the sender node
and to avoid fragmentation
to avoid fragmentation of
the former grows by
avoid fragmentation of repair
the increase is roughly
fragmentation of repair packets
increase is roughly linear
of repair packets we
repair packets we require
packets we require that
we require that the
require that the mtu
as developer productivity remains
that the mtu of
developer productivity remains constant
the mtu of the
mtu of the long
and the latter by
the cost of storage
cost of storage is
haul network be set
of storage is declining
network be set to
storage is declining exponentially
be set to a
set to a slightly
to a slightly larger
a slightly larger value
this requirement is easily
requirement is easily satisfied
is easily satisfied in
easily satisfied in practice
so if amazon s
since gigabit links very
if amazon s pricing
gigabit links very often
amazon s pricing stays
links very often use
s pricing stays competitive
very often use jumbo
often use jumbo frames
use jumbo frames of
jumbo frames of up
frames of up to
this configuration is typical
configuration is typical of
term trend is towards
is typical of the
trend is towards lower
typical of the host
is towards lower costs
of the host environment
the host environment expected
host environment expected for
environment expected for our
expected for our target
additional costs will be
for our target applications
costs will be incurred
will be incurred for
be incurred for front
for the case of
the case of ec
while lan networks have
of the overhead is
lan networks have standard
the overhead is the
networks have standard mtus
overhead is the allocation
have standard mtus of
is the allocation of
a standard machine instance
the allocation of byte
standard machine instance is
allocation of byte arrays
machine instance is billed
of byte arrays to
instance is billed at
byte arrays to send
arrays to send in
to send in the
send in the application
at the receiving data
the receiving data center
the appliance examines incoming
appliance examines incoming repair
plus data transfer of
examines incoming repair packets
incoming repair packets and
repair packets and uses
packets and uses them
and uses them to
uses them to recover
them to recover missing
to recover missing data
recover missing data packets
the data packet is
data packet is injected
packet is injected transparently
per gib in and
is injected transparently into
injected transparently into the
transparently into the stream
into the stream to
the stream to the
stream to the receiving
to the receiving end
of time is spent
time is spent exclusively
is spent exclusively on
recovered data packets will
spent exclusively on copying
data packets will typically
exclusively on copying memory
packets will typically arrive
on copying memory in
will typically arrive out
copying memory in the
memory in the clr
discounts are available if
are available if data
available if data transfer
if data transfer exceeds
order at the end
even though we used
though we used our
we used our own
used our own scatter
and hence it is
hence it is vital
and the instance cost
it is vital that
the instance cost may
gather serialization scheme that
instance cost may be
is vital that packets
serialization scheme that efficiently
cost may be reduced
scheme that efficiently uses
may be reduced to
that efficiently uses scatter
vital that packets be
that packets be recovered
packets be recovered by
be recovered by the
recovered by the appliance
by the appliance extremely
the appliance extremely quickly
appliance extremely quickly to
extremely quickly to avoid
quickly to avoid triggering
to avoid triggering mechanisms
the increase in the
avoid triggering mechanisms in
increase in the memory
triggering mechanisms in commodity
in the memory allocation
mechanisms in commodity stacks
the memory allocation overhead
per hour by paying
in commodity stacks that
memory allocation overhead and
hour by paying a
allocation overhead and the
commodity stacks that interpret
overhead and the activity
stacks that interpret out
and the activity of
the activity of the
activity of the garbage
of the garbage collector
the garbage collector are
garbage collector are caused
collector are caused by
are caused by the
caused by the increasing
order arrival as congestion
by the increasing memory
arrival as congestion in
the increasing memory usage
as congestion in the
congestion in the network
year reservation fee in
reservation fee in advance
flow control while relaying
control while relaying tcp
this gives an amortized
gives an amortized monthly
reflectsan increase of the
an amortized monthly cost
increase of the average
amortized monthly cost of
of the average number
the average number of
average number of multicasts
number of multicasts pending
of multicasts pending completion
maelstrom has two flow
has two flow control
two flow control modes
illustrates these two modes
a copy is kept
as we show in
copy is kept by
we show in the
is kept by the
show in the next
kept by the sender
in the next section
by the sender for
the sender for possible
sender for possible loss
for possible loss recovery
one instance should be
instance should be enough
should be enough for
notice that memory consumption
be enough for almost
that memory consumption grows
enough for almost any
memory consumption grows nearly
for almost any individual
almost any individual project
any individual project or
individual project or moderately
times faster than the
project or moderately sized
faster than the number
or moderately sized community
than the number of
the number of messages
number of messages pending
of messages pending acknowledgement
the appliance treats tcp
if we freeze the
we freeze the sender
usage patterns in addition
freeze the sender process
ip packets as conventional
the sender process and
patterns in addition to
sender process and inspect
packets as conventional ip
process and inspect the
in addition to getting
and inspect the contents
as conventional ip packets
inspect the contents of
addition to getting a
the contents of the
conventional ip packets and
contents of the managed
to getting a grasp
of the managed heap
ip packets and routes
getting a grasp of
packets and routes them
a grasp of the
and routes them through
grasp of the costs
routes them through without
of the costs involved
we find that the
them through without modification
the costs involved in
find that the number
costs involved in moving
that the number of
involved in moving a
the number of objects
in moving a repository
number of objects in
moving a repository to
of objects in memory
a repository to s
objects in memory is
control to proceed between
in memory is more
to proceed between the
memory is more than
proceed between the end
is more than twice
more than twice the
than twice the number
twice the number of
the number of multicasts
number of multicasts pending
it is important to
of multicasts pending acknowledgement
is important to understand
important to understand the
to understand the usage
understand the usage patterns
although some of these
some of these have
of these have already
these have already been
especially the rate at
have already been acknowledged
the rate at which
ip s semantics are
rate at which commits
s semantics are not
at which commits take
semantics are not modified
which commits take place
they haven t yet
haven t yet been
t yet been garbage
yet been garbage collected
when the sending endhost
since achieving the consistency
the sending endhost receives
achieving the consistency properties
sending endhost receives an
the growing amount of
the consistency properties that
endhost receives an acknowledgment
growing amount of unacknowledged
consistency properties that developers
amount of unacknowledged data
properties that developers expect
of unacknowledged data is
that developers expect will
unacknowledged data is caused
it can assume that
data is caused by
can assume that the
developers expect will require
assume that the receiving
is caused by the
that the receiving end
caused by the increase
expect will require a
by the increase of
will require a consistency
the increase of the
require a consistency layer
increase of the average
a consistency layer to
of the average time
host successfully received the
consistency layer to be
the average time to
successfully received the message
average time to acknowledge
layer to be built
time to acknowledge a
to be built in
to acknowledge a message
be built in front
built in front of
in front of s
maelstrom functions as a
functions as a passive
it is crucial that
as a passive device
is crucial that any
crucial that any such
that any such layer
any such layer be
such layer be able
layer be able to
snooping outgoing and incoming
be able to handle
outgoing and incoming traffic
able to handle the
this grows because of
to handle the load
and incoming traffic at
handle the load of
grows because of the
the load of commits
incoming traffic at the
because of the increasing
traffic at the data
of the increasing time
at the data center
the increasing time to
the data center s
increasing time to circulate
the critical statistic to
time to circulate a
critical statistic to consider
to circulate a token
statistic to consider is
data center s edge
to consider is the
circulate a token around
consider is the number
center s edge its
is the number of
a token around the
the number of simultaneous
s edge its failure
number of simultaneous commits
token around the region
edge its failure does
around the region for
its failure does not
the region for purposes
failure does not disrupt
region for purposes of
does not disrupt the
for centralized revision control
not disrupt the flow
centralized revision control system
disrupt the flow of
revision control system such
for purposes of state
the flow of packets
purposes of state aggregation
flow of packets between
control system such as
of packets between the
system such as subversion
packets between the two
between the two data
the two data centers
each commit is assigned
commit is assigned a
is assigned a unique
the time to acknowledge
time to acknowledge is
to acknowledge is only
acknowledge is only slightly
and any change to
is only slightly higher
any change to a
only slightly higher than
change to a versioned
slightly higher than the
side appliance acts as
higher than the expected
appliance acts as a
to a versioned file
acts as a tcp
a versioned file is
versioned file is stored
file is stored as
is stored as a
stored as a diff
as a diff against
a diff against its
diff against its previous
against its previous version
s to wait until
terminating connections and sending
to wait until the
connections and sending back
wait until the next
and sending back acks
until the next token
a commit must be
sending back acks immediately
the next token round
back acks immediately before
commit must be rejected
acks immediately before relaying
immediately before relaying data
must be rejected if
before relaying data on
plus the roundtrip time
relaying data on appliance
be rejected if any
rejected if any of
if any of the
as we scale up
any of the versioned
of the versioned files
the versioned files that
split mode is extremely
versioned files that it
mode is extremely useful
files that it touches
roundtrip time becomes dominant
is extremely useful when
that it touches have
extremely useful when endhosts
it touches have been
useful when endhosts have
touches have been changed
when endhosts have limited
have been changed in
endhosts have limited buffering
these experiments show that
have limited buffering capacity
been changed in an
experiments show that the
changed in an earlier
show that the critical
in an earlier revision
that the critical factor
an earlier revision that
since it allows the
earlier revision that the
it allows the receive
revision that the developer
the critical factor determining
that the developer performing
critical factor determining performance
the developer performing the
factor determining performance is
side appliance to buffer
developer performing the commit
appliance to buffer incoming
performing the commit was
to buffer incoming data
the commit was unaware
determining performance is the
commit was unaware of
buffer incoming data over
performance is the time
incoming data over the
is the time needed
data over the highspeed
the time needed for
over the highspeed long
time needed for the
needed for the system
this ensures that every
for the system to
ensures that every conflict
the system to aggregate
that every conflict gets
system to aggregate state
every conflict gets resolved
to aggregate state over
it also mitigates tcp
aggregate state over regions
conflict gets resolved by
gets resolved by a
resolved by a human
by a human before
a human before becoming
human before becoming part
before becoming part of
becoming part of the
start effects for short
part of the repository
they shed light on
of the repository s
shed light on a
the repository s state
light on a mechanism
on a mechanism that
a mechanism that links
mechanism that links latency
that links latency to
links latency to throughput
exclusive locking is required
maelstrom has to operate
locking is required on
has to operate as
is required on commits
via increased memory consumption
to operate as an
increased memory consumption and
operate as an active
memory consumption and the
as an active device
taking a loose definition
consumption and the resulting
a loose definition of
and the resulting increase
loose definition of simultaneous
the resulting increase in
definition of simultaneous to
resulting increase in allocation
inserted into the critical
of simultaneous to be
increase in allocation and
simultaneous to be within
into the critical communication
to be within one
in allocation and garbage
be within one minute
the critical communication path
allocation and garbage collection
critical communication path its
and garbage collection overheads
communication path its failure
the apache repository had
path its failure disconnects
apache repository had a
its failure disconnects the
repository had a maximum
failure disconnects the communication
had a maximum of
disconnects the communication path
the communication path between
communication path between the
path between the two
between the two data
simultaneous commits and the
the two data centers
commits and the debian
and the debian community
ms increase in latency
ignoring for now that
for now that their
now that their use
that their use of
while maelstrom respects endto
mb increase in memory
increase in memory consumption
end flow control connections
separate repositories allows for
repositories allows for finergrained
allows for finergrained locking
can inflate overheads by
or splits them and
splits them and implements
them and implements its
and implements its own
an aggregate maximum of
implements its own proxy
proxy flow control as
in determining these numbers
flow control as described
control as described above
determining these numbers we
these numbers we filtered
numbers we filtered out
we filtered out any
filtered out any sequences
it is not designed
out any sequences of
is not designed for
and degrade the throughput
any sequences of multiple
degrade the throughput by
not designed for routinely
sequences of multiple commits
designed for routinely congested
of multiple commits by
for routinely congested networks
multiple commits by the
commits by the same
by the same author
the addition of fec
the same author during
addition of fec under
same author during a
of fec under tcp
author during a one
one way to alleviate
during a one minute
way to alleviate the
a one minute period
to alleviate the problem
ip flow control allows
one minute period since
flow control allows it
minute period since those
control allows it to
period since those were
allows it to steal
since those were likely
it to steal bandwidth
alleviate the problem we
to steal bandwidth from
those were likely sequential
steal bandwidth from other
were likely sequential rather
bandwidth from other competing
likely sequential rather than
from other competing flows
ve identified could be
other competing flows running
sequential rather than simultaneous
competing flows running without
identified could be to
flows running without fec
rather than simultaneous and
running without fec in
could be to reduce
without fec in the
than simultaneous and do
be to reduce the
simultaneous and do nor
fec in the link
and do nor represent
to reduce the latency
do nor represent the
reduce the latency of
the latency of state
nor represent the common
latency of state aggregation
represent the common case
though maintaining fairness versus
maintaining fairness versus similarly
fairness versus similarly fec
so that it grows
that it grows sub
the average rates were
this might be achieved
might be achieved by
be achieved by using
achieved by using a
by using a deeper
using a deeper hierarchy
a deeper hierarchy of
deeper hierarchy of rings
friendliness with conventional tcp
and by letting tokens
by letting tokens in
letting tokens in each
tokens in each of
in each of these
ip flows is not
each of these rings
flows is not a
of these rings circulate
is not a primary
these rings circulate independently
not a primary protocol
a primary protocol design
primary protocol design goal
protocol design goal on
so exclusive locking for
this would create a
exclusive locking for commits
would create a more
design goal on over
locking for commits should
create a more complex
for commits should not
a more complex structure
commits should not pose
should not pose any
not pose any scalability
pose any scalability problems
any scalability problems in
but aggregation latency would
scalability problems in a
aggregation latency would grow
problems in a typical
latency would grow logarithmically
in a typical environment
would grow logarithmically rather
which are often dedicated
performance of mfs priorities
grow logarithmically rather than
are often dedicated to
logarithmically rather than linearly
of mfs priorities and
we did not consider
mfs priorities and writeback
often dedicated to specific
did not consider the
dedicated to specific highvalue
is reducing state aggregation
to specific highvalue applications
reducing state aggregation latency
priorities and writeback schemes
state aggregation latency the
not consider the rate
aggregation latency the only
consider the rate of
we see evidence for
the rate of read
see evidence for this
each test consists of
evidence for this assertion
test consists of two
for this assertion in
consists of two concurrent
this assertion in the
of two concurrent processes
assertion in the routine
two concurrent processes executing
in the routine use
concurrent processes executing different
the routine use of
processes executing different workloads
routine use of parallel
rate of read operations
latency the only option
of read operations because
use of parallel flows
read operations because clients
mean times to completion
operations because clients updating
times to completion are
because clients updating their
to completion are shown
we evaluated two alternative
clients updating their working
evaluated two alternative approaches
updating their working copies
completion are shown with
are shown with standard
shown with standard deviations
but found that neither
or reading from the
found that neither can
reading from the repository
that neither can substitute
neither can substitute for
and udp blast protocols
can substitute for lowering
do not require a
three different policies for
not require a lock
substitute for lowering the
different policies for writing
for lowering the latency
policies for writing back
lowering the latency of
for writing back files
the latency of the
writing back files are
latency of the recovery
back files are listed
of the recovery state
the debian community today
the recovery state aggregation
debian community today uses
community today uses only
today uses only a
under uniform or differentiated
uses only a single
uniform or differentiated priorities
only a single subversion
our first approach varies
a single subversion server
first approach varies the
approach varies the rate
reads take precedence over
varies the rate of
and the apache foundation
the rate of aggregation
the apache foundation has
rate of aggregation by
apache foundation has a
take precedence over writes
foundation has a master
of aggregation by increasing
has a master server
aggregation by increasing the
a master server plus
by increasing the rate
master server plus a
increasing the rate at
server plus a european
the rate at which
plus a european mirror
rate at which tokens
at which tokens are
which tokens are released
values in bold are
in bold are of
bold are of particular
primarily for latency reasons
are of particular significance
note that elapsed times
that elapsed times for
we expect that most
elapsed times for write
expect that most communities
both in commercial deployments
times for write workloads
that most communities will
for write workloads give
most communities will have
write workloads give the
communities will have at
in commercial deployments and
will have at most
workloads give the time
have at most a
commercial deployments and by
at most a handful
give the time until
this helps only up
the time until the
helps only up to
deployments and by researchers
most a handful of
and by researchers seeking
a handful of front
by researchers seeking to
only up to a
researchers seeking to transfer
up to a point
seeking to transfer large
time until the process
to transfer large amounts
until the process running
transfer large amounts of
the process running the
large amounts of data
process running the workload
amounts of data over
running the workload finishes
of data over high
achieving consistency amazon s
consistency amazon s infrastructure
amazon s infrastructure is
not when the log
s infrastructure is built
when the log is
infrastructure is built on
the log is flushed
is built on the
built on the principle
on the principle of
the principle of eventual
principle of eventual consistency
this is shown in
layered interleaving in layered
is shown in figure
interleaving in layered interleaving
more than one aggregation
than one aggregation is
an fec protocol with
one aggregation is underway
fec protocol with rate
aggregation is underway at
is underway at a
underway at a time
modified and then deleted
and does not directly
and successive tokens perform
does not directly support
successive tokens perform redundant
not directly support the
tokens perform redundant work
directly support the locking
which requires the file
support the locking required
is produced by running
the locking required for
produced by running c
locking required for revision
by running c multiple
required for revision control
running c multiple instances
requires the file update
c multiple instances of
the file update rpc
processing all these tokens
file update rpc to
all these tokens is
update rpc to be
these tokens is costly
originally developed to run
rpc to be cancelled
developed to run the
to be cancelled if
to run the company
multiple instances of an
be cancelled if it
run the company s
cancelled if it is
the company s own
if it is still
company s own online
it is still in
s own online store
is still in transmission
still in transmission when
in transmission when the
transmission when the remove
when the remove rpc
the remove rpc is
the system preferred availability
remove rpc is initiated
system preferred availability over
preferred availability over consistency
availability over consistency because
fec protocol simultaneously with
over consistency because downtime
protocol simultaneously with increasing
consistency because downtime translated
simultaneously with increasing interleave
because downtime translated directly
with increasing interleave indices
downtime translated directly into
increasing interleave indices i
translated directly into lost
an update to a
s decreases the amount
update to a file
decreases the amount of
to a file will
the amount of unacknowledged
a file will supersede
amount of unacknowledged data
file will supersede any
of unacknowledged data by
will supersede any previous
directly into lost revenue
supersede any previous queued
any previous queued updates
customers may opt to
may opt to shop
opt to shop elsewhere
to shop elsewhere or
shop elsewhere or to
compiles the entire mfs
elsewhere or to simply
the entire mfs file
or to simply forgo
entire mfs file system
to simply forgo impulse
mfs file system and
simply forgo impulse purchases
file system and its
forgo impulse purchases that
system and its rpc
but increases throughput by
impulse purchases that they
increases throughput by less
and its rpc library
purchases that they didn
throughput by less than
that they didn t
they didn t really
didn t really need
t really need anyway
an inconsistent shopping cart
files and directories comprising
could be resolved by
be resolved by heuristics
resolved by heuristics or
by heuristics or user
intervention at checkout time
time spent allocating byte
spent allocating byte arrays
allocating byte arrays in
byte arrays in the
arrays in the application
it is well known
is well known that
well known that consistency
known that consistency and
that consistency and availability
none of the files
consistency and availability cannot
of the files are
the files are initially
and availability cannot both
files are initially in
availability cannot both be
are initially in the
cannot both be achieved
initially in the cache
both be achieved simultaneously
be achieved simultaneously in
achieved simultaneously in any
memory used on sender
simultaneously in any real
used on sender and
this workload performs an
on sender and the
in any real network
sender and the number
workload performs an intensive
and the number of
performs an intensive pattern
the number of multicast
any real network where
number of multicast requests
an intensive pattern of
of multicast requests in
real network where hosts
multicast requests in progress
intensive pattern of reads
network where hosts or
pattern of reads and
where hosts or entire
of reads and writes
hosts or entire subnetworks
reads and writes files
or entire subnetworks are
and writes files without
entire subnetworks are sometimes
writes files without raising
subnetworks are sometimes unreachable
files without raising the
are sometimes unreachable due
without raising the issue
sometimes unreachable due to
raising the issue of
unreachable due to connectivity
the issue of concurrent
due to connectivity losses
issue of concurrent accesses
token roundtrip time and
roundtrip time and an
time and an average
and an average time
a topic we tackle
an average time to
topic we tackle in
average time to acknowledge
we tackle in section
time to acknowledge a
to acknowledge a message
if a cloud service
a cloud service is
cloud service is designed
service is designed to
is designed to provide
designed to provide high
to provide high availability
varying token circulation rate
provide high availability but
high availability but an
availability but an application
but an application instead
an application instead requires
performance evaluation of these
application instead requires perfect
evaluation of these workloads
instead requires perfect consistency
we classified grep and
additional software infrastructure is
three instances of an
classified grep and read
software infrastructure is required
our second approach increased
infrastructure is required to
second approach increased the
is required to bridge
grep and read as
required to bridge the
approach increased the amount
to bridge the gap
and read as foreground
increased the amount of
read as foreground workloads
the amount of feedback
amount of feedback to
of feedback to the
feedback to the sender
for revision control it
and compile and write
revision control it makes
compile and write as
control it makes sense
and write as background
it makes sense to
write as background workloads
makes sense to adopt
in our base implementation
sense to adopt eventual
to adopt eventual consistency
adopt eventual consistency for
eventual consistency for read
four combined workloads were
the first instance with
consistency for read operations
first instance with interleave
combined workloads were then
each aggregate ack contains
workloads were then generated
aggregate ack contains a
instance with interleave i
ack contains a single
since at worst an
contains a single value
were then generated by
a single value maxcontiguous
at worst an earlier
then generated by running
worst an earlier revision
generated by running a
an earlier revision will
by running a foreground
earlier revision will fig
running a foreground and
representing the maximum number
a foreground and a
the maximum number such
foreground and a background
maximum number such that
and a background workload
number such that messages
a background workload concurrently
such that messages with
that messages with this
the second with interleave
messages with this and
second with interleave i
with this and all
system architecture be returned
this and all lower
we denote these as
and all lower numbers
denote these as gc
all lower numbers are
lower numbers are stable
if the user is
numbers are stable in
the user is aware
are stable in the
stable in the region
through some other channel
to increase the amount
increase the amount of
the amount of feedback
and the third with
that a newer version
the third with interleave
a newer version should
third with interleave i
newer version should exist
we permit ack to
permit ack to contain
ack to contain up
to contain up to
contain up to k
up to k numeric
to k numeric ranges
he can retry and
can retry and expect
retry and expect that
and expect that version
expect that version to
that version to be
version to be available
to be available within
be available within a
available within a short
within a short timeframe
perfect consistency is required
consistency is required and
is required and a
required and a locking
and a locking layer
a locking layer must
locking layer must be
layer must be built
must be built to
fec encoding is simply
be built to support
encoding is simply an
built to support this
three types of rpcs
is simply an xor
types of rpcs predominate
simply an xor of
an xor of the
xor of the r
of the r data
this may result in
the r data packets
may result in a
r data packets hence
result in a commit
in a commit being
fetches of file data
a commit being rejected
commit being rejected if
being rejected if consensus
in layered interleaving each
rejected if consensus cannot
layered interleaving each data
and store operations for
if consensus cannot be
store operations for files
consensus cannot be reached
interleaving each data packet
each data packet is
data packet is included
packet is included in
is included in c
in descending order of
but shouldn t be
included in c xors
descending order of priority
shouldn t be a
t be a problem
be a problem because
a problem because code
each of which is
the aim of the
the system can now
aim of the experiments
system can now cleanup
problem because code changes
can now cleanup message
of the experiments was
now cleanup message sequences
because code changes are
cleanup message sequences that
the experiments was to
of which is generated
experiments was to demonstrate
which is generated at
was to demonstrate that
is generated at different
to demonstrate that priorities
generated at different interleaves
code changes are usually
at different interleaves from
demonstrate that priorities improve
different interleaves from the
that priorities improve the
message sequences that have
priorities improve the performance
sequences that have as
improve the performance of
that have as gaps
the performance of the
interleaves from the original
performance of the foreground
from the original data
of the foreground workloads
the original data stream
changes are usually not
messages that are still
are usually not impulse
that are still unstable
usually not impulse decisions
not impulse decisions and
the four combined workloads
impulse decisions and the
four combined workloads were
decisions and the commit
combined workloads were executed
as we shall describe
and the commit can
we shall describe shortly
workloads were executed on
the commit can be
were executed on top
commit can be retried
executed on top of
in the experiment shown
on top of mfs
ensures that the c
top of mfs configured
the experiment shown in
can be retried later
that the c xors
of mfs configured with
the c xors containing
mfs configured with either
c xors containing a
configured with either synchronous
experiment shown in figures
xors containing a data
with either synchronous writes
containing a data packet
a data packet do
d esign as a
data packet do not
esign as a proof
packet do not have
do not have any
update logging or asynchronous
not have any other
logging or asynchronous writeback
have any other data
any other data packet
other data packet in
data packet in common
the update logging mechanism
update logging mechanism was
logging mechanism was configured
the resulting protocol effectively
mechanism was configured to
resulting protocol effectively has
was configured to delay
protocol effectively has a
configured to delay flushing
effectively has a rate
to delay flushing an
has a rate of
delay flushing an update
we set k to
a tool for integrating
set k to the
tool for integrating subversion
k to the number
flushing an update for
to the number of
for integrating subversion with
an update for at
integrating subversion with s
update for at least
the number of partitions
for at least a
at least a second
every experiment was repeated
with each xor generated
experiment was repeated ten
while the amount of
was repeated ten times
the amount of acknowledged
vn is colocated with
each xor generated from
is colocated with subversion
amount of acknowledged data
colocated with subversion and
xor generated from r
with subversion and inserts
generated from r data
subversion and inserts a
from r data packets
and inserts a layer
r data packets and
inserts a layer between
of acknowledged data is
a layer between subversion
repeated ten times at
acknowledged data is reduced
ten times at each
data is reduced by
times at each of
layer between subversion and
at each of five
data packets and each
each of five possible
packets and each data
of five possible bandwidth
and each data packet
five possible bandwidth values
each data packet included
between subversion and s
data packet included in
packet included in c
included in c xors
shows the time taken
as shown in figure
the time taken for
time taken for each
illustrates layered interleaving for
taken for each workload
layered interleaving for a
for each workload at
and the overall throughput
each workload at a
the overall throughput is
workload at a bandwidth
overall throughput is actually
at a bandwidth of
for simplicity we did
throughput is actually lower
simplicity we did not
is actually lower because
we did not modify
actually lower because token
did not modify the
lower because token processing
not modify the subversion
because token processing becomes
modify the subversion server
token processing becomes more
the subversion server in
processing becomes more costly
subversion server in any
server in any way
the system becomes unstable
vn is responsible for
is responsible for receiving
responsible for receiving event
for receiving event notifications
notice the large variances
receiving event notifications from
the large variances in
event notifications from subversion
large variances in figure
shows overall results for
notifications from subversion and
overall results for selected
from subversion and transferring
results for selected configurations
subversion and transferring data
and transferring data between
transferring data between the
data between the local
between the local disk
the results in table
the local disk on
local disk on the
disk on the ec
demonstrate the benefit of
because our flow control
the benefit of priorities
our flow control scheme
benefit of priorities when
of priorities when there
priorities when there is
when there is high
there is high contention
based on limiting the
is high contention between
on limiting the amount
high contention between high
limiting the amount of
the amount of unacknowledged
amount of unacknowledged data
vn at the start
priority rpcs and writes
at the start and
the start and end
start and end of
and end of each
end of each commit
in both the i
while the sender can
the sender can cleanup
sender can cleanup any
can cleanup any portion
cleanup any portion of
any portion of the
portion of the message
of the message sequence
vn acquires and releases
bound gw and rw
standard fec schemes can
acquires and releases locks
fec schemes can be
and releases locks using
receivers have to deliver
schemes can be made
releases locks using yahoo
gw and rw workloads
locks using yahoo s
can be made resistant
using yahoo s open
have to deliver in
be made resistant to
to deliver in fifo
yahoo s open source
deliver in fifo order
adding priorities decreases the
s open source zookeeper
priorities decreases the time
open source zookeeper lock
decreases the time required
source zookeeper lock service
the time required for
the amount of data
time required for the
amount of data they
required for the foreground
of data they cache
made resistant to a
the difficulty achieving consistency
resistant to a certain
difficulty achieving consistency with
data they cache is
achieving consistency with a
they cache is larger
consistency with a service
to a certain loss
for the foreground workload
a certain loss burst
the foreground workload to
with a service such
certain loss burst length
a service such as
and this reduces their
foreground workload to execute
this reduces their ability
service such as amazon
reduces their ability to
such as amazon s
their ability to accept
as amazon s s
ability to accept incoming
loss burst length at
to accept incoming traffic
burst length at the
length at the cost
at the cost of
stems from the fact
the cost of increased
notice the linkage to
cost of increased recovery
the linkage to memory
from the fact that
of increased recovery latency
the fact that files
increased recovery latency for
fact that files pushed
recovery latency for all
that files pushed into
latency for all lost
files pushed into the
see elapsed times for
the growth in memory
elapsed times for rw
growth in memory occurs
pushed into the storage
in memory occurs on
for all lost packets
into the storage cloud
memory occurs on the
the storage cloud do
read with synchronous writes
storage cloud do not
with synchronous writes in
cloud do not simultaneously
including smaller bursts and
synchronous writes in the
smaller bursts and singleton
occurs on the receivers
bursts and singleton drops
writes in the table
do not simultaneously become
not simultaneously become available
simultaneously become available on
but the pattern is
become available on all
the pattern is similar
available on all service
pattern is similar to
on all service endpoints
is similar to what
similar to what we
this is particularly true
layered interleaving provides graceful
is particularly true in
to what we saw
particularly true in the
what we saw earlier
true in the rw
if a file is
interleaving provides graceful degradation
a file is overwritten
in the rw test
provides graceful degradation in
merely having more cached
graceful degradation in the
having more cached data
degradation in the face
different clients may read
more cached data is
clients may read back
where the foreground workload
in the face of
may read back different
cached data is enough
the foreground workload generates
the face of bursty
read back different versions
face of bursty loss
foreground workload generates heavy
of bursty loss for
workload generates heavy contention
data is enough to
generates heavy contention by
is enough to slow
and even the same
enough to slow them
bursty loss for constant
heavy contention by fetching
loss for constant encoding
to slow them down
for constant encoding overhead
contention by fetching a
constant encoding overhead singleton
by fetching a large
even the same client
encoding overhead singleton random
the same client may
overhead singleton random losses
fetching a large volume
singleton random losses are
a large volume of
random losses are recovered
large volume of data
losses are recovered as
token roundtrip time increases
are recovered as quickly
same client may see
recovered as quickly as
client may see the
as quickly as possible
the greatest benefits are
may see the old
greatest benefits are observable
see the old version
benefits are observable for
the old version if
are observable for the
old version if it
observable for the combination
version if it suddenly
for the combination of
if it suddenly switches
the combination of asynchronous
it suddenly switches to
combination of asynchronous writes
by xors generated with
of asynchronous writes with
suddenly switches to speaking
asynchronous writes with priorities
xors generated with an
this delays state aggregation
switches to speaking with
generated with an interleave
to speaking with a
with an interleave of
speaking with a different
since here the performance
with a different s
increases pending messages and
here the performance of
pending messages and reduces
the performance of the
messages and reduces throughput
performance of the background
of the background workload
the background workload can
and each successive layer
background workload can also
each successive layer of
the file will always
successive layer of xors
file will always be
workload can also improve
will always be internally
layer of xors generated
always be internally consistent
of xors generated at
can also improve by
xors generated at a
also improve by not
generated at a higher
improve by not having
at a higher interleave
by not having to
since put and get
not having to wait
put and get operations
having to wait for
and get operations are
a higher interleave catches
to wait for its
higher interleave catches larger
wait for its writes
get operations are atomic
for its writes to
interleave catches larger bursts
its writes to be
catches larger bursts missed
writes to be committed
larger bursts missed by
to be committed at
bursts missed by the
be committed at the
missed by the previous
committed at the server
by the previous layer
but its contents may
more aggressive cleanup with
its contents may not
aggressive cleanup with o
contents may not reflect
in the gc and
the implementation of this
may not reflect expectations
implementation of this algorithm
not reflect expectations that
of this algorithm is
the gc and rc
this algorithm is simple
gc and rc tests
reflect expectations that the
feedback in the token
algorithm is simple and
in the token and
expectations that the client
is simple and shown
that the client formed
simple and shown in
the client formed based
the token and in
client formed based on
token and in acks
formed based on other
and shown in figure
based on other files
where there is lighter
on other files and
there is lighter contention
other files and out
files and out of
and out of band
out of band communication
the impact of priorities
impact of priorities is
of priorities is negligible
a set of repair
set of repair bins
and in some cases
vn works around the
in some cases results
more work with o
some cases results in
works around the consistency
cases results in a
of repair bins is
around the consistency problem
repair bins is maintained
results in a slight
the consistency problem by
in a slight overhead
bins is maintained for
consistency problem by storing
is maintained for each
problem by storing the
maintained for each layer
by storing the number
but this is chiefly
storing the number of
this is chiefly after
the number of the
is chiefly after adding
number of the latest
and lower rates despite
of the latest revision
lower rates despite saving
the latest revision into
rates despite saving on
latest revision into zookeeper
despite saving on memory
with i bins for
chiefly after adding priorities
i bins for a
after adding priorities to
bins for a layer
adding priorities to rpcs
for a layer with
a layer with interleave
layer with interleave i
even if multiple files
if multiple files were
it is natural to
multiple files were changed
is natural to ask
files were changed by
natural to ask when
were changed by the
to ask when they
changed by the client
ask when they are
a repair bin consists
when they are beneficial
memory overheads on the
repair bin consists of
overheads on the receiver
bin consists of a
on the receiver the
consists of a partially
and to what degree
the receiver the reader
is represented by subversion
receiver the reader may
of a partially constructed
the reader may doubt
a partially constructed repair
reader may doubt that
in addition to comparing
partially constructed repair packet
addition to comparing mfs
may doubt that memory
to comparing mfs with
doubt that memory overhead
represented by subversion has
comparing mfs with and
that memory overhead on
an xor and the
memory overhead on receivers
mfs with and without
overhead on receivers is
with and without prioritised
on receivers is the
by subversion has a
and without prioritised rpcs
xor and the recipe
subversion has a single
receivers is the real
has a single file
is the real issue
a single file containing
and the recipe list
single file containing binary
we also investigate the
file containing binary diffs
the recipe list of
containing binary diffs against
considering that their cpus
recipe list of identifiers
that their cpus are
list of identifiers of
binary diffs against earlier
also investigate the performance
diffs against earlier revisions
their cpus are half
investigate the performance impact
of identifiers of data
the performance impact of
identifiers of data packets
performance impact of replacing
of data packets that
impact of replacing synchronous
data packets that compose
of replacing synchronous rpcs
packets that compose the
a revision is never
replacing synchronous rpcs for
revision is never changed
that compose the xor
synchronous rpcs for file
is never changed after
rpcs for file updates
never changed after the
for file updates with
changed after the fact
file updates with asynchronous
updates with asynchronous writeback
each intercepted data packet
intercepted data packet is
data packet is added
packet is added to
the performance of these
is added to each
performance of these alternatives
added to each layer
of these alternatives is
end server attempting to
these alternatives is compared
server attempting to fetch
alternatives is compared in
attempting to fetch a
is compared in a
to fetch a revision
compared in a set
fetch a revision i
in a set of
a revision i from
a set of microbenchmarks
revision i from s
can increasing memory consumption
to each layer where
increasing memory consumption affect
each layer where adding
memory consumption affect a
layer where adding to
and with workloads gathered
where adding to a
with workloads gathered from
adding to a layer
workloads gathered from windows
to a layer simply
gathered from windows nt
will receive either the
consumption affect a half
receive either the one
from windows nt file
a layer simply means
either the one true
layer simply means choosing
windows nt file system
simply means choosing a
nt file system traces
means choosing a repair
choosing a repair bin
a repair bin from
repair bin from the
bin from the layer
from the layer s
our experimental setup consists
the layer s set
experimental setup consists of
we performed an experiment
setup consists of two
performed an experiment with
or a missing file
a missing file error
incrementally updating the xor
missing file error if
ghz pentium iii desktop
file error if i
pentium iii desktop machines
error if i was
iii desktop machines running
if i was posted
updating the xor with
i was posted so
desktop machines running the
the xor with the
machines running the freebsd
xor with the new
was posted so recently
with the new data
posted so recently that
the new data packet
so recently that it
recently that it has
that it has not
in which we vary
and adding the data
which we vary the
adding the data packet
we vary the number
the data packet s
vary the number of
data packet s header
the number of receivers
packet s header to
number of receivers that
s header to the
of receivers that cache
header to the recipe
one of which acts
receivers that cache a
of which acts as
that cache a copy
which acts as an
cache a copy of
acts as an mfs
a copy of each
as an mfs server
copy of each message
to the recipe list
and the other as
replication factor in figure
the other as an
a counter is incremented
other as an mfs
counter is incremented as
as an mfs client
is incremented as each
incremented as each data
as each data packet
each data packet arrives
data packet arrives at
packet arrives at the
the client machine makes
arrives at the appliance
client machine makes use
machine makes use of
makes use of the
use of the dummynet
and choosing the repair
of the dummynet trafficshaping
increasing this value results
choosing the repair bin
this value results in
the dummynet trafficshaping module
value results in a
the repair bin from
results in a linear
dummynet trafficshaping module in
repair bin from the
in a linear increase
trafficshaping module in freebsd
a linear increase of
module in freebsd to
linear increase of memory
in freebsd to limit
increase of memory usage
bin from the layer
freebsd to limit its
of memory usage on
to limit its incoming
from the layer s
limit its incoming and
memory usage on receivers
its incoming and outgoing
the layer s set
incoming and outgoing bandwidth
layer s set is
s set is done
set is done by
if memory overheads were
is done by taking
memory overheads were not
done by taking the
overheads were not a
by taking the modulo
the experiments we conduct
taking the modulo of
were not a significant
the modulo of the
not a significant issue
modulo of the counter
a significant issue on
experiments we conduct in
significant issue on half
of the counter with
we conduct in this
the counter with the
conduct in this section
counter with the number
in this section have
with the number of
this section have a
the number of bins
we would expect performance
number of bins in
would expect performance to
of bins in each
section have a constant
expect performance to remain
have a constant bandwidth
bins in each layer
a constant bandwidth over
performance to remain unchanged
constant bandwidth over the
bandwidth over the duration
over the duration of
the duration of the
for a layer with
duration of the experiment
a layer with interleave
we see a dramatic
but we analyse the
we analyse the performance
analyse the performance of
the performance of mfs
performance of mfs when
of mfs when the
linear increase of the
the xth intercepted packet
increase of the token
xth intercepted packet is
of the token roundtrip
intercepted packet is added
the token roundtrip time
packet is added to
mfs when the bandwidth
is added to the
when the bandwidth varies
the bandwidth varies over
bandwidth varies over the
a slow increase of
varies over the course
slow increase of the
over the course of
increase of the number
the course of an
of the number of
course of an experiment
the number of messages
of an experiment in
number of messages pending
an experiment in section
of messages pending ack
messages pending ack on
pending ack on the
ack on the sender
and a sharp decrease
when a repair bin
a sharp decrease in
a repair bin fills
sharp decrease in throughput
repair bin fills up
bin fills up its
fills up its recipe
up its recipe list
its recipe list contains
end servers are equivalent
recipe list contains r
servers are equivalent and
list contains r data
are equivalent and clients
contains r data packets
equivalent and clients may
r data packets it
and clients may interact
data packets it fires
clients may interact with
may interact with any
interact with any of
with any of them
any of them fig
microbenchmarks the first set
a repair packet is
the first set of
repair packet is generated
first set of experiments
packet is generated consisting
set of experiments compares
is generated consisting of
the underlying mechanism is
generated consisting of the
underlying mechanism is as
of experiments compares different
consisting of the xor
experiments compares different mfs
of the xor and
mechanism is as follows
the xor and the
compares different mfs configurations
xor and the recipe
e valuation we observe
and the recipe list
valuation we observe that
the recipe list and
we observe that running
the increased activity of
different mfs configurations for
recipe list and is
mfs configurations for specific
list and is scheduled
configurations for specific types
and is scheduled for
for specific types of
is scheduled for sending
specific types of contention
increased activity of the
observe that running multiple
activity of the garbage
that running multiple front
of the garbage collector
four workloads were used
while the repair bin
the garbage collector and
the repair bin is
repair bin is re
garbage collector and allocation
collector and allocation overheads
and allocation overheads slow
which cloud computing makes
allocation overheads slow the
cloud computing makes easy
initialized with an empty
computing makes easy to
executes the grep utility
makes easy to do
with an empty recipe
overheads slow the system
an empty recipe list
the grep utility several
slow the system down
grep utility several times
increases the throughput of
the system down and
empty recipe list and
system down and processing
recipe list and blank
utility several times on
list and blank xor
several times on each
the throughput of read
down and processing of
times on each of
and processing of the
throughput of read operations
processing of the incoming
of the incoming packets
the incoming packets and
incoming packets and tokens
packets and tokens takes
and tokens takes more
tokens takes more time
incoming repair packets are
vn by running a
repair packets are processed
by running a fixed
packets are processed as
running a fixed number
are processed as follows
a fixed number of
although the effect is
fixed number of clients
the effect is not
effect is not significant
is not significant when
if all the data
not significant when considering
all the data packets
the files are present
each repeatedly checking out
significant when considering a
repeatedly checking out about
when considering a single
the data packets contained
files are present in
data packets contained in
are present in the
considering a single node
packets contained in the
a single node in
present in the cache
contained in the repair
single node in isolation
in the repair s
the repair s recipe
repair s recipe list
but must be validated
s recipe list have
must be validated before
a token must visit
be validated before they
recipe list have been
token must visit all
list have been received
validated before they are
have been received successfully
before they are used
must visit all nodes
visit all nodes in
all nodes in a
nodes in a region
the repair packet is
in a region to
repair packet is discarded
a region to aggregate
region to aggregate the
to aggregate the recovery
aggregate the recovery state
if the repair s
the repair s recipe
repair s recipe list
s recipe list contains
and delays are cumulative
recipe list contains a
list contains a single
contains a single missing
a single missing data
single missing data packet
mb files in sequence
qsm is configured so
recovery can occur immediately
is configured so that
can occur immediately by
configured so that five
so that five nodes
writing the contents of
that five nodes in
the contents of each
five nodes in each
contents of each file
nodes in each region
of each file to
in each region cache
each region cache each
yet propagated through s
region cache each packet
if half the nodes
half the nodes in
the nodes in a
in the latter case
the files are not
files are not initially
are not initially present
not initially present in
the server retries indefinitely
initially present in the
server retries indefinitely until
present in the cache
retries indefinitely until the
indefinitely until the file
until the file is
the file is available
node region cache each
region cache each figure
zookeeper ensures that the
ensures that the latest
that the latest revision
the latest revision number
latest revision number is
revision number is incremented
number is incremented atomically
zookeeper maintains a simple
maintains a simple filesystem
a simple filesystem like
simple filesystem like tree
filesystem like tree of
like tree of nodes
mb files from the
files from the local
from the local file
the local file system
local file system into
nodes may store a
file system into the
may store a small
system into the mfs
store a small amount
into the mfs file
a small amount of
the mfs file system
small amount of data
amount of data and
of data and can
data and can have
and can have children
varying the number of
the number of caching
number of caching replicas
of caching replicas per
caching replicas per message
vn stores the latest
replicas per message in
stores the latest revision
per message in a
the latest revision number
latest revision number in
as the replication factor
the replication factor increasess
the sender s flow
sender s flow control
s flow control policy
flow control policy kicks
supporting multiple named repositories
control policy kicks in
multiple named repositories in
named repositories in a
repositories in a single
in a single zookeeper
a single zookeeper tree
and the system goes
the system goes into
before pushing a new
pushing a new revision
a form of the
form of the oscillating
end server must acquire
of the oscillating state
server must acquire a
the oscillating state we
must acquire a lock
oscillating state we encountered
acquire a lock by
state we encountered in
a lock by creating
we encountered in figure
lock by creating a
by creating a sequence
creating a sequence node
layer with interleave of
the amount of memory
amount of memory in
of memory in use
memory in use at
in use at the
use at the sender
at the sender ceases
the sender ceases to
sender ceases to be
ceases to be a
to be a good
be a good predictor
a good predictor of
good predictor of the
predictor of the amount
of the amount of
the amount of memory
amount of memory in
of memory in use
memory in use at
in use at receivers
to which zookeeper will
which zookeeper will append
zookeeper will append a
will append a unique
violating what turns out
what turns out to
turns out to be
out to be an
monotonically increasing sequence number
to be an implicit
be an implicit requirement
an implicit requirement of
implicit requirement of our
requirement of our flow
end server then lists
server then lists the
then lists the children
lists the children of
overheads in a perturbed
in a perturbed system
a perturbed system the
perturbed system the reader
system the reader might
the reader might wonder
reader might wonder whether
might wonder whether our
wonder whether our results
whether our results would
if its own lock
our results would be
its own lock node
results would be different
own lock node has
would be different if
lock node has the
be different if the
node has the lowest
different if the system
has the lowest number
if the system experienced
the system experienced high
system experienced high loss
experienced high loss rates
high loss rates or
it may proceed with
loss rates or was
may proceed with the
rates or was otherwise
proceed with the commit
or was otherwise perturbed
otherwise it watches the
it watches the node
watches the node with
the node with the
we performed an experiment
node with the next
performed an experiment in
with the next lower
an experiment in which
the next lower number
experiment in which one
next lower number in
in which one of
lower number in order
which one of the
number in order to
one of the receiver
in order to be
of the receiver nodes
order to be notified
the receiver nodes experiences
to be notified when
receiver nodes experiences a
be notified when that
nodes experiences a periodic
notified when that node
when that node and
that node and its
node and its associated
and its associated lock
its associated lock go
associated lock go away
after comitting the revision
comitting the revision to
s the node sleeps
the revision to s
the node sleeps for
this simulates the effect
simulates the effect of
the effect of disruptive
in the loss scenario
it releases its lock
releases its lock by
its lock by deleting
lock by deleting the
by deleting the lock
deleting the lock node
s the node drops
combining the xor in
the node drops all
the xor in the
node drops all incoming
xor in the repair
drops all incoming packets
in the repair with
lock nodes are marked
all incoming packets for
the repair with the
nodes are marked with
repair with the other
are marked with zookeeper
with the other successfully
marked with zookeeper s
the other successfully received
with zookeeper s ephemeral
other successfully received data
zookeeper s ephemeral flag
successfully received data packets
s ephemeral flag to
ephemeral flag to ensure
flag to ensure that
to ensure that the
ensure that the lock
if the repair contains
that the lock is
the repair contains multiple
the lock is forcibly
repair contains multiple missing
lock is forcibly released
contains multiple missing data
is forcibly released if
multiple missing data packets
forcibly released if the
released if the front
it cannot be used
cannot be used immediately
the loss rate is
be used immediately for
zookeeper runs as a
loss rate is higher
runs as a replicated
used immediately for recovery
as a replicated service
immediately for recovery it
for recovery it is
recovery it is instead
it is instead stored
so it remains available
is instead stored in
it remains available as
instead stored in a
remains available as long
stored in a table
available as long as
in a table that
as long as a
a table that maps
long as a majority
table that maps missing
as a majority of
that maps missing data
a majority of the
maps missing data packets
majority of the hosts
missing data packets to
of the hosts are
data packets to repair
the hosts are up
packets to repair packets
hosts are up and
are up and reachable
because recovery traffic interferes
whenever a data packet
a client only speaks
a data packet is
recovery traffic interferes with
data packet is subsequently
client only speaks to
packet is subsequently received
traffic interferes with regular
is subsequently received or
interferes with regular multicast
only speaks to one
subsequently received or recovered
speaks to one zookeeper
to one zookeeper server
one zookeeper server at
zookeeper server at a
server at a time
this table is checked
table is checked to
though it may fail
is checked to see
cpu utilization at the
checked to see if
utilization at the receivers
gc test rw test
at the receivers is
to see if any
the receivers is in
over to another server
see if any xors
receivers is in the
to another server if
if any xors now
another server if necessary
any xors now have
xors now have singleton
now have singleton losses
have singleton losses due
singleton losses due to
losses due to the
due to the presence
but the server ensures
to the presence of
the server ensures that
the presence of the
server ensures that the
presence of the new
ensures that the relevant
of the new packet
that the relevant state
the new packet and
the relevant state has
new packet and can
relevant state has been
packet and can be
state has been replicated
and can be used
has been replicated before
range and doesn t
can be used for
and doesn t grow
been replicated before responding
doesn t grow with
be used for recovering
replicated before responding to
used for recovering other
before responding to a
for recovering other missing
responding to a client
t grow with system
recovering other missing packets
grow with system size
to a client s
a client s request
in general multiple front
xors received from different
received from different layers
end servers may be
from different layers interact
servers may be run
different layers interact to
layers interact to recover
interact to recover missing
to recover missing data
recover missing data packets
each on its own
on its own ec
in the sleep scenario
since an xor received
an xor received at
xor received at a
the system is organized
received at a higher
system is organized as
the decrease starts at
is organized as in
at a higher interleave
organized as in figure
decrease starts at about
a higher interleave can
higher interleave can recover
interleave can recover a
can recover a packet
recover a packet that
a packet that makes
packet that makes an
unlike the traditional replicated
that makes an earlier
the traditional replicated subversion
makes an earlier xor
traditional replicated subversion setups
an earlier xor at
replicated subversion setups that
earlier xor at a
subversion setups that are
xor at a lower
setups that are used
at a lower interleave
that are used today
nodes and proceeds steadily
a lower interleave usable
and proceeds steadily thereafter
lower interleave usable hence
no single server acts
single server acts as
server acts as a
it doesn t appear
acts as a master
though layered interleaving is
doesn t appear to
layered interleaving is equivalent
t appear to be
interleaving is equivalent to
appear to be correlated
is equivalent to c
to be correlated to
equivalent to c different
be correlated to the
correlated to the amount
to the amount of
vn all are equivalent
the amount of loss
performance of simultaneous checkouts
which oscillates at the
oscillates at the level
at the level of
instances in terms of
in terms of overhead
gw test rc test
terms of overhead and
of overhead and design
its recovery power is
recovery power is much
power is much higher
is much higher and
much higher and comes
higher and comes close
and comes close to
comes close to standard
in the controlled loss
the controlled loss scenario
throughput remains fairly constant
optimizations staggered start for
staggered start for rate
until it falls sharply
performance of simultaneous commits
it falls sharply beyond
limiting in the naive
of simultaneous commits source
in the naive implementation
simultaneous commits source code
the naive implementation of
commits source code from
naive implementation of the
source code from an
implementation of the layered
code from an ec
of the layered interleaving
the layered interleaving algorithm
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
as soon as repair
soon as repair bins
as repair bins fill
performance does not appear
repair bins fill and
does not appear to
bins fill and allow
not appear to be
fill and allow them
appear to be directly
and allow them to
to be directly correlated
allow them to be
and varying the number
be directly correlated to
varying the number of
directly correlated to the
the number of servers
correlated to the observed
number of servers over
to the observed packet
of servers over which
the observed packet loss
servers over which the
them to be constructed
over which the load
which the load was
relative speedup relative speedup
the load was distributed
speedup relative speedup relative
relative speedup relative speedup
throughput is uncorrelated with
is uncorrelated with memory
uncorrelated with memory use
all the repair bins
with memory use both
the repair bins in
memory use both on
repair bins in a
use both on the
bins in a layer
both on the perturbed
in a layer fill
on the perturbed receiver
a layer fill in
write performance was measured
layer fill in quick
performance was measured by
fill in quick succession
was measured by observing
measured by observing the
by observing the latency
observing the latency of
the latency of simultaneous
latency of simultaneous commits
of simultaneous commits from
simultaneous commits from different
commits from different clients
the arrival of packets
uniform priorities async relative
since simultaneous commits to
priorities async relative speedup
simultaneous commits to a
async relative speedup gc
commits to a single
relative speedup gc test
to a single repository
a single repository would
single repository would not
repository would not be
would not be a
not be a typical
be a typical case
at scales of up
scales of up to
memory usage actually decreases
a consequence of the
consequence of the cooperative
vn repositories were used
of the cooperative caching
the cooperative caching policy
cooperative caching policy described
caching policy described in
policy described in section
all sharing the same
will successively fill the
sharing the same set
successively fill the four
the same set of
fill the four repair
same set of front
the four repair bins
four repair bins in
repair bins in layer
the shape of the
end servers and same
shape of the performance
servers and same set
of the performance curve
and same set of
the performance curve does
same set of three
set of three zookeeper
of three zookeeper servers
this behavior leads to
behavior leads to a
leads to a large
each client checked out
to a large number
client checked out a
correlate closely with the
checked out a random
a large number of
out a random repository
closely with the number
a random repository from
with the number of
random repository from a
the number of unacknowledged
repository from a random
number of unacknowledged requests
large number of repair
from a random front
number of repair packets
of repair packets being
repair packets being generated
packets being generated and
being generated and sent
generated and sent within
and sent within a
sent within a short
and then repeatedly committed
within a short period
then repeatedly committed small
a short period of
repeatedly committed small amounts
short period of time
committed small amounts of
small amounts of data
we conclude that the
which results in undesirable
changes were propgated in
results in undesirable overhead
conclude that the drop
in undesirable overhead and
were propgated in the
undesirable overhead and traffic
that the drop in
overhead and traffic spikes
propgated in the background
the drop in performance
in the background to
drop in performance in
the background to the
in performance in these
background to the other
performance in these scenarios
to the other front
in these scenarios can
these scenarios can t
we would like to
scenarios can t be
would like to rate
can t be explained
t be explained by
be explained by correlation
explained by correlation with
by correlation with cpu
correlation with cpu activity
limit transmissions of repair
transmissions of repair packets
of repair packets to
repair packets to one
packets to one for
to one for every
one for every r
for every r data
every r data packets
or loss rates at
shows that adding front
loss rates at the
rates at the receivers
this problem is fixed
problem is fixed by
is fixed by staggering
end servers can indeed
fixed by staggering the
servers can indeed alleviate
but that it does
can indeed alleviate latency
by staggering the starting
indeed alleviate latency problems
staggering the starting sizes
alleviate latency problems caused
the starting sizes of
latency problems caused by
starting sizes of the
problems caused by high
sizes of the bins
caused by high load
that it does appear
it does appear correlated
does appear correlated to
appear correlated to slower
correlated to slower cleanup
and that the overhead
to slower cleanup and
that the overhead of
analogous to the starting
slower cleanup and the
to the starting positions
cleanup and the resulting
the starting positions of
and the resulting memory
the overhead of propagating
starting positions of runners
overhead of propagating data
positions of runners in
of propagating data in
of runners in a
related overheads at the
runners in a sprint
overheads at the sender
propagating data in the
data in the backgound
in the backgound is
the backgound is not
the very first time
the effect is much
backgound is not significant
very first time bin
is not significant enough
first time bin number
not significant enough to
effect is much stronger
significant enough to negatively
time bin number x
enough to negatively affect
is much stronger than
to negatively affect performance
bin number x in
much stronger than in
number x in a
stronger than in the
x in a layer
than in the undisturbed
in a layer of
in the undisturbed experiments
a layer of interleave
layer of interleave i
of interleave i fires
the number of pending
r elated w orks
number of pending messages
elated w orks moving
of pending messages starts
it does so at
pending messages starts at
does so at size
messages starts at a
so at size x
starts at a higher
at size x mod
at a higher level
w orks moving services
size x mod r
orks moving services to
moving services to the
services to the cloud
to the cloud has
the cloud has been
cloud has been published
has been published on
been published on in
published on in other
on in other contexts
relative speedup relative speedup
speedup relative speedup relative
relative speedup relative speedup
the first repair bin
token roundtrip time increases
first repair bin in
repair bin in the
bin in the second
in the second layer
the second layer with
second layer with interleave
is a backup application
a backup application that
backup application that implements
application that implements a
would fire at size
that implements a custom
and if a failure
implements a custom block
if a failure occurs
based file system to
file system to store
system to store multiple
the second would fire
to store multiple versions
second would fire at
store multiple versions of
would fire at size
token rounds before repair
multiple versions of backup
rounds before repair occurs
versions of backup data
of backup data on
backup data on s
and then another round
then another round before
another round before cleanup
round before cleanup takes
before cleanup takes place
the authors make the
authors make the distinction
make the distinction between
the distinction between thin
clouds that provide a
that provide a low
level api and thick
clouds that are designed
that are designed for
are designed for a
designed for a specific
for a specific application
thick clouds for a
clouds for a variety
for a variety of
a variety of purposes
these account for the
including backup and source
account for the rapid
backup and source code
for the rapid increase
and source code repository
the rapid increase in
source code repository hosting
rapid increase in acknowledgement
increase in acknowledgement latency
with sourceforge and google
sourceforge and google code
and google code being
google code being examples
code being examples of
being examples of the
examples of the latter
as the number of
the authors of cumulus
the number of caching
authors of cumulus and
number of caching replicas
of cumulus and we
of caching replicas increases
cumulus and we show
and we show that
we show that thin
cloud solutions can be
solutions can be a
can be a cost
another example of moving
example of moving a
of moving a service
moving a service to
throughput in the experiments
a service to the
in the experiments with
service to the cloud
the experiments with a
to the cloud is
experiments with a perturbed
the cloud is metacdn
with a perturbed node
a content distribution network
the work evaluates the
work evaluates the latency
evaluates the latency of
the latency of various
latency of various cloud
of various cloud storage
various cloud storage services
cloud storage services from
storage services from several
services from several locations
from several locations and
several locations and provides
average packet loss observed
locations and provides an
packet loss observed at
and provides an abstraction
loss observed at the
provides an abstraction to
observed at the perturbed
an abstraction to integrate
at the perturbed node
abstraction to integrate the
to integrate the different
integrate the different offerings
the different offerings into
different offerings into a
offerings into a single
into a single system
memory usage at the
usage at the perturbed
at the perturbed node
at unperturbed nodes it
unperturbed nodes it is
nodes it is similar
like transactional data store
transactional data store backed
data store backed by
store backed by s
and faced similar issues
faced similar issues as
similar issues as s
vn due to its
due to its need
to its need for
although it would be
its need for high
it would be hard
need for high consistency
would be hard to
be hard to precisely
hard to precisely measure
to precisely measure these
elastras assigns update priviledges
precisely measure these delays
assigns update priviledges for
update priviledges for different
priviledges for different areas
for different areas of
different areas of the
measuring alarm delays sheds
areas of the data
alarm delays sheds light
of the data store
delays sheds light on
the data store to
sheds light on the
data store to individual
light on the magnitude
store to individual front
on the magnitude of
the magnitude of the
magnitude of the problem
recall that our timesharing
that our timesharing policy
using the lock service
our timesharing policy assigns
the lock service to
timesharing policy assigns quanta
lock service to elect
policy assigns quanta to
service to elect an
assigns quanta to different
to elect an owner
quanta to different types
elect an owner for
to different types of
an owner for each
different types of events
owner for each partition
high volumes of i
much in the style
in the style described
the style described by
style described by google
described by google s
by google s chubby
such as caused by
as caused by the
caused by the increased
by the increased forwarding
the increased forwarding traffic
will cause qsm to
cause qsm to use
qsm to use a
to use a larger
use a larger fraction
a larger fraction of
larger fraction of its
fraction of its i
a lock service based
lock service based on
service based on paxos
o quantum to process
performance of prioritised rpc
quantum to process i
of prioritised rpc with
prioritised rpc with respect
rpc with respect to
with respect to bandwidth
respect to bandwidth variation
with the consequence that
each pair of graphs
the consequence that timers
pair of graphs in
consequence that timers will
of graphs in shows
that timers will fire
defers finegrained locking to
graphs in shows the
timers will fire late
in shows the speedup
finegrained locking to the
shows the speedup of
locking to the application
the speedup of one
to the application in
speedup of one of
the application in order
of one of three
this effect is magnified
one of three cache
application in order not
of three cache manager
effect is magnified each
three cache manager configurations
is magnified each time
in order not to
magnified each time qsm
order not to burden
second set of rsized
relative to the time
each time qsm is
to the time taken
set of rsized xors
the time taken by
of rsized xors staggered
time taken by uniform
rsized xors staggered start
taken by uniform priorities
xors staggered start xors
not to burden the
time qsm is preempted
to burden the global
by uniform priorities with
burden the global lock
qsm is preempted by
the global lock service
uniform priorities with synchronous
is preempted by other
priorities with synchronous rpcs
global lock service with
with synchronous rpcs at
preempted by other processes
lock service with high
by other processes or
service with high traffic
other processes or by
processes or by its
or by its own
by its own garbage
its own garbage collector
vn we opted to
such delays are typically
we opted to use
delays are typically shorter
opted to use the
are typically shorter than
to use the lock
typically shorter than the
use the lock service
shorter than the i
as well as uniform
well as uniform priorities
as uniform priorities and
uniform priorities and synchronous
priorities and synchronous rpcs
yet longer than the
longer than the alarm
than the alarm quantum
grained locking instead of
locking instead of just
instead of just leader
of just leader election
thus causing the alarm
the graphs also show
graphs also show curves
also show curves for
but not the i
show curves for differentiated
since the latter would
curves for differentiated priorities
the latter would have
for differentiated priorities and
latter would have required
differentiated priorities and synchronous
would have required duplicating
priorities and synchronous rpcs
have required duplicating much
required duplicating much of
duplicating much of zookeeper
much of zookeeper s
of zookeeper s functionality
the maximum alarm firing
zookeeper s functionality to
maximum alarm firing delays
s functionality to replicate
alarm firing delays taken
functionality to replicate the
firing delays taken from
to replicate the leader
delays taken from samples
replicate the leader s
taken from samples in
the leader s state
and differentiated priorities and
differentiated priorities and asynchronous
priorities and asynchronous rpcs
s intervals are indeed
scalability is not an
intervals are indeed much
is not an obstacle
are indeed much larger
not an obstacle because
indeed much larger in
an obstacle because there
much larger in the
obstacle because there is
larger in the perturbed
because there is no
the values plotted for
there is no need
values plotted for bandwidth
is no need for
plotted for bandwidth of
no need for global
in the perturbed experiments
need for global locking
for global locking across
global locking across multiple
locking across multiple repositories
both on the sender
on the sender and
the sender and on
sender and on the
and on the receiver
the load can be
on the receiver side
load can be partitioned
can be partitioned across
be partitioned across as
partitioned across as many
across as many zookeeper
as many zookeeper instances
many zookeeper instances as
zookeeper instances as necessary
s are the same
are the same as
the same as shown
same as shown in
replication is not without
as shown in table
is not without its
not without its dangers
due to the overhead
to the overhead of
the overhead of priorities
overhead of priorities for
of priorities for small
large delays are also
priorities for small rpcs
delays are also more
for small rpcs mentioned
are also more frequent
small rpcs mentioned in
and it has been
rpcs mentioned in section
it has been shown
has been shown that
been shown that replicating
shown that replicating too
that replicating too eagerly
replicating too eagerly leads
too eagerly leads quickly
eagerly leads quickly to
leads quickly to degraded
quickly to degraded performance
the maximum delay measured
maximum delay measured on
delay measured on receivers
measured on receivers in
the solution proposed is
on receivers in the
solution proposed is to
comparing the execution time
proposed is to use
receivers in the perturbed
is to use master
the execution time of
in the perturbed runs
execution time of the
the perturbed runs is
to use master copy
time of the foreground
use master copy replication
of the foreground workloads
the foreground workloads with
foreground workloads with synchronous
workloads with synchronous writes
where a transaction does
a transaction does not
transaction does not immediately
does not immediately update
update logging and asynchronous
not immediately update all
logging and asynchronous writeback
immediately update all replicas
and asynchronous writeback reveals
asynchronous writeback reveals that
writeback reveals that the
reveals that the latter
that the latter two
the latter two options
latter two options generally
two options generally perform
options generally perform comparably
generally perform comparably to
as the master copy
perform comparably to or
comparably to or better
to or better than
or better than synchronous
better than synchronous writes
and only the lock
only the lock service
logging and asynchronous writeback
which deals with simple
and asynchronous writeback greatly
asynchronous writeback greatly improve
writeback greatly improve the
greatly improve the performance
improve the performance of
ms in the unperturbed
the performance of the
in the unperturbed experiments
performance of the background
of the background workloads
bandwidth operations that may
operations that may be
that may be concentrated
may be concentrated on
be concentrated on a
as has been noted
concentrated on a small
has been noted previously
on a small number
the value grows from
a small number of
small number of servers
must be eagerly replicated
also relevant is sundr
the secure untrusted data
secure untrusted data repository
we focus on mfs
focus on mfs with
on mfs with asynchronous
the problem could be
mfs with asynchronous writeback
problem could be alleviated
with asynchronous writeback in
could be alleviated by
asynchronous writeback in the
be alleviated by making
writeback in the rest
alleviated by making our
this file system allows
by making our priority
in the rest of
file system allows clients
making our priority scheduling
the rest of this
our priority scheduling more
system allows clients to
priority scheduling more fine
rest of this paper
allows clients to detect
of this paper because
clients to detect against
this paper because it
to detect against malicious
paper because it provides
detect against malicious or
because it provides comparable
against malicious or compromised
it provides comparable performance
malicious or compromised storage
provides comparable performance to
or compromised storage servers
comparable performance to logged
compromised storage servers or
performance to logged updates
storage servers or hosting
servers or hosting platforms
varying priorities for control
or hosting platforms by
priorities for control packets
hosting platforms by providing
platforms by providing fork
by providing fork consistency
allows straightforward modeless adaptation
or by assigning priorities
straightforward modeless adaptation to
by assigning priorities to
modeless adaptation to bandwidth
assigning priorities to feeds
adaptation to bandwidth variation
a property which ensures
priorities to feeds in
property which ensures that
to feeds in the
which ensures that clients
feeds in the sending
and is easily extensible
ensures that clients can
is easily extensible to
in the sending stack
easily extensible to more
that clients can detect
extensible to more than
clients can detect integrity
to more than one
can detect integrity failures
more than one level
detect integrity failures as
than one level of
integrity failures as long
one level of priority
failures as long as
as long as they
long as they see
as they see each
they see each other
which is required for
see each other s
is required for our
each other s file
number of messages awaiting
other s file modifications
required for our cache
of messages awaiting acknowledgement
for our cache consistency
messages awaiting acknowledgement in
our cache consistency algorithm
awaiting acknowledgement in experiments
acknowledgement in experiments with
similar techniques could be
in experiments with perturbances
techniques could be used
could be used to
since reducing available bandwidth
be used to recover
reducing available bandwidth increases
used to recover data
available bandwidth increases the
to recover data from
bandwidth increases the contention
recover data from client
increases the contention between
data from client working
the contention between rpcs
from client working copies
contention between rpcs of
client working copies in
between rpcs of different
working copies in the
rpcs of different types
copies in the event
in the event of
the event of a
token roundtrip time and
event of a catastrophic
roundtrip time and the
of a catastrophic cloud
time and the time
the benefits of rpc
and the time to
benefits of rpc priorities
the time to recover
a catastrophic cloud failure
time to recover in
of rpc priorities should
to recover in the
rpc priorities should be
priorities should be more
should be more apparent
be more apparent at
once code repositories are
more apparent at lower
code repositories are stored
apparent at lower priorities
repositories are stored in
are stored in the
stored in the cloud
one might imagine enabling
might imagine enabling mashups
shows the experiments of
imagine enabling mashups in
the experiments of table
enabling mashups in ways
mashups in ways not
in ways not previously
ways not previously possible
token roundtrip time and
extended to a wider
roundtrip time and the
to a wider range
time and the time
a wider range of
and the time to
wider range of bandwidth
the time to recover
range of bandwidth values
time to recover in
web based code viewers
to recover in the
in these and later
these and later experiments
and cross reference viewers
cross reference viewers might
we evaluate mfs performance
reference viewers might be
evaluate mfs performance with
viewers might be built
mfs performance with bandwidths
might be built by
it is worth noting
be built by third
performance with bandwidths from
is worth noting that
worth noting that the
noting that the doubled
that the doubled token
the doubled token roundtrip
doubled token roundtrip time
pulling data from the
data from the repositories
from the repositories of
as compared to unperturbed
the repositories of several
compared to unperturbed experiments
repositories of several distinct
of several distinct communities
can t be accounted
t be accounted for
be accounted for by
accounted for by the
for by the increase
by the increase in
the increase in memory
increase in memory overhead
in memory overhead or
memory overhead or cpu
overhead or cpu activity
or cpu activity on
cpu activity on the
activity on the receivers
seeks to enable such
to enable such applications
enable such applications by
as was the case
such applications by granting
was the case in
applications by granting direct
the case in experiments
by granting direct access
case in experiments where
granting direct access of
in experiments where we
direct access of cloud
experiments where we varied
access of cloud storage
where we varied the
s is not low
we varied the replication
of cloud storage to
varied the replication factor
is not low in
cloud storage to third
not low in the
storage to third parties
low in the sense
in the sense of
the sense of prior
the problem can be
sense of prior work
problem can be traced
subject to the data
can be traced to
to the data owner
be traced to a
the data owner s
traced to a priority
it is low enough
to a priority inversion
data owner s security
is low enough to
owner s security requirements
low enough to cause
enough to cause significant
to cause significant contention
because of repeated losses
cause significant contention for
a question that may
significant contention for the
question that may naturally
contention for the workloads
that may naturally arise
for the workloads we
the system maintains a
may naturally arise is
system maintains a high
the workloads we have
maintains a high volume
workloads we have considered
a high volume of
high volume of forwarding
volume of forwarding traffic
why not use a
not use a general
and we believe that
use a general purpose
we believe that our
a general purpose file
the forwarded messages tend
general purpose file system
forwarded messages tend to
purpose file system interface
believe that our results
file system interface to
messages tend to get
system interface to s
that our results will
tend to get ahead
our results will hold
to get ahead of
get ahead of the
results will hold if
ahead of the token
will hold if available
hold if available bandwidth
if available bandwidth and
available bandwidth and grep
bandwidth and grep write
both on the send
on the send path
and store a repository
where in the sinks
store a repository on
a repository on that
we use a simple
use a simple round
this is indeed possible
is indeed possible to
indeed possible to do
robin policy of multiplexing
policy of multiplexing between
of multiplexing between data
multiplexing between data feeds
but would entail pushing
would entail pushing temporary
entail pushing temporary files
afs mfs afs mfs
pushing temporary files such
mfs afs mfs elapsed
temporary files such as
afs mfs elapsed time
files such as transactions
and on the receive
on the receive path
where forwarded packets are
forwarded packets are treated
packets are treated as
and incurring additional monetary
are treated as control
incurring additional monetary costs
treated as control traffic
additional monetary costs due
monetary costs due to
costs due to the
due to the increased
to the increased number
and while they re
the increased number of
while they re prioritized
increased number of s
they re prioritized over
re prioritized over data
they are treated as
are treated as equally
treated as equally important
as equally important as
there would also likely
equally important as tokens
would also likely be
also likely be performance
likely be performance problems
they also increase the
also increase the overall
increase the overall volume
since file append and
the overall volume of
file append and rename
overall volume of i
append and rename operations
and rename operations do
rename operations do not
operations do not map
do not map efficiently
o that the nodes
not map efficiently to
that the nodes process
map efficiently to s
tokens are processed with
are processed with higher
processed with higher latency
fs that is aware
that is aware of
is aware of subversion
aware of subversion s
of subversion s file
subversion s file naming
s file naming and
file naming and use
naming and use scenario
and use scenario could
use scenario could of
scenario could of course
could of course overcome
of course overcome these
course overcome these limitations
overcome these limitations by
these limitations by pushing
limitations by pushing only
by pushing only what
pushing only what is
histogram of maximum alarm
only what is actually
of maximum alarm delays
what is actually required
maximum alarm delays in
is actually required into
actually required into s
but we believe that
we believe that such
believe that such specialized
that such specialized tools
such specialized tools are
specialized tools are better
tools are better built
are better built on
better built on top
built on top of
on top of a
top of a file
histogram of maximum alarm
of a file system
of maximum alarm delays
a file system abstraction
maximum alarm delays in
file system abstraction than
system abstraction than pushed
abstraction than pushed underneath
than pushed underneath it
c onclusion we have
onclusion we have shown
we have shown that
have shown that the
shown that the cost
that the cost of
the cost of using
cost of using a
of using a cloud
using a cloud computing
a cloud computing storage
overheads in a lightly
cloud computing storage service
computing storage service for
storage service for source
service for source code
for source code repository
loaded system so far
source code repository hosting
system so far the
code repository hosting is
so far the evaluation
repository hosting is low
far the evaluation has
the evaluation has focused
evaluation has focused on
has focused on scenarios
both for individual projects
focused on scenarios where
for individual projects and
on scenarios where the
individual projects and moderately
scenarios where the system
projects and moderately sized
where the system was
and moderately sized communities
the system was heavily
system was heavily loaded
considering the costs of
the costs of a
costs of a resilient
with unbounded multicast rates
of a resilient local
unbounded multicast rates and
a resilient local storage
multicast rates and occasional
resilient local storage system
rates and occasional perturbations
local storage system of
storage system of scsi
system of scsi disks
of scsi disks and
scsi disks and tape
disks and tape backup
comparison of mfs and
we traced degraded performance
of mfs and afs
traced degraded performance or
mfs and afs performance
degraded performance or scheduling
cloud computing is a
performance or scheduling delays
computing is a very
or scheduling delays to
is a very attractive
scheduling delays to memory
a very attractive solution
mfs with synchronous rpcs
very attractive solution for
with synchronous rpcs and
attractive solution for this
synchronous rpcs and priorities
solution for this application
rpcs and priorities is
and priorities is compared
but how does the
priorities is compared to
how does the system
is compared to a
does the system behave
compared to a version
the system behave when
to a version of
system behave when lightly
a version of the
behave when lightly loaded
version of the andrew
our implementation of s
of the andrew file
the andrew file system
do similar phenomena occur
vn brings this concept
brings this concept a
speedups for the two
this concept a step
for the two workloads
here we ll see
the two workloads of
we ll see that
two workloads of the
ll see that load
workloads of the gw
see that load has
of the gw test
that load has a
the gw test are
concept a step closer
load has a super
a step closer to
gw test are shown
step closer to becoming
closer to becoming reality
linear impact on performance
relative to the performance
to the performance of
and provides evidence that
the performance of afs
provides evidence that performance
performance of afs at
evidence that performance will
that performance will be
performance will be acceptable
the growth in memory
will be acceptable for
growth in memory consumption
be acceptable for typical
in memory consumption causes
acceptable for typical use
memory consumption causes slowdowns
for typical use scenarios
consumption causes slowdowns that
causes slowdowns that amplify
slowdowns that amplify the
that amplify the increased
amplify the increased latencies
the increased latencies associated
increased latencies associated with
latencies associated with the
traffic are scaled down
associated with the growth
are scaled down further
with the growth in
scaled down further in
the growth in traffic
down further in parallel
to show this we
the graphs in figure
show this we designed
this we designed experiments
we designed experiments that
designed experiments that vary
experiments that vary the
validate the incorporation of
that vary the multicast
the incorporation of rpc
vary the multicast rate
incorporation of rpc priorities
comparison of packet recovery
of packet recovery probability
since all the foreground
all the foreground workloads
technological impact of magnetic
the foreground workloads improve
impact of magnetic hard
foreground workloads improve their
of magnetic hard disk
workloads improve their performance
magnetic hard disk drives
showed that the load
hard disk drives on
that the load on
disk drives on storage
the load on receivers
drives on storage systems
load on receivers grows
improve their performance substantially
on receivers grows roughly
their performance substantially at
receivers grows roughly linearly
performance substantially at lower
substantially at lower bandwidths
as expected given the
expected given the linearly
relative to mfs with
given the linearly increasing
to mfs with no
the linearly increasing load
mfs with no priorities
negligible loss rates and
loss rates and the
rates and the nearly
and the nearly flat
the nearly flat curve
nearly flat curve of
the decrease in throughput
flat curve of memory
decrease in throughput for
staggered start first i
in throughput for the
curve of memory consumption
start first i data
first i data packets
i data packets added
data packets added to
parameter trace mostly writes
packets added to a
added to a layer
to a layer with
a layer with interleave
layer with interleave i
r fire immediately with
fire immediately with just
immediately with just one
the latter reflecting our
with just one packet
latter reflecting our cooperative
just one packet in
reflecting our cooperative caching
one packet in them
our cooperative caching policy
for the next i
load on the sender
the next i data
next i data packets
i data packets added
r fire immediately with
fire immediately with two
because the linear growth
immediately with two data
the linear growth of
with two data packets
linear growth of traffic
two data packets in
data packets in them
combined with our fixed
with our fixed rate
and so on until
our fixed rate of
so on until r
fixed rate of state
on until r i
rate of state aggregation
until r i data
r i data packets
i data packets have
data packets have been
increases the amount of
packets have been added
the amount of unacknowledged
have been added to
amount of unacknowledged data
been added to the
added to the layer
to the layer and
the layer and all
layer and all bins
and all bins have
all bins have fired
bins have fired exactly
have fired exactly once
all bins fire at
bins fire at size
fire at size r
this triggers higher overheads
now that they have
that they have been
they have been staggered
have been staggered at
been staggered at the
the time spent in
staggered at the start
time spent in the
spent in the garbage
in the garbage collector
the garbage collector grows
garbage collector grows from
r fire for any
fire for any i
for any i data
any i data packets
the outlined scheme works
outlined scheme works when
scheme works when i
works when i is
when i is greater
i is greater than
is greater than or
greater than or equal
than or equal to
or equal to r
as is usually the
is usually the case
if i is smaller
i is smaller than
is smaller than r
combined with a linear
with a linear growth
a linear growth of
the bin with index
linear growth of cpu
bin with index x
growth of cpu usage
with index x fires
of cpu usage due
index x fires at
cpu usage due to
usage due to the
due to the increasing
to the increasing volume
the increasing volume of
increasing volume of traffic
these overheads cause the
overheads cause the super
linear growth of cpu
growth of cpu overhead
of cpu overhead shown
cpu overhead shown on
overhead shown on figure
the increasing number of
increasing number of unacknowledged
number of unacknowledged requests
of unacknowledged requests and
unacknowledged requests and the
requests and the resulting
and the resulting overheads
the initial firing sizes
the resulting overheads rise
initial firing sizes would
resulting overheads rise sharply
firing sizes would be
overheads rise sharply at
rise sharply at the
sharply at the highest
at the highest rates
brewer s conjecture and
for the first bin
s conjecture and the
the first bin and
conjecture and the feasibility
the highest rates because
and the feasibility of
highest rates because of
the feasibility of consistent
rates because of the
feasibility of consistent available
because of the increasing
of consistent available partition
of the increasing token
for the second bin
the increasing token roundtrip
these traces are representative
increasing token roundtrip time
traces are representative periods
are representative periods of
representative periods of mixed
if r and i
periods of mixed read
r and i are
in in acm sigact
the issue here is
in acm sigact news
issue here is that
of mixed read and
here is that the
and i are not
is that the amount
mixed read and write
that the amount of
read and write activity
the amount of i
i are not integral
are not integral multiples
not integral multiples of
integral multiples of each
o to be processed
the durations are from
to be processed increases
multiples of each other
durations are from the
are from the original
from the original ntfs
the original ntfs traces
much as in some
as in some of
in some of the
some of the earlier
of the earlier scenarios
note that the total
limiting still works but
that the total file
still works but is
the total file sizes
works but is slightly
total file sizes represent
this delays tokens as
but is slightly less
file sizes represent the
delays tokens as a
sizes represent the amount
is slightly less effective
represent the amount fetched
slightly less effective due
the amount fetched by
tokens as a function
less effective due to
amount fetched by mfs
effective due to rounding
fetched by mfs during
due to rounding errors
by mfs during the
as a function of
mfs during the trace
a function of the
function of the growing
of the growing volume
delaying xors in the
the growing volume of
xors in the straightforward
growing volume of multicast
in the straightforward implementation
volume of multicast traffic
where this is exceed
this is exceed by
is exceed by the
exceed by the write
by the write traffic
repair packets are transmitted
we confirm the hypothesis
packets are transmitted as
confirm the hypothesis by
are transmitted as soon
the hypothesis by looking
transmitted as soon as
hypothesis by looking at
as soon as they
the additional traffic is
soon as they are
by looking at the
as they are generated
additional traffic is due
looking at the end
traffic is due to
is due to new
due to new files
to new files being
this results in the
new files being created
results in the repair
files being created or
in the repair packet
being created or existing
the repair packet leaving
created or existing ones
repair packet leaving immediately
or existing ones extended
packet leaving immediately after
leaving immediately after the
immediately after the last
after the last data
the last data packet
time spent on rpcs
last data packet that
data packet that was
packet that was added
that was added to
was added to it
filesystem backup to the
backup to the cloud
which lowers burst tolerance
lowers burst tolerance if
burst tolerance if the
tolerance if the repair
we would expect latency
if the repair packet
would expect latency to
the repair packet was
expect latency to decrease
repair packet was generated
latency to decrease as
packet was generated at
to decrease as the
was generated at interleave
decrease as the sending
generated at interleave i
as the sending rate
the sending rate increases
sending rate increases because
rate increases because the
increases because the system
the resulting protocol can
because the system operates
resulting protocol can tolerate
the system operates more
protocol can tolerate a
system operates more smoothly
can tolerate a burst
tolerate a burst of
a burst of i
burst of i lost
of i lost data
i lost data packets
avoiding context switching overheads
lost data packets excluding
context switching overheads and
data packets excluding the
switching overheads and the
packets excluding the repair
overheads and the extra
and the extra latencies
the extra latencies caused
extra latencies caused by
but the burst could
latencies caused by the
the burst could swallow
caused by the small
burst could swallow both
by the small amount
could swallow both the
the small amount of
swallow both the repair
small amount of buffering
both the repair and
amount of buffering in
the repair and the
of buffering in our
repair and the last
buffering in our protocol
and the last data
in our protocol stack
the last data packet
last data packet in
data packet in it
packet in it as
in it as they
with larger packets once
it as they are
larger packets once the
as they are not
packets once the rate
they are not separated
once the rate exceeds
are not separated by
not separated by the
separated by the requisite
by the requisite interleave
the solution to this
solution to this is
to this is simple
this is simple delay
is simple delay sending
simple delay sending the
delay sending the repair
sending the repair packet
the repair packet generated
repair packet generated by
the latency starts increasing
packet generated by a
latency starts increasing again
generated by a repair
by a repair bin
a repair bin until
repair bin until the
due to the longer
bin until the next
to the longer pipeline
until the next time
the longer pipeline at
the next time a
longer pipeline at the
next time a data
pipeline at the receive
time a data packet
at the receive side
a data packet is
the receive side and
data packet is added
receive side and other
packet is added to
side and other phenomena
is added to the
harnessing storage clouds for
added to the now
and other phenomena just
to the now empty
storage clouds for high
the now empty bin
other phenomena just mentioned
clouds for high performance
for high performance content
high performance content delivery
this is not the
which happens i packets
is not the case
not the case for
happens i packets later
the case for small
ntfs workloads in addition
i packets later and
case for small packets
workloads in addition to
packets later and introduces
in addition to measuring
later and introduces the
addition to measuring the
and introduces the required
to measuring the performance
introduces the required interleave
measuring the performance of
the required interleave between
the performance of mfs
required interleave between the
performance of mfs with
interleave between the repair
of mfs with synthetic
between the repair packet
mfs with synthetic workloads
th international conference on
the repair packet and
international conference on service
repair packet and the
packet and the last
and the last data
the last data packet
we have also conducted
here the load on
have also conducted experiments
the load on the
last data packet included
load on the system
also conducted experiments with
on the system is
data packet included in
the system is much
conducted experiments with traces
system is much smaller
packet included in it
experiments with traces gathered
with traces gathered from
traces gathered from the
gathered from the windows
from the windows nt
the windows nt file
notice that although transmitting
windows nt file system
that although transmitting the
although transmitting the xor
the above observations are
transmitting the xor immediately
above observations are consistent
the xor immediately results
observations are consistent with
xor immediately results in
are consistent with the
immediately results in faster
consistent with the sharp
results in faster recovery
with the sharp rise
the sharp rise of
sharp rise of the
rise of the average
of the average delay
the average delay for
doing so also reduces
average delay for timer
so also reduces the
delay for timer events
also reduces the probability
reduces the probability of
the probability of a
probability of a lost
of a lost packet
a lost packet being
lost packet being recovered
although mfs is implemented
mfs is implemented on
is implemented on a
implemented on a variant
on a variant of
off results in a
a variant of unix
results in a minor
in a minor control
a minor control knob
minor control knob permitting
as the rate changes
control knob permitting us
the rate changes from
knob permitting us to
and ntfs has a
permitting us to balance
ntfs has a somewhat
us to balance speed
has a somewhat different
to balance speed against
a somewhat different interface
balance speed against burst
somewhat different interface to
speed against burst tolerance
different interface to the
interface to the file
to the file system
our default configuration is
default configuration is to
configuration is to transmit
is to transmit the
the traces were converted
to transmit the xor
traces were converted to
transmit the xor immediately
were converted to run
converted to run on
to run on top
run on top of
on top of mfs
top of mfs with
of mfs with little
mfs with little difficulty
the original traces recorded
original traces recorded file
traces recorded file accesses
recorded file accesses on
timer delays at the
file accesses on a
delays at the receiver
accesses on a set
at the receiver increase
on a set of
the receiver increase from
a set of machines
envelope analysis to start
set of machines in
analysis to start with
of machines in a
machines in a lan
we note that no
note that no two
a majority of the
that no two repair
majority of the accesses
no two repair packets
of the accesses were
two repair packets generated
the accesses were local
repair packets generated at
accesses were local but
packets generated at different
were local but some
generated at different interleaves
local but some were
at different interleaves i
but some were to
some were to remote
and on the sender
were to remote machines
an elastic transactional data
elastic transactional data store
transactional data store in
data store in the
store in the cloud
we extracted subintervals from
extracted subintervals from the
subintervals from the traces
from the traces which
the traces which featured
traces which featured interesting
which featured interesting file
featured interesting file system
interesting file system behaviour
file system behaviour and
system behaviour and processed
behaviour and processed them
and processed them to
processed them to remove
them to remove accesses
to remove accesses to
remove accesses to files
accesses to files over
will have more than
have more than one
more than one data
than one data packet
number of unacknowledged messages
one data packet in
of unacknowledged messages and
data packet in common
this preprocessing was necessary
packet in common as
unacknowledged messages and average
in common as long
preprocessing was necessary to
common as long as
messages and average token
as long as the
was necessary to eliminate
long as the least
and average token roundtrip
as the least common
necessary to eliminate the
the least common multiple
average token roundtrip time
to eliminate the influence
token roundtrip time as
eliminate the influence of
roundtrip time as a
the influence of extremely
time as a function
influence of extremely large
as a function of
of extremely large nt
a function of the
extremely large nt system
function of the sending
large nt system files
of the sending rate
of the interleaves is
the chubby lock service
the interleaves is greater
chubby lock service for
interleaves is greater than
lock service for loosely
is greater than r
greater than r i
pairings of repair bins
of the file system
of repair bins in
the file system traffic
repair bins in two
linearly growing memory use
bins in two different
file system traffic in
growing memory use on
in two different layers
system traffic in some
two different layers with
memory use on sender
different layers with interleaves
traffic in some portions
layers with interleaves i
use on sender and
in some portions of
on sender and the
some portions of the
sender and the nearly
portions of the original
and the nearly flat
of the original traces
the nearly flat usage
nearly flat usage on
flat usage on the
usage on the receiver
on the receiver as
given that mfs retrieves
the receiver as a
that mfs retrieves and
receiver as a function
mfs retrieves and writes
th conference on usenix
retrieves and writes back
as a function of
and writes back whole
conference on usenix symposium
writes back whole files
a function of the
on usenix symposium on
function of the sending
usenix symposium on operating
of the sending rate
symposium on operating systems
on operating systems design
including these system files
operating systems design and
these system files would
systems design and implementation
system files would have
files would have distorted
would have distorted the
have distorted the experiments
distorted the experiments at
the experiments at low
experiments at low bandwidths
a good rule of
good rule of thumb
gives statistics for the
rule of thumb is
statistics for the three
of thumb is to
for the three traces
thumb is to select
is to select interleaves
to select interleaves that
receive latency for varying
select interleaves that are
latency for varying rate
a trace in which
interleaves that are relatively
trace in which reads
that are relatively prime
in which reads predominate
with various message sizes
are relatively prime to
relatively prime to maximize
prime to maximize their
to maximize their lcm
a trace in which
trace in which writes
in which writes predominate
and also ensure that
also ensure that the
ensure that the larger
and one containing exceptionally
that the larger interleave
one containing exceptionally heavy
the larger interleave is
containing exceptionally heavy file
larger interleave is greater
exceptionally heavy file system
interleave is greater than
heavy file system traffic
is greater than r
alarm firing delays on
firing delays on sender
delays on sender and
on sender and receiver
let us assume that
sender and receiver as
us assume that packets
each trace was run
assume that packets are
and receiver as a
that packets are dropped
trace was run over
packets are dropped with
receiver as a function
are dropped with uniform
as a function of
was run over mfs
a function of sending
function of sending rate
run over mfs with
over mfs with the
mfs with the combinations
with the combinations of
the combinations of synchronous
given a lost data
combinations of synchronous and
a lost data packet
of synchronous and asynchronous
synchronous and asynchronous writes
and asynchronous writes and
asynchronous writes and differentiated
what is the probability
writes and differentiated and
is the probability that
and differentiated and uniform
the probability that we
differentiated and uniform priorities
probability that we can
and uniform priorities in
that we can recover
uniform priorities in previous
we can recover it
priorities in previous experiments
we can recover a
and the results are
can recover a data
the results are given
recover a data packet
results are given in
a data packet if
are given in figure
data packet if at
packet if at least
group memory consumption in
if at least one
memory consumption in a
at least one of
consumption in a final
least one of the
in a final set
one of the c
to interpret these graphs
of the c xors
a final set of
the c xors containing
final set of experiments
c xors containing it
xors containing it is
containing it is received
look for instance at
it is received correctly
for instance at the
is received correctly and
we focus on scalability
instance at the heavy
focus on scalability with
at the heavy load
on scalability with the
the heavy load bar
scalability with the number
heavy load bar mostly
with the number of
load bar mostly reads
the number of groups
received correctly and usable
a single sender multicasts
single sender multicasts to
sender multicasts to a
multicasts to a varying
to a varying number
a varying number of
varying number of groups
number of groups in
all the other data
of groups in a
the other data packets
groups in a roundrobin
other data packets in
in a roundrobin fashion
data packets in it
packets in it have
in it have also
it have also been
have also been received
all receivers join all
also been received correctly
receivers join all groups
the probability of which
and since the groups
probability of which is
since the groups are
of which is simply
the groups are perfectly
groups are perfectly overlapped
the system contains a
system contains a single
contains a single region
qsm s regional recovery
s regional recovery protocol
regional recovery protocol is
recovery protocol is oblivious
protocol is oblivious to
is oblivious to the
oblivious to the groups
the probability of a
probability of a received
of a received xor
hence the receivers behave
a received xor being
the receivers behave identically
received xor being unusable
receivers behave identically no
xor being unusable is
behave identically no matter
being unusable is the
identically no matter how
unusable is the complement
no matter how many
matter how many groups
how many groups we
many groups we use
on the other hand
the sender maintains a
sender maintains a number
maintains a number of
a number of per
this affects the sender
affects the sender s
the sender s memory
sender s memory footprint
so changes to throughput
changes to throughput or
to throughput or protocol
throughput or protocol behavior
or protocol behavior must
protocol behavior must be
applications unique files total
behavior must be directly
unique files total file
must be directly or
files total file sizes
be directly or indirectly
the probability x of
directly or indirectly linked
probability x of a
or indirectly linked to
x of a sent
indirectly linked to memory
linked to memory usage
of a sent xor
a sent xor being
sent xor being dropped
xor being dropped or
we do not expect
being dropped or unusable
do not expect the
dropped or unusable is
not expect the token
or unusable is the
expect the token roundtrip
unusable is the sum
the token roundtrip time
is the sum of
token roundtrip time or
the sum of the
roundtrip time or the
sum of the probability
time or the amount
of the probability that
or the amount of
the probability that it
the amount of messages
probability that it was
amount of messages pending
that it was dropped
of messages pending acknowledgement
it was dropped and
messages pending acknowledgement to
was dropped and the
pending acknowledgement to vary
dropped and the probability
acknowledgement to vary with
and the probability that
to vary with the
the probability that it
vary with the number
probability that it was
with the number of
that it was received
the number of groups
it was received and
grep in the gw
was received and unusable
in the gw workload
the gw workload even
gw workload even is
workload even is less
even is less than
is less than would
less than would be
than would be expected
would be expected with
be expected with reduced
expected with reduced bandwidth
here uniform priorities result
uniform priorities result in
priorities result in throughput
groups this is the
result in throughput linear
this is the case
in throughput linear in
throughput linear in the
linear in the bandwidth
while differentiated priorities are
differentiated priorities are less
priorities are less sensitive
the rc and gc
rc and gc tests
and gc tests show
gc tests show the
tests show the benefit
show the benefit of
the benefit of asynchronous
benefit of asynchronous writeback
in this range memory
this range memory consumption
range memory consumption on
memory consumption on the
the dangers of replication
consumption on the sender
dangers of replication and
on the sender grows
of replication and a
since the updates from
replication and a solution
the updates from the
updates from the compile
from the compile workload
the compile workload are
compile workload are committed
workload are committed sooner
are committed sooner to
committed sooner to the
sooner to the server
to the server than
the server than with
server than with synchronous
than with synchronous writes
and so does the
so does the time
does the time spent
due to the overlap
the time spent in
to the overlap of
time spent in the
the overlap of think
spent in the clr
overlap of think time
of think time with
think time with asynchronous
time with asynchronous writes
acm sigmod international conference
since it is easy
sigmod international conference on
it is easy to
international conference on management
is easy to ensure
conference on management of
easy to ensure that
on management of data
to ensure that no
though uniform priorities provide
ensure that no two
uniform priorities provide better
that no two xors
priorities provide better performance
no two xors share
provide better performance for
two xors share more
better performance for the
xors share more than
performance for the write
share more than one
for the write component
more than one data
the write component of
than one data packet
write component of the
component of the rw
of the rw test
the rw test at
the usability probabilities of
usability probabilities of different
probabilities of different xors
of different xors are
different xors are independent
inspection of the managed
the probability of all
of the managed heap
probability of all the
the managed heap in
of all the c
managed heap in a
all the c xors
heap in a debugger
the c xors being
in a debugger shows
c xors being dropped
a debugger shows that
xors being dropped or
debugger shows that the
being dropped or unusable
shows that the growth
as is to be
that the growth in
is to be expected
the growth in memory
dropped or unusable is
growth in memory used
or unusable is xc
in memory used is
memory used is caused
used is caused not
since we are prioritising
is caused not by
we are prioritising reads
caused not by messages
the probability of correctly
but by the per
probability of correctly receiving
of correctly receiving at
correctly receiving at least
this benefit largely vanishes
receiving at least one
benefit largely vanishes at
group elements of the
largely vanishes at lower
elements of the protocol
vanishes at lower bandwidths
of the protocol stack
at least one usable
least one usable xor
one usable xor is
each maintains a queue
though we have concentrated
we have concentrated on
have concentrated on determining
concentrated on determining the
on determining the benefit
determining the benefit of
the benefit of rpc
benefit of rpc priorities
of rpc priorities by
the probability of recovering
rpc priorities by a
small structures for profiling
probability of recovering the
structures for profiling etc
priorities by a comparison
of recovering the lost
by a comparison of
recovering the lost data
a comparison of different
the lost data packet
comparison of different configurations
with thousands of groups
of different configurations of
lost data packet is
different configurations of mfs
configurations of mfs to
of mfs to one
mfs to one another
these add up to
add up to tens
up to tens of
to tens of megabytes
we have also performed
have also performed a
we can confirm the
also performed a few
can confirm the theory
performed a few experiments
confirm the theory by
a few experiments to
the theory by turning
few experiments to compare
theory by turning on
experiments to compare the
by turning on additional
to compare the performance
turning on additional tracing
compare the performance of
on additional tracing in
the performance of mfs
additional tracing in the
performance of mfs to
tracing in the per
of mfs to a
mfs to a standard
to a standard distributed
a standard distributed file
standard distributed file system
this tracing is lightweight
tracing is lightweight and
is lightweight and has
lightweight and has little
and has little effect
has little effect on
illustrates the result of
little effect on cpu
the result of running
effect on cpu consumption
result of running the
of running the gw
form formula only gives
running the gw test
formula only gives us
the gw test over
only gives us a
gw test over mfs
gives us a lower
test over mfs and
but it increases the
over mfs and an
us a lower bound
mfs and an andrew
it increases the memory
and an andrew file
a lower bound on
an andrew file system
increases the memory footprint
lower bound on the
the memory footprint by
bound on the recovery
memory footprint by adding
on the recovery probability
footprint by adding additional
by adding additional data
adding additional data structures
additional data structures that
data structures that are
since the xor usability
structures that are updated
the xor usability formula
that are updated once
we used the arla
xor usability formula does
are updated once per
used the arla implementation
updated once per second
usability formula does not
the arla implementation of
formula does not factor
arla implementation of the
does not factor in
implementation of the afs
which burdens the gc
not factor in the
of the afs cache
factor in the probability
the afs cache manager
in the probability of
the probability of the
probability of the other
of the other data
the other data packets
other data packets in
data packets in the
packets in the xor
in the xor being
the xor being dropped
xor being dropped and
being dropped and recovered
and the openafs server
we extend the analysis
extend the analysis to
afs uses a udp
the analysis to bursty
analysis to bursty losses
based rpc library without
if the lost data
rpc library without priorities
the lost data packet
it is worth noting
lost data packet was
is worth noting that
data packet was part
worth noting that the
packet was part of
noting that the memory
was part of a
that the memory usages
the results largely correspond
the memory usages reported
part of a loss
memory usages reported here
of a loss burst
usages reported here are
a loss burst of
reported here are averages
loss burst of size
results largely correspond to
burst of size b
largely correspond to those
correspond to those in
to those in figure
repair packets generated at
packets generated at interleaves
generated at interleaves less
at interleaves less than
interleaves less than b
and the peak values
mfs significantly outperforms afs
the peak values are
less than b are
peak values are typically
significantly outperforms afs for
than b are dropped
outperforms afs for the
b are dropped or
afs for the foreground
are dropped or useless
for the foreground grep
dropped or useless with
the foreground grep workload
or useless with high
useless with high probability
since afs effectively uses
and we can discount
afs effectively uses synchronous
we can discount them
effectively uses synchronous rpcs
uses synchronous rpcs with
synchronous rpcs with uniform
rpcs with uniform priorities
in the background write
of recovering the data
the background write workload
recovering the data packet
the data packet is
data packet is then
afs slightly outperforms mfs
the nodes on our
nodes on our cluster
on our cluster only
our cluster only have
but it is both
it is both a
is both a more
both a more mature
a more mature system
is the number of
the number of xors
number of xors generated
secure untrusted data repository
of xors generated at
xors generated at interleaves
and more optimised than
generated at interleaves greater
more optimised than mfs
at interleaves greater than
optimised than mfs for
interleaves greater than b
than mfs for this
mfs for this sort
for this sort of
this sort of communication
the formulae derived for
formulae derived for xor
derived for xor usability
for xor usability still
since the results of
xor usability still hold
the results of running
results of running the
of running the other
running the other tests
the other tests are
other tests are similar
since packet losses with
packet losses with more
losses with more than
with more than b
more than b intervening
we omit them for
than b intervening packets
omit them for brevity
b intervening packets between
intervening packets between them
th conference on symposium
packets between them have
conference on symposium on
between them have independent
on symposium on opearting
them have independent probability
symposium on opearting systems
on opearting systems design
mostly reads mostly writes
there is only correlation
reads mostly writes heavy
is only correlation within
mostly writes heavy load
only correlation within the
writes heavy load store
memory footprint is significant
correlation within the bursts
heavy load store overhead
load store overhead priorities
store overhead priorities uniform
overhead priorities uniform priorities
priorities uniform priorities uniform
uniform priorities uniform synchronous
priorities uniform synchronous asynchronous
how does this compare
uniform synchronous asynchronous time
does this compare to
synchronous asynchronous time spent
this compare to traditional
asynchronous time spent on
time spent on rpcs
codes such as reed
the peak footprint approaches
and the system is
the system is close
system is close to
is close to swapping
c repair packets are
repair packets are generated
packets are generated and
are generated and sent
generated and sent for
and sent for every
sent for every r
for every r data
every r data packets
and the correct delivery
the correct delivery of
correct delivery of any
delivery of any r
of any r of
any r of the
r of the r
c packets transmitted is
packets transmitted is sufficient
transmitted is sufficient to
is sufficient to reconstruct
sufficient to reconstruct the
to reconstruct the original
groups are enough to
reconstruct the original r
are enough to trigger
the original r data
enough to trigger signs
original r data packets
to trigger signs of
trigger signs of instability
token roundtrip times start
roundtrip times start to
times start to grow
given a lost data
a lost data packet
communal data sharing in
thus delaying message cleanup
data sharing in public
sharing in public clouds
we can recover it
can recover it if
recover it if at
it if at least
if at least r
at least r packets
least r packets are
r packets are received
packets are received correctly
are received correctly in
received correctly in the
correctly in the encoding
in the encoding set
and increasing memory overhead
the encoding set of
encoding set of r
c data and repair
data and repair packets
and repair packets that
repair packets that the
packets that the lost
that the lost packet
the lost packet belongs
lost packet belongs to
although the process is
the process is fairly
process is fairly unpredictable
the probability of recovering
we see spikes and
probability of recovering a
see spikes and anomalies
of recovering a lost
recovering a lost packet
a lost packet is
lost packet is equivalent
packet is equivalent to
is equivalent to the
equivalent to the probability
to the probability of
we can easily recognize
the probability of losing
can easily recognize a
probability of losing c
easily recognize a super
or less packets from
linear trend starting at
less packets from the
trend starting at around
packets from the total
from the total r
since the number of
the number of other
number of other lost
of other lost packets
other lost packets in
lost packets in the
packets in the xor
at around this point
in the xor is
the xor is a
xor is a random
is a random variable
we also start to
a random variable y
also start to see
random variable y and
start to see occasional
variable y and has
to see occasional bursts
y and has a
see occasional bursts of
and has a binomial
occasional bursts of packet
has a binomial distribution
bursts of packet losses
a binomial distribution with
binomial distribution with parameters
often roughly correlated across
roughly correlated across receivers
such events trigger bursty
events trigger bursty recovery
trigger bursty recovery overloads
is the summation p
the summation p z
summation p z c
number of messages pending
of messages pending ack
messages pending ack and
pending ack and token
ack and token roundtrip
and token roundtrip time
token roundtrip time as
roundtrip time as a
time as a function
as a function of
a function of the
function of the number
of the number of
the number of groups
we plot the recovery
plot the recovery probability
the recovery probability curves
recovery probability curves for
probability curves for layered
curves for layered interleaving
memory usage grows with
for layered interleaving and
usage grows with the
layered interleaving and reed
grows with the number
with the number of
the number of groups
solomon against uniformly random
against uniformly random loss
uniformly random loss rate
beyond a certain threshold
the system is increasingly
system is increasingly unstable
time spent in the
spent in the clr
in the clr code
note that the curves
that the curves are
the curves are very
curves are very close
are very close to
very close to each
close to each other
throughput decreases with the
decreases with the number
with the number of
especially in the loss
the number of groups
in the loss range
the loss range of
loss range of interest
range of interest between
all groups have the
groups have the same
have the same subscribers
local recovery for receiver
recovery for receiver loss
for receiver loss in
receiver loss in the
loss in the absence
in the absence of
the absence of intelligent
absence of intelligent flow
of intelligent flow control
intelligent flow control mechanisms
flow control mechanisms like
control mechanisms like tcp
inexpensive data center end
the key insight is
key insight is that
insight is that all
is that all these
that all these effects
hosts can be easily
all these effects originate
can be easily overwhelmed
these effects originate at
be easily overwhelmed and
effects originate at the
easily overwhelmed and drop
originate at the sender
overwhelmed and drop packets
at the sender node
and drop packets during
drop packets during traffic
packets during traffic spikes
during traffic spikes or
traffic spikes or cpu
which is more loaded
is more loaded and
more loaded and less
loaded and less responsive
intensive maintenance tasks like
maintenance tasks like garbage
tasks like garbage collection
detailed analysis of the
analysis of the captured
of the captured network
level protocols layered over
the captured network traffic
protocols layered over udp
captured network traffic shows
layered over udp for
network traffic shows that
over udp for reliable
traffic shows that the
udp for reliable multicast
shows that the multicast
that the multicast stream
the multicast stream in
multicast stream in all
stream in all cases
in all cases looks
all cases looks basically
cases looks basically identical
the miner s dilemma
miner s dilemma ittay
and hence we cannot
s dilemma ittay eyal
hence we cannot attribute
we cannot attribute token
or high speed data
cannot attribute token latency
high speed data transfer
dilemma ittay eyal cornell
attribute token latency or
ittay eyal cornell university
token latency or losses
latency or losses to
eyal cornell university abstract
or losses to the
losses to the increased
cornell university abstract an
to the increased volume
the increased volume of
university abstract an open
increased volume of traffic
abstract an open distributed
an open distributed system
open distributed system can
throughput spikes or longer
distributed system can be
spikes or longer bursts
system can be secured
or longer bursts of
can be secured by
longer bursts of data
be secured by requiring
for example would ordinarily
secured by requiring participants
example would ordinarily go
by requiring participants to
would ordinarily go back
requiring participants to present
ordinarily go back to
participants to present proof
go back to the
to present proof of
back to the sender
the sender spends more
to the sender to
sender spends more time
the sender to retrieve
spends more time transmitting
sender to retrieve the
more time transmitting at
to retrieve the lost
time transmitting at lower
retrieve the lost packet
transmitting at lower rates
present proof of work
proof of work and
of work and rewarding
work and rewarding them
and rewarding them for
even though it was
rewarding them for participation
but doesn t produce
though it was dropped
doesn t produce any
it was dropped at
t produce any faster
was dropped at the
produce any faster data
dropped at the receiver
any faster data bursts
at the receiver after
faster data bursts than
the receiver after covering
data bursts than those
receiver after covering the
the bitcoin digital currency
after covering the entire
bursts than those we
covering the entire geographical
bitcoin digital currency introduced
the entire geographical distance
than those we observe
digital currency introduced this
those we observe with
currency introduced this mechanism
we observe with smaller
observe with smaller numbers
with smaller numbers of
the maelstrom proxy acts
smaller numbers of groups
maelstrom proxy acts as
proxy acts as a
acts as a local
which is adopted by
as a local packet
is adopted by almost
a local packet cache
adopted by almost all
by almost all contemporary
almost all contemporary digital
all contemporary digital currencies
contemporary digital currencies and
digital currencies and related
storing incoming packets for
currencies and related services
incoming packets for a
packets for a short
for a short period
a natural process leads
a short period of
natural process leads participants
short period of time
receiver performance indicators such
process leads participants of
period of time and
leads participants of such
performance indicators such as
of time and providing
participants of such systems
indicators such as delays
time and providing hooks
of such systems to
and providing hooks that
such systems to form
such as delays in
systems to form pools
providing hooks that allow
as delays in firing
hooks that allow protocols
delays in firing timer
that allow protocols to
in firing timer event
allow protocols to first
firing timer event or
where members aggregate their
protocols to first query
timer event or cpu
members aggregate their power
event or cpu utilization
aggregate their power and
to first query the
or cpu utilization don
first query the cache
their power and share
query the cache to
power and share the
the cache to locate
and share the rewards
cpu utilization don t
cache to locate missing
utilization don t show
to locate missing packets
don t show any
locate missing packets before
t show any noticeable
missing packets before sending
show any noticeable trend
packets before sending retransmission
experience with bitcoin shows
before sending retransmission requests
with bitcoin shows that
sending retransmission requests back
bitcoin shows that the
retransmission requests back to
shows that the largest
requests back to the
that the largest pools
back to the sender
the largest pools are
largest pools are often
pools are often open
all roads lead back
roads lead back to
lead back to the
back to the sender
future versions of maelstrom
versions of maelstrom could
allowing anyone to join
of maelstrom could potentially
maelstrom could potentially use
and the main thing
could potentially use knowledge
the main thing going
potentially use knowledge of
main thing going on
it has long been
thing going on in
use knowledge of protocol
going on in the
has long been known
on in the sender
long been known that
in the sender is
knowledge of protocol internals
the sender is that
been known that a
sender is that it
of protocol internals to
is that it has
known that a member
that it has a
protocol internals to transparently
it has a steadily
that a member can
has a steadily growing
internals to transparently intervene
a steadily growing memory
a member can sabotage
steadily growing memory footprint
member can sabotage an
can sabotage an open
sabotage an open pool
an open pool by
we also looked at
open pool by seemingly
also looked at token
pool by seemingly joining
by intercepting and satisfying
looked at token round
by seemingly joining it
intercepting and satisfying retransmission
seemingly joining it but
and satisfying retransmission requests
joining it but never
satisfying retransmission requests sent
it but never sharing
retransmission requests sent by
but never sharing its
requests sent by the
never sharing its proofs
sent by the receiver
sharing its proofs of
by the receiver in
the distribution of token
the receiver in a
its proofs of work
distribution of token roundtrip
receiver in a nak
of token roundtrip times
token roundtrip times for
roundtrip times for different
the pool shares its
times for different numbers
pool shares its revenue
for different numbers of
shares its revenue with
different numbers of groups
its revenue with the
or by resending packets
revenue with the attacker
numbers of groups shows
by resending packets when
of groups shows an
resending packets when acknowledgments
groups shows an increase
packets when acknowledgments are
shows an increase of
and so each of
when acknowledgments are not
so each of its
an increase of the
each of its participants
increase of the token
of its participants earns
of the token roundtrip
its participants earns less
the token roundtrip time
acknowledgments are not observed
are not observed within
not observed within a
observed within a certain
we define and analyze
caused almost entirely by
within a certain time
define and analyze a
a certain time period
and analyze a game
certain time period in
analyze a game where
time period in an
a game where pools
period in an ack
game where pools use
where pools use some
pools use some of
use some of their
some of their participants
of the tokens that
of their participants to
the tokens that are
their participants to infiltrate
tokens that are delayed
participants to infiltrate other
that are delayed the
to infiltrate other pools
are delayed the most
infiltrate other pools and
implementation details we initially
other pools and perform
details we initially implemented
pools and perform such
we initially implemented and
and perform such an
initially implemented and evaluated
perform such an attack
implemented and evaluated maelstrom
and evaluated maelstrom as
evaluated maelstrom as a
maelstrom as a user
with any number of
any number of pools
performance turned out to
turned out to be
which points to disruptive
out to be limited
points to disruptive events
to be limited by
to disruptive events as
be limited by copying
disruptive events as the
limited by copying and
events as the culprit
by copying and context
attacks is not a
is not a nash
not a nash equilibrium
rather than a uniform
than a uniform increase
a uniform increase of
uniform increase of the
we study the special
increase of the token
and we subsequently reimplemented
of the token processing
study the special cases
the token processing overhead
we subsequently reimplemented the
the special cases where
subsequently reimplemented the system
special cases where either
reimplemented the system as
cases where either two
the system as a
where either two pools
system as a module
either two pools or
as a module that
two pools or any
a module that runs
pools or any number
module that runs within
or any number of
we find that these
any number of identical
find that these tokens
that runs within the
that these tokens were
runs within the linux
these tokens were most
number of identical pools
tokens were most commonly
of identical pools play
were most commonly delayed
identical pools play the
most commonly delayed on
pools play the game
commonly delayed on the
play the game and
delayed on the sender
the game and the
game and the rest
and the rest of
the rest of the
with many thousands of
rest of the participants
many thousands of groups
of the participants are
the participants are uninvolved
the average time to
average time to travel
in both of these
both of these cases
of these cases there
these cases there exists
at an encoding rate
cases there exists an
an encoding rate of
there exists an equilibrium
exists an equilibrium that
an equilibrium that constitutes
time to travel by
equilibrium that constitutes a
to travel by one
that constitutes a tragedy
travel by one hop
constitutes a tragedy of
by one hop from
a tragedy of the
one hop from sender
tragedy of the commons
hop from sender to
of the commons where
from sender to receiver
the commons where the
sender to receiver or
commons where the participating
to receiver or receiver
where the participating pools
receiver or receiver to
the participating pools attack
or receiver to sender
participating pools attack one
receiver to sender can
pools attack one another
the experimental prototype of
attack one another and
experimental prototype of the
to sender can grow
prototype of the kernel
sender can grow to
one another and earn
can grow to nearly
of the kernel version
another and earn less
the kernel version reaches
and earn less than
kernel version reaches output
earn less than they
version reaches output speeds
less than they would
reaches output speeds close
than they would have
output speeds close to
they would have if
would have if none
have if none had
if none had attacked
gigabit per second of
per second of combined
second of combined data
of combined data and
combined data and fec
data and fec traffic
the decision whether or
decision whether or not
whether or not to
limited only by the
or not to attack
only by the capacity
not to attack is
by the capacity of
to attack is the
as compared to an
attack is the miner
compared to an average
is the miner s
the capacity of the
the miner s dilemma
capacity of the outbound
of the outbound network
the outbound network card
ms per hop from
per hop from receiver
an instance of the
hop from receiver to
instance of the iterative
from receiver to receiver
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
lambda networks are already
networks are already reaching
are already reaching speeds
the game is played
already reaching speeds of
game is played daily
is played daily by
played daily by the
daily by the active
by the active bitcoin
the active bitcoin pools
the overloaded sender occasionally
overloaded sender occasionally releases
which apparently choose not
sender occasionally releases the
apparently choose not to
occasionally releases the tokens
choose not to attack
releases the tokens with
the tokens with a
tokens with a delay
if this balance breaks
the revenue of open
revenue of open pools
of open pools might
open pools might diminish
and higher speeds are
higher speeds are a
speeds are a certainty
are a certainty down
making them unattractive to
a certainty down the
them unattractive to participants
certainty down the road
the value of the
value of the delay
of the delay grows
the delay grows with
we envision maelstrom as
delay grows with the
envision maelstrom as a
grows with the number
maelstrom as a small
with the number of
as a small rack
the number of groups
is a digital currency
style cluster of servers
a digital currency that
digital currency that is
currency that is gaining
that is gaining acceptance
each acting as an
acting as an individual
as an individual proxy
traffic would be distributed
our old culprit is
would be distributed over
old culprit is back
be distributed over such
distributed over such a
over such a rack
such a rack by
a rack by partitioning
related costs at the
rack by partitioning the
costs at the sender
by partitioning the address
partitioning the address space
the address space of
address space of the
with an estimated market
space of the remote
an estimated market capitalization
increasing the number of
estimated market capitalization of
the number of groups
market capitalization of over
number of groups slows
of the remote data
of groups slows the
the remote data center
groups slows the sender
remote data center and
data center and routing
center and routing different
and routing different segments
and this cascades to
routing different segments of
this cascades to create
different segments of the
cascades to create all
segments of the space
to create all sorts
of the space through
create all sorts of
the space through distinct
all sorts of downstream
space through distinct maelstrom
sorts of downstream problems
through distinct maelstrom appliance
of downstream problems that
distinct maelstrom appliance pairs
downstream problems that can
problems that can destabilize
that can destabilize the
can destabilize the system
destabilize the system as
the system as a
system as a whole
we plan to experiment
plan to experiment with
to experiment with such
experiment with such configurations
discussion the experiments just
the experiments just reported
experiments just reported make
just reported make it
which would also permit
reported make it clear
would also permit us
make it clear that
also permit us to
it clear that the
permit us to explore
clear that the performance
us to explore fault
limiting factor in the
bitcoin s security stems
factor in the qsm
s security stems from
in the qsm system
security stems from a
the qsm system is
stems from a robust
qsm system is latency
from a robust incentive
if a maelstrom blade
a robust incentive system
a maelstrom blade fails
and that in addition
that in addition to
participants are required to
in addition to protocol
are required to provide
addition to protocol factors
required to provide expensive
to protocol factors such
to provide expensive proofs
protocol factors such as
provide expensive proofs of
factors such as the
expensive proofs of work
such as the length
and to support load
as the length of
the length of token
length of token rings
and they are rewarded
they are rewarded according
are rewarded according to
balancing schemes that might
rewarded according to their
schemes that might vary
latency is strongly influenced
according to their efforts
that might vary the
is strongly influenced by
might vary the ip
strongly influenced by the
vary the ip address
influenced by the memory
this architecture has proved
the ip address space
by the memory footprint
ip address space partitioning
the memory footprint of
address space partitioning dynamically
architecture has proved both
space partitioning dynamically to
has proved both stable
memory footprint of the
partitioning dynamically to spread
footprint of the system
proved both stable and
dynamically to spread the
both stable and scalable
to spread the encoding
spread the encoding load
the encoding load over
encoding load over multiple
load over multiple machines
and it is used
it is used by
when we built the
is used by most
we built the system
used by most contemporary
built the system it
by most contemporary digital
the system it was
most contemporary digital currencies
system it was obvious
contemporary digital currencies and
it was obvious that
digital currencies and related
was obvious that minimizing
currencies and related services
obvious that minimizing latency
that minimizing latency would
we present the implementation
minimizing latency would be
present the implementation and
latency would be important
the implementation and performance
implementation and performance of
and performance of a
performance of a single
this motivated several of
motivated several of the
several of the design
of the design decisions
the design decisions discussed
design decisions discussed in
decisions discussed in section
the kernel implementation is
kernel implementation is a
implementation is a module
is a module for
a module for linux
but the repeated linkage
the repeated linkage of
repeated linkage of latency
linkage of latency and
of latency and oscillatory
latency and oscillatory throughputs
and oscillatory throughputs to
oscillatory throughputs to memory
throughputs to memory was
to memory was a
memory was a surprise
we expected a much
expected a much smaller
a much smaller impact
with hooks into the
hooks into the kernel
into the kernel packet
the kernel packet filter
we can summarize our
can summarize our design
summarize our design insights
our design insights as
design insights as follows
minimize the memory footprint
maelstrom proxies work in
proxies work in pairs
we expected that the
expected that the primary
that the primary cost
one on each side
the primary cost of
on each side of
primary cost of managed
each side of the
cost of managed memory
side of the long
of managed memory would
of the long haul
managed memory would be
the long haul link
memory would be associated
would be associated with
be associated with garbage
associated with garbage collection
each proxy acts both
proxy acts both as
acts both as an
both as an ingress
as an ingress and
an ingress and egress
all costs associated with
ingress and egress router
costs associated with managed
and egress router at
our results apply to
egress router at the
results apply to all
associated with managed memory
apply to all such
router at the same
to all such incentive
with managed memory rise
all such incentive systems
at the same time
managed memory rise in
the same time since
memory rise in the
same time since they
rise in the amount
time since they handle
in the amount of
since they handle duplex
but we use bitcoin
they handle duplex traffic
the amount of allocated
handle duplex traffic in
amount of allocated memory
duplex traffic in the
we use bitcoin terminology
traffic in the following
use bitcoin terminology and
in the following manner
bitcoin terminology and examples
at least in the
terminology and examples since
least in the windows
and examples since it
in the windows clr
examples since it serves
since it serves as
the egress router captures
it serves as an
egress router captures ip
serves as an active
router captures ip packets
as an active and
captures ip packets and
an active and archetypal
ip packets and creates
active and archetypal example
mostly reads mostly writes
packets and creates redundant
reads mostly writes heavy
and creates redundant fec
mostly writes heavy load
creates redundant fec packets
writes heavy load store
bitcoin implements its incentive
heavy load store overhead
implements its incentive systems
load store overhead priorities
its incentive systems with
store overhead priorities uniform
incentive systems with a
the original ip packets
systems with a data
overhead priorities uniform priorities
with a data structure
original ip packets are
a data structure called
priorities uniform priorities uniform
whereas traditional multicast systems
data structure called the
ip packets are routed
structure called the blockchain
traditional multicast systems accept
uniform priorities uniform synchronous
multicast systems accept messages
packets are routed through
priorities uniform synchronous asynchronous
are routed through unaltered
uniform synchronous asynchronous figure
routed through unaltered as
the blockchain is a
through unaltered as they
blockchain is a serialization
unaltered as they would
is a serialization of
as they would have
a serialization of all
they would have been
serialization of all bitcoin
would have been originally
of all bitcoin transactions
systems accept messages whenever
accept messages whenever the
graphs of ntfs traces
messages whenever the application
whenever the application layer
the redundant packets are
the application layer or
it is a single
application layer or the
redundant packets are then
layer or the multicast
is a single global
or the multicast protocols
packets are then forwarded
the multicast protocols produce
a single global ledger
multicast protocols produce it
are then forwarded to
each trace ran with
then forwarded to the
single global ledger maintained
forwarded to the remote
global ledger maintained by
to the remote ingress
ledger maintained by an
the remote ingress router
maintained by an open
remote ingress router via
by an open distributed
ingress router via a
an open distributed system
router via a udp
trace ran with synchronous
qsm uses an upcall
ran with synchronous or
via a udp channel
with synchronous or asynchronous
synchronous or asynchronous writes
since anyone can join
or asynchronous writes and
anyone can join the
asynchronous writes and uniform
can join the open
writes and uniform or
the ingress router captures
and uniform or differentiated
join the open system
uniform or differentiated priorities
ingress router captures and
often we can delay
the open system and
we can delay generating
router captures and stores
can delay generating a
open system and participate
delay generating a message
captures and stores ip
generating a message until
system and participate in
a message until the
and stores ip packets
message until the last
and participate in maintaining
until the last minute
stores ip packets coming
the total height of
ip packets coming from
participate in maintaining the
packets coming from the
total height of each
coming from the direction
in maintaining the blockchain
from the direction of
height of each bar
and we can also
of each bar denotes
the direction of the
each bar denotes the
direction of the egress
bitcoin uses a proof
of the egress router
uses a proof of
bar denotes the time
a proof of work
we can also avoid
proof of work mechanism
denotes the time from
of work mechanism to
can also avoid situations
work mechanism to deter
upon receipt of a
the time from the
receipt of a redundant
mechanism to deter attacks
also avoid situations in
time from the first
avoid situations in which
from the first to
of a redundant packet
the first to last
situations in which data
first to last write
participation requires exerting significant
in which data piles
requires exerting significant compute
which data piles up
exerting significant compute resources
and the shaded portion
data piles up on
the shaded portion denotes
an ip packet is
shaded portion denotes the
piles up on behalf
portion denotes the time
up on behalf of
a participant that proves
on behalf of an
ip packet is recovered
participant that proves she
denotes the time from
packet is recovered if
behalf of an aggressive
is recovered if there
of an aggressive sender
the time from the
that proves she has
time from the first
recovered if there is
from the first to
if there is an
proves she has exerted
the first to last
there is an opportunity
she has exerted enough
is an opportunity to
first to last read
an opportunity to do
has exerted enough resources
opportunity to do so
exerted enough resources with
enough resources with a
resources with a proof
the white portions denote
limit buffering and caching
white portions denote the
redundant packets that can
portions denote the extra
packets that can be
with a proof of
that can be used
denote the extra time
can be used at
most existing multicast protocols
be used at a
the extra time required
used at a later
existing multicast protocols buffer
extra time required to
at a later time
multicast protocols buffer data
a later time are
protocols buffer data at
later time are stored
a proof of work
time required to complete
proof of work is
buffer data at many
of work is allowed
required to complete all
work is allowed to
to complete all writes
if the redundant packet
complete all writes after
is allowed to take
all writes after the
the redundant packet is
writes after the last
data at many layers
redundant packet is useless
after the last read
allowed to take a
the last read has
packet is useless it
at many layers and
is useless it is
last read has finished
useless it is immediately
many layers and cache
to take a step
layers and cache data
take a step in
and cache data rather
a step in the
cache data rather casually
step in the protocol
data rather casually for
in the protocol by
rather casually for recovery
the protocol by generating
casually for recovery purposes
protocol by generating a
for asynchronous writeback with
by generating a block
it is immediately discarded
asynchronous writeback with priorities
writeback with priorities in
with priorities in the
this turns out to
turns out to be
participants are compensated for
upon recovery the ip
out to be extremely
are compensated for their
recovery the ip packet
to be extremely costly
the ip packet is
be extremely costly in
ip packet is sent
compensated for their efforts
packet is sent through
extremely costly in a
is sent through a
for their efforts with
sent through a raw
costly in a managed
through a raw socket
their efforts with newly
a raw socket to
in a managed setting
raw socket to its
a managed setting and
socket to its intended
efforts with newly minted
to its intended destination
managed setting and must
this shows that the
setting and must be
with newly minted bitcoins
and must be avoided
shows that the total
must be avoided whenever
that the total duration
using fec requires that
the process of creating
the total duration of
process of creating a
fec requires that each
of creating a block
be avoided whenever possible
creating a block is
requires that each data
a block is called
total duration of the
block is called mining
duration of the trace
that each data packet
of the trace with
the trace with this
each data packet have
trace with this mfs
with this mfs configuration
and the participants miners
data packet have a
this mfs configuration is
packet have a unique
have a unique identifier
in order to win
a unique identifier that
order to win the
to win the reward
unique identifier that the
cumulative distribution of the
identifier that the receiver
distribution of the multicast
that the receiver can
of the multicast rates
many miners try to
the receiver can use
miners try to generate
the multicast rates for
try to generate blocks
receiver can use to
can use to keep
use to keep track
to keep track of
the system automatically adjusts
keep track of received
system automatically adjusts the
track of received data
but all the fetch
automatically adjusts the difficulty
all the fetch traffic
of received data packets
the fetch traffic is
adjusts the difficulty of
fetch traffic is completed
received data packets and
traffic is completed within
the difficulty of block
data packets and to
difficulty of block generation
packets and to identify
and to identify missing
to identify missing data
identify missing data packets
missing data packets in
such that one block
data packets in a
that one block is
packets in a repair
one block is added
in a repair packet
token roundtrip times for
block is added every
seconds of the start
if we had access
we had access to
had access to end
minutes to the blockchain
this is a significant
is a significant improvement
a significant improvement over
significant improvement over the
this means that each
improvement over the alternative
means that each miner
over the alternative configurations
that each miner seldom
the alternative configurations measured
each miner seldom generates
we could have added
miner seldom generates a
could have added a
seldom generates a block
have added a header
added a header to
a header to each
header to each packet
to each packet with
although its revenue may
each packet with a
its revenue may be
packet with a unique
revenue may be positive
intervals between the subsequent
with a unique sequence
between the subsequent tokens
a unique sequence number
may be positive in
be positive in expectation
seconds of the trace
of the trace are
the trace are taken
trace are taken up
are taken up by
a miner may have
taken up by asynchronously
miner may have to
up by asynchronously writing
may have to wait
by asynchronously writing back
have to wait for
asynchronously writing back file
to wait for an
writing back file updates
wait for an extended
for an extended period
an extended period to
extended period to create
period to create a
in all cases the
to create a block
all cases the traces
create a block and
cases the traces take
a block and earn
the traces take significantly
block and earn the
we intercept traffic transparently
and earn the actual
traces take significantly longer
earn the actual bitcoins
intercept traffic transparently and
take significantly longer than
traffic transparently and need
significantly longer than they
transparently and need to
longer than they originally
than they originally did
they originally did in
originally did in ntfs
route it without modification
it without modification or
clear messages out of
miners form mining pools
messages out of the
without modification or addition
out of the system
where they were mostly
of the system quickly
they were mostly accessing
were mostly accessing the
where all members mine
mostly accessing the local
all members mine concurrently
accessing the local file
data paths should have
the local file system
paths should have rapid
local file system and
members mine concurrently and
file system and therefore
should have rapid data
system and therefore had
mine concurrently and they
and therefore had no
we identify ip packets
concurrently and they share
therefore had no bandwidth
and they share their
had no bandwidth constraints
have rapid data movement
identify ip packets by
rapid data movement as
they share their revenue
data movement as a
ip packets by a
movement as a key
share their revenue whenever
as a key goal
packets by a tuple
the results largely repeat
by a tuple consisting
their revenue whenever one
a tuple consisting of
results largely repeat those
tuple consisting of the
largely repeat those seen
consisting of the source
repeat those seen in
of the source and
those seen in the
revenue whenever one of
seen in the microbenchmarks
the source and destination
whenever one of them
source and destination ip
one of them creates
and destination ip address
of them creates a
them creates a block
to the extent that
the extent that the
we ve already mentioned
extent that the greatest
ve already mentioned that
that the greatest performance
pools are typically implemented
already mentioned that data
the greatest performance improvements
size of the ip
mentioned that data paths
of the ip header
that data paths should
are typically implemented as
data paths should clear
greatest performance improvements are
typically implemented as a
the ip header plus
paths should clear messages
performance improvements are seen
implemented as a pool
ip header plus data
should clear messages quickly
improvements are seen at
as a pool manager
are seen at low
a pool manager and
seen at low bandwidth
pool manager and a
at low bandwidth when
but there are other
low bandwidth when there
there are other important
bandwidth when there is
are other important forms
when there is high
other important forms of
there is high read
important forms of delay
manager and a cohort
and a checksum over
and a cohort of
a checksum over the
a cohort of miners
checksum over the ip
over the ip data
the ip data payload
such as in the
most situations in which
the pool manager joins
situations in which qsm
the checksum over the
in which qsm developed
pool manager joins the
which qsm developed convoy
checksum over the payload
as in the mostly
over the payload is
manager joins the bitcoin
the payload is necessary
joins the bitcoin system
payload is necessary since
like behavior or oscillatory
the bitcoin system as
writes trace where there
bitcoin system as a
trace where there is
system as a single
where there is an
as a single miner
behavior or oscillatory throughput
is necessary since the
or oscillatory throughput can
necessary since the ip
oscillatory throughput can be
since the ip identification
instead of generating proof
the ip identification field
of generating proof of
ip identification field is
generating proof of work
identification field is only
throughput can be traced
can be traced to
decrease in the time
be traced to design
in the time spent
it outsources the work
traced to design decisions
outsources the work to
the time spent to
the work to the
to design decisions that
work to the miners
time spent to read
design decisions that caused
spent to read all
bits long and a
decisions that caused scheduling
long and a single
to read all the
and a single pair
in order to evaluate
a single pair of
read all the files
that caused scheduling jitter
order to evaluate the
single pair of end
to evaluate the miners
caused scheduling jitter or
evaluate the miners efforts
scheduling jitter or allowed
jitter or allowed some
or allowed some form
allowed some form of
hosts communicating at high
some form of priority
even at the higher
the pool manager accepts
at the higher bandwidth
communicating at high speeds
the higher bandwidth of
form of priority inversion
pool manager accepts partial
of priority inversion to
at high speeds will
priority inversion to occur
manager accepts partial proof
high speeds will use
accepts partial proof of
speeds will use the
partial proof of work
will use the same
proof of work and
delaying a crucial message
of work and estimates
use the same identifier
work and estimates each
a crucial message behind
and estimates each miner
crucial message behind a
the same identifier for
message behind a less
estimates each miner s
behind a less important
same identifier for different
a less important one
each miner s power
identifier for different data
there is a decrease
miner s power according
is a decrease of
for different data packets
s power according to
implications included the following
different data packets within
power according to the
data packets within a
according to the rate
packets within a fairly
to the rate with
within a fairly short
the rate with which
a fairly short interval
rate with which it
fairly short interval unless
with which it submits
short interval unless the
which it submits such
interval unless the checksum
it submits such partial
unless the checksum is
submits such partial proof
the checksum is added
such partial proof of
checksum is added to
partial proof of work
the mostlyreads trace is
is added to differentiate
mostlyreads trace is not
added to differentiate between
event handlers should be
to differentiate between them
trace is not much
handlers should be short
is not much affected
when a miner generates
not much affected by
a miner generates a
much affected by changes
miner generates a full
affected by changes in
generates a full proof
by changes in the
a full proof of
changes in the configuration
full proof of work
unique identifiers result in
identifiers result in garbled
result in garbled recovery
in garbled recovery by
it sends it to
garbled recovery by maelstrom
sends it to the
we struggled to make
it to the pool
although there is a
struggled to make the
to the pool manager
there is a slight
to make the overall
an event which will
the pool manager which
is a slight decrease
event which will be
make the overall behavior
pool manager which publishes
which will be caught
a slight decrease in
manager which publishes this
will be caught by
slight decrease in both
which publishes this proof
the overall behavior of
publishes this proof of
be caught by higher
this proof of work
overall behavior of the
proof of work to
caught by higher level
of work to the
behavior of the system
by higher level checksums
work to the bitcoin
of the system as
higher level checksums designed
to the bitcoin system
the system as predictable
level checksums designed to
decrease in both read
system as predictable as
in both read and
checksums designed to deal
as predictable as possible
both read and write
the pool manager thus
predictable as possible not
designed to deal with
pool manager thus receives
as possible not a
to deal with tranmission
manager thus receives the
possible not a trivial
read and write times
thus receives the full
and write times for
not a trivial task
write times for prioritised
receives the full revenue
times for prioritised asynchronous
a trivial task in
for prioritised asynchronous writeback
the full revenue of
trivial task in configurations
deal with tranmission errors
task in configurations where
full revenue of the
with tranmission errors on
in configurations where hundreds
tranmission errors on commodity
revenue of the block
errors on commodity networks
configurations where hundreds of
on commodity networks and
where hundreds of processes
of the block and
hundreds of processes might
commodity networks and hence
of processes might be
the block and distributes
processes might be multicasting
networks and hence does
might be multicasting in
block and distributes it
be multicasting in thousands
and hence does not
and distributes it fairly
hence does not have
distributes it fairly according
does not have significant
it fairly according to
multicasting in thousands of
fairly according to its
not have significant consequences
according to its members
in thousands of overlapping
to its members power
thousands of overlapping groups
have significant consequences unless
significant consequences unless it
consequences unless it occurs
load trace performs best
unless it occurs frequently
trace performs best with
many of the pools
performs best with uniform
of the pools are
by keeping event handlers
the pools are open
best with uniform asynchronous
keeping event handlers short
with uniform asynchronous writeback
event handlers short and
the kernel version of
handlers short and predictable
pools are open they
short and predictable and
kernel version of maelstrom
are open they allow
and predictable and eliminating
we once again attribute
version of maelstrom can
once again attribute this
predictable and eliminating the
again attribute this to
and eliminating the need
attribute this to inefficiency
eliminating the need for
this to inefficiency in
the need for locking
to inefficiency in the
of maelstrom can generate
open they allow any
maelstrom can generate up
they allow any miner
inefficiency in the rpc
allow any miner to
we obtained a more
in the rpc protocol
obtained a more predictable
any miner to join
a more predictable system
miner to join them
can generate up to
to join them using
more predictable system and
join them using a
generate up to a
them using a public
since under extremely heavy
using a public internet
up to a gigabit
a public internet interface
predictable system and were
to a gigabit per
under extremely heavy load
a gigabit per second
system and were able
gigabit per second of
extremely heavy load and
per second of data
and were able to
second of data and
were able to eliminate
of data and fec
able to eliminate multithreading
data and fec traffic
heavy load and high
such open pools are
load and high bandwidth
open pools are susceptible
and high bandwidth it
pools are susceptible to
high bandwidth it performs
are susceptible to the
bandwidth it performs better
with the associated context
it performs better when
the associated context switching
performs better when all
associated context switching and
better when all messages
context switching and locking
when all messages have
switching and locking overheads
all messages have the
susceptible to the classical
messages have the same
with the input data
to the classical block
the input data rate
the classical block withholding
input data rate depending
classical block withholding attack
have the same priority
data rate depending on
rate depending on the
depending on the encoding
on the encoding rate
a file group is
file group is implemented
group is implemented as
we were able to
here we encounter a
is implemented as a
we encounter a tension
were able to saturate
encounter a tension between
implemented as a special
a tension between two
able to saturate the
tension between two goals
as a special type
to saturate the outgoing
where a miner sends
a special type of
saturate the outgoing card
special type of file
the outgoing card at
type of file within
outgoing card at rates
a miner sends only
card at rates as
from a memory footprint
at rates as high
miner sends only partial
of file within the
sends only partial proof
file within the mfs
a memory footprint perspective
rates as high as
only partial proof of
within the mfs file
partial proof of work
the mfs file system
proof of work to
one might prefer not
of work to the
might prefer not to
work to the pool
prefer not to pull
to the pool manager
not to pull in
the pool manager and
to pull in a
with its own file
pull in a message
its own file identifier
in a message until
pool manager and discards
a message until qsm
manager and discards full
message until qsm can
and discards full proof
until qsm can process
discards full proof of
qsm can process it
but not attached to
full proof of work
not attached to any
attached to any specific
to any specific directory
but in a datacenter
in a datacenter or
with cpu overload occurring
a datacenter or cluster
cpu overload occurring at
the file group a
due to the partial
file group a file
to the partial proof
group a file belongs
the partial proof of
a file belongs to
partial proof of work
most message loss occurs
proof of work it
message loss occurs in
of work it sends
loss occurs in the
work it sends to
occurs in the operating
it sends to the
in the operating system
sends to the pool
is one of its
one of its attributes
not on the network
the miner is considered
miner is considered a
is considered a regular
the mfs prefetching subsystem
considered a regular pool
where each incoming data
hence message loss rates
each incoming data packet
a regular pool member
incoming data packet had
message loss rates soar
data packet had to
regular pool member and
packet had to be
loss rates soar if
had to be xored
pool member and the
mfs prefetching subsystem derives
member and the pool
rates soar if we
and the pool can
soar if we leave
the pool can estimate
prefetching subsystem derives much
pool can estimate its
if we leave messages
subsystem derives much of
can estimate its power
we leave messages on
derives much of its
leave messages on input
much of its effectiveness
messages on input sockets
buffering requirements at the
of its effectiveness from
requirements at the receive
on input sockets for
its effectiveness from being
input sockets for long
the attacker shares the
effectiveness from being combined
attacker shares the revenue
from being combined with
shares the revenue obtained
being combined with prioritised
the revenue obtained by
combined with prioritised rpcs
revenue obtained by the
obtained by the other
by the other pool
incoming data packets are
the other pool members
data packets are buffered
while the prefetching algorithm
packets are buffered so
the prefetching algorithm in
but does not contribute
prefetching algorithm in mfs
are buffered so that
algorithm in mfs is
buffered so that they
control the event processing
in mfs is straightforward
the event processing order
so that they can
it reduces the revenue
that they can be
reduces the revenue of
they can be used
the revenue of the
can be used in
it can still make
revenue of the other
be used in conjunction
of the other members
can still make bad
used in conjunction with
still make bad decisions
in conjunction with xors
make bad decisions without
conjunction with xors to
but also its own
with xors to recover
bad decisions without a
xors to recover missing
decisions without a large
to recover missing data
without a large overall
recover missing data packets
we provide necessary background
a large overall performance
provide necessary background on
large overall performance penalty
necessary background on the
overall performance penalty because
background on the bitcoin
performance penalty because the
on the bitcoin protocol
and the imposition of
penalty because the interference
the imposition of an
because the interference of
imposition of an internal
any received xor that
of an internal event
the interference of prefetching
an internal event processing
pools and the classical
internal event processing prioritization
interference of prefetching with
received xor that is
of prefetching with other
and the classical block
prefetching with other file
the classical block withholding
with other file system
small delays add up
classical block withholding attack
other file system activity
block withholding attack in
file system activity is
withholding attack in section
system activity is minimised
attack in section ii
delays add up in
xor that is missing
add up in large
that is missing more
up in large systems
is missing more than
in the same way
missing more than one
the same way that
more than one data
same way that some
than one data packet
and specify our model
way that some local
specify our model in
one data packet is
tight control over event
data packet is stored
our model in section
packet is stored temporarily
that some local file
model in section iii
control over event processing
some local file systems
over event processing largely
local file systems execute
event processing largely eliminated
file systems execute speculative
processing largely eliminated convoy
for a broader view
in case all but
systems execute speculative operations
case all but one
execute speculative operations to
all but one of
speculative operations to improve
but one of the
operations to improve performance
largely eliminated convoy effects
a broader view of
one of the missing
broader view of the
of the missing packets
view of the protocol
the missing packets are
eliminated convoy effects and
missing packets are received
of the protocol and
packets are received later
convoy effects and oscillatory
are received later or
the protocol and ecosystem
received later or recovered
effects and oscillatory throughput
later or recovered through
protocol and ecosystem the
or recovered through other
and oscillatory throughput problems
recovered through other xors
and ecosystem the reader
ecosystem the reader may
the reader may refer
mfs makes use of
reader may refer to
makes use of the
allowing the recovery of
may refer to the
the recovery of the
refer to the survey
recovery of the remaining
to the survey by
use of the speculative
the survey by bonneau
of the remaining missing
survey by bonneau et
of the speculative communication
by bonneau et al
the remaining missing packet
the speculative communication of
remaining missing packet from
act on fresh state
speculative communication of prioritised
missing packet from this
communication of prioritised rpcs
packet from this xor
of prioritised rpcs in
prioritised rpcs in the
rpcs in the hope
many inefficiencies can be
in the hope of
inefficiencies can be traced
the hope of achieving
in practice we stored
hope of achieving a
can be traced to
of achieving a benefit
practice we stored data
be traced to situations
achieving a benefit through
we stored data and
a benefit through prefetching
traced to situations in
benefit through prefetching files
stored data and xor
to situations in which
data and xor packets
situations in which one
and xor packets in
in which one node
xor packets in double
which one node takes
in this work we
packets in double buffered
this work we analyze
one node takes action
work we analyze block
in double buffered red
we analyze block withholding
double buffered red black
analyze block withholding attacks
buffered red black trees
block withholding attacks among
red black trees for
withholding attacks among pools
node takes action on
takes action on the
mfs prefetching implementation the
action on the basis
prefetching implementation the mfs
on the basis of
implementation the mfs cache
the basis of stale
a pool that employs
basis of stale state
the mfs cache manager
of stale state information
pool that employs the
mfs cache manager incorporates
stale state information from
cache manager incorporates a
that employs the pool
manager incorporates a small
state information from some
incorporates a small prefetching
information from some other
employs the pool block
from some other node
a small prefetching module
the pool block withholding
pool block withholding attack
block withholding attack registers
withholding attack registers with
attack registers with the
which can be optionally
triggering redundant retransmissions or
can be optionally enabled
registers with the victim
be optionally enabled at
redundant retransmissions or other
optionally enabled at start
with the victim pool
retransmissions or other overheads
the victim pool as
victim pool as a
entries this occupies around
pool as a regular
as a regular miner
the pull architecture has
when it is initialised
pull architecture has the
architecture has the secondary
has the secondary benefit
it receives tasks from
the secondary benefit of
receives tasks from the
a prefetching thread starts
secondary benefit of letting
tasks from the victim
prefetching thread starts and
benefit of letting us
from the victim pool
thread starts and initiates
of letting us delay
the victim pool and
starts and initiates prefetch
victim pool and transfers
the repair bins in
letting us delay the
and initiates prefetch requests
pool and transfers them
repair bins in the
us delay the preparation
initiates prefetch requests in
and transfers them to
bins in the layered
transfers them to some
prefetch requests in parallel
delay the preparation of
requests in parallel with
them to some of
in parallel with the
the preparation of status
parallel with the main
to some of its
with the main activity
some of its own
the main activity of
of its own miners
main activity of the
preparation of status packets
in the layered interleaving
of status packets until
activity of the cache
status packets until they
of the cache manager
we call these infiltrating
packets until they are
call these infiltrating miners
the layered interleaving scheme
until they are about
layered interleaving scheme store
they are about to
interleaving scheme store incrementally
the core component of
are about to be
scheme store incrementally computed
core component of the
about to be transmitted
and the mining power
store incrementally computed xors
the mining power spent
incrementally computed xors and
component of the cache
computed xors and lists
mining power spent by
of the cache manager
xors and lists of
power spent by a
and lists of data
spent by a pool
lists of data packet
by a pool the
of data packet headers
a pool the infiltration
the cache manager alerts
pool the infiltration rate
conclusions the premise of
cache manager alerts the
the premise of our
without the data packet
manager alerts the prefetching
the data packet payloads
premise of our work
alerts the prefetching module
when the attacking pool
of our work is
the prefetching module every
the attacking pool s
prefetching module every time
resulting in low storage
attacking pool s infiltrating
module every time an
in low storage overheads
our work is that
pool s infiltrating miners
every time an application
s infiltrating miners deliver
time an application reads
infiltrating miners deliver partial
work is that developers
miners deliver partial proofs
an application reads or
is that developers of
low storage overheads for
application reads or writes
storage overheads for each
that developers of services
overheads for each layer
reads or writes a
for each layer that
or writes a file
each layer that rise
developers of services intended
layer that rise linearly
deliver partial proofs of
of services intended to
partial proofs of work
that rise linearly with
by calling the file
services intended to run
rise linearly with the
intended to run on
calling the file access
to run on clustered
the attacker transfers them
run on clustered platforms
attacker transfers them to
on clustered platforms desire
the file access routine
transfers them to the
clustered platforms desire the
them to the victim
platforms desire the productivity
to the victim pool
desire the productivity and
linearly with the value
the productivity and robustness
with the value of
this routine checks whether
the value of the
productivity and robustness benefits
letting the attacked pool
and robustness benefits of
the attacked pool estimate
robustness benefits of managed
attacked pool estimate their
benefits of managed environments
pool estimate their power
routine checks whether the
value of the interleave
checks whether the file
whether the file belongs
the file belongs to
file belongs to a
when the infiltrating miners
and need replication tools
the infiltrating miners deliver
need replication tools integrated
infiltrating miners deliver a
belongs to a file
miners deliver a full
replication tools integrated with
deliver a full proof
to a file group
a full proof of
tools integrated with those
full proof of work
a file group if
the memory footprint for
file group if not
integrated with those environments
memory footprint for a
footprint for a longrunning
for a longrunning proxy
the attacking pool discards
a longrunning proxy was
attacking pool discards it
the access is ignored
building such tools so
longrunning proxy was around
such tools so posed
tools so posed challenges
so posed challenges to
this attack affects the
posed challenges to us
attack affects the revenues
challenges to us as
affects the revenues of
to us as protocol
the revenues of the
us as protocol and
revenues of the pools
prefetching it is a
of the pools in
as protocol and system
mb in our experiments
protocol and system designers
the pools in several
it is a member
pools in several ways
is a member of
a member of a
member of a file
of a file group
which were the primary
were the primary focus
the victim pool s
the primary focus of
victim pool s effective
primary focus of our
other performance enhancing roles
the group is put
focus of our paper
group is put at
performance enhancing roles maelstrom
is put at the
pool s effective mining
put at the head
s effective mining rate
at the head of
enhancing roles maelstrom appliances
the head of the
a central insight is
roles maelstrom appliances can
head of the prefetch
effective mining rate is
of the prefetch list
central insight is that
mining rate is unchanged
maelstrom appliances can optionally
insight is that high
appliances can optionally aggregate
can optionally aggregate small
the prefetch thread periodically
but its total revenue
optionally aggregate small subkilobyte
its total revenue is
performance protocols running in
total revenue is divided
protocols running in managed
revenue is divided among
aggregate small subkilobyte packets
prefetch thread periodically examines
running in managed settings
is divided among more
in managed settings need
divided among more miners
managed settings need to
thread periodically examines the
small subkilobyte packets from
periodically examines the prefetching
settings need to maintain
examines the prefetching is
the attacker s mining
subkilobyte packets from different
the prefetching is commonly
need to maintain the
prefetching is commonly used
to maintain the smallest
is commonly used to
maintain the smallest possible
attacker s mining power
the smallest possible memory
commonly used to improve
smallest possible memory footprint
used to improve the
packets from different flows
to improve the performance
s mining power is
improve the performance of
mining power is reduced
the performance of lo
from different flows into
different flows into larger
flows into larger ones
into larger ones for
since some of its
group at the head
some of its miners
at the head of
of its miners are
the head of the
larger ones for better
its miners are used
ones for better communication
miners are used for
head of the list
are used for block
for better communication efficiency
used for block withholding
better communication efficiency over
communication efficiency over the
efficiency over the long
if the group file
the group file for
but it earns additional
group file for the
it earns additional revenue
file for the group
plication of this principle
for the group is
earns additional revenue through
the group is cal
additional revenue through its
group is cal file
revenue through its infiltration
is cal file systems
through its infiltration of
qsm achieves scalability and
its infiltration of the
in split flow control
infiltration of the other
split flow control mode
of the other pool
as well as distributed
achieves scalability and stability
well as distributed file
flow control mode they
as distributed file systems
scalability and stability even
control mode they can
and stability even at
mode they can perform
stability even at very
they can perform send
even at very high
at very high loads
the total effective mining
total effective mining power
side buffering of in
not in the cache
effective mining power in
an unexpected side effect
mining power in the
unexpected side effect of
power in the system
flight data for multi
in the system is
side effect of building
the system is reduced
it retrieves it from
effect of building qsm
retrieves it from the
of building qsm in
it from the server
building qsm in windows
causing the bitcoin protocol
qsm in windows was
gigabyte flows that exceed
in windows was that
flows that exceed the
the bitcoin protocol to
that exceed the sending
windows was that by
exceed the sending end
bitcoin protocol to reduce
then it scans the
protocol to reduce the
was that by integrating
to reduce the difficulty
it scans the in
that by integrating our
scans the in a
host s buffering capacity
the in a file
by integrating our system
in a file system
integrating our system tightly
a file system with
our system tightly with
file system with whole
system tightly with the
taking all these factors
tightly with the platform
all these factors into
these factors into account
maelstrom appliances can act
appliances can act as
can act as multicast
we created a new
act as multicast forwarding
created a new kind
as multicast forwarding nodes
a new kind of
we observe that a
new kind of live
a mechanism is required
kind of live distributed
observe that a pool
of live distributed objects
that a pool might
mechanism is required files
a pool might be
appliances send multicast packets
is required files in
pool might be able
send multicast packets to
might be able to
multicast packets to each
be able to increase
packets to each other
required files in the
to each other across
able to increase its
abstract data types that
to increase its revenue
data types that form
increase its revenue by
types that form groups
its revenue by attacking
files in the group
revenue by attacking other
each other across the
by attacking other pools
in the group in
other across the long
the group in order
group in order until
in order until it
and that are updated
order until it finds
that are updated using
each pool therefore makes
are updated using qsm
until it finds the
pool therefore makes a
updated using qsm multicasts
therefore makes a choice
and use ip multicast
makes a choice of
it finds the first
a choice of whether
finds the first one
choice of whether to
these look natural to
of whether to attack
look natural to the
the first one which
natural to the windows
whether to attack each
to the windows user
to attack each of
first one which is
attack each of the
one which is not
each of the other
which is not to
of the other pools
is not to determine
the other pools in
such an object changes
other pools in the
an object changes faster
pools in the system
to spread them within
not to determine appropriate
spread them within their
object changes faster than
to determine appropriate prefetching
changes faster than the
them within their data
faster than the average
within their data centers
than the average windows
and with what infiltration
the average windows object
with what infiltration rate
determine appropriate prefetching hints
but the same basic
this gives rise to
the same basic mechanisms
earlier work in file
appliances can take on
same basic mechanisms can
work in file in
gives rise to the
can take on other
basic mechanisms can support
take on other existing
mechanisms can support them
in file in the
rise to the pool
on other existing roles
file in the cache
other existing roles in
to the pool game
existing roles in the
and the component integration
roles in the data
the component integration environment
in the data center
we specify this game
specify this game and
this game and provide
and issues a prefetch
acting as security and
game and provide initial
as security and vpn
and provide initial analysis
security and vpn gateways
provide initial analysis in
and vpn gateways and
initial analysis in section
issues a prefetch request
analysis in section iv
vpn gateways and as
a prefetch request or
gateways and as conventional
extends seamlessly to encompass
prefetch request or system
seamlessly to encompass them
and as conventional performance
request or system prefetching
as conventional performance enhancing
in section v we
conventional performance enhancing proxies
or system prefetching has
section v we analyze
although a great deal
system prefetching has used
a great deal of
v we analyze the
great deal of additional
prefetching has used clustering
deal of additional work
has used clustering to
of additional work is
we analyze the scenario
additional work is needed
used clustering to derive
analyze the scenario where
clustering to derive file
the scenario where exactly
to derive file groups
scenario where exactly two
derive file groups from
qsm should eventually enable
file groups from validation
where exactly two of
should eventually enable casual
groups from validation request
exactly two of the
from validation request for
eventually enable casual use
validation request for it
two of the pools
enable casual use of
of the pools take
casual use of live
the pools take part
use of live objects
pools take part in
of live objects not
take part in the
live objects not just
part in the game
objects not just in
in the game and
if all the files
the game and only
not just in datacenters
all the files are
just in datacenters but
game and only one
in datacenters but also
and only one can
e valuation we evaluated
only one can attack
datacenters but also on
one can attack the
valuation we evaluated maelstrom
can attack the other
the files are valid
we evaluated maelstrom on
but also on desktops
evaluated maelstrom on the
also on desktops in
maelstrom on the emulab
on desktops in wan
on the emulab testbed
files are valid and
the emulab testbed at
desktops in wan settings
emulab testbed at utah
are valid and are
valid and are in
the attacker can always
and are in the
attacker can always increase
are in the cache
can always increase its
in the cache access
opening the door to
the cache access statistics
always increase its revenue
the door to a
increase its revenue by
door to a new
its revenue by attacking
to a new style
a new style of
new style of distributed
style of distributed programming
we conclude that in
conclude that in the
that in the general
in the general case
the current version of
current version of qsm
version of qsm is
of qsm is stable
for all the experiments
qsm is stable in
with any number of
is stable in cluster
any number of pools
stable in cluster settings
in cluster settings and
we used a dumbbell
predicted future file accesses
used a dumbbell topology
future file accesses from
a dumbbell topology of
file accesses from cache
dumbbell topology of two
topology of two clusters
has a growing community
of two clusters of
a growing community of
two clusters of nodes
the group is moved
clusters of nodes connected
group is moved to
of nodes connected via
is moved to the
nodes connected via routing
moved to the end
connected via routing nodes
to the end of
attacks is not a
growing community of users
via routing nodes with
the end of the
routing nodes with a
is not a nash
end of the prefetch
nodes with a high
looking to the future
of the prefetch list
not a nash equilibrium
latency link in between
we plan to scale
link in between them
plan to scale qsm
to scale qsm into
scale qsm into wan
qsm into wan settings
section vi deals with
designed to emulate the
vi deals with the
to emulate the setup
deals with the case
emulate the setup in
with the case of
the setup in figure
the case of two
to support a wider
case of two pools
support a wider range
a wider range of
wider range of multicast
range of multicast reliability
of multicast reliability properties
or allowed applications to
where each can attack
allowed applications to specify
each can attack the
applications to specify prefetch
can attack the other
and ran the proxy
and to introduce a
ran the proxy code
to introduce a gossip
the proxy code on
introduce a gossip infrastructure
proxy code on the
a gossip infrastructure that
code on the routers
gossip infrastructure that would
the thread rechecks the
analysis becomes more complicated
infrastructure that would support
thread rechecks the head
becomes more complicated in
rechecks the head of
more complicated in two
the head of the
complicated in two ways
head of the list
that would support configuration
of the list ing
would support configuration discovery
the list ing hints
support configuration discovery and
list ing hints explicitly
configuration discovery and other
discovery and other self
the revenue of each
revenue of each pool
of each pool affects
each pool affects the
show the performance of
pool affects the revenue
the performance of the
affects the revenue of
performance of the kernel
the revenue of the
of the kernel version
revenue of the other
the kernel version at
of the other through
kernel version at gigabit
the other through the
version at gigabit speeds
other through the infiltrating
live objects pose a
through the infiltrating miners
objects pose a protocol
pose a protocol design
a protocol design challenge
the remainder of the
remainder of the graphs
we prove that for
of the graphs show
prove that for a
the graphs show the
they give rise to
graphs show the performance
that for a static
show the performance of
give rise to irregular
for a static choice
rise to irregular patterns
a static choice of
to irregular patterns of
the performance of the
irregular patterns of overlapping
static choice of infiltration
patterns of overlapping multicast
performance of the user
of overlapping multicast groups
choice of infiltration rates
to find the next
of infiltration rates the
find the next file
infiltration rates the pool
the next file to
rates the pool revenues
space version at slower
the pool revenues converge
version at slower speeds
next file to prefetch
oriented state aggregation mechanisms
state aggregation mechanisms will
to emulate the mtu
a new group may
emulate the mtu difference
new group may now
the mtu difference between
group may now be
once one pool changes
aggregation mechanisms will need
one pool changes its
mechanisms will need to
pool changes its infiltration
will need to be
changes its infiltration rate
need to be redesigned
its infiltration rate of
may now be at
infiltration rate of the
now be at the
rate of the other
be at the inter
mtu difference between the
we have an idea
difference between the long
have an idea for
an idea for solving
idea for solving this
the latter may prefer
file dependencies can also
latter may prefer to
dependencies can also be
may prefer to change
can also be used
prefer to change its
haul link and the
to change its infiltration
link and the data
change its infiltration rate
and the data center
its infiltration rate of
recovery would be performed
infiltration rate of the
also be used as
the data center network
be used as a
would be performed by
used as a source
rate of the former
be performed by selecting
as a source of
performed by selecting a
a source of hints
by selecting a subset
selecting a subset of
therefore the game itself
a subset of nodes
the game itself takes
subset of nodes that
game itself takes multiple
head of the list
of nodes that form
of the list as
itself takes multiple rounds
the list as a
takes multiple rounds to
we set an mtu
nodes that form a
set an mtu of
list as a result
that form a clean
multiple rounds to converge
form a clean overlay
as a result of
a clean overlay structure
a result of further
result of further application
of further application accesses
further application accesses to
we show analytically that
application accesses to files
show analytically that the
rather than just treating
analytically that the game
than just treating every
that the game has
just treating every single
the game has a
treating every single receiver
game has a single
every single receiver as
bytes on the network
single receiver as a
has a single nash
it may be known
receiver as a member
may be known that
as a member of
on the network connecting
a member of a
be known that a
member of a recovery
the network connecting the
a single nash equilibrium
of a recovery region
single nash equilibrium and
network connecting the end
nash equilibrium and numerically
known that a certain
equilibrium and numerically study
that a certain shared
and numerically study the
a certain shared library
numerically study the equilibrium
certain shared library is
study the equilibrium points
whether this can really
the equilibrium points for
this can really scale
equilibrium points for different
can really scale remains
points for different pool
shared library is reprefetch
hosts to the proxy
library is reprefetch requests
to the proxy and
really scale remains to
for different pool sizes
scale remains to be
the proxy and an
is reprefetch requests are
proxy and an mtu
remains to be seen
reprefetch requests are similar
and an mtu of
for pools smaller than
requests are similar to
are similar to regular
similar to regular fetch
to regular fetch requests
regular fetch requests for
fetch requests for files
quired to run a
to run a text
run a text editor
bytes on the long
in this case it
at the equilibrium point
this case it would
the equilibrium point both
haul link between proxies
equilibrium point both pools
case it would be
point both pools earn
it would be advantageous
both pools earn less
the only exception is
would be advantageous with
only exception is figure
pools earn less than
be advantageous with the
earn less than they
advantageous with the exception
less than they would
with the exception that
than they would have
the exception that they
they would have in
exception that they are
would have in the
that they are issued
have in the nonequilibrium
they are issued at
in the nonequilibrium no
where we maintained equal
are issued at the
we maintained equal mtus
issued at the lowest
maintained equal mtus of
at the lowest level
the lowest level of
lowest level of prito
level of prito retrieve
of prito retrieve the
prito retrieve the shared
retrieve the shared library
the shared library from
shared library from the
since pools can decide
library from the server
pools can decide to
from the server as
can decide to start
the server as well
decide to start or
server as well as
to start or stop
as well as retriev
bytes on both links
start or stop attacking
or stop attacking at
stop attacking at any
attacking at any point
all other rpc traffic
this can be modeled
other rpc traffic takes
all the experiments are
can be modeled as
rpc traffic takes precedence
the experiments are done
traffic takes precedence over
be modeled as the
takes precedence over a
experiments are done with
modeled as the miner
are done with maelstrom
precedence over a prefetch
done with maelstrom using
over a prefetch rpc
with maelstrom using end
as the miner s
the miner s dilemma
miner s dilemma an
s dilemma an instance
ing the text editor
dilemma an instance of
the text editor executable
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
attacking is the dominant
is the dominant strategy
the dominant strategy in
dominant strategy in each
strategy in each iteration
as shown in table
design and implementation of
and implementation of a
implementation of a reliable
of a reliable group
but if the pools
a reliable group communication
if the pools can
reliable group communication toolkit
the pools can agree
group communication toolkit for
pools can agree not
communication toolkit for java
can agree not to
agree not to attack
and only one tion
only one tion such
which illustrates the performance
one tion such as
illustrates the performance of
both benefit in the
the performance of split
benefit in the long
tion such as the
in the long run
performance of split mode
such as the operating
of split mode flow
as the operating system
split mode flow control
the operating system s
operating system s database
system s database of
s database of installed
database of installed software
we address in section
of installed software prefetch
address in section vii
installed software prefetch is
in section vii the
software prefetch is made
section vii the case
prefetch is made at
vii the case where
is made at a
the case where the
made at a time
case where the participants
where the participants are
the participants are an
participants are an arbitrary
are an arbitrary number
this is more a
an arbitrary number of
is more a matter
arbitrary number of identical
more a matter of
number of identical pools
a matter of implementapackages
show that commodity tcp
there exists a symmetric
ip throughput collapses in
exists a symmetric equilibrium
throughput collapses in the
a symmetric equilibrium in
collapses in the presence
specified dependency information tion
symmetric equilibrium in which
dependency information tion convenience
equilibrium in which each
information tion convenience than
in the presence of
tion convenience than a
in which each participating
convenience than a design
the presence of non
which each participating pool
than a design decision
each participating pool attacks
participating pool attacks each
pool attacks each of
attacks each of the
each of the other
other work has shown
of the other participating
work has shown can
the other participating pools
and that maelstrom successfully
has shown can be
that maelstrom successfully masks
shown can be used
maelstrom successfully masks loss
successfully masks loss and
as in the minority
masks loss and prevents
in the minority two
loss and prevents this
and prevents this collapse
the benefits initiating multiple
prevents this collapse from
design and evaluation of
this collapse from occurring
benefits initiating multiple concurrent
and evaluation of a
evaluation of a wide
initiating multiple concurrent prefetches
multiple concurrent prefetches from
here too at equilibrium
concurrent prefetches from differany
too at equilibrium all
area event notification service
at equilibrium all pools
prefetches from differany of
equilibrium all pools earn
from differany of these
all pools earn less
differany of these techniques
pools earn less than
shows the performance of
earn less than with
of these techniques could
less than with the
the performance of the
acm transactions on computer
performance of the userspace
transactions on computer systems
of the userspace version
than with the no
the userspace version on
these techniques could be
userspace version on a
techniques could be used
could be used to
be used to derive
used to derive hints
to derive hints for
derive hints for use
hints for use ent
for use ent servers
our results imply that
results imply that block
mbps link and figure
imply that block withholding
that block withholding by
block withholding by pools
withholding by pools leads
by pools leads to
pools leads to an
leads to an unfavorable
to an unfavorable equilibrium
shows the kernel version
the kernel version on
kernel version on a
mfs does not currently
does not currently make
due to the anonymity
not currently make use
to the anonymity of
currently make use of
the anonymity of miners
make use of timeouts
the experiment in each
use of timeouts by
experiment in each case
of timeouts by the
in each case involves
timeouts by the mfs
each case involves running
by the mfs prefetching
case involves running iperf
the mfs prefetching subsystem
a single pool might
single pool might be
pool might be tempted
might be tempted to
be tempted to attack
our evaluation uses hand
leading the other pools
the other pools to
other pools to attack
pools to attack as
to attack as well
as we have noted
we have noted earlier
flows from one node
from one node to
the implications might be
one node to another
implications might be devastating
node to another across
might be devastating for
to another across the
be devastating for open
another across the long
devastating for open pools
but it could easily
it could easily to
could easily to exspecified
easily to exspecified dependency
to exspecified dependency information
if their revenues are
distance link with and
their revenues are reduced
link with and without
with and without intermediary
which is inaccurate in
and without intermediary maelstrom
is inaccurate in some
without intermediary maelstrom proxies
miners will prefer to
inaccurate in some tended
intermediary maelstrom proxies and
will prefer to form
in some tended to
prefer to form closed
maelstrom proxies and measuring
to form closed pools
some tended to abandon
form closed pools that
proxies and measuring obtained
closed pools that cannot
tended to abandon a
pools that cannot be
and measuring obtained throughput
that cannot be attacked
to abandon a prefetching
cannot be attacked in
measuring obtained throughput while
be attacked in this
abandon a prefetching attempt
attacked in this manner
obtained throughput while varying
a prefetching attempt that
throughput while varying loss
prefetching attempt that does
while varying loss rate
attempt that does not
that does not complete
does not complete cases
though this may be
this may be conceived
may be conceived as
left graph on each
be conceived as bad
graph on each figure
conceived as bad news
rather than reimplementing an
as bad news for
than reimplementing an existing
bad news for public
reimplementing an existing hint
news for public mining
for public mining pools
generation in a timely
in a timely manner
on the whole it
the whole it may
whole it may be
it may be good
may be good news
be good news to
good news to the
news to the bitcoin
to the bitcoin system
we focus on the
weight process groups in
focus on the performance
process groups in the
on the performance of
groups in the isis
which prefers small pools
the performance of mfs
the error bars on
performance of mfs with
error bars on the
of mfs with prefetchthe
in the isis system
mfs with prefetchthe main
bars on the graphs
with prefetchthe main complexity
we examine the practicality
prefetchthe main complexity in
examine the practicality of
on the graphs to
the practicality of the
main complexity in implementing
practicality of the attack
the graphs to the
of the attack in
complexity in implementing the
graphs to the left
in implementing the prefetching
the attack in section
implementing the prefetching subing
to the left are
attack in section viii
the left are standard
in section viii and
left are standard errors
section viii and discuss
are standard errors of
viii and discuss implications
standard errors of the
using a deliberately simple
errors of the throughput
and discuss implications and
of the throughput over
a deliberately simple hint
the throughput over ten
discuss implications and model
throughput over ten runs
deliberately simple hint mechanism
implications and model extensions
simple hint mechanism for
and model extensions in
hint mechanism for the
model extensions in section
mechanism for the purposes
extensions in section ix
for the purposes system
the purposes system lies
purposes system lies in
system lies in handling
lies in handling a
in handling a demand
handling a demand fetch
ip s cache of
our contributions are the
s cache of tuning
contributions are the following
cache of tuning parameters
a compulsory fetch to
of tuning parameters to
compulsory fetch to of
tuning parameters to allow
fetch to of evaluation
parameters to allow for
to allow for repeatable
allow for repeatable results
dependencies between files are
between files are conveyed
files are conveyed using
the clients in the
are conveyed using a
definition of the pool
clients in the experiment
conveyed using a service
of the pool game
using a service a
in the experiment are
a service a cache
the pool game where
the experiment are running
pool game where pools
experiment are running tcp
game where pools in
service a cache miss
where pools in a
pools in a proof
ip reno on a
reno on a linux
for a file which
a file which is
ofwork secured system attack
file which is already
secured system attack one
which is already being
system attack one another
is already being prefetched
attack one another with
one another with a
another with a pool
with a pool block
a pool block withholding
pool block withholding attack
which is a list
is a list of
constructing reliable distributed communication
a list of file
reliable distributed communication systems
list of file identifiers
distributed communication systems with
of file identifiers for
communication systems with corba
file identifiers for the
identifiers for the related
for the related files
in the general case
ieee communications magazine feature
communications magazine feature topic
this conflict arises very
magazine feature topic issue
conflict arises very frequently
the maelstrom parameters used
feature topic issue on
maelstrom parameters used are
topic issue on distributed
parameters used are r
particularly when an appliit
issue on distributed object
attacks is not an
on distributed object computing
is not an equilibrium
when an appliit is
an appliit is assumed
appliit is assumed that
is assumed that after
assumed that after one
that after one file
after one file in
one file in the
file in the group
in the group has
the group has been
group has been accessed
with two minority pools
two minority pools participating
cation performs a fast
performs a fast linear
a fast linear scan
fast linear scan of
the only nash equilibrium
linear scan of files
only nash equilibrium is
scan of files in
nash equilibrium is when
of files in a
equilibrium is when the
files in a file
is when the pools
in a file group
when the pools attack
the pools attack one
pools attack one another
an it becomes advantageous
it becomes advantageous to
and both earn less
becomes advantageous to prefetch
both earn less than
advantageous to prefetch the
earn less than if
to prefetch the remainder
less than if none
prefetch the remainder of
than if none had
if none had attacked
the remainder of the
remainder of the files
of the files in
the files in efficient
files in efficient implementation
miners therefore face the
in efficient implementation of
therefore face the miner
efficient implementation of prefetching
face the miner s
implementation of prefetching requires
the miner s dilemma
of prefetching requires that
prefetching requires that the
requires that the demand
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
repeatedly choosing between attack
choosing between attack and
between attack and no
space version involved running
version involved running a
involved running a single
second iperf flow from
iperf flow from one
with multiple pools of
flow from one node
multiple pools of equal
pools of equal size
from one node to
of equal size there
hierarchical clustering of message
equal size there is
one node to another
size there is a
clustering of message flows
there is a symmetric
node to another with
is a symmetric nash
of message flows in
a symmetric nash equilibrium
message flows in a
to another with and
flows in a multicast
in a multicast data
another with and without
a multicast data dissemination
with and without maelstrom
multicast data dissemination system
and without maelstrom running
where all pools earn
without maelstrom running on
all pools earn less
maelstrom running on the
pools earn less than
running on the routers
earn less than if
on the routers and
less than if none
the routers and measuring
than if none had
routers and measuring throughput
if none had attacked
and measuring throughput while
measuring throughput while varying
throughput while varying the
while varying the random
varying the random loss
the random loss rate
random loss rate on
loss rate on the
rate on the link
on the link and
the link and the
link and the oneway
and the oneway latency
inefficient equilibria for open
equilibria for open pools
to test the kernel
for open pools may
test the kernel version
open pools may serve
the kernel version at
pools may serve the
kernel version at gigabit
may serve the system
version at gigabit speeds
serve the system by
the system by reducing
system by reducing their
by reducing their attraction
reducing their attraction and
we ran eight parallel
their attraction and pushing
ran eight parallel iperf
attraction and pushing miners
eight parallel iperf flows
and pushing miners towards
parallel iperf flows from
pushing miners towards smaller
iperf flows from one
miners towards smaller closed
flows from one node
towards smaller closed pools
from one node to
one node to another
node to another for
optimizing buffer management for
buffer management for reliable
management for reliable multicast
the classical block withholding
proceedings of the international
classical block withholding attack
of the international conference
block withholding attack is
the international conference on
withholding attack is old
international conference on dependable
attack is old as
conference on dependable systems
is old as pools
on dependable systems and
old as pools themselves
dependable systems and networks
the curves obtained from
curves obtained from the
but its use by
obtained from the two
its use by pools
from the two versions
use by pools has
the two versions are
by pools has not
two versions are almost
pools has not been
versions are almost identical
has not been suggested
not been suggested until
been suggested until recently
we present both to
present both to show
we overview related attacks
both to show that
overview related attacks and
to show that the
related attacks and prior
show that the kernel
attacks and prior work
and prior work in
that the kernel version
prior work in section
work in section x
the kernel version successfully
kernel version successfully scales
version successfully scales up
successfully scales up the
and conclude with final
scales up the performance
conclude with final remarks
up the performance of
with final remarks in
the performance of the
final remarks in section
performance of the userspace
remarks in section xi
of the userspace version
the userspace version to
userspace version to hundreds
version to hundreds of
to hundreds of megabits
hundreds of megabits of
of megabits of traffic
megabits of traffic per
of traffic per second
p reliminaries b itcoin
reliminaries b itcoin and
b itcoin and p
itcoin and p ooled
and p ooled m
p ooled m ining
ooled m ining bitcoin
m ining bitcoin is
ining bitcoin is a
bitcoin is a distributed
a group membership service
group membership service for
membership service for wans
acm transactions on computer
we show how tcp
transactions on computer systems
ip performance degrades on
performance degrades on a
ms link as the
link as the loss
as the loss rate
the loss rate is
loss rate is increased
rate is increased from
clients use the system
use the system by
the system by issuing
system by issuing transactions
maelstrom masks loss up
and the system s
masks loss up to
the system s only
system s only task
s only task is
only task is to
task is to serialize
is to serialize transactions
without significant throughput degradation
to serialize transactions in
serialize transactions in a
transactions in a single
in a single ledger
with the kernel version
a single ledger and
the kernel version achieving
single ledger and reject
kernel version achieving two
ledger and reject transactions
version achieving two orders
and reject transactions that
achieving two orders of
reject transactions that cannot
two orders of magnitude
transactions that cannot be
orders of magnitude higher
that cannot be serialized
of magnitude higher throughput
cannot be serialized due
magnitude higher throughput that
be serialized due to
higher throughput that conventional
serialized due to conflicts
throughput that conventional tcp
due to conflicts with
to conflicts with previous
conflicts with previous transactions
bitcoin transactions are protected
transactions are protected with
are protected with cryptographic
protected with cryptographic techniques
with cryptographic techniques that
cryptographic techniques that ensure
the graphs on the
techniques that ensure that
graphs on the right
that ensure that only
on the right side
ensure that only the
the right side of
that only the rightful
right side of figures
only the rightful owner
the rightful owner of
rightful owner of a
owner of a bitcoin
of a bitcoin can
a bitcoin can transfer
bitcoin can transfer it
the transaction ledger is
transaction ledger is stored
ledger is stored by
is stored by a
stored by a network
by a network of
a network of miners
network of miners in
of miners in a
ip throughput declining on
miners in a data
throughput declining on a
in a data structure
declining on a link
a data structure caller
on a link of
data structure caller the
a link of increasing
structure caller the blockchain
link of increasing length
of increasing length when
increasing length when subjected
length when subjected to
when subjected to uniform
subjected to uniform loss
to uniform loss rates
uniform loss rates of
revenue for proof of
for proof of work
proof of work the
of work the blockchain
work the blockchain records
the blockchain records the
blockchain records the transactions
records the transactions in
the transactions in units
transactions in units of
in units of blocks
dubbed the genesis block
is defined as part
defined as part of
the top line in
as part of the
top line in the
part of the protocol
line in the graphs
in the graphs is
the graphs is the
graphs is the performance
is the performance of
a valid block contains
the performance of tcp
valid block contains the
block contains the hash
contains the hash of
the hash of the
hash of the previous
of the previous block
ip without loss and
without loss and provides
loss and provides an
and provides an upper
provides an upper bound
the hash of the
an upper bound for
hash of the transactions
upper bound for performance
of the transactions in
bound for performance on
the transactions in the
for performance on the
transactions in the current
performance on the link
in the current block
and a bitcoin address
a bitcoin address which
bitcoin address which is
space and kernel versions
address which is to
which is to be
is to be credited
to be credited with
be credited with a
maelstrom masks packet loss
credited with a reward
masks packet loss and
with a reward for
packet loss and tracks
a reward for generating
loss and tracks the
reward for generating the
and tracks the lossless
for generating the block
tracks the lossless line
the lossless line closely
any miner may add
lagging only when the
miner may add a
only when the link
may add a valid
when the link latency
add a valid block
the link latency is
a valid block to
link latency is low
valid block to the
latency is low and
block to the chain
is low and tcp
to the chain by
ip s throughput is
s throughput is very
throughput is very high
proving that it has
that it has spent
it has spent a
has spent a certain
spent a certain amount
a certain amount of
certain amount of work
amount of work and
of work and publishing
work and publishing the
and publishing the block
publishing the block with
the block with the
block with the proof
with the proof over
the proof over an
proof over an overlay
over an overlay network
an overlay network to
overlay network to all
network to all other
to all other miners
when a miner creates
a miner creates a
miner creates a block
it is compensated for
is compensated for its
compensated for its efforts
for its efforts with
its efforts with bitcoins
this compensation includes a
compensation includes a per
transaction fee paid by
fee paid by the
paid by the users
by the users whose
the users whose transactions
users whose transactions are
whose transactions are included
and an amount of
an amount of minted
amount of minted bitcoins
of minted bitcoins that
minted bitcoins that are
bitcoins that are thus
that are thus introduced
are thus introduced into
thus introduced into the
introduced into the system
the work which a
work which a miner
which a miner is
a miner is required
miner is required to
is required to do
required to do is
to do is to
do is to repeatedly
prefetch no prefetch prefetch
is to repeatedly calculate
no prefetch prefetch no
to repeatedly calculate a
prefetch prefetch no prefetch
repeatedly calculate a a
calculate a a hash
a a hash function
a hash function specifically
hash function specifically the
function specifically the sha
prefetch no prefetch relative
no prefetch relative speedup
prefetch relative speedup relative
relative speedup relative speedup
of a block header
to indicate that he
indicate that he has
that he has performed
ip no loss maelstrom
he has performed this
no loss maelstrom no
has performed this work
loss maelstrom no loss
maelstrom no loss maelstrom
the miner provides a
miner provides a probabilistic
provides a probabilistic proof
a probabilistic proof as
probabilistic proof as follows
the generated block has
generated block has a
block has a nonce
has a nonce field
which can contain any
can contain any value
the miner places different
miner places different values
places different values in
different values in this
values in this field
in this field and
this field and calculates
field and calculates the
and calculates the hash
calculates the hash for
the hash for each
hash for each value
prefetch no prefetch relative
no prefetch relative speedup
if the result of
prefetch relative speedup relative
the result of the
relative speedup relative speedup
result of the hash
of the hash is
the hash is smaller
hash is smaller than
is smaller than a
smaller than a target
than a target value
the nonce is considered
nonce is considered a
is considered a solution
prefetch no prefetch relative
no prefetch relative speedup
and the block is
the block is valid
the number of attempts
number of attempts to
of attempts to find
attempts to find a
to find a single
find a single hash
a single hash is
single hash is therefore
hash is therefore random
is therefore random with
therefore random with a
random with a geometric
prefetch no prefetch relative
with a geometric distribution
no prefetch relative speedup
prefetch relative speedup bad
relative speedup bad groups
as each attempt is
each attempt is a
attempt is a bernoulli
is a bernoulli trial
a bernoulli trial with
bernoulli trial with a
trial with a success
with a success probability
a success probability determined
success probability determined by
probability determined by the
determined by the target
by the target value
at the existing huge
the existing huge hashing
existing huge hashing rates
huge hashing rates and
hashing rates and small
rates and small target
and small target values
the time to find
time to find a
to find a single
find a single hash
a single hash can
single hash can be
hash can be approximated
can be approximated by
be approximated by an
approximated by an exponential
by an exponential distribution
the average time for
average time for a
time for a miner
for a miner to
a miner to find
miner to find a
to find a solution
find a solution is
a solution is therefore
solution is therefore proportional
is therefore proportional to
therefore proportional to its
proportional to its hashing
to its hashing rate
its hashing rate or
hashing rate or mining
rate or mining power
to maintain a constant
maintain a constant rate
a constant rate of
constant rate of bitcoin
rate of bitcoin generation
and as part of
as part of its
part of its defense
of its defense against
its defense against denial
defense against denial of
against denial of service
denial of service and
of service and other
service and other attacks
the system normalizes the
system normalizes the rate
normalizes the rate of
the rate of block
rate of block generation
the protocol deterministically defines
protocol deterministically defines the
deterministically defines the target
defines the target value
the target value for
target value for each
value for each block
for each block according
each block according to
block according to the
according to the time
to the time required
the time required to
time required to generate
required to generate recent
to generate recent blocks
aware adaptation techniques for
adaptation techniques for mobile
techniques for mobile file
for mobile file systems
mobile file systems benjamin
file systems benjamin atkin
is updated once every
systems benjamin atkin kenneth
benjamin atkin kenneth p
birman nec laboratories america
nec laboratories america cornell
laboratories america cornell university
america cornell university atkin
blocks such that the
such that the average
that the average time
the average time for
average time for each
time for each block
for each block to
each block to be
block to be found
to be found is
edu abstract therefore react
abstract therefore react to
therefore react to bandwidth
react to bandwidth variations
to bandwidth variations in
bandwidth variations in a
variations in a fine
note that the exponential
that the exponential distribution
the exponential distribution is
exponential distribution is memoryless
if all miners mine
all miners mine for
miners mine for block
mine for block number
for block number b
life file system traffic
file system traffic featuring
system traffic featuring high
traffic featuring high read
once the block is
the block is found
block is found at
is found at time
write wireless networks present
found at time t
wireless networks present unusual
networks present unusual challenges
present unusual challenges for
unusual challenges for mobile
challenges for mobile file
all miners switch to
for mobile file contention
miners switch to mine
switch to mine for
to mine for the
mine for the subsequent
for the subsequent block
the subsequent block b
mafs is able to
is able to achieve
able to achieve improvements
to achieve improvements in
achieve improvements in execusystem
improvements in execusystem clients
at t without changing
since they are characterised
t without changing their
they are characterised by
without changing their probability
are characterised by unpredictable
changing their probability distribution
characterised by unpredictable tion
their probability distribution of
by unpredictable tion time
probability distribution of finding
unpredictable tion time of
distribution of finding a
tion time of up
of finding a block
time of up to
finding a block after
a block after t
the probability that a
probability that a miner
that a miner i
a miner i with
miner i with mining
i with mining power
with mining power mi
at both low and
mining power mi finds
both low and high
low and high bandwidths
power mi finds the
mi finds the next
finds the next block
the next block is
next block is its
block is its ratio
is its ratio out
its ratio out of
ratio out of the
out of the total
of the total mining
the total mining power
total mining power m
the traditional approach to
mining power m in
power m in the
traditional approach to adapting
m in the system
approach to adapting network
to adapting network communication
adapting network communication to
network communication to these
communication to these conditions
to these conditions is
these conditions is to
miner miner miner pool
conditions is to write
is to write back
to write back file
write back file updates
miner miner miner pool
back file updates asynchronously
relative speedup of workloads
file updates asynchronously when
speedup of workloads with
updates asynchronously when bandwidth
of workloads with prefetching
asynchronously when bandwidth is
these graphs show the
graphs show the speedup
show the speedup gained
the speedup gained by
speedup gained by adding
gained by adding prefetching
by adding prefetching for
adding prefetching for a
this can lead to
prefetching for a range
can lead to underutilisation
for a range of
lead to underutilisation of
a range of bandwidth
to underutilisation of bandwidth
range of bandwidth values
underutilisation of bandwidth and
of bandwidth and inconsistencies
bandwidth and inconsistencies between
and inconsistencies between clients
relative to the time
to the time taken
the time taken with
time taken with a
we describe a new
taken with a bandwidth
describe a new mobile
with a bandwidth of
a new mobile access
new mobile access to
mobile access to shared
access to shared data
to shared data is
shared data is complicated
data is complicated by
is complicated by an
complicated by an unpredictable
by an unpredictable mobile
an unpredictable mobile file
unpredictable mobile file system
s and no prefetching
and one miner mines
one miner mines solo
where a test comprises
a test comprises two
that supports graceful degradation
test comprises two separate
supports graceful degradation computing
comprises two separate processes
graceful degradation computing environment
pools datacenters are built
only the speedup for
datacenters are built around
the speedup for the
are built around the
the network or a
built around the world
speedup for the foreground
network or a particular
for the foreground process
or a particular destination
the foreground process is
a particular destination of
foreground process is shown
particular destination of file
destination of file system
of file system performance
file system performance as
fetch wait for the
system performance as bandwidth
wait for the prefetch
performance as bandwidth is
for the prefetch to
as bandwidth is reduced
the prefetch to complete
as well as may
or that the prefetch
well as may be
that the prefetch be
as may be unavailable
the prefetch be aborted
mining is only profitable
is only profitable using
only profitable using dedicated
profitable using dedicated hardware
or the throughput may
using dedicated hardware in
issuing a fetch rpc
dedicated hardware in cutting
the throughput may be
hardware in cutting edge
throughput may be substandard
in cutting edge mining
a fetch rpc at
cutting edge mining rigs
fetch rpc at the
rpc at the same
at the same time
as rapid propagation of
the same time as
rapid propagation of essential
same time as a
propagation of essential file
otherwise the energy costs
of essential file updates
time as a prefetch
the energy costs exceed
as a prefetch is
energy costs exceed the
a prefetch is in
costs exceed the expected
prefetch is in progress
exceed the expected revenue
is in progress needlessly
mafs is able to
in progress needlessly wastes
is able to shown
progress needlessly wastes bandwidth
able to shown in
to shown in figure
although expected revenue from
expected revenue from mining
revenue from mining is
since it retrieves the
from mining is proportional
it retrieves the same
mining is proportional to
retrieves the same file
is proportional to the
the same file from
proportional to the power
same file from the
this graph shows results
file from the server
to the power of
from the server twice
graph shows results from
the power of the
shows results from packet
power of the mining
of the mining rigs
the mining rigs used
the same could be
same could be true
could be true if
be true if we
true if we opt
a single home miner
if we opt for
single home miner using
we opt for aborting
home miner using a
opt for aborting prefetches
miner using a small
using a small rig
tcp no loss maelstrom
a small rig is
no loss maelstrom no
small rig is unlikely
loss maelstrom no loss
since an aborted prefetch
maelstrom no loss maelstrom
rig is unlikely to
an aborted prefetch could
is unlikely to mine
aborted prefetch could be
unlikely to mine a
prefetch could be very
to mine a block
could be very close
mine a block for
be very close to
a block for years
very close to completion
improvements in execution time
in execution time for
execution time for real
mfs therefore makes the
therefore makes the demand
makes the demand fetch
the demand fetch wait
demand fetch wait for
fetch wait for the
life measurements of available
wait for the prefetch
measurements of available bandwidth
of available bandwidth between
available bandwidth between a
bandwidth between a mobile
between a mobile host
but also raises the
a mobile host on
also raises the priority
mobile host on a
raises the priority of
host on a wireless
the priority of the
on a wireless network
priority of the prefetch
miners often organize themselves
of the prefetch rpc
often organize themselves into
the prefetch rpc to
organize themselves into mining
prefetch rpc to that
themselves into mining pools
rpc to that of
and a wired host
to that of a
a wired host near
that of a regular
wired host near the
of a regular fetch
host near the base
a regular fetch operation
near the base station
a pool is a
to prevent a priority
file system traces featuring
pool is a group
system traces featuring read
prevent a priority inversion
is a group of
a group of miners
group of miners that
of miners that share
this requires an additional
miners that share their
requires an additional raise
that share their revenues
as the mobile host
share their revenues when
the mobile host moves
their revenues when one
revenues when one of
priority rpc to the
when one of them
rpc to the server
one of them successfully
of them successfully mines
factors such as the
them successfully mines a
successfully mines a block
such as the distance
which results in more
as the distance to
results in more overhead
the distance to the
in more overhead than
for each block found
more overhead than the
distance to the base
overhead than the case
to the base station
than the case where
the base station and
the case where a
base station and local
case where a demand
the revenue is distributed
station and local interference
where a demand fetch
revenue is distributed among
and local interference cause
a demand fetch occurs
is distributed among the
demand fetch occurs without
local interference cause the
fetch occurs without a
distributed among the pool
occurs without a fetch
interference cause the host
among the pool members
cause the host s
the pool members in
the host s network
pool members in proportion
host s network card
members in proportion to
s network card to
in proportion to their
network card to switch
proportion to their mining
card to switch to
to their mining power
to switch to higher
on the other hand
the expected revenue of
expected revenue of a
revenue of a pool
of a pool member
a pool member is
pool member is therefore
member is therefore the
is therefore the same
the fetch can frequently
therefore the same as
fetch can frequently make
the same as its
can frequently make use
such switching causes available
same as its revenue
frequently make use of
as its revenue had
switching causes available bandwidth
its revenue had it
make use of the
revenue had it mined
causes available bandwidth to
had it mined solo
use of the data
available bandwidth to oscillate
of the data already
bandwidth to oscillate distributed
the data already transferred
to oscillate distributed file
data already transferred and
oscillate distributed file systems
already transferred and so
distributed file systems are
transferred and so still
file systems are a
and so still results
due to the large
so still results in
to the large power
systems are a common
the large power of
still results in a
large power of the
are a common feature
power of the pool
results in a faster
a common feature of
in a faster response
common feature of large
a faster response to
feature of large com
faster response to the
one way link latency
response to the application
it finds blocks at
finds blocks at a
blocks at a much
at a much higher
a much higher rate
as we have explained
even when the mobile
when the mobile host
and so the frequency
the mobile host is
so the frequency of
mobile host is stationary
the implementation of the
the frequency of revenue
implementation of the prefetching
frequency of revenue collection
of the prefetching subsystem
of revenue collection is
the prefetching subsystem is
if it is to
prefetching subsystem is not
it is to enputing
revenue collection is higher
is to enputing environments
subsystem is not sophisticated
allowing for a stable
for a stable daily
since they simplify sharing
a stable daily or
while it will reach
they simplify sharing data
stable daily or weekly
it will reach an
simplify sharing data between
daily or weekly income
will reach an equilibrium
sharing data between sure
reach an equilibrium if
data between sure that
an equilibrium if the
between sure that clients
equilibrium if the total
sure that clients file
if the total size
that clients file operations
the total size of
clients file operations are
most pools are controlled
file operations are executed
pools are controlled by
operations are executed in
total size of the
are controlled by a
size of the file
controlled by a centralized
of the file groups
are executed in a
the file groups in
by a centralized pool
file groups in the
a centralized pool manager
groups in the prefetch
executed in a timely
in the prefetch list
in a timely way
the prefetch list is
prefetch list is less
list is less than
is less than the
less than the cache
than the cache size
way latency throughput as
miners register with the
latency throughput as a
register with the pool
throughput as a function
with the pool manager
and can provide scalable
as a function of
can provide scalable and
a function of latency
provide scalable and highly
the pool manager and
scalable and highly available
there is no mechanism
and highly available file
pool manager and mine
is no mechanism to
manager and mine on
highly available file ac
and mine on its
no mechanism to prevent
mine on its behalf
mechanism to prevent the
to prevent the prefetching
file system must adapt
prevent the prefetching subsystem
system must adapt to
must adapt to this
the pool manager generates
adapt to this variation
the prefetching subsystem running
pool manager generates tasks
prefetching subsystem running ahead
manager generates tasks and
subsystem running ahead of
generates tasks and the
running ahead of actual
tasks and the miners
ahead of actual file
and the miners search
of actual file accesses
the miners search for
actual file accesses and
miners search for solutions
file accesses and evicting
search for solutions based
accesses and evicting useful
for solutions based on
and evicting useful files
solutions based on these
evicting useful files from
based on these tasks
useful files from the
on these tasks that
files from the cache
these tasks that can
tasks that can serve
that can serve as
can serve as proof
serve as proof of
as proof of work
ip to attain very
or evicting files which
to attain very high
evicting files which it
attain very high speeds
files which it has
supporting mobile clients requires
which it has prefetched
once they find a
it has prefetched but
they find a solution
very high speeds on
mobile clients requires coping
high speeds on the
has prefetched but have
speeds on the gigabit
clients requires coping existing
prefetched but have not
requires coping existing systems
but have not yet
coping existing systems tailored
they send it to
existing systems tailored to
on the gigabit link
systems tailored to low
send it to the
have not yet been
it to the pool
not yet been referenced
to the pool manager
yet been referenced by
we had to set
been referenced by the
bandwidth clients differenwith the
referenced by the user
clients differenwith the atypical
had to set the
differenwith the atypical patterns
the pool manager behaves
the atypical patterns of
to set the mtu
atypical patterns of connectivity
techniques for preventing this
set the mtu of
pool manager behaves as
patterns of connectivity that
manager behaves as a
of connectivity that characterise
behaves as a single
connectivity that characterise them
as a single miner
the mtu of the
a single miner in
mtu of the entire
single miner in the
for preventing this behaviour
of the entire path
preventing this behaviour have
tiate between types of
this behaviour have been
between types of file
behaviour have been discussed
types of file system
have been discussed elsewhere
of file system communication
miner in the bitcoin
the entire path to
in the bitcoin system
entire path to be
path to be the
to be the maximum
so that bandwhile a
that bandwhile a desktop
bandwhile a desktop client
once it obtains a
a desktop client is
it obtains a legitimate
desktop client is well
obtains a legitimate block
a legitimate block from
legitimate block from one
block from one of
from one of its
one of its miners
connected to a file
to a file server
a file server un
width can be devoted
can be devoted to
in order to characterise
the block transfers the
order to characterise the
which meant that the
to characterise the effect
meant that the long
be devoted to important
block transfers the revenue
characterise the effect of
transfers the revenue to
the effect of adding
the revenue to the
effect of adding prefetching
revenue to the control
haul link had the
to the control of
link had the same
the control of the
had the same mtu
control of the pool
the same mtu as
of the pool manager
same mtu as the
we ran a set
mtu as the inter
ran a set of
a set of eight
set of eight microbenchmarks
the pool manager then
pool manager then distributes
manager then distributes the
the experimental setup was
then distributes the revenue
experimental setup was the
distributes the revenue among
this resulted in the
the revenue among the
setup was the same
revenue among the miners
was the same as
among the miners according
the same as in
a mobile client frequently
the miners according to
mobile client frequently lacks
same as in the
client frequently lacks the
as in the priority
miners according to their
resulted in the fragmentation
according to their mining
in the priority tests
to their mining power
in the fragmentation of
the fragmentation of repair
fragmentation of repair packets
of repair packets sent
though this time mfs
the architecture is illustrated
this time mfs was
repair packets sent over
architecture is illustrated in
time mfs was configured
packets sent over udp
mfs was configured to
is illustrated in figure
was configured to run
sent over udp on
configured to run with
over udp on the
to run with asynchronous
udp on the longhaul
run with asynchronous writeback
on the longhaul link
in order to estimate
the longhaul link into
order to estimate the
longhaul link into two
to estimate the mining
link into two ip
and rpc with priorities
estimate the mining power
into two ip packet
the mining power of
two ip packet fragments
mining power of a
power of a miner
and only prefetching was
only prefetching was either
prefetching was either enabled
since the loss of
was either enabled or
the loss of a
either enabled or disabled
loss of a single
the pool manager sets
of a single fragment
writes back changes to
a single fragment resulted
pool manager sets a
single fragment resulted in
manager sets a partial
fragment resulted in the
sets a partial target
resulted in the loss
a partial target for
in the loss of
partial target for each
the loss of the
target for each member
loss of the repair
back changes to files
the tests were run
changes to files asynbandwidth
tests were run at
to files asynbandwidth to
were run at a
files asynbandwidth to perform
we observed a higher
run at a range
asynbandwidth to perform all
at a range of
observed a higher loss
a range of bandwidth
to perform all its
range of bandwidth values
a higher loss rate
perform all its file
higher loss rate for
all its file operations
loss rate for repairs
its file operations in
rate for repairs than
file operations in a
as in the previous
operations in a timely
in the previous section
in a timely fashion
for repairs than for
repairs than for data
than for data packets
each microbenchmark consists of
microbenchmark consists of one
consists of one or
than the target of
of one or two
the target of the
one or two processes
target of the bitcoin
or two processes accessing
of the bitcoin system
two processes accessing files
we expect performance to
expect performance to be
performance to be better
to be better on
each miner is required
be better on a
with some or all
better on a network
some or all of
on a network where
or all of the
miner is required to
all of the files
a network where the
of the files forming
is required to send
the files forming file
assigns lower priorities to
files forming file groups
network where the mtu
lower priorities to asynmobile
where the mtu of
required to send the
the mtu of the
priorities to asynmobile file
mtu of the long
to send the pool
to asynmobile file systems
send the pool manager
asynmobile file systems typically
the pool manager blocks
file systems typically assume
write test is the
systems typically assume that
test is the same
typically assume that a
is the same as
assume that a client
the same as in
that a client is
same as in section
a client is strongly
pool manager blocks that
haul link is truly
manager blocks that are
link is truly larger
blocks that are correct
is truly larger than
chronous operations at the
truly larger than the
that are correct according
larger than the mtu
with a file group
than the mtu within
are correct according to
the mtu within each
a file group added
mtu within each cluster
correct according to the
operations at the ip
according to the partial
file group added for
to the partial target
group added for the
at the ip level
added for the read
even with zero loss
for the read data
the ip level to
ip level to reduce
level to reduce interference
the partial target is
to reduce interference with
partial target is chosen
reduce interference with connected
the compile mfs test
interference with connected like
target is chosen to
with connected like a
ip throughput in figure
connected like a desktop
is chosen to be
compile mfs test has
chosen to be large
like a desktop host
mfs test has six
test has six file
has six file groups
six file groups for
file groups for the
such that partial solutions
groups for the main
that partial solutions arrive
for the main directories
partial solutions arrive frequently
the main directories of
connected and should foreground
main directories of the
solutions arrive frequently enough
directories of the system
and should foreground operations
arrive frequently enough for
declines with link latency
frequently enough for the
enough for the manager
for the manager to
limit its bandwidth consumption
the manager to accurately
its bandwidth consumption to
manager to accurately estimate
this is due to
to accurately estimate the
mb of data in
accurately estimate the power
bandwidth consumption to a
is due to the
consumption to a minimum
estimate the power of
due to the cap
the power of the
to the cap on
power of the miner
the cap on throughput
cap on throughput placed
on throughput placed by
throughput placed by the
placed by the buffering
by the buffering available
forming a single file
the buffering available at
a single file group
buffering available at the
available at the receiving
at the receiving end
to reduce management overhead
mb of small files
as the value of
the preceding experiments were
the value of bitcoin
preceding experiments were done
value of bitcoin rose
experiments were done with
were done with maelstrom
adaptation by deferred transmission
done with maelstrom in
by deferred transmission of
with maelstrom in endto
deferred transmission of file
bitcoin mining has become
transmission of file upwidth
mining has become a
of file upwidth lies
has become a rapidly
file upwidth lies between
become a rapidly advancing
upwidth lies between these
a rapidly advancing industry
lies between these extremes
end flow control mode
technological advancements lead to
all the files are
advancements lead to ever
the files are in
lead to ever more
where it is oblivious
assuming weak connectivity dates
files are in a
to ever more efficient
are in a single
weak connectivity dates has
it is oblivious to
connectivity dates has the
is oblivious to tcp
ever more efficient hashing
in a single file
more efficient hashing asics
dates has the disadvantage
a single file group
has the disadvantage of
ip and does not
the disadvantage of increasing
and does not split
disadvantage of increasing the
does not split connections
of increasing the delay
increasing the delay before
the delay before upcan
delay before upcan be
before upcan be too
fetch runs as two
upcan be too conservative
runs as two process
and is consequently sensitive
is consequently sensitive to
consequently sensitive to the
sensitive to the size
to the size of
since it delays sending
the size of the
it delays sending updates
size of the receiver
delays sending updates to
of the receiver buffer
sending updates to the
updates to the dates
to the dates are
the dates are applied
this is a simplification
dates are applied at
is a simplification that
are applied at the
a simplification that is
applied at the file
simplification that is sufficient
at the file server
that is sufficient for
is sufficient for our
sufficient for our analysis
shows the performance of
and therefore reduces the
the performance of split
therefore reduces the deserver
performance of split mode
reduces the deserver in
of split mode flow
which form a file
the intricacies of reward
the deserver in order
intricacies of reward systems
deserver in order to
split mode flow control
form a file group
of reward systems are
in order to aggregate
reward systems are explained
order to aggregate modifications
systems are explained in
where maelstrom breaks a
the other does the
maelstrom breaks a single
other does the same
breaks a single tcp
gree of consistency between
of consistency between clients
consistency between clients cached
between clients cached copies
but without a file
ip connection into three
without a file group
connection into three hops
for its own this
its own this paper
simultaneous writeback executes in
own this paper examines
writeback executes in the
this paper examines the
executes in the same
paper examines the effectiveness
in the same way
examines the effectiveness of
the effectiveness of mafs
a notable exception is
but the second process
notable exception is p
the second process writes
second process writes the
process writes the files
writes the files to
the files to the
split mode flow control
files to the server
mode flow control eliminates
to the server instead
bandwidth client may decide
the server instead of
flow control eliminates the
server instead of reading
client may decide to
instead of reading them
control eliminates the requirement
may decide to delay
eliminates the requirement for
decide to delay sending
the requirement for large
to delay sending a
requirement for large buffers
delay sending a file
the remaining tests investigate
sending a file system
for large buffers at
remaining tests investigate the
large buffers at the
a file system that
tests investigate the overhead
which we discuss in
buffers at the receiving
we discuss in section
at the receiving end
discuss in section ix
investigate the overhead paid
file system that propagates
the overhead paid for
system that propagates file
overhead paid for weaknesses
that propagates file modifications
paid for weaknesses in
forks block propagation in
propagates file modifications asynchronously
for weaknesses in the
block propagation in the
weaknesses in the prefetching
propagation in the overlay
in the prefetching algorithm
in the overlay network
file modifications asynchronously file
the overlay network takes
throughput is essentially insensitive
modifications asynchronously file s
is essentially insensitive to
overlay network takes seconds
essentially insensitive to one
asynchronously file s update
file s update to
s update to the
update to the file
to the file server
therefore it is possible
it is possible for
is possible for two
possible for two distant
for two distant miners
with a slight drop
two distant miners to
but this decision may
distant miners to generate
a slight drop due
miners to generate competing
this decision may also
slight drop due to
decision may also affect
to generate competing blocks
may also affect at
drop due to buffering
also affect at all
due to buffering overhead
affect at all bandwidth
to buffering overhead on
at all bandwidth levels
buffering overhead on the
both of which name
overhead on the maelstrom
of which name the
on the maelstrom boxes
which name the same
name the same block
rather than delaying writes
the same block as
same block as their
block as their predecessor
mafs other clients that
other clients that would
clients that would like
that would like to
would like to read
kb files and forming
like to read the
files and forming its
to read the file
and forming its own
compares split mode to
forming its own file
split mode to end
its own file group
are rare since the
rare since the average
since the average mining
optimistic concuruses rpc priorities
the average mining interval
on its first iteration
average mining interval is
concuruses rpc priorities to
rpc priorities to reduce
priorities to reduce interference
the workload accesses the
to reduce interference between
workload accesses the first
reduce interference between read
accesses the first file
interference between read and
the first file in
between read and rency
first file in each
read and rency control
file in each directory
and they occur on
and rency control and
they occur on average
rency control and reconciliation
occur on average once
control and reconciliation of
on average once every
and reconciliation of conflicting
reconciliation of conflicting updates
of conflicting updates are
conflicting updates are typwrite
updates are typwrite traffic
are typwrite traffic at
typwrite traffic at low
traffic at low bandwidth
to ensure that file
to provoke a large
ensure that file modifications
provoke a large amount
that file modifications ically
a large amount of
file modifications ically used
large amount of useless
modifications ically used to
amount of useless prefetches
ically used to resolve
used to resolve inconsistencies
good order and bad
order and bad order
and bad order investigate
bad order investigate the
order investigate the effect
the system has a
investigate the effect of
system has a mechanism
the effect of the
has a mechanism to
effect of the ordered
a mechanism to solve
of the ordered list
mechanism to solve forks
the ordered list of
to solve forks when
ordered list of files
solve forks when they
list of files in
forks when they do
of files in a
when they do occur
files in a file
in a file group
causing one of the
one of the blocks
of the blocks to
the blocks to be
blocks to be discarded
when bandwidth are rapidly
bandwidth are rapidly propagated
are rapidly propagated to
rapidly propagated to the
propagated to the clients
we ignore bifurcations for
to the clients that
ignore bifurcations for the
the clients that need
bifurcations for the sake
clients that need them
for the sake of
the sake of simplicity
prefetching evaluation having added
evaluation having added prefetching
having added prefetching to
mafs is very low
added prefetching to mfs
since the choice of
the choice of the
choice of the discarded
of the discarded block
this can be an
the discarded block on
we evaluated whether such
discarded block on bifurcation
evaluated whether such a
block on bifurcation is
can be an acceptable
whether such a straightforward
on bifurcation is random
be an acceptable price
such a straightforward algorithm
an acceptable price to
a straightforward algorithm can
acceptable price to pay
straightforward algorithm can have
one may incorporate this
algorithm can have a
price to pay for
can have a benefit
may incorporate this event
have a benefit for
to pay for the
a benefit for some
incorporate this event into
benefit for some repre
pay for the abilalso
this event into the
for the abilalso incorporates
event into the probability
the abilalso incorporates a
into the probability of
abilalso incorporates a new
the probability of finding
incorporates a new invalidation
probability of finding a
order accesses the files
of finding a block
accesses the files in
the files in the
files in the group
based update propagation ity
in the group in
update propagation ity to
and consider instead the
propagation ity to continue
the group in the
ity to continue accessing
consider instead the probability
to continue accessing a
group in the same
continue accessing a file
instead the probability of
accessing a file server
in the same order
the probability of finding
the same order as
probability of finding a
same order as the
of finding a block
order as the list
finding a block that
but if bandwidth is
a block that is
if bandwidth is less
block that is not
bandwidth is less scheme
that is not discarded
bad order accesses them
order accesses them in
accesses them in reverse
unlike previous mobile file
them in reverse order
previous mobile file systems
pools often charge a
often charge a small
charge a small percentage
a small percentage of
small percentage of the
percentage of the revenue
of the revenue as
the revenue as fee
we discuss in section
discuss in section ix
in section ix the
client consistency is achievable
section ix the implications
ix the implications of
the implications of such
implications of such fees
of such fees to
codaniques that are oblivious
such fees to our
that are oblivious to
fees to our analysis
are oblivious to the
oblivious to the exact
to the exact bandwidth
analysis of prefetching the
the exact bandwidth level
of prefetching the graphs
many pools are open
prefetching the graphs in
pools are open and
the graphs in figure
are open and accept
open and accept any
and can like file
and accept any interested
can like file systems
accept any interested miner
like file systems therefore
show the results of
file systems therefore switch
the results of the
systems therefore switch between
results of the experiments
therefore switch between a
switch between a low
a pool interface is
pool interface is typically
interface is typically comprised
where a test such
is typically comprised of
a test such as
typically comprised of a
test such as simultaneous
comprised of a web
such as simultaneous demand
of a web interface
a web interface for
web interface for registration
writes mode and a
mode buffering flow control
interface for registration and
buffering flow control against
fetch incorporates more than
flow control against one
for registration and a
mode and a synchronous
registration and a miner
incorporates more than one
and a miner interface
more than one workload
a miner interface for
way link latency left
miner interface for the
interface for the mining
for the mining software
only the elapsed time
most bar represents maelstrom
the elapsed time for
bar represents maelstrom in
acthe authors were supported
in order to mine
represents maelstrom in end
authors were supported in
elapsed time for the
order to mine for
were supported in part
to mine for a
time for the foreground
supported in part by
for the foreground workload
mine for a pool
in part by darpa
part by darpa under
end mode with manually
by darpa under afrl
mode with manually configured
darpa under afrl grant
with manually configured large
a miner registers with
under afrl grant radc
manually configured large buffers
miner registers with the
afrl grant radc cording
configured large buffers at
the one accessing a
large buffers at end
registers with the web
grant radc cording to
with the web interface
one accessing a file
radc cording to the
accessing a file group
cording to the available
to the available bandwidth
supplies a bitcoin address
a bitcoin address to
and the second and
bitcoin address to receive
the second and third
address to receive its
second and third bar
in most of the
and third bar from
most of the microbenchmarks
in a wireless f
to receive its future
third bar from left
receive its future shares
bar from left are
its future shares of
from left are split
future shares of the
left are split mode
shares of the revenue
are split mode and
adding prefetching from the
split mode and end
prefetching from the file
from the file groups
the file groups specified
and receives from the
file groups specified has
receives from the pool
groups specified has a
from the pool credentials
specified has a substantial
the pool credentials for
has a substantial improvement
pool credentials for mining
a substantial improvement on
substantial improvement on the
improvement on the performance
on the performance of
the performance of the
performance of the workload
then he feeds his
he feeds his credentials
with standard buffers at
feeds his credentials and
standard buffers at end
his credentials and the
varying with how amenable
credentials and the pool
with how amenable it
and the pool s
how amenable it is
the pool s address
amenable it is to
pool s address to
it is to prefetching
s address to its
address to its mining
to its mining rig
split mode performs as
mode performs as well
performs as well with
as well with default
well with default sized
with default sized buffers
more surplus bandwidth and
default sized buffers as
surplus bandwidth and more
sized buffers as end
bandwidth and more think
the mining rig obtains
and more think time
mining rig obtains its
more think time result
rig obtains its tasks
think time result in
obtains its tasks from
time result in improved
its tasks from the
result in improved performance
tasks from the pool
from the pool and
end mode performs with
the pool and sends
mode performs with large
pool and sends partial
performs with large end
and sends partial and
this naturally means that
sends partial and full
naturally means that the
partial and full proof
means that the greatest
and full proof of
and by afosr under
full proof of work
that the greatest improvements
by afosr under muri
the greatest improvements from
and much better than
afosr under muri grant
much better than end
greatest improvements from prefetching
under muri grant f
typically with the stratum
improvements from prefetching are
with the stratum protocol
from prefetching are evident
prefetching are evident at
are evident at higher
evident at higher bandwidths
end mode with default
mode with default sized
with default sized buffers
six out of eight
out of eight microbenchmarks
of eight microbenchmarks run
eight microbenchmarks run at
microbenchmarks run at least
as it finds blocks
faster when bandwidth is
the pool manager credits
pool manager credits the
manager credits the miner
credits the miner s
the miner s account
miner s account according
s account according to
account according to its
according to its share
to its share of
its share of the
share of the work
and transfers these funds
transfers these funds either
these funds either on
funds either on request
either on request or
on request or automatically
request or automatically to
or automatically to the
automatically to the aforementioned
to the aforementioned bitcoin
the aforementioned bitcoin address
at low bandwidth most
low bandwidth most workloads
too big pools despite
bandwidth most workloads see
big pools despite their
most workloads see no
pools despite their important
workloads see no benefit
despite their important role
variations in bandwidth can
their important role of
in bandwidth can occur
important role of enabling
bandwidth can occur without
since all the bandwidth
role of enabling small
can occur without the
all the bandwidth is
occur without the user
the bandwidth is dedicated
without the user s
bandwidth is dedicated to
the user s with
is dedicated to higher
user s with additional
s with additional support
with additional support from
pools can constitute a
additional support from microsoft
can constitute a threat
support from microsoft research
constitute a threat to
from microsoft research and
a threat to the
microsoft research and from
threat to the bitcoin
research and from the
to the bitcoin system
and from the intel
only two tests perform
from the intel corporation
the bitcoin system if
two tests perform worse
bitcoin system if their
tests perform worse with
system if their size
perform worse with prefetching
if their size is
worse with prefetching than
their size is too
with prefetching than without
size is too large
so that changing modes
if one pool controls
that changing modes creates
one pool controls the
changing modes creates unexpected
pool controls the majority
modes creates unexpected incon
controls the majority of
write test performs slightly
the majority of mining
test performs slightly worse
majority of mining power
performs slightly worse due
slightly worse due to
several clients concurrently modify
worse due to its
clients concurrently modify a
due to its already
concurrently modify a file
to its already heavy
the system becomes unstable
its already heavy network
already heavy network contention
the final contents depend
final contents depend on
contents depend on the
the bad groups test
depend on the client
on the client that
the client that closed
client that closed it
that closed it last
which exploits poor prefetching
exploits poor prefetching hints
a client can lock
client can lock a
can lock a file
lock a file to
a file to synchronise
file to synchronise accesses
performs when prefetching is
when prefetching is used
the server grants the
server grants the client
grants the client a
this effect is due
the client a lease
effect is due to
is due to the
due to the useless
to the useless prefetching
the useless prefetching rpcs
useless prefetching rpcs flooding
prefetching rpcs flooding the
rpcs flooding the outgoing
flooding the outgoing link
the outgoing link and
that is renewed each
outgoing link and imposing
is renewed each time
link and imposing minor
renewed each time the
and imposing minor delays
each time the client
imposing minor delays on
time the client communicates
minor delays on each
the client communicates with
delays on each demand
client communicates with the
on each demand fetch
communicates with the file
with the file server
warns that the system
that the system is
cumulatively these slow down
the system is unstable
these slow down the
system is unstable with
slow down the overall
is unstable with even
down the overall performance
unstable with even smaller
with even smaller pools
an usual phenomenon is
usual phenomenon is that
phenomenon is that the
is that the bad
that the bad order
the bad order test
bad order test consistently
order test consistently outperforms
test consistently outperforms good
consistently outperforms good order
in realistic scenarios of
realistic scenarios of the
scenarios of the bitcoin
of the bitcoin system
the bitcoin system no
even though the latter
bitcoin system no pool
though the latter triggers
system no pool controls
the latter triggers prefetches
no pool controls a
latter triggers prefetches in
pool controls a majority
triggers prefetches in the
controls a majority of
prefetches in the correct
a majority of the
in the correct order
majority of the mining
of the mining power
the explanation is that
for one day in
one day in june
the good order test
good order test suffers
order test suffers from
test suffers from the
suffers from the fast
from the fast linear
the fast linear scan
fast linear scan phenomenon
linear scan phenomenon described
scan phenomenon described in
phenomenon described in section
a single pool called
single pool called ghash
all prefetches in this
prefetches in this test
in this test conflict
this test conflict with
of the blocks in
test conflict with demand
the blocks in the
conflict with demand fetches
blocks in the bitcoin
in the bitcoin main
the bitcoin main chain
the bitcoin community backlashed
bitcoin community backlashed at
community backlashed at the
backlashed at the pool
at the start of
the start of the
start of the bad
of the bad order
which has done nothing
the bad order test
has done nothing worse
done nothing worse than
nothing worse than being
worse than being extremely
than being extremely successful
the prefetching subsystem is
prefetching subsystem is able
subsystem is able to
is able to prefetch
able to prefetch some
to prefetch some files
prefetch some files accessed
some files accessed at
files accessed at the
accessed at the end
at the end of
the end of the
end of the test
io reduced its relative
reduced its relative mining
its relative mining power
relative mining power and
mining power and publicly
without conflicting with a
power and publicly committed
conflicting with a demand
and publicly committed to
with a demand fetch
publicly committed to stay
committed to stay away
to stay away from
stay away from the
it can therefore achieve
can therefore achieve a
therefore achieve a greater
achieve a greater speedup
adaptive remote procedure call
remote procedure call figure
block withholding and its
withholding and its detection
and its detection classical
its detection classical block
detection classical block withholding
time series of wireless
series of wireless bandwidth
mafs uses adaptive remote
uses adaptive remote procedure
adaptive remote procedure call
remote procedure call for
procedure call for client
is an attack performed
an attack performed by
attack performed by a
performed by a pool
by a pool member
a pool member against
pool member against the
member against the other
against the other pool
the other pool members
adaptation based on low
the attacking miner registers
attacking miner registers with
miner registers with the
registers with the pool
with the pool and
the pool and apparently
pool and apparently starts
and apparently starts mining
adaptive rpc is based
apparently starts mining honestly
rpc is based on
starts mining honestly it
is based on our
mining honestly it regularly
based on our earlier
honestly it regularly sends
on our earlier work
it regularly sends the
our earlier work in
regularly sends the pool
earlier work in modes
sends the pool partial
work in modes can
the pool partial proof
in modes can be
pool partial proof of
modes can be ill
partial proof of work
suited to situations where
to situations where bandwidth
situations where bandwidth is
where bandwidth is not
bandwidth is not network
the attacking miner sends
attacking miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
if it finds a
it finds a full
finds a full solution
a full solution that
full solution that constitutes
solution that constitutes a
that constitutes a full
constitutes a full proof
a full proof of
and differs from severely
full proof of work
differs from severely constrained
proof of work it
of work it discards
work it discards the
it discards the solution
but insufficient for a
insufficient for a client
reducing the pool s
for a client to
the pool s total
pool s total revenue
a client to ignore
client to ignore it
to ignore it a
ignore it a typical
it a typical rpc
a typical rpc system
typical rpc system in
this attack is illustrated
rpc system in allowing
attack is illustrated in
system in allowing applications
is illustrated in figure
in allowing applications to
allowing applications to control
applications to control how
to control how concurrent
control how concurrent rpcs
how concurrent rpcs are
concurrent rpcs are transmitted
the attacker does not
attacker does not change
does not change the
and special handling for
not change the pool
special handling for failwhen
change the pool s
handling for failwhen deciding
the pool s effective
for failwhen deciding what
pool s effective mining
failwhen deciding what to
s effective mining power
way delivery latency against
deciding what to send
delivery latency against loss
what to send over
latency against loss rate
to send over the
send over the network
and does not affect
does not affect directly
not affect directly the
affect directly the revenue
directly the revenue of
ures due to insufficient
the revenue of other
due to insufficient bandwidth
revenue of other pools
adaptive rpc requests and
rpc requests and replies
requests and replies can
and replies can contain
the attacked pool shares
replies can contain an
attacked pool shares its
can contain an arbitrary
pool shares its revenue
contain an arbitrary amount
shares its revenue with
an arbitrary amount of
its revenue with the
arbitrary amount of data
revenue with the attacker
a sender also attaches
therefore each miner earns
sender also attaches a
each miner earns less
also attaches a priority
attaches a priority and
a priority and timeout
priority and timeout to
and timeout to the
as the same revenue
timeout to the send
the same revenue is
to the send operation
same revenue is distributed
revenue is distributed among
is distributed among more
distributed among more miners
recall that the proof
file system overview rover
that the proof of
system overview rover queued
the proof of work
overview rover queued rpc
proof of work is
of work is only
work is only valid
is only valid for
only valid for a
valid for a specific
for a specific block
as it is the
it is the nonce
is the nonce with
the nonce with which
nonce with which the
an adaptive rpc can
with which the block
adaptive rpc can be
which the block s
rpc can be asynchronous
the block s hash
block s hash is
s hash is smaller
hash is smaller than
is smaller than its
smaller than its target
adaptive mobile file system
the attacking miner cannot
attacking miner cannot use
miner cannot use it
is a distributed file
a distributed file sys
number of rpcs by
of rpcs by type
so that an application
rpcs by type in
although the term block
by type in bandwidth
the term block withholding
type in bandwidth variability
term block withholding has
in bandwidth variability test
block withholding has become
that an application need
withholding has become canonical
an application need not
application need not block
need not block waiting
not block waiting for
the entries under p
block waiting for the
entries under p denote
note that the block
under p denote periods
waiting for the result
p denote periods in
that the block is
denote periods in the
the block is discarded
periods in the test
block is discarded and
intem designed to support
is discarded and never
designed to support efficient
discarded and never introduced
to support efficient access
and never introduced into
support efficient access to
never introduced into the
efficient access to a
introduced into the system
access to a remote
into the system as
gives the abbreviations for
the system as the
the abbreviations for rpc
system as the name
abbreviations for rpc types
as the name block
to a remote file
the name block withholding
a remote file server
name block withholding implies
remote file server stead
are likely to be
likely to be beneficial
the library makes an
library makes an upcall
makes an upcall when
an upcall when the
the first would reduce
upcall when the reply
miners miners miners pool
when the reply arrives
first would reduce the
would reduce the aggressiveness
reduce the aggressiveness of
the aggressiveness of prefetching
since an application can
an application can perform
application can perform multiple
can perform multiple rpcs
perform multiple rpcs concurby
multiple rpcs concurby mobile
classical block withholding attack
setting a byte threshold
rpcs concurby mobile clients
concurby mobile clients that
mobile clients that must
clients that must cope
a group of miners
that must cope with
group of miners attack
from a file group
of miners attack pool
must cope with variations
a file group if
cope with variations in
file group if it
with variations in available
group if it appeared
with a block withholding
variations in available bandwidth
a block withholding attack
if it appeared that
it appeared that a
appeared that a process
that a process was
the mafs design and
a process was not
denoted by a dashed
mafs design and terminology
by a dashed red
process was not using
a dashed red arrow
design and terminology are
was not using the
and terminology are similar
not using the files
terminology are similar to
using the files prefetched
are similar to rently
the files prefetched based
files prefetched based on
prefetched based on its
based on its prior
on its prior accesses
this attack reduces the
adaptive rpc schedules their
attack reduces the attacker
rpc schedules their transmission
reduces the attacker s
the attacker s revenue
this would reduce the
attacker s revenue compared
would reduce the overhead
s revenue compared to
reduce the overhead in
revenue compared to solo
this corresponds to allocating
compared to solo mining
the overhead in the
to solo mining or
overhead in the bad
solo mining or honest
in the bad groups
mining or honest pool
corresponds to allocating bandwidth
or honest pool participation
the bad groups case
to allocating bandwidth among
allocating bandwidth among the
bandwidth among the competing
among the competing rpcs
it suffers from the
the second would explicitly
suffers from the reduced
second would explicitly detect
from the reduced revenue
the andrew file system
the reduced revenue like
would explicitly detect a
reduced revenue like the
explicitly detect a fast
revenue like the other
detect a fast linear
like the other pool
a fast linear scan
the other pool participants
fast linear scan by
linear scan by a
scan by a process
and its revenue is
its revenue is less
by counting the instances
revenue is less than
counting the instances of
is less than its
the instances of prefetch
less than its share
instances of prefetch and
than its share of
of prefetch and demand
its share of the
prefetch and demand fetch
share of the total
and demand fetch conflict
of the total mining
demand fetch conflict for
the total mining power
fetch conflict for a
total mining power in
conflict for a file
mining power in the
for a file group
power in the system
attaching priorities to rpcs
priorities to rpcs allows
to rpcs allows applications
and then disable prefetching
rpcs allows applications to
then disable prefetching from
this attack can therefore
disable prefetching from the
allows applications to control
prefetching from the group
attack can therefore only
applications to control this
can therefore only be
to control this scheduling
therefore only be used
control this scheduling policy
only be used for
be used for sabotage
a programmer divides rpcs
at a cost to
programmer divides rpcs into
a cost to the
divides rpcs into classes
cost to the attacker
prefetching and bandwidth variability
and bandwidth variability so
bandwidth variability so far
even if a pool
our experimental results have
file access model based
if a pool detects
access model based on
experimental results have demonstrated
model based on the
a pool detects that
based on the importance
results have demonstrated the
on the importance of
pool detects that it
the importance of their
have demonstrated the benefits
importance of their results
detects that it is
of their results to
demonstrated the benefits of
their results to the
that it is under
results to the user
the benefits of mfs
it is under a
benefits of mfs adaptation
is under a block
of mfs adaptation mechanisms
under a block withholding
mfs adaptation mechanisms at
and then mafs clients
a block withholding attack
adaptation mechanisms at various
then mafs clients use
mechanisms at various levels
mafs clients use whole
at various levels of
various levels of bandwidth
levels of bandwidth availability
it might not be
might not be able
not be able to
be able to detect
able to detect which
but not when the
when a file is
not when the bandwidth
to detect which of
a file is accessed
detect which of its
when the bandwidth is
which of its registered
file is accessed assigns
of its registered miners
the bandwidth is changing
its registered miners are
is accessed assigns priorities
registered miners are the
bandwidth is changing over
accessed assigns priorities to
is changing over the
assigns priorities to the
changing over the duration
priorities to the classes
miners are the perpetrators
over the duration of
the duration of the
duration of the test
the library schedules rpcs
library schedules rpcs for
a pool can estimate
schedules rpcs for the
rpcs for the first
to conclude this section
for the first time
pool can estimate its
conclude this section we
can estimate its expected
this section we will
estimate its expected mining
section we will describe
its expected mining power
we will describe an
a client fetches the
expected mining power and
will describe an example
client fetches the entire
mining power and its
describe an example of
fetches the entire file
power and its actual
an example of mfs
the entire file from
and its actual mining
example of mfs traffic
entire file from the
its actual mining power
file from the file
actual mining power by
of mfs traffic under
mining power by the
from the file based
power by the rates
mfs traffic under the
by the rates of
the file based on
traffic under the execution
the rates of partial
file based on priorities
rates of partial proofs
under the execution of
based on priorities whenever
of partial proofs of
on priorities whenever there
partial proofs of work
priorities whenever there is
proofs of work and
the execution of the
of work and full
whenever there is insufficient
work and full proofs
execution of the simultaneous
there is insufficient bandwidth
of the simultaneous writeback
is insufficient bandwidth to
the simultaneous writeback test
insufficient bandwidth to server
simultaneous writeback test described
bandwidth to server and
and full proofs of
to server and caches
writeback test described in
server and caches it
full proofs of work
test described in section
mafs only sends the
only sends the server
sends the server the
the server the contents
supplied by its miners
server the contents transmit
the contents transmit competing
contents transmit competing rpcs
transmit competing rpcs without
competing rpcs without a
a difference above a
rpcs without a noticeable
difference above a set
without a noticeable delay
this test involves two
above a set confidence
test involves two simultaneous
a set confidence interval
involves two simultaneous workloads
set confidence interval indicates
confidence interval indicates an
rpcs of a modified
interval indicates an attack
of a modified file
a modified file when
modified file when it
file when it is
when it is closed
to detect whether a
it is closed by
detect whether a single
is closed by an
whether a single miner
closed by an application
a single miner is
kb to the server
single miner is attacking
to the server and
miner is attacking it
the server and the
server and the other
this is from higher
and the other reads
the pool must use
pool must use a
must use a similar
priority classes are performed
use a similar technique
classes are performed first
kb files from the
files from the server
and rpcs of referred
comparing the estimated mining
rpcs of referred to
of referred to as
the estimated mining power
referred to as writeback
but is slightly modified
estimated mining power of
is slightly modified from
mining power of the
slightly modified from original
power of the attacker
modified from original version
of the attacker based
from original version to
the attacker based on
original version to use
attacker based on its
version to use a
based on its partial
to use a longer
on its partial proof
use a longer think
directory operations cache equal
a longer think time
its partial proof of
longer think time of
operations cache equal priority
partial proof of work
cache equal priority are
proof of work with
equal priority are performed
of work with the
priority are performed in
work with the fact
are performed in parallel
with the fact it
the fact it never
fact it never supplies
it never supplies a
never supplies a full
this ensures that the
supplies a full proof
ensures that the directory
a full proof of
that the directory contents
full proof of work
the directory contents and
seconds when accessing each
directory contents and apply
when accessing each file
contents and apply changes
and apply changes locally
if the attacker has
the attacker has a
improving the potential for
attacker has a small
the potential for rpcs
has a small mining
potential for rpcs to
a small mining power
for rpcs to overlap
as well as mak
packet delivery latencies throughput
it will send frequent
will send frequent partial
application adapts itself to
send frequent partial proofs
adapts itself to the
frequent partial proofs of
itself to the available
partial proofs of work
to the available bandwidth
we enabled asynchronous writeback
the available bandwidth gracefully
enabled asynchronous writeback and
asynchronous writeback and ran
writeback and ran the
but the pool will
and ran the test
the pool will only
ran the test with
ing an rpc to
the test with the
pool will only expect
an rpc to apply
will only expect to
rpc to apply the
test with the synthetic
to apply the changes
only expect to see
apply the changes to
with the synthetic bandwidth
the changes to the
expect to see a
changes to the server
the synthetic bandwidth trace
to the server s
to see a full
the server s copy
synthetic bandwidth trace shown
see a full proof
bandwidth trace shown in
a full proof of
trace shown in figure
full proof of work
proof of work at
of work at very
whole since lower bandwidth
work at very low
at very low frequency
since lower bandwidth translates
lower bandwidth translates into
bandwidth translates into longer
translates into longer delays
into longer delays for
longer delays for lowerfile
delays for lowerfile caching
for lowerfile caching is
it cannot obtain statistically
lowerfile caching is effective
cannot obtain statistically significant
caching is effective if
obtain statistically significant results
is effective if a
which changes the bandwidth
effective if a client
changes the bandwidth once
if a client s
the bandwidth once per
a client s connectivity
bandwidth once per second
statistically significant results that
client s connectivity is
significant results that would
s connectivity is uncertain
results that would indicate
that would indicate an
would indicate an attack
this has three sections
an attacker can use
a brief period when
attacker can use multiple
brief period when the
can use multiple small
period when the bandwidth
rpc timeouts allow the
mbps flow alongside on
when the bandwidth is
use multiple small block
timeouts allow the application
multiple small block withholding
the bandwidth is at
small block withholding miners
allow the application to
block withholding miners and
flow alongside on the
withholding miners and replace
the application to prevent
miners and replace them
alongside on the same
application to prevent since
on the same link
and replace them frequently
to prevent since the
the same link to
prevent since the client
same link to simulate
since the client can
link to simulate a
the client can always
to simulate a real
client can always use
a small miner is
can always use cached
always use cached copies
use cached copies of
cached copies of files
time stream combined with
copies of files instead
stream combined with other
of files instead low
combined with other inter
a gradual decrease to
a miners whose expected
miners whose expected full
priority rpcs being silently
whose expected full proof
rpcs being silently starved
expected full proof of
full proof of work
proof of work frequency
of work frequency is
work frequency is yearly
using priorities alof incrementally
priorities alof incrementally fetching
alof incrementally fetching them
incrementally fetching them from
such a miner will
fetching them from the
a miner will see
them from the server
miner will see a
s over the course
will see a non
over the course of
the course of ten
course of ten seconds
negligible average daily revenue
shows the average delivery
the average delivery latency
and then the maintenance
average delivery latency of
then the maintenance of
lows a programmer to
the maintenance of the
a programmer to write
programmer to write an
to write an adaptive
write an adaptive application
an adaptive application without
adaptive application without ports
level packets in the
application without ports this
without ports this type
ports this type of
this type of disconnected
type of disconnected operation
s rate until the
rate until the end
until the end of
the end of the
end of the test
as loss rates go
loss rates go up
but not to the
not to the ex
having to take account
summary of results the
to take account of
of results the test
take account of the
results the test was
account of the actual
the test was executed
of the actual bandwidth
test was executed once
the actual bandwidth or
was executed once with
actual bandwidth or current
executed once with prefetching
bandwidth or current mix
once with prefetching enabled
or current mix tent
if the attacker replaces
current mix tent of
the attacker replaces such
mix tent of automatic
attacker replaces such a
tent of automatic reconciliation
replaces such a small
of automatic reconciliation of
such a small miner
and despite the simplicity
a small miner every
automatic reconciliation of update
small miner every month
despite the simplicity of
reconciliation of update conflicts
the simplicity of the
simplicity of the mfs
shows the same scenario
of the mfs prefetching
the same scenario with
the mfs prefetching implementation
he will collect about
same scenario with a
will collect about b
scenario with a constant
with a constant uniformly
a constant uniformly random
once with no prefetching
constant uniformly random loss
uniformly random loss rate
at the end of
random loss rate of
the end of each
end of each month
and the rpcs were
the rpcs were then
rpcs were then divided
were then divided acwe
the pool must decide
then divided acwe have
pool must decide within
divided acwe have shown
on of rpcs at
must decide within this
acwe have shown that
of rpcs at runtime
have shown that workloads
decide within this month
shown that workloads which
within this month whether
that workloads which are
this month whether the
workloads which are amenable
month whether the miner
which are amenable to
and avoid having to
are amenable to file
whether the miner is
avoid having to specify
the miner is an
having to specify thresholds
miner is an attacker
to specify thresholds at
specify thresholds at the
maelstrom s delivery latency
thresholds at the other
s delivery latency is
at the other hand
level cording to which
delivery latency is almost
cording to which period
latency is almost exactly
to which period of
is almost exactly equal
and revoke its earnings
almost exactly equal to
which period of the
exactly equal to the
period of the trace
equal to the one
of the trace they
the trace they terminated
level caching reduces the
trace they terminated in
caching reduces the delay
reduces the delay incurred
way latency on the
the delay incurred which
or just an unlucky
delay incurred which it
just an unlucky honest
for each prefetching can
an unlucky honest miner
incurred which it should
latency on the link
which it should switch
each prefetching can achieve
it should switch communication
prefetching can achieve speedups
should switch communication modes
can achieve speedups of
since an honest miner
an honest miner of
honest miner of this
miner of this power
an rpc whose results
ip takes more than
of this power is
takes more than twice
rpc whose results are
more than twice as
this power is unlikely
than twice as long
power is unlikely to
whose results are urgently
is unlikely to find
twice as long once
unlikely to find a
results are urgently required
to find a full
as long once one
find a full proof
are urgently required should
a full proof of
urgently required should be
full proof of work
required should be aswhen
proof of work within
should be aswhen an
way latencies go past
of work within a
four quantities are calculated
be aswhen an application
work within a month
aswhen an application opens
an application opens a
application opens a file
the time spent queued
time spent queued for
spent queued for as
queued for as much
for as much as
as has been shown
has been shown in
been shown in the
according to the exponential
shown in the low
to the exponential distribution
at bandwidths as low
a pool that rejects
bandwidths as low as
pool that rejects miners
that rejects miners based
rejects miners based on
miners based on this
based on this criterion
on this criterion would
this criterion would reject
criterion would reject the
would reject the majority
reject the majority of
the majority of its
majority of its honest
of its honest miners
prefetching both the rpc
it is possible to
both the rpc request
is possible to use
the rpc request and
the alternative of rejecting
rpc request and reply
possible to use a
alternative of rejecting small
to use a signed
of rejecting small miners
use a signed the
rejecting small miners in
and the time taken
a signed the highest
the time taken for
signed the highest priority
small miners in general
time taken for each
miners in general or
taken for each to
in general or distributing
for each to be
particularly if the rpc
each to be carries
if the rpc contains
to be carries a
the rpc contains outcontent
be carries a small
general or distributing revenue
carries a small performance
ip one way link
a small performance overhead
one way link latency
or distributing revenue on
based division of files
distributing revenue on a
division of files into
revenue on a yearly
of files into blocks
even when performed at
files into blocks as
when performed at received
into blocks as the
on a yearly basis
blocks as the basis
a yearly basis contradicts
as the basis for
yearly basis contradicts the
the basis for re
from the first to
basis contradicts the goal
the first to the
contradicts the goal of
first to the last
the goal of pooled
to the last packet
goal of pooled mining
this ignores the time
ignores the time the
the time the lowest
time the lowest priority
m odel and s
but still important rpcs
odel and s tandard
still important rpcs can
which can reduce its
and s tandard o
can reduce its effectiveness
important rpcs can ducing
reduce its effectiveness for
rpcs can ducing client
its effectiveness for fast
s tandard o peration
effectiveness for fast lin
tandard o peration we
o peration we specify
peration we specify the
we specify the basic
spent at the server
specify the basic model
at the server servicing
the basic model in
the server servicing the
split with regular buffers
server servicing the rpc
basic model in which
model in which participants
in which participants operate
which participants operate in
participants operate in section
operate in section iii
trip time ear scan
time ear scan workloads
while the lowest levels
the lowest levels are
lowest levels are useful
it is possible to
proceed to describe how
levels are useful for
is possible to construct
end with large buffers
to describe how honest
are useful for server
possible to construct combination
describe how honest miners
useful for server traffic
how honest miners operate
to construct combination of
honest miners operate in
for server traffic does
miners operate in this
construct combination of file
operate in this environment
server traffic does not
in this environment in
combination of file between
this environment in sections
traffic does not eliminate
environment in sections iii
of file between the
does not eliminate the
file between the client
not eliminate the fundamental
between the client and
eliminate the fundamental problem
and outperforms it with
the fundamental problem of
outperforms it with regular
the client and the
it with regular buffers
client and the server
fundamental problem of rpcs
problem of rpcs that
of rpcs that can
rpcs that can be
that can be arbitrarily
can be arbitrarily delayed
but these quantities are
and how the classical
these quantities are small
how the classical block
quantities are small groups
the classical block withholding
are small groups and
classical block withholding attack
such as speculative activities
small groups and a
as speculative activities like
block withholding attack is
speculative activities like prefetching
groups and a workload
activities like prefetching and
withholding attack is implemented
latency metrics to measure
like prefetching and transferring
metrics to measure the
attack is implemented with
to measure the latency
prefetching and transferring archival
measure the latency effects
is implemented with our
and a workload for
and transferring archival data
a workload for which
implemented with our model
workload for which prefetching
the latency effects of
for which prefetching can
latency effects of tcp
with our model in
which prefetching can significantly
our model in section
if the inicontention for
prefetching can significantly compared
the inicontention for insufficient
model in section iii
inicontention for insufficient bandwidth
can significantly compared to
significantly compared to the
compared to the other
to the other costs
tial assumption regarding the
assumption regarding the correct
regarding the correct priority
these values are added
the correct priority level
values are added up
correct priority level for
are added up for
priority level for an
added up for each
level for an rpc
up for each degrade
for an rpc proves
for each degrade performance
an rpc proves incorrect
mbps stream between two
model the system is
stream between two nodes
the system is comprised
between two nodes over
system is comprised of
two nodes over a
of the rpcs within
is comprised of the
the rpcs within a
a call to the
rpcs within a particular
comprised of the bitcoin
within a particular period
call to the library
of the bitcoin network
to the library can
the bitcoin network and
the library can be
bitcoin network and nodes
library can be made
network and nodes with
can be made to
and nodes with unique
be made to assign
nodes with unique ids
made to assign a
and the results are
the results are shown
results are shown within
are shown within the
and progresses in steps
shown within the constraints
within the constraints imposed
the constraints imposed by
constraints imposed by our
imposed by our file
by our file group
a node i generates
our file group representa
node i generates tasks
i generates tasks which
generates tasks which are
tasks which are associated
which are associated with
are associated with its
associated with its id
client cache consistency new
with its id i
cache consistency new priority
plots delivery latency against
delivery latency against message
a node can work
latency against message identifier
node can work on
when a client fetches
can work on a
a client fetches a
work on a task
client fetches a file
on a task for
a task for the
a key point is
task for the duration
key point is that
for the duration of
point is that we
the file server grants
is that we are
the duration of a
that we are plotting
duration of a step
file server grants it
we are plotting the
server grants it permission
are plotting the delivery
grants it permission to
plotting the delivery latency
it permission to cache
the delivery latency of
the result of this
permission to cache the
delivery latency of all
to cache the file
latency of all packets
cache the file for
result of this work
the file for a
of this work is
file for a limited
this work is a
for a limited period
work is a set
not just lost ones
is a set of
a set of partial
set of partial proofs
of partial proofs of
and adds it to
partial proofs of work
adds it to a
the spikes in latency
it to a list
proofs of work and
spikes in latency are
of work and a
in latency are triggered
work and a set
latency are triggered by
and a set of
the main conclusion we
are triggered by losses
a set of full
main conclusion we draw
set of full proofs
triggered by losses that
of full proofs of
conclusion we draw from
full proofs of work
by losses that lead
we draw from the
losses that lead to
implementation of clients that
draw from the test
of clients that cache
that lead to packets
clients that cache the
the number of proofs
from the test cases
number of proofs in
that cache the file
the test cases exhibitthe
of proofs in each
lead to packets piling
proofs in each set
test cases exhibitthe graphs
in each set has
to packets piling up
each set has a
cases exhibitthe graphs show
set has a poisson
packets piling up both
exhibitthe graphs show how
if the client modifies
piling up both at
has a poisson distribution
up both at the
the client modifies and
both at the receiver
graphs show how priorities
at the receiver and
client modifies and then
the receiver and the
show how priorities affect
receiver and the sender
modifies and then closes
how priorities affect rpcs
partial proofs with a
and then closes the
proofs with a large
then closes the file
priorities affect rpcs and
with a large mean
affect rpcs and how
a large mean and
rpcs and how prefetching
large mean and full
and how prefetching a
mean and full proofs
it transmits the new
and full proofs with
how prefetching a prefetch
full proofs with a
transmits the new contents
ip delays correctly received
the new contents to
proofs with a small
prefetching a prefetch penalty
delays correctly received packets
a prefetch penalty is
with a small mean
prefetch penalty is that
correctly received packets at
penalty is that the
new contents to the
is that the implementation
received packets at the
that the implementation could
contents to the server
the implementation could be
nodes that work on
implementation could be im
packets at the receiver
that work on tasks
at the receiver while
work on tasks are
which mafs is implemented
the receiver while waiting
mafs is implemented in
on tasks are called
receiver while waiting for
tasks are called a
while waiting for missing
are called a miners
ing changes mfs behaviour
is implemented in c
waiting for missing packets
implemented in c on
for missing packets sequenced
in c on freebsd
missing packets sequenced earlier
miners have identical power
packets sequenced earlier by
in all three time
sequenced earlier by the
all three time periods
the client is a
earlier by the sender
client is a usermakes
and hence identical probabilities
is a usermakes a
hence identical probabilities to
a usermakes a callback
identical probabilities to generate
usermakes a callback rpc
probabilities to generate proofs
more time proved to
to generate proofs of
it also delays packets
a callback rpc to
time proved to incorporate
callback rpc to any
proved to incorporate a
rpc to any other
also delays packets at
to any other clients
to incorporate a mechanism
any other clients on
delays packets at the
other clients on the
incorporate a mechanism to
generate proofs of work
a mechanism to inhibit
packets at the sender
mechanism to inhibit prefetching
clients on the list
at the sender when
the sender when it
the bitcoin network pays
sender when it cuts
bitcoin network pays for
the is spent on
when it cuts down
network pays for full
it cuts down on
pays for full proofs
is spent on rpcs
for full proofs of
cuts down on the
full proofs of work
spent on rpcs to
a client level process
down on the sending
client level process that
on rpcs to fetch
level process that stores
on the sending window
process that stores cached
the sending window size
that stores cached files
sending window size in
stores cached files in
window size in response
cached files in a
size in response to
files in a local
in response to the
in a local filesystem
response to the loss
to acquire this payoff
rpcs to fetch file
acquire this payoff an
to the loss events
this payoff an entity
to fetch file attributes
the that receives a
payoff an entity publishes
that receives a callback
fetch file attributes with
receives a callback rpc
an entity publishes a
a callback rpc discards
file attributes with prefetching
callback rpc discards its
entity publishes a task
rpc discards its cached
attributes with prefetching enabled
discards its cached copy
publishes a task task
its cached copy of
the delays caused by
a task task and
cached copy of the
task task and its
copy of the file
task and its corresponding
delays caused by these
and its corresponding proof
with prefetching enabled current
its corresponding proof of
caused by these two
corresponding proof of work
prefetching enabled current prefetching
proof of work to
by these two mechanisms
of work to the
enabled current prefetching algorithm
work to the network
these two mechanisms are
server also stores its
two mechanisms are illustrated
current prefetching algorithm does
mechanisms are illustrated in
also stores its copies
are illustrated in figure
prefetching algorithm does not
the payoff goes to
algorithm does not correlate
payoff goes to the
does not correlate file
goes to the id
stores its copies of
to the id associated
not correlate file accesses
the id associated with
its copies of files
id associated with task
correlate file accesses with
copies of files in
file accesses with than
of files in a
accesses with than without
files in a local
in a local filesystem
where single packet losses
the bitcoin protocol normalizes
single packet losses cause
since the time to
packet losses cause spikes
the time to receive
bitcoin protocol normalizes revenue
losses cause spikes in
time to receive a
protocol normalizes revenue such
to receive a fetch
if an application has
cause spikes in delivery
an application has the
normalizes revenue such that
application has the file
spikes in delivery latency
revenue such that the
has the file open
in delivery latency that
the file open when
such that the average
file open when its
delivery latency that last
that the average total
attributes request the processes
latency that last for
open when its client
that last for hundreds
when its client re
last for hundreds of
request the processes which
the average total revenue
the processes which make
for hundreds of packets
processes which make them
average total revenue distributed
total revenue distributed in
system operations from applications
revenue distributed in each
operations from applications are
distributed in each step
the maelstrom configuration used
in each step is
maelstrom configuration used is
each step is a
configuration used is r
but if this were
from applications are redirected
if this were done
step is a constant
applications are redirected to
is a constant throughout
are redirected to user
a constant throughout the
redirected to user level
constant throughout the execution
to user level ceives
throughout the execution of
user level ceives the
the execution of the
level ceives the callback
execution of the system
two changes or reply
changes or reply is
or reply is negligible
the file is discarded
file is discarded once
any node can transact
is discarded once it
the increased time is
node can transact bitcoins
increased time is due
discarded once it is
time is due to
can transact bitcoins to
is due to a
once it is closed
due to a greater
transact bitcoins to another
to a greater queue
bitcoins to another node
to another node by
another node by issuing
when through a kernel
node by issuing a
through a kernel module
by issuing a bitcoin
a kernel module at
issuing a bitcoin transaction
kernel module at the
module at the client
rpc times at intermediate
times at intermediate bandwidth
nodes that generate tasks
that generate tasks but
generate tasks but outsource
tasks but outsource the
but outsource the work
outsource the work are
the work are called
work are called pools
pools send tasks to
fetch prefetch metadata store
send tasks to miners
prefetch metadata store fetch
tasks to miners over
metadata store fetch file
to miners over the
store fetch file attributes
miners over the network
the miners receive the
miners receive the tasks
pull file update fetch
file update fetch file
update fetch file data
and send the partial
send the partial and
the partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work to
of work to the
prefetch file data lock
work to the pool
file data lock a
data lock a file
apart from working on
from working on tasks
most metadata rpcs store
metadata rpcs store file
rpcs store file data
unlink file such as
file such as deleting
such as deleting a
as deleting a modified
deleting a modified file
such optimisations can be
optimisations can be effective
can be effective at
and receipt are instantaneous
be effective at low
effective at low bandwidth
we assume that the
when there is a
there is a natural
assume that the number
is a natural delay
that the number of
the number of miners
number of miners is
but at high bandwidth
of miners is large
miners is large enough
is large enough such
large enough such that
enough such that mining
an artificial delay in
such that mining power
artificial delay in writing
that mining power can
delay in writing back
mining power can be
in writing back updates
power can be split
writing back updates introduces
can be split arbitrarily
back updates introduces inconsistencies
be split arbitrarily without
updates introduces inconsistencies between
split arbitrarily without resolution
introduces inconsistencies between the
arbitrarily without resolution constraints
inconsistencies between the client
between the client and
the client and the
client and the file
and the file server
denote the number of
the number of pools
number of pools with
of pools with p
this can be acceptable
can be acceptable at
be acceptable at low
acceptable at low bandwidths
the total number of
total number of mining
when the user may
number of mining power
the user may table
of mining power in
mining power in the
power in the system
in the system with
the system with m
system with m and
with m and the
m and the miners
priorities for mafs remote
and the miners participating
for mafs remote procedure
the miners participating in
mafs remote procedure calls
miners participating in pool
participating in pool i
be grateful to be
grateful to be able
to be able to
be able to use
able to use the
to use the file
use the file system
the file system at
file system at all
but should be avoided
should be avoided when
be avoided when bandwidth
we use a quasistatic
avoided when bandwidth is
use a quasistatic analysis
when bandwidth is unconstrained
a quasistatic analysis where
quasistatic analysis where miner
analysis where miner participation
where miner participation in
miner participation in a
participation in a pool
in a pool does
a pool does not
pool does not change
does not change over
not change over time
mafs avoids the need
avoids the need for
the need for modes
solo mining a solo
need for modes by
mining a solo miner
for modes by using
a solo miner is
modes by using asynchronous
solo miner is a
by using asynchronous remote
miner is a node
using asynchronous remote procedure
is a node that
asynchronous remote procedure calls
a node that generates
remote procedure calls between
node that generates its
procedure calls between a
that generates its own
calls between a client
generates its own tasks
between a client and
a client and the
client and the file
and the file server
the file server writeback
in every step it
file server writeback at
every step it generates
server writeback at all
step it generates a
writeback at all bandwidth
it generates a task
at all bandwidth levels
works on it for
and incorporates a new
on it for the
incorporates a new upare
it for the duration
a new upare divided
for the duration of
new upare divided into
the duration of the
upare divided into several
duration of the step
divided into several types
of the step and
into several types depending
the step and if
several types depending on
step and if it
u trsu t u
and if it finds
trsu t u trsu
if it finds a
t u trsu t
types depending on their
u trsu t utrsut
it finds a full
depending on their function
finds a full proof
a full proof of
full proof of work
request queued request send
rpcs date propagation algorithm
queued request send reply
it publishes this proof
date propagation algorithm to
publishes this proof of
request send reply queued
this proof of work
propagation algorithm to reduce
proof of work to
send reply queued reply
of work to earn
algorithm to reduce the
work to earn the
to reduce the possibility
to earn the payoff
reply queued reply send
reduce the possibility of
the possibility of inconsisto
possibility of inconsisto fetch
of inconsisto fetch and
inconsisto fetch and store
fetch and store data
and store data are
store data are self
pools a pool is
a pool is a
pool is a node
is a node that
a node that serves
node that serves as
that serves as a
serves as a coordinator
as a coordinator and
a coordinator and multiple
coordinator and multiple miners
and multiple miners can
multiple miners can register
miners can register to
can register to a
register to a pool
to a pool and
a pool and work
pool and work for
and work for it
as new operations are
new operations are added
operations are added to
in every step it
are added to the
every step it generates
added to the tail
step it generates a
to the tail tions
it generates a task
the tail tions include
generates a task for
tail tions include fetching
a task for each
tions include fetching and
task for each registered
include fetching and setting
for each registered miner
fetching and setting file
each registered miner and
and setting file attributes
registered miner and sends
miner and sends it
and sends it over
sends it over the
it over the network
and directory of the
directory of the log
each miner receives its
the client flushes operations
miner receives its task
client flushes operations serially
receives its task and
flushes operations serially from
its task and works
operations serially from the
task and works on
serially from the head
and works on it
from the head of
works on it for
the head of operations
on it for the
head of operations such
percentage of packets recovered
it for the duration
of operations such as
for the duration of
operations such as creating
the duration of the
such as creating and
duration of the step
as creating and unlinking
creating and unlinking files
at the end of
the end of the
control rpcs the log
end of the step
the miner sends the
miner sends the pool
sends the pool the
the pool the full
pool the full and
server traffic consists of
the full and the
traffic consists of a
full and the partial
consists of a variety
and the partial proofs
of a variety of
the partial proofs of
partial proofs of work
a variety of foreground
proofs of work it
variety of foreground include
of work it has
work it has found
of foreground include locking
foreground include locking files
include locking files and
relatively prime interleaves offer
locking files and the
prime interleaves offer better
the pool receives the
interleaves offer better performance
files and the server
pool receives the proofs
and the server s
receives the proofs of
the server s callback
the proofs of work
server s callback to
proofs of work of
s callback to invalidate
of work of all
callback to invalidate a
work of all its
to invalidate a rpcs
of all its miners
invalidate a rpcs for
a rpcs for control
rpcs for control operations
for control operations and
control operations and fetching
registers the partial proofs
operations and fetching file
the partial proofs of
and fetching file data
partial proofs of work
proofs of work and
of work and publishes
work and publishes the
and publishes the full
publishes the full proofs
and a stream client
a stream client s
stream client s cached
client s cached copy
s cached copy of
it calculates its overall
cached copy of a
calculates its overall revenue
copy of a file
and proceeds to distribute
of background rpcs for
proceeds to distribute it
background rpcs for logged
to distribute it among
rpcs for logged operations
distribute it among its
it among its miners
when bandwidth is high
rpc times at high
each miner receives revenue
times at high bandwidth
miner receives revenue proportional
replayed logged operations complete
receives revenue proportional to
logged operations complete quickly
revenue proportional to its
proportional to its success
to its success in
its success in the
success in the current
with little extra delay
in the current step
when bandwidth is low
namely the ratio of
logged operations are de
the ratio of its
ratio of its partial
of its partial proofs
its partial proofs of
partial proofs of work
communication adaptation layed in
proofs of work out
adaptation layed in proportion
of work out of
layed in proportion to
work out of all
in proportion to the
out of all partial
proportion to the foreground
of all partial proofs
to the foreground rpc
all partial proofs of
the foreground rpc traffic
partial proofs of work
foreground rpc traffic and
proofs of work the
rpc traffic and the
of work the pool
traffic and the availto
work the pool received
and the availto reduce
the availto reduce its
availto reduce its network
reduce its network communication
its network communication when
we assume that pools
network communication when bandwidth
assume that pools do
communication when bandwidth is
that pools do not
when bandwidth is low
pools do not collect
do not collect fees
not collect fees of
collect fees of the
fees of the revenue
pool fees and their
a mobile file system
fees and their implications
mobile file system client
and their implications on
file system client can
their implications on our
system client can automatically
implications on our analysis
client can automatically adapt
on our analysis are
can automatically adapt its
our analysis are discussed
automatically adapt its communication
analysis are discussed in
adapt its communication strategy
are discussed in section
its communication strategy to
discussed in section ix
communication strategy to the
strategy to the available
to the available bandwidth
block withholding miner a
withholding miner a miner
miner a miner registered
a miner registered at
miner registered at a
registered at a pool
at a pool can
a pool can perform
rpc priorities cations transfer
pool can perform the
priorities cations transfer a
can perform the classical
cations transfer a large
perform the classical block
transfer a large volume
the classical block withholding
a large volume of
classical block withholding attack
large volume of data
volume of data that
of data that the
data that the user
that the user is
an attacker miner operates
the user is unlikely
attacker miner operates as
user is unlikely to
miner operates as if
is unlikely to require
operates as if it
unlikely to require immediately
as if it worked
if it worked for
it worked for the
worked for the pool
consuming bandwidth that can
bandwidth that can be
it receives its tasks
that can be used
receives its tasks and
can be used mafs
its tasks and works
be used mafs uses
tasks and works on
used mafs uses priorities
and works on them
mafs uses priorities to
uses priorities to reduce
priorities to reduce contention
to reduce contention between
reduce contention between foreground
only at the end
contention between foreground for
at the end of
between foreground for important
the end of each
foreground for important tasks
end of each round
of each round it
each round it sends
round it sends only
it sends only its
sends only its partial
only its partial proofs
its partial proofs of
partial proofs of work
consider an application that
an application that activities
application that activities and
and omits full proofs
that activities and deferrable
omits full proofs of
activities and deferrable background
full proofs of work
and deferrable background activities
proofs of work if
of work if it
work if it had
if it had found
it had found any
adaptive rpc fetches images
rpc fetches images from
fetches images from a
images from a file
from a file server
the pool registers the
pool registers the miner
registers the miner s
the miner s partial
miner s partial proofs
processes each in turn
but cannot distinguish between
cannot distinguish between miners
distinguish between miners running
between miners running honestly
preferentially allocates bandwidth to
miners running honestly and
allocates bandwidth to foreground
running honestly and block
bandwidth to foreground rpcs
honestly and block withholding
and block withholding miners
unlike plays the resulting
plays the resulting image
the implications are that
implications are that a
are that a miner
and writes it to
that a miner that
writes it to the
a miner that engages
it to the server
miner that engages in
that engages in block
engages in block withholding
in block withholding does
if the user little
block withholding does not
the user little work
withholding does not contribute
does not contribute to
not contribute to the
contribute to the pool
to the pool s
the pool s overall
pool s overall mining
s overall mining power
but still shares the
still shares the pool
shares the pool s
the pool s revenue
which assigns a lower
pool s revenue according
assigns a lower priority
s revenue according to
a lower priority to
revenue according to its
lower priority to writeback
according to its sent
priority to writeback in
to its sent partial
to writeback in wants
its sent partial proofs
writeback in wants to
sent partial proofs of
in wants to see
partial proofs of work
wants to see the
to see the processed
see the processed images
to reason about a
reason about a pool
about a pool s
a pool s efficiency
pool s efficiency we
s efficiency we define
efficiency we define its
one else wants to
we define its per
else wants to im
miner revenue as follows
mafs has a finer
grained differentiation mediately read
differentiation mediately read them
writing the output back
the output back will
the revenue density of
output back will interfere
back will interfere with
revenue density of a
will interfere with between
interfere with between rpcs
density of a pool
of a pool is
a pool is the
pool is the ratio
and uses priorities at
is the ratio between
uses priorities at all
the ratio between the
priorities at all bandwidths
ratio between the average
between the average revenue
the average revenue a
average revenue a pool
this alfetching the next
revenue a pool member
alfetching the next image
a pool member earns
pool member earns and
member earns and the
earns and the average
and slow down the
and the average revenue
slow down the application
the average revenue it
average revenue it would
revenue it would have
it would have earned
would have earned as
lows control over bandwidth
have earned as a
earned as a solo
control over bandwidth allocation
as a solo miner
over bandwidth allocation at
bandwidth allocation at the
allocation at the level
at the level of
the revenue density of
the level of individinterference
revenue density of a
level of individinterference due
density of a solo
of individinterference due to
of a solo miner
individinterference due to write
due to write traffic
to write traffic is
write traffic is often
traffic is often solved
and that of a
is often solved by
that of a miner
often solved by writing
of a miner working
solved by writing ual
a miner working with
by writing ual rpcs
miner working with an
working with an unattacked
with an unattacked pool
an unattacked pool are
unattacked pool are one
without requiring that an
requiring that an mafs
that an mafs client
an mafs client is
if a pool is
mafs client is aware
a pool is attacked
client is aware of
pool is attacked with
is aware of back
is attacked with block
aware of back updates
attacked with block withholding
of back updates asynchronously
its revenue density decreases
the application in our
application in our example
in our example the
our example the precise
example the precise bandwidth
continuous analysis because our
layered interleaving recovery percentage
can start reading another
interleaving recovery percentage and
analysis because our analysis
recovery percentage and latency
start reading another image
percentage and latency c
because our analysis will
reading another image without
our analysis will be
another image without waiting
analysis will be of
image without waiting for
will be of the
without waiting for the
be of the average
layered interleaving and bursty
of the average revenue
waiting for the previwhen
interleaving and bursty loss
for the previwhen choosing
and bursty loss thus
the previwhen choosing priorities
bursty loss thus far
loss thus far we
we will consider proofs
thus far we have
will consider proofs of
far we have shown
consider proofs of work
we have shown how
automatic assignment and fine
have shown how maelstrom
assignment and fine ous
shown how maelstrom effectively
and fine ous output
how maelstrom effectively hides
fine ous output to
maelstrom effectively hides loss
both full and partial
effectively hides loss from
ous output to be
hides loss from tcp
output to be sent
to be sent to
be sent to the
sent to the file
as continuous deterministic sizes
to the file server
ip for packets dropped
for packets dropped with
packets dropped with uniform
dropped with uniform randomness
according to their probability
asynchronous writeback granularity are
writeback granularity are preferable
work on a task
on a task therefore
a task therefore results
we examine the performance
to avoid the need
examine the performance of
avoid the need for
the performance of the
the need for user
task therefore results in
need for user intervenallows
performance of the layered
for user intervenallows i
therefore results in a
of the layered interleaving
results in a deterministic
the layered interleaving algorithm
in a deterministic fraction
a deterministic fraction of
deterministic fraction of proof
o and cpu processing
fraction of proof of
and cpu processing to
of proof of work
cpu processing to be
showing how different parameterizations
processing to be overlapped
how different parameterizations handle
different parameterizations handle bursty
parameterizations handle bursty loss
handle bursty loss patterns
t he p ool
he p ool g
we use a loss
p ool g ame
use a loss model
ool g ame a
tion and provide the
a loss model where
and provide the maximum
loss model where packets
provide the maximum degree
model where packets are
the maximum degree of
the pool block withholding
where packets are dropped
maximum degree of differentiation
packets are dropped in
pool block withholding attack
are dropped in bursts
degree of differentiation among
dropped in bursts of
block withholding attack just
of differentiation among ecution
in bursts of fixed
differentiation among ecution time
bursts of fixed length
withholding attack just as
among ecution time and
attack just as a
ecution time and utilising
just as a miner
time and utilising bandwidth
as a miner can
and utilising bandwidth more
allowing us to study
utilising bandwidth more efficiently
a miner can perform
us to study the
miner can perform block
to study the impact
can perform block withholding
study the impact of
perform block withholding on
the impact of burst
block withholding on a
impact of burst length
withholding on a pool
of burst length on
on a pool j
burst length on performance
the link has a
a pool i can
link has a one
scheduling rpcs based on
pool i can use
rpcs based on priorities
i can use some
based on priorities is
can use some of
on priorities is only
use some of its
priorities is only ever
some of its mining
of its mining power
its mining power to
if bandwidth is low
mining power to infiltrate
percentage of packets recovered
power to infiltrate a
to infiltrate a pool
infiltrate a pool j
a pool j and
contention arises when files
pool j and perform
j and perform a
arises when files are
and perform a block
perform a block withholding
when files are being
a block withholding attack
files are being effective
block withholding attack on
are being effective if
withholding attack on j
being effective if concurrent
effective if concurrent rpcs
if concurrent rpcs usually
concurrent rpcs usually end
denote the amount of
rpcs usually end up
reed solomon layered interleaving
usually end up with
the amount of such
end up with different
amount of such infiltrating
up with different prifetched
of such infiltrating mining
with different prifetched at
such infiltrating mining power
different prifetched at the
infiltrating mining power at
prifetched at the same
mining power at step
at the same time
power at step t
the same time as
at step t by
same time as updates
step t by xi
time as updates are
as updates are written
updates are written back
but processes are too
processes are too coarse
miners working for pool
working for pool i
grained for this purpose
either mining honestly or
mining honestly or used
honestly or used for
or used for infiltrating
tention can be mitigated
used for infiltrating pool
can be mitigated by
for infiltrating pool j
be mitigated by prioritising
mitigated by prioritising file
by prioritising file fetch
prioritising file fetch rpcs
file fetch rpcs above
are loyal to pool
fetch rpcs above file
loyal to pool i
based priorities provide some
at the end of
priorities provide some more
the end of a
provide some more detail
end of a round
but the imporwriteback rpcs
pool i aggregates its
the imporwriteback rpcs to
i aggregates its revenue
imporwriteback rpcs to ensure
aggregates its revenue from
rpcs to ensure that
its revenue from mining
to ensure that they
revenue from mining in
ensure that they will
from mining in the
that they will be
mining in the current
they will be preferentially
in the current round
will be preferentially allo
the current round and
current round and from
round and from its
and from its infiltration
from its infiltration in
tance of a file
its infiltration in the
of a file can
infiltration in the previous
a file can be
in the previous round
file can be hard
can be hard to
be hard to determine
hard to determine automatically
it distributes the revenue
distributes the revenue evenly
the revenue evenly among
revenue evenly among all
evenly among all its
among all its loyal
all its loyal miners
its loyal miners according
loyal miners according to
miners according to their
according to their partial
to their partial proofs
their partial proofs of
partial proofs of work
files can be too
can be too numerous
be too numerous for
the pool s miners
too numerous for the
pool s miners are
numerous for the user
s miners are oblivious
for the user to
miners are oblivious to
the user to manually
are oblivious to their
user to manually assign
oblivious to their role
to manually assign priin
to their role and
manually assign priin this
their role and they
assign priin this section
role and they operate
solomon versus layered interleaving
and they operate as
versus layered interleaving latency
they operate as regular
layered interleaving latency of
operate as regular honest
we assess the effectiveness
as regular honest miners
assess the effectiveness of
the effectiveness of asynchronous
effectiveness of asynchronous orities
ms and a loss
and a loss rate
rpcs are more numerous
a loss rate of
revenue convergence note that
but priorities can be
convergence note that pool
priorities can be autowriteback
note that pool j
can be autowriteback and
that pool j sends
be autowriteback and rpc
pool j sends its
autowriteback and rpc priorities
j sends its revenue
and rpc priorities in
sends its revenue to
rpc priorities in mafs
its revenue to infiltrators
priorities in mafs under
revenue to infiltrators from
in mafs under different
to infiltrators from pool
mafs under different levels
infiltrators from pool i
under different levels matically
from pool i at
different levels matically assigned
pool i at the
levels matically assigned to
i at the end
matically assigned to them
at the end of
assigned to them according
the end of the
where it is varied
end of the step
to them according to
them according to the
according to the operation
to the operation the
the operation the rpc
operation the rpc of
and this revenue is
the rpc of bandwidth
this revenue is calculated
rpc of bandwidth availability
revenue is calculated in
is calculated in pool
calculated in pool i
in pool i at
pool i at the
i at the beginning
at the beginning of
the beginning of the
mbps flow of udp
beginning of the subsequent
flow of udp packets
of the subsequent step
we examine the degree
of udp packets is
examine the degree corresponds
udp packets is sent
the degree corresponds to
packets is sent over
is sent over it
if there is a
there is a chain
is a chain of
as shown in table
a chain of pools
chain of pools of
of pools of length
where each pool infiltrates
each pool infiltrates the
pool infiltrates the next
we show that our
show that our observation
that our observation in
or rpcs to which
our observation in section
rpcs to which a
observation in section iv
to which a file
the pool revenue will
which a file system
pool revenue will not
a file system client
revenue will not be
file system client that
will not be static
e is correct for
system client that avoids
is correct for high
client that avoids switching
correct for high loss
that avoids switching modes
for high loss rates
avoids switching modes in
since the revenue from
switching modes in re
high loss rates if
the revenue from infiltration
loss rates if the
revenue from infiltration takes
rates if the interleaves
from infiltration takes one
if the interleaves are
that the user has
the interleaves are relatively
the user has to
interleaves are relatively prime
user has to wait
infiltration takes one step
has to wait for
takes one step to
one step to take
step to take each
to take each hop
performance improves substantially when
improves substantially when loss
substantially when loss rates
when loss rates are
loss rates are high
rates are high and
are high and losses
high and losses are
and losses are bursty
max is the longest
or sponse to bandwidth
is the longest chain
sponse to bandwidth changes
the longest chain in
the graph plots the
longest chain in the
to bandwidth changes is
chain in the system
graph plots the percentage
bandwidth changes is able
plots the percentage of
changes is able to
the percentage of lost
is able to adapt
percentage of lost packets
able to adapt to
of lost packets successfully
to adapt to both
lost packets successfully recovered
adapt to both insufficient
packets successfully recovered on
to both insufficient rpcs
successfully recovered on the
both insufficient rpcs whose
the revenue stabilizes after
insufficient rpcs whose results
recovered on the y
rpcs whose results can
whose results can be
results can be delayed
axis against an xaxis
against an xaxis of
an xaxis of loss
such as writing back
xaxis of loss rates
as writing back data
of loss rates on
writing back data bandwidth
loss rates on a
if there are loops
rates on a log
there are loops in
on a log scale
are loops in the
loops in the infiltration
and conditions under which
in the infiltration graph
conditions under which bandwidth
under which bandwidth is
the maelstrom configuration used
which bandwidth is plentiful
maelstrom configuration used is
configuration used is r
the system will converge
system will converge to
will converge to a
converge to a certain
to a certain revenue
as stated in the
stated in the following
in the following lemma
prefetching is an example
is an example of
an example of speculative
example of speculative communication
priority rpc whose results
rpc whose results can
whose results can improve
results can improve performance
can improve performance if
improve performance if bandwidth
performance if bandwidth is
if bandwidth is high
if infiltration rates are
infiltration rates are constant
the pool revenues converge
denote the revenue density
the revenue density of
asynchronous writeback but can
revenue density of pool
writeback but can be
density of pool i
but can be safely
of pool i at
can be safely omitted
pool i at the
be safely omitted if
i at the end
safely omitted if bandwidth
at the end of
omitted if bandwidth is
the end of step
if bandwidth is low
end of step t
of step t by
step t by ri
mafs asynchronous writeback is
asynchronous writeback is based
writeback is based on
is based on similar
based on similar mechanisms
and define the revenue
on similar mechanisms the
define the revenue density
similar mechanisms the initial
the revenue density vector
mechanisms the initial priority
revenue density vector r
the initial priority is
initial priority is never
priority is never modified
but the file server
the file server somefound
file server somefound in
server somefound in many
somefound in many mobile
in many mobile file
many mobile file systems
we show the ability
show the ability of
the ability of layered
ability of layered interleaving
of layered interleaving to
layered interleaving to provide
interleaving to provide gracefully
rather than making times
to provide gracefully degrading
than making times requests
provide gracefully degrading performance
making times requests an
gracefully degrading performance in
times requests an increase
degrading performance in the
requests an increase in
performance in the face
an increase in the
in the face of
increase in the priority
the face of bursty
in the priority of
face of bursty loss
the priority of an
priority of an rpc
of an rpc to
an rpc to transmit
rpc to transmit an
to transmit an rpc
transmit an rpc when
p in every round
an rpc when an
we plot the percentage
rpc when an application
plot the percentage of
when an application performs
the percentage of lost
pool i uses its
an application performs a
i uses its mining
percentage of lost packets
uses its mining power
application performs a metadata
of lost packets successfully
performs a metadata update
its mining power of
lost packets successfully recovered
mining power of m
a metadata update or
packets successfully recovered against
metadata update or file
successfully recovered against the
update or file data
recovered against the length
against the length of
the length of loss
length of loss bursts
of loss bursts for
loss bursts for two
bursts for two different
for two different sets
j used for direct
the operation is logged
used for direct mining
two different sets of
for direct mining p
operation is logged and
different sets of interleaves
is logged and replayed
logged and replayed to
and replayed to the
replayed to the file
to the file server
the file server after
and in the bottom
file server after a
in the bottom graph
server after a delay
the bottom graph we
bottom graph we plot
graph we plot the
and shares it among
we plot the average
shares it among its
this scheme reduces bandwidth
plot the average latency
it among its m
the average latency at
scheme reduces bandwidth utilisation
average latency at which
reduces bandwidth utilisation because
latency at which the
bandwidth utilisation because some
at which the packets
utilisation because some logged
request queued request send
which the packets were
queued request send reply
because some logged operations
request send reply queued
the packets were recovered
send reply queued reply
some logged operations may
reply queued reply send
logged operations may be
operations may be superceded
may be superceded by
be superceded by later
recovery latency is defined
superceded by later ones
latency is defined as
is defined as the
defined as the difference
as the difference between
the difference between the
all sums are over
difference between the eventual
sums are over the
between the eventual delivery
are over the range
the eventual delivery time
eventual delivery time of
e dd e dd
delivery time of the
dd e dd f
time of the recovered
e dd f edd
of the recovered packet
dd f edd f
the recovered packet and
f edd f g
recovered packet and the
edd f g fg
packet and the oneway
f g fg e
and the oneway latency
g fg e ed
the oneway latency of
fg e ed e
oneway latency of the
e ed e e
latency of the link
ed e e d
e e d f
e d f eed
d f eed f
f eed f g
eed f g fg
we confirmed that the
f g fg e
confirmed that the emulab
g fg e d
that the emulab link
fg e d e
the emulab link had
e d e d
emulab link had almost
d e d f
link had almost no
had almost no jitter
almost no jitter on
no jitter on correctly
jitter on correctly delivered
denote the direct mining
on correctly delivered packets
the direct mining revenue
direct mining revenue density
mining revenue density of
revenue density of each
density of each pool
way latency an accurate
latency an accurate estimate
an accurate estimate of
accurate estimate of expected
estimate of expected lossless
which is a constant
of expected lossless delivery
is a constant factor
expected lossless delivery time
increasing the interleaves results
the interleaves results in
interleaves results in much
results in much higher
in much higher recovery
much higher recovery percentages
higher recovery percentages at
recovery percentages at large
percentages at large burst
at large burst sizes
but comes at the
comes at the cost
at the cost of
the cost of higher
cost of higher recovery
of higher recovery latency
bcq pcb c bq
pcb c bq pcb
c bq pcb cbqpcb
bq pcb cbqpcb n
pcb cbqpcb n n
cbqpcb n n on
n n on n
n on n c
on n c bc
n c bc bonn
c bc bonn c
bc bonn c bc
bonn c bc b
c bc b cbcb
c bc b cbcb
set of interleaves catches
p the revenue of
of interleaves catches almost
the revenue of pool
interleaves catches almost all
revenue of pool i
catches almost all packets
of pool i in
almost all packets in
pool i in step
all packets in an
i in step t
packets in an extended
in step t taken
in an extended burst
step t taken through
an extended burst of
t taken through infiltration
taken through infiltration from
through infiltration from pool
infiltration from pool j
from pool j s
pool j s revenue
j s revenue in
s revenue in step
revenue in step t
packets at an average
c bc b cbcb
at an average latency
an average latency of
average latency of around
c bc b cbcb
while repairing all random
repairing all random singleton
all random singleton losses
random singleton losses within
pool i distributes this
i distributes this revenue
distributes this revenue among
this revenue among its
revenue among its mi
the graphs also show
graphs also show recovery
also show recovery latency
i members loyal and
show recovery latency rising
c b cb a
members loyal and infiltrators
b cb a a
recovery latency rising gracefully
cb a a k
latency rising gracefully with
a a k k
rising gracefully with the
a k k j
gracefully with the increase
define the p p
k k j jk
the p p infiltration
with the increase in
p p infiltration matrix
the increase in loss
p infiltration matrix by
increase in loss burst
infiltration matrix by its
in loss burst length
matrix by its i
the longer the burst
c bc b cbcb
bc b cbcb kk
b cbcb kk j
the longer it takes
cbcb kk j m
longer it takes to
kk j m lkjj
it takes to recover
j m lkjj ml
takes to recover the
m lkjj ml ml
to recover the lost
lkjj ml ml c
recover the lost packets
ml ml c b
ml c b c
c b c b
b c b cb
c b cb kj
b cb kj ih
the maelstrom configuration used
cb kj ih i
maelstrom configuration used is
kj ih i h
configuration used is r
ih i h ih
i ij and the
i h ih j
ij and the revenue
and the revenue vector
the revenue vector at
revenue vector at step
vector at step t
at step t is
step t is r
in the pool game
the pool game pools
pool game pools try
c bc b c
game pools try to
bc b c bc
pools try to optimize
b c bc b
try to optimize their
c bc b cbcb
to optimize their infiltration
bc b cbcb rpc
optimize their infiltration rates
b cbcb rpc times
their infiltration rates of
cbcb rpc times at
infiltration rates of other
rpc times at low
writes execution time speedup
times at low bandwidth
rates of other pools
of other pools to
other pools to maximize
pools to maximize their
to maximize their revenue
request queued request send
the overall number of
queued request send reply
overall number of miners
request send reply queued
number of miners and
send reply queued reply
of miners and the
reply queued reply send
miners and the number
queued reply send total
and the number of
reply send total time
the number of miners
number of miners loyal
of miners loyal to
miners loyal to each
loyal to each pool
to each pool remain
each pool remain constant
pool remain constant throughout
remain constant throughout the
constant throughout the game
time progresses in rounds
execution time speedup execution
time speedup execution time
speedup execution time speedup
execution time speedup execution
let s be a
time speedup execution time
s be a constant
speedup execution time speedup
be a constant integer
execution time speedup no
a constant integer large
time speedup no priorities
constant integer large enough
integer large enough that
large enough that revenue
we show histograms of
enough that revenue can
show histograms of recovery
that revenue can be
histograms of recovery latencies
revenue can be approximated
of recovery latencies for
can be approximated as
recovery latencies for the
be approximated as its
latencies for the two
approximated as its convergence
for the two interleave
as its convergence limit
the two interleave configurations
two interleave configurations under
interleave configurations under different
configurations under different burst
under different burst lengths
in each round the
each round the system
round the system takes
the system takes s
system takes s steps
the histograms confirm the
takes s steps and
histograms confirm the trends
s steps and then
confirm the trends described
steps and then a
the trends described above
and then a single
then a single pool
packet recoveries take longer
picked with a round
recoveries take longer from
take longer from left
longer from left to
from left to right
left to right as
to right as we
right as we increase
as we increase loss
we increase loss burst
may change its infiltration
increase loss burst length
change its infiltration rates
its infiltration rates of
infiltration rates of all
rates of all other
of all other pools
and from top to
from top to bottom
top to bottom as
to bottom as we
bottom as we increase
the total revenue of
as we increase the
total revenue of each
we increase the interleave
revenue of each step
increase the interleave values
of each step is
each step is normalized
step is normalized to
illustrates the difference between
the difference between a
so the revenue per
difference between a traditional
the revenue per round
between a traditional fec
revenue per round is
a traditional fec code
per round is one
rpc traffic with varying
traditional fec code and
traffic with varying bandwidth
fec code and layered
code and layered interleaving
the pool taking a
and layered interleaving by
pool taking a step
layered interleaving by plotting
taking a step knows
interleaving by plotting a
a step knows the
step knows the rate
knows the rate of
the rate of infiltrators
rate of infiltrators attacking
of infiltrators attacking it
though not their identity
and the revenue rates
the revenue rates of
revenue rates of each
rates of each of
of each of the
each of the other
of the other pools
this knowledge is required
knowledge is required to
is required to optimize
show the time spent
required to optimize a
the time spent on
to optimize a pool
time spent on rpcs
optimize a pool s
spent on rpcs during
a pool s revenue
on rpcs during an
rpcs during an execution
during an execution of
an execution of the
execution of the simultaneous
as we see next
of the simultaneous writeback
the simultaneous writeback test
simultaneous writeback test from
writeback test from section
we explain in section
explain in section viii
in section viii how
section viii how a
viii how a pool
how a pool can
a pool can technically
pool can technically obtain
can technically obtain this
technically obtain this knowledge
with the bandwidth varying
the bandwidth varying according
general analysis recall that
bandwidth varying according to
analysis recall that mi
varying according to the
recall that mi is
according to the curve
that mi is the
to the curve in
mi is the number
is the number of
the number of miners
number of miners loyal
of miners loyal to
miners loyal to pool
loyal to pool i
rpcs are labelled as
are labelled as follows
is the number of
the number of miners
number of miners used
of miners used by
miners used by pool
used by pool i
by pool i to
pool i to infiltrate
i to infiltrate pool
to infiltrate pool j
infiltrate pool j at
pool j at step
j at step t
the mining rate of
mining rate of pool
rate of pool i
of pool i is
pool i is therefore
i is therefore the
is therefore the number
therefore the number of
the number of its
number of its loyal
of its loyal miners
its loyal miners minus
demand fetch to raise
loyal miners minus the
fetch to raise priority
miners minus the miners
to raise priority of
minus the miners it
raise priority of a
the miners it uses
priority of a prefetch
miners it uses for
of a prefetch rpc
it uses for infiltration
this effective mining rate
effective mining rate is
mining rate is divided
rate is divided by
is divided by the
divided by the total
by the total mining
the total mining rate
total mining rate in
mining rate in the
rate in the system
the time spent on
time spent on rpcs
spent on rpcs is
on rpcs is shown
namely the number of
rpcs is shown with
the number of all
is shown with prefetching
number of all miners
shown with prefetching enabled
of all miners that
all miners that do
miners that do not
that do not engage
do not engage in
not engage in block
engage in block withholding
denote the direct mining
the direct mining rate
direct mining rate of
mining rate of pool
rate of pool i
of pool i at
pool i at step
i at step t
at step t by
step t by pp
t by pp mi
by pp mi j
note that rpc interactions
that rpc interactions can
rpc interactions can overlap
interactions can overlap so
can overlap so the
overlap so the quantities
so the quantities for
the quantities for different
quantities for different rpc
for different rpc types
different rpc types are
rpc types are not
types are not additive
for some rpc types
the time spent on
time spent on particular
spent on particular activities
on particular activities is
particular activities is negligible
activities is negligible in
is negligible in proportion
negligible in proportion to
in proportion to the
proportion to the overall
to the overall time
k the revenue density
the revenue density of
revenue density of pool
density of pool i
of pool i at
pool i at the
attribute requests are small
i at the end
requests are small and
at the end of
are small and have
the end of step
small and have a
end of step t
and have a very
of step t is
have a very low
step t is its
a very low transmission
t is its revenue
very low transmission time
is its revenue from
low transmission time relative
its revenue from direct
transmission time relative to
revenue from direct mining
time relative to their
from direct mining together
relative to their queueing
direct mining together with
to their queueing delays
mining together with its
together with its revenue
with its revenue from
its revenue from infiltrated
revenue from infiltrated pools
such users happen to
users happen to be
happen to be working
to be working on
be working on the
divided by the number
working on the same
by the number of
on the same element
the number of its
the same element of
number of its loyal
same element of the
of its loyal miners
element of the design
its loyal miners together
loyal miners together with
miners together with block
it is clear that
is clear that satisfying
workloads with contention between
clear that satisfying a
with contention between priority
withholding infiltrators that attack
contention between priority levels
infiltrators that attack it
that satisfying a request
satisfying a request from
a request from stale
request from stale data
the grep workload consists
grep workload consists of
workload consists of validating
consists of validating cached
whether in from the
of validating cached files
in from the cache
elapsed time to compile
or on a server
time to compile mafs
on a server that
a server that has
server that has yet
that has yet to
has yet to see
yet to see a
to see a delayed
see a delayed writeback
would be visible to
be visible to the
visible to the user
to the user and
the user and costly
strong cache consistency is
cache consistency is certainly
consistency is certainly achievable
is certainly achievable in
certainly achievable in distributed
achievable in distributed file
in distributed file systems
writes execution time speedup
but must be implemented
must be implemented with
be implemented with synchronous
implemented with synchronous rpcs
and requires either readers
requires either readers or
either readers or writers
readers or writers to
or writers to incur
writers to incur a
to incur a delay
incur a delay to
a delay to ensure
delay to ensure that
to ensure that only
ensure that only the
that only the latest
only the latest version
the latest version of
latest version of a
version of a file
distinct processes distinct files
of a file is
processes distinct files total
a file is accessed
distinct files total of
hereinafter we move to
files total of file
we move to a
total of file sizes
move to a static
to a static state
a static state analysis
static state analysis and
state analysis and omit
analysis and omit the
as we have noted
and omit the t
we have noted in
omit the t argument
have noted in section
the t argument in
t argument in the
argument in the expressions
sending file updates to
file updates to a
updates to a server
to a server asynchronously
a server asynchronously has
server asynchronously has two
asynchronously has two potential
has two potential benefits
since the row sums
the row sums of
the process modifying the
row sums of the
process modifying the file
sums of the infiltration
modifying the file need
of the infiltration matrix
the file need not
the infiltration matrix are
file need not wait
infiltration matrix are smaller
need not wait for
matrix are smaller than
not wait for the
are smaller than one
wait for the write
for the write to
the write to complete
its largest eigenvalue is
largest eigenvalue is smaller
eigenvalue is smaller than
if the update is
according to the perron
the update is delayed
update is delayed in
is delayed in the
delayed in the log
in the log for
the log for some
log for some interval
for some interval before
some interval before being
interval before being written
before being written back
the revenues at all
revenues at all pools
at all pools converge
it may be superseded
all pools converge as
may be superseded by
pools converge as follows
be superseded by a
superseded by a later
by a later update
and therefore can be
therefore can be omitted
can be omitted entirely
these benefits come at
benefits come at the
come at the cost
at the cost of
the cost of reduced
cost of reduced cache
of reduced cache consistency
since the version of
the version of the
version of the file
of the file stored
the file stored at
file stored at the
stored at the server
at the server is
the server is inconsistent
server is inconsistent during
is inconsistent during the
inconsistent during the time
during the time that
the time that the
time that the update
that the update remains
the update remains queued
update remains queued for
remains queued for transmission
even though asynchronous writes
though asynchronous writes in
asynchronous writes in mfs
writes in mfs are
in mfs are not
mfs are not delayed
are not delayed to
not delayed to aggregate
delayed to aggregate updates
latency histograms for i
a burst of updates
burst of updates to
of updates to a
updates to a sequence
to a sequence of
a sequence of files
sequence of files may
of files may flood
files may flood the
may flood the link
flood the link to
the link to the
link to the server
to the server and
the server and increase
server and increase the
and increase the delay
increase the delay before
the delay before updates
delay before updates towards
before updates towards the
the pool game if
updates towards the end
pool game if no
towards the end of
game if no pool
the end of the
if no pool engages
end of the burst
no pool engages in
of the burst are
pool engages in block
the burst are committed
engages in block withholding
any other client accessing
other client accessing the
client accessing the file
cache consistency will access
consistency will access the
will access the stale
access the stale version
rather than one which
than one which incorporates
one which incorporates the
which incorporates the pending
incorporates the pending update
we therefore refer to
and we have i
therefore refer to this
refer to this as
to this as a
this as a hidden
as a hidden upstudies
a hidden upstudies of
hidden upstudies of distributed
upstudies of distributed file
of distributed file systems
distributed file systems have
file systems have largely
systems have largely concluded
have largely concluded that
largely concluded that file
concluded that file date
and the cache consistency
the cache consistency problem
cache consistency problem caused
consistency problem caused by
problem caused by asynchronous
each miner s revenue
caused by asynchronous sharing
miner s revenue is
by asynchronous sharing is
s revenue is proportional
asynchronous sharing is infrequent
revenue is proportional to
sharing is infrequent in
is proportional to its
is infrequent in general
proportional to its power
be it in a
it in a pool
in a pool or
a pool or working
pool or working solo
recall that difficulty is
that difficulty is only
difficulty is only adjusted
is only adjusted periodically
and there are transient
there are transient effects
are transient effects that
transient effects that are
effects that are not
writes as the hidden
that are not covered
as the hidden update
are not covered by
the hidden update problem
not covered by this
covered by this stable
we have identified a
have identified a class
identified a class of
a class of cache
class of cache consistency
we discuss this in
of cache consistency scenarmobile
discuss this in section
cache consistency scenarmobile file
this in section viii
consistency scenarmobile file systems
scenarmobile file systems such
file systems such as
systems such as coda
miners miners miners a
controls its infiltration rate
its infiltration rate of
infiltration rate of pool
rely on optimistic conios
on optimistic conios as
optimistic conios as being
conios as being of
as being of high
being of high importance
of high importance and
high importance and inadequately
importance and inadequately served
and inadequately served by
inadequately served by ex
currency control to resolve
control to resolve the
to resolve the conflicts
resolve the conflicts generated
the conflicts generated by
conflicts generated by hidden
and will choose the
generated by hidden upisting
will choose the value
by hidden upisting mobile
choose the value that
hidden upisting mobile file
the value that maximizes
upisting mobile file systems
value that maximizes the
that maximizes the revenue
maximizes the revenue density
suppose that a complex
that a complex engineering
a complex engineering dates
an alternative approach is
alternative approach is to
approach is to use
is to use a
to use a variant
on the first round
use a variant of
the first round of
a variant of callbacks
first round of the
variant of callbacks to
round of the pool
of callbacks to design
of the pool game
callbacks to design is
to design is maintained
design is maintained on
is maintained on a
maintained on a server
the value of r
on a server and
a server and updated
server and updated by
and updated by teams
updated by teams of
by teams of de
is maximized at a
maximized at a single
at a single point
a single point in
single point in the
point in the feasible
allow a client to
in the feasible range
a client to replay
client to replay writes
to replay writes asynchronously
but retain strong signers
latency histograms for i
cannot not react to
not react to pool
the echo file system
this point is the
point is the stable
is the stable state
the stable state of
stable state of the
state of the system
and we denote the
we denote the value
denote the value of
the value of x
site supervisors work from
supervisors work from those
work from those designs
from those designs using
those designs using mobile
we thank larry felser
thank larry felser and
larry felser and his
felser and his team
and his team at
his team at autodesk
team at autodesk for
at autodesk for their
autodesk for their help
for their help in
their help in understanddevices
these supervisors read from
supervisors read from the
read from the server
from the server and
the server and may
server and may also
and may also ing
may also ing the
also ing the file
ing the file access
the file access patterns
file access patterns that
access patterns that arise
and the values of
patterns that arise in
the values of the
that arise in collaborative
values of the corresponding
arise in collaborative work
of the corresponding revenues
in collaborative work applications
the corresponding revenues of
collaborative work applications for
corresponding revenues of the
work applications for very
revenues of the pools
applications for very change
of the pools with
for very change the
the pools with r
very change the design
for example to reflect
moving average of recovery
example to reflect one
average of recovery latencies
to reflect one of
of recovery latencies for
reflect one of the
recovery latencies for both
one of the contingencies
latencies for both codes
of the contingencies large
substituting the stable value
the contingencies large architectural
the stable value x
contingencies large architectural and
large architectural and engineering
traffic numbers are for
the channel is configured
numbers are for synchronous
architectural and engineering design
are for synchronous writeback
channel is configured to
and engineering design firms
is configured to lose
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
singleton packets randomly at
we obtain the revenues
packets randomly at a
obtain the revenues of
randomly at a loss
the revenues of the
at a loss rate
revenues of the two
a loss rate of
of the two pools
all are given in
are given in figure
encountered and resolved only
and resolved only as
resolved only as construction
only as construction proceeds
and additionally lose long
additionally lose long bursts
as we have seen
lose long bursts of
we have seen earlier
to simplify the expressions
high traffic can cause
traffic can cause delays
can cause delays in
cause delays in the
packets at occasional intervals
delays in the round
compiling mafs on top
mafs on top of
on top of mafs
both codes are configured
trip time for small
codes are configured with
time for small rpcs
are configured with r
data rpcs have a
rpcs have a higher
have a higher outgoing
a higher outgoing queueing
higher outgoing queueing delay
bandwidth is high enough
outgoing queueing delay in
is high enough to
queueing delay in the
high enough to eliminate
delay in the absence
enough to eliminate differences
in the absence of
and recover all lost
the absence of prefetching
to eliminate differences between
recover all lost packets
eliminate differences between writeback
all lost packets reedsolomon
differences between writeback schemes
lost packets reedsolomon uses
packets reedsolomon uses an
this is due to
reedsolomon uses an interleave
is due to the
uses an interleave of
due to the majority
to the majority of
the majority of the
majority of the competing
asynchronous writeback is clearly
of the competing rpcs
writeback is clearly beneficial
the competing rpcs being
competing rpcs being high
rpcs being high priority
and layered interleaving uses
being high priority fetch
layered interleaving uses interleaves
and priortwo questions are
interleaving uses interleaves of
priortwo questions are of
questions are of particular
are of particular interest
o ne attacker we
of particular interest in
ne attacker we begin
particular interest in evaluating
attacker we begin our
interest in evaluating the
we begin our analysis
in evaluating the perfor
begin our analysis with
our analysis with a
analysis with a simplified
these rpcs are mostly
with a simplified game
rpcs are mostly replaced
a simplified game of
are mostly replaced by
simplified game of two
mostly replaced by prefetches
game of two pools
ities are advantageous in
are advantageous in reducing
advantageous in reducing contention
in reducing contention between
which operate at a
reducing contention between reading
operate at a lower
contention between reading mance
at a lower priority
and consequently both have
a lower priority than
consequently both have a
between reading mance of
lower priority than store
reading mance of mafs
both have a maximum
mance of mafs communication
have a maximum tolerable
of mafs communication adaptation
a maximum tolerable burst
maximum tolerable burst length
tolerable burst length of
until any point where
any point where a
point where a concurrent
which is not possible
where a concurrent demand
is not possible when
a concurrent demand fetch
not possible when synchronous
concurrent demand fetch rpc
possible when synchronous writeback
demand fetch rpc raises
when synchronous writeback is
fetch rpc raises their
synchronous writeback is used
we use a publicly
rpc raises their priorities
use a publicly available
raises their priorities to
a publicly available implementation
their priorities to the
publicly available implementation of
priorities to the fetch
available implementation of a
implementation of a reed
solomon code based on
code based on vandermonde
do priorities improve performance
based on vandermonde matrices
a comparison of fetch
priorities improve performance by
improve performance by reducing
miners outside both pools
performance by reducing rpc
outside both pools mine
by reducing rpc conthe
data and prefetch rpcs
both pools mine solo
and prefetch rpcs reveals
reducing rpc conthe second
prefetch rpcs reveals the
rpc conthe second microbenchmark
rpcs reveals the effect
conthe second microbenchmark evaluates
reveals the effect of
second microbenchmark evaluates a
the effect of the
microbenchmark evaluates a workload
effect of the bandwidth
evaluates a workload that
of the bandwidth decrease
a workload that contention
or with closed pools
with closed pools that
closed pools that do
pools that do not
that do not attack
tains explicit contention between
do not attack and
explicit contention between different
not attack and cannot
the code is plugged
contention between different types
code is plugged into
attack and cannot be
is plugged into maelstrom
and cannot be attacked
plugged into maelstrom instead
between different types of
into maelstrom instead of
different types of rpc
maelstrom instead of layered
types of rpc traf
instead of layered interleaving
the test run with
test run with prefetching
run with prefetching performs
with prefetching performs a
prefetching performs a fetch
this scenario is illustrated
showing that we can
scenario is illustrated in
that we can use
is illustrated in figure
we can use new
is it possible to
data rpc to get
it possible to combine
rpc to get the
possible to combine the
to get the first
can use new encodings
get the first file
to combine the benefit
use new encodings within
combine the benefit of
new encodings within the
the benefit of asynchronous
encodings within the same
the dashed red arrow
which triggers prefetching from
within the same framework
triggers prefetching from its
the same framework seamlessly
prefetching from its file
dashed red arrow indicates
benefit of asynchronous write
from its file group
red arrow indicates that
arrow indicates that x
because of the large
of the large delay
solomon code recovers all
the large delay between
large delay between file
code recovers all lost
delay between file accesses
recovers all lost packets
all lost packets with
lost packets with roughly
prefetches complete entirely without
packets with roughly the
complete entirely without any
entirely without any overlapping
with roughly the same
without any overlapping demand
any overlapping demand fetches
s mining power infiltrates
roughly the same latency
mining power infiltrates pool
the same latency whereas
same latency whereas layered
latency whereas layered interleaving
over the course of
one process performs a
the course of the
with a block withholding
whereas layered interleaving recovers
a block withholding attack
process performs a grep
layered interleaving recovers singleton
course of the second
performs a grep on
of the second period
interleaving recovers singleton losses
a grep on a
the second period of
recovers singleton losses almost
second period of time
grep on a set
singleton losses almost immediately
on a set of
losses almost immediately and
does not engage in
almost immediately and exhibits
a set of back
bandwidth becomes insufficient for
immediately and exhibits latency
set of back at
becomes insufficient for a
not engage in block
insufficient for a prefetch
engage in block withholding
for a prefetch to
of back at low
a prefetch to complete
and exhibits latency spikes
prefetch to complete during
back at low bandwidth
to complete during the
exhibits latency spikes whenever
all of its m
latency spikes whenever the
at low bandwidth with
spikes whenever the longer
low bandwidth with acceptable
whenever the longer loss
bandwidth with acceptable performance
the longer loss burst
loyal miners work on
with acceptable performance at
miners work on its
longer loss burst occurs
work on its behalf
acceptable performance at cached
performance at cached files
at cached files that
cached files that need
files that need to
that need to be
s delay between accesses
need to be validated
to be validated before
be validated before they
r elated w ork
validated before they can
before they can be
elated w ork maelstrom
they can be opened
on the other hand
w ork maelstrom lies
the other hand does
and raisepriority rpcs are
other hand does not
ork maelstrom lies in
raisepriority rpcs are triggered
hand does not employ
rpcs are triggered by
does not employ x
are triggered by the
maelstrom lies in the
triggered by the consequent
lies in the intersection
by the consequent cache
in the intersection of
the consequent cache misses
the intersection of two
intersection of two research
of two research areas
as the bandwidth decreases
two research areas that
research areas that have
areas that have seen
of its loyal miners
that have seen major
another process either writes
the queueing delays increase
process either writes higher
have seen major innovations
queueing delays increase as
seen major innovations in
and its direct mining
either writes higher bandwidths
its direct mining power
major innovations in the
direct mining power is
delays increase as a
mining power is only
innovations in the last
increase as a proportion
in the last decade
data to files rapidly
power is only m
as a proportion of
the last decade high
a proportion of the
proportion of the total
of the total time
the total time spent
total time spent on
time spent on prefetches
haul communication and forward
communication and forward error
and forward error correction
the modifying client to
grepwe compare mafs to
modifying client to flush
compare mafs to alternative
ip variants such as
the bitcoin system normalizes
variants such as compound
client to flush its
such as compound tcp
bitcoin system normalizes these
mafs to alternative approaches
to flush its updates
to alternative approaches in
system normalizes these rates
alternative approaches in two
flush its updates whenever
approaches in two sets
normalizes these rates by
in two sets of
its updates whenever another
these rates by the
updates whenever another client
two sets of compile
rates by the total
whenever another client accesses
by the total number
another client accesses the
the total number of
client accesses the file
total number of miners
number of miners that
of miners that publish
miners that publish full
that publish full proofs
namely all miners but
all miners but x
separates invalidating a file
invalidating a file from
a file from transmitting
file from transmitting its
use transmission delay to
from transmitting its update
transmission delay to detect
one process reads files
delay to detect backed
process reads files at
to detect backed up
reads files at the
detect backed up routers
files at the same
the pools direct revenues
at the same experiments
we have implemented a
pools direct revenues are
have implemented a similar
direct revenues are therefore
implemented a similar scheme
replacing or supplementing packet
a similar scheme in
revenues are therefore m
similar scheme in mfs
or supplementing packet loss
microbenchmarks to measure execution
supplementing packet loss as
to measure execution time
packet loss as a
measure execution time time
loss as a signal
in which an access
as a signal of
execution time time as
a signal of congestion
which an access to
time time as another
an access to a
time as another is
access to a file
as another is writing
to a file which
while such protocols solve
a file which has
another is writing files
file which has an
such protocols solve the
which has an uncommitted
protocols solve the congestion
has an uncommitted update
solve the congestion collapse
an uncommitted update at
the congestion collapse experienced
uncommitted update at a
congestion collapse experienced by
update at a different
collapse experienced by conventional
at a different client
experienced by conventional tcp
a different client will
different client will force
client will force the
will force the writeback
shows that priorispeedup for
the mfs consistency algorithm
that priorispeedup for simple
mfs consistency algorithm differs
priorispeedup for simple workloads
consistency algorithm differs in
algorithm differs in its
differs in its incorporation
in its incorporation of
its incorporation of file
they cannot mitigate the
incorporation of file access
and traces of actual
of file access information
cannot mitigate the longer
traces of actual windows
mitigate the longer packet
of actual windows ties
the longer packet delivery
actual windows ties are
longer packet delivery latencies
windows ties are beneficial
packet delivery latencies caused
rather than enforce the
delivery latencies caused by
ties are beneficial for
latencies caused by packet
than enforce the same
caused by packet loss
are beneficial for the
enforce the same level
beneficial for the small
the same level of
for the small validation
same level of consistency
the small validation rpcs
and they do not
level of consistency for
they do not eliminate
of consistency for all
small validation rpcs when
consistency for all files
do not eliminate the
validation rpcs when the
not eliminate the need
rpcs when the backnt
eliminate the need for
when the backnt file
the need for larger
the backnt file system
mfs differentiates between private
need for larger buffers
differentiates between private files
for larger buffers at
larger buffers at end
which have recently only
have recently only been
recently only been accessed
only been accessed by
been accessed by a
accessed by a single
fec has seen major
by a single client
divides its revenue among
has seen major innovations
its revenue among its
the ntfs traces were
revenue among its loyal
seen major innovations in
among its loyal miners
major innovations in the
its loyal miners and
innovations in the last
loyal miners and the
ntfs traces were gathered
in the last fifteen
which are accessed by
miners and the miners
traces were gathered ground
and the miners that
the last fifteen years
were gathered ground traffic
are accessed by multiple
the miners that infiltrated
accessed by multiple clients
gathered ground traffic is
miners that infiltrated it
ground traffic is heavy
enforcing cache consistency between
level fec was first
with the sporadic background
fec was first described
the sporadic background traffic
was first described for
cache consistency between clients
first described for high
its revenue density is
sporadic background traffic in
revenue density is therefore
consistency between clients necessarily
density is therefore r
background traffic in the
between clients necessarily requires
traffic in the cornell
speed wan networks as
in the cornell university
wan networks as early
the cornell university computer
networks as early as
clients necessarily requires that
cornell university computer science
necessarily requires that shared
university computer science department
requires that shared files
that shared files are
shared files are kept
files are kept highly
are kept highly consistent
and of compiling mafs
improvements are confined to
are confined to low
but modifications to private
confined to low bandcontain
modifications to private files
to low bandcontain access
to private files can
low bandcontain access to
private files can be
bandcontain access to local
files can be written
access to local and
can be written back
to local and remote
be written back to
local and remote file
written back to the
and remote file systems
back to the server
remote file systems by
to the server less
file systems by clients
the server less aggressively
systems by clients in
by clients in a
clients in a width
in a width levels
the technique of using
technique of using file
of using file access
using file access patterns
it was applied by
file access patterns to
was applied by researchers
access patterns to adjust
applied by researchers in
patterns to adjust a
by researchers in the
to adjust a cache
researchers in the context
adjust a cache consistency
in the context of
a cache consistency protocol
the context of atm
divides its revenue among
context of atm networks
its revenue among its
cache consistency protocol has
revenue among its registered
demonstrates that priorities can
consistency protocol has been
that priorities can imlocal
among its registered miners
protocol has been used
has been used in
been used in the
used in the sprite
in the sprite distributed
the sprite distributed operation
the revenue includes both
sprite distributed operation system
revenue includes both its
includes both its direct
both its direct mining
its direct mining revenue
direct mining revenue and
mining revenue and the
revenue and the revenue
and the revenue its
the revenue its infiltrators
revenue its infiltrators obtained
its infiltrators obtained from
infiltrators obtained from pool
level fec for ip
fec for ip networks
for ip networks was
ip networks was revived
networks was revived in
priority read performance with
read performance with only
though in sprite changes
performance with only a
in sprite changes in
with only a small
sprite changes in caching
only a small overhead
changes in caching policy
a small overhead for
in caching policy were
small overhead for writes
caching policy were made
policy were made when
were made when a
made when a file
when a file was
a file was opened
file was opened simultaneously
was opened simultaneously at
opened simultaneously at different
these microbenchmarks show that
simultaneously at different clients
microbenchmarks show that asynmicrobenchmarks
show that asynmicrobenchmarks chronous
the revenue per loyal
that asynmicrobenchmarks chronous writeback
revenue per loyal pool
while mfs uses longer
asynmicrobenchmarks chronous writeback improves
chronous writeback improves performance
writeback improves performance even
miner is therefore r
in the context of
improves performance even at
the context of both
performance even at comparaour
context of both reliable
even at comparaour first
of both reliable multicast
the remainder of this
both reliable multicast and
at comparaour first microbenchmark
reliable multicast and long
remainder of this section
comparaour first microbenchmark compiles
of this section describes
first microbenchmark compiles mafs
this section describes our
microbenchmark compiles mafs from
section describes our consistency
describes our consistency algorithm
our consistency algorithm in
consistency algorithm in detail
rizzo subsequently provided a
subsequently provided a working
provided a working implementation
and an evaluation of
a working implementation of
an evaluation of its
working implementation of a
evaluation of its effectiveness
implementation of a software
of its effectiveness in
of a software packet
its effectiveness in reducing
effectiveness in reducing cache
mb of tively high
in reducing cache inconsistencies
of tively high bandwidths
and priorities are effective
host reader writer parameter
priorities are effective in
are effective in mitigating
reader writer parameter delay
effective in mitigating source
writer parameter delay between
in mitigating source code
mitigating source code stored
parameter delay between accessing
source code stored in
code stored in an
delay between accessing modules
stored in an mafs
in an mafs filesystem
between accessing modules operations
accessing modules operations per
modules operations per module
operations per module delay
per module delay between
we obtain the expression
module delay between operations
obtain the expression for
the expression for r
delay between operations delay
maelstrom represents a natural
between operations delay between
represents a natural evolution
operations delay between accessing
a natural evolution of
delay between accessing modules
natural evolution of these
between accessing modules operations
evolution of these ideas
accessing modules operations per
modules operations per module
mb contention between different
operations per module delay
contention between different classes
per module delay between
between different classes of
module delay between operations
the emphasis on applying
different classes of rpcs
delay between operations size
emphasis on applying error
between operations size of
on applying error correcting
operations size of external
applying error correcting codes
size of external files
of output in the
of external files value
error correcting codes at
output in the same
correcting codes at higher
in the same filesystem
codes at higher levels
at higher levels of
higher levels of the
levels of the software
of the software stack
the software stack has
software stack has been
stack has been accompanied
compares the execution time
has been accompanied by
the execution time speedup
been accompanied by advances
execution time speedup for
accompanied by advances in
time speedup for the
by advances in the
speedup for the benchmark
advances in the codes
for the benchmark under
in the codes themselves
the benchmark under differing
benchmark under differing asynchronous
under differing asynchronous writeback
differing asynchronous writeback and
asynchronous writeback and priority
prior to the mid
writeback and priority schemes
as bandwidth is var
we evaluated mafs at
evaluated mafs at a
the standard encoding used
mafs at a larger
standard encoding used was
at a larger scale
encoding used was reed
a larger scale using
larger scale using the
scale using the ntfs
derived the dominant feature
the dominant feature of
dominant feature of figure
an erasure code that
erasure code that performs
code that performs excellently
that performs excellently at
is that asynchronous write
performs excellently at small
excellently at small scale
at small scale but
traces summarised in table
small scale but does
scale but does not
but does not scale
does not scale to
not scale to large
scale to large sets
to large sets of
large sets of data
sets of data and
although the original execution
of data and error
the original execution back
data and error correcting
original execution back is
and error correcting symbols
execution back is beneficial
back is beneficial at
is beneficial at all
beneficial at all bandwidths
at all bandwidths until
this scalability barrier resulted
scalability barrier resulted in
barrier resulted in the
resulted in the development
in the development of
the development of new
development of new variants
of new variants of
new variants of low
variants of low density
of low density parity
low density parity check
there is less times
is less times of
less times of these
times of these traces
of these traces were
these traces were short
traces were short on
were short on windows
short on windows nt
they execute improvement at
we analyze this game
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
by finding the x
where throughput is so
throughput is so low
is so low that
so low that con
slowly on mafs due
configuration parameters for the
on mafs due to
parameters for the cache
mafs due to high
for the cache consistency
due to high bandwidth
the cache consistency evaluation
to high bandwidth requirements
and substituting this value
substituting this value for
individual instances are uniformally
trol traffic and the
this value for r
traffic and the delay
instances are uniformally distributed
and the delay in
are uniformally distributed within
the delay in fetching
uniformally distributed within the
delay in fetching files
distributed within the listed
in fetching files become
within the listed ranges
fetching files become dominating
files become dominating figure
we vary the sizes
shows execution times under
vary the sizes of
execution times under four
the sizes of the
times under four combinations
sizes of the pools
under four combinations of
of the pools through
four combinations of writeback
the pools through the
if the file is
combinations of writeback scheme
the file is shared
of writeback scheme and
pools through the entire
writeback scheme and priorities
file is shared and
through the entire feasible
is shared and no
which are orders of
shared and no other
the entire feasible range
and no other shared
are orders of magnitude
no other shared update
orders of magnitude faster
other shared update is
of magnitude faster than
shared update is being
magnitude faster than reed
update is being sent
entire feasible range and
feasible range and depict
range and depict the
and depict the optimal
depict the optimal x
solomon and much more
the thread begins transmitting
and much more scalable
thread begins transmitting the
much more scalable in
begins transmitting the update
more scalable in input
transmitting the update at
scalable in input size
the update at the
update at the store
but require slightly more
require slightly more data
slightly more data to
and the corresponding revenues
more data to be
the corresponding revenues in
data to be received
corresponding revenues in figure
if another shared update
to be received at
another shared update is
be received at the
shared update is being
received at the decoder
update is being written
is being written back
while the layered interleaving
each point in each
a synchronous forward invalidation
the layered interleaving code
point in each graph
synchronous forward invalidation rpc
layered interleaving code used
in each graph represents
forward invalidation rpc is
interleaving code used by
invalidation rpc is made
code used by maelstrom
rpc is made to
used by maelstrom is
is made to the
each graph represents the
made to the server
by maelstrom is similar
to the server at
graph represents the equilibrium
the server at the
maelstrom is similar to
server at the highest
represents the equilibrium point
at the highest priority
is similar to the
the equilibrium point of
similar to the tornado
equilibrium point of a
point of a game
of a game with
a game with the
and then the update
game with the corresponding
then the update is
lt and raptor codes
the update is queued
with the corresponding m
update is queued for
and raptor codes in
is queued for later
raptor codes in its
queued for later high
codes in its use
in its use of
its use of simple
use of simple xor
of simple xor operations
where we normalize m
it differs from them
differs from them in
a forward invalidation is
from them in one
forward invalidation is only
them in one very
invalidation is only made
in one very important
is only made if
one very important aspect
only made if the
very important aspect it
made if the update
the top right half
important aspect it seeks
if the update cannot
top right half of
the update cannot be
aspect it seeks to
update cannot be transmitted
right half of the
cannot be transmitted immediately
it seeks to minimize
half of the range
seeks to minimize the
of the range in
to minimize the latency
the range in all
minimize the latency between
range in all graphs
the latency between the
in practice it can
latency between the arrival
in all graphs is
between the arrival of
all graphs is not
the arrival of a
graphs is not feasible
practice it can therefore
arrival of a packet
it can therefore be
of a packet at
can therefore be omitted
a packet at the
therefore be omitted at
packet at the send
as the sum of
be omitted at high
the sum of m
omitted at high bandwidth
at high bandwidth or
high bandwidth or when
bandwidth or when traffic
side proxy and its
or when traffic is
proxy and its successful
when traffic is low
and its successful reception
its successful reception at
successful reception at the
reception at the receive
sending a forward invalidation
we use this range
a forward invalidation rpc
use this range as
forward invalidation rpc without
this range as a
invalidation rpc without requiring
range as a reference
rpc without requiring the
codes such as tornado
as a reference color
such as tornado encode
without requiring the modifying
as tornado encode over
requiring the modifying process
tornado encode over a
the modifying process to
encode over a fixed
modifying process to wait
over a fixed set
process to wait introduces
a fixed set of
and we use a
fixed set of input
we use a dashed
set of input symbols
use a dashed line
a dashed line to
dashed line to show
line to show the
to show the bound
without treating symbols differently
show the bound between
treating symbols differently based
the bound between this
symbols differently based on
bound between this value
differently based on their
between this value within
based on their sequence
the consistency maintenance algorithm
on their sequence in
this value within the
their sequence in the
consistency maintenance algorithm a
sequence in the data
value within the feasible
in the data stream
maintenance algorithm a transient
within the feasible range
algorithm a transient inconsistency
when the server receives
as mentioned in section
the server receives a
mentioned in section iv
server receives a forward
receives a forward invalidation
a shows the optimal
a forward invalidation for
shows the optimal infiltration
forward invalidation for a
the optimal infiltration rate
invalidation for a shared
for a shared the
layered interleaving is unique
a shared the mfs
interleaving is unique in
in the entire feasible
shared the mfs cache
is unique in allowing
the entire feasible range
the mfs cache consistency
entire feasible range we
unique in allowing the
feasible range we see
in allowing the recovery
range we see that
mfs cache consistency algorithm
we see that pool
allowing the recovery latency
cache consistency algorithm is
the recovery latency of
consistency algorithm is intended
recovery latency of lost
algorithm is intended to
latency of lost packets
is intended to achieve
chooses a strictly positive
intended to achieve a
of lost packets to
to achieve a file
lost packets to depend
a strictly positive value
packets to depend on
strictly positive value for
to depend on the
positive value for x
depend on the actual
on the actual burst
or begins receiving an
the actual burst size
begins receiving an update
actual burst size experienced
receiving an update for
an update for a
update for a file
as opposed to the
it records the idenhigh
opposed to the maximum
records the idenhigh degree
to the maximum tolerable
the idenhigh degree of
the maximum tolerable burst
idenhigh degree of consistency
maximum tolerable burst size
tolerable burst size as
burst size as with
size as with other
as with other encoding
subject to the constraints
with other encoding schemes
to the constraints imposed
the revenue of pool
the constraints imposed by
constraints imposed by tity
imposed by tity of
by tity of the
tity of the writer
is depicted in figure
c onclusion modern distributed
onclusion modern distributed systems
marks the file as
modern distributed systems are
b and in the
the file as dirty
and in the entire
distributed systems are compelled
in the entire feasible
systems are compelled by
file as dirty and
are compelled by real
the entire feasible region
as dirty and issues
entire feasible region it
dirty and issues callbacks
feasible region it is
and issues callbacks to
region it is strictly
issues callbacks to file
world imperatives to coordinate
callbacks to file semantics
it is strictly larger
to file semantics and
is strictly larger than
imperatives to coordinate across
file semantics and the
to coordinate across data
semantics and the desirability
coordinate across data centers
and the desirability of
across data centers separated
the desirability of minimising
data centers separated by
desirability of minimising overhead
centers separated by thousands
separated by thousands of
which the pool would
by thousands of miles
the pool would have
pool would have gotten
we all the clients
would have gotten without
all the clients caching
have gotten without attacking
the clients caching it
packet loss cripples the
loss cripples the performance
cripples the performance of
the performance of such
performance of such systems
if one of these
one of these clients
of these clients fetches
and reliability and flow
these clients fetches the
clients fetches the file
fetches the file have
control protocols designed for
the file have opted
protocols designed for lans
file have opted for
designed for lans and
have opted for a
opted for a compromise
for a compromise which
a compromise which results
or the commodity internet
compromise which results in
the commodity internet fail
which results in a
commodity internet fail to
results in a small
internet fail to achieve
in a small overhead
a small overhead before
small overhead before the
overhead before the update
before the update has
the update has been
update has been committed
optimal performance on the
performance on the high
c depicts the revenue
the server sends highbut
depicts the revenue of
server sends highbut admits
the revenue of pool
sends highbut admits the
highbut admits the possibility
admits the possibility of
the possibility of a
possibility of a transient
haul lambda networks linking
of a transient inconsistency
lambda networks linking data
networks linking data centers
which is strictly smaller
is strictly smaller than
priority server pull rpcs
deploying new protocols is
server pull rpcs to
new protocols is not
pull rpcs to the
in the entire range
protocols is not an
rpcs to the clients
is not an option
to the clients with
not an option for
the clients with outstanding
an option for commodity
clients with outstanding upthe
option for commodity clusters
with outstanding upthe algorithm
for commodity clusters where
outstanding upthe algorithm requires
commodity clusters where standardization
upthe algorithm requires information
note that the total
algorithm requires information about
that the total system
clusters where standardization is
the total system mining
requires information about client
total system mining power
where standardization is critical
system mining power is
information about client accesses
mining power is reduced
standardization is critical for
power is reduced when
about client accesses in
is reduced when pool
is critical for cost
client accesses in dates
critical for cost mitigation
chooses to infiltrate pool
which causes them to
causes them to raise
maelstrom is an edge
them to raise the
is an edge appliance
to raise the priority
an edge appliance that
raise the priority of
edge appliance that uses
the priority of any
appliance that uses forward
priority of any store
that uses forward error
uses forward error correction
forward error correction to
error correction to mask
the revenue of third
correction to mask packet
data order to divide
to mask packet loss
order to divide files
mask packet loss from
revenue of third parties
packet loss from endto
to divide files according
divide files according their
files according their status
miners not in either
not in either pool
either shared or unrpcs
shared or unrpcs to
or unrpcs to expedite
unrpcs to expedite transmission
ip throughput and latency
throughput and latency by
and latency by orders
a fetch rpc for
latency by orders of
fetch rpc for an
by orders of magnitude
rpc for an unshared
orders of magnitude when
for an unshared file
of magnitude when loss
an unshared file shared
magnitude when loss occurs
maelstrom is easy to
since the file server
is easy to install
easy to install and
the file server always
to install and deploy
file server always assumes
server always assumes that
always assumes that an
and is completely transparent
assumes that an unshared
is completely transparent to
that an unshared which
completely transparent to applications
an unshared which is
transparent to applications and
unshared which is already
to applications and protocols
which is already cached
applications and protocols literally
is already cached by
and protocols literally providing
already cached by a
protocols literally providing reliability
cached by a different
literally providing reliability in
by a different client
providing reliability in an
a different client always
reliability in an inexpensive
therefore pays for the
in an inexpensive box
different client always triggers
pays for the increased
client always triggers a
for the increased revenue
always triggers a file
the increased revenue of
triggers a file has
increased revenue of its
a file has an
revenue of its attacker
file has an uncommitted
of its attacker and
has an uncommitted write
its attacker and everyone
an uncommitted write when
attacker and everyone else
uncommitted write when it
and everyone else in
write when it is
everyone else in the
when it is accessed
else in the system
it is accessed by
is accessed by an
accessed by an addiserver
by an addiserver pull
implications to the general
since the server has
to the general case
the server has no
the general case consider
server has no way
general case consider the
has no way of
case consider the case
no way of knowing
consider the case of
way of knowing if
the case of p
of knowing if the
case of p pools
knowing if the file
if the file has
the file has tional
file has tional client
for any choice of
any choice of the
choice of the pools
of the pools sizes
incorrect information about the
the pools sizes m
information about the status
optical domain performance monitoring
about the status of
the status of a
status of a file
of a file only
a file only outstanding
elapsed time for all
file only outstanding updates
time for all fetch
for all fetch rpcs
affects the efficiency of
the efficiency of the
efficiency of the algorithm
detection of such a
of such a misfinally
the optical fiber communication
since updates to shared
optical fiber communication conference
updates to shared and
at least one pool
to shared and unshared
least one pool will
shared and unshared files
one pool will choose
and unshared files are
pool will choose to
unshared files are writclassification
will choose to perform
mostly writes mostly reads
choose to perform block
files are writclassification results
writes mostly reads trace
to perform block withholding
mostly reads trace mixed
are writclassification results in
writclassification results in the
results in the file
in the file being
the file being marked
mostly writes mostly reads
file being marked as
writes mostly reads trace
being marked as shared
mostly reads trace mixed
in a system with
mostly writes mostly reads
a system with p
writes mostly reads trace
system with p pools
mostly reads trace mixed
ten back to the
reads trace mixed figure
back to the server
to the server at
the server at different
server at different priorities
the original order of
original order of the
order of the status
of the status of
the status of files
status of files can
trace duration for asynchronous
of files can be
duration for asynchronous writes
files can be specified
for asynchronous writes is
is not an equilibrium
asynchronous writes is until
can be specified by
writes is until completion
be specified by the
is until completion of
specified by the user
until completion of the
by the user or
completion of the last
the user or by
of the last read
user or by applithe
assume towards negation this
or by applithe sequence
towards negation this is
by applithe sequence of
negation this is not
applithe sequence of updates
this is not the
sequence of updates is
is not the case
of updates is no
server is beneficial in
updates is no longer
is beneficial in the
is no longer entirely
beneficial in the mostly
no longer entirely preserved
in the mostly writes
the mostly writes trace
isn t quite enough
which has high readwrite
has high readwrite contention
or can be inferred
can be inferred by
be inferred by the
inferred by the file
is an equilibrium point
by the file server
the file server according
file server according to
server according to how
now consider a setting
according to how it
consider a setting with
to how it dates
a setting with only
how it dates to
setting with only pools
it dates to shared
dates to shared files
to shared files form
shared files form a
files form a subsequence
form a subsequence of
a subsequence of the
it is less effective
subsequence of the original
is less effective than
of the original updates
less effective than synchronous
effective than synchronous writeback
and treat the other
treat the other pools
the other pools as
other pools as independent
due to increased contention
pools as independent miners
but this effect is
this is the setting
this effect is mitigated
automatic inference should incorpoas
effect is mitigated by
is the setting analyzed
is mitigated by using
inference should incorpoas do
mitigated by using priorities
should incorpoas do the
the setting analyzed above
incorpoas do the updates
setting analyzed above and
do the updates to
analyzed above and we
the updates to unshared
above and we have
updates to unshared files
and we have seen
this is clearer in
we have seen there
is clearer in the
have seen there that
clearer in the graph
seen there that pool
in the graph for
the graph for time
graph for time spent
for time spent on
time spent on fetch
spent on fetch rpcs
can increase its revenue
implicit dependenrate a heuristic
increase its revenue by
dependenrate a heuristic for
its revenue by performing
a heuristic for the
revenue by performing a
heuristic for the sharing
by performing a block
for the sharing status
performing a block withholding
the sharing status of
a block withholding attack
sharing status of new
block withholding attack on
at the timescales in
status of new files
the timescales in the
withholding attack on pool
timescales in the ntfs
in the ntfs traces
and a mechacies between
a mechacies between file
mechacies between file updates
the improvements are less
between file updates are
improvements are less dramatic
file updates are preserved
are less dramatic than
where did my performance
less dramatic than in
s infiltration rate by
dramatic than in the
infiltration rate by x
than in the microbenchmarks
did my performance go
since the combination of
the combination of nism
combination of nism for
but they demonstrate that
of nism for converting
they demonstrate that mafs
demonstrate that mafs can
nism for converting shared
that mafs can improve
rate limiting rears its
for converting shared files
limiting rears its ugly
mafs can improve the
rears its ugly head
converting shared files to
can improve the performance
improve the performance of
shared files to be
the performance of large
files to be unshared
to be unshared if
be unshared if they
unshared if they cease
if they cease to
they cease to forward
cease to forward invalidations
store rpc begins to
to forward invalidations and
take this values p
rpc begins to arrive
this values p m
forward invalidations and compulsory
begins to arrive store
invalidations and compulsory server
to arrive store rpc
and compulsory server pull
arrive store rpc received
compulsory server pull rpcs
store rpc received dat
server pull rpcs for
rpc received dat ar
pull rpcs for unbe
received dat ar re
rpcs for unbe accessed
dat ar re sto
for unbe accessed by
ar re sto reply
unbe accessed by more
re sto reply ata
accessed by more than
sto reply ata e
by more than a
reply ata e d
more than a single
ata e d stor
than a single client
e d stor pc
d stor pc time
stor pc time open
pc time open file
time open file for
open file for writing
the current implemenshared files
file for writing close
for writing close file
current implemenshared files prevents
implemenshared files prevents a
files prevents a client
prevents a client from
replay log log update
a client from accessing
log log update store
client from accessing new
log update store rpc
from accessing new versions
accessing new versions of
update store rpc complete
new versions of files
store rpc complete writeback
versions of files tation
rpc complete writeback window
of files tation in
complete writeback window analysis
files tation in mfs
writeback window analysis client
tation in mfs assumes
window analysis client both
in mfs assumes that
analysis client both experiments
mfs assumes that every
client both experiments confirm
assumes that every new
both experiments confirm the
that every new file
experiments confirm the benefits
every new file is
confirm the benefits of
new file is unshared
the benefits of asynchronous
benefits of asynchronous writeback
and monin contravention of
monin contravention of their
contravention of their update
even at bandwidths where
of their update order
at bandwidths where a
bandwidths where a typical
where a typical mobile
a typical mobile file
typical mobile file system
itors client accesses to
mobile file system performs
client accesses to a
file system performs all
accesses to a file
system performs all rpcs
performs all rpcs synchronously
to a file according
a file according to
file according to an
according to an overlapping
asynchronous writeback avoids the
to an overlapping series
writeback avoids the need
an overlapping series of
avoids the need to
overlapping series of time
the need to switch
series of time periods
need to switch operation
a cross layer study
of time periods to
cross layer study of
to switch operation into
time periods to ensure
switch operation into a
layer study of packet
operation into a distinct
periods to ensure that
into a distinct low
study of packet loss
to ensure that files
of packet loss in
ensure that files which
packet loss in all
that files which are
files which are regularly
which are regularly accessed
are regularly accessed remain
regularly accessed remain shared
and choosing a bandwidth
choosing a bandwidth threshold
a bandwidth threshold at
bandwidth threshold at which
threshold at which to
at which to switch
since the mfs file
the mfs file monitoring
mfs file monitoring component
file monitoring component op
when used by themselves
priorities do not always
do not always result
not always result in
always result in improved
result in improved performance
since they are only
they are only effective
experimental setup erates on
are only effective if
setup erates on a
only effective if concurrent
erates on a larger
effective if concurrent rpcs
on a larger time
if concurrent rpcs have
a larger time scale
concurrent rpcs have different
larger time scale than
rpcs have different priorities
time scale than the
scale than the experiments
than the experiments considered
the experiments considered in
experiments considered in at
considered in at the
in at the start
at the start of
they reduce uservisible delay
the start of this
reduce uservisible delay and
start of this section
uservisible delay and contention
of this section we
delay and contention that
this section we identified
and contention that is
section we identified large
contention that is introduced
that is introduced by
is introduced by asynchronous
introduced by asynchronous writeback
scale collaborative this paper
we omit its details
omit its details for
its details for brevity
update propagation using asynchronous
propagation using asynchronous writeback
using asynchronous writeback at
asynchronous writeback at all
engineering design as an
writeback at all bandwidths
design as an example
at all bandwidths delays
as an example of
all bandwidths delays sending
an example of a
bandwidths delays sending updates
example of a scenario
delays sending updates to
of a scenario which
sending updates to the
a scenario which features
updates to the file
scenario which features when
to the file server
which features when a
features when a process
when a process modifies
a process modifies a
process modifies a file
we evaluate the effectiveness
an update is scheduled
evaluate the effectiveness of
update is scheduled to
the effectiveness of an
is scheduled to be
effectiveness of an update
scheduled to be a
of an update propagation
to be a high
an update propagation scheme
be a high degree
update propagation scheme to
a high degree of
propagation scheme to reduce
high degree of read
scheme to reduce this
to reduce this delay
mafs allows a client
allows a client to
a client to delay
at present we have
client to delay transmitting
present we have evalappended
to delay transmitting updates
we have evalappended to
have evalappended to the
evalappended to the log
but the file server
the file server forces
file server forces file
and the process continues
server forces file updates
the process continues executing
forces file updates to
process continues executing withuated
file updates to be
continues executing withuated the
updates to be written
executing withuated the mfs
to be written back
withuated the mfs cache
be written back when
the mfs cache consistency
written back when another
mfs cache consistency algorithm
back when another client
cache consistency algorithm using
when another client must
consistency algorithm using a
another client must read
algorithm using a synthetic
client must read an
journal of lightwave technology
must read an up
using a synthetic out
a synthetic out having
synthetic out having to
out having to wait
having to wait for
to wait for the
wait for the server
for the server to
the server to be
date copy of the
server to be contacted
copy of the file
though we are hoping
we are hoping to
are hoping to obtain
timeline of a file
hoping to obtain real
of a file update
to obtain real data
obtain real data from
real data from such
data from such an
time advances from left
from such an thread
advances from left to
such an thread then
from left to right
an thread then checks
thread then checks the
then checks the status
checks the status of
the status of the
client will access stale
status of the file
will access stale data
of the file the
the file the update
file the update modifies
due to network latency
if the environment in
the environment in the
environment in the future
the writeback window can
writeback window can never
window can never be
can never be eliminated
the update is queued
but adding an additional
update is queued for
adding an additional delay
is queued for transmission
an additional delay before
queued for transmission at
additional delay before writing
for transmission at the
delay before writing back
transmission at the reg
before writing back the
writing back the update
back the update increases
the update increases the
update increases the scope
increases the scope for
the scope for inconsistency
illustrates how this inconsistency
how this inconsistency can
this inconsistency can arise
like file system such
file system such as
system such as mafs
a different type of
different type of inconsistency
type of inconsistency is
of inconsistency is introduced
inconsistency is introduced between
is introduced between a
introduced between a client
between a client and
a client and the
client and the server
and the server when
the server when a
server when a file
when a file is
a file is modified
since the change is
the change is hidden
change is hidden from
is hidden from the
hidden from the server
from the server until
the effects of systemic
the server until the
effects of systemic packet
server until the file
of systemic packet loss
until the file is
systemic packet loss on
the file is closed
packet loss on aggregate
stable state where only
loss on aggregate tcp
state where only pool
on aggregate tcp flows
for the purposes of
the purposes of this
purposes of this investigation
of this investigation we
this investigation we assume
investigation we assume that
we assume that the
assume that the open
close interval for a
interval for a file
for a file is
a file is small
file is small relative
is small relative to
ieee conference on supercomputing
small relative to the
relative to the network
to the network latency
the network latency and
network latency and writeback
latency and writeback delay
the update propagation techniques
update propagation techniques we
propagation techniques we describe
techniques we describe can
we describe can be
describe can be applied
can be applied equally
be applied equally well
applied equally well to
equally well to individual
well to individual file
to individual file writes
individual file writes as
file writes as to
writes as to writeback
two pools where one
pools where one infiltrates
where one infiltrates the
one infiltrates the other
techniques for update propagation
for update propagation although
update propagation although coda
optimal infiltration rate x
like file systems can
file systems can generate
systems can generate inconsistencies
can generate inconsistencies between
generate inconsistencies between clients
they were designed to
were designed to permit
designed to permit a
to permit a client
permit a client to
a client to function
client to function at
to function at low
function at low bandwidth
rather than for rapid
than for rapid update
for rapid update propagation
as a function of
a function of pool
function of pool sizes
since it is impractical
it is impractical to
end performance effects of
is impractical to lock
performance effects of parallel
impractical to lock files
effects of parallel tcp
to lock files if
of parallel tcp sockets
lock files if clients
parallel tcp sockets on
files if clients are
tcp sockets on a
if clients are permitted
sockets on a lossy
clients are permitted to
on a lossy wide
are permitted to modify
permitted to modify the
to modify the filesystem
modify the filesystem while
the filesystem while they
filesystem while they are
while they are disconnected
coda supports stronger consistency
supports stronger consistency through
stronger consistency through optimistic
consistency through optimistic replication
number of rpcs average
of rpcs average time
and the lines in
international parallel and distributed
parallel and distributed processing
and distributed processing symposium
an alternative approach is
alternative approach is to
approach is to allow
show the revenue density
is to allow a
the revenue density of
to allow a client
allow a client to
a client to use
client to use asynchronous
to use asynchronous writeback
hik j ihkj m
but require that it
j ihkj m l
back to the setting
ihkj m l ml
to the setting at
require that it alerts
the setting at hand
m l ml cb
setting at hand with
that it alerts the
at hand with p
l ml cb c
hand with p pools
it alerts the file
ml cb c b
alerts the file server
cb c b cbcb
the file server when
c b cbcb ed
file server when a
b cbcb ed f
server when a file
the revenue of pool
when a file is
cbcb ed f gf
a file is modified
ed f gf cb
f gf cb c
gf cb c b
cb c b yx
is better when x
c b yx cbcb
by sending an invalidation
sending an invalidation rpc
z eded f f
eded f f gfgf
this informs the server
f f gfgf cb
informs the server that
f gfgf cb b
the server that the
gfgf cb b on
server that the update
cb b on yxyx
that the update exists
b on yxyx cbb
the update exists before
update exists before the
exists before the new
before the new file
the new file contents
new file contents ar
the performance of tcp
z eded f f
ip for networks with
for networks with high
networks with high bandwidth
delay products and random
products and random loss
origin of inconsistencies since
of inconsistencies since asynchronous
gfgf c c b
inconsistencies since asynchronous writeback
c c b on
since asynchronous writeback decouples
c b on yx
acm transactions on networking
b on yx ccb
asynchronous writeback decouples modifying
on yx ccb qp
writeback decouples modifying a
decouples modifying a file
modifying a file from
a file from notifying
file from notifying the
from notifying the server
notifying the server that
the server that a
server that a change
that a change has
a change has occurred
gf cb b c
cb b c onon
b c onon yxxy
c onon yxxy cbbc
onon yxxy cbbc qpqp
it can generate inconsistencies
can generate inconsistencies between
generate inconsistencies between cached
inconsistencies between cached copies
z eded r f
eded r f f
r f f srs
illustrates the potential for
the potential for inconsistency
during the writeback window
another client accessing a
client accessing a cached
accessing a cached copy
gfgf c b onon
c b onon yx
b onon yx cb
or fetching the file
onon yx cb qp
fetching the file from
the file from the
file from the file
from the file server
will not read up
z ed r f
ed r f r
can improve its revenue
improve its revenue by
its revenue by attacking
revenue by attacking pool
gf invalidations and server
from the server s
invalidations and server pulls
the server s perspective
and server pulls mfs
there is no inconsistency
since it is unaware
it is unaware of
attacks is not an
is unaware of the
is not an equilibrium
unaware of the new
not an equilibrium point
of the new update
diff synchronous average time
from a global perspective
case as a test
as a test case
writing client writes a
we take the pool
client writes a closes
take the pool distribution
writes a closes a
the pool distribution in
pool distribution in january
reading client server fetch
client server fetch a
server fetch a fetch
fetch a fetch reply
flushes update store a
update store a callback
store a callback for
a callback for a
callback for a fetch
a simple model and
for a fetch a
simple model and its
a fetch a open
model and its empirical
fetch a open a
and its empirical validation
acm sigcomm computer communication
sigcomm computer communication review
writes a closes a
we analyze the cases
analyze the cases where
the cases where each
cases where each of
where each of the
each of the pools
of the pools attacks
the pools attacks all
flushes update open a
pools attacks all other
attacks all other open
all other open pools
all of which behave
of which behave honestly
fetch reply reading client
reply reading client server
reading client server invalidate
note that attacking all
client server invalidate a
that attacking all pools
attacking all pools with
all pools with force
pools with force proportional
with force proportional to
force proportional to their
proportional to their size
to their size yields
their size yields the
size yields the same
yields the same results
the same results as
same results as attacking
results as attacking a
as attacking a single
attacking a single pool
a single pool of
single pool of their
pool of their aggregate
of their aggregate size
plugging in the numbers
in the numbers into
writing client pull a
the numbers into the
numbers into the analysis
into the analysis above
the analysis above shows
analysis above shows that
above shows that a
shows that a larger
that a larger pool
callback for a fetch
a larger pool needs
larger pool needs to
pool needs to use
needs to use a
for a fetch a
to use a smaller
use a smaller ratio
a smaller ratio of
smaller ratio of its
ratio of its mining
of its mining power
its mining power for
mining power for infiltration
power for infiltration and
for infiltration and can
infiltration and can increase
and can increase its
can increase its revenue
increase its revenue density
its revenue density more
store a fetch reply
revenue density more than
density more than a
more than a small
than a small pool
congestion control for high
control for high bandwidth
achieves its optimum attack
its optimum attack rate
optimum attack rate at
asynchronous writeback with invalidations
of the pool s
writeback with invalidations figure
the pool s mining
pool s mining power
increasing its revenue by
its revenue by almost
a client s update
client s update is
s update is logged
update is logged when
is logged when the
logged when the file
when the file is
the file is closed
this amounts to a
amounts to a daily
to a daily revenue
a daily revenue increase
while it is in
daily revenue increase of
it is in the
revenue increase of b
is in the log
other clients see the
clients see the server
see the server s
the server s stale
server s stale version
an invalidation rpc allows
invalidation rpc allows the
effective erasure codes for
rpc allows the server
erasure codes for reliable
allows the server to
codes for reliable computer
the server to invalidate
for reliable computer communication
server to invalidate other
reliable computer communication protocols
to invalidate other clients
invalidate other clients cached
other clients cached copies
acm sigcomm computer communication
usd at the exchange
sigcomm computer communication review
at the exchange rate
the exchange rate on
exchange rate on that
rate on that date
a client that modifies
client that modifies a
that modifies a file
this represents a considerable
modifies a file could
represents a considerable increase
a file could save
a considerable increase of
file could save bandwidth
considerable increase of the
could save bandwidth by
increase of the pools
save bandwidth by not
of the pools net
bandwidth by not sending
the pools net revenue
by not sending it
not sending it to
sending it to the
it to the file
to the file server
the file server at
file server at all
for the smallest pool
unless the server pulls
the server pulls it
server pulls it to
pulls it to supply
it to supply it
to supply it to
supply it to another
the attack is much
it to another client
attack is much less
is much less profitable
mafs clients push updates
clients push updates to
to reach the optimum
push updates to the
reach the optimum it
updates to the server
the optimum it needs
to the server in
optimum it needs almost
the server in the
it needs almost a
server in the background
needs almost a third
almost a third of
a third of its
third of its power
to reduce the delay
of its power for
reduce the delay incurred
its power for attacking
the delay incurred when
power for attacking but
delay incurred when fetching
for attacking but increases
incurred when fetching an
attacking but increases its
when fetching an invalidated
but increases its revenue
fetching an invalidated file
increases its revenue density
its revenue density by
revenue density by merely
pushing updates can result
updates can result in
can result in the
result in the server
in the server having
the server having received
server having received some
or all of the
all of the update
of the update by
the update by the
update by the time
by the time another
the time another client
time another client accesses
another client accesses it
on the feasibility of
the feasibility of software
feasibility of software fec
universita di pisa deit
di pisa deit technical
pisa deit technical report
selective invalidation with reader
deit technical report lr
invalidation with reader pull
with reader pull the
reader pull the effect
pull the effect of
the effect of selective
effect of selective invalidation
of selective invalidation and
name size discusfish antpool
selective invalidation and reader
size discusfish antpool ghash
invalidation and reader pull
and reader pull is
reader pull is that
pull is that mafs
is that mafs incorporates
that mafs incorporates sirp
io btchine btcguild eligius
btchine btcguild eligius others
a new algorithm for
new algorithm for maintaining
algorithm for maintaining inter
sirp behaves similarly to
behaves similarly to synchronous
similarly to synchronous writeback
to synchronous writeback if
synchronous writeback if a
writeback if a client
if a client client
a client client consistency
which combines asynchronous writeback
combines asynchronous writeback with
asynchronous writeback with concurrently
writeback with concurrently fetches
with concurrently fetches a
concurrently fetches a file
but behaves like asynchronous
behaves like asynchronous writeinvalidations
like asynchronous writeinvalidations and
asynchronous writeinvalidations and expedited
writeinvalidations and expedited transmission
and expedited transmission of
expedited transmission of updates
transmission of updates for
of updates for files
updates for files back
for files back when
files back when there
back when there are
when there are no
there are no concurrent
are no concurrent fetches
like synchronous that other
the case for packet
synchronous that other clients
case for packet level
that other clients are
for packet level fec
other clients are attempting
clients are attempting to
are attempting to read
in fifth international workshop
fifth international workshop on
international workshop on protocols
workshop on protocols for
on protocols for high
sirp sends an rpc
sends an rpc to
an rpc to the
rpc to the server
to the server as
the server as soon
server as soon as
as soon as an
soon as an application
as an application closes
an application closes a
application closes a modified
closes a modified file
but it can defer
it can defer transmitting
can defer transmitting the
defer transmitting the selective
transmitting the selective invalidation
using an invalidation rpc
an invalidation rpc to
invalidation rpc to alert
rpc to alert the
to alert the actual
alert the actual contents
the actual contents until
actual contents until they
contents until they are
until they are needed
file server to the
server to the existence
to the existence of
the existence of a
existence of a new
of a new update
a new update improves
new update improves cache
update improves cache consistency
but consumes additional bandwidth
if writeback traffic is
writeback traffic is low
traffic is low enough
is low enough for
low enough for the
enough for the server
for the server to
the server to start
server to start receiving
to start receiving an
start receiving an update
experimental evaluation immediately after
evaluation immediately after it
immediately after it receives
after it receives the
it receives the invalidation
lateral error correction for
error correction for time
the invalidation we conclude
invalidation we conclude this
we conclude this section
conclude this section with
this section with an
section with an experiment
with an experiment that
an experiment that compares
experiment that compares the
that compares the is
compares the is superfluous
sirp avoids this overhead
avoids this overhead by
this overhead by performing
overhead by performing selec
effectiveness of sirp to
of sirp to three
sirp to three alternatives
fourth usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
when a client adds
a client adds an
client adds an update
adds an update to
an update to the
update to the writeback
to the writeback back
the writeback back transmits
writeback back transmits an
back transmits an update
transmits an update as
an update as soon
update as soon as
as soon as a
soon as a file
as a file is
a file is closed
it only sends an
only sends an invalidation
sends an invalidation if
an invalidation if the
invalidation if the queue
if the queue is
the queue is not
queue is not empty
chronous writeback puts the
writeback puts the update
puts the update in
the update in a
update in a queue
in a queue and
a queue and transmits
queue and transmits it
and transmits it if
transmits it if the
it if the queue
if the queue is
the queue is empty
the invalidation is piggybacked
invalidation is piggybacked onto
is piggybacked onto the
piggybacked onto the as
onto the as soon
the as soon as
as soon as it
soon as it reaches
as it reaches the
it reaches the front
reaches the front of
the front of the
front of the queue
we also compare update
sirp against a policy
against a policy we
a policy we refer
policy we refer to
we refer to as
refer to as sirp
which only differs from
only differs from sirp
differs from sirp in
from sirp in performing
sirp in performing compulsory
in performing compulsory invalidations
when the server receives
the server receives an
server receives an invalidation
the six largest open
receives an invalidation from
six largest open pool
an invalidation from a
largest open pool sizes
invalidation from a date
open pool sizes as
from a date results
pool sizes as of
a date results in
sizes as of january
date results in an
results in an invalidation
an integrated experimental environment
in an invalidation rpc
integrated experimental environment for
an invalidation rpc to
experimental environment for distributed
invalidation rpc to the
environment for distributed systems
rpc to the server
for distributed systems and
distributed systems and networks
it makes callbacks to
makes callbacks to all
callbacks to all the
to all the other
all the other clients
the other clients that
other clients that cache
clients that cache the
that cache the are
cache the are of
the are of particular
are of particular interest
of particular interest in
particular interest in this
interest in this comparison
fifth usenix symposium on
usenix symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
to tell them to
tell them to discard
them to discard their
average duration of reader
to discard their copies
duration of reader fetch
their optimal infiltration rates
if several clients modify
several clients modify are
clients modify are the
of each pool as
modify are the files
each pool as a
are the files readers
pool as a fraction
the files readers read
as a fraction of
a fraction of its
fraction of its size
if it attacked all
it attacked all others
how is the performance
attacked all others without
is the performance of
all others without reciprocation
the performance of the
performance of the same
of the same file
modifications are serialised in
are serialised in the
and their revenue density
serialised in the order
their revenue density when
in the order of
revenue density when attacking
the order of their
order of their readers
of their readers and
their readers and writers
readers and writers affected
and writers affected by
writers affected by stronger
affected by stronger consistency
t wo p ools
wo p ools we
p ools we proceed
ools we proceed to
we proceed to analyze
proceed to analyze the
to analyze the case
analyze the case where
the case where two
the client that made
case where two pools
client that made the
where two pools may
that made the update
two pools may attack
made the update only
pools may attack each
the update only transmits
may attack each other
update only transmits it
attack each other and
only transmits it when
each other and the
transmits it when it
other and the other
it when it reaches
and the other miners
when it reaches the
the other miners mine
it reaches the head
other miners mine solo
reaches the head of
physical layer impact upon
the head of the
layer impact upon packet
head of the writeback
impact upon packet errors
of the writeback queue
again we have pool
if another client attempts
another client attempts to
client attempts to fetch
attempts to fetch the
to fetch the file
fetch the file during
the file during the
file during the update
during the update s
the update s experimental
update s experimental setup
s experimental setup writeback
experimental setup writeback window
the server blocks that
server blocks that client
passive and active measurement
blocks that client until
and active measurement workshop
that client until the
controls its infiltration rate
client until the update
its infiltration rate x
until the update has
the update has arrived
the server also makes
server also makes a
also makes a pull
makes a pull rpc
a pull rpc to
pull rpc to the
rpc to the client
to the client that
the client that experiments
client that experiments were
that experiments were conducted
experiments were conducted in
were conducted in a
conducted in a network
in a network of
a network of five
network of five hosts
also controls its infiltration
controls its infiltration rate
its infiltration rate x
one modified the file
instructing it to expedite
it to expedite sending
to expedite sending the
expedite sending the update
one writer client that
writer client that was
this scenario is illustrated
client that was responsible
scenario is illustrated in
that was responsible for
is illustrated in figure
was responsible for modifying
responsible for modifying when
for modifying when it
modifying when it receives
when it receives the
the total mining power
it receives the pull
total mining power in
receives the pull rpc
mining power in the
power in the system
in the system is
the system is m
system is m x
the client begins sending
client begins sending back
begins sending back a
sending back a collection
back a collection of
a collection of files
and three reader clients
three reader clients that
reader clients that only
clients that only read
that only read the
only read the the
read the the update
the the update at
the update at the
update at the same
at the same priority
the same priority as
same priority as an
priority as an rpc
as an rpc to
an rpc to fetch
rpc to fetch file
to fetch file data
the direct revenues r
the bandwidth between the
of the pools from
bandwidth between the writer
the pools from mining
between the writer client
pools from mining are
the writer client and
from mining are their
writer client and the
mining are their effective
client and the server
are their effective mining
and the server that
their effective mining rates
the server that it
server that it will
that it will be
it will be preferentially
will be preferentially allocated
be preferentially allocated bandwidth
if the update was
the update was set
update was set to
and the reader client
the university of illinois
server was already being
university of illinois national
was already being written
of illinois national center
already being written back
illinois national center for
national center for supercomputing
center for supercomputing applications
the client increases its
client increases its priority
bandwidth was always set
was always set to
two attacking pools system
so that it can
that it can prevent
it can prevent inconsistencies
can prevent inconsistencies by
prevent inconsistencies by inhibiting
inconsistencies by inhibiting access
by inhibiting access to
inhibiting access to the
access to the file
to the file by
the file by other
file by other clients
as shown in figure
as a function of
a function of pool
function of pool sizes
global crossing current network
crossing current network performance
invalidations are used in
are used in fluid
used in fluid replication
to allow clients to
on onon yxyx p
allow clients to avoid
onon yxyx p p
clients to avoid sending
yxyx p p qpqp
to avoid sending data
avoid sending data across
sending data across a
data across a wide
z onon yxyx p
onon yxyx p p
yxyx p p qppq
z on yx p
the server only asks
on yx p qp
server only asks the
only asks the client
asks the client for
the client for a
client for a file
z onon yxxy p
for a file s
onon yxxy p p
a file s data
yxxy p p qpqp
file s data if
s data if another
data if another client
if another client requests
another client requests it
z on yx p
on yx p qp
z time spent on
time spent on invalidations
s read staleness at
qwest ip network statistics
average store rpc duration
vice president of research
president of research and
of research and t
two pools infiltrating each
pools infiltrating each other
divided by the total
by the total mining
the total mining rate
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
staleness of version retrieved
v v w w
v w w ut
w w ut v
w ut v wv
ut v wv ut
acm transactions on networking
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
the total revenue of
total revenue of each
revenue of each pool
of each pool is
each pool is its
pool is its direct
is its direct mining
its direct mining revenue
and the infiltration revenue
the infiltration revenue from
infiltration revenue from the
cumulative proportion of reads
revenue from the previous
from the previous round
which is the attacked
is the attacked pool
the attacked pool s
attacked pool s total
pool s total revenue
s total revenue multiplied
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
is divided among its
divided among its loyal
graphs for cache consistency
among its loyal miners
for cache consistency trace
its loyal miners and
loyal miners and miners
miners and miners that
and miners that infiltrated
miners that infiltrated it
these graphs show various
graphs show various features
show various features of
various features of the
features of the performance
at stable state this
of the performance results
stable state this is
state this is r
async denotes asynchronous invalidations
staleness of version retrieved
of version retrieved read
version retrieved read staleness
retrieved read staleness at
and none no invalidations
diff denotes differentiated writeback
denotes differentiated writeback priorities
differentiated writeback priorities for
writeback priorities for shared
priorities for shared and
for shared and unshared
shared and unshared files
and unif denotes uniform
unif denotes uniform priorities
cc is the mfs
is the mfs cache
the mfs cache consistency
cumulative proportion of reads
mfs cache consistency algorithm
proportion of reads cumulative
of reads cumulative proportion
reads cumulative proportion of
cumulative proportion of reads
the height of a
a method for improving
height of a bar
method for improving tcp
of a bar counts
for improving tcp performance
a bar counts the
improving tcp performance over
bar counts the number
tcp performance over wireless
counts the number of
performance over wireless links
the number of invalidations
the white portion counts
white portion counts the
portion counts the number
counts the number of
the number of server
our experimental setup consisting
experimental setup consisting of
setup consisting of three
consisting of three hosts
nd ieee wireless communications
ieee wireless communications and
wireless communications and networking
communications and networking conference
and a writer client
the bandwidth from the
bandwidth from the reader
from the reader to
the reader to the
reader to the server
to the server was
the server was fixed
server was fixed at
we obtain the following
synchronous writeback asynchronous writeback
obtain the following closed
writeback asynchronous writeback sirp
the following closed expressions
asynchronous writeback sirp c
following closed expressions for
writeback sirp c sirp
closed expressions for each
we express the revenues
express the revenues as
the revenues as functions
revenues as functions of
as functions of x
and the bandwidth from
the bandwidth from the
bandwidth from the writer
from the writer to
the writer to the
writer to the server
to the server was
the server was varied
server was varied according
was varied according to
varied according to the
according to the experiment
the writer was configured
writer was configured in
was configured in one
configured in one of
in one of seven
one of seven different
staleness of version retrieved
of seven different ways
an adaptive forward error
adaptive forward error correction
forward error correction protocol
error correction protocol for
correction protocol for end
synchronous or no invalidations
end transport of real
staleness of reader file
and differentiated or uniform
of reader file accesses
differentiated or uniform priorities
or uniform priorities for
uniform priorities for writing
priorities for writing back
for writing back shared
cumulative distributions for the
writing back shared and
distributions for the staleness
back shared and unshared
for the staleness of
shared and unshared files
the staleness of all
staleness of all accesses
of all accesses to
all accesses to files
accesses to files by
the mfs concurrency control
to files by the
mfs concurrency control algorithm
files by the three
by the three readers
the three readers are
three readers are shown
higher curves represent less
curves represent less staleness
th international conference on
corresponds to asynchronous invalidations
total writer execution time
to asynchronous invalidations with
international conference on computer
asynchronous invalidations with differentiated
conference on computer communications
invalidations with differentiated priority
on computer communications and
computer communications and networks
with differentiated priority for
differentiated priority for shared
priority for shared files
both clients access a
clients access a shared
access a shared repository
a shared repository of
shared repository of files
repository of files stored
of files stored on
files stored on the
stored on the file
on the file server
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
each module has a
module has a descriptor
has a descriptor file
a descriptor file and
descriptor file and a
file and a set
and a set of
module descriptor files are
descriptor files are about
kb in size and
in size and the
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
based loss recovery for
member files take up
loss recovery for reliable
files take up an
recovery for reliable multicast
take up an average
for reliable multicast transmission
up an average of
the total size of
total size of all
size of all the
of all the files
all the files in
the files in the
files in the collection
in the collection is
the writer workload consists
writer workload consists of
workload consists of the
consists of the writer
of the writer updating
the writer updating modules
writer updating modules in
updating modules in a
modules in a random
in a random order
an update to a
update to a module
to a module consists
a module consists of
module consists of a
consists of a sequence
of a sequence of
a sequence of operations
of which are reads
which are reads and
end performance evaluation of
are writes to a
writes to a file
to a file in
a file in the
file in the module
consist of writes to
of writes to unshared
writes to unshared external
to unshared external files
which are each created
are each created with
each created with a
created with a unique
with a unique name
th symposium on high
symposium on high performance
on high performance interconnects
there is a pause
is a pause between
a pause between each
pause between each operation
between each operation and
each operation and a
operation and a longer
and a longer pause
a longer pause between
longer pause between updates
pause between updates to
between updates to modules
the reader workload is
each pool controls only
reader workload is similar
pool controls only its
controls only its own
only its own infiltration
its own infiltration rate
but an access to
an access to a
access to a module
to a module consists
in each round of
a module consists of
each round of the
module consists of a
round of the pool
consists of a series
of the pool game
of a series of
a series of reads
each pool will optimize
and external files are
average reader execution time
external files are never
pool will optimize its
files are never accessed
will optimize its infiltration
optimize its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the other
the configuration parameters used
configuration parameters used to
parameters used to generate
used to generate the
to generate the reader
generate the reader and
the reader and writer
acts at step t
reader and writer workload
and writer workload are
writer workload are listed
workload are listed in
are listed in table
it optimizes its revenue
optimizes its revenue with
its revenue with x
the writer workload has
end forward error correction
writer workload has a
workload has a nominal
has a nominal duration
a nominal duration of
nominal duration of two
duration of two minutes
while the reader workload
the reader workload is
reader workload is extended
workload is extended to
is extended to terminate
extended to terminate at
to terminate at the
terminate at the same
at the same time
the same time as
same time as the
time as the writer
as the writer workload
the writer workload actually
international zurich seminar on
writer workload actually finishes
zurich seminar on communications
since low bandwidth could
low bandwidth could extend
bandwidth could extend its
could extend its running
extend its running time
its running time beyond
running time beyond two
time beyond two minutes
analysis of the results
of the results figure
shows graphs of some
graphs of some selected
of some selected results
some selected results from
selected results from the
results from the experiments
while synchronous writes provide
execution times for concurrent
synchronous writes provide strong
times for concurrent access
writes provide strong concurrency
for concurrent access trace
provide strong concurrency control
acts at step t
reader execution times are
they resulted in the
execution times are averages
resulted in the lowest
times are averages for
it optimizes its revenue
are averages for the
optimizes its revenue with
averages for the three
its revenue with x
for the three readers
in the lowest rate
the lowest rate of
lowest rate of completed
rate of completed writes
of completed writes in
completed writes in all
writes in all the
in all the tests
the case for application
higher bandwidth results in
bandwidth results in less
results in less staleness
since the writer had
level network striping for
the writer had no
network striping for data
writer had no possibility
since writes can be
had no possibility of
striping for data intensive
no possibility of over
writes can be sent
for data intensive applications
can be sent to
data intensive applications using
be sent to the
intensive applications using high
sent to the file
applications using high speed
to the file server
using high speed wide
the file server faster
high speed wide area
lapping think time with
speed wide area networks
think time with asynchronous
time with asynchronous writeback
at all bandwidth levels
all bandwidth levels the
bandwidth levels the mfs
cc algorithm outperformed synchronous
algorithm outperformed synchronous writes
outperformed synchronous writes by
synchronous writes by at
writes by at least
sirp is most effective
is most effective at
most effective at reducing
ieee conference on supercomputing
effective at reducing staleness
though many reads return
many reads return out
and was among the
was among the options
among the options with
the options with the
options with the highest
date file contents when
with the highest write
file contents when compared
the highest write throughput
contents when compared to
when compared to the
compared to the optimal
to the optimal version
this is clear from
is clear from graph
an equilibrium exists where
equilibrium exists where neither
more sirp reads are
exists where neither pool
sirp reads are up
which shows the average
shows the average time
the average time to
average time to complete
time to complete store
to complete store rpcs
complete store rpcs initiated
store rpcs initiated by
rpcs initiated by the
can improve its revenue
initiated by the writer
improve its revenue by
its revenue by changing
revenue by changing its
compared to synchronous or
by changing its infiltration
to synchronous or asynchronous
changing its infiltration rate
synchronous or asynchronous writeback
tsunami file transfer protocol
allowing higher degrees of
higher degrees of staleness
any pair of values
pair of values x
cc outperforms all of
outperforms all of the
all of the alternatives
this is because of
more reads performed with
is because of the
reads performed with sirp
because of the reduced
performed with sirp are
of the reduced number
with sirp are within
the reduced number of
reduced number of invalidations
number of invalidations it
of invalidations it generates
versions of the optimal
first international workshop on
such that arg maxx
international workshop on protocols
workshop on protocols for
on protocols for fast
with this bandwidth level
protocols for fast long
in contrast to most
contrast to most of
to most of the
most of the other
synchronous and asynchronous writeback
of the other schemes
and asynchronous writeback coincide
asynchronous writeback coincide in
writeback coincide in performance
it is able to
is able to take
able to take advantage
since they are constrained
to take advantage of
they are constrained by
take advantage of both
are constrained by the
advantage of both differentiated
constrained by the bandwidth
of both differentiated writeback
by the bandwidth bottleneck
the bandwidth bottleneck and
bandwidth bottleneck and send
bottleneck and send updates
and send updates in
send updates in the
updates in the same
in the same order
pull rpcs to raise
rpcs to raise the
to raise the priority
raise the priority of
by suppressing unnecessary invalidations
the priority of its
priority of its writes
sirp reduces its bandwidth
reduces its bandwidth usage
its bandwidth usage and
bandwidth usage and achieves
usage and achieves a
and achieves a small
achieves a small improvement
a small improvement over
small improvement over sirp
shows the performance from
the performance from the
performance from the reader
from the reader s
the reader s perspective
since devoting less bandwidth
while the writer is
devoting less bandwidth to
the writer is able
less bandwidth to invalidations
writer is able to
bandwidth to invalidations results
is able to decrease
to invalidations results in
able to decrease its
invalidations results in data
to decrease its time
results in data reaching
decrease its time spent
in data reaching the
its time spent performing
data reaching the server
time spent performing store
reaching the server faster
spent performing store rpcs
the reader s average
reader s average time
asynchronous writeback performs as
s average time spent
writeback performs as well
average time spent on
performs as well as
time spent on fetches
as well as sirp
spent on fetches increases
on fetches increases sharply
fetches increases sharply when
increases sharply when the
sharply when the file
when the file in
the file in question
synchronous writeback continues to
file in question must
writeback continues to underperform
in question must be
question must be pulled
predictable high performance bulk
must be pulled from
high performance bulk data
be pulled from the
performance bulk data transfer
pulled from the writer
this is because the
is because the progress
because the progress of
the progress of writers
progress of writers using
of writers using asynchronous
writers using asynchronous writeback
using asynchronous writeback schemes
this cost must be
asynchronous writeback schemes is
cost must be weighed
writeback schemes is less
must be weighed against
schemes is less constrained
be weighed against the
is less constrained by
weighed against the benefit
less constrained by the
against the benefit of
constrained by the bandwidth
the benefit of substantially
benefit of substantially increased
of substantially increased writer
substantially increased writer throughput
and they can overlap
ieee international conference on
they can overlap computation
international conference on cluster
can overlap computation and
conference on cluster computing
overlap computation and fetching
differentiated writeback succeeds in
computation and fetching file
writeback succeeds in reducing
and fetching file contents
succeeds in reducing the
fetching file contents with
in reducing the time
file contents with writeback
reducing the time the
the time the reader
time the reader has
the reader has to
reader has to wait
rather than simply being
has to wait when
than simply being a
to wait when accessing
simply being a selfinterested
wait when accessing a
being a selfinterested optimisation
when accessing a shared
a selfinterested optimisation by
accessing a shared file
selfinterested optimisation by writers
optimisation by writers to
by writers to improve
writers to improve their
to improve their own
improve their own performance
asynchronous writeback therefore benefits
writeback therefore benefits both
therefore benefits both writers
benefits both writers and
both writers and readers
the files shared between
files shared between the
show statistics for invalidations
shared between the clients
statistics for invalidations and
between the clients were
for invalidations and serverpull
the clients were divided
invalidations and serverpull rpcs
clients were divided into
and serverpull rpcs for
serverpull rpcs for those
rpcs for those writer
for those writer configurations
those writer configurations which
writer configurations which make
configurations which make use
which make use of
make use of them
file lengths were randomised
cc significantly reduces the
solomon codes and their
significantly reduces the number
codes and their applications
with an average length
reduces the number of
an average length of
the number of invalidations
number of invalidations it
of invalidations it must
invalidations it must transmit
it must transmit by
must transmit by putting
transmit by putting off
by putting off invalidating
putting off invalidating a
off invalidating a file
invalidating a file until
a file until it
file until it is
until it is added
it is added to
to prevent the clients
is added to the
added to the log
prevent the clients falling
the clients falling into
clients falling into lockstep
falling into lockstep in
into lockstep in the
lockstep in the course
yet the effect of
in the course of
the effect of this
the course of fetching
effect of this policy
course of fetching and
of this policy on
of fetching and writing
this policy on the
fetching and writing back
policy on the number
and writing back the
on the number of
writing back the files
the number of serverpull
number of serverpull rpcs
of serverpull rpcs is
serverpull rpcs is minor
the feasible region for
feasible region for the
region for the pool
for the pool sizes
the pool sizes is
pool sizes is m
which differs from mfs
consisting of selecting a
of selecting a random
selecting a random file
cc in omitting differentiated
a random file set
in omitting differentiated writeback
random file set and
file set and performing
set and performing a
and performing a sequence
makes more invalidations and
performing a sequence of
more invalidations and incurs
a sequence of reads
invalidations and incurs more
sequence of reads or
and incurs more server
of reads or writes
reads or writes on
or writes on files
writes on files in
on files in it
nat and packet mangling
and packet mangling for
packet mangling for linux
because its store rpcs
the writer performed a
its store rpcs must
writer performed a file
store rpcs must compete
performed a file set
rpcs must compete with
a file set operation
must compete with the
file set operation of
compete with the rpcs
with the rpcs to
the rpcs to write
rpcs to write back
to write back external
write back external files
this increases the commit
increases the commit delay
the commit delay for
commit delay for each
delay for each file
the revenue function for
for each file and
revenue function for ri
each file and the
function for ri is
file and the likelihood
for ri is concave
and the likelihood of
ri is concave in
the likelihood of it
is concave in xi
likelihood of it being
concave in xi for
of it being accessed
in xi for all
it being accessed by
xi for all feasible
being accessed by the
for all feasible values
accessed by the reader
all feasible values of
by the reader while
feasible values of the
the reader while it
values of the variables
reader while it is
with each access being
while it is being
each access being equally
it is being written
access being equally likely
is being written back
being equally likely to
equally likely to open
likely to open a
to open a file
open a file for
a file for reading
file for reading or
for reading or writing
these experiments demonstrate that
experiments demonstrate that for
demonstrate that for the
readers performed a file
that for the trace
performed a file set
for the trace we
a file set operation
the trace we have
file set operation of
trace we have examined
the mfs algorithm of
mfs algorithm of asynchronous
algorithm of asynchronous invalidations
of asynchronous invalidations and
therefore the solutions for
asynchronous invalidations and differentiated
the solutions for equations
invalidations and differentiated writeback
and differentiated writeback is
differentiated writeback is able
writeback is able to
multicast routing in datagram
is able to maintain
routing in datagram internetworks
in datagram internetworks and
able to maintain cache
datagram internetworks and extended
to maintain cache consistency
internetworks and extended lans
maintain cache consistency between
cache consistency between the
are unique and are
file sets were treated
unique and are either
sets were treated as
and are either at
consistency between the two
acm transactions on computers
were treated as hot
transactions on computers systems
between the two clients
are either at the
the two clients and
either at the borders
two clients and to
at the borders of
clients and to allow
the borders of the
and to allow the
borders of the feasible
to allow the writer
of the feasible region
allow the writer to
the feasible region or
the writer to write
feasible region or where
writer to write back
region or where ri
to write back changes
write back changes to
of the file set
back changes to the
the file set operations
changes to the stored
file set operations were
to the stored data
set operations were directed
the stored data faster
operations were directed to
stored data faster than
were directed to those
data faster than is
directed to those file
faster than is possible
to those file sets
than is possible with
is possible with the
possible with the alternative
with the alternative schemes
read staleness comparing update
staleness comparing update propagation
from section v we
comparing update propagation schemes
section v we know
we intend to further
update propagation schemes requires
intend to further evaluate
v we know that
propagation schemes requires a
we know that no
to further evaluate the
schemes requires a criterion
further evaluate the perfor
requires a criterion for
a criterion for measuring
criterion for measuring the
attack is not an
for measuring the staleness
is not an equilibrium
measuring the staleness of
not an equilibrium point
references mance of the
the staleness of file
mance of the algorithm
staleness of file reads
of the algorithm to
the algorithm to determine
algorithm to determine its
since each pool can
to determine its effectiveness
each pool can increase
determine its effectiveness under
we identified updates to
its effectiveness under other
pool can increase its
effectiveness under other workloads
identified updates to files
can increase its revenue
updates to files by
increase its revenue by
to files by associating
its revenue by choosing
files by associating a
revenue by choosing a
and with more clients
by associating a version
by choosing a strictly
associating a version number
choosing a strictly positive
a version number with
a strictly positive infiltration
version number with each
strictly positive infiltration rate
number with each file
and incrementing it every
incrementing it every time
it every time the
every time the file
time the file was
the file was modified
reads were labelled with
were labelled with the
labelled with the version
with the version number
the version number of
version number of the
number of the file
of the file at
the file at the
file at the time
at the time the
evaluation of an adaptive
the time the read
of an adaptive transport
time the read occurred
an adaptive transport protocol
in proceedings of the
the staleness of a
staleness of a particular
of a particular read
a particular read was
particular read was determined
nd annual joint conference
read was determined according
annual joint conference of
is not a solution
joint conference of the
was determined according to
conference of the ieee
not a solution to
determined according to an
a solution to equations
of the ieee computer
according to an ideal
the ieee computer and
to an ideal version
ieee computer and communications
an ideal version number
computer and communications societies
ideal version number derived
version number derived from
number derived from executing
derived from executing the
from executing the experiment
executing the experiment with
the experiment with all
experiment with all participants
with all participants running
all participants running on
participants running on a
running on a single
on a single host
nash equilibrium therefore exists
performance enhancing proxies intended
equilibrium therefore exists with
enhancing proxies intended to
therefore exists with x
proxies intended to mitigate
in a real execution
intended to mitigate link
the difference between the
difference between the version
between the version number
the version number a
version number a read
number a read returns
a read returns and
read returns and the
returns and the optimal
and the optimal version
the optimal version number
optimal version number determines
version number determines how
number determines how stale
determines how stale the
how stale the read
stale the read is
shows cumulative distributions for
cumulative distributions for the
distributions for the staleness
for the staleness of
the staleness of reads
staleness of reads at
of reads at different
reads at different writer
conclusion the growing use
the growing use of
growing use of mobile
use of mobile computers
of mobile computers and
mobile computers and wireless
improved consistency results in
computers and wireless networks
consistency results in fewer
and wireless networks has
results in fewer stale
wireless networks has greatly
in fewer stale reads
networks has greatly increased
has greatly increased the
greatly increased the scope
increased the scope for
the scope for adapting
and this is reflected
scope for adapting data
this is reflected by
for adapting data access
is reflected by a
adapting data access to
reflected by a curve
data access to vary
by a curve that
a curve that is
curve that is higher
that is higher on
is higher on the
higher on the left
on the left side
the left side of
left side of the
side of the graph
consistency maintenance cost the
maintenance cost the overhead
cost the overhead of
the overhead of the
overhead of the update
of the update propagation
the update propagation schemes
update propagation schemes can
propagation schemes can be
schemes can be compared
can be compared by
be compared by referring
compared by referring to
by referring to the
referring to the reader
to the reader and
the reader and writer
reader and writer execution
and writer execution times
acknowledgements shown in figure
udp bandwidth measurement tool
reader execution time is
execution time is the
time is the average
is the average for
the average for all
average for all three
for all three readers
this paper has explored
paper has explored applying
has explored applying and
explored applying and j
the reduced staleness achievable
reduced staleness achievable by
staleness achievable by sirp
measurements of a distributed
achievable by sirp has
of a distributed file
by sirp has little
a distributed file the
sirp has little or
distributed file the technique
has little or no
file the technique of
little or no cost
the technique of modeless
or no cost compared
technique of modeless adaptation
no cost compared to
of modeless adaptation to
cost compared to asynchronous
modeless adaptation to a
compared to asynchronous writeback
adaptation to a distributed
to asynchronous writeback with
to a distributed file
asynchronous writeback with no
a distributed file system
distributed file system system
writeback with no invalidations
using symbolic computation tools
in proceedings of the
since the writer is
the writer is up
we see that there
writer is up to
see that there is
that there is a
there is a single
is a single pair
th acm symposium to
a single pair of
acm symposium to improve
single pair of values
symposium to improve its
pair of values for
to improve its performance
of values for which
values for which equation
slower when using sirp
the cache manager for
cache manager for our
manager for our mfs
for our mfs on
our mfs on operating
c compared to sirp
mfs on operating systems
holds for any feasible
on operating systems principles
for any feasible choice
any feasible choice of
feasible choice of m
selective invalidation is clearly
invalidation is clearly beneficial
sirp has the highest
has the highest average
the highest average execution
highest average execution time
numerical analysis a numerical
but this is because
analysis a numerical analysis
this is because it
a numerical analysis confirms
a scalable and tcp
numerical analysis confirms these
is because it provides
analysis confirms these observations
because it provides the
it provides the best
provides the best consistency
friendly congestion control for
the best consistency of
congestion control for high
pacific file system incorporates
best consistency of all
we simulate the pool
consistency of all the
file system incorporates features
of all the schemes
simulate the pool game
system incorporates features that
the pool game for
incorporates features that are
pool game for a
features that are not
game for a range
if a reader reads
that are not present
a reader reads more
for a range of
reader reads more up
are not present in
not present in existing
present in existing grove
then it transfers more
it transfers more data
a range of pool
range of pool sizes
the reader execution time
reader execution time for
for each choice of
execution time for each
each choice of pool
time for each case
choice of pool sizes
for each case is
each case is proportional
file systems for mobile
case is proportional to
systems for mobile hosts
is proportional to the
we start the simulation
proportional to the amount
start the simulation when
to the amount of
the simulation when both
the amount of data
adaptation to bandwidth variation
amount of data transferred
simulation when both pools
of data transferred between
when both pools do
data transferred between the
both pools do not
transferred between the reader
pools do not infiltrate
between the reader and
do not infiltrate each
the reader and server
not infiltrate each other
to bandwidth variation through
bandwidth variation through the
variation through the use
through the use of
the use of prioritised
use of prioritised communication
though lack of space
lack of space precludes
of space precludes showing
space precludes showing this
precludes showing this in
showing this in a
this in a graph
we thank robbert van
thank robbert van renesse
emin gu n sirer
rimon barr and stephen
barr and stephen rago
and stephen rago for
stephen rago for comments
rago for comments regarding
and the revenue densities
for comments regarding this
the revenue densities are
o hint genercache consistency
revenue densities are r
comments regarding this work
hint genercache consistency protocol
genercache consistency protocol using
consistency protocol using file
protocol using file access
using file access information
third international workshop on
file access information to
international workshop on protocols
access information to imation
workshop on protocols for
information to imation through
on protocols for fast
to imation through speculative
protocols for fast long
imation through speculative execution
in operating systems prove
operating systems prove performance
at each round one
each round one pool
round one pool chooses
one pool chooses its
pool chooses its optimal
chooses its optimal infiltration
its optimal infiltration rate
evaluation of an adaptive
optimal infiltration rate based
of an adaptive transport
infiltration rate based on
an adaptive transport protocol
rate based on the
based on the pool
on the pool sizes
the pool sizes and
pool sizes and the
in proceedings of the
sizes and the rate
proceedings of the twenty
and the rate with
the rate with which
rate with which it
with which it is
which it is infiltrated
second annual joint conference
annual joint conference of
joint conference of the
conference of the ieee
of the ieee computer
and we calculate the
the ieee computer and
we calculate the revenue
ieee computer and communications
calculate the revenue after
computer and communications societies
the revenue after convergence
revenue after convergence with
after convergence with equation
we have evaluated the
have evaluated the effect
evaluated the effect of
the effect of these
effect of these features
of these features on
these features on performance
features on performance at
on performance at varying
performance at varying bandwidth
recall the players in
packet recovery in high
the players in the
at varying bandwidth levels
players in the pool
varying bandwidth levels and
in the pool game
bandwidth levels and under
the pool game are
levels and under both
speed networks using coding
pool game are chosen
and under both synthetic
networks using coding and
game are chosen with
under both synthetic and
are chosen with the
both synthetic and real
chosen with the round
using coding and buffer
with the round robin
coding and buffer management
the round robin policy
so the pools take
the pools take turns
and we let the
we let the game
let the game run
the game run until
game run until convergence
the results are illustrated
results are illustrated in
are illustrated in figure
each run with some
run with some m
values results in a
results in a single
in a single point
including a workload emulating
a single point in
a workload emulating collaborative
single point in each
workload emulating collaborative data
point in each graph
in each graph in
each graph in figure
performance evaluation of forward
evaluation of forward error
of forward error correction
forward error correction in
error correction in atm
correction in atm networks
we depict the infiltration
depict the infiltration rates
the infiltration rates of
infiltration rates of both
rates of both pools
of both pools x
performance measurements access with
measurements access with high
access with high read
and found that while
found that while the
that while the of
while the of automatic
the of automatic prefetching
in proceedings of the
proceedings of the isca
of the isca interadditional
the isca interadditional costs
isca interadditional costs imposed
interadditional costs imposed are
costs imposed are mostly
imposed are mostly hidden
b and the pools
and the pools revenue
they can have benenational
the pools revenue densities
can have benenational conference
pools revenue densities r
have benenational conference on
benenational conference on parallel
the importance of translucence
conference on parallel and
importance of translucence in
on parallel and distributed
of translucence in mobile
parallel and distributed computfits
translucence in mobile computing
and distributed computfits which
in mobile computing systems
distributed computfits which are
computfits which are very
which are very visible
acm transactions on computer
modal nature of ing
nature of ing systems
for each choice of
each choice of m
the values of x
adaptation in mfs allows
in mfs allows clients
mfs allows clients to
allows clients to adapt
clients to adapt quickly
to adapt quickly to
adapt quickly to a
quickly to a variety
to a variety of
a variety of bandwidth
variety of bandwidth conditions
of bandwidth conditions without
bandwidth conditions without substantial
conditions without substantial changes
without substantial changes in
substantial changes in operation
efficient erasure correcting codes
are the points in
the points in each
points in each of
in each of the
each of the graphs
ieee transactions on information
of the graphs with
transactions on information theory
the graphs with the
graphs with the respective
with the respective coordinates
j graphs we draw
graphs we draw a
we draw a border
draw a border around
a border around the
border around the region
tolerant mechanism for distributed
around the region where
mechanism for distributed file
the region where there
for distributed file cache
region where there is
distributed file cache consistency
where there is no
in proceedings of the
attack by i in
proceedings of the twelth
by i in equilibrium
of the twelth symposium
the twelth symposium on
twelth symposium on operating
symposium on operating systems
on operating systems principles
for the ri graphs
the ri graphs we
ri graphs we draw
graphs we draw a
we draw a line
draw a line around
a line around the
our evaluation has included
line around the region
evaluation has included comparisons
around the region where
has included comparisons of
the region where the
included comparisons of mfs
region where the revenue
comparisons of mfs to
where the revenue is
of mfs to cache
the revenue is the
mfs to cache manm
revenue is the same
is the same as
the same as in
same as in the
as in the no
we first observe that
first observe that only
observe that only in
that only in extreme
only in extreme cases
in extreme cases a
extreme cases a pool
cases a pool does
a pool does not
pool does not attack
does not attack its
not attack its counterpart
ager configurations corresponding to
this experiment demonstrates that
configurations corresponding to prior
experiment demonstrates that sirp
corresponding to prior work
demonstrates that sirp is
that sirp is preferable
sirp is preferable to
is preferable to asynchronous
preferable to asynchronous writeback
and confirmed scale and
to asynchronous writeback at
at equilibrium a pool
asynchronous writeback at low
confirmed scale and performance
equilibrium a pool will
scale and performance in
writeback at low bandwidth
and performance in a
a pool will refrain
performance in a distributed
pool will refrain from
in a distributed file
will refrain from attacking
a distributed file system
and adds little additional
refrain from attacking only
adds little additional overhead
from attacking only if
attacking only if the
only if the other
acm that there are
if the other pool
that there are situations
the other pool is
there are situations in
other pool is larger
are situations in which
pool is larger than
situations in which mfs
the difference between asynchronous
in which mfs would
is larger than about
which mfs would outperform
difference between asynchronous schemes
mfs would outperform afs
between asynchronous schemes is
asynchronous schemes is minimal
transactions on computer systems
but any scheme improves
any scheme improves over
scheme improves over synchronous
improves over synchronous writeback
of the total mining
the total mining power
for the same reasons
the same reasons that
same reasons that it
reasons that it improves
that it improves performance
rd annual ieee symposium
asynchronous writeback reduces staleness
annual ieee symposium on
ieee symposium on foundations
symposium on foundations of
we observe that a
on foundations of computer
observe that a pool
foundations of computer science
that a pool improves
and sirp makes it
a pool improves its
sirp makes it an
pool improves its revenue
makes it an acceptable
improves its revenue compared
it an acceptable choice
its revenue compared to
an acceptable choice at
revenue compared to the
acceptable choice at low
compared to the no
choice at low bandwidth
attacks scenario only when
scenario only when it
only when it controls
when it controls a
it controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
these are the small
are the small triangular
the small triangular regions
small triangular regions in
triangular regions in figures
coda and little work
these earlier systems were
earlier systems were designed
in the rest of
systems were designed for
the rest of the
were designed for a
rest of the space
designed for a mobile
for a mobile environment
a mobile environment which
mobile environment which is
environment which is substantially
the trapezoids in the
which is substantially different
trapezoids in the figures
ieee transactions on information
transactions on information theory
the revenue of the
revenue of the pool
of the pool is
the pool is inferior
pool is inferior compared
is inferior compared to
inferior compared to the
compared to the no
the prisoner s dilemma
prisoner s dilemma in
s dilemma in a
partially connected operafrom that
dilemma in a healthy
connected operafrom that available
in a healthy bitcoin
operafrom that available today
a healthy bitcoin environment
where neither pool controls
neither pool controls a
pool controls a strict
mfs is able to
controls a strict majority
is able to provide
a strict majority of
scale and performance in
strict majority of the
able to provide tion
majority of the mining
and performance in a
of the mining power
performance in a distributed
in a distributed file
a distributed file system
both pools will earn
pools will earn less
acm transactions on computer
will earn less at
transactions on computer systems
earn less at equilibrium
less at equilibrium than
at equilibrium than if
equilibrium than if both
than if both pools
if both pools ran
both pools ran without
pools ran without attacking
we can analyze in
can analyze in this
analyze in this case
in this case a
this case a game
case a game where
a game where each
game where each pool
where each pool chooses
each pool chooses either
pool chooses either to
chooses either to attack
either to attack and
to attack and optimize
attack and optimize its
and optimize its revenue
or to refrain from
to refrain from attacking
without loss of generality
as we have seen
we have seen in
have seen in section
seen in section v
improved performance in periods
performance in periods of
in periods of high
periods of high network
of high network contention
high network contention by
can increase its revenue
increase its revenue above
does attack but pool
we denote the revenue
denote the revenue of
the revenue of pool
the exact value of
exact value of r
mofavouring cache validation and
cache validation and rpcs
depends on the values
validation and rpcs to
on the values of
and rpcs to retrieve
the values of m
rpcs to retrieve files
to retrieve files over
retrieve files over other
files over other bile
over other bile computing
other bile computing with
bile computing with the
computing with the rover
with the rover toolkit
but it is always
ieee transactypes of traffic
it is always smaller
is always smaller than
always smaller than one
we have not compared
have not compared mfs
as we have seen
not compared mfs with
we have seen above
compared mfs with lbfs
mfs with lbfs since
with lbfs since tions
lbfs since tions on
since tions on computers
does choose to attack
special issue on mobile
issue on mobile computing
their approaches are orthogonal
but does not surpass
does not surpass one
the game is summarized
game is summarized in
is summarized in figure
this is the classical
is the classical prisoner
the classical prisoner s
classical prisoner s dilemma
attack is the dominant
is the dominant strategy
chooses to attack or
to attack or not
the revenue of pool
is larger when attacking
larger when attacking than
mobile computing with the
when attacking than when
computing with the rover
attacking than when refraining
with the rover toolkit
than when refraining from
when refraining from attack
ieee transactions on computers
and the same for
the same for pool
at equilibrium of this
equilibrium of this attack
not present in the
present in the earlier
in the earlier systems
the earlier systems we
earlier systems we have
systems we have compared
we have compared against
when both pools attack
we anticipate that implementing
the revenue of each
anticipate that implementing lbfs
revenue of each pool
that implementing lbfs file
of each pool is
implementing lbfs file chunks
each pool is smaller
lbfs file chunks in
pool is smaller than
file chunks in mfs
is smaller than its
chunks in mfs would
smaller than its revenue
than its revenue if
its revenue if neither
revenue if neither pool
if neither pool attacked
the game is not
game is not played
is not played once
where each pool can
each pool can change
pool can change its
can change its strategy
change its strategy between
its strategy between attack
strategy between attack and
between attack and no
further improve performance its
the pools can agree
improve performance its performance
and performance in a
performance in a wide
to refrain from attacking
in proceedin future work
and in each round
in each round xxx
each round xxx xxx
round xxx xxx pool
we plan to investigate
plan to investigate the
no attack xxx pool
to investigate the performance
investigate the performance of
the performance of ings
performance of ings of
of ings of the
ings of the first
of the first usenix
the first usenix conference
first usenix conference on
usenix conference on file
conference on file and
on file and storage
file and storage modeless
and storage modeless adaptation
storage modeless adaptation and
modeless adaptation and mfs
adaptation and mfs in
and mfs in wide
and performance in a
performance in a wide
area and more web
in proceedings of the
proceedings of the first
of the first usenix
the first usenix conference
first usenix conference on
usenix conference on file
conference on file and
on file and storage
file and storage technologies
as well as further
well as further evaluating
as further evaluating the
further evaluating the performance
evaluating the performance of
the performance of the
performance of the mfs
this paper has described
of the mfs cache
paper has described mafs
the mfs cache consistency
mfs cache consistency algorithm
a new file system
we also intend to
new file system for
also intend to use
file system for mobile
system for mobile clients
for mobile clients that
mobile clients that is
clients that is tailored
that is tailored for
is tailored for wireless
tailored for wireless networks
for wireless networks by
wireless networks by incorporating
networks by incorporating automatic
by incorporating automatic adaptation
incorporating automatic adaptation to
automatic adaptation to the
adaptation to the available
to the available bandwidth
mafs differs from previous
differs from previous designs
from previous designs in
previous designs in making
designs in making use
in making use of
disconnected operamfs to further
making use of asynchronous
operamfs to further examine
use of asynchronous writeback
to further examine the
of asynchronous writeback at
further examine the benefits
asynchronous writeback at all
examine the benefits achievable
writeback at all bandwidth
the benefits achievable from
at all bandwidth levels
benefits achievable from the
achievable from the autotion
from the autotion in
the autotion in the
autotion in the coda
rather than switching from
in the coda file
than switching from synchronous
the coda file system
switching from synchronous to
from synchronous to asynchronous
synchronous to asynchronous writeback
to asynchronous writeback when
asynchronous writeback when bandwidth
acm transactions on commatic
writeback when bandwidth is
transactions on commatic generation
when bandwidth is insufficient
on commatic generation of
commatic generation of caching
generation of caching policies
of caching policies for
caching policies for files
rpc priorities and a
priorities and a new
and a new update
a new update propagation
new update propagation algorithm
reduce a client s
a client s contention
client s contention for
s contention for wireless
contention for wireless bandwidth
and permit a degree
permit a degree of
a degree of consistency
degree of consistency that
of consistency that is
consistency that is equivalent
that is equivalent to
is equivalent to instantaneous
equivalent to instantaneous propagation
to instantaneous propagation of
instantaneous propagation of updates
experiments demonstrate that these
demonstrate that these techniques
that these techniques allow
these techniques allow mafs
techniques allow mafs to
allow mafs to achieve
mafs to achieve performance
to achieve performance that
achieve performance that is
prisoner s dilemma for
performance that is at
s dilemma for two
that is at least
dilemma for two pools
is at least equal
at least equal to
the revenue density of
and in most cases
revenue density of each
in most cases superior
density of each pool
most cases superior to
of each pool is
cases superior to that
each pool is determined
superior to that achievable
pool is determined by
to that achievable by
is determined by the
that achievable by conventional
determined by the decision
achievable by conventional file
by the decision of
by conventional file system
the decision of both
conventional file system designs
decision of both pools
file system designs that
of both pools whether
system designs that switch
both pools whether to
designs that switch between
pools whether to attack
that switch between lowand
whether to attack or
switch between lowand high
to attack or not
bandwidth modes according to
modes according to thresholds
the dominant strategy of
dominant strategy of each
strategy of each player
of each player is
each player is to
player is to attack
mafs is therefore able
is therefore able to
therefore able to make
able to make efficient
to make efficient use
however the payoff of
make efficient use of
the payoff of both
efficient use of the
payoff of both would
use of the network
of both would be
of the network and
both would be larger
the network and provide
would be larger if
automated hoarding for mobile
be larger if they
hoarding for mobile computers
larger if they both
network and provide predictable
if they both refrain
and provide predictable file
they both refrain from
provide predictable file system
both refrain from attacking
predictable file system semantics
in proceedings of the
proceedings of the sixteenth
of the sixteenth acm
the sixteenth acm symposium
sixteenth acm symposium on
a pool can detect
acm symposium on operating
regardless of the available
symposium on operating systems
pool can detect whether
on operating systems principles
of the available bandwidth
can detect whether it
detect whether it is
whether it is being
it is being attacked
is being attacked and
being attacked and deduce
attacked and deduce that
and deduce that the
deduce that the other
that the other pool
the other pool is
other pool is violating
pool is violating the
is violating the agreement
cooperation where neither pool
where neither pool attacks
neither pool attacks is
pool attacks is a
attacks is a possible
is a possible stable
a possible stable state
automated hoarding for mobile
hoarding for mobile computers
in proceedings of the
proceedings of the sixteenth
of the sixteenth acm
the sixteenth acm symposium
sixteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
enforcing fairness in a
fairness in a live
streaming system maya haridasana
acknowledgements we would like
we would like to
despite the fact that
would like to thank
the fact that the
like to thank robbert
fact that the single
to thank robbert van
that the single nash
portob and robbert van
the single nash equilibrium
thank robbert van renesse
single nash equilibrium in
and robbert van renessea
nash equilibrium in every
robbert van renessea a
equilibrium in every round
van renessea a dept
in every round is
every round is to
round is to attack
emin gu n sirer
gu n sirer and
n sirer and paul
sirer and paul francis
and paul francis for
paul francis for comments
francis for comments and
new york b institute
for comments and suggestions
york b institute of
comments and suggestions regarding
b institute of informatics
case as an example
and suggestions regarding mfs
as an example we
an example we take
example we take again
we take again the
federal university of rio
take again the pool
university of rio grande
we also thank rimon
of rio grande do
also thank rimon barr
rio grande do sul
again the pool sizes
grande do sul porto
the pool sizes shown
do sul porto alegre
pool sizes shown in
sizes shown in figure
and kevin walsh for
kevin walsh for helpful
walsh for helpful discussions
for helpful discussions and
helpful discussions and corrections
and study the case
discussions and corrections to
study the case where
and corrections to this
the case where the
corrections to this paper
case where the two
where the two largest
the two largest pools
the optimal infiltration rates
out of the total
of the total system
the total system mining
total system mining power
edu abstract we describe
abstract we describe a
exploiting weak connectivity for
we describe a practical
weak connectivity for mobile
describe a practical auditing
connectivity for mobile file
a practical auditing approach
for mobile file access
practical auditing approach designed
auditing approach designed to
approach designed to encourage
designed to encourage fairness
to encourage fairness in
in proceedings of the
encourage fairness in peer
proceedings of the fifteenth
of the fifteenth acm
the fifteenth acm symposium
fifteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
and the pools would
the pools would lose
auditing is employed to
is employed to ensure
a coherent distributed file
employed to ensure that
coherent distributed file cache
to ensure that correct
distributed file cache with
ensure that correct nodes
file cache with directory
that correct nodes are
cache with directory write
correct nodes are able
nodes are able to
are able to receive
able to receive streams
to receive streams even
receive streams even in
streams even in the
even in the presence
acm transactions on computer
in the presence of
transactions on computer systems
the presence of nodes
presence of nodes that
compared to the no
of nodes that do
nodes that do not
that do not upload
do not upload enough
not upload enough data
q i dentical p
i dentical p ools
dentical p ools let
p ools let there
and scales well when
ools let there be
scales well when compared
let there be q
well when compared to
there be q pools
when compared to previous
be q pools of
compared to previous solutions
q pools of identical
to previous solutions that
pools of identical size
previous solutions that rely
of identical size that
solutions that rely on
identical size that engage
that rely on tit
size that engage in
that engage in block
engage in block withholding
in block withholding against
block withholding against one
withholding against one another
tat style of data
style of data exchange
other miners neither attack
miners neither attack nor
neither attack nor are
attack nor are being
auditing involves two roles
nor are being attacked
in this case there
this case there exists
case there exists a
there exists a symmetric
untrusted local auditors run
exists a symmetric equilibrium
local auditors run on
auditors run on all
run on all nodes
on all nodes in
all nodes in the
nodes in the system
without loss of generality
and are responsible for
are responsible for collecting
responsible for collecting and
a step of pool
for collecting and maintaining
collecting and maintaining accountable
and maintaining accountable information
maintaining accountable information regarding
accountable information regarding data
information regarding data sent
regarding data sent and
data sent and received
it controls its attack
sent and received by
controls its attack rates
and received by each
its attack rates each
received by each node
attack rates each of
rates each of the
each of the other
of the other pools
and due to symmetry
due to symmetry they
one or more trusted
to symmetry they are
or more trusted global
symmetry they are all
more trusted global auditors
they are all the
trusted global auditors periodically
are all the same
global auditors periodically sample
auditors periodically sample the
bandwidth network file system
periodically sample the state
sample the state of
the state of participating
state of participating nodes
in proceedings of the
proceedings of the eighteenth
of the eighteenth acm
estimate whether the streaming
the eighteenth acm symposium
whether the streaming quality
eighteenth acm symposium on
the streaming quality is
acm symposium on operating
streaming quality is satisfactory
symposium on operating systems
on operating systems principles
the attack rate of
attack rate of pool
and decide whether any
decide whether any actions
whether any actions are
any actions are required
a lowbandwidth network file
against any other pool
lowbandwidth network file system
we demonstrate through simulation
each of the other
demonstrate through simulation that
in proceedings of the
of the other pools
through simulation that our
proceedings of the seventeenth
the other pools can
of the seventeenth acm
other pools can attack
simulation that our approach
pools can attack its
the seventeenth acm symposium
that our approach can
can attack its peers
seventeenth acm symposium on
attack its peers as
our approach can successfully
its peers as well
acm symposium on operating
approach can successfully detect
symposium on operating systems
can successfully detect and
on operating systems principles
successfully detect and react
detect and react to
and react to the
react to the presence
to the presence of
the presence of opportunistic
all attack rates by
presence of opportunistic nodes
attack rates by all
of opportunistic nodes in
rates by all attackers
opportunistic nodes in streaming
by all attackers are
nodes in streaming sessions
all attackers are identical
it incurs low network
incurs low network and
low network and computational
network and computational overheads
the attack rate of
attack rate of any
rate of any pool
of any pool other
any pool other than
which remain fixed as
remain fixed as the
fixed as the system
as the system scales
against any other pool
introduction video and audio
video and audio streaming
and audio streaming account
audio streaming account for
streaming account for a
account for a large
for a large percentage
a large percentage of
large percentage of content
percentage of content accessed
of content accessed over
content accessed over the
accessed over the web
one popular style of
popular style of streaming
style of streaming on
of streaming on the
streaming on the web
on the web is
the direct revenue of
the web is on
direct revenue of each
web is on demand
revenue of each of
of each of the
each of the other
of the other pools
in which users access
which users access pre
similarly denote by r
stored content at will
caching in the sprite
in the sprite network
the sprite network file
sprite network file system
another style requires streams
style requires streams to
the revenue densities of
requires streams to be
revenue densities of pool
acm transactions on computer
streams to be generated
transactions on computer systems
to be generated and
be generated and disseminated
generated and disseminated in
and disseminated in real
this may be the
may be the case
be the case with
the case with important
case with important social
are instantiated to mi
an important property of
managing update conflicts in
important property of live
update conflicts in bayou
streaming is that data
a weakly connected replicated
is that data is
weakly connected replicated storage
that data is not
connected replicated storage system
data is not available
is not available in
not available in advance
in proceedings of the
proceedings of the fifteenth
of the fifteenth acm
the fifteenth acm symposium
being generated just before
fifteenth acm symposium on
generated just before transmission
acm symposium on operating
just before transmission at
symposium on operating systems
before transmission at the
on operating systems principles
transmission at the sender
interested users ideally want
users ideally want to
ideally want to receive
want to receive the
to receive the stream
receive the stream without
the stream without much
stream without much delay
without much delay from
much delay from its
delay from its original
from its original transmission
streaming systems now allow
systems now allow large
now allow large numbers
allow large numbers of
large numbers of interested
numbers of interested users
of interested users to
interested users to receive
users to receive streamed
to receive streamed data
receive streamed data in
streamed data in near
data in near real
in near real time
without requiring extensive amounts
requiring extensive amounts of
extensive amounts of resources
these systems are based
systems are based on
are based on the
based on the peer
where nodes interested in
nodes interested in receiving
file system usage in
interested in receiving data
system usage in windows
in receiving data also
usage in windows nt
receiving data also help
data also help disseminate
also help disseminate it
help disseminate it to
disseminate it to each
it to each other
alleviating the bottleneck at
the bottleneck at the
bottleneck at the source
initial protocols were based
perspectives on optimistically replicated
in proceedings of the
on optimistically replicated peer
protocols were based on
proceedings of the seventeenth
were based on building
of the seventeenth acm
based on building a
the seventeenth acm symposium
on building a tree
seventeenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
based overlay of nodes
overlay of nodes through
of nodes through which
software practice and experience
nodes through which data
through which data would
which data would be
data would be pushed
such as chainsaw and
as chainsaw and coolstreaming
have shown that the
shown that the use
that the use of
the use of a
use of a mesh
of a mesh of
a mesh of connected
mesh of connected nodes
of connected nodes and
connected nodes and a
nodes and a pull
symmetric case we have
case we have r
based data dissemination approach
data dissemination approach can
dissemination approach can provide
approach can provide similar
can provide similar results
provide similar results with
similar results with better
results with better resilience
with better resilience to
better resilience to failures
resilience to failures and
to failures and churn
the expression is shown
expression is shown in
is shown in equation
nodes joining and leaving
joining and leaving the
and leaving the system
nodes notify each other
notify each other of
given any value of
each other of receipt
any value of q
other of receipt of
value of q and
of receipt of data
of q and mi
receipt of data packets
and request packets from
request packets from their
packets from their neighbors
from their neighbors based
their neighbors based on
neighbors based on the
based on the received
on the received notifications
practical systems based on
systems based on pull
the feasible range of
feasible range of the
range of the infiltration
based streaming now exist
of the infiltration rates
streaming now exist in
the infiltration rates is
now exist in china
where they are used
they are used to
are used to disseminate
used to disseminate television
to disseminate television channels
disseminate television channels to
television channels to thousands
channels to thousands of
to thousands of users
within this range ri
this range ri is
range ri is continuous
even though the p
informed prefetching and caching
p paradigm allows systems
and concave in x
paradigm allows systems to
in proceedings of the
allows systems to scale
proceedings of the fifteenth
systems to scale with
of the fifteenth acm
to scale with the
the fifteenth acm symposium
scale with the number
fifteenth acm symposium on
with the number of
acm symposium on operating
the number of users
symposium on operating systems
on operating systems principles
it also leaves them
also leaves them vulnerable
leaves them vulnerable to
them vulnerable to opportunistic
vulnerable to opportunistic behavior
the optimal point for
optimal point for pool
opportunistic nodes attempt to
nodes attempt to receive
attempt to receive a
to receive a stream
receive a stream without
a stream without uploading
stream without uploading their
without uploading their fair
uploading their fair share
their fair share of
fair share of data
reducing the overall upload
the overall upload capacity
overall upload capacity of
upload capacity of the
capacity of the system
despite the damage that
the damage that they
damage that they may
that they may cause
not much work has
much work has been
work has been done
has been done in
since the function is
been done in studying
the function is concave
done in studying mechanisms
function is concave the
in studying mechanisms to
is concave the equation
studying mechanisms to avoid
concave the equation yields
mechanisms to avoid their
the equation yields a
to avoid their presence
equation yields a single
avoid their presence in
yields a single feasible
their presence in live
a single feasible solution
which is a function
is a function of
a function of the
function of the attack
the goal of this
of the attack rates
goal of this the
the attack rates of
of this the authors
attack rates of the
this the authors were
rates of the other
the authors were supported
of the other pools
authors were supported by
were supported by afrl
supported by afrl award
by afrl award fa
to find a symmetric
find a symmetric equilibrium
design and implementation of
and implementation of the
implementation of the sun
of the sun network
the sun network file
sun network file system
in proceedings of usenix
proceedings of usenix summer
of usenix summer conference
and obtain a single
obtain a single feasible
a single feasible solution
the equilibrium infiltration rate
equilibrium infiltration rate and
infiltration rate and the
rate and the matching
and the matching revenues
the matching revenues are
matching revenues are shown
revenues are shown in
are shown in equation
the evolution of coda
acm transactions on computer
transactions on computer systems
as in the two
the revenue at the
revenue at the symmetric
at the symmetric equilibrium
the symmetric equilibrium is
symmetric equilibrium is inferior
equilibrium is inferior to
is inferior to the
inferior to the no
up our analysis addresses
our analysis addresses the
analysis addresses the eventual
addresses the eventual revenue
software defined networks and
the eventual revenue of
eventual revenue of the
defined networks and gossip
revenue of the pools
networks and gossip protocols
and gossip protocols robert
gossip protocols robert soule
protocols robert soule ken
assuming the mining difficulty
robert soule ken birman
the mining difficulty is
soule ken birman nate
mining difficulty is set
ken birman nate foster
difficulty is set based
birman nate foster university
is set based on
nate foster university of
set based on the
foster university of lugano
based on the effective
university of lugano cornell
on the effective mining
of lugano cornell university
the effective mining power
lugano cornell university cornell
cornell university cornell university
university cornell university the
cornell university the performance
university the performance of
not including mining power
the performance of data
including mining power used
mining power used for
power used for withholding
center applications are critically
applications are critically dependent
are critically dependent on
critically dependent on the
dependent on the underlying
on the underlying network
difficulty is updated only
is updated only periodically
updated only periodically every
determinism and asynchrony of
and asynchrony of set
asynchrony of set iterators
of set iterators to
set iterators to reduce
given the complexities associated
iterators to reduce aggregrate
the complexities associated with
to reduce aggregrate file
complexities associated with management
reduce aggregrate file i
networks today typically provide
today typically provide little
typically provide little more
provide little more than
little more than best
in proceedings of the
when mining power in
proceedings of the sixteenth
mining power in the
of the sixteenth acm
power in the system
effort packet delivery between
in the system is
packet delivery between hosts
the system is regularly
the sixteenth acm symposium
system is regularly increasing
sixteenth acm symposium on
acm symposium on operating
symposium on operating system
the emergence of software
on operating system principles
which has been true
has been true for
been true for the
true for the majority
for the majority of
the majority of bitcoin
majority of bitcoin s
of bitcoin s history
has created an opportunity
created an opportunity to
an opportunity to build
opportunity to build more
the views and conclusions
to build more dynamic
views and conclusions herein
build more dynamic networks
and conclusions herein are
more dynamic networks that
conclusions herein are those
dynamic networks that can
herein are those of
networks that can be
are those of the
that can be tailored
those of the authors
can be tailored precisely
be tailored precisely to
tailored precisely to the
no adjustment may be
precisely to the needs
adjustment may be necessary
to the needs of
the needs of applications
if an attacker purchases
an attacker purchases new
existing solutions for monitoring
attacker purchases new mining
solutions for monitoring within
purchases new mining hardware
for monitoring within sdns
new mining hardware and
monitoring within sdns suffer
mining hardware and employs
within sdns suffer from
hardware and employs it
sdns suffer from several
and employs it directly
suffer from several short
employs it directly for
it directly for block
directly for block withholding
this mining power is
either they are inaccurate
mining power is never
power is never included
is never included in
never included in the
due to eventual consistency
included in the difficulty
to eventual consistency of
in the difficulty calculation
eventual consistency of architecture
the difficulty calculation the
difficulty calculation the system
calculation the system is
the system is never
system is never aware
is never aware of
never aware of it
the difficulty is therefore
difficulty is therefore already
is therefore already correctly
therefore already correctly calculated
already correctly calculated and
file system usage in
correctly calculated and the
system usage in windows
calculated and the attack
usage in windows nt
and the attack is
due to limitations of
the attack is profitable
to limitations of current
attack is profitable immediately
limitations of current hardware
if the mining power
the mining power is
mining power is static
in proceedings of the
proceedings of the seventeenth
of the seventeenth acm
the seventeenth acm symposium
the attack becomes profitable
seventeenth acm symposium on
attack becomes profitable only
acm symposium on operating
becomes profitable only after
symposium on operating systems
profitable only after the
on operating systems principles
or too costly to
only after the bitcoin
too costly to be
after the bitcoin system
costly to be practical
the bitcoin system has
to be practical at
bitcoin system has normalized
be practical at scale
system has normalized the
has normalized the revenues
normalized the revenues by
the revenues by adjusting
revenues by adjusting difficulty
due to reliance on
to reliance on switch
reliance on switch forwarding
on switch forwarding rules
switch forwarding rules and
forwarding rules and centralization
the revenue of an
revenue of an attacking
of an attacking pool
an attacking pool is
attacking pool is reduced
pool is reduced due
is reduced due to
reduced due to the
due to the reduction
to the reduction in
the reduction in block
reduction in block generation
in block generation of
block generation of both
we argue that gossip
generation of both the
argue that gossip protocols
of both the attacking
that gossip protocols offer
both the attacking and
gossip protocols offer an
the attacking and attacked
protocols offer an ideal
attacking and attacked pools
offer an ideal alternative
an ideal alternative for
ideal alternative for sdn
alternative for sdn monitoring
pool knowledge and r
due to their scalability
to their scalability and
their scalability and resiliency
ignored the crucial monitoring
minimum and average download
the crucial monitoring component
and average download rates
crucial monitoring component that
average download rates across
monitoring component that aggregates
download rates across all
component that aggregates network
rates across all nodes
that aggregates network and
across all nodes when
aggregates network and application
all nodes when using
network and application state
nodes when using the
when using the bar
using the bar gossip
the bar gossip and
bar gossip and chainsaw
and sends the events
gossip and chainsaw protocols
sends the events to
the events to the
events to the controller
paper is to propose
is to propose and
arla a free afs
to propose and evaluate
a free afs client
a complete system would
propose and evaluate a
complete system would have
and evaluate a mechanism
system would have a
evaluate a mechanism that
in proceedings of the
would have a closed
a mechanism that can
have a closed loop
mechanism that can defend
that can defend against
can defend against this
defend against this problem
continuously monitoring applications and
monitoring applications and the
applications and the network
whithout incurring large overheads
the approach that most
approach that most closely
then adjusting sdn policies
that most closely relates
adjusting sdn policies to
most closely relates to
sdn policies to optimize
closely relates to our
policies to optimize the
relates to our work
to optimize the use
to our work is
optimize the use of
our work is the
the use of resources
work is the bar
is the bar gossip
the bar gossip protocol
gossip protocols are an
protocols are an ideal
which employs a tit
are an ideal choice
an ideal choice for
ideal choice for implementing
choice for implementing a
for implementing a wide
implementing a wide range
a wide range monitoring
wide range monitoring tasks
tat approach for encouraging
approach for encouraging nodes
for encouraging nodes to
encouraging nodes to contribute
with a gossip protocol
a node only sends
node only sends as
each node exchanges information
only sends as much
node exchanges information with
sends as much data
exchanges information with a
as much data to
information with a randomly
much data to another
with a randomly selected
data to another node
a randomly selected peer
to another node as
randomly selected peer at
another node as it
selected peer at periodic
node as it receives
peer at periodic intervals
as it receives back
because it is based
it is based on
it provides an elegant
is based on periodic
provides an elegant solution
based on periodic peer
an elegant solution shown
elegant solution shown to
solution shown to tolerate
shown to tolerate both
to tolerate both opportunistic
tolerate both opportunistic behavior
both opportunistic behavior and
opportunistic behavior and other
behavior and other malicious
and other malicious attacks
gossip s network load
s network load tends
network load tends to
load tends to be
tends to be well
volume leases for consistency
leases for consistency in
for consistency in large
scaling linearly with system
linearly with system size
with system size and
system size and not
tat does present a
size and not prone
does present a few
and not prone to
present a few undesirable
not prone to reactive
a few undesirable requirements
ieee transactions on knowledge
prone to reactive feedback
transactions on knowledge and
on knowledge and data
knowledge and data engineering
because peers are selected
the data source should
peers are selected randomly
data source should ensure
source should ensure that
should ensure that packets
no single node is
ensure that packets are
single node is indispensable
that packets are evenly
packets are evenly spread
are evenly spread across
evenly spread across the
so tools built on
spread across the system
tools built on gossip
across the system by
built on gossip are
the system by sending
on gossip are extremely
system by sending data
by sending data to
gossip are extremely tolerant
sending data to a
are extremely tolerant to
data to a fixed
extremely tolerant to disruptions
to a fixed proportion
tolerant to disruptions and
a fixed proportion of
to disruptions and able
fixed proportion of nodes
disruptions and able to
and able to rapidly
able to rapidly recover
to rapidly recover from
and by sending different
rapidly recover from failures
by sending different packets
sending different packets to
different packets to different
packets to different nodes
and solving we obtain
although individual gossip protocols
solving we obtain a
individual gossip protocols are
we obtain a single
gossip protocols are typically
obtain a single expression
protocols are typically very
a single expression for
are typically very simple
single expression for any
expression for any ri
it requires the source
requires the source and
the source and all
composing multiple protocols can
source and all nodes
multiple protocols can lead
since in the in
protocols can lead to
in the in order
and all nodes to
the in order to
can lead to complex
in order to choose
all nodes to have
order to choose its
lead to complex interactions
to choose its optimal
nodes to have full
choose its optimal infiltration
to complex interactions with
its optimal infiltration rate
to have full membership
complex interactions with unpredictable
have full membership knowledge
interactions with unpredictable behavior
a pool has to
pool has to know
we designed the mica
has to know the
these restrictions affect scalability
to know the rate
restrictions affect scalability when
know the rate at
affect scalability when the
the rate at which
scalability when the data
rate at which it
when the data source
at which it is
the data source has
which it is attacked
data source has bounded
source has bounded upload
has bounded upload bandwidth
framework to address this
to address this problem
and the revenue density
the revenue density of
revenue density of potential
to illustrate this problem
density of potential victim
mica allows programmers to
of potential victim pools
allows programmers to describe
programmers to describe gossip
to describe gossip protocols
we fixed the upload
describe gossip protocols with
fixed the upload capacity
gossip protocols with a
the upload capacity of
protocols with a small
upload capacity of a
a pool can estimate
capacity of a data
of a data source
pool can estimate the
a data source at
can estimate the rate
estimate the rate with
the rate with which
mbps and simulated bar
rate with which it
and simulated bar gossip
and compose the protocols
simulated bar gossip when
with which it is
compose the protocols with
bar gossip when streaming
which it is attacked
the protocols with a
it is attacked by
protocols with a rich
is attacked by comparing
with a rich collection
attacked by comparing the
a rich collection of
by comparing the rates
rich collection of operators
comparing the rates of
collection of operators to
the rates of partial
of operators to create
rates of partial and
operators to create sophisticated
of partial and full
to create sophisticated protocols
partial and full proofs
create sophisticated protocols in
and full proofs of
sophisticated protocols in a
kbps with increasing numbers
protocols in a modular
full proofs of work
in a modular style
with increasing numbers of
proofs of work it
increasing numbers of receivers
of work it receives
work it receives from
it receives from its
receives from its miners
mica ensures that the
ensures that the composed
varied between one and
that the composed protocols
between one and thirty
the composed protocols maintain
one and thirty thousand
composed protocols maintain strong
and thirty thousand nodes
as explained in section
explained in section ii
we compare its scalability
compare its scalability against
its scalability against the
scalability against the chainsaw
robustness and convergence guarantees
against the chainsaw protocol
in order to estimate
order to estimate the
to estimate the revenue
estimate the revenue densities
in our evaluation of
the revenue densities of
our evaluation of mica
revenue densities of the
densities of the other
of the other pools
for which we fixed
which we fixed the
we fixed the source
we have built monitoring
fixed the source s
have built monitoring tasks
the source s upload
a pool can use
source s upload bandwidth
pool can use one
s upload bandwidth to
can use one of
built monitoring tasks that
use one of two
monitoring tasks that maintain
one of two methods
tasks that maintain a
that maintain a predictable
maintain a predictable performance
even when hundreds of
when hundreds of separate
hundreds of separate instances
of separate instances are
separate instances are deployed
instances are deployed on
are deployed on the
we present the average
deployed on the same
present the average and
on the same machines
the average and minimum
average and minimum download
and minimum download rates
as ratios of the
ratios of the stream
of the stream rate
of both protocols when
both protocols when the
a control program reacts
protocols when the number
control program reacts to
when the number of
program reacts to network
the number of nodes
reacts to network events
number of nodes is
of nodes is increased
and updates forwarding rules
updates forwarding rules on
forwarding rules on switches
rules on switches to
on switches to manage
switches to manage packets
bar gossip is not
gossip is not able
is not able to
building on this interface
not able to sustain
able to sustain its
to sustain its performance
our work on merlin
sustain its performance without
its performance without scaling
performance without scaling the
without scaling the upload
scaling the upload capacity
the upload capacity of
upload capacity of the
capacity of the source
of the source proportionally
the source proportionally with
source proportionally with the
is novel among network
proportionally with the size
novel among network programming
with the size of
among network programming languages
the size of the
network programming languages in
size of the system
programming languages in that
languages in that it
in that it determines
that it determines allocations
it determines allocations of
determines allocations of limited
allocations of limited network
chainsaw is able to
wide resources such as
is able to scale
resources such as bandwidth
able to scale well
such as bandwidth and
to scale well even
as bandwidth and paths
scale well even with
well even with a
even with a fixed
with a fixed lower
a fixed lower upload
we have used merlin
fixed lower upload bandwidth
have used merlin to
lower upload bandwidth at
used merlin to improve
upload bandwidth at the
merlin to improve the
bandwidth at the source
to improve the latency
improve the latency of
the latency of hadoop
latency of hadoop jobs
of hadoop jobs running
but cannot handle the
hadoop jobs running in
cannot handle the presence
jobs running in the
handle the presence of
running in the presence
the presence of opportunistic
in the presence of
presence of opportunistic nodes
the presence of udp
presence of udp background
of udp background traffic
we propose to use
propose to use auditing
to use auditing to
or prioritize classes of
use auditing to encourage
prioritize classes of traffic
auditing to encourage data
classes of traffic used
of traffic used for
traffic used for state
machine replication in fault
streaming systems like chainsaw
our auditing approach establishes
auditing approach establishes a
approach establishes a minimum
establishes a minimum threshold
a minimum threshold for
minimum threshold for the
threshold for the amount
for the amount of
the amount of data
amount of data sent
these experiments demonstrate that
of data sent by
experiments demonstrate that an
data sent by any
demonstrate that an sdn
sent by any node
that an sdn framework
by any node in
any node in the
node in the system
with the correct information
the correct information as
correct information as input
and removes nodes that
removes nodes that upload
can provide automated network
nodes that upload less
provide automated network management
that upload less data
automated network management customized
upload less data than
network management customized to
less data than the
management customized to the
data than the threshold
customized to the needs
to the needs of
the needs of resident
needs of resident distributed
of resident distributed applications
instead of relying on
of relying on a
relying on a tit
while the merlin compiler
the merlin compiler generates
merlin compiler generates static
compiler generates static network
generates static network configurations
merlin uses a small
we focus on encouraging
focus on encouraging nodes
on encouraging nodes to
runtime component to allow
encouraging nodes to respect
component to allow for
nodes to respect the
to allow for dynamic
to respect the established
allow for dynamic adaptation
respect the established protocol
nodes are forced to
are forced to provide
forced to provide accountable
based approach allows this
to provide accountable information
approach allows this adaptation
provide accountable information regarding
allows this adaptation to
accountable information regarding packets
this adaptation to happen
information regarding packets sent
adaptation to happen safely
regarding packets sent to
packets sent to and
sent to and received
to and received from
and received from neighbors
by providing policy language
providing policy language constructs
policy language constructs that
language constructs that can
constructs that can be
and the auditing system
that can be automatically
the auditing system is
can be automatically verified
auditing system is responsible
system is responsible for
is responsible for detecting
responsible for detecting and
for detecting and removing
implicit in the design
detecting and removing misbehaving
in the design of
and removing misbehaving nodes
the design of this
design of this runtime
of this runtime component
notice that identifying the
that identifying the misbehaving
and sdn networks in
identifying the misbehaving nodes
sdn networks in general
the misbehaving nodes is
misbehaving nodes is not
nodes is not a
is not a trivial
not a trivial task
is the notion that
the notion that network
notion that network events
that network events are
since there is no
network events are generated
there is no fixed
events are generated in
is no fixed minimum
are generated in response
no fixed minimum amount
generated in response to
fixed minimum amount of
in response to the
minimum amount of data
response to the situational
amount of data that
to the situational status
of data that nodes
the situational status culled
data that nodes should
situational status culled from
that nodes should contribute
status culled from a
nodes should contribute to
culled from a wide
should contribute to the
from a wide range
contribute to the system
a wide range of
wide range of sources
if we assume a
we assume a model
expression for ri in
assume a model where
for ri in a
a model where misbehaving
ri in a system
model where misbehaving nodes
in a system with
where misbehaving nodes simply
a system with pools
misbehaving nodes simply did
system with pools of
nodes simply did not
with pools of equal
simply did not upload
pools of equal size
did not upload any
not upload any data
detecting them would be
them would be an
would be an easier
be an easier task
packet and drop rates
once we assume that
we assume that misbehaving
assume that misbehaving nodes
that misbehaving nodes may
misbehaving nodes may adjust
nodes may adjust their
may adjust their contribution
adjust their contribution level
their contribution level based
contribution level based on
level based on the
based on the policy
on the policy used
the policy used by
policy used by an
used by an auditing
by an auditing system
a more elaborate approach
more elaborate approach is
elaborate approach is required
this paper presents and
paper presents and evaluates
presents and evaluates an
and evaluates an auditing
evaluates an auditing model
an auditing model based
auditing model based on
model based on sampling
based on sampling the
on sampling the system
sampling the system and
the system and using
system and using the
and using the sampled
using the sampled information
the sampled information to
sampled information to build
information to build a
to build a global
build a global view
a global view of
global view of how
view of how the
of how the system
how the system is
the system is currently
system is currently behaving
user preferences for a
preferences for a particular
for a particular network
auditors employ strategies to
q mi q mi
employ strategies to identify
strategies to identify the
to identify the misbehaving
identify the misbehaving nodes
the misbehaving nodes that
misbehaving nodes that should
nodes that should be
that should be punished
the paper is organized
paper is organized as
is organized as follows
we state the exact
state the exact problem
the exact problem that
exact problem that we
problem that we aim
that we aim to
we aim to solve
aim to solve and
much of this information
to solve and the
of this information must
solve and the assumptions
this information must be
and the assumptions considered
information must be created
the assumptions considered in
must be created and
assumptions considered in this
be created and updated
considered in this work
created and updated dynamically
existing sdn frameworks have
sdn frameworks have largely
frameworks have largely closing
have largely closing the
largely closing the loop
we review the pull
to accommodate the ever
based streaming protocol employed
streaming protocol employed in
protocol employed in our
employed in our system
growing demands of cloud
demands of cloud and
of cloud and data
cloud and data center
and data center application
followed by a description
by a description of
a description of our
description of our novel
of our novel auditing
networks will need to
our novel auditing approach
will need to become
novel auditing approach in
need to become more
auditing approach in section
to become more flexible
become more flexible and
more flexible and dynamic
as networks continue to
networks continue to grow
continue to grow in
to grow in complexity
it will become increasingly
we evaluate the proposed
will become increasingly difficult
evaluate the proposed approach
become increasingly difficult for
increasingly difficult for network
difficult for network operators
we then discuss the
for network operators to
then discuss the costs
network operators to provide
discuss the costs of
operators to provide this
the costs of auditing
to provide this flexibility
provide this flexibility without
this flexibility without the
flexibility without the support
without the support of
and briefly describe how
the support of proper
briefly describe how to
support of proper tools
describe how to extend
of proper tools and
how to extend our
proper tools and infrastructure
to extend our model
extend our model for
our model for heterogeneous
model for heterogeneous systems
provide both the control
both the control and
the control and monitoring
control and monitoring components
and monitoring components necessary
monitoring components necessary to
we present related work
components necessary to automatically
present related work in
necessary to automatically adapt
related work in section
to automatically adapt the
automatically adapt the network
adapt the network to
q symmetric equilibrium values
the network to the
symmetric equilibrium values for
network to the needs
equilibrium values for a
to the needs of
values for a system
the needs of the
for a system of
needs of the applications
and conclude in section
a system of q
system of q pools
of q pools of
q pools of equal
pools of equal sizes
because both systems use
both systems use a
systems use a language
often publish this data
publish this data to
this data to demonstrate
data to demonstrate their
to demonstrate their honesty
demonstrate their honesty to
they have rigorous semantics
their honesty to their
have rigorous semantics that
honesty to their miners
rigorous semantics that can
problem statement our approach
semantics that can be
statement our approach focuses
that can be formally
like it or not
our approach focuses on
can be formally defined
approach focuses on a
focuses on a target
on a target streaming
a target streaming system
web services are distributed
target streaming system consisting
services are distributed objects
streaming system consisting of
system consisting of one
consisting of one data
they provide predictable operational
of one data source
provide predictable operational behavior
they allow for the
cornell university within the
allow for the rigorous
university within the community
for the rigorous expression
within the community developing
the rigorous expression of
the community developing the
rigorous expression of algorithms
community developing the web
expression of algorithms for
developing the web services
which disseminates data at
the web services architecture
of algorithms for monitoring
web services architecture and
disseminates data at a
services architecture and products
algorithms for monitoring or
data at a fixed
for monitoring or managing
at a fixed rate
monitoring or managing sdn
a fixed rate to
or managing sdn networks
fixed rate to a
an increasingly schizophrenic message
rate to a dynamic
increasingly schizophrenic message is
to a dynamic set
schizophrenic message is emerging
a dynamic set of
dynamic set of receivers
marketing materials assure us
materials assure us that
the source has limited
assure us that web
source has limited upload
us that web services
has limited upload bandwidth
that web services are
web services are a
services are a breakthrough
and hence can only
hence can only send
can only send data
offering unparalleled interoperability and
only send data directly
unparalleled interoperability and comprehensive
a pool can infiltrate
interoperability and comprehensive standards
send data directly to
pool can infiltrate each
data directly to a
and comprehensive standards for
can infiltrate each of
comprehensive standards for associated
directly to a small
infiltrate each of the
to a small subset
standards for associated technologies
each of the other
a small subset of
of the other pools
small subset of interested
subset of interested receivers
the other pools with
other pools with some
pools with some nominal
with some nominal probing
they portray web services
some nominal probing mining
participating nodes are consequently
this work was supported
portray web services as
nominal probing mining power
nodes are consequently required
web services as a
probing mining power and
services as a seamless
are consequently required to
as a seamless interconnection
mining power and measure
a seamless interconnection layer
consequently required to forward
seamless interconnection layer that
power and measure the
interconnection layer that will
required to forward packets
layer that will propel
to forward packets to
that will propel computer
forward packets to their
by a grant from
and measure the revenue
a grant from the
packets to their neighbors
grant from the darpa
measure the revenue density
from the darpa mrc
the revenue density directly
the darpa mrc program
revenue density directly by
density directly by monitoring
computer commerce to a
helping disseminate all packets
commerce to a previously
directly by monitoring the
disseminate all packets across
by monitoring the probe
to a previously inaccessible
monitoring the probe s
all packets across the
the probe s rewards
packets across the system
probe s rewards from
a previously inaccessible level
s rewards from the
rewards from the pool
the streamed data should
and they use language
streamed data should be
they use language evocative
data should be received
use language evocative of
should be received by
language evocative of marketing
block withholding recycling we
be received by all
evocative of marketing for
received by all nodes
of marketing for distributed
withholding recycling we assume
marketing for distributed object
by all nodes within
recycling we assume that
for distributed object middleware
all nodes within a
we assume that the
nodes within a fixed
assume that the infiltrating
within a fixed latency
that the infiltrating miners
a fixed latency from
the infiltrating miners are
technologists are sending a
infiltrating miners are loyal
are sending a somewhat
miners are loyal to
sending a somewhat different
are loyal to the
a somewhat different message
loyal to the attacker
fixed latency from the
online measurement of large
latency from the source
measurement of large traffic
from the source s
of large traffic aggregates
the source s original
large traffic aggregates on
source s original transmission
traffic aggregates on commodity
aggregates on commodity switches
in an essay entitled
some of the pool
an essay entitled web
of the pool s
essay entitled web services
the pool s members
entitled web services are
even in the presence
pool s members may
in the presence of
web services are not
the presence of opportunistic
s members may be
presence of opportunistic nodes
services are not distributed
members may be disloyal
are not distributed objects
may be disloyal infiltrators
werner vogels argues that
when sending disloyal miners
vogels argues that web
sending disloyal miners to
we first assume a
disloyal miners to perform
first assume a system
miners to perform block
assume a system in
argues that web services
a system in which
to perform block withholding
system in which all
that web services will
in which all nodes
perform block withholding at
web services will work
block withholding at other
services will work well
withholding at other pools
will work well for
work well for important
well for important classes
for important classes of
important classes of applications
an attacker takes a
have similar upload and
attacker takes a significant
similar upload and download
takes a significant risk
upload and download bandwidths
but he also cites
he also cites significant
also cites significant limits
as vogels sees it
can use a loyal
use a loyal miner
a loyal miner w
the architecture is so
loyal miner w to
architecture is so centered
miner w to infiltrate
is so centered on
w to infiltrate pool
so centered on document
centered on document exchange
we briefly discuss how
briefly discuss how to
and at its core
discuss how to extend
at its core is
how to extend our
its core is so
to extend our model
core is so simple
extend our model to
our model to work
model to work in
to work in heterogeneous
work in heterogeneous scenarios
that many features taken
thinking the miner is
many features taken for
the miner is loyal
features taken for granted
miner is loyal to
taken for granted in
is loyal to it
we assume that malicious
for granted in object
assume that malicious nodes
that malicious nodes exhibit
might use it to
malicious nodes exhibit byzantine
use it to attack
nodes exhibit byzantine behavior
it to attack pool
oriented systems are fundamentally
a compositional architecture for
systems are fundamentally lacking
compositional architecture for gossip
architecture for gossip protocols
while correct nodes follow
correct nodes follow the
nodes follow the protocol
examples include dynamic object
follow the protocol as
include dynamic object creation
the miner m can
the protocol as defined
miner m can perform
dynamic object creation and
m can perform honest
object creation and garbage
can perform honest mining
creation and garbage collection
perform honest mining for
honest mining for pool
requesting data as needed
data as needed and
as needed and sending
needed and sending data
and sending data as
sending data as requested
data as requested from
as requested from them
dynamically created object references
rather than withhold its
than withhold its blocks
altrustic nodes are a
and a variety of
nodes are a subgroup
and not return any
a variety of reliability
not return any revenue
are a subgroup of
return any revenue to
variety of reliability and
a subgroup of correct
of reliability and transactional
any revenue to pool
reliability and transactional mechanisms
subgroup of correct nodes
of correct nodes that
correct nodes that are
nodes that are willing
that are willing to
are willing to upload
willing to upload more
to upload more data
upload more data than
more data than required
data than required from
than required from them
it will take its
will take its share
take its share of
its share of pool
both perspectives can t
perspectives can t be
we employ the term
can t be correct
employ the term opportunistic
which thinks the miner
thinks the miner is
the term opportunistic to
the miner is loyal
miner is loyal to
it s easy to
is loyal to it
term opportunistic to refer
s easy to see
easy to see how
opportunistic to refer to
to see how this
see how this situation
to refer to a
how this situation arose
and deliver it back
refer to a subgroup
deliver it back to
to a subgroup of
it back to pool
a subgroup of byzantine
subgroup of byzantine nodes
web services are the
of byzantine nodes that
services are the most
byzantine nodes that attempt
are the most recent
nodes that attempt to
the most recent in
that attempt to give
most recent in a
attempt to give less
recent in a long
to give less data
in a long series
to avoid such a
a long series of
give less data than
long series of object
avoid such a risk
series of object oriented
less data than they
of object oriented interoperability
data than they would
object oriented interoperability platforms
than they would if
they would if they
a pool needs a
would if they behaved
pool needs a sufficient
if they behaved as
and mixes ideas from
they behaved as correct
mixes ideas from corba
behaved as correct nodes
needs a sufficient number
a sufficient number of
sufficient number of verified
number of verified miners
of verified miners miners
with the intention of
verified miners miners that
the intention of obtaining
miners miners that it
intention of obtaining as
miners that it knows
of obtaining as much
that it knows to
obtaining as much data
it knows to be
as much data as
knows to be loyal
much data as possible
managing the network with
data as possible at
the network with merlin
as possible at least
while exploiting xml and
possible at least feasible
exploiting xml and other
at least feasible cost
xml and other web
the optimal infiltration rate
optimal infiltration rate may
infiltration rate may be
these may employ a
rate may be as
may employ a simple
may be as high
employ a simple strategy
be as high as
developers using popular middleware
using popular middleware platforms
popular middleware platforms can
such as refuse to
middleware platforms can transform
as refuse to contribute
platforms can transform a
refuse to contribute any
can transform a program
to contribute any upload
transform a program object
contribute any upload resources
a program object into
program object into a
of the pool size
object into a web
into a web services
a web services object
or a more elaborate
a more elaborate strategy
but this is only
more elaborate strategy that
this is only in
or access a remote
elaborate strategy that allows
access a remote ws
is only in extreme
a remote ws object
strategy that allows them
only in extreme cases
that allows them to
in extreme cases when
allows them to cheat
extreme cases when pools
them to cheat without
cases when pools are
to cheat without being
when pools are large
at the touch of
cheat without being easily
the touch of a
without being easily detected
touch of a button
for practical pool sizes
notice that our model
performance leaves something to
that our model diverges
leaves something to be
our model diverges from
something to be desired
model diverges from the
diverges from the one
from the one used
a pool may need
the one used in
pool may need up
one used in bar
but computers and networks
used in bar gossip
may need up to
computers and networks have
and networks have become
networks have become astonishingly
have become astonishingly fast
major application providers are
in which nodes are
application providers are planning
which nodes are classified
providers are planning to
nodes are classified as
of its mining power
are classified as byzantine
are planning to offer
its mining power for
planning to offer ws
mining power for infiltration
to offer ws interfaces
offer ws interfaces to
ws interfaces to their
interfaces to their products
so it makes perfect
pools typically have loyal
it makes perfect sense
typically have loyal mining
makes perfect sense that
have loyal mining power
perfect sense that the
loyal mining power either
rational nodes attempt to
sense that the marketing
mining power either run
nodes attempt to maximize
that the marketing community
attempt to maximize their
power either run directly
the marketing community would
to maximize their utility
marketing community would feel
either run directly by
community would feel that
maximize their utility while
run directly by the
would feel that finally
their utility while still
directly by the pool
utility while still following
by the pool owners
while still following the
the pool owners or
still following the defined
they ve reached the
following the defined protocol
pool owners or sold
ve reached the promised
owners or sold as
a language for provisioning
or sold as a
language for provisioning network
reached the promised land
for provisioning network resources
sold as a service
our model is actually
as a service but
model is actually less
a service but run
is actually less lenient
service but run on
but run on the
run on the pool
on the pool owners
the pool owners hardware
nodes employing strategies to
employing strategies to maximize
strategies to maximize their
to maximize their utility
has an understandable emphasis
maximize their utility are
their utility are classified
an understandable emphasis on
utility are classified as
are classified as byzantine
understandable emphasis on facts
emphasis on facts on
on facts on the
so that we can
facts on the ground
that we can build
we can build a
on the ground and
can build a practical
build a practical punishment
the ground and the
ground and the vogels
and the vogels essay
the vogels essay reflects
based system in which
vogels essay reflects the
system in which any
essay reflects the realities
in which any node
reflects the realities of
which any node not
the realities of an
any node not contributing
realities of an architecture
node not contributing its
of an architecture focused
not contributing its fair
an architecture focused at
contributing its fair share
architecture focused at its
its fair share of
focused at its core
fair share of data
at its core on
share of data may
however the size of
of data may be
its core on using
data may be expelled
the size of this
may be expelled from
core on using document
be expelled from the
size of this mining
expelled from the system
on using document exchange
of this mining power
using document exchange to
this mining power is
document exchange to access
mining power is considered
exchange to access backend
power is considered a
to access backend servers
is considered a trade
throughout the paper we
considered a trade secret
a trade secret and
the paper we use
trade secret and is
secret and is not
paper we use the
and is not published
this core has been
we use the terms
core has been extended
use the terms upload
has been extended with
the terms upload factor
been extended with such
terms upload factor and
software defined traffic measurement
extended with such mechanisms
defined traffic measurement with
upload factor and download
traffic measurement with opensketch
countermeasures as in the
factor and download factor
with such mechanisms as
as in the case
and download factor to
in the case of
such mechanisms as rpc
the case of classical
download factor to refer
case of classical block
mechanisms as rpc and
of classical block withholding
factor to refer to
classical block withholding explained
as rpc and asynchronous
block withholding explained in
rpc and asynchronous messaging
withholding explained in section
to refer to the
explained in section ii
refer to the ratio
to the ratio between
the ratio between an
ratio between an upload
between an upload or
an upload or download
upload or download rate
or download rate and
a pool might detect
download rate and the
pool might detect that
rate and the original
might detect that it
and the original stream
detect that it is
the original stream rate
that it is being
it is being attacked
a variety of roll
but cannot detect which
cannot detect which of
given a stream rate
detect which of its
a stream rate of
forward and rendezvous options
which of its miners
of its miners is
its miners is the
miners is the attacker
therefore a pool cannot
but the primary usage
a pool cannot block
the primary usage case
pool cannot block or
primary usage case remains
cannot block or punish
usage case remains that
block or punish withholding
case remains that of
or punish withholding miners
a download rate of
remains that of a
that of a client
of a client sending
a client sending documents
client sending documents to
sending documents to a
documents to a back
various techniques can be
techniques can be used
can be used to
be used to encourage
end service in a
used to encourage miners
service in a client
kbps corresponds to a
to encourage miners to
corresponds to a download
encourage miners to submit
to a download factor
miners to submit full
a download factor of
to submit full blocks
a pool can pay
pool can pay a
can pay a bonus
pay a bonus for
the assumption is that
a bonus for submitting
assumption is that the
bonus for submitting a
is that the application
for submitting a full
that the application can
submitting a full proof
the application can tolerate
a full proof of
application can tolerate substantial
full proof of work
can tolerate substantial delay
tolerate substantial delay before
substantial delay before a
delay before a response
before a response arrives
this would increase the
would increase the revenue
streaming system model our
increase the revenue of
system model our auditing
and mechanisms capable of
the revenue of the
model our auditing approach
mechanisms capable of introducing
our auditing approach is
revenue of the miner
auditing approach is used
capable of introducing delays
approach is used over
of the miner that
is used over the
of introducing delays are
used over the chainsaw
the miner that found
over the chainsaw protocol
introducing delays are scattered
miner that found a
delays are scattered throughout
that found a block
are scattered throughout the
found a block while
scattered throughout the architecture
a block while reducing
block while reducing the
while reducing the revenue
reducing the revenue of
all nodes participating in
the revenue of the
nodes participating in the
revenue of the other
the more basic assumption
of the other miners
participating in the system
the other miners from
more basic assumption is
other miners from this
in the system are
miners from this block
basic assumption is that
the system are organized
system are organized into
assumption is that it
are organized into a
organized into a fully
is that it all
into a fully connected
while the average revenue
that it all boils
a fully connected mesh
the average revenue of
it all boils down
average revenue of each
fully connected mesh overlay
all boils down to
revenue of each miner
boils down to moving
of each miner would
each miner would stay
down to moving documents
miner would stay the
where each node has
would stay the same
each node has the
to moving documents around
node has the same
has the same number
moving documents around whereas
the same number of
documents around whereas the
small miners will suffer
same number of neighbors
miners will suffer from
around whereas the most
will suffer from higher
whereas the most basic
suffer from higher variance
the most basic assumption
from higher variance in
most basic assumption of
the source is randomly
basic assumption of a
higher variance in revenue
source is randomly connected
assumption of a distributed
is randomly connected to
of a distributed object
randomly connected to a
a distributed object system
connected to a small
distributed object system is
to a small subset
another approach is to
a small subset of
object system is that
small subset of the
approach is to introduce
subset of the nodes
system is that the
is to introduce a
is that the world
to introduce a joining
that the world consists
introduce a joining fee
the world consists of
the streaming process starts
a joining fee by
streaming process starts at
world consists of programs
process starts at the
joining fee by paying
starts at the source
consists of programs and
fee by paying new
of programs and data
by paying new miners
paying new miners less
new miners less for
which breaks the data
miners less for their
breaks the data stream
less for their work
active and passive objects
the data stream into
for their work until
data stream into packets
their work until they
stream into packets and
work until they have
the gist of vogel
until they have established
into packets and sends
they have established a
gist of vogel s
have established a reputation
packets and sends notifications
established a reputation with
of vogel s essay
a reputation with the
and sends notifications to
reputation with the pool
vogel s essay is
sends notifications to its
s essay is that
notifications to its neighbors
essay is that even
to its neighbors as
is that even with
its neighbors as soon
that even with all
neighbors as soon as
miners that seek flexibility
as soon as it
even with all the
soon as it has
that seek flexibility may
as it has packets
with all the contemplated
it has packets to
seek flexibility may not
all the contemplated extensions
has packets to disseminate
flexibility may not accept
may not accept this
not accept this policy
accept this policy and
this policy and choose
web services are deeply
policy and choose another
these notifications are small
and choose another pool
services are deeply mismatched
notifications are small messages
are deeply mismatched with
are small messages used
deeply mismatched with distributed
small messages used only
mismatched with distributed object
messages used only to
with distributed object computing
used only to inform
only to inform neighbors
to inform neighbors of
the pool can use
inform neighbors of the
pool can use a
the dilemma underlying the
neighbors of the availability
can use a honeypot
dilemma underlying the debate
of the availability of
use a honeypot trap
the availability of new
the one issue that
a honeypot trap by
availability of new packets
underlying the debate is
one issue that unites
honeypot trap by sending
the debate is that
issue that unites almost
trap by sending the
debate is that the
that unites almost all
is that the platforms
based on the received
unites almost all approaches
that the platforms one
almost all approaches to
the platforms one uses
by sending the miners
on the received notifications
all approaches to distributed
platforms one uses to
sending the miners tasks
one uses to create
approaches to distributed computing
uses to create wscompatible
the miners tasks which
to distributed computing is
to create wscompatible objects
each node requests missing
create wscompatible objects impose
node requests missing packets
wscompatible objects impose no
distributed computing is the
objects impose no such
miners tasks which it
impose no such restrictions
computing is the need
tasks which it knows
is the need to
which it knows will
and the source satisfies
it knows will result
the need to know
knows will result in
there is nothing in
will result in a
need to know whether
result in a full
is nothing in j
in a full proof
to know whether certain
a full proof of
the source satisfies as
know whether certain components
source satisfies as many
full proof of work
satisfies as many requests
whether certain components in
as many requests as
certain components in the
many requests as allowed
components in the system
requests as allowed by
net that warns a
as allowed by its
in the system have
allowed by its upload
that warns a user
by its upload capacity
the system have failed
warns a user that
system have failed or
a user that an
have failed or are
user that an intended
failed or are otherwise
that an intended use
or are otherwise unavailable
an intended use of
intended use of the
use of the architecture
of the architecture may
with chainsaw the upload
the architecture may be
chainsaw the upload capacity
if a miner fails
when designing and building
architecture may be inappropriate
designing and building systems
a miner fails to
and building systems that
the upload capacity of
building systems that need
miner fails to submit
systems that need to
upload capacity of the
that need to function
fails to submit the
need to function at
capacity of the source
to function at a
much of the excitement
function at a global
of the source does
at a global scale
of the excitement reflects
to submit the full
the excitement reflects the
the source does not
excitement reflects the realization
source does not need
reflects the realization that
does not need to
the realization that with
failure management needs to
realization that with web
not need to increase
submit the full proof
need to increase with
that with web services
to increase with the
the full proof of
increase with the size
management needs to be
with the size of
needs to be considered
full proof of work
to be considered a
interoperability really is easier
be considered a fundamental
proof of work it
considered a fundamental building
the size of the
a fundamental building block
size of the system
of work it is
developers have long struggled
work it is tagged
have long struggled with
it is tagged as
long struggled with program
is tagged as an
tagged as an attacker
this paper describes the
even an upload capacity
paper describes the development
an upload capacity of
describes the development of
upload capacity of twice
the development of a
to prevent the attacker
development of a system
capacity of twice the
prevent the attacker from
of twice the stream
the attacker from learning
program interconnection and integration
twice the stream rate
attacker from learning them
the stream rate is
independent failure management service
stream rate is sufficient
rate is sufficient to
and it is natural
is sufficient to ensure
it is natural to
sufficient to ensure that
is natural to applaud
which allows systems and
natural to applaud a
the honeypot tasks have
to applaud a widely
allows systems and applications
applaud a widely adopted
honeypot tasks have to
a widely adopted advance
systems and applications to
to ensure that the
and applications to incorporate
ensure that the system
tasks have to be
that the system performs
have to be regularly
the system performs and
to be regularly refreshed
system performs and scales
like it or not
performs and scales well
applications to incorporate accurate
to incorporate accurate detection
incorporate accurate detection of
accurate detection of failed
web services are becoming
detection of failed processes
services are becoming a
as nodes receive packets
are becoming a de
pools can also incorporate
can also incorporate out
also incorporate out of
incorporate out of band
they mimic the role
facto standard for everything
mimic the role of
out of band mechanisms
the role of the
without the need for
role of the source
of band mechanisms to
the need for making
band mechanisms to deter
need for making compromises
mechanisms to deter attacks
that s not all
for making compromises in
sending notifications to their
making compromises in their
notifications to their own
compromises in their particular
to their own neighbors
in their particular design
their own neighbors in
such as verifying the
own neighbors in the
as verifying the identity
neighbors in the mesh
verifying the identity of
the identity of miners
based direct sales systems
identity of miners or
direct sales systems are
of miners or using
with the advent of
sales systems are turning
the advent of ubiquitous
miners or using trusted
allowing packets to be
or using trusted computing
packets to be propagated
using trusted computing technologies
systems are turning to
to be propagated through
are turning to the
be propagated through the
turning to the ws
propagated through the system
to the ws architecture
the ws architecture as
ws architecture as a
architecture as a means
as a means of
it is becoming clear
a means of enlarging
is becoming clear that
means of enlarging their
becoming clear that the
of enlarging their markets
based approach to acquisition
clear that the systems
approach to acquisition of
that the systems that
to acquisition of packets
the systems that are
that assure no block
systems that are used
assure no block withholding
that are used today
no block withholding is
are used today in
block withholding is taking
used today in local
withholding is taking place
com has developed a
has developed a web
this would require miners
would require miners to
require miners to use
miners to use specialized
can not simply be
to use specialized hardware
access library whereby third
use specialized hardware and
not simply be employed
specialized hardware and software
provides some resilience to
simply be employed in
some resilience to failure
be employed in their
resilience to failure or
party application developers can
to failure or malicious
employed in their existing
failure or malicious behavior
an overhead miners may
application developers can access
overhead miners may not
in their existing form
miners may not accept
developers can access their
their existing form or
since a participant will
can access their datacenters
a participant will have
existing form or trivially
participant will have multiple
form or trivially converted
access their datacenters from
or trivially converted for
will have multiple possible
trivially converted for wide
there is no known
their datacenters from a
is no known silver
have multiple possible sources
no known silver bullet
datacenters from a diversity
multiple possible sources for
from a diversity of
possible sources for each
a diversity of end
sources for each packet
all these techniques reduce
these techniques reduce the
techniques reduce the pool
reduce the pool s
the mesh overlay defines
the pool s attractiveness
mesh overlay defines a
pool s attractiveness and
overlay defines a predetermined
s attractiveness and deter
an application could order
attractiveness and deter miners
whatever form such systems
defines a predetermined set
form such systems may
application could order thus
such systems may take
a predetermined set of
systems may take in
could order thus supplies
may take in the
predetermined set of neighbors
take in the future
order thus supplies directly
set of neighbors for
thus supplies directly from
of neighbors for each
block withholding in practice
neighbors for each peer
supplies directly from amazon
withholding in practice long
whether they are replicated
in practice long term
they are replicated databases
practice long term block
are replicated databases of
long term block withholding
replicated databases of hyper
term block withholding attacks
which also makes it
block withholding attacks are
withholding attacks are difficult
also makes it hard
attacks are difficult to
query the fulfillment system
makes it hard for
are difficult to hide
the fulfillment system to
it hard for malicious
fulfillment system to track
hard for malicious peers
system to track order
for malicious peers to
to track order status
since miners using an
track order status or
malicious peers to round
order status or billing
miners using an attacked
peers to round up
status or billing data
view or virtual synchronous
using an attacked pool
or virtual synchronous groups
to round up on
virtual synchronous groups or
an attacked pool would
synchronous groups or agents
round up on individual
groups or agents employing
attacked pool would notice
up on individual peers
pool would notice the
or agents employing lazy
would notice the reduced
on individual peers since
notice the reduced revenue
agents employing lazy consistency
the reduced revenue density
individual peers since attackers
both the vendor and
peers since attackers lack
the vendor and the
employing lazy consistency schemes
vendor and the application
since attackers lack a
and the application developer
attackers lack a deterministic
the application developer benefit
lack a deterministic means
a deterministic means of
such attacks are rarely
one of the key
deterministic means of acquiring
of the key problems
attacks are rarely reported
means of acquiring control
the key problems that
com enlarges its client
key problems that needs
enlarges its client base
of acquiring control of
problems that needs to
acquiring control of all
that needs to be
control of all of
and we can therefore
needs to be addressed
of all of its
while the developer avoids
all of its neighbors
we can therefore conclude
the developer avoids duplicating
can therefore conclude that
developer avoids duplicating an
therefore conclude that they
avoids duplicating an enormous
conclude that they are
is that of the
that they are indeed
duplicating an enormous technology
they are indeed rare
all nodes with exception
that of the detection
an enormous technology investment
of the detection and
nodes with exception of
the detection and handling
with exception of the
a recent exception is
detection and handling of
recent exception is an
and handling of faulty
exception of the source
handling of faulty components
exception is an attack
of the source have
is an attack on
web service components will
the source have a
an attack on the
source have a fixed
attack on the eligius
have a fixed upper
service components will play
a fixed upper limit
on the eligius pool
components will play a
the eligius pool performed
fixed upper limit on
eligius pool performed in
building distributed systems and
pool performed in may
upper limit on their
performed in may and
distributed systems and applications
in may and june
limit on their upload
systems and applications today
on their upload contribution
will play a critical
and applications today is
play a critical role
applications today is done
a critical role in
today is done using
critical role in tremendous
is done using a
role in tremendous numbers
done using a variety
in tremendous numbers of
using a variety of
tremendous numbers of end
a variety of systems
variety of systems ranging
of systems ranging from
systems ranging from the
ranging from the bare
from the bare bone
the bare bone protocols
bare bone protocols interfaces
the challenge is to
bone protocols interfaces like
challenge is to make
protocols interfaces like bsd
is to make such
interfaces like bsd sockets
to make such systems
like bsd sockets and
make such systems work
bsd sockets and the
such systems work reliably
sockets and the tdi
times the stream rate
outages that plague human
that plague human users
to rpc based systems
plague human users of
rpc based systems such
human users of web
based systems such as
defined by the protocol
users of web browsers
systems such as dce
of web browsers don
such as dce and
web browsers don t
as dce and to
browsers don t cause
dce and to more
don t cause much
and to more advanced
t cause much harm
to more advanced distributed
bitcoin before detecting the
this upper limit is
more advanced distributed support
upper limit is not
before detecting the attack
limit is not respected
advanced distributed support systems
is not respected by
distributed support systems such
not respected by opportunistic
support systems such as
respected by opportunistic nodes
systems such as isis
outages could disrupt a
at which point payouts
could disrupt a computer
which point payouts to
point payouts to the
payouts to the attackers
who attempt to reduce
to the attackers were
attempt to reduce it
the attackers were blocked
to reduce it with
reduce it with the
it with the goal
with the goal of
computer pathway buried deep
the goal of uploading
the attackers continued the
goal of uploading less
pathway buried deep within
of uploading less data
attackers continued the attack
buried deep within an
deep within an application
within an application on
an application on which
on the course of
application on which an
the course of a
on which an enterprise
course of a streaming
which an enterprise has
of a streaming session
an enterprise has become
enterprise has become dependent
each node stores packets
it is too easy
node stores packets and
more bitcoin before realizing
is too easy to
stores packets and forwards
bitcoin before realizing they
too easy to dismiss
before realizing they were
packets and forwards them
realizing they were not
easy to dismiss these
they were not receiving
and forwards them to
were not receiving their
to dismiss these concerns
forwards them to other
not receiving their payout
dismiss these concerns by
them to other peers
these concerns by arguing
to other peers only
concerns by arguing that
other peers only while
by arguing that the
peers only while the
arguing that the web
only while the packet
the reasons the attack
while the packet is
that the web is
the packet is within
reasons the attack was
packet is within its
the web is extremely
is within its availability
the attack was so
within its availability window
web is extremely scalable
attack was so easily
is extremely scalable and
was so easily subverted
extremely scalable and robust
so easily subverted is
usually spanning a few
easily subverted is the
spanning a few seconds
subverted is the limited
is the limited efforts
but this ignores the
the limited efforts of
this ignores the way
limited efforts of the
ignores the way we
efforts of the attackers
the way we use
of the attackers to
way we use the
each node also maintains
we use the web
the attackers to hide
node also maintains an
attackers to hide themselves
also maintains an interest
after years of experience
maintains an interest window
years of experience with
a human can deal
of experience with building
human can deal with
experience with building these
can deal with the
they have only used
with building these systems
have only used two
building these systems and
only used two payout
these systems and applications
used two payout addresses
deal with the many
two payout addresses to
which represents the set
payout addresses to collect
with the many error
represents the set of
addresses to collect their
the set of packets
to collect their payouts
set of packets in
the many error conditions
of packets in which
many error conditions the
packets in which the
error conditions the web
it is clear that
conditions the web exposes
in which the peer
is clear that failure
and so it was
which the peer is
clear that failure management
the peer is currently
so it was possible
peer is currently interested
handling those conditions in
it was possible for
that failure management is
those conditions in a
was possible for the
conditions in a seamless
failure management is not
possible for the alert
nodes choose packets to
management is not just
for the alert pool
is not just a
choose packets to request
not just a essential
automated manner is an
packets to request from
manner is an entirely
just a essential tool
is an entirely different
to request from each
an entirely different challenge
request from each of
the alert pool manager
a essential tool for
from each of its
essential tool for group
each of its neighbors
tool for group oriented
alert pool manager to
for group oriented systems
pool manager to cluster
manager to cluster the
when we take what
respecting a maximum limit
to cluster the attacking
all which have built
a maximum limit l
we take what was
maximum limit l on
cluster the attacking miners
limit l on the
take what was once
l on the number
the attacking miners and
on the number of
what was once a
the number of outstanding
attacking miners and obtain
number of outstanding requests
was once a batch
of outstanding requests to
miners and obtain a
outstanding requests to each
once a batch service
but that it is
a batch service or
and obtain a statistically
batch service or a
obtain a statistically significant
service or a web
that it is a
or a web site
a statistically significant proof
it is a fundamental
statistically significant proof of
a web site and
significant proof of their
is a fundamental service
proof of their wrongdoing
web site and transform
a fundamental service that
site and transform it
fundamental service that should
and transform it into
service that should be
transform it into a
it is unknown whether
it into a web
that should be placed
into a web service
is unknown whether this
should be placed among
unknown whether this was
be placed among such
whether this was a
placed among such established
this was a classical
among such established basic
was a classical block
such established basic services
there is no way
established basic services as
a classical block withholding
basic services as naming
is no way to
classical block withholding attack
no way to enforce
way to enforce appropriate
to enforce appropriate patterns
enforce appropriate patterns of
appropriate patterns of use
with the goal of
the goal of sabotage
what s to stop
s to stop a
or a more elaborate
to stop a web
service brokerage and ipc
a more elaborate scheme
stop a web client
a web client from
web client from trying
client from trying to
from trying to download
to verify the effectiveness
this paper reports on
trying to download amazon
verify the effectiveness of
paper reports on an
the effectiveness of block
effectiveness of block withholding
reports on an ongoing
of block withholding for
com s entire catalog
block withholding for profit
on an ongoing research
an ongoing research effort
ongoing research effort to
research effort to abstract
the only answer is
effort to abstract the
to abstract the failure
abstract the failure handling
the failure handling strategies
failure handling strategies from
handling strategies from a
strategies from a variety
from a variety of
implemented an experimental bitcoin
a variety of popular
one might argue that
an experimental bitcoin test
variety of popular distributed
might argue that none
experimental bitcoin test network
of popular distributed systems
bitcoin test network and
argue that none of
popular distributed systems and
that none of these
test network and demonstrated
distributed systems and to
network and demonstrated the
none of these uses
systems and to develop
and demonstrated the practicality
of these uses are
and to develop a
demonstrated the practicality of
these uses are what
to develop a basic
the practicality of the
uses are what the
practicality of the attack
develop a basic failure
are what the architecture
what the architecture is
a basic failure management
the architecture is intended
architecture is intended to
basic failure management service
is intended to support
failure management service that
management service that can
service that can be
that can be used
not so many years
can be used by
so many years ago
bitcoin s health large
be used by any
s health large pools
used by any distributed
health large pools hinder
by any distributed system
large pools hinder bitcoin
any distributed system regardless
pools hinder bitcoin s
distributed system regardless of
server architectures faltered over
system regardless of the
hinder bitcoin s distributed
regardless of the purpose
architectures faltered over precisely
of the purpose of
bitcoin s distributed nature
the purpose of that
faltered over precisely this
s distributed nature as
over precisely this type
purpose of that system
distributed nature as they
precisely this type of
nature as they put
this type of situation
of that system or
as they put a
that system or the
they put a lot
system or the techniques
put a lot of
or the techniques used
a lot of mining
lot of mining power
of mining power in
mining power in the
server technologies of the
power in the hands
in the hands of
the hands of a
the strategies employed by
hands of a few
of a few pool
strategies employed by this
a few pool managers
employed by this basic
by this basic service
this basic service are
basic service are specifically
service are specifically targeted
this has been mostly
are specifically targeted towards
has been mostly addressed
specifically targeted towards applications
s were widely seen
targeted towards applications that
were widely seen as
been mostly addressed by
widely seen as a
towards applications that need
mostly addressed by community
seen as a kind
addressed by community pressure
as a kind of
upload factor download factor
applications that need to
by community pressure on
that need to operate
a kind of panacea
need to operate on
community pressure on miners
to operate on a
pressure on miners to
operate on a global
on miners to avoid
on a global scale
miners to avoid forming
a silver bullet that
to avoid forming large
silver bullet that would
avoid forming large pools
bullet that would slay
that would slay evil
would slay evil mainframe
slay evil mainframe architectures
to build a successful
build a successful service
a successful service the
enterprises fell over themselves
successful service the following
fell over themselves in
service the following goals
over themselves in a
the following goals were
themselves in a kind
following goals were set
in a kind of
a kind of technology
kind of technology gold
of technology gold rush
design a failure management
however such recommendations had
a failure management system
only to discover that
such recommendations had only
failure management system that
recommendations had only had
to discover that the
had only had limited
management system that is
discover that the technology
only had limited success
system that is independent
that the technology had
that is independent of
the technology had been
is independent of the
technology had been oversold
and mining is still
independent of the distributed
mining is still dominated
of the distributed systems
is still dominated by
the distributed systems packages
still dominated by a
distributed systems packages in
dominated by a small
systems packages in use
by a small number
packages in use and
a small number of
the total cost of
small number of large
in use and provide
number of large pools
total cost of ownership
use and provide failure
cost of ownership for
and provide failure detection
of ownership for clientserver
provide failure detection of
ownership for clientserver systems
failure detection of processes
as a characteristic example
for clientserver systems remains
clientserver systems remains excessively
systems remains excessively high
in the period of
the period of november
the number of system
improve the accuracy of
number of system administrators
the accuracy of detection
of system administrators remains
accuracy of detection of
system administrators remains roughly
of detection of process
administrators remains roughly proportional
detection of process and
remains roughly proportional to
of process and node
roughly proportional to the
process and node failure
proportional to the size
and node failure through
to the size of
node failure through systems
the size of the
failure through systems support
size of the deployment
design support for failure
support for failure detectors
for failure detectors to
failure detectors to work
detectors to work in
a list like these
to work in large
list like these comments
work in large scale
like these comments might
in large scale systems
these comments might have
comments might have seemed
might have seemed like
three pools generated over
have seemed like an
while maintaining a high
seemed like an indictment
maintaining a high level
like an indictment of
a high level of
an indictment of the
high level of accuracy
indictment of the technology
provide support for the
because we lacked solutions
support for the detection
for the detection of
of the proofs of
the detection of partitions
the proofs of work
detection of partitions in
of partitions in networks
build a comprehensive software
a comprehensive software package
we know how to
comprehensive software package that
know how to implement
software package that can
how to implement management
package that can be
to implement management tools
that can be easily
implement management tools and
can be easily integrated
management tools and fault
be easily integrated into
easily integrated into various
integrated into various distributed
into various distributed systems
the fact that block
various distributed systems packages
fact that block withholding
distributed systems packages and
how to replicate data
that block withholding attacks
systems packages and applications
to replicate data and
block withholding attacks are
replicate data and functionality
withholding attacks are rarely
attacks are rarely observed
the resulting system is
are rarely observed may
and how to achieve
resulting system is implemented
rarely observed may indicate
how to achieve high
system is implemented and
to achieve high ava
is implemented and is
achieve high ava ilability
implemented and is under
observed may indicate that
and is under test
may indicate that the
is under test in
we ve had decades
indicate that the active
ve had decades of
under test in a
had decades of experience
test in a wide
decades of experience with
that the active pools
of experience with large
the active pools have
active pools have reached
pools have reached an
have reached an implicit
scale system monitoring and
reached an implicit or
system monitoring and control
an implicit or explicit
in a local setting
implicit or explicit agreement
a local setting of
or explicit agreement not
local setting of a
explicit agreement not to
setting of a mix
agreement not to attack
and are beginning to
not to attack one
of a mix of
to attack one another
are beginning to understand
a mix of high
beginning to understand how
to understand how to
understand how to build
how to build solutions
to build solutions on
speed and traditional networks
build solutions on an
and traditional networks and
solutions on an internet
an attacked pool cannot
on an internet scale
traditional networks and in
maximum upload factor figure
networks and in the
attacked pool cannot detect
and in the internet
pool cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners are
a first software release
its miners are attacking
first software release is
miners are attacking it
software release is planned
download and upload factors
release is planned for
and upload factors of
peer file sharing turns
is planned for the
file sharing turns out
let alone which pool
sharing turns out to
alone which pool controls
planned for the autumn
which pool controls the
for the autumn of
pool controls the miners
turns out to be
upload factors of nodes
out to be illegal
factors of nodes in
of nodes in an
nodes in an ideal
at some point a
in an ideal system
some point a pool
an ideal system where
and it doesn t
point a pool might
it doesn t work
ideal system where all
doesn t work all
a pool might miscalculate
t work all that
system where all nodes
pool might miscalculate and
where all nodes behave
work all that well
all nodes behave correctly
might miscalculate and decide
miscalculate and decide to
and decide to try
decide to try and
to try and increase
try and increase its
and increase its revenue
external failure detector modules
failure detector modules originate
detector modules originate in
one pool might be
modules originate in asynchronous
this limit not only
originate in asynchronous distributed
limit not only improves
in asynchronous distributed systems
not only improves the
but spawned a new
only improves the general
pool might be enough
spawned a new generation
might be enough to
improves the general flow
where they were introduced
the general flow of
they were introduced to
general flow of packets
were introduced to de
be enough to break
a new generation of
enough to break the
new generation of technologies
to break the agreement
generation of technologies based
but also makes it
couple the mechanism by
also makes it harder
of technologies based on
possibly leading to a
makes it harder for
leading to a constant
technologies based on distributed
to a constant rate
it harder for malicious
a constant rate of
based on distributed hash
constant rate of attacks
harder for malicious peers
rate of attacks among
on distributed hash tables
the mechanism by which
distributed hash tables and
of attacks among pools
hash tables and epidemic
attacks among pools and
tables and epidemic communication
among pools and a
and epidemic communication protocols
pools and a reduced
for malicious peers to
mechanism by which failures
malicious peers to overrequest
and a reduced revenue
peers to overrequest packets
by which failures are
to overrequest packets from
these offer remarkably stable
overrequest packets from their
which failures are detected
packets from their neighbors
failures are detected from
if open pools reach
are detected from the
open pools reach a
detected from the protocols
scalable tools for dealing
from the protocols used
peers maintain a queue
the protocols used to
maintain a queue of
protocols used to tolerate
a queue of non
pools reach a state
tools for dealing with
reach a state where
used to tolerate those
a state where their
to tolerate those failures
state where their revenue
satisfied requests from its
for dealing with enormous
requests from its neighbors
where their revenue density
dealing with enormous numbers
their revenue density is
with enormous numbers of
revenue density is reduced
enormous numbers of components
density is reduced due
numbers of components scattered
is reduced due to
keeping only the l
of components scattered over
only the l most
reduced due to attacks
components scattered over a
the l most recent
scattered over a network
l most recent ones
miners will leave them
chandra and toueg successfully
will leave them in
not all the stories
and toueg successfully show
leave them in favor
all the stories are
them in favor of
the stories are positive
in favor of other
toueg successfully show that
favor of other available
successfully show that it
of other available options
show that it is
that it is possible
it is possible to
is possible to develop
possible to develop consensus
the web services community
expected behavior our first
miners of sufficient size
to develop consensus algorithms
of sufficient size can
behavior our first goal
sufficient size can mine
develop consensus algorithms using
size can mine solo
our first goal is
web services community decided
first goal is to
consensus algorithms using failure
goal is to explore
services community decided not
is to explore the
smaller miners can form
algorithms using failure detectors
miners can form private
to explore the typical
can form private pools
community decided not to
form private pools with
decided not to adapt
private pools with closed
not to adapt the
pools with closed access
to adapt the corba
explore the typical signature
adapt the corba fault
even if these failure
the typical signature of
if these failure detectors
limited to trusted participants
these failure detectors make
typical signature of the
failure detectors make frequent
signature of the system
tolerance standard for their
detectors make frequent mistakes
standard for their setting
such a change may
make frequent mistakes in
a change may be
frequent mistakes in their
change may be in
mistakes in their observations
may be in favor
since an understanding of
be in favor of
this is a specification
in favor of bitcoin
is a specification i
favor of bitcoin as
a specification i know
of bitcoin as a
specification i know well
bitcoin as a whole
an understanding of the
understanding of the behavior
of the behavior of
it was based on
the behavior of pullbased
since they require such
was based on the
they require such intimate
behavior of pullbased dissemination
require such intimate trust
based on the virtual
of pullbased dissemination in
on the virtual synchrony
pullbased dissemination in the
the virtual synchrony model
dissemination in the absence
virtual synchrony model colleagues
private pools are likely
in the absence of
synchrony model colleagues of
pools are likely to
the absence of opportunistic
are likely to be
model colleagues of mine
absence of opportunistic nodes
likely to be smaller
colleagues of mine and
of opportunistic nodes will
of mine and i
opportunistic nodes will turn
mine and i developed
nodes will turn out
and form a fine
and i developed in
form a fine grained
will turn out to
a fine grained distribution
i developed in work
the failure detector work
developed in work on
fine grained distribution of
in work on the
failure detector work is
work on the isis
grained distribution of mining
turn out to be
distribution of mining power
out to be important
of mining power with
on the isis toolkit
mining power with many
to be important when
power with many small
detector work is extended
with many small pools
be important when we
work is extended to
important when we set
many small pools and
the standard hasn t
small pools and solo
when we set out
pools and solo miners
standard hasn t been
is extended to systems
hasn t been a
we set out to
t been a commercial
extended to systems that
been a commercial success
set out to introduce
to systems that also
out to introduce auditing
systems that also take
that also take network
also take network failure
but the corba standard
take network failure into
the corba standard limits
network failure into account
we conducted experiments using
corba standard limits itself
conducted experiments using an
standard limits itself to
experiments using an event
limits itself to lock
state replication of a
replication of a deterministic
a pool may engage
of a deterministic server
off in designing practical
which is described in
pool may engage in
is described in more
in designing practical distributed
described in more detail
may engage in an
designing practical distributed systems
in more detail in
perhaps the issue is
more detail in section
practical distributed systems based
engage in an attack
the issue is the
in an attack against
issue is the way
an attack against another
distributed systems based on
is the way the
systems based on the
attack against another pool
the way the technology
against another pool not
way the technology was
another pool not to
the technology was used
pool not to increase
based on the theory
not to increase its
on the theory developed
to increase its absolute
the theory developed for
not the technology itself
increase its absolute revenue
we evaluate the performance
theory developed for asynchronous
evaluate the performance of
developed for asynchronous systems
for asynchronous systems is
asynchronous systems is where
but rather to attract
systems is where and
rather to attract miners
is where and how
used in other ways
where and how to
to attract miners by
and how to introduce
attract miners by temporarily
how to introduce the
miners by temporarily increasing
to introduce the notion
has been quite successful
by temporarily increasing its
introduce the notion of
temporarily increasing its revenue
the notion of time
increasing its revenue relative
nodes during an ideal
its revenue relative to
during an ideal execution
revenue relative to a
an ideal execution of
relative to a competing
ideal execution of chainsaw
to a competing pool
traditionally failure detectors have
isis runs the new
failure detectors have been
runs the new york
detectors have been implemented
the new york stock
where all the nodes
new york stock exchange
recent work has investigated
all the nodes behave
have been implemented using
the nodes behave correctly
work has investigated the
york stock exchange quote
been implemented using time
stock exchange quote and
has investigated the motivation
exchange quote and trade
investigated the motivation of
quote and trade reporting
we fixed the upload
and trade reporting system
out mechanisms in the
the motivation of pools
mechanisms in the transport
fixed the upload factor
in the transport layer
motivation of pools to
the transport layer that
a role it has
transport layer that implements
role it has played
the upload factor of
it has played since
layer that implements inter
of pools to utilize
upload factor of the
pools to utilize part
factor of the source
to utilize part of
of the source at
utilize part of their
part of their resources
of their resources towards
their resources towards sabotage
resources towards sabotage attacks
towards sabotage attacks against
sabotage attacks against each
attacks against each other
outs remain an important
remain an important tool
an important tool in
important tool in the
tool in the failure
in the failure manager
the failure manager described
failure manager described in
manager described in this
described in this paper
and the french air
the french air traffic
the mechanism is integrated
french air traffic control
mechanism is integrated into
air traffic control system
is integrated into a
and the stream rate
integrated into a more
the stream rate to
into a more comprehensive
and the us naval
a more comprehensive approach
the us naval aegis
more comprehensive approach that
us naval aegis warship
comprehensive approach that treats
naval aegis warship communication
approach that treats failure
aegis warship communication system
that treats failure detection
treats failure detection using
failure detection using methods
detection using methods based
to name just a
using methods based on
name just a few
methods based on an
based on an analogy
on an analogy with
we varied the maximum
an analogy with fault
the model of those
varied the maximum upload
leslie lamport s paxos
model of those works
the maximum upload factor
lamport s paxos protocol
of those works is
s paxos protocol has
maximum upload factor of
those works is different
detection techniques used in
paxos protocol has been
techniques used in daily
works is different from
upload factor of nodes
protocol has been used
used in daily life
has been used to
factor of nodes to
been used to build
is different from the
of nodes to see
used to build file
different from the pool
to build file systems
nodes to see how
build file systems and
when trying to contact
file systems and scalable
to see how it
from the pool game
systems and scalable clusters
see how it affected
trying to contact a
how it affected both
the pool game model
to contact a person
it affected both the
pool game model in
contact a person who
none of these examples
affected both the download
a person who has
game model in two
both the download and
of these examples uses
the download and upload
these examples uses lock
download and upload factors
model in two major
and upload factors of
person who has allegedly
upload factors of nodes
in two major ways
factors of nodes across
step replication of the
of nodes across the
two major ways a
nodes across the system
replication of the type
major ways a sabotage
of the type mandated
who has allegedly disappeared
the type mandated by
ways a sabotage attack
type mandated by corba
has allegedly disappeared one
a sabotage attack does
the maximum upload factor
allegedly disappeared one would
sabotage attack does not
maximum upload factor is
attack does not transfer
disappeared one would never
does not transfer revenue
upload factor is a
one would never be
not transfer revenue from
factor is a fixed
would never be satisfied
every technology has its
transfer revenue from victim
technology has its successes
revenue from victim to
has its successes and
from victim to attacker
its successes and failures
never be satisfied with
is a fixed parameter
be satisfied with making
a fixed parameter which
satisfied with making repeated
fixed parameter which defines
and migrating miners switch
with making repeated phone
migrating miners switch to
parameter which defines the
miners switch to less
making repeated phone calls
switch to less attacked
which defines the maximum
to less attacked pools
repeated phone calls to
defines the maximum rate
phone calls to the
the maximum rate at
calls to the same
maximum rate at which
to the same location
rate at which a
changing pool sizes and
these technologies could take
pool sizes and hence
at which a node
sizes and hence revenues
technologies could take the
and hence revenues until
which a node will
hence revenues until convergence
could take the web
the same location for
take the web services
a node will upload
the web services architecture
same location for half
web services architecture to
the model is parametrized
services architecture to a
location for half an
node will upload data
for half an hour
will upload data to
half an hour and
upload data to all
an hour and then
data to all its
model is parametrized by
architecture to a new
hour and then declaring
to a new level
is parametrized by the
to all its neighbors
parametrized by the cost
and then declaring the
by the cost of
then declaring the disappearance
the cost of the
declaring the disappearance a
cost of the attack
the disappearance a fact
for fairness in nodes
of the attack and
fairness in nodes bandwidth
doing so could greatly
in nodes bandwidth consumption
so could greatly enlarge
the attack and by
could greatly enlarge the
attack and by the
greatly enlarge the web
and by the mobility
enlarge the web services
no matter whether the
by the mobility of
we would like all
the mobility of the
the web services market
mobility of the miners
matter whether the phone
would like all nodes
whether the phone was
like all nodes to
the phone was not
all nodes to upload
phone was not picked
so what s the
nodes to upload data
what s the bottom
was not picked up
to upload data at
s the bottom line
and the analysis demonstrates
upload data at a
the analysis demonstrates that
data at a factor
analysis demonstrates that when
a busy tone was
demonstrates that when considering
busy tone was heard
at a factor as
tone was heard or
that when considering only
was heard or the
a factor as close
when considering only sabotage
heard or the phone
considering only sabotage attacks
or the phone was
are web services distributed
the phone was disconnected
web services distributed objects
factor as close as
only sabotage attacks there
as close as possible
sabotage attacks there are
close as possible to
attacks there are regions
there are regions where
of course they are
are regions where no
in practice one would
practice one would work
one would work to
would work to gain
the marketing people are
attack is the best
work to gain more
is the best strategy
marketing people are listening
to gain more confidence
people are listening to
gain more confidence in
are listening to customers
more confidence in such
the miner s dilemma
confidence in such a
miner s dilemma is
in such a decision
s dilemma is therefore
such a decision by
dilemma is therefore not
a decision by talking
is therefore not manifested
decision by talking to
we varied the maximum
by talking to the
therefore not manifested in
and they want distributed
varied the maximum upload
talking to the landlord
not manifested in that
they want distributed objects
manifested in that model
the maximum upload factor
maximum upload factor of
upload factor of nodes
factor of nodes from
the neighbors or others
but vogels is right
neighbors or others that
pool competition for miners
or others that may
competition for miners is
others that may have
for miners is an
that may have a
miners is an incentive
may have a more
is an incentive in
have a more informed
an incentive in and
a more informed idea
incentive in and of
more informed idea about
in and of its
informed idea about the
and of its own
idea about the situation
of its own for
about the situation of
its own for mutual
the situation of the
own for mutual attacks
situation of the person
of the person in
the person in question
it s time for
s time for the
and a pool may
time for the web
a pool may therefore
for the web services
the failure management described
the web services community
the left graph shows
failure management described in
web services community to
pool may therefore choose
services community to come
management described in this
community to come to
may therefore choose to
to come to grips
described in this paper
left graph shows the
therefore choose to perform
graph shows the minimum
in this paper is
come to grips with
this paper is capable
to grips with the
paper is capable of
grips with the needs
is capable of following
with the needs of
capable of following a
average and maximum download
of following a similar
the needs of their
following a similar strategy
choose to perform block
and maximum download factors
needs of their customer
maximum download factors across
of their customer base
to perform block withholding
download factors across the
if a process under
factors across the nodes
perform block withholding even
a process under investigation
across the nodes when
one can justify solutions
block withholding even if
can justify solutions that
the nodes when the
justify solutions that make
withholding even if its
process under investigation is
even if its revenue
nodes when the maximum
if its revenue would
under investigation is not
its revenue would increase
when the maximum upload
revenue would increase only
the maximum upload factor
would increase only after
maximum upload factor of
increase only after the
upload factor of nodes
only after the next
factor of nodes is
investigation is not responding
of nodes is increased
after the next difficult
of the customers happy
the next difficult adjustment
the customers happy but
is not responding it
customers happy but leave
not responding it will
responding it will contact
it will contact the
the two models are
will contact the operating
two models are therefore
by increasing the maximum
contact the operating system
increasing the maximum upload
models are therefore complimentary
the maximum upload factor
the operating system under
maximum upload factor of
operating system under which
upload factor of nodes
system under which the
under which the process
the analysis of their
which the process is
analysis of their combination
the process is running
of their combination is
we increase the global
their combination is left
increase the global upload
combination is left for
the global upload capacity
is left for future
or other nodes on
left for future work
global upload capacity of
a solution that tries
upload capacity of the
other nodes on the
capacity of the system
nodes on the same
solution that tries to
on the same sub
that tries to do
tries to do better
to do better will
leading to a better
do better will probably
to a better flow
net to help reach
better will probably overreach
to help reach a
a better flow of
help reach a decision
better flow of packets
reach a decision in
a decision in which
decision in which one
but you can t
we assumed in our
in which one can
you can t get
which one can have
assumed in our analysis
can t get there
one can have greater
in our analysis that
the discrepancy among the
can have greater confidence
our analysis that pools
discrepancy among the upload
analysis that pools do
t get there if
among the upload factors
that pools do not
the upload factors of
get there if you
upload factors of individual
pools do not charge
factors of individual nodes
there if you close
do not charge fees
most distributed systems in
of individual nodes also
if you close your
individual nodes also increases
distributed systems in use
not charge fees from
systems in use today
you close your eyes
in use today deal
close your eyes to
use today deal with
charge fees from their
today deal with failure
your eyes to the
deal with failure of
fees from their members
with failure of nodes
eyes to the way
failure of nodes or
from their members since
of nodes or networks
to the way the
nodes or networks in
their members since such
or networks in some
the way the customers
as seen in the
way the customers are
seen in the graph
the customers are likely
in the graph to
customers are likely to
the graph to the
are likely to use
networks in some way
likely to use the
graph to the right
to use the technology
members since such fees
since such fees are
such fees are typically
fees are typically nominal
in general the problem
when the maximum upload
will the web services
the maximum upload factor
general the problem is
maximum upload factor is
the web services community
upload factor is increased
the problem is detected
web services community have
problem is detected in
services community have the
is detected in the
community have the wisdom
some nodes participate more
have the wisdom to
detected in the communication
the wisdom to tackle
nodes participate more actively
in the communication subsystem
wisdom to tackle the
participate more actively in
to tackle the tough
the communication subsystem where
tackle the tough issues
more actively in dissemination
of a pool s
communication subsystem where session
the tough issues before
actively in dissemination while
tough issues before circumstances
subsystem where session or
issues before circumstances force
in dissemination while others
where session or transport
before circumstances force it
dissemination while others end
session or transport protocols
while others end up
circumstances force it upon
or transport protocols are
force it upon them
a pool s revenue
others end up contributing
transport protocols are unable
end up contributing less
protocols are unable to
are unable to make
unable to make progress
to make progress because
even though all of
make progress because of
though all of them
progress because of the
all of them are
because of the lack
of them are behaving
of the lack of
them are behaving correctly
a fellow of the
the lack of response
fellow of the acm
lack of response from
of response from remote
response from remote nodes
this is an important
is an important consideration
the model can be
traditionally packets are being
model can be extended
packets are being retransmitted
can be extended to
when we introduce auditing
be extended to include
are being retransmitted after
extended to include pools
being retransmitted after a
to include pools fees
retransmitted after a time
we do not want
do not want to
fees would add a
out period and after
not want to punish
would add a friction
period and after a
want to punish nodes
add a friction element
and after a retry
to punish nodes that
after a retry threshold
a friction element to
a retry threshold is
punish nodes that are
friction element to the
retry threshold is reached
element to the flow
nodes that are willing
to the flow of
threshold is reached the
the flow of revenue
that are willing to
flow of revenue among
is reached the remote
are willing to contribute
of revenue among infiltrated
reached the remote destination
revenue among infiltrated and
willing to contribute but
among infiltrated and infiltrating
the remote destination is
infiltrated and infiltrating pools
to contribute but cannot
and has worked on
remote destination is marked
has worked on reliability
destination is marked as
contribute but cannot do
worked on reliability and
is marked as unreachable
but cannot do so
on reliability and scalability
cannot do so because
reliability and scalability issues
do so because of
and scalability issues in
so because of factors
scalability issues in distributed
because of factors such
some systems inject additional
of factors such as
issues in distributed systems
systems inject additional packets
factors such as their
would change to take
such as their physical
inject additional packets into
as their physical positioning
change to take into
additional packets into the
their physical positioning in
in distributed systems since
physical positioning in the
packets into the data
to take into account
distributed systems since starting
take into account a
systems since starting his
into account a pool
since starting his research
account a pool fee
into the data stream
positioning in the system
starting his research career
a pool fee of
the data stream to
pool fee of f
fee of f pp
data stream to ensure
of f pp ri
stream to ensure timely
he is the author
to ensure timely detection
in all our future
is the author of
all our future experiments
the author of many
ensure timely detection of
author of many articles
our future experiments we
of many articles on
timely detection of failures
many articles on the
future experiments we set
articles on the subject
experiments we set the
detection of failures at
we set the maximum
of failures at moments
set the maximum upload
failures at moments when
the maximum upload factor
at moments when the
maximum upload factor to
moments when the traffic
when the traffic is
the traffic is low
traffic is low or
is low or unidirectional
and applications will be
applications will be published
will be published by
be published by springer
published by springer verlag
by springer verlag in
springer verlag in fall
effect of opportunistic behavior
of opportunistic behavior our
opportunistic behavior our next
behavior our next goal
our next goal was
next goal was to
goal was to understand
expect the application to
was to understand the
the application to handle
to understand the expected
application to handle the
understand the expected behavior
to handle the failure
the expected behavior of
handle the failure management
expected behavior of correct
the failure management as
behavior of correct nodes
failure management as the
of correct nodes under
management as the support
correct nodes under different
as the support system
nodes under different scenarios
the support system does
under different scenarios where
support system does not
different scenarios where opportunistic
system does not contain
scenarios where opportunistic nodes
does not contain any
where opportunistic nodes compromise
not contain any fault
opportunistic nodes compromise the
contain any fault management
nodes compromise the system
web services are not
services are not distributed
are not distributed objects
often these systems cannot
we therefore studied how
these systems cannot distinguish
therefore studied how the
systems cannot distinguish between
studied how the download
cannot distinguish between process
how the download and
the download and contribution
download and contribution rates
and contribution rates of
node or network failure
contribution rates of correct
rates of correct nodes
of correct nodes are
correct nodes are affected
nodes are affected under
the mechanisms used to
are affected under these
mechanisms used to detect
affected under these conditions
used to detect failure
to detect failure do
detect failure do not
failure do not adapt
do not adapt to
not adapt to changing
opportunistic nodes may contribute
adapt to changing network
nodes may contribute with
to changing network conditions
may contribute with some
contribute with some data
a pool with a
with some data in
pool with a fee
some data in an
with a fee of
data in an attempt
a fee of f
making it almost impossible
fee of f is
in an attempt to
of f is a
an attempt to disguise
f is a less
attempt to disguise their
is a less attractive
to disguise their opportunistic
a less attractive target
disguise their opportunistic behavior
less attractive target for
it almost impossible to
attractive target for block
target for block withholding
almost impossible to use
impossible to use these
to use these systems
since the attacker s
use these systems unmodified
we considered different rates
the attacker s revenue
these systems unmodified in
considered different rates of
attacker s revenue is
systems unmodified in wide
s revenue is reduced
different rates of contribution
unmodified in wide area
revenue is reduced by
rates of contribution for
is reduced by f
in wide area systems
of contribution for opportunistic
contribution for opportunistic nodes
wide area systems without
area systems without resorting
however it is also
systems without resorting to
it is also less
without resorting to heavy
is also less attractive
resorting to heavy weight
also less attractive for
to heavy weight solutions
less attractive for miners
heavy weight solutions like
attractive for miners in
weight solutions like using
for miners in general
solutions like using a
like using a tcp
using a tcp connection
a tcp connection as
trading off the two
tcp connection as the
off the two for
connection as the preferred
the two for best
as the preferred transport
two for best protection
the preferred transport method
for best protection is
preferred transport method for
best protection is left
transport method for each
protection is left for
method for each rpc
is left for future
for each rpc call
left for future work
as part of the
part of the treatment
of the treatment of
the treatment of the
treatment of the miner
especially those designed to
those designed to support
designed to support high
r elated w ork
elated w ork a
management in a more
in a more integrated
a more integrated way
the block withholding attack
block withholding attack the
withholding attack the danger
attack the danger of
many of these systems
the danger of a
of these systems are
danger of a block
these systems are structured
of a block withholding
systems are structured as
a block withholding attack
are structured as groups
block withholding attack is
structured as groups of
withholding attack is as
as groups of cooperating
attack is as old
groups of cooperating processes
is as old as
of cooperating processes using
as old as bitcoin
cooperating processes using some
old as bitcoin pools
processes using some form
using some form of
some form of group
form of group membership
the attack was described
attack was described by
was described by rosenfeld
presents the average and
the average and minimum
average and minimum download
and minimum download factors
detection to be able
minimum download factors among
to be able to
download factors among all
be able to reach
factors among all correct
able to reach consensus
among all correct nodes
all correct nodes under
correct nodes under different
nodes under different configurations
various methods are used
the stream rate was
stream rate was fixed
of which fault monitors
rate was fixed at
as pools were becoming
pools were becoming a
were becoming a dominant
and all correct nodes
becoming a dominant player
all correct nodes had
a dominant player in
correct nodes had a
dominant player in the
nodes had a maximum
player in the bitcoin
had a maximum upload
in the bitcoin world
a maximum upload factor
maximum upload factor of
the paper described the
paper described the standard
described the standard attack
used by a miner
by a miner to
a miner to sabotage
miner to sabotage a
to sabotage a pool
sabotage a pool at
a pool at the
pool at the cost
at the cost of
the cost of reducing
cost of reducing its
of reducing its own
reducing its own revenue
are the most popular
a more general view
more general view of
general view of fairness
view of fairness in
of fairness in proof
however in each of
fairness in proof of
in each of these
we ran experiments with
in proof of work
each of these systems
proof of work schemes
of work schemes was
of these systems the
work schemes was discussed
schemes was discussed in
these systems the failure
systems the failure management
the failure management is
failure management is an
management is an integral
is an integral part
an integral part of
integral part of the
part of the particular
nodes and increasing percentages
of the particular membership
and increasing percentages of
the particular membership or
increasing percentages of opportunistic
particular membership or transport
percentages of opportunistic nodes
membership or transport system
of opportunistic nodes in
or transport system and
opportunistic nodes in the
transport system and not
nodes in the system
system and not available
and not available for
not available for general
available for general use
although some research groups
in the context of
the context of the
context of the hashcash
of the hashcash system
optimizing power consumption in
power consumption in large
consumption in large scale
in large scale storage
large scale storage systems
scale storage systems lakshmi
storage systems lakshmi ganesh
early work did not
work did not address
we vary the percentage
did not address the
vary the percentage of
not address the possibility
ken birman computer science
address the possibility of
birman computer science department
the percentage of opportunistic
the possibility of pools
percentage of opportunistic nodes
possibility of pools infiltrating
are focusing on wide
of pools infiltrating other
focusing on wide area
pools infiltrating other pools
on wide area systems
infiltrating other pools for
other pools for block
pools for block withholding
we can observe that
the majority of the
can observe that the
majority of the existing
observe that the download
of the existing failure
that the download factors
the existing failure detectors
the download factors of
existing failure detectors are
download factors of correct
failure detectors are not
factors of correct nodes
detectors are not suitable
of correct nodes decreases
are not suitable for
correct nodes decreases since
not suitable for use
nodes decreases since the
suitable for use in
decreases since the aggregated
for use in large
since the aggregated upload
use in large scale
the aggregated upload capacity
in large scale systems
aggregated upload capacity in
upload capacity in the
capacity in the system
in the system becomes
experimentally demonstrate that block
demonstrate that block withholding
because of their inflexibility
that block withholding can
of their inflexibility or
block withholding can increase
their inflexibility or the
withholding can increase the
inflexibility or the simplicity
can increase the attacker
or the simplicity of
increase the attacker s
the simplicity of their
the attacker s revenue
simplicity of their assumptions
edu abstract data centers
abstract data centers are
data centers are the
centers are the backend
they do not address
are the backend for
do not address the
the backend for a
not address the question
backend for a large
address the question of
for a large number
the question of mutual
a large number of
building a failure detector
large number of services
question of mutual attacks
number of services that
a failure detector that
of services that we
services that we take
failure detector that is
that we take for
avg download factor min
we take for granted
detector that is not
take for granted today
download factor min download
factor min download factor
that is not an
is not an integral
a significant fraction of
not an integral part
significant fraction of the
fraction of the total
an integral part of
of the total cost
the total cost of
integral part of the
total cost of ownership
cost of ownership of
part of the communication
of ownership of these
have recently noted that
ownership of these large
of the communication architecture
recently noted that a
noted that a pool
the communication architecture permits
that a pool can
communication architecture permits the
a pool can increase
scale storage systems is
pool can increase its
storage systems is the
architecture permits the implementation
systems is the cost
can increase its overall
is the cost of
permits the implementation of
the cost of keeping
increase its overall revenue
cost of keeping hundreds
the implementation of a
of keeping hundreds of
its overall revenue with
keeping hundreds of thousands
implementation of a collection
hundreds of thousands of
overall revenue with block
of thousands of disks
of a collection of
thousands of disks spinning
revenue with block withholding
a collection of failure
with block withholding if
block withholding if all
collection of failure detection
withholding if all other
if all other mining
we present a simple
of failure detection techniques
all other mining is
present a simple idea
failure detection techniques and
other mining is performed
a simple idea that
detection techniques and support
mining is performed by
simple idea that allows
techniques and support for
is performed by honest
idea that allows the
and support for failure
performed by honest pools
that allows the storage
support for failure detection
allows the storage system
for failure detection methods
the storage system to
failure detection methods of
storage system to turn
detection methods of varying
system to turn off
we consider the general
to turn off a
methods of varying levels
turn off a large
consider the general case
off a large fraction
of varying levels of
a large fraction of
the general case where
varying levels of complexity
large fraction of its
general case where not
fraction of its disks
levels of complexity from
case where not all
of complexity from which
where not all mining
complexity from which the
not all mining is
from which the system
all mining is performed
without incurring unacceptable performance
which the system designer
incurring unacceptable performance penalties
mining is performed through
the system designer can
is performed through public
system designer can choose
performed through public pools
designer can choose to
can choose to match
of particular appeal is
choose to match the
particular appeal is the
to match the system
appeal is the fact
match the system requirements
and analyze situations where
is the fact that
analyze situations where pools
the fact that our
situations where pools can
fact that our solution
where pools can attack
that our solution is
pools can attack one
our solution is not
can attack one another
solution is not application
the failure management service
failure management service consists
management service consists of
service consists of three
the discrepancy between the
consists of three functional
discrepancy between the calculations
of three functional modules
between the calculations of
savings for a very
for a very generic
a very generic data
very generic data center
generic data center model
and our results for
our results for the
we describe our solution
results for the special
for the special case
the special case analyzed
special case analyzed there
identify the parameters that
case analyzed there can
the parameters that determine
analyzed there can be
parameters that determine its
there can be explained
that determine its cost
can be explained by
a library that implements
be explained by the
library that implements simple
explained by the strong
that implements simple failure
by the strong approximations
implements simple failure management
the strong approximations in
simple failure management functionality
strong approximations in that
and present a simulator
failure management functionality and
approximations in that work
present a simulator that
management functionality and provide
a simulator that allows
functionality and provide the
simulator that allows us
and provide the api
that allows us to
provide the api to
allows us to explore
the api to the
us to explore this
api to the complete
to explore this parameter
to the complete service
explore this parameter space
we calculate exactly how
calculate exactly how infiltrating
exactly how infiltrating miners
a service implementing per
how infiltrating miners reduce
service implementing per node
we also present some
implementing per node failure
infiltrating miners reduce the
per node failure management
also present some initial
miners reduce the revenue
present some initial simulation
reduce the revenue density
some initial simulation results
the revenue density of
combining fault management with
initial simulation results that
revenue density of the
fault management with other
density of the infiltrated
simulation results that add
of the infiltrated pool
management with other local
results that add weight
with other local nodes
that add weight to
other local nodes to
add weight to our
local nodes to exploit
weight to our claim
nodes to exploit locality
to our claim that
to exploit locality of
our claim that our
exploit locality of communication
claim that our solution
locality of communication and
temporary block withholding in
that our solution represents
of communication and failure
block withholding in the
communication and failure patterns
our solution represents a
withholding in the block
solution represents a new
in the block withholding
represents a new powersaving
the block withholding attack
a new powersaving opportunity
an inquiry service closely
new powersaving opportunity for
block withholding attack discussed
powersaving opportunity for large
inquiry service closely coupled
withholding attack discussed in
service closely coupled with
attack discussed in this
closely coupled with the
discussed in this work
coupled with the operating
in this work the
with the operating system
this work the withheld
the operating system which
work the withheld blocks
the withheld blocks are
withheld blocks are never
blocks are never published
introduction the declining costs
the declining costs of
provides information about the
declining costs of commodity
information about the state
costs of commodity disk
about the state of
of commodity disk drives
blocks can be withheld
commodity disk drives has
can be withheld temporarily
the state of local
disk drives has made
state of local participating
drives has made online
of local participating processes
not following the bitcoin
has made online data
following the bitcoin protocol
made online data storage
online data storage a
data storage a way
storage a way of
a way of life
to improve an attacker
improve an attacker s
an attacker s revenue
the most fundamental operation
most fundamental operation offered
so much so that
fundamental operation offered by
much so that companies
a miner or a
so that companies like
operation offered by a
miner or a pool
that companies like google
or a pool can
offered by a failure
a pool can perform
companies like google and
pool can perform a
by a failure detection
can perform a selfish
like google and yahoo
perform a selfish mining
a failure detection service
a selfish mining attack
google and yahoo host
failure detection service is
and yahoo host hundreds
detection service is that
yahoo host hundreds of
service is that of
host hundreds of thousands
is that of the
hundreds of thousands of
that of the investigation
of thousands of servers
of the investigation of
thousands of servers for
the investigation of a
of servers for storage
investigation of a suspected
of a suspected process
to make use of
make use of this
there is a catch
use of this operation
with selfish mining the
of this operation it
selfish mining the attacker
this operation it is
a hundred thousand servers
operation it is not
mining the attacker increases
it is not necessary
hundred thousand servers consume
the attacker increases its
is not necessary for
thousand servers consume a
attacker increases its revenue
not necessary for either
servers consume a lot
increases its revenue by
necessary for either the
consume a lot of
its revenue by temporarily
a lot of power
for either the local
revenue by temporarily withholding
either the local or
by temporarily withholding its
the local or remote
temporarily withholding its blocks
local or remote process
not only does this
or remote process to
withholding its blocks and
only does this translate
remote process to run
its blocks and publishing
process to run any
does this translate to
to run any of
blocks and publishing them
run any of the
this translate to many
and publishing them in
any of the heartbeat
translate to many millions
of the heartbeat or
publishing them in response
the heartbeat or polling
them in response to
heartbeat or polling patterns
to many millions of
in response to block
many millions of dollars
response to block publication
millions of dollars annually
to block publication by
of dollars annually on
block publication by other
dollars annually on electricity
publication by other pools
annually on electricity bills
by other pools and
the reasons that the
other pools and miners
reasons that the local
that the local process
the local process began
the heat produced by
local process began to
heat produced by so
this attack is independent
produced by so much
process began to suspect
attack is independent of
by so much computing
began to suspect the
so much computing power
is independent of the
much computing power can
to suspect the remote
computing power can be
independent of the block
power can be searing
suspect the remote process
of the block withholding
the remote process are
the block withholding attack
remote process are not
block withholding attack we
process are not of
withholding attack we discuss
are not of any
an article in the
not of any importance
attack we discuss here
of any importance to
article in the new
any importance to the
we discuss here and
importance to the failure
in the new york
to the failure management
discuss here and the
the new york times
here and the two
new york times describes
and the two can
york times describes one
the two can be
times describes one of
two can be performed
describes one of google
can be performed in
one of google s
be performed in concert
of google s data
google s data centers
an attacker can also
attacker can also perform
can also perform a
also perform a double
perform a double spending
a double spending attack
double spending attack as
spending attack as follows
a computing center as
computing center as big
center as big as
as big as two
big as two football
as two football fields
of opportunistic nodes figure
with twin cooling plants
twin cooling plants protruding
cooling plants protruding four
plants protruding four stories
the process at address
protruding four stories into
process at address is
four stories into the
at address is investigated
minimum and average download
stories into the sky
address is investigated and
he intentionally generates two
and average download factors
intentionally generates two conflicting
is investigated and a
average download factors across
generates two conflicting transactions
investigated and a report
download factors across all
and a report is
factors across all correct
a report is returned
across all correct nodes
report is returned within
places one in a
all correct nodes when
one in a block
is returned within the
in a block it
correct nodes when opportunistic
a block it withholds
returned within the deadline
nodes when opportunistic nodes
within the deadline set
when opportunistic nodes are
the deadline set by
opportunistic nodes are present
deadline set by the
and publishes the other
set by the local
publishes the other transaction
by the local process
power conservation is an
conservation is an important
each curve corresponds to
is an important concern
curve corresponds to a
an important concern for
after the recipient sees
the local process does
important concern for big
corresponds to a different
local process does not
concern for big server
the recipient sees the
to a different contribution
process does not have
a different contribution rate
recipient sees the published
different contribution rate used
sees the published transaction
for big server clusters
does not have to
contribution rate used by
not have to wait
rate used by opportunistic
have to wait for
used by opportunistic nodes
since disks account for
the attacker publishes the
disks account for a
to wait for the
account for a significant
attacker publishes the withheld
wait for the investigation
for a significant fraction
publishes the withheld block
a significant fraction of
for the investigation to
significant fraction of the
the withheld block to
fraction of the energy
withheld block to revoke
of the energy consumed
the investigation to finish
block to revoke the
investigation to finish but
to revoke the former
to finish but can
revoke the former transaction
finish but can make
but can make use
can make use of
make use of the
use of the asynch
this attack is performed
of the asynch interface
attack is performed by
the asynch interface to
is performed by miners
asynch interface to collect
performed by miners or
interface to collect the
by miners or pools
to collect the result
miners or pools against
collect the result at
or pools against service
the result at a
several approaches for disk
pools against service providers
approaches for disk power
against service providers that
for disk power management
service providers that accept
result at a later
providers that accept bitcoin
at a later moment
disk power management have
power management have been
management have been proposed
have been proposed and
been proposed and studied
and it not directly
it not directly related
not directly related to
the report contains information
directly related to this
related to this work
report contains information on
we will examine some
will examine some of
contains information on whether
examine some of these
some of these here
information on whether the
on whether the remote
whether the remote node
block withholding defense most
the remote node was
withholding defense most crypto
but first let us
remote node was reachable
first let us lay
node was reachable within
let us lay out
was reachable within the
currencies use a proof
us lay out some
reachable within the deadline
lay out some of
within the deadline and
out some of the
the deadline and whether
some of the groundwork
deadline and whether the
and whether the process
whether the process under
the process under investigation
work architecture similar to
process under investigation was
architecture similar to bitcoin
any disk power management
under investigation was still
disk power management scheme
investigation was still present
power management scheme essentially
was still present at
management scheme essentially attempts
where finding proof of
still present at the
finding proof of work
present at the host
scheme essentially attempts to
proof of work is
essentially attempts to exploit
of work is the
attempts to exploit one
work is the result
to exploit one fact
is the result of
if the mode parameter
the result of solution
the mode parameter was
result of solution guessing
mode parameter was used
of solution guessing and
parameter was used to
solution guessing and checking
avg upload factor min
was used to request
upload factor min upload
disks can be run
factor min upload factor
used to request a
can be run in
to request a more
be run in highpower
request a more detailed
run in highpower mode
a more detailed remote
all of the algorithms
more detailed remote reporting
of the algorithms we
the algorithms we are
algorithms we are aware
we are aware of
are aware of are
process checkpoint information is
aware of are susceptible
checkpoint information is returned
of are susceptible to
information is returned or
are susceptible to the
is returned or the
susceptible to the block
returned or the remote
with a corresponding performance
or the remote process
a corresponding performance tradeoff
to the block withholding
the remote process is
the block withholding attack
remote process is interrupted
process is interrupted to
is interrupted to provide
interrupted to provide status
to provide status information
as in all of
in all of them
a disk can be
all of them the
disk can be shut
see the section on
can be shut off
of them the miner
be shut off so
the section on os
shut off so that
section on os integration
off so that it
them the miner can
so that it consumes
the miner can check
that it consumes no
miner can check whether
it consumes no power
can check whether she
check whether she found
whether she found a
she found a full
if the node was
given a large cluster
found a full or
a large cluster of
the node was not
large cluster of disks
a full or a
node was not reachable
full or a partial
was not reachable and
or a partial proof
not reachable and the
a partial proof of
reachable and the local
partial proof of work
only a fraction of
and the local process
a fraction of them
the local process has
fraction of them is
local process has requested
of them is accessed
process has requested extensive
prominent examples are litecoin
them is accessed at
has requested extensive investigation
is accessed at any
accessed at any time
the failure investigator will
so that the rest
failure investigator will try
that the rest could
investigator will try to
the rest could potentially
will try to contact
rest could potentially be
try to contact a
could potentially be switched
to contact a failure
potentially be switched to
contact a failure manager
be switched to a
a failure manager at
switched to a low
failure manager at the
manager at the node
net or within its
since mode transitions consume
or within its administrative
mode transitions consume time
within its administrative domain
its administrative domain which
administrative domain which should
domain which should be
which should be able
should be able to
be able to give
able to give a
to give a more
give a more conclusive
a more conclusive answer
more conclusive answer about
conclusive answer about the
answer about the node
it is possible to
is possible to use
possible to use an
to use an alternative
s failure to respond
use an alternative proof
transitions consume time and
an alternative proof of
consume time and power
alternative proof of work
if network failure is
proof of work mechanism
network failure is the
of work mechanism in
failure is the cause
work mechanism in which
disk management schemes have
is the cause of
mechanism in which miners
the cause of the
management schemes have to
cause of the loss
in which miners would
of the loss of
schemes have to walk
which miners would not
the loss of connectivity
miners would not be
have to walk the
would not be able
to walk the tightrope
not be able to
walk the tightrope of
be able to distinguish
the report will indicate
able to distinguish partial
the tightrope of finding
report will indicate which
to distinguish partial from
tightrope of finding the
distinguish partial from full
will indicate which part
partial from full proofs
of finding the right
from full proofs of
indicate which part of
full proofs of work
finding the right balance
which part of the
the right balance between
part of the path
right balance between power
of the path is
balance between power consumption
the path is reachable
between power consumption and
path is reachable and
power consumption and performance
is reachable and where
reachable and where the
and where the suspected
the solution space explored
solution space explored thus
space explored thus far
explored thus far in
thus far in the
far in the literature
in the literature can
the literature can be
literature can be divided
can be divided as
be divided as follows
if the failure investigator
the failure investigator is
failure investigator is configured
investigator is configured with
is configured with alternative
configured with alternative outgoing
with alternative outgoing paths
these paths are probed
paths are probed to
are probed to see
probed to see if
to see if it
see if it is
if it is possible
it is possible to
is possible to circumvent
possible to circumvent the
to circumvent the network
circumvent the network failure
the network failure and
network failure and in
failure and in such
and in such a
in such a way
such a way collect
a way collect information
way collect information about
collect information about the
information about the remote
about the remote process
such a solution could
a solution could reduce
solution could reduce or
could reduce or remove
reduce or remove the
or remove the danger
the report contains information
remove the danger of
report contains information about
the danger of block
contains information about the
danger of block withholding
information about the results
about the results of
the results of these
results of these probes
each of these solutions
of these solutions proposes
these solutions proposes a
solutions proposes a new
early triggers many systems
making such a change
proposes a new system
triggers many systems find
a new system of
such a change may
new system of some
many systems find it
system of some kind
a change may not
systems find it desirable
change may not be
find it desirable to
may not be in
it desirable to detect
not be in the
desirable to detect failure
be in the interest
to detect failure of
in the interest of
detect failure of remote
the interest of the
based solutions propose novel
interest of the community
failure of remote processes
solutions propose novel storage
of remote processes even
propose novel storage hierarchies
remote processes even if
novel storage hierarchies to
processes even if there
storage hierarchies to strike
even if there is
hierarchies to strike the
if there is no
to strike the right
there is no data
strike the right balance
or even its potential
the right balance between
is no data exchange
right balance between performance
no data exchange actually
balance between performance and
data exchange actually under
between performance and power
exchange actually under way
performance and power consumption
could lead to a
lead to a reduction
to a reduction of
a reduction of pool
reduction of pool sizes
systems are free to
disk management solutions interject
are free to implement
management solutions interject a
as explained in section
free to implement whatever
solutions interject a new
explained in section ix
interject a new disk
to implement whatever scheme
a new disk management
implement whatever scheme they
new disk management layer
whatever scheme they find
disk management layer on
scheme they find appropriate
management layer on top
they find appropriate and
layer on top of
find appropriate and use
on top of the
appropriate and use the
top of the file
and use the failure
of the file system
use the failure investigator
decentralized pools although most
the failure investigator from
pools although most pools
failure investigator from the
although most pools use
investigator from the previous
most pools use a
which controls disk configuration
pools use a centralized
from the previous section
use a centralized manager
controls disk configuration and
the previous section to
disk configuration and data
previous section to handle
configuration and data layout
section to handle the
and data layout to
to handle the suspicions
data layout to achieve
a prominent exception is
layout to achieve power
prominent exception is p
or they can make
optimal disk access patterns
pool a distributed pool
they can make use
of opportunistic nodes figure
can make use of
a distributed pool architecture
make use of two
distributed pool architecture with
use of two standardized
caching solutions devise new
of two standardized schemes
solutions devise new power
pool architecture with no
two standardized schemes implemented
architecture with no central
standardized schemes implemented by
with no central manager
schemes implemented by the
minimum and average upload
implemented by the failure
aware caching algorithms that
and average upload factors
by the failure manager
caching algorithms that allow
the failure manager library
average upload factors across
algorithms that allow large
upload factors across all
that allow large fractions
factors across all correct
allow large fractions of
across all correct nodes
the first scheme uses
all correct nodes when
first scheme uses a
large fractions of the
scheme uses a heartbeat
correct nodes when opportunistic
uses a heartbeat mechanism
fractions of the storage
nodes when opportunistic nodes
of the storage system
when opportunistic nodes are
the storage system to
opportunistic nodes are present
storage system to remain
which sends out i
system to remain idle
but the question of
to remain idle for
remain idle for longer
the question of whether
idle for longer periods
each curve corresponds to
question of whether a
for longer periods of
curve corresponds to a
longer periods of time
of whether a pool
corresponds to a different
alive messages to a
whether a pool is
messages to a group
to a different contribution
a pool is run
to a group of
a different contribution rate
a group of processes
pool is run by
group of processes using
different contribution rate used
is run by a
of processes using multiple
allowing them to be
processes using multiple point
run by a centralized
contribution rate used by
them to be switched
rate used by opportunistic
to be switched to
by a centralized manager
used by opportunistic nodes
a centralized manager or
be switched to lower
centralized manager or with
point messages or a
switched to lower power
messages or a single
to lower power modes
or a single ip
insufficient to provide all
manager or with a
to provide all nodes
or with a decentralized
provide all nodes with
with a decentralized architecture
all nodes with all
the principal contribution of
nodes with all data
a decentralized architecture is
principal contribution of this
decentralized architecture is almost
contribution of this paper
architecture is almost immaterial
of this paper is
each process keeps track
is almost immaterial for
this paper is to
almost immaterial for the
process keeps track of
immaterial for the attack
paper is to argue
for the attack we
keeps track of the
the attack we describe
is to argue that
track of the reception
to argue that there
the extent of the
argue that there is
of the reception times
that there is a
extent of the impact
there is a fourth
of the impact may
the reception times of
the impact may be
is a fourth niche
reception times of messages
a fourth niche as
pool group can be
fourth niche as yet
impact may be surprising
niche as yet unexplored
group can be infiltrated
times of messages and
can be infiltrated and
of messages and if
be infiltrated and attacked
messages and if a
and if a number
if a number of
a number of consecutive
number of consecutive heartbeats
of consecutive heartbeats from
consecutive heartbeats from a
heartbeats from a destination
pool code can be
from a destination is
code can be changed
a destination is missed
can be changed to
destination is missed a
be changed to support
is missed a suspicion
changed to support attacks
missed a suspicion is
to support attacks against
a suspicion is raised
support attacks against other
we do not present
performance drops by as
do not present a
drops by as much
not present a new
by as much as
present a new system
attacks against other pools
on the other hand
we take an idea
fixed period or an
take an idea that
period or an exponential
an idea that has
or an exponential back
idea that has been
pool can be used
that has been around
can be used by
has been around for
be used by groups
been around for well
used by groups of
around for well over
by groups of miners
for well over a
presents the average and
well over a decade
groups of miners to
over a decade now
the average and minimum
of miners to easily
average and minimum upload
miners to easily form
and minimum upload factors
to easily form closed
minimum upload factors among
easily form closed pools
fixed or estimated by
upload factors among all
or estimated by the
factors among all correct
estimated by the system
among all correct nodes
these do not accept
do not accept untrusted
not accept untrusted miners
and multiple suspicion levels
and are therefore protected
multiple suspicion levels are
are therefore protected against
suspicion levels are configurable
therefore protected against block
levels are configurable by
protected against block withholding
are configurable by the
axis we vary the
configurable by the application
we vary the percentage
vary the percentage of
the percentage of opportunistic
percentage of opportunistic nodes
the application can provide
application can provide application
and on the y
c onclusion we explored
and argue that technological
can provide application specific
onclusion we explored a
argue that technological evolution
provide application specific data
we explored a block
that technological evolution has
axis we present the
explored a block withholding
technological evolution has given
we present the upload
application specific data to
a block withholding attack
specific data to be
present the upload factors
data to be piggybacked
block withholding attack among
to be piggybacked on
the upload factors of
be piggybacked on the
withholding attack among bitcoin
piggybacked on the heartbeats
upload factors of nodes
attack among bitcoin mining
evolution has given it
among bitcoin mining pools
has given it a
bitcoin mining pools an
given it a new
the second scheme uses
mining pools an attack
which can vary up
it a new relevance
can vary up to
pools an attack that
second scheme uses a
a new relevance today
an attack that is
scheme uses a polling
new relevance today as
attack that is possible
relevance today as a
uses a polling method
today as a natural
that is possible in
as a natural power
a polling method to
is possible in any
polling method to collect
possible in any similar
method to collect acknowledgments
in any similar system
to collect acknowledgments from
any similar system that
saving opportunity for large
similar system that rewards
collect acknowledgments from the
system that rewards for
acknowledgments from the peer
that rewards for proof
from the peer processes
it is interesting to
rewards for proof of
is interesting to note
for proof of work
interesting to note that
to note that the
if no acknowledgments are
the key insight is
note that the average
key insight is that
no acknowledgments are received
that the average upload
such systems are gaining
the average upload factor
systems are gaining popularity
acknowledgments are received after
average upload factor among
where other solutions attempt
upload factor among correct
are received after a
factor among correct nodes
running most digital currencies
among correct nodes initially
received after a number
correct nodes initially increases
most digital currencies and
other solutions attempt to
digital currencies and related
after a number of
currencies and related services
solutions attempt to predict
a number of retries
attempt to predict disk
number of retries a
and then starts falling
to predict disk access
then starts falling when
predict disk access to
starts falling when the
disk access to determine
falling when the percentage
access to determine which
when the percentage of
to determine which disks
of retries a suspicion
determine which disks to
we observe that no
which disks to power
retries a suspicion is
the percentage of opportunistic
a suspicion is raised
disks to power down
percentage of opportunistic nodes
of opportunistic nodes increases
opportunistic nodes increases significantly
attacks is not a
the lfs automatically provides
is not a nash
lfs automatically provides a
this behavior can be
not a nash equilibrium
behavior can be explained
automatically provides a perfect
can be explained by
provides a perfect prediction
be explained by the
a perfect prediction mechanism
explained by the fact
by the fact that
if none of the
none of the other
of the other pools
and retransmission limits are
the other pools attack
simply by virtue of
retransmission limits are configurable
by virtue of the
limits are configurable by
virtue of the fact
are configurable by the
of the fact that
correct nodes start contributing
the fact that all
a pool can increase
fact that all write
nodes start contributing more
configurable by the application
pool can increase its
by the application or
can increase its revenue
start contributing more to
increase its revenue by
accesses go to the
contributing more to compensate
go to the log
the application or can
its revenue by attacking
application or can be
revenue by attacking the
or can be adapted
by attacking the others
can be adapted by
to the log head
be adapted by the
more to compensate for
adapted by the failure
to compensate for the
when two pools can
by the failure manager
two pools can attack
compensate for the lack
the failure manager to
pools can attack each
failure manager to the
for the lack of
can attack each other
the lack of data
explains and expands on
lack of data provided
and expands on this
manager to the network
expands on this idea
of data provided by
they face a version
data provided by a
face a version of
provided by a small
a version of the
by a small percentage
version of the prisoner
instrumenting the operating system
of the prisoner s
a small percentage of
the prisoner s dilemma
small percentage of opportunistic
percentage of opportunistic nodes
to achieve greater failure
achieve greater failure detection
if one pool chooses
greater failure detection accuracy
one pool chooses to
pool chooses to attack
idea overview to see
once the effect of
overview to see why
the victim s revenue
the effect of opportunistic
it is necessary to
victim s revenue is
effect of opportunistic nodes
s revenue is reduced
is necessary to instrument
to see why lfs
of opportunistic nodes becomes
see why lfs is
necessary to instrument the
why lfs is a
and it can retaliate
lfs is a natural
it can retaliate by
is a natural solution
can retaliate by attacking
a natural solution to
to instrument the operating
natural solution to the
retaliate by attacking and
solution to the problem
instrument the operating environment
to the problem of
by attacking and increase
the problem of disk
the operating environment with
problem of disk power
attacking and increase its
of disk power management
operating environment with support
opportunistic nodes becomes significant
environment with support for
and increase its revenue
with support for process
support for process investigation
consider some of the
some of the challenges
the system collapses and
of the challenges involved
system collapses and correct
it has always been
collapses and correct nodes
has always been argued
and correct nodes are
always been argued that
correct nodes are not
been argued that in
nodes are not able
server systems typically are
are not able to
argued that in a
not able to keep
systems typically are not
able to keep contributing
that in a distributed
at nash equilibrium both
typically are not idle
nash equilibrium both earn
are not idle long
equilibrium both earn less
not idle long enough
both earn less than
another important point to
earn less than they
idle long enough to
important point to note
less than they would
point to note is
than they would have
in a distributed system
they would have if
to note is that
would have if neither
a distributed system it
have if neither attacked
note is that the
long enough to make
is that the minimum
enough to make it
distributed system it is
to make it worthwhile
that the minimum upload
make it worthwhile to
with multiple pools of
it worthwhile to incur
the minimum upload factor
worthwhile to incur the
multiple pools of equal
to incur the time
minimum upload factor does
system it is impossible
upload factor does not
pools of equal size
factor does not follow
it is impossible to
does not follow a
power expense of switching
is impossible to distinguish
not follow a clearly
impossible to distinguish a
follow a clearly defined
to distinguish a crashed
a clearly defined pattern
of equal size a
expense of switching the
equal size a similar
distinguish a crashed process
size a similar situation
a crashed process from
a similar situation arises
crashed process from one
of switching the disk
process from one that
making it hard to
similar situation arises with
switching the disk to
situation arises with a
the disk to a
arises with a symmetric
disk to a lowpower
from one that is
to a lowpower mode
with a symmetric equilibrium
it hard to estimate
one that is slow
hard to estimate the
to estimate the minimum
and switching it back
estimate the minimum contribution
switching it back when
the fact that block
it back when it
the minimum contribution of
fact that block withholding
back when it is
minimum contribution of correct
that block withholding is
when it is accessed
contribution of correct nodes
block withholding is not
of correct nodes under
withholding is not common
correct nodes under compromised
is not common may
this is a notable
not common may be
is a notable point
but with the proper
nodes under compromised scenarios
with the proper system
a notable point of
the proper system support
common may be explained
proper system support this
notable point of difference
system support this is
may be explained by
support this is no
point of difference between
be explained by modeling
this is no longer
explained by modeling the
is no longer true
of difference between server
by modeling the attack
difference between server systems
modeling the attack decisions
between server systems and
the attack decisions as
server systems and typical
by applying thresholds to
systems and typical mobile
attack decisions as an
and typical mobile device
decisions as an iterative
typical mobile device scenarios
applying thresholds to punish
if the node is
thresholds to punish opportunistic
the node is reachable
to punish opportunistic nodes
node is reachable and
as an iterative prisoner
is reachable and operating
an iterative prisoner s
reachable and operating correctly
iterative prisoner s dilemma
correct nodes may also
nodes may also be
may also be unfairly
the operating system can
also be unfairly penalized
operating system can determine
system can determine whether
which makes it hard
can determine whether or
makes it hard to
determine whether or not
it hard to translate
whether or not the
we argue that the
or not the process
hard to translate the
not the process has
argue that the situation
the process has crashed
to translate the solutions
that the situation is
translate the solutions devised
the situation is unstable
the solutions devised for
situation is unstable since
solutions devised for mobile
is unstable since the
auditing protocol our idea
devised for mobile devices
protocol our idea for
for mobile devices to
our idea for auditing
mobile devices to server
idea for auditing the
devices to server systems
for auditing the described
unstable since the attack
the failure management integrated
since the attack can
auditing the described live
failure management integrated into
the attack can be
as we shall see
attack can be done
management integrated into the
can be done anonymously
integrated into the os
streaming system against opportunistic
into the os offers
system against opportunistic behavior
the os offers processes
against opportunistic behavior is
os offers processes a
opportunistic behavior is motivated
access to a small
behavior is motivated by
to a small subset
one pool may decide
a small subset of
offers processes a mechanism
is motivated by the
processes a mechanism to
motivated by the graphs
pool may decide to
by the graphs presented
a mechanism to register
the graphs presented in
may decide to increase
graphs presented in the
mechanism to register and
presented in the previous
decide to increase its
in the previous section
to register and request
small subset of disks
register and request a
to increase its revenue
and request a certain
increase its revenue and
request a certain level
we propose to employ
its revenue and drag
propose to employ auditing
revenue and drag the
a certain level of
when combined with a
certain level of service
combined with a cache
and drag the others
with a cache that
drag the others to
a cache that absorbs
to employ auditing to
cache that absorbs read
the others to attack
employ auditing to ensure
others to attack as
auditing to ensure that
to attack as well
to ensure that all
ensure that all nodes
that all nodes in
all nodes in the
nodes in the system
results in long disk
ending with a reduced
in long disk idle
is a simple binary
long disk idle periods
with a reduced revenue
in the system contribute
a reduced revenue for
a simple binary test
reduced revenue for all
the system contribute more
simple binary test performed
system contribute more than
binary test performed by
low predictability of idle
test performed by the
predictability of idle periods
performed by the os
contribute more than a
by the os upon
the inferior revenue would
the os upon receipt
more than a particular
os upon receipt of
than a particular specified
upon receipt of an
a particular specified threshold
receipt of an inquiry
inferior revenue would push
revenue would push miners
would push miners to
push miners to join
miners to join private
to join private pools
indicating whether the process
whether the process is
the process is still
have shown that there
which can verify that
process is still present
can verify that their
shown that there exists
verify that their registered
is still present in
that their registered miners
that there exists low
their registered miners do
still present in the
registered miners do not
there exists low correlation
miners do not withhold
present in the process
exists low correlation between
we illustrate the potential
in the process table
low correlation between a
illustrate the potential benefit
the process table and
do not withhold blocks
process table and thus
the potential benefit from
table and thus not
correlation between a given
and thus not has
potential benefit from using
between a given idle
this would lead to
benefit from using auditing
thus not has crashed
from using auditing in
not has crashed or
using auditing in a
has crashed or voluntary
auditing in a system
crashed or voluntary exited
in a system where
would lead to smaller
a given idle period
lead to smaller pools
given idle period s
idle period s duration
period s duration and
the two other levels
s duration and the
two other levels that
duration and the duration
other levels that are
and the duration of
levels that are currently
and so ultimately to
that are currently implemented
the duration of previous
so ultimately to a
of the nodes are
duration of previous idle
the nodes are correct
ultimately to a better
nodes are correct and
to a better environment
of previous idle periods
a better environment for
provide a remote process
better environment for bitcoin
environment for bitcoin as
a remote process with
for bitcoin as a
bitcoin as a whole
remote process with information
this variability makes it
process with information about
variability makes it difficult
with information about the
makes it difficult to
information about the progress
it difficult to devise
about the progress the
difficult to devise effective
for their valuable advice
the latter do not
to devise effective predictive
latter do not upload
the progress the local
do not upload any
devise effective predictive mechanisms
progress the local process
effective predictive mechanisms for
not upload any data
predictive mechanisms for disk
the local process is
mechanisms for disk idle
the author is grateful
for disk idle times
local process is making
author is grateful to
process is making which
is grateful to ken
is making which is
grateful to ken birman
making which is useful
the lfs neatly circumvents
which is useful in
lfs neatly circumvents this
is useful in the
neatly circumvents this problem
useful in the investigation
circumvents this problem by
in the investigation of
this problem by predetermining
the investigation of processes
problem by predetermining which
investigation of processes that
by predetermining which disk
of processes that are
predetermining which disk is
processes that are alive
emin gu n sirer
which disk is written
no punishment was applied
disk is written to
punishment was applied in
is written to at
was applied in an
written to at all
applied in an attempt
but that appear slow
to at all times
that appear slow or
in an attempt to
appear slow or unresponsive
and the paper shepherd
an attempt to simulate
the paper shepherd joseph
attempt to simulate a
paper shepherd joseph bonneau
to simulate a system
simulate a system with
a system with no
system with no auditing
server systems are often
at certain intervals the
systems are often constrained
certain intervals the process
are often constrained by
intervals the process logs
often constrained by service
the process logs checkpoint
constrained by service level
process logs checkpoint timestamps
by service level agreements
logs checkpoint timestamps with
service level agreements to
checkpoint timestamps with the
level agreements to guarantee
timestamps with the failure
agreements to guarantee a
with the failure service
to guarantee a certain
guarantee a certain level
a certain level of
certain level of performance
which simultaneously logs the
simultaneously logs the process
so that finding a
auditing is enabled and
that finding a solution
is enabled and opportunistic
finding a solution that
enabled and opportunistic nodes
a solution that provides
and opportunistic nodes start
solution that provides acceptable
the response to an
opportunistic nodes start to
that provides acceptable performance
peer electronic cash system
response to an inquiry
nodes start to be
to an inquiry request
provides acceptable performance to
an inquiry request holds
start to be expelled
inquiry request holds the
acceptable performance to only
to be expelled from
performance to only a
request holds the last
to only a fraction
holds the last checkpoint
only a fraction of
be expelled from the
a fraction of the
the last checkpoint timestamp
fraction of the incoming
expelled from the system
of the incoming requests
from the system for
the system for low
system for low contribution
the current local time
albeit a large fraction
whether the process has
the process has been
may often not be
process has been allocated
often not be sufficient
has been allocated cpu
the minimum upload factor
been allocated cpu time
minimum upload factor for
allocated cpu time since
upload factor for nodes
cpu time since the
as we shall show
time since the last
factor for nodes to
since the last checkpoint
for nodes to stay
nodes to stay in
to stay in the
stay in the system
the lfs provides an
in the system was
and whether the process
lfs provides an applicationindependent
the system was set
whether the process has
system was set to
provides an applicationindependent solution
the process has consumed
an applicationindependent solution that
process has consumed any
applicationindependent solution that allows
has consumed any messages
solution that allows the
consumed any messages since
ebay s paypal unit
that allows the system
any messages since the
s paypal unit to
messages since the last
allows the system to
since the last checkpoint
paypal unit to start
the system to perform
unit to start accepting
system to perform consistently
to start accepting bitcoin
to perform consistently across
start accepting bitcoin payments
perform consistently across a
consistently across a wide
across a wide range
a wide range of
wide range of datasets
upon receipt of an
receipt of an inquiry
of an inquiry the
an inquiry the operating
inquiry the operating system
the law of large
the operating system uses
law of large numbers
operating system uses an
system uses an upcall
large scale server systems
scale server systems process
server systems process incredibly
systems process incredibly large
to interrupt the process
process incredibly large request
interrupt the process and
incredibly large request loads
the process and requests
process and requests that
and requests that the
requests that the process
that the process prepares
directing these to a
the process prepares a
these to a small
process prepares a special
to a small fraction
prepares a special response
a small fraction of
small fraction of the
fraction of the total
of the total number
the total number of
total number of disks
this response is returned
response is returned to
is returned to the
returned to the caller
the fraction that is
fraction that is in
that is in high
google adds bitcoin currency
adds bitcoin currency conversion
the previous sections all
bitcoin currency conversion to
without auditing with auditing
currency conversion to search
previous sections all deal
sections all deal with
can significantly raise the
all deal with provisions
significantly raise the probability
deal with provisions targeted
raise the probability of
with provisions targeted towards
the probability of error
provisions targeted towards the
probability of error and
targeted towards the failure
of error and failure
towards the failure management
the failure management of
failure management of processes
the fact that the
fact that the disks
that the disks used
exploiting the close coupled
the disks used in
the close coupled nature
disks used in these
close coupled nature of
used in these contexts
coupled nature of a
in these contexts are
nature of a process
these contexts are typically
of a process and
contexts are typically low
a process and the
process and the operating
and the operating system
the operating system it
operating system it runs
system it runs under
end with relatively weak
with relatively weak reliability
relatively weak reliability guarantees
to aid accurate detection
aid accurate detection in
accurate detection in the
detection in the case
in the case of
as we shall see
the case of node
case of node failure
of node failure the
node failure the fault
failure the fault management
our solution alleviates this
the fault management system
solution alleviates this problem
fault management system implements
alleviates this problem by
management system implements a
this problem by making
system implements a node
problem by making sure
implements a node management
by making sure that
a node management service
making sure that the
sure that the live
that the live subset
the live subset of
live subset of disks
subset of disks is
of disks is not
which is based on
disks is not constant
is based on the
based on the experience
on the experience that
the experience that local
the rest of this
experience that local failure
rest of this paper
download factor of correct
of this paper is
that local failure investigation
this paper is organized
factor of correct nodes
paper is organized as
of correct nodes during
is organized as follows
correct nodes during a
local failure investigation on
failure investigation on a
investigation on a subnet
on a subnet is
a subnet is more
subnet is more accurate
is more accurate than
describes some of the
more accurate than investigation
some of the solutions
accurate than investigation over
of the solutions explored
than investigation over the
the solutions explored in
investigation over the internet
solutions explored in the
second streaming session with
explored in the first
in the first three
the first three quadrants
first three quadrants mentioned
on a participating subnet
three quadrants mentioned above
a participating subnet one
participating subnet one or
subnet one or more
one or more node
or more node failure
more node failure monitors
presents and analyzes our
and analyzes our solution
auditing is enabled in
is enabled in the
enabled in the last
these are simple services
are simple services capable
discusses our evaluation methodology
simple services capable of
our evaluation methodology and
services capable of performing
evaluation methodology and results
capable of performing local
of performing local failure
performing local failure investigations
local failure investigations upon
failure investigations upon requests
we conclude in section
investigations upon requests from
upon requests from remote
requests from remote nodes
we present the minimum
average and maximum download
and maximum download factors
maximum download factors across
download factors across correct
factors across correct nodes
across correct nodes varying
correct nodes varying along
multicast to announce their
to announce their availability
based solutions the concept
announce their availability within
solutions the concept of
their availability within the
the concept of a
availability within the organization
concept of a memory
within the organization where
of a memory hierarchy
the organization where their
a memory hierarchy arose
organization where their presence
memory hierarchy arose as
where their presence is
hierarchy arose as a
their presence is being
arose as a result
presence is being tracked
as a result of
is being tracked by
as observed in this
being tracked by the
a result of the
tracked by the other
observed in this particular
by the other nfm
result of the natural
in this particular example
of the natural tradeoff
the natural tradeoff between
natural tradeoff between memory
tradeoff between memory speed
between memory speed and
memory speed and memory
auditing has the potential
speed and memory cost
has the potential to
the potential to improve
an nfm accepts queries
potential to improve the
nfm accepts queries from
to improve the quality
accepts queries from remote
improve the quality of
queries from remote nodes
the quality of streamed
from remote nodes about
quality of streamed sessions
remote nodes about the
of streamed sessions significantly
nodes about the availability
about the availability of
the availability of a
availability of a node
of a node within
and at low cost
a node within its
node within its organization
one important concern is
important concern is that
it will forward this
concern is that if
is that if the
will forward this request
that if the specified
that there exists a
if the specified threshold
there exists a similar
the specified threshold is
exists a similar tradeoff
specified threshold is too
forward this request to
a similar tradeoff between
threshold is too high
this request to an
similar tradeoff between performance
request to an nfm
tradeoff between performance and
to an nfm on
between performance and power
more opportunistic nodes may
an nfm on the
opportunistic nodes may be
nodes may be caught
nfm on the particular
on the particular subnet
the particular subnet which
particular subnet which will
but correct nodes may
performance disks and low
subnet which will investigate
correct nodes may also
which will investigate the
nodes may also be
will investigate the availability
may also be unfairly
investigate the availability of
also be unfairly punished
performance disks such as
the availability of the
disks such as laptop
availability of the node
such as laptop disks
of the node by
the node by launching
node by launching a
by launching a number
launching a number of
they explore the possibility
no correct nodes were
a number of fault
correct nodes were mistakenly
explore the possibility of
nodes were mistakenly expelled
number of fault test
were mistakenly expelled from
of fault test requests
mistakenly expelled from the
the possibility of setting
expelled from the system
possibility of setting up
of setting up a
setting up a disk
up a disk hierarchy
if this is support
a disk hierarchy by
this is support by
disk hierarchy by using
is support by the
hierarchy by using high
support by the host
by the host under
the host under investigation
host under investigation or
under investigation or by
investigation or by icmp
or by icmp echo
by icmp echo requests
auditing components we now
icmp echo requests if
performance disks in conjunction
echo requests if not
components we now give
disks in conjunction with
we now give some
in conjunction with each
now give some additional
conjunction with each other
give some additional details
the result of the
some additional details of
result of the query
additional details of the
of the query is
details of the auditing
in a related vein
of the auditing architecture
the query is then
query is then returned
is then returned to
then returned to the
returned to the requesting
to the requesting node
focusing upon two aspects
the nfm also functions
nfm also functions as
also functions as proxy
functions as proxy for
as proxy for process
proxy for process availability
for process availability queries
process availability queries in
availability queries in the
propose dynamic rotations per
collecting accountable information about
dynamic rotations per minute
queries in the case
repurposing bitcoin work for
accountable information about the
bitcoin work for data
in the case where
work for data preservation
information about the download
the case where a
about the download and
case where a firewall
the download and upload
where a firewall obstructs
download and upload factors
a firewall obstructs the
in proceedings of the
firewall obstructs the free
proceedings of the ieee
obstructs the free querying
and upload factors of
whereby disks can be
upload factors of individual
of the ieee symposium
factors of individual nodes
disks can be run
of individual nodes in
the ieee symposium on
the free querying of
can be run at
free querying of the
be run at multiple
querying of the nodes
ieee symposium on security
of the nodes by
individual nodes in the
symposium on security and
nodes in the system
on security and privacy
the nodes by their
run at multiple speeds
nodes by their peers
at multiple speeds depending
multiple speeds depending on
speeds depending on whether
depending on whether power
on whether power or
whether power or performance
power or performance takes
or performance takes precedence
s are configured with
are configured with domain
configured with domain and
with domain and acl
domain and acl mechanisms
establishing and applying the
and acl mechanisms to
and applying the best
acl mechanisms to control
applying the best threshold
mechanisms to control access
the best threshold at
to control access to
best threshold at any
control access to the
threshold at any given
access to the information
at any given time
poses a significant engineering
any given time during
a significant engineering challenge
given time during execution
significant engineering challenge whose
engineering challenge whose feasibility
an extension which is
challenge whose feasibility is
extension which is under
whose feasibility is far
which is under investigation
we employ two types
is under investigation is
feasibility is far from
employ two types of
is far from obvious
under investigation is to
two types of components
investigation is to have
types of components to
is to have nodes
of components to perform
to have nodes multicast
components to perform these
have nodes multicast heartbeats
to perform these two
another approach is proposed
namecoin dns dotbit project
approach is proposed by
perform these two roles
is proposed by colarelli
nodes multicast heartbeats with
proposed by colarelli et
multicast heartbeats with local
heartbeats with local node
with local node information
local and global auditors
local node information periodically
local auditors are executed
this information can be
auditors are executed on
information can be collected
are executed on the
can be collected by
executed on the nodes
be collected by the
on the nodes participating
collected by the local
the nodes participating in
by the local nfm
nodes participating in the
participating in the system
s and shared in
and shared in compressed
and therefore cannot be
shared in compressed form
using massive arrays of
in compressed form among
massive arrays of inexpensive
compressed form among the
arrays of inexpensive disks
form among the other
therefore cannot be trusted
among the other nfm
if a node is
s in the organization
a node is malicious
it might report false
they propose the use
might report false data
local system management tools
propose the use of
system management tools can
the use of a
management tools can connect
use of a small
tools can connect to
of a small number
can connect to an
global auditors are trusted
connect to an nfm
a small number of
to an nfm to
auditors are trusted components
an nfm to retrieve
small number of cache
nfm to retrieve the
are trusted components that
to retrieve the information
number of cache disks
retrieve the information and
trusted components that run
the information and set
of cache disks in
information and set trap
components that run on
and set trap conditions
cache disks in addition
that run on dedicated
disks in addition to
run on dedicated external
in addition to the
on dedicated external nodes
addition to the maid
to the maid disks
there can be just
can be just one
in distributed systems build
be just one or
the data in these
just one or a
distributed systems build on
one or a few
data in these cache
or a few global
systems build on top
a few global auditors
in these cache disks
a next generation smart
these cache disks is
build on top of
cache disks is updated
on top of a
disks is updated to
we describe their roles
is updated to reflect
describe their roles and
updated to reflect the
their roles and interactions
next generation smart contract
roles and interactions in
to reflect the workload
and interactions in detail
top of a web
reflect the workload that
of a web of
interactions in detail below
a web of interconnected
the workload that is
web of interconnected networks
workload that is currently
that is currently being
is currently being accessed
the maid disks can
maid disks can then
we have to take
disks can then be
have to take network
can then be powered
to take network failure
then be powered down
take network failure into
network failure into account
and need only be
need only be spun
failures at network level
only be spun up
at network level are
be spun up when
network level are in
spun up when a
level are in general
up when a cache
local auditors each node
when a cache miss
are in general related
a cache miss occurs
auditors each node n
in general related to
each node n runs
general related to crash
node n runs a
related to crash failures
n runs a local
to crash failures of
upon which their contents
runs a local auditor
which their contents are
crash failures of routers
their contents are copied
failures of routers and
contents are copied onto
of routers and gateways
are copied onto the
copied onto the cache
which interacts with other
onto the cache disks
interacts with other local
with other local auditors
or to severe degradation
other local auditors and
to severe degradation of
local auditors and has
this approach has several
severe degradation of the
approach has several of
auditors and has two
has several of the
and has two main
degradation of the service
has two main roles
several of the weaknesses
of the service level
of the weaknesses that
the service level due
the weaknesses that memory
service level due to
weaknesses that memory caches
level due to network
that memory caches suffer
due to network congestion
publish n s data
n s data exchange
s data exchange history
only on a larger
on a larger scale
causing minimum performance requirements
minimum performance requirements to
performance requirements to be
n s local auditor
requirements to be violated
s local auditor periodically
if the cache disks
local auditor periodically compiles
the cache disks are
auditor periodically compiles and
cache disks are insufficient
periodically compiles and distributes
disks are insufficient to
the failure investigator will
compiles and distributes the
are insufficient to store
and distributes the history
insufficient to store the
distributes the history of
to store the entire
when not able to
store the entire working
not able to reach
the history of packets
able to reach the
history of packets exchanged
the entire working set
of packets exchanged by
entire working set of
packets exchanged by n
to reach the node
working set of the
reach the node under
set of the current
the node under investigation
of the current workload
node under investigation or
under investigation or a
investigation or a relevant
or a relevant nfm
perform a path search
with considerable latency penalties
it queries the local
a path search to
queries the local streaming
path search to find
search to find the
the local streaming application
to find the trouble
find the trouble spot
local streaming application running
the trouble spot in
trouble spot in the
streaming application running on
spot in the network
the cache disks represent
application running on n
cache disks represent a
running on n for
disks represent a significant
analysis of bitcoin pooled
on n for the
of bitcoin pooled mining
it uses the traceroute
n for the set
bitcoin pooled mining reward
represent a significant added
pooled mining reward systems
for the set of
uses the traceroute technique
a significant added cost
the traceroute technique of
significant added cost in
the set of packets
added cost in themselves
traceroute technique of emitting
set of packets it
technique of emitting small
of packets it sent
of emitting small messages
packets it sent and
emitting small messages with
disk management solutions pinheiro
small messages with limited
management solutions pinheiro and
messages with limited ttl
it sent and received
solutions pinheiro and bianchini
sent and received using
and received using the
received using the streaming
using the streaming protocol
the streaming protocol in
streaming protocol in the
protocol in the most
triggering icmp responses from
in the most recent
icmp responses from routers
the most recent time
responses from routers among
most recent time interval
from routers among the
routers among the path
suggest that if data
if an obstruction is
that if data is
an obstruction is found
if data is laid
obstruction is found it
data is laid out
is found it is
is laid out on
found it is reported
laid out on disks
it is reported to
out on disks according
is reported to the
on disks according to
reported to the caller
disks according to frequency
according to frequency of
the local auditor signs
to frequency of access
local auditor signs and
auditor signs and publishes
the failure management library
signs and publishes the
failure management library offers
and publishes the collected
with the most popular
management library offers functionality
publishes the collected history
the most popular files
the collected history to
most popular files being
collected history to an
popular files being located
history to an assigned
files being located in
library offers functionality to
being located in one
to an assigned subset
located in one set
an assigned subset of
in one set of
assigned subset of its
one set of disks
subset of its neighboring
offers functionality to keep
of its neighboring nodes
functionality to keep the
to keep the obstruction
and the least popular
keep the obstruction under
the least popular ones
from whom other auditors
the obstruction under investigation
whom other auditors may
least popular ones in
other auditors may obtain
obstruction under investigation and
auditors may obtain it
popular ones in another
under investigation and to
investigation and to notify
and to notify the
to notify the application
notify the application once
then the latter set
the application once the
this level of indirection
application once the obstruction
the latter set of
level of indirection is
latter set of disks
once the obstruction seems
of indirection is used
set of disks could
the obstruction seems to
of disks could be
obstruction seems to be
indirection is used to
seems to be removed
disks could be powered
is used to prevent
could be powered down
used to prevent nodes
be powered down to
to prevent nodes from
powered down to conserve
prevent nodes from masking
this way the process
down to conserve energy
nodes from masking their
way the process does
from masking their real
the process does not
masking their real upload
process does not need
their real upload and
their scheme is called
real upload and download
does not need to
scheme is called popular
upload and download factors
not need to keep
is called popular data
and download factors by
need to keep the
called popular data concentration
download factors by presenting
to keep the partitioned
factors by presenting different
keep the partitioned processes
by presenting different information
the partitioned processes under
presenting different information to
partitioned processes under investigation
different information to different
processes under investigation but
information to different auditors
and they implement and
under investigation but can
they implement and evaluate
investigation but can wait
implement and evaluate a
but can wait until
and evaluate a prototype
can wait until the
audit n s neighbors
evaluate a prototype file
n s neighbors histories
wait until the connectivity
a prototype file server
until the connectivity is
prototype file server called
the connectivity is restored
file server called nomad
connectivity is restored by
server called nomad fs
is restored by simply
n s local auditor
restored by simply monitoring
s local auditor periodically
by simply monitoring the
local auditor periodically audits
simply monitoring the trouble
which runs on top
auditor periodically audits the
monitoring the trouble spot
runs on top of
periodically audits the published
on top of the
audits the published histories
top of the file
the published histories of
of the file system
research perspectives on bitcoin
published histories of the
in case the network
histories of the nodes
case the network topology
of the nodes with
the network topology permits
the nodes with whom
network topology permits it
nodes with whom n
perspectives on bitcoin and
with whom n exchanges
the file system and
on bitcoin and secondgeneration
file system and monitors
bitcoin and secondgeneration cryptocurrencies
the investigator can be
system and monitors data
investigator can be configured
and monitors data layout
can be configured to
monitors data layout on
whom n exchanges packets
data layout on disks
in ieee symposium on
be configured to use
ieee symposium on security
configured to use alternate
symposium on security and
to use alternate paths
on security and privacy
their findings are that
findings are that if
are that if the
that if the low
if node n exchanges
node n exchanges packets
n exchanges packets with
exchanges packets with nodes
access disks are powered
packets with nodes p
disks are powered down
to reach one of
reach one of the
one of the destination
q and r in
this results in a
and r in the
results in a considerable
r in the livestreaming
of the destination nfm
in the livestreaming protocol
in a considerable performance
a considerable performance hit
n s local auditor
they suggest instead that
s local auditor compares
suggest instead that they
from cornell for example
instead that they be
local auditor compares these
that they be run
cornell for example it
they be run at
auditor compares these three
be run at low
for example it is
run at low speed
compares these three nodes
example it is possible
these three nodes histories
it is possible to
three nodes histories with
is possible to construct
while their idea is
nodes histories with n
their idea is sound
histories with n s
with n s own
n s own history
alternative routes to anywhere
routes to anywhere in
it is not clear
to anywhere in california
is not clear whether
this involves ensuring that
not clear whether this
clear whether this scheme
whether this scheme would
this scheme would adapt
scheme would adapt to
would adapt to different
adapt to different workloads
the request contains sufficient
request contains sufficient information
contains sufficient information for
sufficient information for the
information for the nfm
for the nfm to
the nfm to construct
nfm to construct a
to construct a symmetric
construct a symmetric return
the amount of data
a symmetric return path
amount of data sent
propose another data layout
of data sent by
another data layout management
data sent by these
data layout management scheme
sent by these nodes
protocols that can exploit
by these nodes satisfies
that can exploit this
these nodes satisfies the
layout management scheme to
can exploit this type
nodes satisfies the defined
exploit this type of
satisfies the defined minimum
this type of information
the defined minimum threshold
type of information are
defined minimum threshold for
of information are under
minimum threshold for the
information are under development
threshold for the system
management scheme to optimize
scheme to optimize disk
to optimize disk access
optimize disk access patterns
the set of packets
set of packets they
of packets they claim
their approach uses finer
packets they claim to
they claim to have
claim to have sent
grained control over data
to have sent to
control over data layout
over data layout on
have sent to and
data layout on disk
sent to and received
failure investigation of a
to and received from
investigation of a process
of a process at
and received from node
a process at the
tuning it on a
process at the same
it on a per
at the same sub
received from node n
from node n corresponds
node n corresponds to
n corresponds to the
net has always been
corresponds to the set
has always been viewed
to the set of
always been viewed as
the set of packets
applications are instrumented and
set of packets n
are instrumented and then
of packets n claims
instrumented and then profiled
packets n claims to
and then profiled to
been viewed as a
then profiled to obtain
n claims to have
profiled to obtain array
viewed as a reasonably
to obtain array access
claims to have respectively
obtain array access sequences
as a reasonably accurate
to have respectively received
have respectively received from
respectively received from and
received from and sent
from and sent to
which their system then
and sent to them
reasons for false suspicions
their system then uses
for false suspicions were
system then uses to
false suspicions were overload
then uses to determine
suspicions were overload in
uses to determine optimal
were overload in the
to determine optimal disk
overload in the receiver
determine optimal disk layouts
in the receiver os
if the first check
optimal disk layouts by
the first check comparison
disk layouts by computing
first check comparison fails
layouts by computing optimal
by computing optimal stripe
computing optimal stripe factor
the local auditor issues
local auditor issues an
auditor issues an accusation
issues an accusation against
an accusation against the
accusation against the node
against the node to
the node to a
node to a global
to a global auditor
which could cause high
the wisdom of marrying
could cause high message
wisdom of marrying the
cause high message loss
of marrying the disk
in the second case
marrying the disk layout
the disk layout to
disk layout to the
layout to the application
or unresponsiveness due to
to the application seems
unresponsiveness due to application
the application seems questionable
the local auditor is
due to application overload
local auditor is not
auditor is not able
is not able to
not able to prove
able to prove the
although that could be
to prove the neighbor
that could be seen
prove the neighbor s
could be seen as
proposed by zhu et
be seen as a
the neighbor s misbehavior
seen as a design
as a design error
it instructs its local
although confident about the
instructs its local streaming
confident about the result
its local streaming application
local streaming application to
streaming application to not
application to not further
one was never guaranteed
to not further exchange
was never guaranteed that
not further exchange packets
combines a number of
further exchange packets with
a number of ideas
never guaranteed that the
exchange packets with the
guaranteed that the process
packets with the misbehaving
that the process had
with the misbehaving neighbor
the process had truly
process had truly crashed
it assumes multispeed disks
more complex types of
using the os failure
and computes online the
the os failure management
complex types of checks
os failure management extensions
computes online the optimal
types of checks may
online the optimal speed
of checks may also
the optimal speed that
checks may also be
optimal speed that each
this assurance is now
speed that each disk
assurance is now available
that each disk should
may also be performed
each disk should run
also be performed to
disk should run at
be performed to address
performed to address other
the time needed by
to address other types
time needed by the
address other types of
needed by the failure
other types of byzantine
to minimize speed transition
types of byzantine behavior
by the failure detector
minimize speed transition overheads
the failure detector to
failure detector to come
detector to come to
to come to a
come to a result
disks maintain their speeds
to a result has
maintain their speeds for
a result has been
their speeds for a
result has been greatly
speeds for a fixed
has been greatly reduced
been greatly reduced in
greatly reduced in the
reduced in the optimistic
common case that the
case that the node
that the node on
the node on which
they call this the
node on which the
call this the coarse
on which the process
which the process was
the process was running
process was running is
was running is reachable
information propagation in the
propagation in the bitcoin
in the bitcoin network
regardless if the process
if the process has
the process has failed
process has failed or
has failed or not
hibernator includes a file
includes a file server
a file server that
file server that sits
the node is able
server that sits on
node is able to
that sits on top
th ieee international conference
is able to indicate
ieee international conference on
sits on top of
international conference on peer
able to indicate whether
on top of the
to indicate whether or
top of the file
indicate whether or not
of the file system
whether or not the
the file system and
or not the process
file system and manipulates
not the process has
system and manipulates data
the process has crashed
and manipulates data layout
manipulates data layout to
data layout to put
layout to put the
to put the most
in general a single
general a single round
accessed data on the
data on the highest
on the highest speed
trip time is sufficient
the highest speed disks
time is sufficient at
is sufficient at the
sufficient at the local
at the local network
the local network to
local network to get
the authors address the
network to get a
to get a result
authors address the issue
address the issue of
the issue of performance
issue of performance guarantees
of performance guarantees by
performance guarantees by stipulating
guarantees by stipulating that
by stipulating that if
area case this time
stipulating that if performance
case this time is
that if performance drops
this time is a
if performance drops below
time is a function
performance drops below some
is a function of
drops below some threshold
a function of the
function of the level
of the level of
the level of congestion
level of congestion in
then all disks are
of congestion in the
all disks are spun
congestion in the network
disks are spun up
in the network path
are spun up to
spun up to their
up to their highest
to their highest speed
bitcoin and the age
and the age of
the age of bespoke
the os extensions also
age of bespoke silicon
os extensions also improve
caching solutions zhu et
extensions also improve the
also improve the confidence
in proceedings of the
improve the confidence in
the confidence in the
confidence in the failure
in the failure investigation
the failure investigation process
failure investigation process in
investigation process in the
process in the wide
observe that the storage
that the storage cache
international conference on compilers
using the old strategy
the storage cache management
the old strategy of
storage cache management policy
old strategy of simply
cache management policy is
strategy of simply polling
management policy is pivotal
architectures and synthesis for
policy is pivotal in
and synthesis for embedded
of simply polling a
synthesis for embedded systems
is pivotal in determining
simply polling a process
pivotal in determining the
polling a process until
in determining the sequence
a process until a
determining the sequence of
process until a time
the sequence of requests
sequence of requests that
of requests that access
requests that access disks
out occurs gives much
occurs gives much less
gives much less confidence
much less confidence in
less confidence in the
confidence in the result
in the result of
the result of the
cache management policies could
result of the failure
management policies could be
of the failure investigation
policies could be tailored
could be tailored to
be tailored to change
tailored to change the
to change the average
if no response was
change the average idle
no response was received
the average idle time
response was received after
average idle time between
was received after the
idle time between disk
received after the maximum
time between disk requests
after the maximum number
the maximum number of
maximum number of retransmission
number of retransmission is
of retransmission is reached
thus providing more opportunities
providing more opportunities for
more opportunities for reducing
opportunities for reducing disk
for reducing disk energy
it was not certain
reducing disk energy consumption
was not certain whether
not certain whether this
certain whether this was
whether this was because
this was because of
was because of network
because of network failure
into the bitcoin mines
cache policies that are
policies that are aware
host failure or process
that are aware of
failure or process failure
are aware of the
aware of the underlying
of the underlying disk
the underlying disk management
underlying disk management schemes
with the new scheme
the new scheme it
new scheme it is
scheme it is possible
it is possible to
is possible to distinguish
possible to distinguish among
to distinguish among these
distinguish among these different
which disks are running
among these different failures
disks are running at
are running at which
running at which speeds
additional information the full
information the full report
the full report contains
full report contains the
can make more intelligent
report contains the detailed
make more intelligent replacement
contains the detailed results
more intelligent replacement decisions
the detailed results of
detailed results of the
results of the trace
of the trace study
the authors present both
the trace study on
authors present both offline
present both offline and
trace study on the
both offline and online
study on the accuracy
offline and online power
on the accuracy and
the accuracy and performance
accuracy and performance of
and performance of the
aware cache replacement algorithms
performance of the failure
cache replacement algorithms to
of the failure detector
replacement algorithms to optimize
the failure detector in
algorithms to optimize read
failure detector in the
to optimize read accesses
detector in the internet
global auditing there are
auditing there are two
there are two ways
they also show through
are two ways in
the effectiveness of its
two ways in which
also show through experiments
effectiveness of its partition
ways in which a
of its partition detection
show through experiments the
its partition detection mechanism
in which a node
through experiments the somewhat
which a node could
experiments the somewhat obvious
a node could pretend
the somewhat obvious fact
node could pretend to
somewhat obvious fact that
could pretend to be
obvious fact that for
pretend to be sending
fact that for write
host failure measurements and
that for write accesses
to be sending more
failure measurements and measurements
be sending more or
measurements and measurements of
sending more or receiving
and measurements of failure
more or receiving less
measurements of failure detection
or receiving less data
of failure detection for
receiving less data than
failure detection for server
less data than it
detection for server fail
data than it actually
back policies offer more
than it actually does
policies offer more opportunities
offer more opportunities to
more opportunities to save
opportunities to save power
to save power than
it could send different
save power than write
could send different histories
send different histories to
different histories to each
histories to each neighbor
it will be available
will be available later
be available later this
available later this year
always lying about its
later this year through
lying about its interactions
this year through the
about its interactions with
year through the cornell
its interactions with other
in the context of
interactions with other neighbors
the context of write
through the cornell university
the cornell university technical
cornell university technical report
university technical report server
a very natural candidate
n could send a
very natural candidate is
could send a history
natural candidate is the
send a history to
candidate is the log
a history to p
history to p pretending
to p pretending to
p pretending to send
pretending to send more
to send more data
send more data to
more data to q
data to q than
to q than it
q than it actually
than it actually did
while it sends a
it sends a different
sends a different history
a different history to
different history to q
history to q where
we now give a
to q where it
now give a brief
q where it pretends
give a brief overview
where it pretends to
a brief overview of
relevant url s the
brief overview of the
it pretends to send
overview of the log
url s the horus
pretends to send more
s the horus project
to send more data
the horus project the
send more data to
structured file system before
horus project the cornell
file system before describing
more data to p
system before describing the
data to p than
before describing the power
to p than it
project the cornell cluster
p than it actually
than it actually did
the cornell cluster computing
cornell cluster computing project
saving opportunity it represents
cluster computing project werner
computing project werner vogels
project werner vogels personal
n s goal would
werner vogels personal home
s goal would be
vogels personal home page
goal would be to
personal home page papers
would be to send
home page papers on
be to send less
page papers on failure
to send less data
papers on failure detection
send less data while
on failure detection http
less data while not
data while not being
while not being caught
not being caught by
being caught by any
caught by any of
structured file system the
by any of its
file system the log
any of its neighbors
the process of publishing
process of publishing a
of publishing a node
publishing a node s
a node s history
was motivated by a
node s history to
motivated by a need
s history to a
by a need to
history to a predefined
a need to optimize
to a predefined set
need to optimize the
a predefined set of
to optimize the latency
predefined set of neighbors
optimize the latency of
set of neighbors ensures
the latency of write
of neighbors ensures that
neighbors ensures that the
ensures that the node
that the node cannot
the node cannot send
node cannot send conflicting
cannot send conflicting histories
send conflicting histories to
writing a block of
conflicting histories to different
a block of data
histories to different neighbors
block of data to
to different neighbors undetected
of data to a
data to a seagate
to a seagate barracuda
a seagate barracuda disk
seagate barracuda disk costs
therefore avoiding this problem
barracuda disk costs about
a node could also
node could also lie
could also lie about
also lie about the
lie about the set
about the set of
the set of packets
set of packets sent
of packets sent to
packets sent to or
ms in seek time
sent to or received
in seek time and
to or received from
or received from a
received from a particular
from a particular neighbor
a particular neighbor p
p will be able
will be able to
be able to identify
able to identify that
to identify that the
identify that the node
that the node has
the node has lied
node has lied and
kb in transmission time
has lied and will
lied and will therefore
and will therefore stop
will therefore stop exchanging
the key observation here
therefore stop exchanging packets
key observation here is
stop exchanging packets with
observation here is that
exchanging packets with n
here is that seek
is that seek time
that seek time is
seek time is a
time is a large
given that an opportunistic
is a large and
that an opportunistic node
a large and constant
an opportunistic node s
large and constant term
opportunistic node s goal
and constant term in
node s goal is
constant term in latency
s goal is to
term in latency computation
goal is to maximize
is to maximize its
to maximize its utility
to eliminate this term
it should have no
should have no interest
have no interest in
the lfs replaces write
no interest in losing
lfs replaces write operations
interest in losing data
replaces write operations by
in losing data exchange
write operations by append
losing data exchange partners
operations by append operations
secondary storage is treated
storage is treated as
is treated as a
treated as a large
opportunistic nodes have no
as a large append
nodes have no incentive
have no incentive to
no incentive to publish
incentive to publish incorrect
to publish incorrect histories
only log and writes
log and writes always
and writes always go
writes always go to
always go to the
go to the log
to the log head
local auditing ensures that
seek time is thus
auditing ensures that correct
time is thus eliminated
ensures that correct information
that correct information is
correct information is available
information is available regarding
and write latency becomes
is available regarding the
write latency becomes purely
available regarding the set
latency becomes purely a
regarding the set of
becomes purely a function
the set of data
purely a function of
set of data sent
a function of the
of data sent and
function of the disk
data sent and received
of the disk bandwidth
sent and received by
and received by any
received by any node
how do reads in
do reads in the
reads in the lfs
in the lfs work
and allows nodes to
allows nodes to monitor
nodes to monitor each
to monitor each other
monitor each other s
in the same way
each other s contribution
the same way as
other s contribution rates
same way as in
way as in conventional
as in conventional file
in conventional file systems
transis a communication subsystem
a communication subsystem for
communication subsystem for high
subsystem for high availability
and hence do not
hence do not avoid
do not avoid seek
idigest of papers of
global auditors global auditors
auditors global auditors are
global auditors are trusted
auditors are trusted components
are trusted components with
the assumption is that
trusted components with global
assumption is that with
components with global membership
is that with good
with global membership knowledge
that with good caching
with good caching mechanisms
who interact with one
interact with one another
reads will be a
with one another and
will be a small
one another and with
be a small fraction
another and with the
a small fraction of
and with the local
small fraction of disk
with the local auditors
fraction of disk accesses
as shown in figure
as can be imagined
space reclamation is a
reclamation is a tricky
is a tricky problem
global auditors execute on
a tricky problem in
auditors execute on nodes
tricky problem in log
execute on nodes external
problem in log structured
on nodes external to
in log structured file
nodes external to the
log structured file systems
external to the system
fast message ordering and
their main roles are
message ordering and membership
ordering and membership using
and membership using a
excellent solutions have been
membership using a logical
solutions have been proposed
define the minimum upload
have been proposed to
the minimum upload threshold
using a logical token
been proposed to solve
proposed to solve it
global auditors periodically sample
auditors periodically sample the
and one such is
periodically sample the state
one such is of
sample the state of
such is of interest
the state of the
is of interest to
state of the system
of interest to us
of the system by
the system by querying
system by querying local
by querying local auditors
the disk is divided
disk is divided into
is divided into large
they then cooperate to
divided into large log
then cooperate to analyze
into large log segments
cooperate to analyze the
to analyze the collected
analyze the collected samples
once a log segment
a log segment gets
log segment gets filled
and on this basis
on this basis compute
this basis compute the
basis compute the minimum
compute the minimum upload
a new log segment
the minimum upload contribution
new log segment is
minimum upload contribution threshold
log segment is allocated
segment is allocated and
is allocated and the
allocated and the log
and the log head
different strategies may be
the log head moves
strategies may be employed
log head moves to
may be employed for
head moves to the
be employed for choosing
moves to the new
employed for choosing the
to the new segment
for choosing the best
choosing the best possible
the best possible threshold
when some threshold of
some threshold of a
threshold of a segment
of a segment gets
a segment gets invalidated
once thresholds are varied
its valid data is
valid data is moved
data is moved to
is moved to another
they are gossiped to
moved to another segment
are gossiped to all
gossiped to all local
to all local auditors
replacing that segment s
reliable communication in the
that segment s invalid
communication in the presence
segment s invalid data
who then enforce the
in the presence of
then enforce the determined
the presence of failure
enforce the determined threshold
acm transaction on computer
expurge nodes from the
and it is then
nodes from the system
transaction on computer systems
it is then added
is then added to
then added to the
added to the pool
to the pool of
global auditors are also
the pool of free
auditors are also responsible
pool of free log
are also responsible for
of free log segments
also responsible for verifying
responsible for verifying accusations
for verifying accusations issued
verifying accusations issued by
accusations issued by local
issued by local auditors
by local auditors against
local auditors against particular
auditors against particular nodes
this process results in
process results in a
results in a natural
in a natural division
a natural division of
natural division of allocated
and after validating the
division of allocated segments
after validating the accusation
how a mining monopoly
of allocated segments into
a mining monopoly can
allocated segments into stable
mining monopoly can attack
expurging misbehaving nodes from
monopoly can attack bitcoin
misbehaving nodes from the
nodes from the system
validation involves verifying that
involves verifying that the
verifying that the accused
consisting almost entirely of
that the accused node
almost entirely of data
the accused node s
entirely of data that
accused node s history
of data that is
node s history indeed
data that is rarely
s history indeed indicates
that is rarely invalidated
history indeed indicates that
indeed indicates that the
indicates that the node
that the node is
the node is sending
node is sending less
is sending less data
sending less data than
less data than the
data than the current
group membership and viewsynchronous
than the current threshold
membership and viewsynchronous communication
and viewsynchronous communication in
viewsynchronous communication in partitionable
which need to be
communication in partitionable asynchronous
need to be constantly
in partitionable asynchronous systems
expurging a node involves
to be constantly cleaned
a node involves informing
node involves informing the
involves informing the nodes
informing the nodes immediate
the nodes immediate neighbors
nodes immediate neighbors of
we will see how
immediate neighbors of its
will see how this
neighbors of its status
see how this feature
of its status and
how this feature can
its status and forcing
this feature can be
status and forcing the
feature can be used
and forcing the removal
can be used to
forcing the removal of
be used to save
the removal of the
used to save power
removal of the node
of the node from
the node from the
node from the overlay
from the overlay mesh
the number of global
number of global auditors
of global auditors may
global auditors may vary
auditors may vary according
may vary according to
vary according to different
according to different parameters
such as the size
as the size of
the size of the
size of the system
saving opportunity we shall
opportunity we shall now
the use of more
we shall now argue
use of more global
shall now argue that
of more global auditors
now argue that there
more global auditors distributes
argue that there remains
global auditors distributes the
that there remains an
auditors distributes the load
there remains an unexplored
distributes the load of
remains an unexplored quadrant
the load of sampling
an unexplored quadrant in
load of sampling and
unexplored quadrant in this
of sampling and improves
quadrant in this solution
sampling and improves efficiency
in this solution space
and improves efficiency in
improves efficiency in reacting
efficiency in reacting to
in reacting to accusations
reacting to accusations against
caches are used to
to accusations against nodes
are used to minimize
used to minimize accesses
to minimize accesses to
minimize accesses to disk
global auditors are also
unreliable failure detectors for
auditors are also perfect
failure detectors for reliable
good caching algorithms practically
detectors for reliable distributed
are also perfect candidates
caching algorithms practically eliminate
for reliable distributed systems
algorithms practically eliminate read
also perfect candidates to
practically eliminate read accesses
perfect candidates to perform
eliminate read accesses to
candidates to perform membership
read accesses to disk
to appear in journal
to perform membership tasks
appear in journal of
perform membership tasks such
in journal of the
membership tasks such as
journal of the acm
tasks such as acting
such as acting as
as acting as entry
acting as entry points
as entry points to
entry points to the
points to the p
whether synchronous or not
majority is not enough
must still eventually access
still eventually access the
since they are required
eventually access the disk
they are required to
bitcoin mining is vulnerable
in financial cryptography and
financial cryptography and data
cryptography and data security
disk access will be
access will be write
are required to have
putting a disk management
required to have full
a disk management layer
to have full membership
disk management layer on
have full membership knowledge
management layer on top
full membership knowledge of
layer on top of
impossibility of distributed consensus
on top of the
membership knowledge of the
top of the file
of distributed consensus with
knowledge of the system
distributed consensus with one
of the system for
consensus with one faulty
the system for performing
with one faulty process
system for performing their
system to optimize data
for performing their auditing
to optimize data layout
performing their auditing roles
optimize data layout for
data layout for writes
journal of the acm
layout for writes is
for writes is only
writes is only halfway
is only halfway to
only halfway to the
halfway to the solution
global auditing monitors the
auditing monitors the global
to take this idea
monitors the global health
take this idea to
this idea to its
the global health of
idea to its logical
to its logical conclusion
global health of the
health of the system
of the system to
the system to identify
it is necessary to
system to identify the
is necessary to rethink
to identify the best
necessary to rethink the
identify the best value
to rethink the file
the best value for
rethink the file the
best value for the
the file the disk
value for the minimum
for the minimum upload
the minimum upload threshold
minimum upload threshold at
upload threshold at any
management policies described in
threshold at any time
policies described in the
at any time during
described in the related
any time during a
in the related works
time during a streaming
the related works section
during a streaming session
related works section essentially
works section essentially attack
section essentially attack the
essentially attack the problem
and makes final decisions
attack the problem by
makes final decisions regarding
the problem by trying
final decisions regarding punishment
problem by trying to
r van and vogels
decisions regarding punishment of
by trying to predict
regarding punishment of nodes
trying to predict in
to predict in advance
predict in advance which
in advance which disk
advance which disk any
which disk any given
disk any given access
any given access will
given access will go
access will go to
they optimize the data
support for highly reliable
optimize the data layout
adaptive threshold strategies choosing
the data layout on
threshold strategies choosing an
data layout on disks
strategies choosing an upload
layout on disks to
choosing an upload threshold
on disks to ensure
an upload threshold requires
disks to ensure that
upload threshold requires care
to ensure that accesses
ensure that accesses are
that accesses are localized
accesses are localized to
are localized to some
a low threshold may
localized to some fraction
low threshold may not
to some fraction of
threshold may not be
some fraction of the
may not be sufficient
fraction of the disks
not be sufficient to
be sufficient to identify
sufficient to identify opportunistic
to identify opportunistic nodes
so that only these
acm sigops european workshop
cooperative equilibrium for supergames
that only these need
only these need be
while high thresholds may
these need be powered
high thresholds may incorrectly
need be powered up
thresholds may incorrectly punish
the review of economic
may incorrectly punish correct
review of economic studies
incorrectly punish correct nodes
we considered different strategies
these are all probabilistic
considered different strategies for
are all probabilistic models
different strategies for the
strategies for the choice
for the choice of
the choice of the
a new access has
choice of the minimum
new access has some
of the minimum contribution
access has some probability
the minimum contribution t
has some probability of
minimum contribution t hreshold
some probability of not
contribution t hreshold used
probability of not fitting
t hreshold used for
of not fitting this
hreshold used for identifying
not fitting this model
used for identifying misbehaving
fitting this model and
for identifying misbehaving nodes
this model and needing
model and needing to
and needing to access
needing to access a
to access a powered
the simplest strategy sets
simplest strategy sets a
strategy sets a fixed
sets a fixed threshold
disk layout becomes tied
layout becomes tied to
becomes tied to particular
tied to particular applications
two applications that have
applications that have completely
that have completely different
have completely different access
completely different access patterns
different access patterns might
reliable multicast for distributed
access patterns might require
multicast for distributed interactive
patterns might require completely
for distributed interactive simulation
might require completely different
require completely different data
independent of the current
completely different data layouts
of the current state
different data layouts on
proceedings of acm sigcomm
the current state of
data layouts on disk
current state of the
layouts on disk leading
state of the system
on disk leading to
disk leading to conflicts
leading to conflicts that
to conflicts that reduce
conflicts that reduce possible
term competition a game
that reduce possible powersavings
any node contributing at
node contributing at a
contributing at a rate
at a rate of
since all writes in
a rate of less
all writes in an
rate of less than
writes in an lfs
in an lfs are
an lfs are to
lfs are to the
are to the log
to the log head
we know in advance
know in advance which
in advance which disk
of the stream rate
advance which disk they
the stream rate would
which disk they will
stream rate would be
disk they will access
rate would be removed
this gives us the
one downside of using
gives us the perfect
downside of using a
us the perfect prediction
of using a fixed
the perfect prediction mechanism
using a fixed threshold
a fixed threshold is
fixed threshold is that
at least for writeaccesses
threshold is that opportunistic
is that opportunistic nodes
that opportunistic nodes that
opportunistic nodes that learn
nodes that learn the
that learn the threshold
learn the threshold can
this prediction mechanism is
the threshold can simply
prediction mechanism is also
threshold can simply contribute
mechanism is also entirely
can simply contribute at
is also entirely application
simply contribute at the
contribute at the lowest
at the lowest possible
the lowest possible upload
lowest possible upload factor
view synchronous communication in
synchronous communication in large
communication in large scale
if most accesses to
most accesses to disks
from the graphs in
accesses to disks were
the graphs in section
to disks were writes
nd open broadcast workshop
we could power down
could power down every
power down every disk
down every disk but
it is clear that
every disk but the
is clear that such
disk but the one
clear that such a
but the one that
that such a stretagy
the one that the
such a stretagy may
one that the log
a stretagy may disrupt
that the log head
stretagy may disrupt the
the log head resides
may disrupt the streaming
log head resides on
disrupt the streaming session
choosing a high threshold
a high threshold is
high threshold is not
is an ideal case
threshold is not a
an ideal case scenario
is not a practical
not a practical option
our view is that
since correct nodes would
correct nodes would get
nodes would get unfairly
with a good caching
would get unfairly punished
a good caching algorithm
to avoid this problem
increasing reliability of communication
reliability of communication in
of communication in large
communication in large scale
aware caching algorithms described
we have explored adaptive
in large scale distributed
have explored adaptive strategies
caching algorithms described in
algorithms described in the
described in the related
in the related works
the related works section
one simple strategy starts
related works section are
simple strategy starts with
works section are good
strategy starts with a
section are good candidates
starts with a minimum
with a minimum threshold
reads to disk can
to disk can be
disk can be minimized
and only a small
only a small fraction
a small fraction of
small fraction of the
fraction of the disks
of the disks need
the disks need be
disks need be powered
need be powered on
be powered on in
powered on in order
on in order to
in order to serve
order to serve all
to serve all writes
serve all writes as
all writes as well
writes as well as
as well as reads
increasing it only if
it only if the
only if the system
if the system is
the system is compromised
what about the performance
about the performance and
the performance and power
global auditors sample the
performance and power costs
auditors sample the system
and power costs of
sample the system to
power costs of log
the system to identify
costs of log cleaning
system to identify the
to identify the average
identify the average download
the average download factor
and if this factor
if this factor is
al present some optimizations
this factor is lower
present some optimizations in
factor is lower than
a generic architecture for
generic architecture for dependable
architecture for dependable distributed
for dependable distributed computing
to hide the performance
hide the performance penalty
the performance penalty of
performance penalty of log
penalty of log cleaning
of log cleaning even
log cleaning even when
cleaning even when the
even when the workload
io bitcoin mining pool
when the workload allows
the workload allows little
workload allows little idle
once the download factor
allows little idle time
the download factor reaches
download factor reaches a
factor reaches a satisfactory
reaches a satisfactory level
a satisfactory level again
the power costs of
power costs of log
costs of log cleaning
of log cleaning are
log cleaning are a
the threshold may be
cleaning are a little
threshold may be reduced
are a little more
may be reduced back
a little more tricky
be reduced back to
little more tricky to
reduced back to its
more tricky to justify
back to its initial
to its initial value
this stepwise approach allows
stepwise approach allows the
this is where the
approach allows the system
is where the natural
allows the system to
where the natural division
the system to catch
the natural division of
system to catch opportunistic
natural division of segments
to catch opportunistic nodes
division of segments into
catch opportunistic nodes in
of segments into stable
opportunistic nodes in case
segments into stable and
nodes in case their
into stable and volatile
in case their presence
stable and volatile ones
case their presence starts
and volatile ones that
their presence starts affecting
volatile ones that the
presence starts affecting the
ones that the log
starts affecting the performance
that the log cleaning
affecting the performance of
the log cleaning process
the performance of the
log cleaning process results
performance of the system
cleaning process results in
a flexible group communications
flexible group communications system
while avoiding incorrect accusations
avoiding incorrect accusations of
incorrect accusations of correct
accusations of correct nodes
cornell university technical report
we also considered a
after a significant fraction
also considered a second
a significant fraction of
considered a second adaptive
significant fraction of segments
a second adaptive strategy
fraction of segments on
of segments on a
segments on a disk
on a disk have
a disk have been
disk have been classified
have been classified as
been classified as stable
for computing the threshold
computing the threshold based
the threshold based on
threshold based on periodically
based on periodically sampled
on periodically sampled download
periodically sampled download and
we power the disk
sampled download and upload
power the disk on
download and upload factors
the disk on and
disk on and copy
on and copy the
and copy the stable
copy the stable segments
the stable segments to
the average download factors
stable segments to a
average download factors once
segments to a stable
download factors once again
to a stable disk
factors once again are
once again are used
again are used for
are used for detecting
volatile segments to a
used for detecting whether
segments to a volatile
for detecting whether the
to a volatile disk
detecting whether the threshold
whether the threshold should
the threshold should be
threshold should be varied
should be varied or
disk is kept on
be varied or not
and the entire disk
the entire disk is
our initial threshold is
entire disk is freed
initial threshold is set
disk is freed for
threshold is set to
is freed for reuse
is set to null
this is similar to
and the threshold is
is similar to the
the threshold is chosen
similar to the log
threshold is chosen from
to the log cleaning
is chosen from sampled
the log cleaning scheme
chosen from sampled upload
log cleaning scheme described
from sampled upload factors
cleaning scheme described in
if the system seems
the system seems to
system seems to be
seems to be in
to be in a
be in a compromised
in a compromised state
the collected upload factors
which uses a hidden
collected upload factors are
uses a hidden structure
upload factors are ordered
a hidden structure embedded
factors are ordered and
hidden structure embedded in
are ordered and the
structure embedded in the
ordered and the value
embedded in the log
and the value dividing
in the log to
the value dividing the
the log to track
value dividing the lowest
log to track segment
to track segment utilization
cleaning an entire disk
an entire disk amortizes
percent is used as
entire disk amortizes the
is used as the
disk amortizes the cost
used as the new
amortizes the cost of
as the new threshold
the cost of powering
cost of powering the
of powering the disk
powering the disk on
this approach relies on
approach relies on efficiently
relies on efficiently sampling
on efficiently sampling the
number of accesses number
efficiently sampling the system
of accesses number of
accesses number of files
number of files touched
of files touched number
files touched number of
and on fact that
touched number of bytes
on fact that if
number of bytes touched
fact that if the
of bytes touched average
that if the system
bytes touched average number
if the system s
touched average number of
the system s performance
average number of bytes
system s performance is
s performance is not
performance is not satisfactory
percent of the nodes
of the nodes are
the nodes are opportunistic
evaluation in this section
we evaluate the performance
evaluate the performance of
the performance of our
performance of our proposed
of our proposed auditing
our proposed auditing strategy
proposed auditing strategy over
auditing strategy over the
strategy over the original
over the original streaming
the original streaming protocol
we built an event
driven simulator and used
simulator and used it
and used it to
used it to simulate
it to simulate streaming
to simulate streaming sessions
simulate streaming sessions on
streaming sessions on networks
sessions on networks with
nodes and an average
and an average of
based simulator of a
simulator of a log
given a trace of
a trace of read
the target streaming rate
trace of read and
target streaming rate in
of read and write
streaming rate in the
read and write requests
kncminer bitcoin mining cloud
rate in the experiments
bitcoin mining cloud mining
a private framework for
in the experiments was
private framework for distributed
the experiments was fixed
logsim returns the observed
experiments was fixed to
framework for distributed computation
returns the observed access
for distributed computation edward
the observed access latencies
distributed computation edward tremel
and ma rk jelasity
ma rk jelasity there
and all our experiments
all our experiments were
rk jelasity there is
our experiments were repeated
jelasity there is a
there is a growing
for the chosen set
is a growing class
the chosen set of
chosen set of configuration
a growing class of
set of configuration parameters
growing class of distributed
class of distributed systems
of distributed systems applications
confidence intervals were small
distributed systems applications in
systems applications in which
world traces for our
applications in which data
traces for our simulations
and for simplicity are
in which data stored
for simplicity are omitted
for our simulations from
simplicity are omitted from
which data stored on
are omitted from the
our simulations from a
omitted from the graphs
simulations from a web
data stored on client
stored on client platforms
on client platforms must
client platforms must be
server that serves images
platforms must be aggregated
that serves images from
must be aggregated or
serves images from a
be aggregated or analyzed
images from a database
aggregated or analyzed without
the source of the
or analyzed without revealing
source of the stream
analyzed without revealing private
of the stream has
without revealing private information
the stream has an
revealing private information to
stream has an upload
private information to the
has an upload capacity
information to the operator
an upload capacity of
upload capacity of four
capacity of four times
of four times the
four times the stream
times the stream rate
systems such as the
such as the smart
as the smart power
the smart power grid
control systems for energy
and is connected to
describes the characteristics of
the characteristics of a
characteristics of a sample
of a sample trace
and traffic analysis in
traffic analysis in large
analysis in large cities
in large cities all
while a true evaluation
large cities all depend
a true evaluation of
cities all depend on
true evaluation of the
other nodes have enough
all depend on the
evaluation of the feasibility
depend on the analysis
nodes have enough download
on the analysis of
of the feasibility and
the analysis of data
have enough download capacity
analysis of data supplied
the feasibility and efficacy
of data supplied by
enough download capacity to
data supplied by measurement
feasibility and efficacy of
supplied by measurement devices
download capacity to receive
and efficacy of our
capacity to receive the
efficacy of our solution
to receive the stream
of our solution can
our solution can only
yet the clients being
solution can only be
the clients being tracked
can only be achieved
and upload factor of
clients being tracked are
only be achieved through
being tracked are unwilling
be achieved through an
tracked are unwilling to
achieved through an actual
are unwilling to reveal
through an actual implementation
unwilling to reveal such
to reveal such measurement
reveal such measurement data
such measurement data directly
measurement data directly to
simulation provides an elegant
data directly to the
provides an elegant way
directly to the system
an elegant way to
to the system owner
elegant way to identify
we defined an availability
way to identify and
defined an availability window
to identify and explore
an availability window of
identify and explore some
and explore some of
who might be curious
explore some of the
might be curious about
some of the cost
be curious about private
curious about private client
about private client information
seconds and an interest
benefit tradeoffs in a
and an interest window
tradeoffs in a scaled
an interest window of
an authorization architecture for
these systems thus may
authorization architecture for trustworthy
systems thus may elicit
architecture for trustworthy computing
down version of our
thus may elicit public
version of our system
may elicit public opposition
elicit public opposition despite
to evaluate the quality
in proceedings of the
public opposition despite their
the mechanism we simulate
proceedings of the twenty
mechanism we simulate is
opposition despite their useful
we simulate is as
evaluate the quality of
simulate is as follows
despite their useful features
the quality of each
their useful features because
quality of each auditing
third acm symposium on
of each auditing strategy
useful features because of
acm symposium on operating
features because of a
symposium on operating systems
because of a perceived
on operating systems principles
of a perceived privacy
a perceived privacy risk
we evaluate the average
evaluate the average download
the average download factors
average download factors of
disks are assumed to
download factors of correct
are assumed to begin
factors of correct nodes
there are ways to
of correct nodes during
assumed to begin in
correct nodes during a
are ways to upload
to begin in the
ways to upload sensitive
begin in the on
to upload sensitive data
in the on state
upload sensitive data to
sensitive data to an
data to an aggregator
to an aggregator without
and an access count
an aggregator without compromising
aggregator without compromising privacy
second time interval after
time interval after auditing
interval after auditing is
after auditing is first
but existing options have
auditing is first applied
existing options have limitations
is first applied to
is maintained for each
first applied to the
maintained for each disk
applied to the system
one possibility is to
possibility is to keep
the user specifies the
is to keep the
user specifies the maximum
to keep the data
specifies the maximum percentage
keep the data encrypted
the data encrypted with
data encrypted with keys
encrypted with keys known
with keys known only
keys known only to
we considered that global
known only to the
considered that global auditors
only to the clients
that global auditors collected
of disks that are
global auditors collected information
disks that are kept
auditors collected information from
that are kept powered
are kept powered on
but this requires expensive
this requires expensive homomorphic
requires expensive homomorphic encryption
expensive homomorphic encryption if
homomorphic encryption if the
encryption if the aggregator
if the aggregator is
the aggregator is to
aggregator is to compute
is to compute directly
nodes between each interval
to compute directly on
between each interval of
compute directly on it
another is to employ
is to employ a
to employ a mechanism
employ a mechanism to
a mechanism to de
notice that the sample
that the sample size
the sample size does
correlate client identifiers from
sample size does not
client identifiers from their
size does not increase
identifiers from their data
does not increase with
a disk check process
not increase with the
disk check process scans
increase with the size
check process scans the
as chen et al
with the size of
process scans the access
the size of the
scans the access count
size of the system
the access count for
access count for each
count for each disk
for each disk and
each disk and powers
which is a positive
disk and powers down
is a positive aspect
and powers down all
a positive aspect of
powers down all but
positive aspect of the
down all but the
aspect of the auditing
all but the most
of the auditing approach
but this imposes restrictions
this imposes restrictions on
imposes restrictions on the
restrictions on the kind
on the kind of
the kind of aggregation
kind of aggregation that
of aggregation that can
as well as any
aggregation that can be
well as any disk
that can be done
we discuss the costs
as any disk which
discuss the costs involved
any disk which does
the costs involved in
disk which does not
costs involved in collecting
which does not have
involved in collecting these
does not have at
in collecting these samples
not have at least
have at least t
at least t access
it would be beneficial
least t access count
would be beneficial to
be beneficial to execute
beneficial to execute needed
to execute needed computation
execute needed computation directly
needed computation directly on
computation directly on the
directly on the client
on the client platforms
so that the system
that the system operator
the system operator or
miss results in an
system operator or analyst
results in an access
operator or analyst only
in an access to
or analyst only sees
an access to a
analyst only sees aggregate
access to a powered
only sees aggregate results
this approach would provide
approach would provide a
would provide a better
then this disk is
provide a better alternative
this disk is spun
a better alternative to
disk is spun up
better alternative to central
alternative to central aggregation
to central aggregation provided
central aggregation provided it
aggregation provided it is
to remain powered on
provided it is privacy
remain powered on until
powered on until the
on until the next
until the next disk
the next disk check
and there is a
there is a corresponding
is a corresponding latency
a corresponding latency penalty
a data aggregation system
data aggregation system based
aggregation system based on
system based on client
judicious choice of the
choice of the parameters
of the parameters m
side computation suggests a
the parameters m and
computation suggests a purely
parameters m and t
suggests a purely peer
m and t minimizes
and t minimizes the
t minimizes the probability
minimizes the probability of
the probability of this
number of false positives
probability of this occurrence
of false positives download
false positives download factor
which many systems have
many systems have used
systems have used to
have used to avoid
used to avoid centralized
to avoid centralized control
methodology we have proposed
we have proposed the
have proposed the use
proposed the use of
the use of lfs
use of lfs in
of lfs in lieu
lfs in lieu of
in lieu of ffs
or other conventional file
other conventional file systems
center scenarios to achieve
scenarios to achieve power
to achieve power conservation
for this idea to
this idea to be
idea to be accepted
on power splitting games
power splitting games in
two questions need to
splitting games in distributed
questions need to be
games in distributed computation
need to be answered
to be answered in
peer systems have problems
be answered in the
systems have problems of
answered in the affirmative
have problems of their
the case of bitcoin
problems of their own
case of bitcoin pooled
of bitcoin pooled mining
even if we set
if we set privacy
we set privacy concerns
set privacy concerns aside
by eschewing centralization entirely
does this new scheme
this new scheme result
new scheme result in
scheme result in significant
they can no longer
result in significant power
can no longer take
in significant power savings
no longer take advantage
longer take advantage of
take advantage of the
advantage of the powerful
of the powerful management
the powerful management tools
powerful management tools developed
management tools developed for
tools developed for today
developed for today s
for today s cloud
today s cloud computing
s cloud computing model
does this new scheme
this new scheme provide
new scheme provide comparable
scheme provide comparable performance
provide comparable performance to
comparable performance to existing
performance to existing schemes
clients are isolated network
are isolated network hosts
isolated network hosts rather
network hosts rather than
the answers to these
hosts rather than devices
answers to these questions
rather than devices within
to these questions must
than devices within a
these questions must be
devices within a single
questions must be largely
within a single administrative
must be largely applicationindependent
a single administrative domain
and must apply to
must apply to a
and often have difficulty
apply to a generic
often have difficulty maintaining
to a generic data
have difficulty maintaining connections
a generic data center
difficulty maintaining connections to
generic data center model
maintaining connections to each
connections to each other
to each other through
each other through firewalls
to address these questions
other through firewalls and
through firewalls and address
firewalls and address translation
and address translation barriers
we present a simulator
determining the membership of
the membership of a
membership of a peer
logsim consists of less
consists of less than
of less than a
less than a thousand
than a thousand lines
a thousand lines of
peer network is a
thousand lines of java
network is a surprisingly
lines of java code
is a surprisingly difficult
of java code and
a surprisingly difficult problem
java code and is
code and is a
and is a single
since there is no
there is no one
is no one entity
no one entity that
one entity that knows
entity that knows the
that knows the identities
knows the identities of
the identities of all
identities of all the
of all the clients
we must turn off
must turn off some
turn off some percentage
and changes in membership
off some percentage of
changes in membership may
some percentage of disks
in membership may not
percentage of disks in
membership may not be
of disks in the
may not be detected
disks in the storage
weekly bitcoin network statistics
in the storage system
not be detected and
be detected and propagated
detected and propagated in
and propagated in a
propagated in a timely
in a timely fashion
there are two opposing
are two opposing forces
two opposing forces at
opposing forces at play
forces at play here
a large number of
large number of powered
without a centralized service
on disks results in
a centralized service to
disks results in good
centralized service to assign
results in good performance
service to assign and
to assign and manage
assign and manage node
and manage node identities
but also low power
also low power savings
on the other hand
decreasing the number of
the number of powered
on disks incurs two
disks incurs two possible
incurs two possible penalties
peer system is extremely
system is extremely vulnerable
is extremely vulnerable to
extremely vulnerable to a
vulnerable to a few
to a few malicious
a few malicious peers
few malicious peers becoming
malicious peers becoming a
peers becoming a majority
becoming a majority of
a majority of the
majority of the apparent
of the apparent nodes
the apparent nodes in
apparent nodes in the
transitions consume power and
nodes in the system
consume power and thus
power and thus counter
and thus counter the
thus counter the potential
counter the potential savings
even choosing peers fairly
the potential savings achieved
choosing peers fairly becomes
potential savings achieved by
peers fairly becomes difficult
savings achieved by powered
because peers usually do
peers usually do not
usually do not store
do not store the
not store the entire
to find the optimal
store the entire membership
find the optimal percentage
the entire membership list
the optimal percentage of
entire membership list locally
optimal percentage of disks
percentage of disks to
of disks to be
disks to be powered
to be powered down
and it is fairly
it is fairly easy
is fairly easy for
we ran a set
fairly easy for malicious
ran a set of
easy for malicious peers
a set of simulations
for malicious peers to
set of simulations on
malicious peers to poison
of simulations on logsim
peers to poison local
simulations on logsim and
to poison local mem
on logsim and varied
poison local mem cornell
logsim and varied the
local mem cornell bership
and varied the number
mem cornell bership views
varied the number of
cornell bership views so
the number of disks
bership views so that
number of disks that
views so that they
of disks that we
so that they will
disks that we kept
that they will be
that we kept powered
they will be preferred
we kept powered up
will be preferred as
kept powered up from
be preferred as neighbors
powered up from none
preferred as neighbors by
as neighbors by honest
neighbors by honest nodes
quality of streaming when
of streaming when applying
streaming when applying the
when applying the fixed
applying the fixed threshold
the fixed threshold strategy
threshold is varied from
since neither completely centralized
neither completely centralized aggregation
completely centralized aggregation nor
centralized aggregation nor a
out of a total
aggregation nor a completely
of a total of
nor a completely peer
and the contribution rate
the contribution rate of
theoretic analysis of ddos
contribution rate of opportunistic
analysis of ddos attacks
peer system is adequate
of ddos attacks against
rate of opportunistic nodes
ddos attacks against bitcoin
system is adequate for
attacks against bitcoin mining
of opportunistic nodes is
against bitcoin mining pools
is adequate for our
opportunistic nodes is varied
adequate for our purposes
nodes is varied from
in workshop on bitcoin
workshop on bitcoin research
we explore a new
explore a new approach
a new approach that
new approach that combines
approach that combines the
that combines the features
combines the features of
the features of these
features of these two
of these two extremes
although the idea of
the idea of a
idea of a communication
of a communication system
a communication system that
communication system that combines
system that combines some
that combines some centralized
combines some centralized control
some centralized control with
centralized control with a
presents the average download
control with a peer
the average download factors
average download factors across
download factors across all
factors across all correct
across all correct nodes
peer overlay is not
overlay is not new
we are the first
are the first to
presents the number of
the first to use
the number of correct
first to use such
number of correct nodes
to use such a
of correct nodes incorrectly
use such a system
disks were kept powered
such a system to
correct nodes incorrectly punished
were kept powered up
a system to preserve
system to preserve privacy
to preserve privacy while
preserve privacy while computing
privacy while computing on
while computing on sensitive
computing on sensitive data
when bitcoin mining pools
bitcoin mining pools run
this combination is a
mining pools run dry
combination is a sensible
is a sensible tradeoff
a sensible tradeoff for
sensible tradeoff for the
tradeoff for the kinds
in workshop on bitcoin
for the kinds of
workshop on bitcoin research
the kinds of systems
we consider the use
kinds of systems we
consider the use of
of systems we target
the use of fixed
use of fixed thresholds
in which there is
which there is an
we studied the effects
there is an owner
studied the effects of
is an owner or
the effects of using
an owner or operator
effects of using different
owner or operator who
of using different values
or operator who can
using different values for
operator who can be
different values for t
who can be trusted
can be trusted to
be trusted to provide
trusted to provide basic
to provide basic services
provide basic services such
basic services such as
services such as node
such as node identification
as node identification and
node identification and membership
identification and membership tracking
and membership tracking but
membership tracking but not
and increasing it until
tracking but not to
but not to see
not to see non
comparison of mining pools
aggregated raw client data
we treat the system
treat the system operator
the system operator as
system operator as an
operator as an honest
of the stream rate
who will keep the
and present a detailed
will keep the system
present a detailed set
keep the system running
a detailed set of
comparison of mining pools
the system running correctly
detailed set of results
system running correctly but
set of results on
running correctly but cannot
of results on applying
correctly but cannot be
results on applying different
but cannot be allowed
on applying different thresholds
cannot be allowed to
applying different thresholds to
be allowed to see
different thresholds to different
allowed to see more
thresholds to different scenarios
to see more information
see more information than
more information than he
information than he or
than he or she
he or she needs
or she needs to
she needs to know
the ratio of opportunistic
ratio of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is fixed
nodes is fixed to
but their contribution factor
we introduce a method
introduce a method for
a method for constructing
method for constructing a
for constructing a communication
constructing a communication overlay
a communication overlay among
hashcash amortizable publicly auditable
communication overlay among the
amortizable publicly auditable cost
overlay among the client
among the client nodes
the client nodes that
client nodes that can
nodes that can safely
that can safely be
can safely be used
safely be used to
be used to perform
used to perform aggregation
to perform aggregation and
perform aggregation and computation
aggregation and computation on
and computation on private
computation on private data
although this overlay is
this overlay is set
overlay is set up
cdf number of accesses
is set up and
set up and operated
up and operated by
and operated by the
operated by the system
by the system owner
it provides minimal opportunity
provides minimal opportunity for
minimal opportunity for the
opportunity for the owner
for the owner to
the owner to learn
owner to learn any
to learn any information
learn any information about
any information about the
information about the data
about the data being
the data being aggregated
data being aggregated other
being aggregated other than
aggregated other than the
other than the final
than the final result
the final result of
final result of the
result of the computation
nodes follow the protocol
when combined with differential
combined with differential privacy
with differential privacy techniques
with a maximum contribution
a maximum contribution rate
maximum contribution rate set
contribution rate set to
to protect the aggregation
protect the aggregation results
the aggregation results themselves
it can be used
can be used to
be used to ensure
used to ensure that
to ensure that no
ensure that no query
that no query made
no query made to
query made to the
made to the system
to the system reveals
the system reveals the
system reveals the contribution
reveals the contribution of
the contribution of any
contribution of any particular
of any particular node
our overlay network looks
overlay network looks a
network looks a bit
looks a bit like
hashcash a denial of
a bit like a
a denial of service
bit like a gossip
denial of service counter
like a gossip infrastructure
we present the average
present the average download
the average download rates
and the number of
and can be used
the number of correct
can be used to
number of correct nodes
be used to run
of correct nodes mistakenly
used to run gossip
correct nodes mistakenly removed
nodes mistakenly removed from
mistakenly removed from the
removed from the system
with the key difference
the key difference that
key difference that the
difference that the random
that the random peer
the random peer selection
random peer selection of
peer selection of gossip
selection of gossip is
of gossip is replaced
gossip is replaced with
for each of these
is replaced with a
each of these configurations
replaced with a completely
with a completely deterministic
a completely deterministic function
the threshold applied is
threshold applied is presented
applied is presented on
nodes are assigned virtual
is presented on the
are assigned virtual ids
presented on the x
assigned virtual ids that
virtual ids that are
ids that are either
that are either integers
are either integers or
either integers or finite
integers or finite field
or finite field elements
in the left graph
and each node uses
as the threshold increases
each node uses a
node uses a function
uses a function based
higher download averages are
a function based on
download averages are observed
function based on either
based on either modular
on either modular arithmetic
either modular arithmetic or
since more opportunistic nodes
modular arithmetic or finite
more opportunistic nodes are
arithmetic or finite fields
opportunistic nodes are detected
or finite fields to
nodes are detected and
finite fields to compute
are detected and punished
fields to compute the
to compute the order
compute the order in
the order in which
order in which it
in which it should
which it should communicate
the number of nodes
it should communicate with
number of nodes incorrectly
should communicate with the
of nodes incorrectly accused
communicate with the other
nodes incorrectly accused also
with the other nodes
incorrectly accused also increases
accused also increases with
also increases with higher
increases with higher thresholds
we construct this function
construct this function to
as observed in the
this function to ensure
observed in the right
function to ensure that
in the right graph
to ensure that the
ensure that the network
that the network is
the network is optimally
on subversive miner strategies
scenarios where opportunistic nodes
network is optimally robust
where opportunistic nodes contribute
is optimally robust and
subversive miner strategies and
optimally robust and efficient
opportunistic nodes contribute at
miner strategies and block
nodes contribute at higher
strategies and block withholding
contribute at higher rates
and block withholding attack
converging in logarithmic time
block withholding attack in
in logarithmic time and
withholding attack in bitcoin
logarithmic time and tolerating
attack in bitcoin digital
time and tolerating message
in bitcoin digital currency
and tolerating message failures
tolerating message failures with
message failures with minimal
failures with minimal delay
are less disruptive to
key cryptography to encrypt
less disruptive to the
cryptography to encrypt messages
disruptive to the system
ensuring that the the
but they also require
that the the system
they also require higher
the the system operator
also require higher thresholds
the system operator cannot
require higher thresholds to
system operator cannot infer
higher thresholds to be
operator cannot infer anything
thresholds to be applied
cannot infer anything about
infer anything about the
anything about the data
about the data being
the data being aggregated
different thresholds yield best
data being aggregated by
thresholds yield best results
being aggregated by observing
yield best results under
aggregated by observing network
best results under different
by observing network traffic
results under different scenarios
even the communication pattern
the communication pattern is
effect of increasing percentage
communication pattern is completely
of increasing percentage of
from the results presented
pattern is completely predictable
the results presented in
increasing percentage of powered
results presented in figure
is completely predictable and
completely predictable and hence
predictable and hence reveals
and hence reveals nothing
up disks on performance
we concluded that the
concluded that the best
that the best fixed
the best fixed threshold
best fixed threshold is
malicious nodes cannot significantly
fixed threshold is t
nodes cannot significantly deviate
cannot significantly deviate from
significantly deviate from correct
effect of increasing percentage
deviate from correct behavior
of increasing percentage of
from correct behavior without
increasing percentage of powered
correct behavior without being
behavior without being detected
up disks on power
disks on power consumption
so the network encourages
on power consumption both
the network encourages the
power consumption both its
network encourages the operator
consumption both its performance
encourages the operator to
the operator to behave
operator to behave correctly
providing the best compromise
the best compromise in
as well as its
best compromise in terms
well as its power
compromise in terms of
and it even tolerates
in terms of performance
it even tolerates byzantine
terms of performance and
even tolerates byzantine failure
of performance and false
tolerates byzantine failure by
performance and false positives
byzantine failure by a
and false positives across
failure by a small
false positives across all
the former is measured
positives across all scenarios
by a small minority
former is measured using
a small minority of
how incentivize large bitcoin
small minority of clients
incentivize large bitcoin mining
is measured using the
large bitcoin mining http
measured using the observed
using the observed access
the observed access latencies
this ensures that important
ensures that important queries
that important queries will
important queries will not
while the latter is
we compare all three
queries will not be
compare all three strategies
the latter is measured
all three strategies proposed
will not be corrupted
three strategies proposed in
not be corrupted or
latter is measured by
be corrupted or blocked
strategies proposed in subsection
corrupted or blocked by
is measured by comparing
or blocked by compromised
measured by comparing the
blocked by compromised devices
by comparing the cumulative
comparing the cumulative percentage
the cumulative percentage of
cumulative percentage of time
percentage of time the
of time the disks
and that an adversary
time the disks are
that an adversary cannot
the disks are kept
against each other and
an adversary cannot compromise
each other and against
disks are kept powered
other and against a
are kept powered on
and against a configuration
adversary cannot compromise the
against a configuration with
cannot compromise the privacy
a configuration with no
compromise the privacy of
as well as the
configuration with no auditing
well as the number
the privacy of client
as the number of
privacy of client data
the number of mode
of client data by
client data by gaining
data by gaining control
by gaining control of
gaining control of a
control of a few
of a few devices
a few devices in
few devices in the
devices in the system
for the fixed threshold
the fixed threshold strategy
fixed threshold strategy and
threshold strategy and as
strategy and as the
and as the initial
show the results of
as the initial threshold
the results of these
the initial threshold in
results of these simulations
initial threshold in the
threshold in the stepwise
in the stepwise adaptive
the stepwise adaptive strategy
we summarize the three
summarize the three strategies
ro bert orma ndi
the three strategies in
three strategies in table
istva n hegedu s
of the disks powered
the disks powered on
we simulated sessions where
and ma rk jelasity
gossip learning with linear
learning with linear models
with linear models on
linear models on fully
models on fully distributed
on fully distributed this
fully distributed this work
of the nodes were
distributed this work was
the nodes were opportunistic
this work was supported
nodes were opportunistic and
were opportunistic and with
opportunistic and with varying
of the disks can
and with varying ratios
the disks can be
with varying ratios of
disks can be spun
varying ratios of contribution
can be spun down
by a grant from
be spun down while
a grant from the
spun down while still
grant from the nsf
down while still maintaining
from the nsf data
while still maintaining performance
still maintaining performance comparable
maintaining performance comparable to
performance comparable to that
comparable to that of
to that of a
the contribution rate of
that of a conventional
contribution rate of opportunistic
of a conventional file
rate of opportunistic nodes
a conventional file system
practice and exsmart grids
of opportunistic nodes is
and exsmart grids program
opportunistic nodes is varied
nodes is varied from
the performance of our
performance of our system
of our system depends
our system depends very
system depends very heavily
depends very heavily on
very heavily on its
heavily on its cache
on its cache configuration
since cache optimization is
cache optimization is an
all other nodes are
optimization is an orthogonal
other nodes are correct
is an orthogonal issue
an orthogonal issue that
orthogonal issue that comprises
issue that comprises an
contributing at a maximum
that comprises an entire
at a maximum rate
comprises an entire field
a maximum rate of
an entire field of
entire field of research
field of research in
of research in itself
it is important to
is important to isolate
important to isolate its
to isolate its effect
isolate its effect on
its effect on performance
we present both the
present both the average
both the average and
the average and the
average and the minimum
we implemented an ideal
and the minimum download
implemented an ideal cache
the minimum download factors
an ideal cache algorithm
minimum download factors across
download factors across all
factors across all correct
across all correct nodes
all correct nodes in
which we term the
correct nodes in the
we term the oracle
nodes in the system
this data point represents
as the contribution rate
data point represents the
the contribution rate of
contribution rate of opportunistic
rate of opportunistic nodes
point represents the best
of opportunistic nodes increases
represents the best performance
the best performance we
best performance we could
the download factors are
performance we could achieve
download factors are expected
we could achieve since
factors are expected to
could achieve since an
are expected to increase
achieve since an oracle
since an oracle has
an oracle has future
oracle has future knowledge
which is clear from
has future knowledge and
is clear from the
future knowledge and is
clear from the curves
knowledge and is able
from the curves presented
and is able to
antony rowstron and peter
is able to replace
rowstron and peter druschel
able to replace items
to replace items accessed
strategy no auditing fixed
replace items accessed furthest
no auditing fixed threshold
items accessed furthest in
auditing fixed threshold stepwise
accessed furthest in the
fixed threshold stepwise adaptive
furthest in the future
threshold stepwise adaptive percentile
based adaptive description fixed
adaptive description fixed t
and routing for large
we also wish to
also wish to provide
wish to provide a
to provide a performance
provide a performance comparison
a performance comparison of
performance comparison of our
comparison of our system
of our system against
our system against conventional
as an approximation of
an approximation of such
approximation of such a
of such a system
we implemented a random
implemented a random placement
a random placement algorithm
if avg sampled download
which maps each block
avg sampled download factor
maps each block to
each block to a
block to a random
to a random disk
all disks are kept
disks are kept powered
are kept powered up
having set the context
let us examine fig
decrease t back to
when avg download is
avg download is satisfactory
download is satisfactory again
the additional two data
points described above are
described above are represented
above are represented in
are represented in fig
correctness of a gossip
of a gossip based
a gossip based membership
gossip based membership protocol
in proceedings of the
proceedings of the twenty
if avg sampled download
avg sampled download factor
fourth annual acm sympo
t is chosen based
is chosen based on
chosen based on sampled
based on sampled upload
on sampled upload factors
and ma rk jelasity
a private framework for
private framework for distributed
framework for distributed comsium
for distributed comsium on
distributed comsium on principles
comsium on principles of
on principles of distributed
principles of distributed computing
if we imagine a
we imagine a line
imagine a line at
a line at y
strategies used for defining
used for defining the
for defining the minimum
defining the minimum upload
the minimum upload threshold
minimum upload threshold t
upload threshold t figure
shows that all strategies
that all strategies yield
all strategies yield significantly
strategies yield significantly better
yield significantly better results
significantly better results compared
better results compared to
results compared to an
compared to an approach
to an approach with
an approach with no
approach with no auditing
while both adaptive strategies
both adaptive strategies yield
adaptive strategies yield excellent
strategies yield excellent download
yield excellent download rates
excellent download rates to
download rates to correct
rates to correct nodes
of the accesses live
the accesses live above
the fixed threshold strategy
accesses live above this
fixed threshold strategy s
live above this line
threshold strategy s performance
strategy s performance is
s performance is not
performance is not as
is not as good
not as good when
as good when opportunistic
good when opportunistic nodes
when opportunistic nodes are
opportunistic nodes are contributing
nodes are contributing with
disks on is the
on is the third
is the third best
the third best configuration
next only to the
only to the oracle
to the oracle and
or slightly more kbps
the performance degradation in
performance degradation in going
degradation in going from
at those rates opportunistic
those rates opportunistic nodes
rates opportunistic nodes are
opportunistic nodes are harmful
nodes are harmful to
are harmful to the
harmful to the system
yet the fixed threshold
the fixed threshold of
uniform node sampling service
node sampling service robust
sampling service robust against
service robust against collusions
robust against collusions of
against collusions of malicious
is not able to
collusions of malicious nodes
not able to detect
able to detect them
disks on is negligibly
on is negligibly small
for the system under
the system under test
we consider a scenario
consider a scenario where
the optimal configuration is
a scenario where opportunistic
optimal configuration is to
scenario where opportunistic nodes
configuration is to fig
where opportunistic nodes contribute
opportunistic nodes contribute with
nodes contribute with different
contribute with different rates
ifip international conference on
international conference on dependable
conference on dependable systems
on dependable systems and
dependable systems and networks
shows an estimate of
we varied the percentage
an estimate of the
varied the percentage of
estimate of the actual
the percentage of opportunistic
of the actual power
percentage of opportunistic nodes
the actual power savings
of opportunistic nodes in
actual power savings achieved
opportunistic nodes in the
power savings achieved by
nodes in the system
savings achieved by our
in the system from
achieved by our solution
we assume the following
assume the following disk
the following disk specifications
and evenly assigned them
evenly assigned them different
assigned them different contribution
them different contribution rates
the graphs present the
graphs present the average
present the average and
the average and minimum
average and minimum download
and minimum download rates
minimum download rates for
download rates for these
rates for these scenarios
no auditing performs significantly
auditing performs significantly worse
performs significantly worse than
significantly worse than any
worse than any of
than any of the
any of the proposed
of the proposed strategies
the stepwise adaptive approach
stepwise adaptive approach yields
adaptive approach yields the
approach yields the best
yields the best results
the best results when
best results when large
results when large percentages
when large percentages of
large percentages of opportunistic
percentages of opportunistic nodes
byzantine resilient random membership
of opportunistic nodes are
resilient random membership sampling
opportunistic nodes are present
nodes are present in
are present in the
present in the system
in proceedings of the
proceedings of the twenty
it is also simpler
is also simpler than
also simpler than the
simpler than the percentile
seventh acm symposium on
acm symposium on principles
avg time for transition
symposium on principles of
on principles of distributed
principles of distributed computing
since it is based
it is based only
is based only on
based only on samples
only on samples of
on samples of the
samples of the download
of the download rates
we see that turning
the download rates of
see that turning off
download rates of nodes
in both sets of
both sets of experiments
the number of false
number of false positives
of the disks results
of false positives was
the disks results in
false positives was practically
positives was practically null
was practically null under
practically null under all
null under all three
under all three strategies
all three strategies considered
at most one in
managed transactional consistency for
most one in some
one in some cases
transactional consistency for web
consistency for web caching
for web caching ittay
web caching ittay eyal
caching ittay eyal ken
ittay eyal ken birman
eyal ken birman robbert
ken birman robbert van
birman robbert van renesse
robbert van renesse cornell
van renesse cornell university
renesse cornell university abstract
cornell university abstract in
with all the disks
all the disks off
while maintaining acceptable performance
auditing costs the overheads
only caches are widely
costs the overheads imposed
caches are widely used
the overheads imposed by
are widely used in
overheads imposed by auditing
widely used in cloud
imposed by auditing are
used in cloud infrastructure
by auditing are an
in cloud infrastructure to
auditing are an important
cloud infrastructure to reduce
are an important consideration
infrastructure to reduce access
to reduce access latency
shows some of the
reduce access latency and
some of the tradeoffs
access latency and to
of the tradeoffs involved
latency and to reduce
which we address in
and to reduce load
we address in this
to reduce load on
address in this subsection
note that the y
reduce load on backend
load on backend databases
most of the work
axis represents three different
of the work of
represents three different quantities
the work of auditing
operators view coherent caches
work of auditing is
view coherent caches as
of auditing is performed
coherent caches as impractical
auditing is performed by
caches as impractical at
is performed by local
the cumulative percentage of
performed by local auditors
as impractical at genuinely
cumulative percentage of time
impractical at genuinely large
percentage of time the
at genuinely large scale
of time the disks
genuinely large scale and
time the disks are
large scale and many
the disks are powered
scale and many client
disks are powered on
in proceedings of the
which are executed on
proceedings of the acm
are executed on the
of the acm sigcomm
executed on the user
on the user nodes
facing caches are updated
the total duration of
caches are updated in
total duration of the
are updated in an
duration of the simulation
updated in an asynchronous
the overhead is constant
in an asynchronous manner
an asynchronous manner with
asynchronous manner with best
independent of the size
of the size of
the size of the
size of the system
and the cumulative number
the cumulative number of
existing solutions that support
cumulative number of mode
and is not significant
solutions that support cache
that support cache consistency
support cache consistency are
transitions that the disks
cache consistency are inapplicable
that the disks undergo
since nodes only exchange
consistency are inapplicable to
nodes only exchange a
are inapplicable to this
only exchange a small
inapplicable to this scenario
exchange a small amount
to this scenario since
a small amount of
this scenario since they
small amount of accounting
scenario since they require
amount of accounting data
since they require a
of accounting data at
they require a round
both the total duration
require a round trip
the total duration of
accounting data at pre
total duration of the
a round trip to
duration of the experiment
round trip to the
trip to the database
to the database on
defined intervals of time
the database on every
as well as the
database on every cache
well as the number
on every cache transaction
as the number of
the number of mode
existing incoherent cache technologies
incoherent cache technologies are
cache technologies are oblivious
increase as the percentage
technologies are oblivious to
as the percentage of
are oblivious to transactional
the percentage of disks
oblivious to transactional data
percentage of disks that
to transactional data access
of disks that is
disks that is powered
that is powered on
is powered on is
if we consider a
powered on is decreased
we consider a packet
even if the backend
consider a packet rate
if the backend database
a packet rate of
the backend database supports
backend database supports transactions
we see that keeping
aware cache for read
seconds the maximum number
the maximum number of
maximum number of packets
number of packets received
of packets received and
disks on strikes an
packets received and sent
on strikes an acceptable
received and sent by
strikes an acceptable balance
and sent by each
sent by each node
by each node is
cache improves cache consistency
improves cache consistency despite
cache consistency despite asynchronous
consistency despite asynchronous and
despite asynchronous and unreliable
conclusion in this paper
asynchronous and unreliable communication
and unreliable communication between
unreliable communication between the
communication between the cache
between the cache and
we point out a
the cache and the
point out a new
cache and the database
out a new opportunity
a new opportunity for
new opportunity for saving
opportunity for saving power
for saving power in
for each packet sent
saving power in large
each packet sent or
packet sent or received
the history needs to
history needs to indicate
the idea is elegant
needs to indicate which
idea is elegant in
a variant of serializability
is elegant in its
to indicate which neighbor
elegant in its simplicity
variant of serializability that
indicate which neighbor sent
of serializability that is
which neighbor sent or
serializability that is suitable
neighbor sent or received
that is suitable for
epidemic algorithms for replicated
sent or received the
algorithms for replicated database
or received the packet
for replicated database maintenance
is suitable for incoherent
log structured file systems
suitable for incoherent caches
structured file systems write
file systems write only
in proceedings of the
systems write only to
proceedings of the sixth
write only to the
of the sixth annual
only to the log
and prove that with
to the log head
the sixth annual acm
bits to identify each
sixth annual acm symposium
to identify each neighbor
annual acm symposium on
prove that with unbounded
acm symposium on principles
that with unbounded resources
symposium on principles of
with unbounded resources t
on principles of distributed
principles of distributed computing
the history s size
if read accesses are
history s size adds
read accesses are served
s size adds up
accesses are served by
size adds up to
are served by the
served by the cache
then write accesses touch
write accesses touch only
accesses touch only the
touch only the log
only the log head
the log head disk
cache allows the system
allows the system manager
the system manager to
system manager to choose
manager to choose a
potentially allowing us to
to choose a trade
allowing us to power
us to power down
to power down all
power down all the
down all the other
all the other disks
off between performance and
between performance and consistency
existing solutions like disk
solutions like disk management
our evaluation shows that
like disk management solutions
evaluation shows that t
this is not significant
cache detects many inconsistencies
is not significant compared
detects many inconsistencies with
not significant compared to
many inconsistencies with only
significant compared to the
inconsistencies with only nominal
compared to the amount
with only nominal overhead
to the amount of
the amount of regular
amount of regular data
of regular data exchanged
regular data exchanged in
we use synthetic workloads
data exchanged in a
use synthetic workloads to
exchanged in a streaming
synthetic workloads to demonstrate
in a streaming session
workloads to demonstrate the
to demonstrate the efficacy
demonstrate the efficacy of
the efficacy of t
we also analyzed the
also analyzed the costs
analyzed the costs of
the costs of the
cache when data accesses
costs of the global
when data accesses are
of the global auditors
data accesses are clustered
the working set model
accesses are clustered and
working set model for
are clustered and its
set model for program
clustered and its adaptive
model for program behavior
since they are dedicated
and its adaptive reaction
they are dedicated and
its adaptive reaction to
are dedicated and external
adaptive reaction to workload
dedicated and external to
reaction to workload changes
and external to the
external to the system
with workloads based on
workloads based on the
based on the real
the overhead imposed by
overhead imposed by them
imposed by them is
by them is of
them is of higher
is of higher concern
global auditors main tasks
auditors main tasks consist
main tasks consist of
tasks consist of sampling
consist of sampling the
of sampling the system
sampling the system to
the system to collect
system to collect download
to collect download and
collect download and upload
download and upload rates
and upload rates of
upload rates of nodes
and of occasionally disseminating
of occasionally disseminating updates
occasionally disseminating updates to
disseminating updates to the
of the inconsistencies and
updates to the threshold
the inconsistencies and increases
to the threshold value
inconsistencies and increases the
and increases the rate
increases the rate of
the rate of consistent
rate of consistent transactions
of consistent transactions by
the sample size remains
in lecture notes in
sample size remains fixed
lecture notes in computer
size remains fixed independent
notes in computer science
remains fixed independent of
fixed independent of the
independent of the size
of the size of
the size of the
size of the population
we ran simulations to
ran simulations to estimate
simulations to estimate the
to estimate the worst
case standard deviation of
standard deviation of the
deviation of the download
of the download rates
the download rates across
download rates across all
rates across all nodes
time disks on num
i ntroduction internet services
ntroduction internet services like
internet services like online
services like online retailers
transitions total time of
like online retailers and
we estimate that a
online retailers and social
estimate that a sample
total time of run
that a sample size
retailers and social networks
a sample size of
and social networks store
social networks store important
networks store important data
store important data sets
important data sets in
data sets in large
sets in large distributed
in large distributed databases
nodes is sufficient to
is sufficient to provide
technical challenges have forced
challenges have forced such
have forced such large
system operators to forgo
operators to forgo transactional
independent of the population
to forgo transactional consistency
of the population size
providing perobject consistency instead
such as the ones
often with some form
as the ones simulated
with some form of
the ones simulated in
some form of eventual
ones simulated in this
form of eventual consistency
simulated in this work
even a smaller number
a smaller number of
improving the performance of
smaller number of samples
the performance of log
number of samples was
of samples was found
samples was found to
was found to be
found to be sufficient
structured file systems with
to be sufficient to
file systems with adaptive
be sufficient to yield
systems with adaptive methods
sufficient to yield satisfactory
to yield satisfactory results
centralized costs are fixed
and provide a clear
provide a clear advantage
a clear advantage for
clear advantage for using
advantage for using auditing
for using auditing against
using auditing against tit
tat approaches in large
support transactions with guarantees
transactions with guarantees such
with guarantees such as
guarantees such as snapshot
heterogenous systems so far
such as snapshot isolation
systems so far we
as snapshot isolation and
so far we considered
snapshot isolation and even
far we considered the
isolation and even full
we considered the use
and even full transactional
considered the use of
even full transactional atomicity
the use of auditing
use of auditing to
of auditing to enforce
auditing to enforce node
our work begins with
to enforce node contribution
work begins with the
enforce node contribution in
begins with the observation
node contribution in systems
with the observation that
contribution in systems where
in systems where all
systems where all nodes
where all nodes are
all nodes are assumed
nodes are assumed to
are assumed to have
assumed to have homogeneous
to have homogeneous bandwidth
it can be difficult
have homogeneous bandwidth resources
can be difficult for
be difficult for client
enough to upload and
to upload and download
tier applications to leverage
upload and download at
and download at a
applications to leverage the
download at a rate
to leverage the transactions
at a rate close
leverage the transactions that
a rate close to
the transactions that the
rate close to the
transactions that the databases
close to the stream
that the databases provide
to the stream rate
their reads are satisfied
pullbased streaming may be
reads are satisfied primarily
streaming may be extended
are satisfied primarily from
reducing energy consumption of
satisfied primarily from incoherent
may be extended to
primarily from incoherent cache
energy consumption of disk
be extended to heterogenous
consumption of disk storage
extended to heterogenous systems
of disk storage using
to heterogenous systems by
disk storage using power
the benefits of caching
heterogenous systems by organizing
benefits of caching are
systems by organizing nodes
of caching are twofold
by organizing nodes into
organizing nodes into multiple
nodes into multiple groups
it reduces database load
thereby enabling higher throughput
based fast overlay topology
fast overlay topology construction
the caches are typically
caches are typically placed
are typically placed close
typically placed close to
placed close to the
close to the clients
the problem centers on
problem centers on the
centers on the asynchronous
on the asynchronous style
the asynchronous style of
asynchronous style of communication
style of communication used
of communication used between
communication used between the
used between the database
no auditing fixed threshold
between the database and
auditing fixed threshold stepwise
the database and the
fixed threshold stepwise percentile
database and the geo
a cache should not
cache should not access
should not access the
not access the database
access the database on
the database on every
database on every transaction
any approach requiring a
avg download factor min
approach requiring a high
download factor min download
requiring a high rate
factor min download factor
a high rate of
high rate of round
trips to an authoritative
to an authoritative backend
an authoritative backend database
authoritative backend database would
backend database would cause
database would cause unacceptable
would cause unacceptable latency
a cache must respond
cache must respond instantly
and asynchronous updates rule
asynchronous updates rule out
updates rule out cache
rule out cache coherency
out cache coherency schemes
cache coherency schemes that
coherency schemes that would
schemes that would require
that would require the
would require the backend
require the backend database
the backend database to
no auditing fixed threshold
backend database to promptly
auditing fixed threshold stepwise
database to promptly invalidate
fixed threshold stepwise percentile
to promptly invalidate or
promptly invalidate or update
invalidate or update cached
or update cached this
update cached this work
cached this work is
this work is supported
and maarten van steen
effect of increasing percentage
of increasing percentage of
increasing percentage of powered
by a grant from
a grant from the
grant from the darpa
from the darpa mrc
up disks on power
the darpa mrc program
disks on power and
on power and time
and caching solutions are
caching solutions are typically
solutions are typically application
or even to track
even to track the
to track the locations
track the locations at
the locations at which
locations at which cached
at which cached objects
which cached objects reside
we define a variant
on the other hand
define a variant of
a variant of serializability
variant of serializability called
of serializability called cacheserializability
is applicable to any
serializability called cacheserializability that
applicable to any cacheable
called cacheserializability that is
to any cacheable dataset
cacheserializability that is suitable
that is suitable for
is suitable for incoherent
suitable for incoherent caches
since existing solutions are
existing solutions are typically
solutions are typically layered
a wide range of
are typically layered on
wide range of web
typically layered on top
range of web applications
layered on top of
on top of the
top of the file
from social networks to
social networks to online
networks to online retailers
they could be used
settle for caches that
could be used in
for caches that are
be used in conjunction
caches that are oblivious
used in conjunction with
that are oblivious to
in conjunction with our
are oblivious to transactions
conjunction with our solution
with our solution to
our solution to take
solution to take advantage
to take advantage of
take advantage of application
despite the fact that
the fact that an
fact that an inconsistent
that an inconsistent read
an inconsistent read access
inconsistent read access can
read access can deter
access can deter a
can deter a client
we also provide some
deter a client and
also provide some initial
a client and reduce
provide some initial simulation
client and reduce their
some initial simulation results
and reduce their income
initial simulation results that
simulation results that validate
results that validate our
that validate our claim
validate our claim that
our claim that power
they cannot afford consistent
cannot afford consistent cache
afford consistent cache techniques
consistent cache techniques that
savings are possible using
cache techniques that require
are possible using a
techniques that require backend
possible using a log
that require backend accesses
require backend accesses on
backend accesses on every
accesses on every transaction
while simulations can never
simulations can never provide
can never provide conclusive
upload rate of opportunistic
never provide conclusive evidence
rate of opportunistic nodes
provide conclusive evidence for
conclusive evidence for the
evidence for the feasibility
a novel caching scheme
for the feasibility of
novel caching scheme that
the feasibility of a
caching scheme that improves
feasibility of a system
scheme that improves consistency
that improves consistency at
improves consistency at the
consistency at the cache
they are an effective
at the cache level
are an effective means
the cache level with
an effective means to
cache level with a
effective means to identify
level with a nominal
means to identify promising
with a nominal storage
to identify promising solutions
a nominal storage and
nominal storage and communication
storage and communication tradeoff
our principal contribution in
principal contribution in this
contribution in this paper
in this paper is
this paper is in
paper is in having
is in having shown
cache significantly improves consistency
in having shown a
significantly improves consistency for
having shown a new
improves consistency for workloads
shown a new fit
consistency for workloads where
a new fit for
for workloads where data
new fit for an
workloads where data accesses
fit for an old
where data accesses are
for an old idea
data accesses are clustered
we believe that the
which is common in
believe that the log
is common in today
common in today s
in today s large
structured file system shows
file system shows promise
system shows promise as
shows promise as a
promise as a powersaving
as a powersaving opportunity
a powersaving opportunity for
this is achieved while
powersaving opportunity for large
is achieved while retaining
achieved while retaining the
while retaining the global
retaining the global scalability
the global scalability afforded
global scalability afforded by
scalability afforded by executing
afforded by executing read
acknowledgments this work was
this work was partially
work was partially funded
only transactions on the
was partially funded by
transactions on the edge
partially funded by intel
funded by intel corporation
by intel corporation and
intel corporation and the
corporation and the national
directly from the cache
and the national science
the national science foundation
we do this by
do this by storing
special thanks to saikat
this by storing dependency
thanks to saikat guha
by storing dependency information
to saikat guha for
storing dependency information with
saikat guha for his
dependency information with the
guha for his input
information with the cached
for his input in
with the cached objects
his input in the
input in the simulator
in the simulator design
we also wish to
also wish to thank
wish to thank our
to thank our anonymous
thank our anonymous reviewers
our anonymous reviewers for
to identify possible inconsistencies
anonymous reviewers for their
identify possible inconsistencies without
reviewers for their valuable
possible inconsistencies without contacting
for their valuable feedback
inconsistencies without contacting the
without contacting the database
upload rate of opportunistic
rate of opportunistic nodes
the user can improve
user can improve the
can improve the level
improve the level of
the level of consistency
level of consistency by
of consistency by adjusting
consistency by adjusting the
by adjusting the size
adjusting the size of
the size of this
size of this dependency
of this dependency data
minimum and average download
and average download factors
average download factors across
more dependency data leads
download factors across all
dependency data leads to
factors across all correct
data leads to increased
across all correct nodes
leads to increased consistency
all correct nodes when
correct nodes when using
nodes when using different
when using different strategies
using different strategies for
to demonstrate the efficacy
different strategies for choosing
demonstrate the efficacy of
strategies for choosing the
conserving disk energy in
for choosing the threshold
disk energy in network
the efficacy of the
energy in network servers
efficacy of the proposed
of the proposed scheme
the upload contribution rate
upload contribution rate of
contribution rate of opportunistic
rate of opportunistic nodes
we created a prototype
of opportunistic nodes is
created a prototype implementation
opportunistic nodes is varied
a prototype implementation and
nodes is varied in
prototype implementation and exposed
is varied in the
implementation and exposed it
varied in the x
and exposed it to
exposed it to workloads
it to workloads based
to workloads based on
workloads based on graphically
and the number of
th international conference on
the number of opportunistic
international conference on supercomputing
number of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is fixed
nodes is fixed at
such as those seen
as those seen in
those seen in social
avg download factor min
download factor min download
factor min download factor
of the inconsistencies and
the inconsistencies and can
inconsistencies and can increase
and can increase the
can increase the ratio
increase the ratio of
the ratio of consistent
ratio of consistent transactions
of consistent transactions by
the case for massive
case for massive arrays
for massive arrays of
massive arrays of idle
arrays of idle disks
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise percentile
both with low overhead
we construct synthetic workloads
construct synthetic workloads and
synthetic workloads and observe
workloads and observe how
and observe how t
conference on file and
on file and storage
cache reacts to different
file and storage technologies
reacts to different clustering
to different clustering levels
different clustering levels and
clustering levels and how
levels and how it
and how it adapts
how it adapts as
it adapts as clusters
adapts as clusters change
with perfectly clustered workloads
cache implements full cache
no auditing fixed threshold
auditing fixed threshold stepwise
to explain this perfect
fixed threshold stepwise percentile
explain this perfect behavior
this perfect behavior we
perfect behavior we prove
behavior we prove a
we prove a related
prove a related claim
a related claim we
related claim we show
claim we show that
we show that with
show that with unbounded
that with unbounded resources
with unbounded resources t
helping disk arrays sleep
disk arrays sleep through
arrays sleep through the
sleep through the winter
the contributions of this
contributions of this work
of this work are
proceedings of the twentieth
of the twentieth acm
the twentieth acm symposium
twentieth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
a variant of serializability
variant of serializability suitable
of serializability suitable for
serializability suitable for incoherent
suitable for incoherent caches
which allows trading off
allows trading off efficiency
trading off efficiency and
off efficiency and transaction
consistency in large scale
in large scale cache
large scale cache deployments
interplay of energy and
of energy and performance
energy and performance for
and performance for disk
performance for disk arrays
for disk arrays running
disk arrays running transaction
arrays running transaction processing
running transaction processing workloads
cache with synthetic workloads
in ieee international symposium
ieee international symposium on
international symposium on performance
symposium on performance analysis
on performance analysis of
demonstrating its adaptivity and
performance analysis of systems
its adaptivity and sensitivity
analysis of systems and
adaptivity and sensitivity to
of systems and software
and sensitivity to clustering
cache with workloads based
with workloads based on
workloads based on graphically
world data demonstrating detection
data demonstrating detection rates
demonstrating detection rates of
and consistency improvements of
reducing disk power consumption
disk power consumption in
power consumption in servers
consumption in servers with
in servers with drpm
cache with unbounded resources
with unbounded resources implements
unbounded resources implements cache
the complexity of implementing
complexity of implementing geo
scale databases with strong
hiding in plain sight
databases with strong guarantees
with strong guarantees initially
strong guarantees initially led
guarantees initially led companies
initially led companies to
google seeks more power
led companies to abandon
companies to abandon cross
in the new york
ratio of freeloaders figure
the new york times
object consistency altogether and
consistency altogether and make
altogether and make do
and make do with
make do with weak
do with weak guarantees
with weak guarantees such
weak guarantees such as
guarantees such as per
minimum and average download
object atomicity or eventual
and average download factors
atomicity or eventual consistency
average download factors across
download factors across all
factors across all correct
across all correct nodes
all correct nodes when
correct nodes when using
nodes when using different
when using different strategies
using different strategies for
such systems do repair
different strategies for choosing
systems do repair any
strategies for choosing the
do repair any problems
for choosing the threshold
repair any problems that
any problems that arise
each session has mixed
session has mixed set
has mixed set of
mixed set of opportunistic
set of opportunistic nodes
contributing at different rates
user is sometimes exposed
is sometimes exposed to
sometimes exposed to inconsistency
and percentage of opportunistic
percentage of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is varied
for some applications this
nodes is varied on
some applications this is
is varied on the
applications this is acceptable
varied on the x
berkeley db java edition
and the approach has
db java edition architecture
the approach has been
approach has been surprisingly
has been surprisingly successful
to their upload bandwidths
an oracle white paper
in today s cloud
nodes able to upload
able to upload at
to upload at a
upload at a rate
relaxed consistency is something
at a rate higher
consistency is something of
a rate higher than
is something of a
rate higher than the
something of a credo
higher than the stream
than the stream rate
the stream rate are
stream rate are placed
rate are placed in
are placed in higher
which are closer to
are closer to the
closer to the source
the source sends data
source sends data to
sends data to the
data to the highest
to the highest level
the highest level group
highest level group only
only transactions by accessing
transactions by accessing caches
who uses the basic
uses the basic protocol
the basic protocol to
which receive their values
basic protocol to disseminate
receive their values by
protocol to disseminate data
their values by reading
to disseminate data among
values by reading from
disseminate data among each
by reading from the
data among each other
reading from the database
nodes in lower levels
in lower levels may
lower levels may receive
levels may receive data
may receive data at
receive data at smaller
data at smaller rates
update transactions go directly
transactions go directly to
go directly to the
after some filtering is
directly to the database
some filtering is applied
eduardo pinheiro and ricardo
level nodes may be
pinheiro and ricardo bianchini
nodes may be used
may be used to
subsequent cache invalidations can
be used to act
cache invalidations can be
used to act as
invalidations can be delayed
energy conservation techniques for
can be delayed or
conservation techniques for disk
be delayed or even
techniques for disk array
to act as sources
delayed or even lost
act as sources to
or even lost due
as sources to the
even lost due to
sources to the lower
lost due to race
due to race conditions
alleviating the burden at
leading to a potentially
the burden at the
to a potentially inconsistent
burden at the source
a potentially inconsistent view
potentially inconsistent view by
inconsistent view by the
view by the cache
by the cache clients
auditing can be used
can be used to
be used to avoid
used to avoid the
to avoid the presence
th annual international conference
avoid the presence of
annual international conference on
the presence of opportunistic
international conference on supercomputing
presence of opportunistic and
of opportunistic and lower
opportunistic and lower bandwidth
and lower bandwidth nodes
lower bandwidth nodes in
bandwidth nodes in the
nodes in the higher
large internet services store
internet services store vast
services store vast amounts
store vast amounts of
vast amounts of data
it can ensure that
can ensure that the
ensure that the hierarchy
that the hierarchy of
the hierarchy of nodes
online retailers such as
hierarchy of nodes is
retailers such as amazon
of nodes is obeyed
such as amazon and
nodes is obeyed by
as amazon and ebay
is obeyed by all
amazon and ebay maintain
obeyed by all nodes
and ebay maintain product
ebay maintain product stocks
maintain product stocks and
product stocks and information
while allowing the system
allowing the system to
the system to leverage
and social networking sites
system to leverage additional
social networking sites such
to leverage additional resources
networking sites such as
leverage additional resources from
sites such as facebook
additional resources from privileged
such as facebook and
resources from privileged altruistic
as facebook and twitter
from privileged altruistic nodes
facebook and twitter maintain
privileged altruistic nodes to
and twitter maintain graphical
altruistic nodes to forward
characteristics of file system
nodes to forward data
of file system workloads
to forward data to
twitter maintain graphical databases
forward data to lower
data to lower level
maintain graphical databases representing
to lower level groups
graphical databases representing user
databases representing user relations
representing user relations and
user relations and group
relations and group structures
we intend to explore
intend to explore this
to explore this further
explore this further in
this further in future
further in future work
such databases are sharded
related work several p
databases are sharded and
are sharded and replicated
the vast majority of
vast majority of accesses
majority of accesses are
streaming protocols have been
of accesses are read
protocols have been previously
have been previously proposed
the first generation of
first generation of systems
mendel rosenblum and john
rosenblum and john k
the design and implementation
design and implementation of
and implementation of a
implementation of a log
relied on approaches based
on approaches based on
approaches based on pushing
based on pushing data
acm transactions on computer
on pushing data through
transactions on computer systems
pushing data through a
data through a single
through a single dissemination
a single dissemination tree
later approaches focused on
approaches focused on improving
focused on improving fairness
on improving fairness among
improving fairness among peers
fairness among peers and
among peers and resilience
peers and resilience to
and resilience to churn
resilience to churn by
to churn by breaking
churn by breaking data
by breaking data into
breaking data into multiple
data into multiple substreams
to reduce database load
into multiple substreams and
reduce database load and
multiple substreams and sending
database load and to
substreams and sending them
load and to reduce
and sending them along
and to reduce access
sending them along disjoing
to reduce access latency
them along disjoing paths
these companies employ a
companies employ a twotier
employ a twotier structure
placing layers of cache
layers of cache servers
of cache servers in
cache servers in front
servers in front of
in front of the
front of the database
more recent systems like
recent systems like coolstreaming
the caches of primary
caches of primary interest
of primary interest to
primary interest to us
interest to us are
to us are typically
us are typically situated
based style of data
are typically situated far
style of data dissemination
typically situated far from
situated far from the
far from the backend
from the backend database
the backend database systems
coolstreaming breaks the data
backend database systems to
breaks the data into
database systems to reduce
the data into packets
systems to reduce latency
and peers organized into
companies place caches close
peers organized into a
place caches close to
organized into a mesh
caches close to clients
into a mesh request
a mesh request packets
mesh request packets from
request packets from their
packets from their neighbors
timeouts are used to
from their neighbors using
are used to ensure
their neighbors using a
disk layout optimization for
neighbors using a scheduling
used to ensure that
using a scheduling algorithm
layout optimization for reducing
to ensure that stale
optimization for reducing energy
ensure that stale cached
for reducing energy consumption
that stale cached objects
as we saw earlier
stale cached objects will
cached objects will eventually
objects will eventually be
will eventually be flushed
chainsaw uses a simpler
uses a simpler policy
a simpler policy for
simpler policy for requesting
but to achieve a
policy for requesting packets
to achieve a high
achieve a high cache
a high cache hit
high cache hit ratio
randomly fetching them while
fetching them while respecting
them while respecting a
timeout values are generally
while respecting a maximum
values are generally large
respecting a maximum limit
th annual international conference
a maximum limit on
annual international conference on
maximum limit on the
international conference on supercomputing
limit on the number
to obtain reasonable consistency
on the number of
the number of outstanding
number of outstanding requests
of outstanding requests to
outstanding requests to each
requests to each neighbor
the database sends an
database sends an asynchronous
sends an asynchronous stream
an asynchronous stream of
asynchronous stream of invalidation
chainsaw presents smaller delays
stream of invalidation records
presents smaller delays for
of invalidation records or
smaller delays for the
invalidation records or cache
delays for the receipt
records or cache updates
for the receipt of
the receipt of packets
receipt of packets compared
of packets compared to
packets compared to the
compared to the coolstreaming
often using protocols optimized
to the coolstreaming protocol
using protocols optimized for
protocols optimized for throughput
optimized for throughput and
for throughput and freshness
in a more recent
throughput and freshness and
a more recent work
and freshness and lacking
freshness and lacking absolute
and lacking absolute guarantees
lacking absolute guarantees of
absolute guarantees of order
guarantees of order or
of order or reliability
based approaches are shown
it is difficult to
approaches are shown to
is difficult to make
are shown to present
difficult to make this
shown to present better
to make this invalidation
to present better performance
make this invalidation mechanism
present better performance over
this invalidation mechanism reliable
better performance over tree
invalidation mechanism reliable without
mechanism reliable without hampering
reliable without hampering database
without hampering database efficiency
previous papers have considered
the issues are many
papers have considered a
have considered a variety
considered a variety of
a variety of possible
variety of possible mechanisms
of possible mechanisms to
possible mechanisms to encourage
mechanisms to encourage node
the databases are large
to encourage node contribution
residing on many servers
is a framework proposed
a framework proposed to
framework proposed to enforce
proposed to enforce download
to enforce download rate
databases use locks prudently
enforce download rate limitations
use locks prudently in
download rate limitations on
locks prudently in order
rate limitations on p
prudently in order to
in order to maximize
order to maximize concurrency
p media streaming systems
to the extent that
the extent that the
extent that the database
the protocol relies on
that the database keeps
protocol relies on a
the database keeps track
relies on a set
database keeps track of
on a set of
keeps track of the
a set of trusted
track of the caches
set of trusted nodes
of the caches that
of trusted nodes that
the caches that hold
trusted nodes that store
caches that hold a
nodes that store information
that hold a copy
that store information on
hold a copy of
store information on the
a copy of each
information on the data
copy of each object
on the data downloaded
the data downloaded by
data downloaded by each
downloaded by each node
by each node receiving
each node receiving data
it may be possible
may be possible to
be possible to send
possible to send an
to send an invalidation
nodes only send an
only send an object
send an object after
but tracking the state
an object after consulting
tracking the state of
object after consulting the
the state of caches
after consulting the trusted
state of caches is
consulting the trusted nodes
of caches is complicated
the trusted nodes to
caches is complicated and
trusted nodes to verify
is complicated and hence
nodes to verify if
complicated and hence if
to verify if the
and hence if they
verify if the nodes
hence if they are
if the nodes requesting
if they are used
the nodes requesting the
they are used at
nodes requesting the stream
are used at all
requesting the stream are
the stream are not
stream are not overrequesting
are not overrequesting data
such systems view invalidations
systems view invalidations as
view invalidations as a
invalidations as a kind
it is targeted to
as a kind of
is targeted to systems
a kind of hint
targeted to systems where
to systems where nodes
systems where nodes upload
where nodes upload full
nodes upload full media
they could be delayed
upload full media objects
full media objects from
media objects from each
objects from each other
and not for live
streaming systems where all
systems where all nodes
where all nodes are
due to buffering or
all nodes are interested
to buffering or retransmissions
nodes are interested in
buffering or retransmissions after
are interested in receiving
or retransmissions after message
interested in receiving the
retransmissions after message loss
in receiving the exact
receiving the exact same
the exact same data
exact same data in
same data in close
data in close to
in close to real
close to real time
consider fairness issues in
due to an inaccurate
fairness issues in the
to an inaccurate list
issues in the context
an inaccurate list of
in the context of
inaccurate list of locations
the context of tree
the authors present mechanisms
authors present mechanisms that
present mechanisms that rank
mechanisms that rank peers
that rank peers according
rank peers according to
peers according to their
according to their level
due to a system
to their level of
to a system configuration
their level of cooperation
a system configuration change
level of cooperation with
of cooperation with the
cooperation with the system
one of their techniques
of their techniques involves
or because of races
their techniques involves the
because of races between
techniques involves the reconstruction
of races between reads
involves the reconstruction of
the reconstruction of trees
reconstruction of trees as
of trees as a
trees as a way
as a way of
a way of punishing
way of punishing opportunistic
of punishing opportunistic nodes
most of their mechanisms
of their mechanisms require
their mechanisms require peers
a missing invalidation obviously
mechanisms require peers to
missing invalidation obviously leaves
require peers to keep
invalidation obviously leaves the
peers to keep track
obviously leaves the corresponding
to keep track of
leaves the corresponding cache
keep track of their
the corresponding cache entry
track of their parents
corresponding cache entry stale
of their parents and
their parents and children
parents and children s
and children s behavior
pitfalls of such invalidation
of such invalidation schemes
such invalidation schemes are
invalidation schemes are described
schemes are described in
are described in detail
described in detail by
studied the effect of
in detail by nishita
the effect of different
detail by nishita et
a scalable services architecture
effect of different types
by nishita et al
scalable services architecture tudor
of different types of
services architecture tudor marian
different types of incentives
architecture tudor marian ken
types of incentives on
tudor marian ken birman
of incentives on the
marian ken birman department
incentives on the chainsaw
ken birman department of
on the chainsaw protocol
birman department of computer
department of computer science
of computer science cornell
computer science cornell university
and by bronson et
by bronson et al
tat and some variations
the authors propose an
authors propose an algorithm
propose an algorithm that
but forgoing transactional consistency
an algorithm that sets
forgoing transactional consistency can
algorithm that sets up
transactional consistency can result
that sets up local
consistency can result in
sets up local markets
can result in undesired
up local markets at
result in undesired behavior
local markets at every
in undesired behavior of
markets at every node
undesired behavior of a
behavior of a service
where neighbors compete for
neighbors compete for the
compete for the node
consider a buyer at
for the node s
the node s upload
a buyer at an
node s upload capacity
buyer at an online
at an online site
an online site who
online site who looks
nodes favor neighbors who
site who looks for
favor neighbors who contribute
who looks for a
neighbors who contribute more
looks for a toy
for a toy train
a toy train with
toy train with its
train with its matching
edu abstract data centers
with its matching tracks
abstract data centers constructed
its matching tracks just
data centers constructed as
with nodes classified as
matching tracks just as
nodes classified as fast
centers constructed as clusters
classified as fast or
tracks just as the
as fast or slow
constructed as clusters of
fast or slow nodes
just as the vendor
as clusters of inexpensive
as the vendor is
clusters of inexpensive machines
the vendor is adding
of inexpensive machines have
vendor is adding them
inexpensive machines have compelling
is adding them to
machines have compelling cost
adding them to the
the results indicate that
them to the database
results indicate that the
indicate that the proposed
that the proposed algorithm
the proposed algorithm improves
the client may see
proposed algorithm improves the
but developing services to
algorithm improves the performance
client may see only
developing services to run
improves the performance of
may see only the
services to run on
the performance of the
see only the train
to run on them
performance of the system
only the train in
run on them can
of the system when
the train in stock
on them can be
the system when the
train in stock but
them can be challenging
system when the total
in stock but not
when the total upload
stock but not the
the total upload capacity
but not the tracks
total upload capacity is
this paper reports on
upload capacity is not
paper reports on a
not the tracks because
capacity is not enough
reports on a new
the tracks because the
is not enough to
tracks because the product
not enough to supply
on a new framework
because the product insertion
enough to supply all
the product insertion transaction
to supply all the
product insertion transaction would
supply all the nodes
the scalable services architecture
insertion transaction would often
transaction would often be
would often be broken
often be broken into
be broken into two
broken into two or
into two or more
two or more atomic
or more atomic but
more atomic but independent
atomic but independent subtransactions
which helps developers develop
helps developers develop scalable
developers develop scalable clustered
in a social network
streaming system where nodes
develop scalable clustered applications
system where nodes choose
where nodes choose their
nodes choose their neighbors
choose their neighbors based
an inconsistency with unexpected
their neighbors based on
the work is focused
neighbors based on their
inconsistency with unexpected results
based on their history
work is focused on
on their history of
with unexpected results can
their history of interaction
is focused on nontransactional
unexpected results can occur
focused on nontransactional high
results can occur if
can occur if a
occur if a user
nodes are placed in
if a user x
are placed in the
a user x s
placed in the system
user x s record
in the system according
x s record says
the system according to
s record says it
system according to their
record says it belongs
according to their current
these are poorly supported
to their current trading
says it belongs to
their current trading performances
are poorly supported in
it belongs to a
poorly supported in existing
belongs to a certain
supported in existing platforms
to a certain group
encouraging nodes to contribute
nodes to contribute more
to contribute more and
contribute more and therefore
but that group s
more and therefore be
that group s record
and therefore be closer
group s record does
therefore be closer to
s record does not
a primary goal was
be closer to the
record does not include
closer to the source
primary goal was to
does not include x
goal was to keep
was to keep the
to keep the ssa
keep the ssa as
the ssa as small
web albums maintain picture
ssa as small and
albums maintain picture data
as small and simple
maintain picture data and
small and simple as
is a more recent
and simple as possible
picture data and access
a more recent live
data and access control
and access control lists
key elements include a
elements include a tcp
streaming approach that tolerates
approach that tolerates the
that tolerates the existence
tolerates the existence of
based chain replication mechanism
the existence of opportunistic
and it is important
existence of opportunistic and
chain replication mechanism and
of opportunistic and malicious
replication mechanism and a
opportunistic and malicious nodes
mechanism and a gossip
it is important that
is important that acl
important that acl and
that acl and album
time is divided into
acl and album updates
is divided into rounds
based subsystem for managing
and album updates are
subsystem for managing configuration
album updates are consistent
for managing configuration data
managing configuration data and
in which each peer
configuration data and repairing
which each peer communicates
data and repairing inconsistencies
each peer communicates with
and repairing inconsistencies after
the classical example involves
repairing inconsistencies after faults
peer communicates with another
classical example involves removing
communicates with another peer
example involves removing one
with another peer selected
involves removing one s
another peer selected using
removing one s boss
peer selected using a
our experimental results confirm
selected using a pseudo
one s boss from
experimental results confirm the
s boss from the
results confirm the effectiveness
boss from the album
confirm the effectiveness of
from the album acl
the effectiveness of the
the album acl and
effectiveness of the approach
album acl and then
acl and then adding
and then adding unflattering
then adding unflattering pictures
peers exchange their current
exchange their current history
their current history containing
introduction large computing systems
current history containing the
large computing systems are
history containing the identifiers
computing systems are often
containing the identifiers of
while many of these
the identifiers of all
systems are often structured
identifiers of all the
many of these systems
of all the current
of these systems make
are often structured as
these systems make do
all the current data
systems make do with
often structured as service
make do with weak
the current data they
do with weak consistency
structured as service oriented
current data they hold
as service oriented architectures
their utility is reduced
as basis for the
utility is reduced when
basis for the next
is reduced when their
for the next exchanges
reduced when their clients
when their clients observe
their clients observe inconsistencies
nodes also perform a
for example using web
also perform a phase
example using web services
perform a phase of
using web services platforms
there has been a
a phase of optimistic
has been a wave
phase of optimistic push
been a wave of
a wave of recent
wave of recent innovations
of recent innovations within
forwarding useful updates to
recent innovations within the
useful updates to pseudo
innovations within the backend
clients access services in
access services in a
services in a request
randomly picked peers with
picked peers with no
offering scalable object stores
peers with no guarantee
scalable object stores that
with no guarantee of
object stores that can
no guarantee of useful
stores that can efficiently
each service is self
guarantee of useful return
that can efficiently support
can efficiently support transactions
efficiently support transactions through
support transactions through snapshot
transactions through snapshot isolation
through snapshot isolation and
snapshot isolation and even
isolation and even full
offers its own api
and even full atomicity
conclusion we propose and
we propose and evaluate
and handles its own
propose and evaluate a
handles its own quality
and evaluate a scalable
its own quality of
evaluate a scalable auditing
own quality of service
quality of service or
of service or availability
service or availability guarantees
based technique for enforcing
technique for enforcing fairness
for enforcing fairness in
enforcing fairness in a
fairness in a live
for example by arranging
example by arranging to
by arranging to be
arranging to be restarted
to be restarted after
be restarted after a
restarted after a failure
our approach employs local
approach employs local auditors
employs local auditors that
while many services need
local auditors that execute
many services need to
auditors that execute on
services need to maintain
that execute on all
need to maintain availability
execute on all nodes
to maintain availability in
on all nodes in
maintain availability in the
all nodes in a
availability in the face
nodes in a streaming
in the face of
in a streaming session
the face of challenging
face of challenging operating
of challenging operating conditions
they are responsible for
are responsible for collecting
responsible for collecting auditable
for collecting auditable information
collecting auditable information about
auditable information about other
information about other neighbors
about other neighbors data
other neighbors data exchanges
and for verifying that
for verifying that neighbors
verifying that neighbors upload
that neighbors upload more
building services with these
neighbors upload more data
services with these properties
upload more data than
with these properties is
more data than a
these properties is difficult
data than a specified
our challenge is to
than a specified threshold
challenge is to improve
is to improve transaction
existing web services platforms
to improve transaction consistency
web services platforms offer
improve transaction consistency at
this threshold is defined
transaction consistency at the
services platforms offer load
consistency at the cache
threshold is defined by
at the cache layer
is defined by dedicated
defined by dedicated global
by dedicated global auditors
balancing and restart mechanisms
and restart mechanisms for
even when the cache
restart mechanisms for transactional
when the cache cannot
mechanisms for transactional services
the cache cannot access
for transactional services implemented
which periodically sample the
transactional services implemented using
cache cannot access the
services implemented using a
cannot access the backend
implemented using a three
access the backend on
periodically sample the state
the backend on each
backend on each read
sample the state of
the state of the
state of the system
of the system to
the system to determine
but not for services
system to determine if
not for services implemented
to determine if the
for services implemented using
determine if the overall
services implemented using other
if the overall download
implemented using other technologies
the overall download rate
overall download rate is
download rate is compromised
rate is compromised by
today s consistency solutions
is compromised by the
s consistency solutions are
developers of nontransactional web
compromised by the presence
consistency solutions are limited
by the presence of
of nontransactional web services
the presence of opportunistic
solutions are limited to
presence of opportunistic nodes
nontransactional web services must
are limited to the
web services must implement
limited to the database
services must implement their
to the database backend
must implement their own
implement their own mechanisms
global auditing determines the
their own mechanisms for
auditing determines the minimum
own mechanisms for replicating
determines the minimum threshold
mechanisms for replicating data
the minimum threshold for
even when the database
minimum threshold for uploads
when the database itself
the database itself is
database itself is consistent
tracking membership and live
membership and live this
and works with local
and live this work
works with local auditing
live this work was
the vast majority of
this work was supported
vast majority of operations
work was supported by
with local auditing to
was supported by darpa
majority of operations are
local auditing to punish
of operations are read
auditing to punish nodes
to punish nodes that
punish nodes that do
nodes that do not
ipto under the srs
that do not upload
only transactions issued by
under the srs program
do not upload enough
transactions issued by edge
not upload enough data
the srs program and
issued by edge clients
srs program and by
by edge clients and
program and by the
edge clients and are
and by the rome
we study the efficiency
by the rome air
clients and are at
the rome air force
study the efficiency of
rome air force research
the efficiency of our
air force research laboratory
efficiency of our auditing
and are at high
of our auditing approach
are at high risk
our auditing approach through
at high risk of
auditing approach through simulation
high risk of observing
risk of observing inconsistent
of observing inconsistent state
observing inconsistent state in
inconsistent state in the
state in the cache
and show that it
show that it is
under the prometheus program
that it is able
it is able to
the outright loss of
is able to maintain
outright loss of cache
able to maintain the
additional support was provided
loss of cache invalidations
support was provided by
to maintain the throughput
of cache invalidations emerges
was provided by the
maintain the throughput of
provided by the nsf
cache invalidations emerges as
the throughput of the
invalidations emerges as an
throughput of the streaming
emerges as an especially
of the streaming system
as an especially significant
the streaming system even
an especially significant problem
streaming system even in
especially significant problem if
system even in the
significant problem if transactional
even in the presence
problem if transactional consistency
in the presence of
robbert van renesse ness
the presence of a
if transactional consistency is
presence of a large
transactional consistency is required
of a large number
a large number of
large number of opportunistic
redirecting requests during failures
number of opportunistic nodes
requests during failures to
during failures to minimize
an acceptable solution for
failures to minimize client
acceptable solution for a
to minimize client disruption
solution for a consistent
for a consistent cache
a consistent cache must
consistent cache must maintain
and detecting and repairing
cache must maintain the
detecting and repairing inconsistencies
must maintain the performance
maintain the performance properties
the performance properties of
performance properties of the
properties of the existing
our premise in this
of the existing caching
premise in this paper
the existing caching tier
in this paper is
this paper is that
paper is that for
is that for many
that for many services
we need to maintain
the transactional model is
need to maintain the
transactional model is a
to maintain the shielding
model is a poor
maintain the shielding role
is a poor fit
the shielding role of
a poor fit and
shielding role of the
poor fit and hence
role of the cache
fit and hence that
and hence that tools
hence that tools aimed
that tools aimed at
tools aimed at non
the cache hit ratio
cache hit ratio should
hit ratio should be
ratio should be high
transactional web services systems
web services systems will
services systems will be
systems will be needed
a case for end
case for end system
we recognize that this
for end system multicast
recognize that this is
that this is debatable
only cache access should
cache access should complete
access should complete with
should complete with a
vendors have generally argued
complete with a single
have generally argued that
with a single client
generally argued that only
argued that only transactional
that only transactional systems
only transactional systems offer
transactional systems offer the
systems offer the hooks
offer the hooks needed
the hooks needed to
hooks needed to support
needed to support automated
to support automated scalability
trip on cache hits
this prohibits coherent cache
prohibits coherent cache solutions
coherent cache solutions such
cache solutions such as
repair and restart mechanisms
key to this argument
to this argument is
this argument is the
argument is the ease
is the ease with
the ease with which
ease with which interrupted
with which interrupted transactions
which interrupted transactions can
interrupted transactions can be
transactions can be rolled
can be rolled back
a rchitecture since the
rchitecture since the cache
since the cache is
the cache is required
cache is required to
is required to respond
required to respond immediately
to respond immediately to
respond immediately to the
immediately to the client
to the client on
the client on hits
and the relative simplicity
the relative simplicity of
relative simplicity of cleaning
simplicity of cleaning up
of cleaning up a
cleaning up a database
up a database after
cache channel is asynchronous
a database after a
database after a crash
we decided to employ
decided to employ a
yet the transactional programming
to employ a transactional
the transactional programming model
employ a transactional consistency
transactional programming model also
a transactional consistency that
programming model also brings
transactional consistency that is
model also brings constraints
consistency that is weaker
also brings constraints and
that is weaker than
brings constraints and overheads
is weaker than the
weaker than the full
than the full acid
the full acid model
were this not the
this not the case
the transactional model would
transactional model would long
model would long ago
would long ago have
long ago have become
ago have become universal
only transactions and update
transactions and update transactions
and update transactions that
reliable multicasting with an
update transactions that access
some of these constraints
multicasting with an overlay
transactions that access the
with an overlay network
of these constraints relate
that access the same
these constraints relate to
access the same cache
constraints relate to the
the same cache are
relate to the challenges
same cache are guaranteed
to the challenges of
cache are guaranteed an
the challenges of maintaining
are guaranteed an atomic
challenges of maintaining a
guaranteed an atomic execution
of maintaining a clean
maintaining a clean separation
a clean separation of
th symposium on operating
clean separation of code
symposium on operating systems
separation of code and
on operating systems design
of code and data
operating systems design and
systems design and implementation
only transactions that access
transactions that access different
not all applications can
that access different caches
all applications can be
access different caches may
applications can be structured
different caches may observe
can be structured in
caches may observe different
be structured in this
structured in this manner
may observe different orderings
observe different orderings for
different orderings for independent
orderings for independent update
for independent update transactions
transactional rollback and restart
rollback and restart can
and restart can be
restart can be costly
and restarting a database
restarting a database after
a database after a
database after a crash
after a crash incurs
a crash incurs delays
crash incurs delays while
incurs delays while cleanup
delays while cleanup code
while cleanup code runs
high availability is difficult
availability is difficult to
is difficult to acheive
every partial execution that
difficult to acheive in
partial execution that includes
to acheive in the
execution that includes all
acheive in the transactional
that includes all update
in the transactional model
includes all update transactions
all update transactions in
update transactions in and
transactions in and all
in and all read
the fastest database replication
fastest database replication schemes
only transactions that go
transactions that go through
that go through a
go through a single
through a single cache
a single cache server
suffer from failure scenarios
from failure scenarios that
failure scenarios that can
scenarios that can require
that can require intervention
can require intervention by
require intervention by a
intervention by a human
our solution seeks to
by a human operator
solution seeks to approximate
seeks to approximate cache
to approximate cache serializability
approximate cache serializability with
yet the higher fidelity
cache serializability with bounded
the higher fidelity schemes
serializability with bounded caches
higher fidelity schemes require
with bounded caches and
fidelity schemes require expensive
bounded caches and asynchronous
schemes require expensive multi
caches and asynchronous communication
and asynchronous communication with
asynchronous communication with the
communication with the db
phase commit protocols and
commit protocols and hence
protocols and hence may
and hence may not
our idea starts with
hence may not give
idea starts with an
may not give adequate
starts with an observation
not give adequate performance
objects form clusters with
clustered threetier database products
form clusters with strong
threetier database products are
clusters with strong locality
database products are powerful
with strong locality properties
products are powerful solutions
transactions are likely to
but they negotiate these
are likely to access
they negotiate these potential
likely to access objects
negotiate these potential pitfalls
highbandwidth content distribution in
to access objects that
content distribution in cooperative
access objects that are
these potential pitfalls in
distribution in cooperative environments
potential pitfalls in ways
pitfalls in ways that
in ways that preclude
ways that preclude important
that preclude important classes
preclude important classes of
important classes of applications
close to each other
our motivation is to
for retailers this might
motivation is to show
retailers this might involve
is to show that
th acm symposium on
this might involve related
to show that a
acm symposium on operating
show that a simple
symposium on operating systems
might involve related products
on operating systems principles
that a simple and
a simple and remarkably
simple and remarkably inexpensive
and remarkably inexpensive infrastructure
for social networks the
remarkably inexpensive infrastructure can
social networks the set
inexpensive infrastructure can support
networks the set of
infrastructure can support clustered
the set of friends
can support clustered execution
support clustered execution of
clustered execution of a
execution of a significant
of a significant class
for geographical services physical
a significant class of
geographical services physical proximity
significant class of non
and for web albums
for web albums the
web albums the acl
albums the acl objects
the acl objects and
the work reported here
acl objects and the
work reported here focuses
objects and the pictures
reported here focuses on
and the pictures assigned
here focuses on services
the pictures assigned to
focuses on services that
pictures assigned to them
on services that don
services that don t
that don t fit
don t fit the
t fit the transactional
fit the transactional paradigm
in some cases applications
typically for reasons of
some cases applications explicitly
for reasons of performance
cases applications explicitly cluster
applications explicitly cluster their
explicitly cluster their data
cluster their data accesses
ones that operate directly
their data accesses to
that operate directly on
data accesses to benefit
operate directly on in
accesses to benefit from
to benefit from improved
benefit from improved parallelism
memory data structures or
data structures or simple
structures or simple non
to simplify our task
the resulting transactions access
resulting transactions access objects
we assume that these
transactions access objects from
assume that these services
access objects from a
that these services are
objects from a single
these services are capable
from a single cluster
services are capable of
are capable of handling
capable of handling outof
although there will also
there will also be
will also be some
also be some frequency
be some frequency of
and that processes implementing
some frequency of transactions
that processes implementing them
frequency of transactions that
processes implementing them experience
of transactions that access
implementing them experience only
eliminating trees from overlay
them experience only crash
trees from overlay multicast
experience only crash failures
transactions that access unrelated
that access unrelated objects
access unrelated objects in
unrelated objects in different
objects in different clusters
as will be shown
will be shown below
th international workshop on
international workshop on peer
our solution requires minor
solution requires minor changes
our assumptions hold for
requires minor changes to
assumptions hold for a
minor changes to the
hold for a very
changes to the database
for a very large
to the database object
a very large group
the database object representation
very large group of
database object representation format
large group of applications
imposing a small and
the ssa was built
a small and constant
ssa was built using
small and constant memory
was built using epidemic
and constant memory overhead
independent of the database
communication protocols in conjunction
of the database size
protocols in conjunction with
the database size and
in conjunction with a
database size and the
conjunction with a novel
size and the transaction
with a novel variant
and the transaction rate
a novel variant of
novel variant of the
variant of the chain
of the chain replication
the chain replication scheme
chain replication scheme which
replication scheme which has
this overhead involves tracking
scheme which has evolved
overhead involves tracking and
which has evolved from
involves tracking and caching
has evolved from the
tracking and caching what
evolved from the mechanism
and caching what we
from the mechanism first
caching what we refer
the mechanism first proposed
what we refer to
mechanism first proposed in
we refer to as
refer to as dependency
to as dependency lists
length lists of object
lists of object identifiers
of object identifiers and
object identifiers and the
identifiers and the associated
and the associated version
the associated version numbers
gossip based infrastructures are
based infrastructures are beneficial
infrastructures are beneficial because
are beneficial because they
each representing some recently
beneficial because they are
representing some recently updated
some recently updated objects
recently updated objects upon
updated objects upon which
objects upon which the
simple to implement rapidly
upon which the cached
to implement rapidly self
which the cached object
the cached object depends
stabilizing after disruptions analytically
after disruptions analytically appealing
disruptions analytically appealing this
analytically appealing this paper
sized list can omit
appealing this paper reports
list can omit dependency
this paper reports on
can omit dependency information
paper reports on the
omit dependency information required
reports on the architecture
dependency information required to
on the architecture and
information required to detect
the architecture and performance
required to detect inconsistencies
architecture and performance of
and performance of the
performance of the platform
hence it is important
driven overlay network for
it is important to
and explores the limitations
overlay network for efficient
explores the limitations of
network for efficient live
the limitations of its
for efficient live media
limitations of its underlying
efficient live media streaming
of its underlying techniques
is important to use
important to use a
to use a bound
use a bound large
a bound large enough
bound large enough to
large enough to capture
enough to capture most
to capture most of
capture most of the
the experiments are designed
most of the relevant
of the relevant dependencies
experiments are designed to
are designed to help
th conference on computer
designed to help us
conference on computer communications
at present we lack
on computer communications and
present we lack an
to help us fully
we lack an automated
computer communications and networking
lack an automated way
help us fully understand
an automated way to
automated way to do
us fully understand the
way to do this
fully understand the fundamental
understand the fundamental properties
the fundamental properties of
we require the developer
fundamental properties of a
require the developer to
properties of a single
the developer to tune
of a single partitioned
developer to tune the
a single partitioned replicated
to tune the length
single partitioned replicated service
tune the length so
partitioned replicated service and
the length so that
replicated service and thus
length so that the
service and thus gain
so that the frequency
and thus gain a
that the frequency of
thus gain a firm
the frequency of errors
gain a firm grasp
frequency of errors is
a firm grasp on
of errors is reduced
firm grasp on the
errors is reduced to
grasp on the behavior
is reduced to an
on the behavior of
reduced to an acceptable
the behavior of the
to an acceptable level
behavior of the ssa
of the ssa s
the ssa s building
ssa s building blocks
reasoning about the trade
we defer for future
defer for future work
for future work the
future work the full
work the full scale
in a manner we
the full scale evaluation
a manner we discuss
full scale evaluation of
manner we discuss further
scale evaluation of multiple
we discuss further below
evaluation of multiple services
of multiple services deployed
multiple services deployed and
services deployed and running
deployed and running at
and running at the
running at the same
at the same time
dependency lists should be
defense against intrusion in
lists should be roughly
against intrusion in a
should be roughly the
the ssa currently runs
intrusion in a live
be roughly the same
ssa currently runs on
roughly the same size
in a live streaming
the same size as
currently runs on a
same size as the
a live streaming multicast
size as the size
runs on a tightly
as the size of
on a tightly coupled
the size of the
live streaming multicast system
size of the workload
a tightly coupled cluster
of the workload s
tightly coupled cluster of
the workload s clusters
coupled cluster of blade
cluster of blade servers
our extensions offer a
extensions offer a transactional
we show that developers
offer a transactional interface
show that developers can
a transactional interface to
that developers can tune
th ieee international conference
transactional interface to the
ieee international conference on
developers can tune parameters
international conference on peer
interface to the cache
can tune parameters to
to the cache in
tune parameters to trade
the cache in addition
parameters to trade overhead
cache in addition to
to trade overhead for
in addition to the
trade overhead for speed
addition to the standard
overhead for speed of
to the standard read
for speed of repair
speed of repair and
of repair and we
repair and we believe
and we believe that
we believe that our
believe that our results
that our results validate
our results validate the
results validate the approach
our algorithm detects and
algorithm detects and fixes
detects and fixes inconsistent
and fixes inconsistent read
application model our work
only transactions at the
model our work focuses
transactions at the cache
our work focuses on
at the cache with
work focuses on datacenters
the cache with constant
focuses on datacenters supporting
cache with constant complexity
on datacenters supporting one
datacenters supporting one or
supporting one or more
one or more services
it does so by
or more services deployed
does so by either
more services deployed within
so by either aborting
services deployed within a
by either aborting the
deployed within a cluster
either aborting the transaction
within a cluster of
a cluster of compute
cluster of compute nodes
which can then be
can then be retried
or invalidating a cached
tailer might implement a
invalidating a cached object
might implement a front
a cached object which
cached object which can
object which can then
which can then force
can then force a
end service that builds
then force a read
service that builds web
force a read from
that builds web pages
a read from the
read from the database
parallelizing the task by
the task by dispatching
similar to handling cache
task by dispatching sub
to handling cache misses
tasks to services to
to services to rank
services to rank product
to rank product popularity
when the dependency lists
the dependency lists fail
dependency lists fail to
lists fail to document
fail to document a
to document a necessary
document a necessary dependency
an application might be
application might be exposed
might be exposed to
be exposed to stale
exposed to stale values
because we have in
we have in mind
th conference on computer
have in mind client
conference on computer communications
end service would probably
service would probably just
side applications that are
would probably just be
applications that are unlikely
probably just be cloned
that are unlikely to
are unlikely to validate
unlikely to validate against
to validate against the
validate against the back
with identical replicas that
identical replicas that build
replicas that build pages
for many of our
many of our intended
of our intended uses
end services might be
our intended uses some
services might be partitioned
intended uses some level
might be partitioned into
uses some level of
be partitioned into subservices
some level of undetected
partitioned into subservices for
level of undetected inconsistency
into subservices for scalability
of undetected inconsistency can
subservices for scalability using
undetected inconsistency can slip
for scalability using some
inconsistency can slip past
scalability using some key
because the developer would
the developer would often
developer would often be
would often be able
often be able to
be able to tune
able to tune the
to tune the mechanism
and subservices cloned for
subservices cloned for faulttolerance
cloned for faulttolerance and
for faulttolerance and load
state operation of large
operation of large applications
this is a common
is a common model
the rate of unnoticed
rate of unnoticed inconsistencies
of unnoticed inconsistencies could
unnoticed inconsistencies could be
jim gray and others
inconsistencies could be extremely
gray and others have
could be extremely low
and others have suggested
others have suggested that
have suggested that such
suggested that such a
that such a system
with clustered workloads we
such a system be
clustered workloads we will
a system be termed
workloads we will demonstrate
system be termed a
we will demonstrate that
be termed a farm
will demonstrate that it
termed a farm consisting
demonstrate that it is
a farm consisting of
that it is sufficient
farm consisting of raps
it is sufficient to
is sufficient to store
sufficient to store a
to store a small
store a small set
reliable array of partitioned
a small set of
array of partitioned services
small set of dependencies
set of dependencies to
of dependencies to detect
dependencies to detect most
to detect most inconsistencies
reliable array of cloned
array of cloned server
we also investigate workloads
of cloned server processes
also investigate workloads where
investigate workloads where the
workloads where the clustered
where the clustered access
the clustered access pattern
clustered access pattern is
access pattern is less
pattern is less strongly
is less strongly evident
our approach is less
approach is less effective
is less effective even
less effective even with
effective even with longer
even with longer dependency
with longer dependency list
longer dependency list lengths
up to the present
thus our solution is
our solution is not
solution is not a
is not a panacea
this structure has arisen
structure has arisen mostly
has arisen mostly in
arisen mostly in very
mostly in very large
in very large datacenters
for applications matched to
very large datacenters and
applications matched to our
large datacenters and is
matched to our assumptions
datacenters and is supported
and is supported primarily
is supported primarily in
supported primarily in the
primarily in the context
can be highly effective
in the context of
the context of three
database we assume that
we assume that the
assume that the database
that the database tags
the database tags each
we believe that similar
database tags each object
th symposium on operating
believe that similar architectures
symposium on operating systems
tags each object with
on operating systems design
that similar architectures will
operating systems design and
each object with a
systems design and implementation
similar architectures will be
object with a version
architectures will be needed
with a version number
will be needed more
a version number specific
be needed more widely
version number specific to
number specific to the
specific to the transaction
to the transaction that
because the need to
the transaction that most
the need to tolerate
transaction that most recently
need to tolerate heavy
that most recently updated
to tolerate heavy loads
most recently updated it
tolerate heavy loads is
heavy loads is increasingly
loads is increasingly ubiquitous
and economic considerations favor
and that there is
economic considerations favor clustered
that there is a
considerations favor clustered solutions
there is a total
is a total ordering
a total ordering on
total ordering on version
ordering on version numbers
game servers require scalability
the version of a
servers require scalability for
version of a transaction
require scalability for situations
of a transaction is
scalability for situations in
a transaction is chosen
for situations in which
transaction is chosen to
situations in which there
is chosen to be
in which there are
chosen to be larger
which there are many
to be larger than
there are many users
be larger than the
larger than the versions
than the versions of
the versions of all
versions of all objects
military systems require scalability
of all objects accessed
systems require scalability to
all objects accessed by
require scalability to support
objects accessed by the
scalability to support new
accessed by the transaction
to support new generations
support new generations of
new generations of integrated
generations of integrated applications
the database stores for
database stores for each
stores for each object
for each object o
hospital automation is putting
each object o a
automation is putting new
object o a list
is putting new demands
o a list of
putting new demands on
a list of k
new demands on medical
list of k dependencies
demands on medical information
on medical information subsystems
in a wide range
a wide range of
wide range of everyday
range of everyday settings
the rollout of soas
rollout of soas and
of soas and the
soas and the ease
and the ease of
the ease of application
ease of application integration
of application integration they
application integration they support
high bandwidth data dissemination
integration they support will
bandwidth data dissemination using
they support will place
data dissemination using an
support will place services
dissemination using an overlay
will place services under
using an overlay mesh
place services under growing
services under growing load
our goal is to
goal is to make
is to make it
to make it easy
make it easy to
it easy to build
easy to build raps
to build raps and
build raps and racs
raps and racs from
and racs from traditional
th acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
web service applications designed
service applications designed for
applications designed for quick
designed for quick responsiveness
we also want to
also want to build
want to build the
to build the simplest
build the simplest platform
the simplest platform capable
simplest platform capable of
this is a list
platform capable of accomplishing
is a list of
capable of accomplishing this
a list of identifiers
of accomplishing this task
list of identifiers and
of identifiers and versions
identifiers and versions of
and versions of other
versions of other objects
of other objects that
other objects that the
objects that the current
that the current version
the current version of
current version of o
version of o depends
a set of racs
of o depends on
only transaction that sees
transaction that sees the
that sees the current
sees the current version
the current version of
current version of o
version of o must
of o must not
o must not see
must not see object
not see object di
see object di with
object di with version
di with version smaller
with version smaller than
version smaller than vi
when a transaction t
a transaction t with
transaction t with version
t with version vt
with version vt touches
version vt touches objects
vt touches objects o
a comparative study of
comparative study of live
study of live p
it updates both their
updates both their versions
both their versions and
their versions and their
versions and their dependency
and their dependency lists
subsequent accesses to object
accesses to object o
must see object o
th conference on computer
conference on computer communications
with a version not
a version not smaller
version not smaller than
not smaller than vt
gossip traffic chain figure
it inherits all of
inherits all of the
all of the l
of the l dependencies
the l dependencies of
l dependencies of o
where l is the
l is the length
is the length of
the length of o
elements of the model
of the model a
the model a service
model a service is
a service is simply
service is simply an
is simply an application
simply an application that
so the dependency list
an application that provides
the dependency list of
application that provides interfaces
dependency list of o
that provides interfaces that
provides interfaces that manipulate
interfaces that manipulate objects
that manipulate objects of
manipulate objects of unspecified
objects of unspecified nature
a query operation reads
query operation reads some
operation reads some object
reads some object and
some object and returns
object and returns a
and returns a computed
returns a computed value
an update operation modifies
update operation modifies one
operation modifies one or
modifies one or more
one or more objects
one unusual assumption made
unusual assumption made in
assumption made in our
made in our work
in our work is
our work is that
preventing dos attacks in
work is that many
dos attacks in peer
is that many services
that many services can
many services can process
services can process updates
can process updates out
process updates out of
updates out of order
peer media streaming systems
we focus on services
focus on services that
on services that can
services that can respond
that can respond correctly
can respond correctly to
respond correctly to queries
correctly to queries even
th annual multimedia computing
to queries even if
annual multimedia computing and
queries even if some
multimedia computing and networking
even if some updates
computing and networking conference
if some updates are
some updates are temporarily
updates are temporarily missing
converge into a state
into a state determined
a state determined entirely
state determined entirely by
determined entirely by the
entirely by the set
by the set of
the set of updates
so that if two
that if two members
if two members of
two members of some
members of some subservice
of some subservice receive
some subservice receive the
subservice receive the same
receive the same updates
the same updates they
same updates they will
updates they will be
they will be in
will be in equivalent
be in equivalent states
even if those updates
if those updates were
those updates were delivered
updates were delivered in
were delivered in different
delivered in different orders
a reissued query or
reissued query or update
query or update returns
or update returns an
update returns an equivalent
returns an equivalent result
what this amounts to
this amounts to is
amounts to is that
to is that the
is that the ssa
that the ssa should
the ssa should deliver
ssa should deliver updates
should deliver updates as
deliver updates as soon
updates as soon as
as soon as it
soon as it can
as it can even
it can even if
can even if they
even if they are
if they are not
they are not in
are not in order
one way that an
way that an application
that an application might
an application might process
application might process out
might process out of
process out of order
out of order updates
of order updates is
order updates is simply
updates is simply to
is simply to delay
simply to delay processing
to delay processing them
delay processing them until
processing them until it
them until it can
until it can sort
it can sort them
nd workshop on the
can sort them into
workshop on the economics
sort them into order
on the economics of
the economics of peer
but we believe that
we believe that for
believe that for many
that for many uses
it will be possible
will be possible to
be possible to act
possible to act on
to act on an
act on an update
on an update or
an update or query
update or query immediately
or query immediately upon
query immediately upon receiving
immediately upon receiving it
the ssa can support
ssa can support raps
a raps of racs
when a transaction is
a transaction is committed
a service that can
this update is done
service that can be
update is done for
that can be structured
is done for all
can be structured as
done for all objects
be structured as a
for all objects in
structured as a raps
all objects in the
as a raps must
objects in the transaction
a raps must have
in the transaction at
raps must have a
the transaction at once
must have a partitioning
have a partitioning function
a partitioning function that
given a read set
partitioning function that can
a read set readset
function that can be
that can be used
can be used to
be used to map
used to map each
and a write set
to map each operation
a write set writeset
map each operation to
improving robustness of peer
each operation to the
operation to the subservice
to the subservice that
containing tuples comprised of
the subservice that should
tuples comprised of the
subservice that should execute
comprised of the keys
that should execute it
of the keys accessed
peer streaming with incentives
their versions and their
existing systems typically implement
versions and their dependency
systems typically implement partitioning
and their dependency lists
typically implement partitioning functions
implement partitioning functions in
partitioning functions in one
functions in one of
in one of two
one of two ways
the database aggregates them
database aggregates them to
st workshop on the
aggregates them to a
workshop on the economics
them to a single
on the economics of
to a single full
the economics of networked
a single full dependency
economics of networked systems
single full dependency list
full dependency list as
the service exports its
dependency list as follows
service exports its partitioning
exports its partitioning function
so that clients are
that clients are able
clients are able to
are able to locally
able to locally implement
to locally implement the
locally implement the logic
implement the logic mapping
the logic mapping requests
logic mapping requests to
mapping requests to subservices
the cluster might control
cluster might control the
might control the dns
or could influence the
could influence the creation
influence the creation of
the creation of web
creation of web pages
of web pages by
web pages by modifying
pages by modifying urls
so that clients will
that clients will be
clients will be directed
will be directed to
be directed to an
directed to an appropriate
readset writeset this list
to an appropriate subservice
writeset this list is
this list is pruned
list is pruned to
is pruned to match
pruned to match the
to match the target
match the target size
the target size using
target size using lru
the servers might export
servers might export actual
might export actual code
export actual code that
and stored with each
actual code that the
stored with each write
code that the client
that the client runs
a list entry can
list entry can be
the partitioning logic is
entry can be discarded
partitioning logic is situated
can be discarded if
logic is situated on
be discarded if the
is situated on a
discarded if the same
situated on a load
if the same entry
on a load balancing
the same entry s
a load balancing component
same entry s object
load balancing component resident
entry s object appears
balancing component resident in
s object appears in
component resident in the
object appears in another
resident in the server
appears in another entry
p live streaming system
in another entry with
in the server cluster
another entry with a
entry with a larger
with a larger version
the load balancer sprays
load balancer sprays requests
of the ninth ieee
balancer sprays requests over
the ninth ieee global
sprays requests over the
ninth ieee global internet
requests over the subservices
ieee global internet workshop
over the subservices in
were their lengths not
the subservices in accordance
their lengths not bounded
subservices in accordance with
in accordance with server
accordance with server logic
dependency lists could quickly
lists could quickly grow
the ssa supports the
could quickly grow to
ssa supports the latter
quickly grow to include
supports the latter approach
grow to include all
to include all objects
include all objects in
all objects in the
objects in the database
offering a mechanism that
a mechanism that assists
mechanism that assists the
that assists the load
cache in our scheme
balancing component in tracking
component in tracking membership
in tracking membership so
tracking membership so that
membership so that it
the cache interacts with
so that it can
cache interacts with the
that it can appropriately
interacts with the database
it can appropriately route
with the database in
can appropriately route queries
the database in essentially
appropriately route queries and
database in essentially the
route queries and updates
in essentially the same
essentially the same manner
the same manner as
same manner as for
manner as for a
as for a consistency
we assume that processes
assume that processes are
that processes are fail
should a failure occur
and will eventually be
and receiving invalidations as
will eventually be detected
receiving invalidations as the
eventually be detected as
invalidations as the database
be detected as faulty
as the database updates
the database updates objects
a failure may be
failure may be transient
the caches read from
a process can become
caches read from the
process can become temporarily
read from the database
can become temporarily unavailable
from the database not
the database not only
database not only the
not only the object
only the object s
but then restart and
the object s value
then restart and recover
restart and recover any
and recover any missing
recover any missing updates
but also its version
also its version and
its version and the
version and the dependency
and the dependency list
the extended cache exports
extended cache exports a
cache exports a transactional
discussion our model is
exports a transactional read
our model is not
model is not completely
is not completely general
and for this reason
for this reason some
client read requests are
this reason some discussion
read requests are extended
reason some discussion is
requests are extended with
some discussion is needed
are extended with a
extended with a transaction
with a transaction identifier
a transaction identifier and
transaction identifier and a
identifier and a last
consider the following example
we wish to support
wish to support a
to support a scalable
support a scalable inventory
a scalable inventory service
scalable inventory service that
inventory service that receives
service that receives updates
that receives updates corresponding
receives updates corresponding to
updates corresponding to inventory
corresponding to inventory consumption
to inventory consumption and
inventory consumption and re
the transaction identifier txnid
transaction identifier txnid allows
identifier txnid allows the
txnid allows the cache
allows the cache to
the cache to recognize
cache to recognize reads
to recognize reads belonging
recognize reads belonging to
queries against such a
reads belonging to the
against such a service
belonging to the same
such a service would
to the same transaction
a service would compute
service would compute and
would compute and return
compute and return an
the cache responds with
and return an inventory
cache responds with either
return an inventory count
responds with either the
an inventory count as
with either the value
inventory count as of
either the value of
count as of the
the value of the
as of the time
value of the requested
of the time the
of the requested object
the time the query
time the query was
the query was processed
or with an abort
with an abort if
but inventory can change
inventory can change in
an abort if it
can change in real
abort if it detects
if it detects an
it detects an inconsistency
detects an inconsistency between
an inconsistency between this
inconsistency between this read
between this read and
this read and any
read and any of
reissued a moment later
and any of the
any of the previous
of the previous reads
the previous reads with
might yield a different
previous reads with the
yield a different result
reads with the same
a different result and
with the same transaction
different result and yet
the same transaction id
result and yet both
and yet both would
yet both would be
both would be correct
we do not guarantee
do not guarantee that
not guarantee that inconsistencies
guarantee that inconsistencies will
that inconsistencies will be
inconsistencies will be detected
responses reflecting a reasonably
reflecting a reasonably current
a reasonably current server
reasonably current server state
the lastop allows the
current server state are
lastop allows the cache
server state are acceptable
allows the cache to
the cache to garbage
on the other hand
collect its transaction record
its transaction record after
a response reflecting a
transaction record after responding
response reflecting a very
record after responding to
reflecting a very stale
after responding to the
a very stale state
responding to the last
very stale state would
to the last read
stale state would be
the last read operation
state would be incorrect
last read operation of
read operation of the
operation of the transaction
a client should not
client should not be
the cache will treat
should not be offered
cache will treat subsequent
not be offered a
will treat subsequent accesses
be offered a promotional
treat subsequent accesses with
offered a promotional price
subsequent accesses with the
a promotional price on
accesses with the same
promotional price on a
with the same transaction
price on a plasma
the same transaction id
on a plasma tv
same transaction id as
a plasma tv if
transaction id as new
plasma tv if the
id as new transactions
tv if the last
if the last unit
the last unit was
last unit was actually
unit was actually sold
to implement this interface
was actually sold hours
actually sold hours ago
the cache maintains a
cache maintains a record
maintains a record of
a record of each
record of each transaction
of each transaction with
the inventory service should
each transaction with its
inventory service should reflect
transaction with its read
service should reflect as
with its read values
should reflect as many
reflect as many updates
as many updates as
many updates as possible
updates as possible in
as possible in the
possible in the replies
in the replies it
and their dependency lists
the replies it gives
replies it gives to
it gives to requests
on a read of
a read of keycurr
but any reply is
any reply is correct
reply is correct provided
is correct provided that
the cache first obtains
correct provided that it
cache first obtains the
provided that it was
first obtains the requested
that it was based
obtains the requested entry
it was based on
the requested entry from
was based on a
requested entry from memory
based on a recent
on a recent state
we shall see that
shall see that the
see that the ssa
that the ssa allows
the ssa allows brief
ssa allows brief inconsistencies
allows brief inconsistencies but
brief inconsistencies but that
inconsistencies but that they
but that they can
that they can be
they can be limited
can be limited to
the entry includes the
be limited to a
entry includes the value
limited to a few
to a few seconds
version vercurr and dependency
vercurr and dependency list
and dependency list deplistcurr
operations against the inventory
against the inventory service
the inventory service happen
inventory service happen to
service happen to be
the cache checks the
happen to be commutative
cache checks the currently
checks the currently read
the currently read object
currently read object against
read object against each
hence the service can
object against each of
the service can process
against each of the
service can process updates
each of the previously
can process updates out
of the previously read
process updates out of
the previously read objects
updates out of order
if a previously read
but many kinds of
a previously read version
many kinds of services
previously read version v
kinds of services can
read version v is
of services can handle
version v is older
services can handle out
v is older than
can handle out of
is older than expected
handle out of order
older than expected by
out of order updates
than expected by the
expected by the current
by the current read
the current read s
current read s dependencies
if for no other
read s dependencies v
for no other reason
s dependencies v k
no other reason than
other reason than that
reason than that in
than that in many
that in many settings
each update is uniquely
update is uniquely sequenced
is uniquely sequenced by
uniquely sequenced by its
sequenced by its source
permitting the service to
the service to sort
service to sort updates
to sort updates and
sort updates and to
updates and to process
and to process queries
to process queries against
process queries against the
queries against the sorted
against the sorted database
our group has held
group has held discussions
has held discussions with
held discussions with operators
discussions with operators of
with operators of several
operators of several large
of several large datacenters
and concluded that many
concluded that many services
that many services have
many services have the
services have the kinds
have the kinds of
the kinds of properties
kinds of properties just
of properties just cited
ability to respond based
building collaboration applications that
to respond based on
or the current read
respond based on a
collaboration applications that mix
based on a reasonable
the current read vcurr
on a reasonable current
applications that mix web
a reasonable current state
current read vcurr is
that mix web services
read vcurr is older
mix web services hosted
vcurr is older than
web services hosted content
and to handle out
services hosted content with
is older than expected
hosted content with p
older than expected by
than expected by the
expected by the dependencies
by the dependencies of
the dependencies of a
dependencies of a previous
of a previous read
a previous read v
the ssa is a
previous read v v
ssa is a good
is a good match
a good match for
good match for personalization
match for personalization services
krzysztof ostrowski cornell university
dept of computer science
an inconsistency is detected
otherwise the cache returns
the cache returns the
cache returns the read
returns the read value
the read value to
read value to the
value to the client
upon detecting an inconsistency
the cache can take
cache can take one
can take one of
take one of three
one of three paths
these deal primarily with
deal primarily with weakly
abort the current transaction
primarily with weakly consistent
with weakly consistent data
compared to the other
to the other approaches
this has the benefit
has the benefit of
the benefit of affecting
and all sorts of
benefit of affecting only
all sorts of services
of affecting only the
sorts of services in
affecting only the running
of services in which
only the running transaction
services in which replies
the running transaction and
in which replies are
running transaction and limiting
which replies are intrinsically
transaction and limiting collateral
replies are intrinsically noisy
and limiting collateral damage
such as services that
as services that report
edu abstract the most
services that report data
abstract the most commonly
that report data gathered
the most commonly deployed
report data gathered from
most commonly deployed web
data gathered from remote
commonly deployed web service
gathered from remote sensors
deployed web service applications
web service applications employ
service applications employ client
abort the current transaction
the current transaction and
current transaction and evict
transaction and evict the
and evict the violating
a datacenter would also
datacenter would also host
would also host some
also host some kinds
with clients running remotely
host some kinds of
clients running remotely and
some kinds of services
running remotely and services
kinds of services ill
remotely and services hosted
and services hosted in
services hosted in data
hosted in data centers
matched to our model
object from the cache
but because we are
because we are working
this approach guesses that
we make the case
we are working with
make the case for
approach guesses that future
the case for service
are working with web
guesses that future transactions
working with web services
that future transactions are
future transactions are likely
transactions are likely to
are likely to abort
likely to abort because
services running on the
to abort because of
running on the ssa
abort because of this
on the ssa can
because of this object
the ssa can easily
applications that combine service
ssa can easily interact
can easily interact with
easily interact with services
interact with services that
with services that employ
services that employ other
hosted data with collaboration
that employ other solutions
data with collaboration features
with collaboration features implemented
collaboration features implemented using
features implemented using peerto
check which is the
which is the violating
is the violating object
collaboration features are awkward
features are awkward to
if it is the
are awkward to support
consistency semantics the ssa
awkward to support solely
it is the currently
semantics the ssa implements
is the currently accessed
the ssa implements stochastic
the currently accessed object
to support solely based
ssa implements stochastic consistency
support solely based on
implements stochastic consistency semantics
solely based on the
based on the existing
on the existing web
the existing web services
existing web services technologies
an application will only
application will only observe
will only observe an
only observe an inconsistency
observe an inconsistency if
indirection through the data
an inconsistency if a
through the data center
inconsistency if a fault
the data center introduces
if a fault occurs
data center introduces high
treat this access as
center introduces high latencies
this access as a
introduces high latencies and
access as a miss
high latencies and limits
and even then only
as a miss and
latencies and limits scalability
a miss and respond
even then only for
miss and respond to
then only for a
and respond to it
only for a period
respond to it with
for a period of
and precludes collaboration between
a period of time
to it with a
period of time associated
it with a value
of time associated with
precludes collaboration between clients
time associated with our
with a value read
associated with our repair
collaboration between clients connected
with our repair protocol
a value read from
between clients connected to
value read from the
clients connected to one
read from the database
and only if it
only if it has
another but lacking connectivity
if it has the
but lacking connectivity to
if the violating object
lacking connectivity to the
it has the bad
connectivity to the data
the violating object was
to the data center
has the bad luck
violating object was returned
the bad luck to
object was returned to
bad luck to query
was returned to the
luck to query a
returned to the user
cornell s live distributed
to query a node
to the user as
query a node impacted
s live distributed objects
a node impacted by
the user as the
node impacted by the
live distributed objects platform
impacted by the failure
user as the result
distributed objects platform combines
as the result of
objects platform combines web
the result of a
platform combines web services
result of a read
combines web services with
this window can be
web services with direct
window can be made
services with direct peerto
can be made small
of a read earlier
a read earlier in
read earlier in the
earlier in the transaction
peer communication to eliminate
so that applications are
communication to eliminate these
that applications are unlikely
to eliminate these issues
applications are unlikely to
are unlikely to observe
unlikely to observe a
to observe a problem
or permitted to grow
permitted to grow somewhat
to grow somewhat larger
introduction there is a
evict the stale object
there is a growing
the stale object and
is a growing opportunity
stale object and abort
a growing opportunity to
depending upon the cost
growing opportunity to use
object and abort the
opportunity to use service
upon the cost of
and abort the transaction
the cost of inconsistency
cost of inconsistency and
of inconsistency and the
inconsistency and the relative
and the relative value
consistency with unbounded resources
applications in ways that
in ways that can
ways that can slash
that can slash health
of faster response time
cache detects all inconsistencies
faster response time versus
response time versus lower
time versus lower risk
versus lower risk of
lower risk of an
as stated in the
risk of an observed
stated in the following
of an observed fault
in the following theorem
permit more effective search
more effective search and
effective search and rescue
in the experimental work
search and rescue after
the experimental work that
and rescue after a
experimental work that follows
rescue after a disaster
we measure these windows
enable a more nimble
measure these windows for
a more nimble information
these windows for scenarios
windows for scenarios representative
cache with unbounded cache
for scenarios representative of
with unbounded cache size
scenarios representative of conditions
unbounded cache size and
representative of conditions that
cache size and unbounded
of conditions that arise
size and unbounded dependency
conditions that arise in
and unbounded dependency lists
that arise in realistic
or make possible a
arise in realistic settings
unbounded dependency lists implements
make possible a world
dependency lists implements cache
possible a world of
a world of professional
world of professional dialog
of professional dialog and
professional dialog and collaboration
dialog and collaboration without
and collaboration without travel
the ssa framework the
ssa framework the basic
framework the basic operation
the basic operation of
basic operation of the
soc applications will need
operation of the ssa
applications will need to
of the ssa is
will need to combine
the ssa is as
need to combine two
deferred to appendix a
ssa is as follows
to combine two types
combine two types of
two types of content
is by constructing a
as queries or updates
by constructing a serialization
queries or updates are
traditional web service hosted
or updates are received
web service hosted content
updates are received in
constructing a serialization of
are received in the
a serialization of the
received in the cluster
serialization of the transactions
such as data from
of the transactions in
as data from databases
the transactions in the
transactions in the database
they are passed through
in the database and
are passed through a
the database and in
passed through a partition
database and in one
through a partition mapping
and in one cache
a partition mapping component
based on the fact
which directs the request
and weather prediction systems
directs the request to
on the fact that
the request to an
the fact that the
request to an appropriate
fact that the transactions
to an appropriate racs
that the transactions in
with a variety of
the transactions in the
a variety of collaboration
transactions in the database
variety of collaboration features
in the database are
the database are serializable
we will use the
database are serializable by
will use the term
are serializable by definition
use the term subservice
such as chat windows
the term subservice rather
term subservice rather than
subservice rather than racs
rather than racs in
the implications of theorem
than racs in the
racs in the remainder
in the remainder of
the remainder of the
remainder of the paper
will be seen in
be seen in section
seen in section v
peer video and other
to create a subservice
video and other media
create a subservice the
and other media streams
a subservice the developer
subservice the developer must
the developer must first
developer must first implement
must first implement a
first implement a non
cache converges to perfect
converges to perfect detection
existing web service technologies
this is then cloned
to perfect detection when
is then cloned using
web service technologies make
perfect detection when stable
then cloned using the
service technologies make it
cloned using the ssa
detection when stable clusters
using the ssa platform
technologies make it easy
when stable clusters are
make it easy to
stable clusters are as
it easy to build
clusters are as large
easy to build applications
each replica is placed
are as large as
replica is placed on
as large as its
to build applications in
large as its dependency
is placed on a
as its dependency lists
placed on a separate
build applications in which
on a separate node
applications in which all
in which all data
which all data travels
in such a scenario
all data travels through
and the replicas are
data travels through a
the replicas are then
travels through a data
replicas are then linked
through a data center
the dependency lists are
are then linked using
dependency lists are large
then linked using tcp
lists are large enough
linked using tcp to
are large enough to
using tcp to create
large enough to describe
implementing collaboration features using
enough to describe all
tcp to create a
collaboration features using these
to create a chain
to describe all relevant
features using these technologies
describe all relevant dependencies
using these technologies is
these technologies is problematic
technologies is problematic because
is problematic because collaborative
problematic because collaborative applications
because collaborative applications can
collaborative applications can generate
applications can generate high
e xperimental s etup
xperimental s etup to
s etup to evaluate
etup to evaluate the
to evaluate the effectiveness
bursty update rates and
evaluate the effectiveness of
we therefore have a
the effectiveness of our
update rates and yet
effectiveness of our scheme
rates and yet often
and yet often require
yet often require low
often require low latencies
we implemented a prototype
require low latencies and
low latencies and tight
latencies and tight synchronization
and tight synchronization between
to study the properties
tight synchronization between collaborating
study the properties of
mapping between a subservice
the properties of the
synchronization between collaborating users
properties of the cache
between a subservice and
a subservice and a
subservice and a chain
one can often achieve
we only need a
can often achieve better
only need a single
often achieve better performance
need a single column
achieve better performance using
better performance using direct
performance using direct client
gossip based chain replication
based chain replication the
namely a single cache
chain replication the replication
a single cache backed
replication the replication scheme
single cache backed by
the replication scheme has
cache backed by a
replication scheme has evolved
backed by a single
scheme has evolved out
by a single database
has evolved out of
a single database server
evolved out of the
out of the chain
of the chain replication
the chain replication mechanism
chain replication mechanism first
replication mechanism first introduced
mechanism first introduced in
illustrates the structure of
the structure of our
structure of our experimental
of our experimental setup
but in today s
in today s soa
today s soa plat
a single database implements
single database implements a
database implements a transactional
implements a transactional key
band communication is hard
communication is hard to
the original scheme was
is hard to integrate
hard to integrate with
original scheme was developed
to integrate with hosted
scheme was developed as
integrate with hosted content
was developed as a
developed as a means
as a means of
a means of obtaining
this problem is reflected
means of obtaining high
update clients access database
problem is reflected by
of obtaining high throughput
is reflected by a
obtaining high throughput and
reflected by a growing
high throughput and availability
by a growing number
throughput and availability for
a growing number of
which sends invalidations to
and availability for query
sends invalidations to the
growing number of publications
invalidations to the cache
availability for query and
number of publications on
for query and update
of publications on the
query and update requests
publications on the integration
and update requests without
on the integration of
update requests without sacrificing
the integration of web
requests without sacrificing strong
integration of web services
without sacrificing strong consistency
of web services with
sacrificing strong consistency guarantees
web services with peer
only clients access cache
the gossip based chain
gossip based chain replication
based chain replication behaves
chain replication behaves in
replication behaves in the
behaves in the following
in the following manner
the following manner during
receives all transactions and
following manner during normal
all transactions and rigorously
manner during normal operation
transactions and rigorously detects
during normal operation when
and rigorously detects inconsistencies
normal operation when nodes
rigorously detects inconsistencies for
operation when nodes aren
detects inconsistencies for statistics
when nodes aren t
nodes aren t failing
aren t failing or
t failing or restarting
update operations are forwarded
operations are forwarded to
are forwarded to the
forwarded to the head
to the head of
the head of the
head of the chain
a set of cache
set of cache clients
of cache clients perform
cache clients perform readonly
where the request is
clients perform readonly transactions
the request is processed
perform readonly transactions through
request is processed using
readonly transactions through a
is processed using the
transactions through a single
processed using the local
through a single cache
using the local replica
a single cache server
the state changes are
the cache serves the
state changes are passed
cache serves the requests
changes are passed along
serves the requests from
are passed along down
the requests from its
passed along down the
requests from its local
along down the chain
from its local storage
down the chain to
its local storage if
the chain to the
local storage if possible
chain to the next
to the next element
or reads from the
reads from the database
which in turn updates
from the database otherwise
in turn updates it
turn updates it s
updates it s state
it s state and
s state and performs
state and performs the
and performs the same
performs the same operation
the cache registers an
the same operation until
cache registers an upcall
same operation until the
registers an upcall that
operation until the tail
an upcall that can
until the tail is
upcall that can be
the tail is reached
that can be used
can be used by
be used by the
used by the database
by the database to
the database to report
queries can either be
database to report invalidations
can either be directed
either be directed towards
be directed towards a
directed towards a randomly
towards a randomly selected
after each update transaction
a randomly selected process
each update transaction the
randomly selected process in
update transaction the database
selected process in the
transaction the database asynchronously
process in the group
the database asynchronously sends
in the group or
database asynchronously sends invalidations
the group or to
asynchronously sends invalidations to
group or to a
sends invalidations to the
or to a specific
invalidations to the cache
to a specific one
to the cache for
the cache for all
cache for all objects
for all objects that
all objects that were
objects that were modified
the strongest consistency guarantee
strongest consistency guarantee is
consistency guarantee is acheived
guarantee is acheived if
is acheived if all
acheived if all query
if all query operations
all query operations are
query operations are targeted
operations are targeted at
are targeted at the
targeted at the tail
at the tail of
the tail of the
tail of the chain
of the chain node
chosen uniformly at random
which is the case
is the case for
are dropped by the
the case for the
dropped by the experiment
case for the vanilla
for the vanilla chain
the vanilla chain replication
vanilla chain replication scheme
this is extreme and
is extreme and would
however this eliminates the
extreme and would only
this eliminates the opportunity
and would only be
eliminates the opportunity to
would only be seen
the opportunity to load
only be seen in
be seen in the
seen in the real
in the real world
the real world under
real world under conditions
world under conditions of
under conditions of overload
faults and node restarts
conditions of overload or
and node restarts can
of overload or when
node restarts can disrupt
overload or when the
restarts can disrupt the
or when the system
can disrupt the primary
when the system configuration
disrupt the primary communication
the system configuration is
the primary communication pattern
system configuration is changed
primary communication pattern of
communication pattern of the
pattern of the ssa
both the database and
if the head of
the database and the
the head of a
database and the cache
head of a chain
and the cache report
of a chain fails
the cache report all
cache report all completed
report all completed transactions
all completed transactions to
completed transactions to a
update sources will need
transactions to a consistency
sources will need to
to a consistency monitor
will need to discover
yet the issue remains
need to discover a
the issue remains unresolved
to discover a new
discover a new head
created in order to
in order to gather
order to gather statistics
to gather statistics for
if an inner node
gather statistics for our
an inner node crashes
statistics for our evaluation
inner node crashes the
node crashes the chain
crashes the chain may
the chain may break
this server collects both
server collects both committed
collects both committed and
and if the tail
both committed and aborted
cornell s live distributed
committed and aborted transactions
s live distributed objects
and aborted transactions and
if the tail crashes
aborted transactions and it
live distributed objects platform
transactions and it maintains
and it maintains the
it maintains the full
maintains the full dependency
acks might not be
the full dependency graph
might not be sent
not be sent back
it performs full serialization
performs full serialization graph
full serialization graph testing
or some of its
some of its members
live objects for short
and calculates the rate
calculates the rate of
allow even a non
the rate of inconsistent
processes will miss updates
rate of inconsistent transactions
will miss updates and
of inconsistent transactions that
miss updates and hence
inconsistent transactions that committed
updates and hence queries
programmer to construct content
and hence queries will
transactions that committed and
hence queries will return
that committed and the
queries will return outdated
committed and the rate
will return outdated results
and the rate of
rich solutions that blend
the rate of consistent
solutions that blend traditional
rate of consistent transactions
that blend traditional web
of consistent transactions that
blend traditional web services
consistent transactions that were
to repair these inconsistencies
transactions that were unnecessarily
traditional web services and
that were unnecessarily aborted
web services and peer
the ssa implements a
ssa implements a secondary
implements a secondary update
a secondary update propagation
secondary update propagation mechanism
our prototype does not
prototype does not address
does not address the
not address the issue
address the issue of
it uses gossip protocols
the issue of cache
uses gossip protocols to
issue of cache eviction
and to share them
of cache eviction when
to share them with
cache eviction when running
share them with others
gossip protocols to rapidly
eviction when running out
protocols to rapidly detect
when running out of
to rapidly detect and
running out of memory
rapidly detect and repair
detect and repair inconsistencies
this is like creating
is like creating a
like creating a slide
creating a slide show
while simultaneously orchestrating repair
simultaneously orchestrating repair of
orchestrating repair of the
repair of the chain
all objects in the
objects in the workload
in the workload fit
the workload fit in
workload fit in the
the gossip rate can
fit in the cache
gossip rate can be
rate can be tuned
after which the solution
which the solution can
the solution can be
and eviction is only
solution can be shared
eviction is only done
with a higher rate
is only done if
a higher rate overheads
can be shared in
higher rate overheads rise
only done if there
rate overheads rise but
done if there is
overheads rise but repair
if there is a
rise but repair occurs
there is a direct
but repair occurs more
is a direct reason
repair occurs more rapidly
be shared in a
shared in a file
in a file or
a file or via
file or via email
or via email and
via email and opened
email and opened on
and opened on other
had we modeled them
opened on other machines
repair is slower but
is slower but overheads
slower but overheads drop
evictions would reduce the
the users are immersed
would reduce the cache
users are immersed in
reduce the cache hit
the subsections that follow
are immersed in the
the cache hit rate
immersed in the resulting
subsections that follow discuss
in the resulting collaborative
that follow discuss the
the resulting collaborative application
follow discuss the two
discuss the two core
but could not cause
the two core mechanisms
could not cause new
two core mechanisms in
not cause new inconsistencies
core mechanisms in greater
they can interact with
mechanisms in greater detail
can interact with the
interact with the application
with the application and
the application and peers
we evaluate the effectiveness
application and peers see
a second class of
evaluate the effectiveness of
and peers see the
second class of faults
the effectiveness of our
class of faults are
peers see the results
effectiveness of our transactional
see the results instantly
of faults are transient
of our transactional cache
faults are transient and
our transactional cache using
are transient and relate
transactional cache using various
transient and relate to
updates are applied to
and relate to the
cache using various workloads
relate to the behavior
are applied to all
to the behavior of
using various workloads and
the behavior of tcp
applied to all replicas
behavior of tcp when
various workloads and varying
of tcp when a
to all replicas in
tcp when a node
workloads and varying the
when a node is
all replicas in a
a node is subjected
and varying the size
node is subjected to
replicas in a consistent
is subjected to stress
varying the size of
in a consistent manner
the size of the
size of the dependency
of the dependency lists
such as a burst
the dependency lists maintained
as a burst of
dependency lists maintained by
a burst of traffic
lists maintained by the
in contrast to today
maintained by the cache
contrast to today s
by the cache and
to today s web
the cache and the
today s web service
cache and the database
s web service platforms
the os tends to
for the cases considered
os tends to lose
tends to lose packets
to lose packets and
lose packets and the
p communication can coexist
packets and the effect
short dependency lists suffice
communication can coexist with
and the effect is
can coexist with more
the effect is that
coexist with more standard
effect is that tcp
with more standard solutions
is that tcp will
more standard solutions that
that tcp will impose
standard solutions that reach
tcp will impose congestion
solutions that reach back
will impose congestion control
that reach back to
impose congestion control mechanisms
reach back to the
congestion control mechanisms and
back to the hosted
control mechanisms and choke
to the hosted content
mechanisms and choke back
an open question for
the hosted content and
open question for further
hosted content and trigger
question for further study
content and trigger updates
for further study is
and trigger updates at
updates will cease to
trigger updates at the
further study is whether
updates at the associated
will cease to propagate
at the associated data
study is whether there
the associated data centers
cease to propagate down
is whether there are
to propagate down the
whether there are workloads
propagate down the chain
there are workloads that
are workloads that might
workloads that might require
that might require limited
might require limited but
even though most of
require limited but larger
though most of the
limited but larger values
when an application needs
most of the nodes
an application needs high
of the nodes involved
application needs high data
the nodes involved could
needs high data rates
nodes involved could still
note that dependencies arise
involved could still have
that dependencies arise from
could still have ample
dependencies arise from the
still have ample capacity
arise from the topology
from the topology of
the topology of the
topology of the object
of the object graph
it can use protocols
we will show that
can use protocols that
will show that when
and not from the
show that when such
use protocols that bypass
that when such a
not from the size
when such a problem
protocols that bypass the
such a problem arises
from the size of
that bypass the data
the size of the
bypass the data center
size of the transactions
the data center to
of the transactions read
gossip will route data
the transactions read and
data center to achieve
transactions read and write
will route data around
read and write sets
center to achieve the
route data around the
to achieve the full
data around the congested
achieve the full performance
around the congested nodes
as a baseline for
the full performance of
a baseline for comparison
full performance of the
performance of the network
and will also deliver
will also deliver missed
we also implemented a
also deliver missed updates
also implemented a timeout
this paper makes the
deliver missed updates to
paper makes the following
missed updates to the
makes the following contributions
updates to the overloaded
to the overloaded nodes
the overloaded nodes when
overloaded nodes when the
nodes when the problem
we describe a new
when the problem ends
describe a new class
it reduces the probability
a new class of
reduces the probability of
new class of service
the probability of inconsistency
probability of inconsistency by
in the original chain
of inconsistency by limiting
the original chain replication
inconsistency by limiting the
original chain replication scheme
by limiting the life
chain replication scheme the
limiting the life span
replication scheme the queries
the life span of
scheme the queries are
life span of cache
the queries are directed
span of cache entries
queries are directed to
applications that integrate service
are directed to the
that integrate service hosted
directed to the tail
integrate service hosted content
to the tail of
service hosted content with
we compare this method
hosted content with peer
the tail of the
compare this method against
tail of the chain
this method against our
method against our transactional
against our transactional cache
our transactional cache by
transactional cache by measuring
since there is no
cache by measuring its
there is no additional
by measuring its effectiveness
is no additional epidemic
measuring its effectiveness with
no additional epidemic communication
its effectiveness with a
effectiveness with a varying
we analyze two important
with a varying time
analyze two important examples
two important examples of
important examples of soc
any update known to
examples of soc applications
update known to the
known to the tail
to the tail is
the tail is stable
search and rescue mission
tail is stable because
and rescue mission and
is stable because it
rescue mission and virtual
stable because it must
mission and virtual worlds
because it must first
it must first have
must first have been
first have been seen
have been seen by
been seen by all
seen by all the
by all the members
all the members of
the members of the
members of the chain
both read and update
read and update transactions
and update transactions access
we list the key
list the key challenges
to maintain such an
the key challenges that
maintain such an invariant
key challenges that soc
our experiment satisfies all
challenges that soc applications
experiment satisfies all read
that soc applications place
soc applications place on
the original paper includes
applications place on their
original paper includes mechanisms
only transactions from the
place on their runtime
transactions from the cache
paper includes mechanisms to
on their runtime environments
includes mechanisms to ensure
mechanisms to ensure that
to ensure that a
while passing all update
ensure that a request
we describe a new
that a request really
describe a new class
passing all update transactions
a new class of
a request really reaches
new class of multi
all update transactions directly
request really reaches the
update transactions directly to
really reaches the head
transactions directly to the
reaches the head of
directly to the backend
the head of the
layered mashups and contrast
head of the chain
to the backend database
mashups and contrast them
and contrast them with
contrast them with more
them with more traditional
that updates are passed
each cache server is
updates are passed down
cache server is unaware
are passed down the
server is unaware of
passed down the chain
is unaware of the
down the chain and
unaware of the other
the chain and applied
of the other servers
based approach to building
the other servers it
approach to building mashups
chain and applied in
other servers it has
and applied in a
servers it has its
applied in a strictly
it has its own
in a strictly fifo
has its own clients
a strictly fifo manner
its own clients and
characteristic of today s
own clients and communicates
of today s web
strictly fifo manner even
today s web development
clients and communicates directly
fifo manner even when
and communicates directly with
manner even when nodes
communicates directly with the
even when nodes fail
directly with the backend
when nodes fail and
with the backend database
nodes fail and the
we discuss the relative
fail and the chain
discuss the relative advantages
and the chain is
the relative advantages of
the chain is restructured
relative advantages of these
the percentage of read
advantages of these two
of these two approaches
these two approaches for
two approaches for building
and that queries are
approaches for building soc
that queries are sent
for building soc applications
queries are sent to
only transactions can be
are sent to the
transactions can be arbitrarily
sent to the tail
can be arbitrarily high
to the tail of
be arbitrarily high or
the tail of the
arbitrarily high or low
tail of the chain
high or low in
we discuss the advantages
or low in this
low in this situation
discuss the advantages of
the advantages of decoupling
advantages of decoupling transport
strong consistency follows easily
of decoupling transport and
consistency follows easily because
decoupling transport and information
follows easily because query
transport and information layers
easily because query requests
and information layers as
we can push the
information layers as a
can push the percentage
layers as a means
because query requests and
as a means of
push the percentage up
a means of achieving
query requests and update
means of achieving reusability
requests and update requests
and update requests are
update requests are processed
our simulation focuses on
requests are processed serially
simulation focuses on just
are processed serially at
focuses on just a
processed serially at the
on just a single
serially at the tail
ability to rapidly deploy
at the tail element
just a single cache
to rapidly deploy soc
a single cache it
rapidly deploy soc applications
single cache it would
deploy soc applications in
cache it would behave
soc applications in new
it would behave the
the gossip based chain
would behave the same
applications in new environments
behave the same had
gossip based chain replication
the same had there
in new environments and
same had there been
based chain replication weakens
had there been many
new environments and adapt
there been many cache
chain replication weakens the
been many cache servers
environments and adapt them
replication weakens the model
and adapt them dynamically
weakens the model in
adapt them dynamically this
the model in two
them dynamically this work
model in two key
dynamically this work was
in two key respects
this work was supported
cache can be used
can be used with
our solution might sometimes
be used with any
solution might sometimes use
used with any transactional
might sometimes use the
with any transactional backend
sometimes use the wrong
any transactional backend and
use the wrong head
transactional backend and any
the wrong head of
backend and any transactional
wrong head of the
and any transactional workload
head of the chain
qi huang is a
huang is a visiting
for example if an
is a visiting scientist
example if an update
a visiting scientist from
if an update source
visiting scientist from the
an update source is
scientist from the school
update source is operating
from the school of
only transactions will be
the school of computer
transactions will be similar
school of computer sci
will be similar to
source is operating with
be similar to non
is operating with inaccurate
operating with inaccurate membership
with inaccurate membership information
the underlying database is
underlying database is only
huazhong university of sci
database is only accessed
is only accessed on
updates might sometimes arrive
only accessed on cache
might sometimes arrive out
accessed on cache misses
sometimes arrive out of
arrive out of order
supported by the chinese
by the chinese nsfc
for example if the
example if the chain
inconsistencies may be observed
if the chain is
the chain is disrupted
chain is disrupted by
is disrupted by a
disrupted by a failure
by a failure and
a failure and some
failure and some updates
we will use synthetic
and some updates arrive
some updates arrive via
will use synthetic workloads
updates arrive via the
arrive via the gossip
use synthetic workloads so
via the gossip protocol
synthetic workloads so we
workloads so we can
so we can evaluate
we can evaluate how
can evaluate how much
evaluate how much inconsistency
these changes substantially simplify
how much inconsistency can
changes substantially simplify the
much inconsistency can be
substantially simplify the algorithm
inconsistency can be observed
simplify the algorithm but
can be observed as
the algorithm but they
be observed as a
algorithm but they also
observed as a function
but they also weaken
as a function of
they also weaken the
a function of the
also weaken the properties
function of the amount
weaken the properties of
of the amount of
the properties of the
the amount of clustering
properties of the solution
amount of clustering in
of clustering in the
clustering in the workload
a less significant change
less significant change is
significant change is that
this also allows us
change is that we
also allows us to
is that we load
allows us to look
us to look at
to look at the
look at the dynamic
at the dynamic behavior
balance queries over the
the dynamic behavior of
queries over the members
dynamic behavior of the
over the members of
behavior of the system
the members of the
members of the chain
when the amount of
the amount of clustering
amount of clustering and
of clustering and the
clustering and the clustering
but in ways that
and the clustering formation
in ways that seem
the clustering formation change
ways that seem to
clustering formation change over
layered mashup to the
formation change over time
mashup to the changing
that seem to match
to the changing needs
seem to match the
to match the class
match the class of
the class of applications
class of applications of
we discuss the resulting
of applications of interest
discuss the resulting objectoriented
we will look at
the resulting objectoriented perspective
will look at workloads
look at workloads based
at workloads based on
and has the potential
workloads based on amazon
has the potential to
based on amazon s
in which instances of
the potential to greatly
on amazon s product
potential to greatly improve
amazon s product co
to greatly improve query
which instances of distributed
greatly improve query performance
instances of distributed communication
of distributed communication protocols
distributed communication protocols are
purchasing and orkut s
communication protocols are modeled
and orkut s social
protocols are modeled uniformly
orkut s social network
are modeled uniformly as
s social network to
modeled uniformly as objects
social network to see
uniformly as objects similar
network to see how
as objects similar to
to see how much
objects similar to those
see how much inconsistency
similar to those in
how much inconsistency t
to those in java
epidemic dissemination as noted
dissemination as noted earlier
cache can detect as
can detect as a
detect as a function
as a function of
ssa uses gossip to
a function of dependency
uses gossip to detect
function of dependency list
gossip to detect and
of dependency list length
to detect and repair
detect and repair the
and repair the inconsistencies
repair the inconsistencies that
and compare this with
the embedded script is
compare this with a
the inconsistencies that can
this with a ttl
embedded script is often
inconsistencies that can arise
script is often tightly
that can arise after
is often tightly integrated
can arise after a
often tightly integrated with
arise after a failure
tightly integrated with backend
after a failure or
integrated with backend services
a failure or when
with backend services in
we are also interested
failure or when a
are also interested in
backend services in the
also interested in overhead
or when a node
services in the data
when a node joins
in the data center
particularly the additional load
the additional load on
the basic idea is
making it awkward to
basic idea is simple
additional load on the
it awkward to access
load on the backend
awkward to access the
on the backend database
to access the underlying
the backend database that
access the underlying services
each process in the
backend database that could
process in the system
the underlying services directly
in the system runs
database that could form
the system runs a
underlying services directly from
system runs a periodic
that could form if
runs a periodic local
services directly from a
a periodic local timer
could form if the
directly from a different
form if the the
from a different script
if the the rate
a different script or
the the rate of
different script or a
the rate of cache
script or a standalone
without synchronization across processes
or a standalone client
rate of cache misses
of cache misses increases
when a timer expires
a process computes a
the only way such
b presented three strategies
process computes a summary
presented three strategies for
only way such services
three strategies for responding
way such services can
strategies for responding to
such services can be
also called a digest
for responding to inconsistency
services can be mashed
responding to inconsistency detection
can be mashed up
be mashed up with
mashed up with other
up with other web
for both the synthetic
with other web content
both the synthetic and
other web content is
the synthetic and realistic
web content is by
synthetic and realistic workloads
content is by either
is by either having
a list of things
by either having the
list of things that
either having the data
of things that it
having the data center
things that it knows
we compare the efficacy
the data center compute
compare the efficacy of
data center compute the
the efficacy of the
center compute the mashup
efficacy of the three
of the three strategies
this summary is sent
summary is sent to
is sent to a
sent to a randomly
to a randomly selected
so that it can
a randomly selected peer
that it can be
it can be accessed
can be accessed via
be accessed via the
synthetic workloads synthetic workloads
accessed via the minibrowser
or subset of peers
workloads synthetic workloads allow
synthetic workloads allow us
workloads allow us to
allow us to understand
us to understand the
to understand the efficacy
understand the efficacy of
the efficacy of t
quick delivery is more
or by embedding the
delivery is more important
by embedding the entire
is more important than
cache as a function
embedding the entire minibrowser
as a function of
more important than reliability
a function of clustering
the entire minibrowser window
important than reliability for
entire minibrowser window in
than reliability for gossip
minibrowser window in a
reliability for gossip messages
window in a web
in a web page
for the experiments described
the experiments described here
hence we favor udp
we favor udp datagrams
but an embedded minibrowser
favor udp datagrams over
an embedded minibrowser can
udp datagrams over tcp
embedded minibrowser can t
datagrams over tcp for
minibrowser can t seamlessly
cache with a maximum
over tcp for this
with a maximum of
can t seamlessly blend
tcp for this kind
t seamlessly blend with
for this kind of
seamlessly blend with the
this kind of communication
blend with the surrounding
elements per dependency list
with the surrounding content
the recipient compares the
recipient compares the gossiped
compares the gossiped information
it is like a
the gossiped information with
is like a standalone
gossiped information with its
like a standalone browser
information with its own
a standalone browser within
with its own state
standalone browser within its
browser within its own
describes synthetic workload generation
within its own frame
identifying information known to
information known to the
known to the sender
to the sender but
and runs independent of
the sender but unknown
runs independent of the
sender but unknown to
independent of the rest
but unknown to itself
of the rest of
the rest of the
rest of the page
measures how many inconsistencies
or known to it
how many inconsistencies we
known to it but
many inconsistencies we can
to it but apparently
to illustrate this point
inconsistencies we can detect
it but apparently unknown
we can detect as
but apparently unknown to
can detect as a
apparently unknown to the
detect as a function
unknown to the sender
as a function of
a function of clustering
function of clustering and
of clustering and section
clustering and section v
it then sends back
then sends back a
sends back a gossip
back a gossip reply
the figures are screenshots
figures are screenshots of
are screenshots of web
considers clustering changes over
screenshots of web applications
clustering changes over time
using an unreliable datagram
an unreliable datagram protocol
with content from multiple
content from multiple sources
from multiple sources mashed
containing information the sender
information the sender might
the sender might find
sender might find useful
might find useful and
find useful and requesting
compares the efficacy of
useful and requesting information
the efficacy of various
and requesting information it
efficacy of various approaches
requesting information it lacks
of various approaches to
various approaches to dealing
approaches to dealing with
to dealing with detected
was constructed using a
dealing with detected inconsistencies
constructed using a standard
using a standard web
a standard web services
standard web services approach
the originator of the
originator of the exchange
of the exchange will
pulling content from the
the exchange will send
content from the yahoo
exchange will send a
will send a final
send a final message
a final message containing
final message containing any
maps and weather web
message containing any data
our basic synthetic workload
containing any data that
and weather web services
any data that was
basic synthetic workload is
data that was solicited
synthetic workload is constructed
weather web services and
workload is constructed as
that was solicited by
web services and assembling
was solicited by the
is constructed as follows
solicited by the receiver
services and assembling it
and assembling it into
assembling it into a
it into a web
into a web page
gossip messages are bounded
a web page as
messages are bounded in
web page as a
are bounded in size
page as a set
as a set of
a set of tiled
set of tiled frames
thus during a round
during a round each
a round each process
each frame is a
round each process will
frame is a minibrowser
each process will send
is a minibrowser with
process will send a
a minibrowser with its
will send a message
minibrowser with its own
with its own interactive
its own interactive controls
perhaps eliciting a reply
and comes from a
comes from a single
from a single content
a single content source
and perhaps will respond
perhaps will respond to
will respond to that
respond to that reply
to illustrate one of
illustrate one of the
one of the many
of the many restrictions
in the worst case
the objects are divided
objects are divided into
if the user pans
are divided into clusters
the user pans or
divided into clusters of
user pans or zooms
a round results in
pans or zooms in
into clusters of size
or zooms in the
zooms in the map
in the map frame
the associated map will
associated map will shift
the load imposed on
map will shift or
load imposed on the
will shift or zoom
imposed on the network
on the network will
the network will thus
network will thus be
will thus be linear
but the other frames
thus be linear in
the other frames remain
be linear in the
other frames remain as
linear in the number
frames remain as they
in the number of
remain as they were
the number of processes
as they were the
they were the frames
were the frames are
the frames are not
frames are not synchronized
but any individual process
any individual process will
individual process will see
process will see a
will see a constant
see a constant load
independent of system size
here we see a
we see a similar
see a similar application
a similar application constructed
similar application constructed using
application constructed using live
constructed using live objects
the ssa gossips about
ssa gossips about membership
content from different sources
from different sources is
different sources is overlaid
recoveries and application state
sources is overlaid in
is overlaid in the
overlaid in the same
in the same window
the same window and
using this information to
same window and synchronized
this information to initiate
and there are two
information to initiate repairs
there are two types
are two types of
two types of workloads
we used white backgrounds
used white backgrounds to
one form of repair
white backgrounds to highlight
form of repair involves
backgrounds to highlight the
of repair involves disruption
to highlight the contributions
repair involves disruption to
highlight the contributions of
involves disruption to a
the contributions of different
disruption to a chain
clustering is perfect and
contributions of different sources
is perfect and each
perfect and each transaction
and each transaction chooses
each transaction chooses a
if a fault breaks
but there are no
transaction chooses a single
there are no frame
a fault breaks a
are no frame boundaries
chooses a single cluster
fault breaks a chain
a single cluster and
breaks a chain or
single cluster and chooses
a chain or disables
chain or disables the
elements of this mashup
or disables the head
disables the head of
the head of a
head of a chain
times with repetitions within
with repetitions within this
which can include map
repetitions within this cluster
can include map layers
within this cluster to
this cluster to establish
gossip is used to
cluster to establish its
is used to detect
to establish its access
tables showing buildings or
establish its access set
used to detect the
showing buildings or points
to detect the problem
buildings or points of
detect the problem and
or points of interest
in the second type
the problem and repair
the second type of
problem and repair involves
second type of workloads
type of workloads access
and repair involves designating
icons representing severe weather
of workloads access is
representing severe weather reports
repair involves designating a
workloads access is not
involves designating a new
access is not fully
designating a new head
is not fully contained
a new head for
not fully contained within
new head for the
fully contained within each
head for the chain
contained within each cluster
for the chain or
the chain or establishing
chain or establishing a
or establishing a new
establishing a new tcp
when a transaction starts
a new tcp connection
new tcp connection bridging
tcp connection bridging the
connection bridging the gap
it chooses a cluster
chooses a cluster uniformly
exist layers within which
a cluster uniformly at
layers within which the
cluster uniformly at random
a second form of
within which the end
second form of repair
which the end user
form of repair involves
the end user can
of repair involves lost
end user can easily
repair involves lost updates
user can easily navigate
if subservice a has
subservice a has a
data can come from
a has a member
each object is chosen
has a member m
can come from many
a member m that
object is chosen using
member m that knows
come from many kinds
is chosen using a
from many kinds of
chosen using a bounded
many kinds of we
using a bounded pareto
we assume that all
kinds of we discuss
a bounded pareto distribution
assume that all forms
of we discuss our
bounded pareto distribution starting
that all forms of
pareto distribution starting at
we discuss our live
distribution starting at detected
all forms of information
discuss our live distributed
starting at detected inconsistencies
forms of information are
our live distributed objects
of information are uniquely
live distributed objects platform
information are uniquely named
distributed objects platform as
are uniquely named and
objects platform as an
uniquely named and that
platform as an example
named and that updates
as an example of
and that updates are
an example of a
that updates are ordered
example of a technology
updates are ordered separately
of a technology that
are ordered separately by
a technology that fits
ordered separately by each
technology that fits well
separately by each update
that fits well with
by each update source
fits well with the
well with the layered
update clients access the
clients access the database
access the database at
the database at a
of update x and
database at a rate
update x and a
at a rate of
x and a member
componentized model we derived
and a member m
model we derived through
a member m that
we derived through our
member m that lacks
derived through our analysis
m that lacks x
we compare performance of
gossip can be used
compare performance of hosted
can be used to
performance of hosted enterprise
be used to detect
of hosted enterprise service
used to detect this
hosted enterprise service bus
to detect this and
detect this and m
this and m can
and m can then
m can then send
only clients access the
can then send x
clients access the cache
then send x to
access the cache at
send x to m
the cache at a
x to m directly
cache at a rate
at a rate of
without waiting for the
waiting for the chain
for the chain to
peer communication protocols as
the chain to be
communication protocols as an
chain to be repaired
protocols as an underlying
as an underlying communication
an underlying communication substrate
underlying communication substrate for
communication substrate for soc
substrate for soc applications
gossip is not a
is not a particularly
not a particularly fast
the relative strengths of
a particularly fast protocol
relative strengths of each
strengths of each of
of each of the
each of the solutions
of the solutions tested
the solutions tested and
solutions tested and the
tested and the lack
and the lack of
the lack of a
lack of a clear
rounds of the protocol
of a clear winner
of the protocol to
a clear winner serve
the protocol to reach
clear winner serve as
protocol to reach n
winner serve as a
to reach n processes
serve as a further
as a further justification
a further justification for
further justification for the
on the other hand
justification for the decoupling
for the decoupling of
the decoupling of information
decoupling of information and
if rounds occur frequently
of information and transport
information and transport layers
and transport layers advocated
transport layers advocated above
the delay before information
delay before information spreads
before information spreads to
information spreads to all
spreads to all members
to all members of
all members of a
members of a system
of a system may
a system may still
system may still be
may still be small
limitations of the existing
of the existing model
the existing model there
existing model there are
even in a large
model there are two
in a large system
there are two important
are two important reasons
two important reasons why
important reasons why integrating
reasons why integrating peerto
gossip is astonishingly robust
peer collaboration with server
there are exponentially many
hosted content is difficult
are exponentially many paths
exponentially many paths by
many paths by which
paths by which information
the first is not
by which information can
first is not strictly
which information can pass
is not strictly limited
information can pass from
not strictly limited to
can pass from point
strictly limited to collaboration
pass from point a
limited to collaboration and
from point a to
to collaboration and peer
point a to point
a to point b
hence almost any imaginable
almost any imaginable disruption
any imaginable disruption short
imaginable disruption short of
disruption short of a
short of a lasting
of a lasting partitioning
a lasting partitioning failure
lasting partitioning failure can
partitioning failure can be
failure can be overcome
it is a general
is a general weakness
a general weakness of
general weakness of the
the gossip protocols implemented
weakness of the current
gossip protocols implemented in
of the current web
protocols implemented in the
the current web mashup
implemented in the ssa
current web mashup technologies
in the ssa have
web mashup technologies that
the ssa have been
mashup technologies that makes
ssa have been designed
technologies that makes it
have been designed specifically
that makes it hard
been designed specifically for
makes it hard to
designed specifically for use
it hard to seamlessly
specifically for use in
hard to seamlessly integrate
for use in our
to seamlessly integrate data
use in our modified
seamlessly integrate data from
in our modified version
integrate data from several
our modified version of
data from several different
modified version of chain
from several different sources
version of chain replication
the web developers community
and with the goal
web developers community has
with the goal of
ratio of inconsistencies as
the goal of running
developers community has slowly
goal of running in
of inconsistencies as a
of running in large
community has slowly converged
running in large clusters
inconsistencies as a function
in large clusters or
as a function of
large clusters or datacenters
has slowly converged towards
slowly converged towards service
converged towards service platforms
towards service platforms that
the head of its
service platforms that export
head of its cluster
let be a group
of its cluster i
be a group of
platforms that export autonomous
a group of processes
that export autonomous interactive
export autonomous interactive components
autonomous interactive components to
interactive components to their
components to their clients
and let p be
let p be a
p be a process
be a process in
a process in that
process in that group
in the form of
in that group p
the form of what
form of what we
of what we ll
what we ll call
if the pareto variable
we ll call minibrowser
the pareto variable plus
ll call minibrowser interfaces
pareto variable plus the
variable plus the offset
each process has its
plus the offset results
process has its own
the offset results in
has its own view
offset results in a
its own view of
results in a number
own view of the
in a number outside
a minibrowser is an
a number outside the
view of the group
number outside the range
minibrowser is an interactive
is an interactive web
an interactive web page
interactive web page with
web page with embedded
page with embedded script
these views can lag
views can lag reality
optimized for displaying a
for displaying a single
for example if a
displaying a single type
example if a process
a single type of
if a process joins
single type of content
a process joins or
process joins or leaves
for example interactive maps
example interactive maps from
interactive maps from google
the count wraps back
maps from google earth
count wraps back to
from google earth or
google earth or virtual
and different members might
earth or virtual earth
different members might not
members might not have
might not have consistent
not have consistent views
our work assumes that
work assumes that the
our example actually overlays
assumes that the network
example actually overlays weather
that the network within
actually overlays weather from
the network within a
overlays weather from google
network within a cluster
weather from google on
inconsistency detection as a
within a cluster does
detection as a function
from google on terrain
as a function of
a cluster does not
google on terrain maps
cluster does not partition
on terrain maps from
terrain maps from microsoft
maps from microsoft s
we start by exploring
from microsoft s virtual
although there are low
start by exploring the
microsoft s virtual earth
by exploring the importance
s virtual earth platform
exploring the importance of
virtual earth platform and
the importance of the
earth platform and extracts
probability failure patterns that
platform and extracts census
importance of the cluster
and extracts census data
failure patterns that could
of the cluster structure
patterns that could temporarily
extracts census data from
the cluster structure by
census data from the
that could temporarily partition
data from the us
cluster structure by varying
from the us census
could temporarily partition some
the us census bureau
structure by varying the
temporarily partition some subservice
by varying the parameter
partition some subservice in
varying the parameter of
some subservice in a
the parameter of the
subservice in a logical
parameter of the pareto
the lion coexists with
of the pareto distribution
in a logical sense
lion coexists with the
coexists with the lamb
we vary the pareto
vary the pareto parameter
the second problem is
the pareto parameter from
second problem is that
problem is that with
is that with the
that with the traditional
with the traditional style
the traditional style of
traditional style of web
style of web development
process p chooses a
p chooses a random
chooses a random subset
a random subset of
content is assumed to
random subset of a
is assumed to be
subset of a particular
assumed to be fetched
of a particular size
to be fetched from
a particular size view
be fetched from a
fetched from a server
either directly over http
in this experiment we
this experiment we are
experiment we are only
we are only interested
or by interacting with
are only interested in
by interacting with a
only interested in detection
and commences a dialog
interacting with a web
commences a dialog with
with a web service
a dialog with each
dialog with each process
with each process in
so we choose the
each process in the
we choose the abort
process in the set
choose the abort strategy
web pages downloaded by
pages downloaded by clients
downloaded by clients browsers
by clients browsers contain
the initial message is
clients browsers contain embedded
initial message is a
browsers contain embedded addresses
message is a compact
contain embedded addresses of
is a compact state
embedded addresses of specific
a compact state digest
shows the ratio of
addresses of specific servers
the ratio of inconsistencies
compact state digest summarizing
ratio of inconsistencies detected
state digest summarizing the
of inconsistencies detected by
digest summarizing the state
inconsistencies detected by t
summarizing the state of
technologies such as ajax
the state of the
such as ajax allow
state of the sender
as ajax allow for
ajax allow for asynchronous
cache compared to the
compared to the total
to the total number
the follow up dialog
the total number of
follow up dialog consists
total number of potential
up dialog consists of
number of potential inconsistencies
dialog consists of an
consists of an explicit
of an explicit request
an explicit request of
explicit request of missing
request of missing update
of missing update operations
but traffic is still
traffic is still always
is still always routed
still always routed through
always routed through a
several details of the
routed through a data
through a data center
details of the epidemic
of the epidemic protocols
the epidemic protocols employed
epidemic protocols employed in
the clients don t
protocols employed in the
clients don t talk
employed in the framework
don t talk to
in the framework turned
t talk to one
the framework turned out
talk to one another
framework turned out to
turned out to be
out to be important
the distribution is almost
to be important determinants
distribution is almost uniform
be important determinants of
is almost uniform across
important determinants of system
almost uniform across the
determinants of system performance
uniform across the object
of system performance and
across the object set
live objects allow visual
system performance and behavior
objects allow visual content
allow visual content and
visual content and update
content and update events
and the inconsistency detection
and update events to
suppose that a process
update events to be
the inconsistency detection ratio
events to be communicated
that a process disseminates
to be communicated using
inconsistency detection ratio is
a process disseminates information
be communicated using any
detection ratio is low
communicated using any sort
process disseminates information via
using any sort of
ratio is low the
any sort of protocol
disseminates information via epidemics
is low the dependency
information via epidemics about
low the dependency lists
via epidemics about a
the dependency lists are
epidemics about a subject
dependency lists are too
about a subject s
lists are too small
are too small to
too small to hold
small to hold all
to hold all relevant
hold all relevant information
process p gossips about
but also overlay multicast
p gossips about subject
gossips about subject s
about subject s a
subject s a finite
at the other extreme
s a finite number
a finite number of
finite number of times
as long as subject
long as subject s
as subject s is
subject s is hot
even a custom protocol
a custom protocol designed
custom protocol designed by
after which subject s
protocol designed by the
which subject s is
designed by the content
the distribution is so
by the content provider
subject s is no
distribution is so spiked
s is no longer
is so spiked that
is no longer gossiped
so spiked that almost
no longer gossiped about
spiked that almost all
that almost all accesses
almost all accesses of
this makes it possible
all accesses of a
makes it possible to
explicit requests for copies
accesses of a transaction
requests for copies of
of a transaction are
for copies of missed
a transaction are within
it possible to achieve
transaction are within a
copies of missed messages
are within a cluster
possible to achieve extremely
of missed messages are
to achieve extremely high
missed messages are limited
achieve extremely high levels
messages are limited in
extremely high levels of
are limited in size
allowing for perfect inconsistency
high levels of throughput
for perfect inconsistency detection
levels of throughput and
of throughput and latency
to prevent a process
prevent a process that
we note that the
a process that lagged
it also enhances security
note that the rate
process that lagged behind
that the rate of
that lagged behind or
the rate of detected
lagged behind or just
the data center server
behind or just joined
rate of detected inconsistencies
or just joined from
data center server can
of detected inconsistencies is
just joined from trying
center server can t
joined from trying to
detected inconsistencies is so
from trying to catch
server can t see
inconsistencies is so high
trying to catch up
can t see data
to catch up all
is so high at
catch up all at
t see data exchanged
up all at once
so high at this
see data exchanged directly
high at this point
data exchanged directly between
at this point that
exchanged directly between peers
this point that much
which would result in
point that much of
would result in enormous
that much of the
result in enormous messages
much of the load
in enormous messages and
of the load goes
enormous messages and serious
the load goes to
the above discussion motivates
load goes to the
messages and serious fluctuations
goes to the backend
above discussion motivates our
to the backend database
and serious fluctuations in
the backend database and
discussion motivates our problem
backend database and saturates
motivates our problem statement
database and saturates it
serious fluctuations in system
fluctuations in system load
allow web applications to
web applications to overlay
reducing the overall throughput
applications to overlay content
to overlay content from
overlay content from multiple
such a process may
content from multiple sources
a process may need
from multiple sources in
process may need to
multiple sources in a
may need to catch
sources in a layered
need to catch up
in a layered fashion
to catch up over
catch up over many
up over many seconds
such that the distinct
that the distinct content
so far we have
the distinct content layers
explicit message requests are
far we have considered
distinct content layers share
we have considered behavior
message requests are honored
have considered behavior with
content layers share a
considered behavior with static
requests are honored if
behavior with static clusters
layers share a single
are honored if the
share a single view
honored if the requested
a single view and
if the requested messages
single view and remain
the requested messages are
view and remain well
requested messages are still
and remain well synchronized
messages are still in
are still in the
over the entire run
still in the bounded
the entire run of
in the bounded buffers
entire run of each
run of each experiment
of each experiment accesses
each experiment accesses are
experiment accesses are confined
once a message has
accesses are confined to
a message has been
are confined to the
message has been delivered
confined to the same
has been delivered to
or panning should cause
been delivered to the
panning should cause all
delivered to the upper
should cause all layers
to the upper levels
cause all layers to
all layers to respond
layers to respond simultaneously
and it has been
it has been expunged
has been expunged from
and an update in
been expunged from the
an update in any
expunged from the buffers
update in any of
from the buffers located
in any of the
in a real system
any of the layers
the buffers located at
of the layers should
buffers located at the
the layers should be
located at the gossiper
layers should be reflected
at the gossiper level
should be reflected in
be reflected in all
reflected in all other
in all other layers
and so if t
requests are simply ignored
allow updates to be
cache converges to maintain
updates to be carried
the requesting process would
converges to maintain the
to be carried by
requesting process would have
to maintain the correct
process would have to
maintain the correct dependency
would have to try
the correct dependency lists
have to try to
correct dependency lists as
to try to find
dependency lists as clusters
try to find the
lists as clusters change
to find the missing
be carried by the
find the missing data
carried by the protocol
the missing data elsewhere
by the protocol best
our setup serves as
the protocol best matched
setup serves as a
protocol best matched to
serves as a valid
best matched to the
as a valid quasi
matched to the setting
to the setting in
the setting in which
if data cannot be
setting in which the
data cannot be recovered
in which the application
which the application is
the application is used
we signal this to
signal this to the
this to the application
we investigate the convergence
to the application by
investigate the convergence of
the application by delivering
the convergence of t
application by delivering an
by delivering an exception
the solutions discussed here
delivering an exception upcall
solutions discussed here are
discussed here are based
here are based on
cache when clusters change
are based on live
when clusters change over
based on live objects
clusters change over time
since the dependency lists
and leave it to
the dependency lists of
leave it to the
dependency lists of the
it to the application
lists of the objects
to the application to
of the objects are
the application to decide
the objects are updated
application to decide how
objects are updated using
to decide how to
are updated using lru
decide how to handle
how to handle the
to handle the problem
the dependency list of
dependency list of an
the size of the
list of an object
size of the buffers
new types of components
of an object o
of the buffers is
types of components must
the buffers is configurable
an object o tends
of components must be
object o tends to
components must be created
o tends to include
must be created for
tends to include those
be created for each
to include those objects
created for each type
but this rule implies
include those objects that
for each type of
those objects that are
each type of content
objects that are frequently
this rule implies that
that are frequently accessed
rule implies that certain
are frequently accessed together
implies that certain kinds
frequently accessed together with
that certain kinds of
accessed together with o
but the existing collection
certain kinds of failures
the existing collection of
kinds of failures may
existing collection of components
of failures may be
collection of components provides
failures may be unrecoverable
dependencies in a new
may be unrecoverable within
of components provides access
be unrecoverable within the
in a new cluster
unrecoverable within the ssa
components provides access to
a new cluster automatically
provides access to several
new cluster automatically push
access to several different
cluster automatically push out
to several different types
automatically push out dependencies
several different types of
digests are bounded in
push out dependencies that
different types of web
out dependencies that are
types of web services
dependencies that are now
of web services hosted
that are now outside
web services hosted content
are now outside the
are bounded in the
now outside the cluster
bounded in the number
in the number of
the number of messages
including all the examples
number of messages they
all the examples given
of messages they advertise
the examples given above
messages they advertise about
they advertise about in
advertise about in one
about in one single
in one single datagram
one single datagram packet
we perform an experiment
perform an experiment where
an experiment where accesses
experiment where accesses suddenly
where accesses suddenly become
accesses suddenly become clustered
and each round only
the resulting live application
each round only a
resulting live application is
round only a single
live application is stored
only a single digest
application is stored as
a single digest is
initially accesses are uniformly
single digest is disseminated
is stored as an
accesses are uniformly at
stored as an xml
are uniformly at random
as an xml file
uniformly at random from
at random from the
even if the subset
random from the entire
if the subset view
from the entire set
the subset view selected
the file can be
file can be moved
can be moved about
be moved about and
moved about and even
about and even embedded
and even embedded in
even embedded in email
has cardinality greater than
cardinality greater than one
users that open it
that open it find
open it find themselves
messages that are potentially
it find themselves immersed
that are potentially in
find themselves immersed into
are potentially in transit
themselves immersed into the
potentially in transit are
immersed into the application
in transit are not
transit are not retransmitted
are not retransmitted to
then at a single
not retransmitted to requesting
at a single moment
retransmitted to requesting processes
several transport protocols optimized
a single moment they
transport protocols optimized for
single moment they become
protocols optimized for various
moment they become perfectly
optimized for various settings
they become perfectly clustered
for example if a
for various settings are
become perfectly clustered into
example if a process
perfectly clustered into clusters
various settings are or
clustered into clusters of
settings are or will
into clusters of size
if a process p
are or will be
or will be available
a process p makes
will be available in
be available in a
process p makes an
available in a near
in a near future
p makes an explicit
makes an explicit request
transactions are aborted on
an explicit request for
are aborted on detecting
including support for wan
explicit request for a
support for wan networks
aborted on detecting an
for wan networks with
on detecting an inconsistency
wan networks with nats
request for a message
networks with nats and
with nats and firewalls
for a message m
a message m and
we use a transaction
message m and the
use a transaction rate
m and the request
a transaction rate of
and the request lands
transaction rate of approximately
the request lands at
request lands at process
lands at process q
at process q that
process q that has
q that has already
that has already sent
has already sent p
already sent p a
sent p a copy
p a copy of
a copy of m
copy of m in
of m in the
m in the recent
in the recent past
the recent past then
recent past then m
past then m will
then m will not
m will not be
will not be retransmitted
a process creates a
process creates a digest
creates a digest based
a digest based upon
digest based upon all
based upon all the
upon all the messages
all the messages received
high throughput and very
the messages received by
throughput and very large
shows the percentage of
and very large numbers
messages received by means
very large numbers of
the percentage of transactions
large numbers of nodes
received by means of
percentage of transactions that
by means of any
of transactions that commit
means of any communication
transactions that commit and
of any communication channels
that commit and are
commit and are consistent
not just the epidemics
the percentage of transactions
percentage of transactions that
of transactions that commit
transactions that commit but
that commit but are
commit but are inconsistent
the messages received by
messages received by fifo
large numbers of irregularly
received by fifo chained
numbers of irregularly overlapping
by fifo chained channels
of irregularly overlapping multicast
irregularly overlapping multicast groups
and the percentage of
the percentage of transactions
percentage of transactions that
the message buffers are
of transactions that abort
message buffers are bounded
and once a message
once a message has
a message has been
message has been delivered
has been delivered by
been delivered by means
delivered by means of
by means of an
means of an upcall
of an upcall it
and strong reliability properties
an upcall it is
upcall it is prone
it is prone to
is prone to be
prone to be replaced
to be replaced by
be replaced by the
replaced by the replacement
by the replacement policy
the ssa implements several
ssa implements several replacement
implements several replacement policies
most advertised message in
advertised message in digests
although the ssa should
the ssa should work
ssa should work well
should work well on
work well on clusters
well on clusters with
on clusters with as
clusters with as many
before saying more about
with as many as
saying more about our
as many as thousands
more about our approach
many as thousands of
as thousands of nodes
we analyze a concrete
companies like google and
analyze a concrete example
like google and amazon
a concrete example of
google and amazon reportedly
concrete example of a
and amazon reportedly operate
example of a soc
amazon reportedly operate centers
of a soc application
reportedly operate centers with
a soc application more
operate centers with tens
soc application more carefully
centers with tens of
application more carefully to
with tens of thousands
more carefully to expose
tens of thousands of
carefully to expose the
of thousands of machines
to expose the full
thousands of machines in
expose the full range
of machines in them
the full range of
full range of needs
range of needs and
of needs and issues
needs and issues that
and issues that arise
and are said to
are said to deploy
said to deploy some
to deploy some popular
consider a rescue mission
abort evict retry behavior
deploy some popular services
evict retry behavior on
a rescue mission coordinator
retry behavior on inconsistency
some popular services on
behavior on inconsistency detection
popular services on huge
services on huge numbers
on huge numbers of
huge numbers of nodes
a police or fire
police or fire chief
or fire chief coordinating
fire chief coordinating teams
were we to use
chief coordinating teams who
we to use the
coordinating teams who will
to use the ssa
teams who will enter
use the ssa in
who will enter a
the ssa in such
will enter a disaster
ssa in such settings
enter a disaster zone
a disaster zone in
disaster zone in the
zone in the wake
in the wake of
our gossip protocol might
the wake of a
gossip protocol might need
wake of a catastrophe
protocol might need to
of a catastrophe to
might need to be
a catastrophe to help
need to be revisited
catastrophe to help survivors
to be revisited to
be revisited to ensure
revisited to ensure that
to ensure that messages
ensure that messages do
that messages do not
messages do not become
do not become excessively
not become excessively large
one way to accomplish
way to accomplish this
to accomplish this might
accomplish this might be
this might be to
might be to modify
be to modify the
to modify the epidemic
modify the epidemic protocol
the epidemic protocol using
epidemic protocol using spatial
protocol using spatial distributions
using spatial distributions to
spatial distributions to improve
distributions to improve the
to improve the performance
and move supplies as
move supplies as needed
such an approach would
would arrive on the
an approach would let
arrive on the scene
approach would let us
would let us restrict
let us restrict information
us restrict information to
build a new collaboration
restrict information to the
a new collaboration tool
information to the vicinity
to the vicinity of
the vicinity of the
vicinity of the nodes
of the nodes where
and distribute it to
the nodes where it
distribute it to his
nodes where it might
where it might be
it might be needed
in effect adding an
each team member would
effect adding an additional
team member would carry
adding an additional layer
member would carry a
an additional layer of
would carry a tablet
additional layer of hierarchy
layer of hierarchy to
of hierarchy to the
hierarchy to the architecture
style device with wireless
device with wireless communication
with wireless communication capabilities
we believe the required
believe the required changes
the required changes would
required changes would be
the application built by
changes would be relatively
application built by the
would be relatively minor
built by the coordinator
by the coordinator would
the coordinator would be
coordinator would be installed
s accesses are uniformly
would be installed on
accesses are uniformly at
be installed on each
are uniformly at random
installed on each team
on each team member
each team member s
team member s mobile
member s mobile device
and in the offices
in the offices in
the offices in mission
offices in mission headquarters
epidemic analytical model one
the coordinator would then
analytical model one benefit
coordinator would then deploy
model one benefit of
would then deploy teams
one benefit of using
then deploy teams in
benefit of using gossip
deploy teams in the
of using gossip in
teams in the field
the efficacy of t
using gossip in the
gossip in the ssa
in the ssa is
the ssa is that
our rescue workers now
cache as a function
rescue workers now use
as a function of
ssa is that we
a function of the
workers now use the
function of the strategy
now use the solution
of the strategy taken
use the solution to
is that we can
the solution to coordinate
that we can use
solution to coordinate and
the strategy taken for
to coordinate and prioritize
we can use analytical
strategy taken for handling
coordinate and prioritize actions
can use analytical methods
taken for handling detected
use analytical methods to
for handling detected inconsistencies
analytical methods to predict
methods to predict the
to predict the behavior
inform each other of
predict the behavior of
each other of the
the behavior of a
other of the evolving
behavior of a cluster
of the evolving situation
complementing our experimental work
steer clear of hazards
of the uncommitable tranasctions
a basic result of
basic result of epidemic
result of epidemic theory
as new events occur
of epidemic theory states
and evict and retry
epidemic theory states that
evict and retry reduce
theory states that simple
and retry reduce the
the situational status would
states that simple epidemics
situational status would evolve
retry reduce the rate
that simple epidemics eventually
reduce the rate of
simple epidemics eventually infect
the rate of uncommitable
epidemics eventually infect the
rate of uncommitable transactions
eventually infect the entire
of uncommitable transactions to
infect the entire population
uncommitable transactions to about
and the team member
the entire population with
the team member who
entire population with probability
team member who causes
member who causes or
who causes or observes
causes or observes these
or observes these status
observes these status changes
these status changes would
status changes would need
moreover starting with a
changes would need to
starting with a single
would need to report
with a single infected
need to report them
a single infected site
to report them to
single infected site this
report them to the
the middle portion is
infected site this is
middle portion is committed
them to the others
portion is committed transactions
site this is achieved
is committed transactions that
this is achieved in
committed transactions that are
is achieved in expected
transactions that are inconsistent
achieved in expected time
in expected time proportional
expected time proportional to
time proportional to the
and the top portion
proportional to the log
the top portion is
removing debris blocking access
top portion is aborted
to the log of
portion is aborted transactions
debris blocking access to
the log of the
blocking access to a
log of the population
access to a building
of the population size
to a building may
a building may enable
building may enable the
may enable the team
enable the team to
the team to check
team to check it
to check it for
check it for victims
and fire that breaks
fire that breaks out
that breaks out in
the protocol roughly falls
breaks out in a
protocol roughly falls under
out in a chemical
roughly falls under the
in a chemical storage
falls under the category
a chemical storage warehouse
under the category of
chemical storage warehouse may
the category of a
storage warehouse may force
category of a push
warehouse may force diversion
may force diversion of
force diversion of resources
and the exact formula
the exact formula for
as rescue workers capture
exact formula for it
rescue workers capture information
formula for it can
for it can be
it can be expressed
can be expressed as
be expressed as log
their mobile devices send
mobile devices send updates
devices send updates that
send updates that must
updates that must be
that must be propagated
must be propagated in
be propagated in real
having defined the scenario
now let s analyze
let s analyze in
s analyze in more
analyze in more detail
in more detail the
more detail the requirements
detail the requirements it
the requirements it places
requirements it places on
it places on our
places on our collaboration
on our collaboration tool
for large values of
large values of n
where n the number
n the number of
the collaboration tool pulls
the number of sites
collaboration tool pulls data
number of sites participating
tool pulls data from
of sites participating in
pulls data from many
sites participating in the
data from many kinds
participating in the epidemic
from many kinds of
in the epidemic spread
many kinds of sources
let pi be the
it makes far more
pi be the probability
makes far more sense
be the probability that
far more sense to
the probability that a
more sense to imagine
probability that a site
sense to imagine that
that a site remains
to imagine that weather
a site remains susceptible
imagine that weather information
not touched by the
touched by the epidemic
after the ith round
the ith round of
ith round of the
round of the protocol
a site remains susceptible
site remains susceptible after
remains susceptible after the
susceptible after the i
messages and alerts come
and alerts come from
alerts come from a
come from a dozen
th round if it
from a dozen providers
round if it was
a dozen providers than
if it was susceptible
dozen providers than to
it was susceptible after
providers than to assume
was susceptible after the
than to assume that
susceptible after the ith
to assume that one
after the ith cycle
assume that one organization
the ith cycle and
that one organization would
ith cycle and it
one organization would be
cycle and it is
organization would be hosting
and it is not
would be hosting services
it is not contacted
be hosting services with
is not contacted by
hosting services with everything
not contacted by any
services with everything we
contacted by any infectious
with everything we need
by any infectious site
everything we need in
any infectious site in
we need in one
infectious site in the
need in one place
site in the i
data from distinct sources
from distinct sources could
distinct sources could have
sources could have different
could have different format
have different format and
different format and one
format and one will
and one will often
one will often need
will often need to
often need to interface
need to interface to
to interface to each
interface to each using
to each using its
each using its own
using its own protocols
relation that we obtain
its own protocols and
that we obtain is
own protocols and interfaces
as conditions evolve the
conditions evolve the team
evolve the team might
the team might need
team might need to
might need to be
need to be modify
to be modify the
be modify the application
for example adding new
example adding new types
adding new types of
new types of information
since infection starts with
infection starts with one
starts with one site
changing the way it
the way it is
way it is represented
for any randomly chosen
any randomly chosen site
randomly chosen site p
or even modifying the
even modifying the way
modifying the way team
the way team members
way team members communicate
perfectly clustered synthetic workload
clustered synthetic workload where
synthetic workload where the
workload where the clusters
where the clusters shift
the clusters shift by
back network links fail
marked by vertical lines
as a function of
whereas a minibrowser would
a function of the
a minibrowser would typically
function of the rate
minibrowser would typically be
of the rate of
would typically be prebuilt
the rate of gossip
typically be prebuilt with
be prebuilt with all
prebuilt with all the
with all the available
all the available features
the available features in
we can predict the
available features in place
s access is unclustered
can predict the delay
predict the delay before
the delay before a
and as a result
our scenario demands a
as a result the
delay before a typical
a result the dependency
scenario demands a much
result the dependency lists
before a typical process
the dependency lists are
demands a much more
dependency lists are useless
a typical process that
a much more flexible
typical process that has
much more flexible kind
process that has been
more flexible kind of
only few inconsistencies are
flexible kind of tool
few inconsistencies are detected
that has been disrupted
kind of tool that
has been disrupted by
of tool that can
been disrupted by a
tool that can be
disrupted by a failure
that can be redesigned
by a failure will
can be redesigned while
a failure will learn
be redesigned while in
failure will learn about
redesigned while in use
will learn about inconsistency
learn about inconsistency introduced
about inconsistency introduced by
inconsistency introduced by the
introduced by the failure
by the failure and
the failure and can
failure and can initiate
and can initiate repair
depending on the location
of the transactions that
on the location and
the transactions that commit
the location and other
transactions that commit have
location and other factors
that commit have witnessed
commit have witnessed inconsistent
have witnessed inconsistent data
if the model predicts
the best networking protocols
the model predicts that
best networking protocols and
model predicts that for
networking protocols and connectivity
predicts that for a
protocols and connectivity options
that for a given
and connectivity options may
for a given gossip
connectivity options may vary
a given gossip rate
in our rescue scenario
a broken chain should
broken chain should be
chain should be repaired
should be repaired within
accesses become perfectly clustered
the workers may have
workers may have to
may have to use
have to use wireless
to use wireless p
we see fast improvement
p protocols much of
see fast improvement of
protocols much of the
fast improvement of inconsistency
much of the time
improvement of inconsistency detection
one can anticipate that
can anticipate that the
reaching back to hosted
the inconsistency rate drops
anticipate that the disruption
back to hosted services
inconsistency rate drops as
that the disruption associated
rate drops as the
to hosted services only
drops as the abort
the disruption associated with
as the abort rate
hosted services only intermittently
disruption associated with a
the abort rate rises
services only intermittently when
associated with a failure
abort rate rises this
only intermittently when a
with a failure should
intermittently when a drone
rate rises this is
when a drone aircraft
rises this is desired
a drone aircraft passes
this is desired as
drone aircraft passes within
is desired as well
a failure should be
aircraft passes within radio
failure should be limited
passes within radio range
should be limited to
be limited to the
the overall rate of
limited to the maximum
overall rate of consistent
to the maximum number
rate of consistent committed
the maximum number of
of consistent committed transactions
maximum number of updates
the right choice of
consistent committed transactions drops
right choice of protocol
number of updates that
committed transactions drops because
choice of protocol should
of updates that would
of protocol should reflect
transactions drops because the
protocol should reflect the
updates that would be
should reflect the operating
drops because the probability
reflect the operating conditions
that would be sent
because the probability of
would be sent to
the probability of conflicts
be sent to a
probability of conflicts in
sent to a given
of conflicts in the
to a given subservice
conflicts in the clustered
a given subservice during
in the clustered scenario
given subservice during a
the clustered scenario is
and if these change
clustered scenario is higher
the platform should be
platform should be capable
should be capable of
be capable of swapping
to illustrate more realistic
capable of swapping in
illustrate more realistic behavior
of swapping in a
swapping in a different
in a different protocol
a different protocol without
different protocol without disrupting
we use clustered accesses
protocol without disrupting the
use clustered accesses that
without disrupting the end
clustered accesses that slowly
if we know how
accesses that slowly drift
disrupting the end user
we know how large
know how large the
how large the typical
large the typical update
the typical update is
transactions are perfectly clustered
this argues for a
argues for a decoupling
for a decoupling of
a decoupling of functionality
as in the previous
in the previous experiment
and we know the
whereas a minibrowser packages
we know the size
a minibrowser packages it
know the size limit
minibrowser packages it all
the size limit on
packages it all into
size limit on data
it all into one
limit on data sent
all into one object
on data sent in
minutes the cluster structure
data sent in response
the cluster structure shifts
sent in response to
cluster structure shifts by
in response to explicit
response to explicit requests
better is a design
is a design in
a design in which
we can predict the
design in which the
can predict the amount
in which the presentation
predict the amount of
which the presentation object
the amount of time
the presentation object is
amount of time that
presentation object is distinct
of time that will
object is distinct from
time that will be
is distinct from objects
that will be needed
distinct from objects representing
will be needed to
from objects representing information
be needed to repair
objects representing information sources
needed to repair the
representing information sources and
to repair the resulting
information sources and objects
repair the resulting data
sources and objects representing
the resulting data inconsistency
and objects representing transport
objects representing transport protocols
these capabilities should help
decoupling makes it possible
capabilities should help the
makes it possible to
should help the developer
it possible to dynamically
help the developer parameterize
possible to dynamically modify
the developer parameterize the
to dynamically modify or
developer parameterize the cluster
dynamically modify or even
parameterize the cluster to
modify or even replace
the cluster to balance
or even replace a
cluster to balance overhead
even replace a component
to balance overhead for
replace a component with
balance overhead for gossip
a component with some
overhead for gossip against
component with some other
for gossip against repair
gossip against repair times
against repair times desired
repair times desired by
times desired by the
desired by the application
option when changing conditions
when changing conditions require
changing conditions require it
membership some readers may
some readers may be
we have posed what
readers may be curious
have posed what may
may be curious about
posed what may sound
be curious about what
what may sound like
curious about what will
may sound like a
about what will seem
sound like a very
what will seem to
like a very specialized
will seem to be
a very specialized problem
seem to be a
to be a chicken
but in fact we
in fact we see
fact we see this
we see this as
see this as a
this as a good
as a good example
on the one hand
a good example of
good example of a
example of a more
of a more general
we use gossip epidemics
a more general kind
use gossip epidemics to
more general kind of
gossip epidemics to propagate
and wrapping back to
epidemics to propagate information
wrapping back to zero
to propagate information about
back to zero after
general kind of need
propagate information about membership
kind of need that
information about membership changes
of need that could
need that could arise
that could arise in
could arise in many
arise in many kinds
in many kinds of
yet the gossip protocol
many kinds of settings
the gossip protocol uses
gossip protocol uses membership
protocol uses membership information
uses membership information to
membership information to select
information to select gossip
to select gossip peers
consider a physician treating
a physician treating a
physician treating a patient
treating a patient with
a patient with a
patient with a complex
our solution starts with
with a complex condition
solution starts with approximate
starts with approximate membership
with approximate membership information
who needs collaboration help
needs collaboration help from
collaboration help from specialists
extracted from a group
from a group management
a group management service
the objects dependency lists
and who might even
group management service component
objects dependency lists are
who might even be
dependency lists are outdated
management service component that
might even be working
service component that list
even be working in
component that list the
be working in a
that list the nodes
this leads to a
working in a remote
leads to a sudden
list the nodes in
in a remote location
to a sudden increased
a remote location under
the nodes in the
remote location under conditions
a sudden increased inconsistency
location under conditions demanding
nodes in the cluster
under conditions demanding urgent
sudden increased inconsistency rate
conditions demanding urgent action
in the cluster and
increased inconsistency rate that
the cluster and the
inconsistency rate that converges
cluster and the rough
rate that converges back
and the rough mapping
the mixture of patient
that converges back to
mixture of patient data
the rough mapping of
converges back to zero
rough mapping of services
mapping of services to
of services to those
services to those nodes
until this convergence is
this convergence is interrupted
convergence is interrupted by
is interrupted by the
interrupted by the next
by the next shift
and then refines this
then refines this with
refines this with incremental
this with incremental updates
a different concern relates
may be just as
different concern relates to
be just as rich
concern relates to behavior
just as rich and
relates to behavior when
as rich and dynamic
to behavior when membership
rich and dynamic as
behavior when membership information
and dynamic as in
when membership information is
dynamic as in our
membership information is perceived
as in our search
information is perceived differently
in our search and
is perceived differently at
our search and rescue
perceived differently at different
search and rescue scenario
differently at different nodes
b presented three possible
presented three possible strategies
three possible strategies for
and the underlying communication
possible strategies for the
the underlying communication options
strategies for the cache
underlying communication options equally
for the cache to
communication options equally heterogeneous
although such a condition
options equally heterogeneous and
the cache to deal
equally heterogeneous and unpredictable
such a condition may
cache to deal with
a condition may arise
to deal with inconsistency
condition may arise during
deal with inconsistency detection
may arise during transitional
arise during transitional periods
designed for a wired
for a wired environment
these quickly resolve as
a wired environment might
quickly resolve as additional
wired environment might perform
resolve as additional rounds
environment might perform poorly
as additional rounds of
might perform poorly or
additional rounds of gossip
perform poorly or fail
rounds of gossip replace
poorly or fail under
of gossip replace stale
or fail under such
gossip replace stale data
fail under such conditions
replace stale data with
stale data with more
data with more accurate
if there is a
there is a way
is a way to
a way to solve
way to solve the
to solve the problem
we have never observed
have never observed a
never observed a membership
there is a way
observed a membership inconsistency
is a way to
a membership inconsistency that
a way to build
membership inconsistency that persisted
aborting and evicting value
inconsistency that persisted for
way to build the
that persisted for longer
to build the desired
persisted for longer than
build the desired mashup
for longer than a
longer than a few
than a few hundred
a few hundred milliseconds
throughout the above we
the above we noted
above we noted requirements
the ssa is quite
ssa is quite tolerant
is quite tolerant of
quite tolerant of short
we now summarize them
now summarize them below
customuserserviceapp heartbeatmonitor gossiper subserviceprocess
heartbeatmonitor gossiper subserviceprocess chainlink
gossiper subserviceprocess chainlink subservicecontrol
subserviceprocess chainlink subservicecontrol nonblockingtransport
these needs are seen
through when possible as
needs are seen in
when possible as in
are seen in many
possible as in cache
seen in many settings
as in cache miss
we believe them to
believe them to be
them to be typical
to be typical of
be typical of most
the component stack of
typical of most soc
component stack of one
of most soc applications
stack of one subservice
we will now compare
of one subservice process
will now compare their
now compare their efficacies
we would like to
would like to enable
like to enable a
to enable a non
we use the approximate
use the approximate clusters
the approximate clusters workload
approximate clusters workload with
programmer to rapidly develop
failure and recovery process
to rapidly develop a
and recovery process failure
rapidly develop a new
recovery process failure detection
develop a new collaborative
process failure detection is
a new collaborative application
failure detection is accomplished
new collaborative application by
detection is accomplished by
collaborative application by composing
is accomplished by means
application by composing together
accomplished by means of
by composing together and
by means of two
composing together and customizing
means of two mechanisms
together and customizing preexisting
and customizing preexisting components
a window size of
detecting fifo channels that
fifo channels that break
we would like to
would like to be
like to be able
to be able to
be able to overlay
in our case they
able to overlay data
a pareto parameter of
to overlay data from
our case they are
overlay data from multiple
case they are tcp
data from multiple sources
they are tcp channels
are tcp channels with
tcp channels with low
channels with low value
with low value for
potentially in different formats
low value for the
value for the so
for the so timeout
the so timeout property
obtained using different protocols
using different protocols and
different protocols and inconsistent
and the maximum dependency
protocols and inconsistent interfaces
the maximum dependency list
maximum dependency list size
dependency list size is
list size is set
size is set to
we would like to
would like to be
like to be able
based heartbeat detection mechanism
to be able to
be able to dynamically
able to dynamically customize
to dynamically customize the
dynamically customize the application
once a process is
customize the application at
a process is deceased
the application at runtime
the information is propagated
information is propagated within
is propagated within the
propagated within the group
within the group in
the group in two
group in two ways
the lower portion of
lower portion of the
portion of the graph
of the graph is
by incorporating new data
the graph is the
incorporating new data sources
the process that has
graph is the ratio
new data sources or
process that has detected
is the ratio of
data sources or changing
that has detected the
sources or changing the
the ratio of committed
or changing the way
has detected the membership
changing the way data
ratio of committed transactions
the way data is
detected the membership change
of committed transactions that
way data is presented
the membership change feeds
committed transactions that the
membership change feeds the
transactions that the abort
change feeds the event
that the abort strategy
feeds the event description
the abort strategy provides
the event description into
abort strategy provides a
event description into the
strategy provides a significant
description into the chain
provides a significant improvement
into the chain itself
and without disrupting system
a significant improvement over
without disrupting system operation
significant improvement over a
improvement over a normal
this is delivered in
is delivered in chain
we would like to
delivered in chain order
would like to be
in chain order to
like to be able
chain order to every
to be able to
order to every non
be able to accommodate
able to accommodate new
to accommodate new types
accommodate new types of
new types of data
faulty process and where
as the strategy detects
process and where necessary
types of data sources
the strategy detects and
strategy detects and aborts
detects and aborts over
chain repair procedure is
repair procedure is undertaken
new formats or protocols
formats or protocols that
or protocols that we
protocols that we may
that we may not
we may not have
may not have anticipated
not have anticipated at
the same detector process
of all inconsistent transactions
have anticipated at the
same detector process starts
anticipated at the time
all inconsistent transactions that
at the time the
detector process starts up
the time the system
inconsistent transactions that would
time the system was
process starts up a
the system was released
transactions that would have
starts up a backup
that would have been
up a backup gossip
would have been committed
a backup gossip notification
backup gossip notification stream
data might be published
might be published by
be published by the
but the other strategies
published by the individual
the other strategies make
by the individual users
other strategies make further
this is a fast
strategies make further improvements
is a fast dying
a fast dying epidemic
and it might be
evict reduces uncommittable transactions
it might be necessary
reduces uncommittable transactions to
it spreads rapidly but
might be necessary for
spreads rapidly but also
be necessary for the
rapidly but also dies
necessary for the users
but also dies out
for the users to
also dies out rapidly
the users to exchange
users to exchange their
to exchange their data
exchange their data without
the fifo channels are
their data without access
of its value with
data without access to
its value with abort
fifo channels are rebuilt
without access to a
channels are rebuilt appropriately
access to a centralized
are rebuilt appropriately by
to a centralized repository
this indicates that violating
rebuilt appropriately by the
appropriately by the processes
by the processes that
the processes that identify
data may be obtained
processes that identify themselves
may be obtained using
that identify themselves to
be obtained using different
identify themselves to be
obtained using different types
themselves to be affected
using different types of
to be affected by
different types of network
be affected by the
types of network protocols
cache entries are likely
affected by the membership
entries are likely to
by the membership change
are likely to be
likely to be repeat
to be repeat offenders
and the type of
the type of the
type of the physical
and the group converges
of the physical network
the group converges to
they are too old
group converges to a
the physical network or
are too old for
converges to a stable
physical network or protocols
to a stable configuration
too old for objects
network or protocols may
old for objects that
or protocols may not
for objects that are
protocols may not be
objects that are likely
may not be known
that are likely to
not be known in
are likely to be
be known in advance
likely to be accessed
update sources can use
to be accessed together
sources can use this
be accessed together with
can use this update
accessed together with them
it should be possible
use this update to
together with them in
should be possible to
with them in future
this update to reconnect
be possible to rapidly
them in future transactions
update to reconnect to
possible to rapidly compose
to reconnect to a
to rapidly compose the
reconnect to a new
rapidly compose the application
to a new head
compose the application using
and so it is
a new head of
the application using whatever
so it is better
new head of any
it is better to
application using whatever communication
is better to evict
using whatever communication infrastructure
better to evict them
head of any chain
whatever communication infrastructure is
of any chain that
communication infrastructure is currently
any chain that may
infrastructure is currently available
chain that may have
retry reduces uncommittable transactions
that may have lost
reduces uncommittable transactions further
may have lost its
uncommittable transactions further to
have lost its previous
transactions further to about
users may be mobile
lost its previous head
may be mobile or
its previous head as
be mobile or temporarily
previous head as a
mobile or temporarily disconnected
head as a consequence
as a consequence of
a consequence of the
consequence of the crash
of its value with
its value with abort
and the topology of
the topology of the
topology of the network
if a process wants
of the network and
a process wants to
the network and its
process wants to join
network and its characteristics
and its characteristics might
realistic workloads we now
its characteristics might change
workloads we now evaluate
characteristics might change over
we now evaluate the
might change over time
now evaluate the efficacy
it starts by sending
evaluate the efficacy of
starts by sending a
the efficacy of t
by sending a request
the system should be
sending a request to
system should be easily
a request to a
should be easily reconfigurable
request to a random
to a random member
cache with workloads based
a random member of
with workloads based on
random member of the
workloads based on two
the requirements outlined above
member of the group
based on two sampled
requirements outlined above might
on two sampled topologies
outlined above might seem
two sampled topologies from
above might seem hard
sampled topologies from the
might seem hard to
topologies from the online
seem hard to satisfy
from the online retailer
the online retailer amazon
the group member will
online retailer amazon and
group member will commence
retailer amazon and the
member will commence a
amazon and the social
will commence a membership
and the social network
commence a membership change
the social network orkut
the solution is surprisingly
a membership change protocol
solution is surprisingly simple
membership change protocol as
change protocol as described
protocol as described above
our analysis motivates a
analysis motivates a component
again once all the
once all the nodes
all the nodes receive
the nodes receive the
describes how we generated
nodes receive the membership
how we generated these
receive the membership event
we generated these workloads
the membership event and
in which the web
membership event and update
which the web services
event and update their
the web services and
and update their view
web services and hosted
services and hosted content
and hosted content are
hosted content are modeled
content are modeled as
measures the efficacy of
are modeled as reusable
the efficacy of t
modeled as reusable overlayed
as reusable overlayed information
reusable overlayed information layers
overlayed information layers backed
cache on these workloads
implementation details the framework
information layers backed by
details the framework was
layers backed by customizable
on these workloads as
backed by customizable transport
the framework was implemented
by customizable transport layers
framework was implemented using
these workloads as a
was implemented using the
workloads as a function
implemented using the java
as a function of
a graph of components
a function of maximum
using the java language
function of maximum dependency
the java language and
of maximum dependency list
java language and its
maximum dependency list size
language and its non
a collaborative application is
collaborative application is a
application is a forest
and compares this to
compares this to a
this to a strategy
a set of such
to a strategy based
set of such graphs
a strategy based on
strategy based on ttls
our vision demands a
the system design was
vision demands a new
system design was strongly
demands a new kind
design was strongly influenced
a new kind of
was strongly influenced by
new kind of soc
strongly influenced by prior
kind of soc standard
influenced by prior work
by prior work on
compares the efficacy of
prior work on highperformance
the efficacy of the
work on highperformance services
efficacy of the three
on highperformance services platforms
in order to facilitate
of the three strategies
order to facilitate the
the three strategies of
to facilitate the side
three strategies of dealing
strategies of dealing with
notably welsh s seda
of dealing with detected
welsh s seda architecture
dealing with detected inconsistencies
side coexistence of components
coexistence of components that
of components that might
components that might today
that might today be
might today be implemented
today be implemented as
be implemented as proprietary
implemented as proprietary minibrowsers
if we enable components
we enable components to
we generated two workloads
enable components to talk
generated two workloads based
components to talk to
two workloads based on
to talk to oneanother
workloads based on real
components are highly autonomous
based on real data
we need to agree
need to agree on
to agree on the
agree on the events
on the events and
the events and representation
events and representation that
and representation that the
representation that the dialog
there are only four
that the dialog will
are only four distinct
the dialog will employ
we started from a
only four distinct control
started from a snapshot
four distinct control threads
from a snapshot of
distinct control threads in
a snapshot of amazon
control threads in the
snapshot of amazon s
threads in the component
of amazon s product
in the component stack
amazon s product co
the decoupling of functionality
the component stack of
decoupling of functionality into
component stack of a
of functionality into layers
stack of a process
functionality into layers also
purchasing graph taken early
into layers also suggests
layers also suggests a
also suggests a need
suggests a need for
a need for a
need for a standardized
for a standardized layering
in the examples above
namely one for the
one for the non
for the non blocking
the non blocking transport
one can identify at
can identify at least
identify at least four
the tcp chain and
tcp chain and for
chain and for the
and for the heartbeat
for the heartbeat component
the linkage layer that
linkage layer that talks
layer that talks to
that talks to the
talks to the underlying
each product sold by
to the underlying data
product sold by the
the underlying data source
sold by the online
the ssa is roughly
by the online retailer
the online retailer is
online retailer is a
the update generating and
retailer is a node
update generating and interpreting
is a node and
generating and interpreting layer
a node and each
node and each pair
and each pair of
each pair of products
and the transport protocol
pair of products purchased
of products purchased in
products purchased in a
purchased in a single
in a single user
a single user session
single user session is
user session is an
session is an edge
we propose that this
propose that this decoupling
that this decoupling be
this decoupling be done
decoupling be done using
the original graph contains
be done using event
original graph contains more
graph contains more than
a natural way of
natural way of thinking
way of thinking about
of thinking about components
thinking about components that
about components that dates
components that dates back
that dates back to
dates back to smalltalk
rather than having the
than having the data
having the data center
the data center developer
data center developer offer
center developer offer content
developer offer content through
offer content through proprietary
content through proprietary minibrowser
through proprietary minibrowser interface
she would define an
would define an event
we used a snapshot
used a snapshot of
based interface between transport
a snapshot of the
interface between transport and
snapshot of the friendship
between transport and information
of the friendship relations
transport and information layers
the friendship relations graph
friendship relations graph in
relations graph in the
graph in the orkut
in the orkut social
the orkut social network
the visual events delivered
visual events delivered by
events delivered by the
delivered by the transport
by the transport could
the transport could then
transport could then be
could then be delivered
then be delivered to
be delivered to an
delivered to an information
to an information layer
an information layer responsible
information layer responsible for
layer responsible for visualizing
responsible for visualizing them
user mouse and keyboard
mouse and keyboard events
and keyboard events and
keyboard events and pass
events and pass them
and pass them down
each user is a
user is a node
with this type of
is a node and
this type of event
a node and each
node and each pair
and each pair of
each pair of users
pair of users with
of users with a
users with a friend
with a friend relationship
either layer could easily
a friend relationship is
layer could easily be
friend relationship is an
could easily be replaced
relationship is an edge
easily be replaced with
be replaced with a
replaced with a different
with a different one
the original graph contains
original graph contains more
graph contains more than
peer protocols would also
protocols would also be
would also be encapsulated
also be encapsulated within
be encapsulated within their
encapsulated within their respective
within their respective transport
their respective transport layers
one version of a
version of a transport
of a transport layer
a transport layer could
transport layer could fetch
layer could fetch data
could fetch data directly
fetch data directly from
data directly from a
because the sampled topologies
directly from a server
from a server in
the sampled topologies are
a server in a
server in a data
sampled topologies are large
in a data center
topologies are large and
are large and we
large and we only
whereas a different version
and we only need
a different version might
we only need to
different version might use
only need to simulate
version might use a
might use a peer
need to simulate a
to simulate a single
simulate a single column
a single column of
single column of the
column of the system
of the system for
the system for our
system for our purposes
for our purposes one
a reliable multicast protocol
our purposes one database
purposes one database server
one database server and
database server and one
it could leverage different
server and one cache
could leverage different type
and one cache server
leverage different type of
one cache server we
different type of hardware
cache server we down
type of hardware or
of hardware or be
hardware or be optimized
or be optimized for
be optimized for different
sample both graphs to
optimized for different types
for different types of
different types of workloads
provided that the different
that the different versions
the different versions of
different versions of the
versions of the transport
of the transport layer
the transport layer conform
transport layer conform to
layer conform to the
conform to the same
to the same standardized
the same standardized event
we use a technique
use a technique based
a technique based on
technique based on random
based on random walks
on random walks that
random walks that maintains
walks that maintains important
the application could then
that maintains important properties
application could then switch
maintains important properties of
could then switch between
important properties of the
then switch between them
properties of the original
switch between them as
of the original graph
between them as conditions
them as conditions demand
users interact through live
interact through live objects
specifically clustering which is
through live objects that
clustering which is central
which is central to
live objects that transform
is central to our
central to our experiment
objects that transform actions
that transform actions into
transform actions into updates
actions into updates that
we start by choosing
into updates that are
start by choosing a
updates that are communicated
by choosing a node
that are communicated in
choosing a node uniformly
are communicated in the
a node uniformly and
communicated in the form
node uniformly and random
in the form of
uniformly and random and
the form of events
and random and start
form of events that
random and start a
of events that are
and start a random
events that are shared
start a random walk
that are shared via
a random walk from
are shared via the
random walk from that
shared via the transport
walk from that location
via the transport layer
the protocol implemented by
protocol implemented by the
implemented by the transport
by the transport layer
the transport layer might
transport layer might replicate
layer might replicate the
might replicate the event
deliver it to the
it to the tablets
to the tablets of
the tablets of our
tablets of our rescue
the walk reverts back
of our rescue workers
walk reverts back to
reverts back to the
back to the first
to the first node
the first node and
and report it through
first node and start
report it through the
node and start again
it through the event
this is repeated until
based interface back to
is repeated until the
interface back to the
repeated until the target
back to the information
until the target number
to the information layer
the target number of
the information layer at
target number of nodes
information layer at which
number of nodes have
layer at which the
of nodes have been
at which the event
nodes have been visited
which the event has
the event has originated
the transport layer with
transport layer with the
layer with the embedded
with the embedded distributed
the embedded distributed protocol
embedded distributed protocol would
distributed protocol would behave
protocol would behave very
would behave very much
behave very much like
very much like an
much like an object
like an object in
an object in smalltalk
show a further down
it would consume events
would consume events and
consume events and respond
events and respond with
and respond with events
this motivates thinking about
motivates thinking about communication
thinking about communication protocols
about communication protocols as
nodes to provide some
communication protocols as objects
to provide some perception
provide some perception of
some perception of the
perception of the topologies
and indeed in treating
indeed in treating them
the graphs are visibly
in treating them as
graphs are visibly clustered
treating them as objects
them as objects much
as objects much as
the amazon topology more
objects much as we
amazon topology more so
much as we treat
topology more so than
as we treat any
more so than the
we treat any other
so than the orkut
treat any other kind
than the orkut one
any other kind of
other kind of object
kind of object in
of object in a
object in a language
in a language like
a language like java
language like java or
like java or in
java or in a
or in a runtime
in a runtime environment
a runtime environment like
runtime environment like jini
environment like jini or
its topology has a
topology has a more
has a more clustered
a more clustered structure
doing so unifies apparently
and so the dependency
so unifies apparently distinct
so the dependency lists
unifies apparently distinct approaches
the dependency lists hold
dependency lists hold more
lists hold more relevant
hold more relevant information
just as a remotely
as a remotely hosted
a remotely hosted form
treating nodes of the
remotely hosted form of
nodes of the graphs
hosted form of content
of the graphs as
form of content such
the graphs as database
of content such as
graphs as database objects
content such as a
such as a map
as a map or
a map or an
map or an image
transactions are likely to
or an image of
are likely to access
an image of a
likely to access objects
image of a raincloud
to access objects that
of a raincloud can
access objects that are
a raincloud can be
objects that are topologically
raincloud can be modeled
that are topologically close
can be modeled as
are topologically close to
be modeled as an
topologically close to one
modeled as an object
close to one another
so can network protocols
for the online retailer
can network protocols be
network protocols be treated
protocols be treated as
be treated as objects
it is likely that
is likely that objects
likely that objects bought
that objects bought together
objects bought together are
bought together are also
together are also viewed
are also viewed and
p systems try to
also viewed and updated
systems try to make
viewed and updated together
try to make everything
to make everything a
make everything a p
but in the examples
in the examples we
the examples we ve
examples we ve seen
viewing and buying a
and buying a toy
buying a toy train
several kinds of content
a toy train and
kinds of content would
toy train and matching
of content would more
train and matching rails
content would more naturally
would more naturally be
more naturally be hosted
for the social network
it is likely that
is likely that data
d images of terrain
likely that data of
images of terrain and
that data of befriended
of terrain and buildings
data of befriended users
of befriended users are
befriended users are viewed
users are viewed and
are viewed and updated
viewed and updated together
on the other hand
soc applications are likely
tagging a person in
applications are likely to
a person in a
are likely to embody
person in a picture
likely to embody quite
to embody quite a
embody quite a range
quite a range of
a range of p
commenting on a post
on a post by
a post by a
post by a friend
by a friend s
a friend s friend
each separate video object
or viewing one s
viewing one s neighborhood
we run a set
run a set of
a set of experiments
set of experiments similar
of experiments similar to
may have its own
experiments similar to the
have its own associated
similar to the t
its own associated update
own associated update stream
if one thinks of
one thinks of these
thinks of these as
varying cache entry ttl
of these as topics
cache entry ttl to
these as topics in
entry ttl to evaluate
as topics in publish
ttl to evaluate the
to evaluate the efficacy
evaluate the efficacy of
the efficacy of this
efficacy of this method
of this method in
this method in reducing
method in reducing inconsistencies
an application could have
in reducing inconsistencies and
application could have many
reducing inconsistencies and the
could have many such
inconsistencies and the corresponding
have many such topics
and the corresponding overhead
and the application instance
the application instance running
application instance running on
instance running on a
running on a given
on a given user
a given user s
given user s machine
limiting ttl has detrimental
user s machine could
ttl has detrimental effects
s machine could simultaneously
has detrimental effects on
machine could simultaneously display
detrimental effects on cache
could simultaneously display data
effects on cache hit
simultaneously display data from
on cache hit ratio
display data from several
data from several topics
quickly increasing the database
increasing the database workload
we have previously said
have previously said that
previously said that we
said that we d
that we d like
by increasing database access
we d like to
increasing database access rate
d like to think
database access rate to
like to think of
access rate to more
to think of protocols
rate to more than
think of protocols as
to more than twice
of protocols as objects
more than twice its
than twice its original
as seen by the
twice its original load
seen by the entire
it now becomes clear
its original load we
by the entire chain
original load we only
now becomes clear that
load we only observe
becomes clear that further
we only observe a
clear that further precision
only observe a reduction
that further precision is
observe a reduction of
further precision is needed
a reduction of inconsistencies
reduction of inconsistencies of
of inconsistencies of about
the objects aren t
objects aren t merely
aren t merely protocols
but in fact are
in fact are individual
fact are individual protocol
are individual protocol instances
our system will need
this is more than
system will need to
is more than twice
will need to simultaneously
more than twice the
need to simultaneously support
than twice the rate
to simultaneously support potentially
twice the rate of
simultaneously support potentially large
the rate of inconsistencies
support potentially large numbers
rate of inconsistencies achieved
potentially large numbers of
of inconsistencies achieved by
large numbers of transport
inconsistencies achieved by t
numbers of transport objects
of transport objects running
transport objects running concurrently
objects running concurrently in
running concurrently in the
concurrently in the end
cache for the retailer
for the retailer workload
the retailer workload and
retailer workload and only
workload and only slightly
and only slightly better
only slightly better than
slightly better than the
in support of a
better than the rate
support of a variety
than the rate of
of a variety of
the rate of inconsistencies
a variety of applications
rate of inconsistencies achieved
variety of applications and
of inconsistencies achieved by
of applications and uses
inconsistencies achieved by t
all of this leads
cache for the social
of this leads to
for the social network
this leads to new
the social network workload
leads to new challenges
and with twice the
the obvious one was
with twice the additional
obvious one was mentioned
twice the additional load
one was mentioned earlier
the additional load on
additional load on the
load on the database
today s web services
s web services don
web services don t
services don t support
don t support p
we generate a transactional
experimental results and validation
generate a transactional workload
a transactional workload that
transactional workload that accesses
workload that accesses products
that accesses products that
contemporary web services solutions
accesses products that are
web services solutions presume
products that are topologically
services solutions presume a
that are topologically close
solutions presume a client
server style of interaction
we use random walks
with data relayed through
data relayed through a
relayed through a message
each transaction starts by
transaction starts by picking
starts by picking a
by picking a node
picking a node uniformly
a node uniformly at
node uniformly at random
uniformly at random and
even if clients are
at random and takes
if clients are connected
clients are connected to
are connected to one
steps of a random
of a random walk
the nodes visited by
if they lose connectivity
nodes visited by the
they lose connectivity to
visited by the random
the tests reported here
by the random walk
lose connectivity to the
the random walk are
connectivity to the broker
random walk are the
tests reported here employ
walk are the objects
reported here employ a
are the objects the
here employ a hard
the objects the transaction
they can t collaborate
objects the transaction accesses
another serious issue arises
update transactions first read
serious issue arises if
transactions first read all
issue arises if the
first read all objects
arises if the clients
read all objects from
if the clients don
all objects from the
the ssa is a
objects from the database
the clients don t
ssa is a work
clients don t trust
is a work in
don t trust the
a work in progress
t trust the data
trust the data center
and then update all
then update all objects
update all objects at
all objects at the
objects at the database
sensitive data will need
data will need to
will need to be
need to be encrypted
fledged system will use
read transactions read the
system will use a
transactions read the objects
will use a software
read the objects directly
use a software partitioning
the objects directly from
a software partitioning mechanism
objects directly from the
software partitioning mechanism based
directly from the cache
the problem here is
partitioning mechanism based on
problem here is that
mechanism based on the
here is that web
based on the web
is that web services
on the web services
that web services security
the web services request
web services security standards
web services request invocation
services security standards tend
services request invocation model
security standards tend to
standards tend to trust
tend to trust the
to trust the web
trust the web services
the web services platform
although extracting the partitioning
web services platform itself
in this section we
extracting the partitioning key
this section we evaluate
the partitioning key from
section we evaluate t
partitioning key from incoming
key from incoming requests
from incoming requests will
incoming requests will impose
the standards offer no
requests will impose some
cache using the workloads
will impose some overhead
standards offer no help
using the workloads described
offer no help at
the workloads described above
no help at all
help at all if
at all if we
all if we need
we do not expect
if we need to
do not expect performance
we need to provide
not expect performance of
need to provide end
we found that the
expect performance of the
found that the abort
performance of the full
that the abort rate
the abort rate is
abort rate is negligible
rate is negligible in
is negligible in all
negligible in all runs
fledged system to deviate
end encryption mechanisms while
system to deviate significantly
encryption mechanisms while also
to deviate significantly from
mechanisms while also preventing
deviate significantly from what
efficacy is therefore defined
while also preventing the
significantly from what is
also preventing the hosted
from what is reported
is therefore defined to
what is reported below
preventing the hosted services
therefore defined to be
the hosted services from
defined to be the
hosted services from seeing
to be the ratio
services from seeing the
be the ratio of
from seeing the keys
the ratio of inconsistent
ratio of inconsistent transactions
of inconsistent transactions out
inconsistent transactions out of
transactions out of all
out of all commits
we encounter debilitating latency
the overhead of the
encounter debilitating latency and
overhead of the system
debilitating latency and throughput
of the system is
latency and throughput issues
the system is twofold
hosted services will be
services will be performance
dependency list maintenance implies
list maintenance implies storage
limiting bottlenecks when used
maintenance implies storage and
bottlenecks when used in
implies storage and bandwidth
when used in settings
storage and bandwidth overhead
used in settings with
and bandwidth overhead at
in settings with large
bandwidth overhead at both
settings with large numbers
overhead at both the
with large numbers of
at both the database
large numbers of clients
both the database and
the database and the
database and the cache
as we will see
we will see in
will see in our
see in our experimental
as well as compute
in our experimental section
well as compute overhead
as compute overhead for
compute overhead for dependency
overhead for dependency list
we are left with
for dependency list merging
are left with a
dependency list merging at
left with a mixture
list merging at the
with a mixture of
merging at the server
a mixture of good
at the server and
mixture of good and
the server and consistency
of good and bad
server and consistency checks
good and bad news
and consistency checks at
consistency checks at the
checks at the cache
web services standardize client
services standardize client access
standardize client access to
client access to hosted
access to hosted services
to hosted services and
hosted services and data
the storage required is
storage required is only
required is only for
is only for object
only for object ids
for object ids and
we can easily build
object ids and versions
can easily build some
easily build some form
build some form of
some form of multiframed
form of multiframed web
of multiframed web page
multiframed web page that
and both updates and
web page that could
both updates and checks
page that could host
updates and checks are
that could host each
and checks are o
could host each kind
host each kind of
each kind of information
kind of information in
of information in its
information in its own
in its own minibrowser
update injection time against
when connectivity is adequate
in the number of
injection time against delivery
the number of objects
time against delivery time
number of objects in
against delivery time at
of objects in the
delivery time at node
relaying data via a
objects in the system
data via a hosted
in the system and
via a hosted service
the system and o
a hosted service has
hosted service has many
service has many of
has many of the
many of the benefits
of the benefits of
the benefits of a
benefits of a publishsubscribe
of a publishsubscribe architecture
in the size of
the size of the
size of the dependency
such as robustness as
of the dependency lists
as robustness as the
robustness as the set
as the set of
the set of clients
set of clients changes
which is limited to
the natural way to
natural way to think
way to think of
to think of our
think of our application
of our application is
our application is as
the second and potentially
application is as an
is as an object
second and potentially more
and potentially more significant
potentially more significant overhead
more significant overhead is
significant overhead is the
overhead is the effect
is the effect on
but web services provide
the effect on cache
web services provide no
effect on cache hit
services provide no support
on cache hit ratio
provide no support for
cache hit ratio due
no support for this
hit ratio due to
support for this kind
ratio due to evictions
for this kind of
due to evictions and
this kind of client
to evictions and hence
kind of client application
evictions and hence the
of client application development
and hence the database
hence the database load
our solution may perform
solution may perform very
may perform very poorly
since cache load is
cache load is significantly
load is significantly larger
is significantly larger than
or fail if the
significantly larger than database
fail if the hosted
larger than database load
if the hosted services
the hosted services are
hosted services are inaccessible
all data will probably
orders of magnitude for
data will probably be
of magnitude for facebook
will probably be visible
probably be visible to
be visible to the
visible to the hosted
to the hosted services
the hosted services unless
hosted services unless the
services unless the developer
unless the developer uses
the developer uses some
developer uses some sort
uses some sort of
some sort of non
even a minor deterioration
a minor deterioration in
minor deterioration in hit
deterioration in hit ratio
in hit ratio can
hit ratio can yield
ratio can yield a
can yield a prohibitive
yield a prohibitive load
a prohibitive load on
prohibitive load on the
load on the backend
on the backend database
using live objects for
live objects for soc
objects for soc applications
for soc applications cornell
c shows the experiment
soc applications cornell s
shows the experiment results
applications cornell s live
cornell s live objects
s live objects platform
live objects platform supports
objects platform supports componentized
each data point is
data point is the
point is the result
is the result of
the result of a
result of a single
layered mashup creation and
of a single run
mashup creation and sharing
and overcomes limitations of
we vary the dependency
overcomes limitations of existing
vary the dependency list
limitations of existing web
the dependency list size
of existing web technologies
dependency list size and
list size and for
size and for each
and for each value
the major design aspects
for each value run
major design aspects are
each value run the
design aspects are as
aspects are as follows
value run the experiment
run the experiment for
the experiment for the
experiment for the two
the developer starts by
for the two workloads
developer starts by creating
the two workloads and
two workloads and measure
workloads and measure the
and measure the average
measure the average values
or gaining access to
the average values of
average values of these
values of these metrics
update delay as seen
a collection of components
delay as seen by
as seen by individual
seen by individual processes
each component is an
cache is able to
component is an object
is able to reduce
is an object that
able to reduce inconsistencies
an object that supports
to reduce inconsistencies significantly
object that supports live
that supports live functionality
for the retailer workload
and exposes eventbased interfaces
exposes eventbased interfaces by
eventbased interfaces by which
a single dependency reduces
interfaces by which it
single dependency reduces inconsistencies
by which it interacts
dependency reduces inconsistencies to
which it interacts with
it interacts with other
interacts with other components
of their original value
components representing hosted content
representing hosted content sensors
hosted content sensors and
two dependencies reduce inconsistencies
dependencies reduce inconsistencies to
content sensors and actuators
sensors and actuators renderers
and actuators renderers that
actuators renderers that graphically
renderers that graphically depict
that graphically depict events
graphically depict events replication
depict events replication protocols
of their original value
events replication protocols synchronization
replication protocols synchronization protocols
protocols synchronization protocols folders
and three to less
synchronization protocols folders containing
three to less than
protocols folders containing sets
folders containing sets of
containing sets of objects
sets of objects display
of objects display interfaces
objects display interfaces that
display interfaces that visualize
interfaces that visualize folders
for the social network
mashups of components are
the social network workload
of components are represented
components are represented as
are represented as a
represented as a kind
as a kind of
a kind of xml
kind of xml web
of xml web pages
each describing a recipe
describing a recipe for
a recipe for obtaining
recipe for obtaining and
our experiments were conducted
for obtaining and parameterizing
of the inconsistencies remain
obtaining and parameterizing components
experiments were conducted using
and parameterizing components that
were conducted using the
parameterizing components that will
conducted using the ssa
components that will serve
using the ssa framework
in both workloads there
that will serve as
both workloads there is
will serve as layers
workloads there is no
serve as layers of
there is no visible
as layers of the
the ssa framework deployed
layers of the composed
is no visible effect
of the composed mashup
ssa framework deployed on
no visible effect on
framework deployed on a
visible effect on cache
deployed on a tightly
effect on cache hit
on a tightly coupled
on cache hit ratio
we call such an
a tightly coupled homogeneous
call such an xml
tightly coupled homogeneous cluster
such an xml page
coupled homogeneous cluster of
an xml page a
xml page a live
and hence no increased
page a live object
hence no increased access
a live object reference
no increased access rate
increased access rate at
access rate at the
rate at the database
references can be distributed
can be distributed as
be distributed as files
the nodes are connected
nodes are connected by
the reduction in inconsistency
are connected by two
connected by two separate
reduction in inconsistency ratio
by two separate high
in inconsistency ratio is
two separate high speed
http or other means
inconsistency ratio is significantly
separate high speed ethernet
ratio is significantly better
high speed ethernet backbone
is significantly better for
speed ethernet backbone planes
an soc application is
significantly better for the
soc application is created
better for the next
application is created by
for the next we
is created by building
the next we compared
we experimented with several
created by building a
experimented with several configurations
next we compared our
by building a forest
we compared our technique
building a forest consisting
compared our technique with
a forest consisting of
our technique with a
forest consisting of graphs
some placed the control
consisting of graphs of
technique with a simple
placed the control traffic
of graphs of references
with a simple approach
the control traffic on
graphs of references that
a simple approach in
of references that are
control traffic on a
references that are mashed
simple approach in which
traffic on a different
approach in which we
that are mashed together
in which we limited
on a different switched
which we limited the
we limited the life
a different switched ethernet
limited the life span
different switched ethernet segment
switched ethernet segment while
ethernet segment while others
segment while others aggregated
while others aggregated both
others aggregated both the
an automated tool lets
aggregated both the control
both the control traffic
automated tool lets the
the control traffic and
tool lets the developer
control traffic and the
lets the developer drag
traffic and the data
the developer drag and
and the data traffic
here inconsistencies are not
the data traffic on
inconsistencies are not detected
data traffic on the
developer drag and drop
traffic on the same
on the same segment
drag and drop to
and drop to combine
but their probability of
drop to combine references
their probability of being
to combine references for
no significant differences were
probability of being witnessed
combine references for individual
significant differences were observed
of being witnessed is
references for individual objects
being witnessed is reduced
for individual objects into
witnessed is reduced by
individual objects into an
but this may be
is reduced by having
objects into an xml
this may be because
into an xml mashup
reduced by having the
an xml mashup of
may be because our
xml mashup of references
by having the cache
be because our control
having the cache evict
mashup of references describing
the cache evict entries
because our control traffic
of references describing a
our control traffic consisted
cache evict entries after
control traffic consisted mainly
references describing a graph
traffic consisted mainly of
evict entries after a
consisted mainly of fast
describing a graph of
entries after a certain
a graph of objects
after a certain period
a certain period even
certain period even if
period even if the
even if the database
if the database did
which put little stress
the database did not
put little stress on
database did not indicate
little stress on the
did not indicate they
stress on the communication
not indicate they are
on the communication channels
indicate they are invalid
checks mashups to verify
mashups to verify that
to verify that they
verify that they compose
that they compose correctly
in the future we
the future we hope
future we hope to
we hope to explore
hope to explore scenarios
to explore scenarios that
explore scenarios that generate
scenarios that generate exceptionally
that generate exceptionally heavy
generate exceptionally heavy control
exceptionally heavy control traffic
d visualization of an
which would allow us
visualization of an airplane
would allow us to
of an airplane may
allow us to explore
an airplane may need
us to explore the
compares the efficacy of
airplane may need to
the efficacy of the
to explore the benefits
efficacy of the abort
may need to be
explore the benefits of
need to be connected
the benefits of isolation
to be connected to
benefits of isolation of
be connected to a
of isolation of that
connected to a source
evict and retry policies
to a source of
isolation of that traffic
a source of gps
and retry policies with
source of gps and
of that traffic with
of gps and other
retry policies with the
gps and other orientation
that traffic with respect
and other orientation data
policies with the amazon
traffic with respect to
with the amazon and
with respect to data
the amazon and orkut
respect to data traffic
amazon and orkut workloads
which in turn needs
in turn needs to
turn needs to run
needs to run over
in these experiments we
to run over a
in the interest of
run over a data
these experiments we use
the interest of brevity
experiments we use dependency
over a data replication
we use dependency lists
interest of brevity we
use dependency lists of
a data replication protocol
of brevity we did
dependency lists of length
data replication protocol with
brevity we did not
replication protocol with specific
we did not perform
protocol with specific reliability
did not perform any
not perform any experiments
perform any experiments to
ordering or security properties
just as with the
any experiments to evaluate
as with the synthetic
experiments to evaluate the
with the synthetic workload
to evaluate the load
when activated on a
evaluate the load balancing
activated on a user
the load balancing component
on a user s
load balancing component but
a user s machine
evicting conflicting transactions is
balancing component but we
conflicting transactions is an
component but we plan
transactions is an effective
but we plan to
an xml mashup yields
we plan to do
is an effective way
plan to do so
xml mashup yields a
an effective way of
to do so in
mashup yields a graph
do so in the
effective way of invalidating
so in the future
yields a graph of
way of invalidating stale
a graph of interconnected
of invalidating stale objects
graph of interconnected proxies
invalidating stale objects that
all the experiments involved
stale objects that might
the experiments involved a
objects that might cause
experiments involved a single
that might cause problems
a proxy is a
might cause problems for
proxy is a piece
cause problems for future
involved a single partitioned
problems for future transactions
is a piece of
a single partitioned and
a piece of running
single partitioned and replicated
piece of running code
partitioned and replicated service
of running code that
running code that may
the effects are more
code that may render
effects are more pronounced
are more pronounced for
for ease of exposition
more pronounced for the
pronounced for the well
this service implements a
service implements a simple
implements a simple wall
or transform visual content
with the amazon workload
encapsulate a protocol stack
abort is able to
the service itself maintains
is able to detect
service itself maintains the
itself maintains the time
with updates coming from
updates coming from client
coming from client applications
component in the xml
from client applications that
in the xml mashup
client applications that read
the xml mashup produces
of the inconsistent transactions
xml mashup produces an
applications that read a
mashup produces an associated
that read a high
produces an associated proxy
whereas with the less
quality clock and send
clock and send the
the hierarchy of proxies
and send the current
clustered orkut workload it
hierarchy of proxies reflects
orkut workload it only
send the current value
workload it only detects
of proxies reflects the
proxies reflects the hierarchical
reflects the hierarchical structure
the hierarchical structure of
as processes forward updates
hierarchical structure of the
processes forward updates along
structure of the xml
forward updates along the
of the xml mashup
updates along the chain
they will track the
will track the clock
in both cases evict
track the clock themselves
both cases evict reduces
cases evict reduces uncommittable
an object proxy can
evict reduces uncommittable transactions
object proxy can initialize
reduces uncommittable transactions considerably
proxy can initialize itself
all of our partitioning
can initialize itself by
of our partitioning scenarios
initialize itself by copying
our partitioning scenarios included
itself by copying the
partitioning scenarios included at
relative to their value
scenarios included at least
to their value with
included at least four
by copying the state
at least four subservices
their value with abort
copying the state from
the state from some
state from some active
from some active proxy
and each subservice included
each subservice included between
our platform assists with
platform assists with this
assists with this sort
with this sort of
this sort of state
with the amazon workload
sort of state transfer
the amazon workload and
the object proxies then
object proxies then become
we expect these to
proxies then become active
expect these to be
these to be typical
to be typical cases
be typical cases for
typical cases for real
cases for real deployments
in the amazon workload
for real deployments of
real deployments of the
deployments of the ssa
retry further reduces this
further reduces this value
for example by relaying
reduces this value to
example by relaying events
it should be noted
by relaying events from
should be noted that
relaying events from sensors
be noted that small
events from sensors into
noted that small subservice
from sensors into a
that small subservice sizes
sensors into a replica
of its value with
its value with abort
or by receiving events
by receiving events and
receiving events and reacting
events and reacting to
and reacting to them
can result in degenerate
result in degenerate behavior
r elated w ork
in degenerate behavior and
elated w ork a
degenerate behavior and are
behavior and are not
and are not appropriate
are not appropriate configurations
not appropriate configurations for
appropriate configurations for the
configurations for the ssa
for the ssa architecture
by redisplaying an aircraft
recent years have seen
years have seen a
have seen a surge
seen a surge of
a surge of progress
surge of progress in
of progress in the
our approach shares certain
progress in the development
approach shares certain similarities
in the development of
shares certain similarities with
the development of scalable
certain similarities with the
development of scalable object
similarities with the existing
of scalable object stores
with the existing web
scalable object stores that
mapping between service processes
object stores that support
between service processes and
stores that support transactions
service processes and physical
the existing web development
processes and physical nodes
existing web development model
some systems such as
in order to avoid
in the sense that
order to avoid os
the sense that it
to avoid os resource
sense that it uses
avoid os resource contention
that it uses hierarchical
it uses hierarchical xml
uses hierarchical xml documents
hierarchical xml documents to
xml documents to define
we experimented with groups
documents to define the
experimented with groups of
to define the content
on the other hand
we depart from some
depart from some of
from some of the
some of the de
facto stylistic standards that
stylistic standards that have
standards that have emerged
for example if one
example if one pulls
if one pulls a
one pulls a minibrowser
pulls a minibrowser from
a minibrowser from google
minibrowser from google earth
it expects to interact
expects to interact directly
to interact directly with
interact directly with the
directly with the end
with the end user
by convention the head
convention the head of
the head of the
and includes embedded javascript
head of the chain
includes embedded javascript that
of the chain for
embedded javascript that handles
the chain for each
javascript that handles such
chain for each group
that handles such interactions
for each group was
each group was called
group was called node
export novel consistency definitions
the same functionality would
novel consistency definitions that
same functionality would be
consistency definitions that allow
definitions that allow for
and all update requests
that allow for effective
functionality would be represented
allow for effective optimizations
all update requests for
would be represented as
update requests for a
be represented as a
requests for a partition
represented as a mashup
for a partition were
several recent systems implement
as a mashup of
a partition were routed
recent systems implement full
partition were routed towards
a mashup of a
were routed towards this
systems implement full fledged
mashup of a component
routed towards this node
implement full fledged atomicity
of a component that
full fledged atomicity while
a component that fetches
fledged atomicity while preserving
component that fetches maps
atomicity while preserving the
since delivery delays in
that fetches maps and
delivery delays in the
while preserving the system
delays in the chain
fetches maps and similar
preserving the system s
in the chain were
maps and similar content
the chain were measured
the system s scalability
chain were measured relative
and similar content with
were measured relative to
system s scalability with
measured relative to node
similar content with a
s scalability with a
content with a second
scalability with a wide
with a second component
with a wide variety
a second component that
a wide variety of
second component that provides
wide variety of workloads
component that provides the
that provides the visualization
all the statistics pertaining
provides the visualization interface
the statistics pertaining to
statistics pertaining to the
google s spanner utilizes
pertaining to the group
s spanner utilizes accurate
to the group disregarded
spanner utilizes accurate clock
the group disregarded node
utilizes accurate clock synchronization
although the term mashup
the term mashup may
term mashup may sound
mashup may sound static
we simulated two classes
in the sense of
simulated two classes of
the sense of having
two classes of failures
sense of having its
of having its components
having its components predetermined
by balakrishnan et al
this is not necessarily
is not necessarily the
at some time t
not necessarily the case
some time t one
is constructed on top
time t one process
constructed on top of
on top of the
top of the scalable
of the scalable corfu
one kind of live
kind of live object
of live object could
live object could be
object could be a
could be a folder
be a folder including
a folder including a
folder including a set
including a set of
a set of objects
the system must detect
system must detect the
must detect the failure
for example extracted from
example extracted from a
extracted from a directory
repair the broken fifo
from a directory in
the broken fifo channel
a directory in a
directory in a file
in a file system
a file system or
file system or pulled
system or pulled from
or pulled from a
pulled from a database
from a database in
a database in response
database in response to
in response to a
response to a query
utilize a large set
a large set of
large set of independent
set of independent logs
the failed process recovers
failed process recovers and
when the folder contents
process recovers and rejoins
the folder contents change
recovers and rejoins the
and rejoins the chain
the mashup is dynamically
mashup is dynamically updated
the join protocol would
join protocol would run
as might occur when
might occur when a
and the previously failed
occur when a rescue
the previously failed node
when a rescue worker
previously failed node would
a rescue worker enters
failed node would become
rescue worker enters a
node would become the
worker enters a building
would become the new
enters a building or
become the new tail
a building or turns
the new tail of
building or turns a
new tail of the
or turns a corner
tail of the chain
the scenario is intended
scenario is intended to
is intended to model
live objects can easily
intended to model a
objects can easily support
to model a common
can easily support applications
model a common case
easily support applications that
a common case in
support applications that dynamically
common case in which
applications that dynamically recompute
case in which the
that dynamically recompute the
in which the failure
use lock chains and
which the failure detection
lock chains and assume
dynamically recompute the set
chains and assume transactions
recompute the set of
and assume transactions are
the set of visible
the failure detection mechanism
set of visible objects
assume transactions are known
failure detection mechanism senses
transactions are known in
detection mechanism senses a
are known in advance
mechanism senses a transient
as a function of
senses a transient problem
a function of location
function of location and
of location and orientation
these methods all scale
methods all scale well
all scale well and
scale well and in
and dynamically add or
well and in many
dynamically add or remove
and in many cases
a node that has
add or remove them
in many cases allow
or remove them from
node that has become
remove them from the
many cases allow databases
them from the mashup
that has become overloaded
cases allow databases to
has become overloaded or
allow databases to accept
become overloaded or is
databases to accept loads
overloaded or is unresponsive
to accept loads similar
or is unresponsive for
a rescuer would automatically
is unresponsive for some
accept loads similar to
unresponsive for some other
rescuer would automatically and
for some other reason
loads similar to those
would automatically and instantly
similar to those handled
automatically and instantly be
to those handled by
and instantly be shown
those handled by non
such as garbage collection
instantly be shown the
be shown the avatars
shown the avatars of
the avatars of others
avatars of others who
of others who are
others who are already
who are already working
are already working at
and does not respond
already working at that
does not respond to
working at that site
not respond to the
they are not expected
respond to the heartbeat
are not expected to
to the heartbeat within
not expected to disrupt
the heartbeat within the
expected to disrupt the
and be able to
to disrupt the prevailing
be able to participate
disrupt the prevailing two
able to participate in
heartbeat within the accepted
to participate in conference
within the accepted window
by reconfiguring the chain
note that we are
that we are addressing
point dialog with them
we are addressing the
the load on node
are addressing the problem
load on node drops
addressing the problem of
the problem of read
through chat objects that
chat objects that run
objects that run over
and the problem will
that run over multicast
the problem will eventually
only incoherent caches that
problem will eventually resolve
run over multicast protocol
incoherent caches that respond
over multicast protocol objects
caches that respond to
that respond to queries
respond to queries without
it then requests a
to queries without access
then requests a rejoin
queries without access to
this model can support
without access to the
model can support a
access to the backend
can support a wide
to the backend database
a node crash that
support a wide variety
node crash that results
a wide variety of
crash that results in
wide variety of collaboration
that results in a
previous work on coherent
variety of collaboration and
results in a reboot
work on coherent caches
of collaboration and coordination
in a reboot would
collaboration and coordination paradigms
a reboot would result
reboot would result in
would result in similar
result in similar behavior
the live objects platform
live objects platform makes
objects platform makes it
platform makes it easy
makes it easy for
it easy for a
easy for a non
all the nodes in
the nodes in the
nodes in the subservice
in the subservice remain
programmer to create the
the subservice remain operational
to create the needed
create the needed soc
the needed soc application
but one of them
one of them becomes
of them becomes overloaded
the rescue coordinator pulls
rescue coordinator pulls prebuilt
coordinator pulls prebuilt object
pulls prebuilt object references
prebuilt object references from
causing the tcp link
object references from a
the tcp link to
references from a folder
tcp link to the
link to the upstream
to the upstream node
the upstream node to
upstream node to become
each corresponding to a
node to become congested
corresponding to a desired
to become congested and
to a desired kind
become congested and starving
a desired kind of
congested and starving downstream
desired kind of information
and starving downstream nodes
which begin to miss
begin to miss updates
this scenario models a
scenario models a behavior
models a behavior common
a behavior common in
behavior common in experiments
common in experiments on
in experiments on our
experiments on our cluster
supports transactions using locks
transactions using locks or
would correspond to objects
using locks or communication
correspond to objects that
when a node becomes
locks or communication with
a node becomes very
to objects that point
node becomes very busy
objects that point to
becomes very busy or
or communication with the
very busy or the
that point to a
busy or the communication
point to a web
communication with the database
to a web service
with the database on
a web service over
or the communication subsystem
web service over the
the database on each
service over the network
database on each transaction
the communication subsystem becomes
communication subsystem becomes heavily
subsystem becomes heavily loaded
these techniques are not
techniques are not applicable
are not applicable in
tcp at the node
not applicable in our
at the node upstream
applicable in our scenario
the node upstream from
peer objects would implement
node upstream from it
objects would implement chat
upstream from it will
would implement chat windows
from it will sense
it will sense congestion
will sense congestion and
sense congestion and reduce
congestion and reduce its
and reduce its window
reduce its window size
event interfaces allow such
if the impacted node
interfaces allow such objects
the impacted node is
allow such objects to
impacted node is in
such objects to coexist
node is in the
objects to coexist in
is in the middle
to coexist in a
in the middle of
coexist in a shared
the middle of the
in a shared display
middle of the chain
a shared display window
shared display window that
display window that can
window that can pan
it ceases to relay
ceases to relay updates
or does so after
does so after long
jump to new locations
so after long delays
the relative advantages and
hence downstream nodes fall
relative advantages and disadvantages
downstream nodes fall behind
advantages and disadvantages of
and disadvantages of our
disadvantages of our model
of our model can
our model can be
model can be summarized
can be summarized as
be summarized as follows
the chain replication scheme
chain replication scheme slows
replication scheme slows to
scheme slows to a
like other modern web
slows to a crawl
other modern web development
modern web development tools
our platform supports drag
the ssa benefits from
ssa benefits from its
benefits from its gossip
from its gossip repair
its gossip repair mechanisms
drop style of development
which route missing updates
route missing updates around
missing updates around the
updates around the slow
around the slow node
easy creation of content
route them to that
the resulting solutions are
them to that node
resulting solutions are easy
solutions are easy to
are easy to share
when it recovers and
it recovers and needs
by selecting appropriate transport
recovers and needs to
selecting appropriate transport layers
and needs to repair
needs to repair its
to repair its state
functionality such as coordination
such as coordination between
as coordination between searchers
coordination between searchers can
between searchers can remain
searchers can remain active
can remain active even
remain active even if
active even if connectivity
knowing that gossip will
even if connectivity to
that gossip will kick
if connectivity to the
gossip will kick in
connectivity to the data
to the data center
the data center is
data center is disrupted
an upstream node can
upstream node can deliberately
node can deliberately drop
can deliberately drop updates
streams of video or
deliberately drop updates on
of video or sensor
drop updates on congested
updates on congested tcp
video or sensor data
on congested tcp connections
or sensor data can
sensor data can travel
data can travel directly
we used our wall
can travel directly and
travel directly and won
directly and won t
and won t be
clock service to evaluate
won t be delayed
service to evaluate the
t be delayed by
to evaluate the behavior
be delayed by the
evaluate the behavior of
delayed by the need
the behavior of the
by the need to
behavior of the overall
the need to ricochet
of the overall system
need to ricochet off
the overall system in
to ricochet off a
overall system in various
ricochet off a remote
system in various scenarios
off a remote and
in various scenarios and
a remote and potentially
various scenarios and with
remote and potentially inaccessible
scenarios and with different
and potentially inaccessible server
and with different parameters
a stream of updates
stream of updates of
of updates of various
updates of various rates
of various rates is
based interoperability standards are
various rates is injected
interoperability standards are needed
rates is injected into
is injected into the
injected into the head
into the head of
the head of the
head of the chain
we could lose access
could lose access to
lose access to some
access to some of
to some of the
some of the sophisticated
of the sophisticated proprietary
the sophisticated proprietary interactive
for groups of nodes
sophisticated proprietary interactive functionality
proprietary interactive functionality optimized
interactive functionality optimized for
functionality optimized for proprietary
optimized for proprietary minibrowser
established point in time
based solutions with an
solutions with an embedded
with an embedded javascript
a victim node receives
victim node receives a
node receives a command
receives a command that
a command that forces
command that forces it
that forces it to
forces it to halt
peer communication can be
the node continues to
communication can be much
node continues to listen
can be much harder
continues to listen for
be much harder to
to listen for commands
much harder to use
listen for commands that
harder to use than
for commands that would
to use than relaying
commands that would restart
use than relaying data
that would restart it
than relaying data through
relaying data through a
data through a hosted
through a hosted service
a hosted service that
hosted service that uses
service that uses an
that uses an enterprise
this is accomplished by
uses an enterprise service
is accomplished by having
an enterprise service bus
accomplished by having node
send a crash command
a crash command to
crash command to the
command to the victim
to the victim node
the victim node once
victim node once a
node once a certain
once a certain number
a certain number of
the lack of a
certain number of updates
lack of a one
number of updates were
of a one size
of updates were injected
a one size fits
updates were injected into
one size fits all
were injected into the
size fits all publish
injected into the chain
subscribe substrate forces the
substrate forces the developers
forces the developers to
the developers to become
developers to become familiar
to become familiar with
become familiar with and
the victim node will
familiar with and choose
victim node will stop
with and choose between
node will stop participating
and choose between a
will stop participating in
choose between a range
stop participating in the
between a range of
participating in the normal
a range of different
in the normal protocol
range of different and
the normal protocol and
of different and incompatible
normal protocol and will
different and incompatible options
protocol and will handle
and will handle only
will handle only wakeup
handle only wakeup commands
an wrong choice of
only wakeup commands from
wrong choice of transport
wakeup commands from this
choice of transport could
commands from this moment
of transport could result
from this moment onwards
transport could result in
could result in degraded
result in degraded qos
the chain detects the
chain detects the failure
or even data loss
repairs and announces the
and announces the membership
announces the membership change
after a number of
a number of updates
number of updates have
of updates have been
updates have been injected
second life as a
have been injected since
life as a soc
been injected since the
as a soc application
injected since the crash
a soc application up
since the crash command
soc application up to
the crash command was
application up to now
crash command was issued
we have focused on
have focused on a
focused on a small
sends a wakeup command
db access rate normed
a wakeup command to
wakeup command to the
command to the victim
to the victim node
but our longer term
our longer term goal
longer term goal is
term goal is to
goal is to support
is to support a
to support a large
scale nextgeneration collaboration system
db access rate normed
nextgeneration collaboration system similar
collaboration system similar to
the victim node rejoins
system similar to second
victim node rejoins the
similar to second life
node rejoins the group
a virtual reality immersion
it has to catch
virtual reality immersion system
has to catch up
reality immersion system created
to catch up by
immersion system created by
catch up by obtaining
system created by linden
up by obtaining copies
created by linden labs
by obtaining copies of
obtaining copies of updates
copies of updates that
of updates that it
updates that it has
that it has missed
second life is implemented
we experimentally determined that
life is implemented with
is implemented with a
implemented with a data
with a data center
repetitions of each experiment
a data center including
of each experiment were
data center including a
each experiment were enough
center including a large
experiment were enough to
including a large number
were enough to yield
a large number of
enough to yield accurate
large number of servers
to yield accurate measurements
number of servers storing
yield accurate measurements with
of servers storing the
accurate measurements with low
servers storing the state
measurements with low variance
storing the state of
the state of the
state of the virtual
of the virtual world
the locations of all
locations of all users
shows the update delivery
the update delivery delay
update delivery delay for
delivery delay for a
delay for a set
for a set of
a set of four
set of four consecutive
of four consecutive nodes
four consecutive nodes in
consecutive nodes in a
nodes in a chain
starting with the victim
with the victim node
then move about and
move about and interact
about and interact with
and interact with others
hit ratio hit ratio
the chain length is
one can create a
can create a cybercaf
and we report on
we report on a
report on a gossip
on a gossip rate
a gossip rate of
as other second life
other second life users
second life users enter
life users enter the
users enter the room
milliseconds at a steady
at a steady update
a steady update injection
steady update injection rate
update injection rate of
they can interact with
can interact with the
interact with the environment
with the environment and
the environment and one
in the second life
the second life architecture
there are three anomalies
are three anomalies that
three anomalies that can
anomalies that can be
whenever an avatar moves
that can be seen
an avatar moves or
can be seen on
avatar moves or performs
be seen on the
product a nity social
seen on the graphs
a nity social network
moves or performs some
or performs some action
performs some action in
some action in the
action in the virtual
the first one is
in the virtual world
first one is experienced
one is experienced by
is experienced by the
experienced by the victim
by the victim node
a request describing this
the victim node for
request describing this event
victim node for updates
describing this event is
node for updates injected
this event is passed
for updates injected between
event is passed to
is passed to the
passed to the hosting
to the hosting data
the hosting data center
hosting data center and
data center and processed
center and processed by
and processed by servers
processed by servers running
by servers running there
clients do perform a
do perform a variety
seconds after the start
perform a variety of
after the start of
a variety of decoding
the start of the
variety of decoding and
start of the experiment
of decoding and rendering
decoding and rendering functions
and rendering functions locally
the second is experienced
second is experienced by
is experienced by all
but the data center
experienced by all the
the data center must
by all the other
data center must be
all the other nodes
center must be in
the other nodes for
must be in the
other nodes for update
be in the loop
nodes for update messages
in the loop to
for update messages injected
the loop to ensure
update messages injected at
loop to ensure that
messages injected at around
to ensure that all
ensure that all users
that all users observe
all users observe consistent
users observe consistent state
seconds after the start
after the start of
when the number of
the start of the
the number of users
start of the experiment
number of users in
of users in a
users in a scenario
in a scenario isn
a scenario isn t
scenario isn t huge
while the third one
the third one is
third one is a
one is a smaller
is a smaller mixed
a smaller mixed burst
second life can easily
smaller mixed burst for
life can easily keep
mixed burst for updates
can easily keep up
burst for updates injected
easily keep up using
for updates injected at
keep up using a
up using a standard
using a standard workload
a standard workload partitioning
standard workload partitioning scheme
workload partitioning scheme in
seconds into the experiment
partitioning scheme in which
scheme in which different
in which different servers
which different servers handle
note that the y
different servers handle different
servers handle different portions
handle different portions of
different portions of the
portions of the virtual
of the virtual world
axes have different scales
have different scales to
different scales to observe
scales to observe how
to observe how the
observe how the system
how the system handles
the system handles the
system handles the transient
handles the transient failure
the transient failure better
for example because large
example because large numbers
therefore the third anomaly
because large numbers of
the third anomaly appears
large numbers of users
third anomaly appears to
numbers of users want
anomaly appears to grow
of users want to
appears to grow with
users want to enter
to grow with the
want to enter the
grow with the chain
to enter the same
with the chain distance
enter the same virtual
the chain distance from
the same virtual discotheque
chain distance from the
distance from the victim
from the victim node
the servers can become
servers can become overwhelmed
the growth is not
can become overwhelmed and
growth is not significant
become overwhelmed and are
overwhelmed and are forced
and are forced to
are forced to reject
since the cause of
forced to reject some
the cause of this
to reject some of
cause of this anomaly
reject some of the
of this anomaly is
some of the users
this anomaly is an
of the users or
anomaly is an artifact
the users or reduce
is an artifact of
users or reduce their
an artifact of java
or reduce their frame
artifact of java s
of java s garbage
java s garbage collection
s garbage collection mechanism
garbage collection mechanism kicking
rendering rates and resolution
collection mechanism kicking in
as can be noted
second life might seem
life might seem jumpy
might seem jumpy and
seem jumpy and unrealistic
performed recovery for the
recovery for the updates
second life as a
for the updates it
life as a live
the updates it has
as a live objects
updates it has missed
a live objects application
it has missed during
live objects application poses
has missed during the
objects application poses some
missed during the period
application poses some new
during the period it
poses some new challenges
the period it was
period it was down
on the one hand
because the chain delivers
the chain delivers new
product a nity social
chain delivers new updates
a nity social network
delivers new updates at
many aspects of the
new updates at the
aspects of the application
updates at the moment
of the application can
at the moment of
the application can be
the moment of rejoin
application can be addressed
can be addressed in
be addressed in the
addressed in the same
all past updates were
in the same manner
past updates were solely
the same manner we
updates were solely recovered
same manner we ve
were solely recovered by
manner we ve outlined
solely recovered by means
we ve outlined for
recovered by means of
ve outlined for the
by means of epidemics
outlined for the search
for the search and
the search and rescue
search and rescue application
the second anomaly that
second anomaly that shows
anomaly that shows up
one could use microsoft
that shows up in
could use microsoft virtual
shows up in the
use microsoft virtual earth
up in the update
in the update delivery
the update delivery delay
update delivery delay for
delivery delay for the
delay for the nodes
for the nodes downstream
as a source of
the nodes downstream from
nodes downstream from the
downstream from the victim
from the victim node
d textures representing landscapes
the victim node reflects
victim node reflects the
node reflects the period
reflects the period when
the period when the
period when the chain
when the chain is
the chain is broken
during the time it
the time it took
time it took for
in standards for creating
it took for the
standards for creating mashups
took for the failure
for creating mashups could
for the failure detection
creating mashups could be
the failure detection mechanism
mashups could be used
failure detection mechanism to
could be used to
detection mechanism to declare
be used to identify
mechanism to declare the
used to identify sensors
to declare the node
to identify sensors and
declare the node deceased
identify sensors and other
sensors and other data
and other data sources
to start up the
start up the membership
up the membership change
which could then be
the membership change protocol
could then be wrapped
then be wrapped as
be wrapped as live
wrapped as live objects
as live objects and
and for the membership
live objects and incorporated
for the membership information
objects and incorporated into
the membership information to
and incorporated into live
membership information to propagate
incorporated into live scenes
the chain is interrupted
on top of this
chain is interrupted between
is interrupted between node
streaming media sources such
media sources such as
sources such as video
such as video cameras
as video cameras mounted
video cameras mounted at
and hence the updates
cameras mounted at street
hence the updates circumvent
mounted at street level
the updates circumvent the
at street level in
updates circumvent the gap
street level in places
circumvent the gap by
level in places such
the gap by means
in places such as
gap by means of
places such as tokyo
by means of gossip
such as tokyo s
as tokyo s ginza
tokyo s ginza can
s ginza can be
ginza can be added
updates can bypass nodes
can be added to
can bypass nodes in
be added to create
bypass nodes in the
added to create realistic
nodes in the chain
to create realistic experience
in the chain using
the chain using the
chain using the gossip
using the gossip as
the gossip as it
gossip as it can
as it can be
it can be seen
the more complex issue
can be seen in
be seen in the
more complex issue is
seen in the figure
complex issue is that
issue is that a
is that a search
that a search and
but this phenomenon is
a search and rescue
this phenomenon is less
search and rescue application
phenomenon is less likely
and rescue application can
is less likely as
rescue application can be
less likely as the
application can be imagined
likely as the node
can be imagined as
as the node receiving
be imagined as a
the node receiving the
imagined as a situational
node receiving the update
as a situational state
receiving the update is
a situational state fully
the update is farther
situational state fully replicated
update is farther away
state fully replicated across
is farther away downstream
fully replicated across all
farther away downstream from
replicated across all of
away downstream from the
across all of its
downstream from the victim
all of its users
from the victim node
all machines would see
contains an aggregated view
machines would see all
an aggregated view of
would see all the
limited cache entry ttl
see all the state
aggregated view of the
all the state updates
cache entry ttl fig
view of the data
of the data in
the data in figure
even if the user
if the user is
the user is zoomed
for the entire chain
user is zoomed into
is zoomed into some
zoomed into some particular
into some particular spot
some particular spot within
at gossip rates of
particular spot within the
experiments with workloads based
spot within the overall
with workloads based on
within the overall scene
workloads based on a
based on a web
on a web retailer
a web retailer product
web retailer product affinity
retailer product affinity topology
product affinity topology and
affinity topology and a
one can contemplate such
topology and a social
can contemplate such an
and a social network
contemplate such an approach
a social network topology
such an approach because
social network topology illustrated
an approach because the
network topology illustrated in
approach because the aggregate
because the aggregate amount
the aggregate amount of
milliseconds showing that the
aggregate amount of information
showing that the behavior
amount of information might
that the behavior of
of information might not
the behavior of the
information might not be
behavior of the scheme
might not be that
of the scheme is
not be that large
the scheme is not
scheme is not a
is not a fluke
note that the delay
second life conceptually is
that the delay of
life conceptually is a
conceptually is a whole
the delay of the
is a whole universe
delay of the updates
of the updates delivered
the updates delivered at
unbounded in size and
updates delivered at the
compared against the alternative
in size and hence
against the alternative of
delivered at the victim
the alternative of reducing
size and hence with
alternative of reducing cache
at the victim node
of reducing cache entry
and hence with different
reducing cache entry time
the victim node is
hence with different users
victim node is significantly
with different users in
node is significantly larger
different users in very
is significantly larger than
users in very distinct
significantly larger than that
in very distinct parts
larger than that of
very distinct parts of
than that of the
distinct parts of the
that of the nodes
parts of the space
of the nodes downstream
the nodes downstream of
nodes downstream of it
downstream of it in
of it in the
it in the chain
it would make no
would make no sense
make no sense for
no sense for every
data points are medians
sense for every user
we observed that even
for every user to
points are medians and
every user to see
observed that even with
user to see every
are medians and error
that even with sufficiently
medians and error bars
even with sufficiently high
and error bars bound
to see every event
error bars bound the
with sufficiently high gossip
sufficiently high gossip rate
the only node to
only node to experience
we would solve this
node to experience any
would solve this problem
to experience any significant
solve this problem using
experience any significant inconsistency
this problem using the
any significant inconsistency window
problem using the dynamic
significant inconsistency window is
using the dynamic database
inconsistency window is the
the dynamic database querying
window is the node
dynamic database querying approach
is the node that
database querying approach outlined
the node that failed
querying approach outlined in
approach outlined in section
note that when the
that when the failed
when the failed node
the failed node rejoins
each user would see
user would see only
this could work well
would see only the
could work well if
see only the objects
work well if a
only the objects within
well if a system
the objects within some
if a system has
objects within some range
queries are performed against
a system has multiple
are performed against its
system has multiple classes
performed against its data
has multiple classes of
against its data before
multiple classes of objects
or within line of
its data before it
within line of sight
data before it has
before it has time
it has time to
has time to fully
all clustered but with
time to fully recover
clustered but with different
as a user moves
but with different associated
a user moves about
with different associated clustering
different associated clustering properties
once the chain is
the chain is restored
the platform would recompute
platform would recompute the
would recompute the query
recompute the query result
all new updates are
new updates are received
and then update the
then update the display
update the display accordingly
there were rare cases
were rare cases when
rare cases when gossip
cases when gossip circumvented
when gossip circumvented the
gossip circumvented the chain
circumvented the chain replication
the chain replication even
chain replication even though
replication even though the
even though the chain
that since some live
though the chain was
since some live objects
the chain was not
some live objects uses
chain was not broken
live objects uses p
but this happened only
p protocols that might
this happened only for
protocols that might organize
happened only for gossip
that might organize user
only for gossip rates
might organize user s
for gossip rates close
organize user s machines
gossip rates close to
user s machines into
rates close to the
s machines into groups
close to the update
machines into groups forwarding
to the update injection
into groups forwarding streams
the update injection rate
groups forwarding streams of
forwarding streams of data
streams of data to
of data to one
data to one another
consistent inconsistent aborted ab
later in this section
inconsistent aborted ab ev
in this section we
aborted ab ev re
this section we will
we end up in
ab ev re ab
section we will show
end up in a
we will show that
ev re ab ev
will show that even
up in a situation
show that even with
re ab ev re
that even with these
in a situation where
even with these rapid
ab ev re i
a situation where each
with these rapid repairs
ev re i i
situation where each user
re i i tr
where each user belongs
i i tr tr
each user belongs to
i tr tr o
user belongs to a
the gossip overhead is
belongs to a potentially
gossip overhead is actually
to a potentially large
overhead is actually low
tr tr o o
a potentially large number
tr o o rt
potentially large number of
o o rt ct
large number of such
o rt ct rt
number of such groups
rt ct rt ct
ct rt ct y
rt ct y y
ct y y amazon
y y amazon orkut
y amazon orkut fig
and the groups that
the groups that one
groups that one user
that one user is
one user is a
user is a part
is a part of
a part of might
part of might be
the efficacy of t
of might be very
might be very different
of the messages were
be very different from
the messages were delivered
very different from the
cache as a function
messages were delivered by
different from the groups
as a function of
from the groups that
were delivered by gossip
the groups that other
a function of the
groups that other users
delivered by gossip ahead
that other users belong
function of the inconsistency
other users belong to
by gossip ahead of
of the inconsistency handling
gossip ahead of the
the inconsistency handling strategy
ahead of the chain
inconsistency handling strategy for
of the chain for
handling strategy for realistic
to support such a
strategy for realistic workloads
support such a model
the chain for gossip
chain for gossip rate
for gossip rate identical
gossip rate identical to
rate identical to the
identical to the update
we need to be
to the update injection
need to be able
the update injection rate
to be able to
be able to support
able to support very
to support very large
much work has been
support very large numbers
work has been done
very large numbers of
has been done on
large numbers of publish
been done on creating
done on creating consistent
on creating consistent caches
creating consistent caches for
consistent caches for web
contains a plot of
caches for web servers
a plot of update
plot of update injection
of update injection time
and with different users
update injection time against
with different users subscribed
injection time against update
different users subscribed to
time against update delivery
users subscribed to very
against update delivery time
subscribed to very different
update delivery time for
to very different sets
delivery time for the
very different sets of
time for the victim
different sets of topics
for the victim node
ideally this is a
up to now we
this is a straight
is a straight line
to now we have
a straight line because
straight line because of
now we have been
line because of chain
because of chain replication
we have been fairly
have been fairly negative
been fairly negative about
note that once the
fairly negative about the
that once the victim
once the victim node
negative about the trend
the victim node recovers
about the trend to
the trend to standardize
trend to standardize client
it gracefully catches up
to standardize client access
gracefully catches up and
standardize client access to
catches up and does
client access to hosted
up and does so
access to hosted content
and does so quickly
to hosted content through
does so quickly for
hosted content through web
so quickly for both
content through web minibrowsers
quickly for both gossip
through web minibrowsers that
for both gossip rates
web minibrowsers that make
both gossip rates identical
minibrowsers that make the
gossip rates identical and
that make the javascript
rates identical and half
make the javascript running
identical and half the
the javascript running on
and half the update
javascript running on a
half the update injection
running on a user
the update injection rate
on a user s
a user s machine
user s machine virtually
s machine virtually inseparable
now consider the link
machine virtually inseparable from
consider the link congestion
virtually inseparable from the
the link congestion case
inseparable from the data
from the data center
our core criticism was
core criticism was that
criticism was that for
was that for most
that for most soc
for most soc applications
a minibrowser approach would
minibrowser approach would lack
approach would lack the
would lack the flexibility
lack the flexibility to
the flexibility to seamlessly
flexibility to seamlessly combine
to seamlessly combine content
seamlessly combine content from
combine content from different
content from different sources
and to customize the
to customize the underlying
customize the underlying communication
the underlying communication substrate
our earlier concerns carry
earlier concerns carry over
concerns carry over to
carry over to the
over to the second
to the second life
the second life scenario
d texture representing terrain
texture representing terrain in
representing terrain in some
terrain in some region
in a minibrowser approach
the minibrowser generates the
minibrowser generates the texture
generates the texture from
the texture from hosted
texture from hosted data
this model makes it
model makes it difficult
to superimpose other content
superimpose other content over
other content over the
content over the texture
and higher level objects
we would need to
would need to rely
need to rely on
to rely on a
rely on a hosting
on a hosting system
a hosting system s
hosting system s mashup
system s mashup technology
s mashup technology to
mashup technology to do
technology to do this
if we wanted to
we wanted to blend
wanted to blend weather
to blend weather information
blend weather information from
weather information from the
information from the national
from the national hurricane
the national hurricane center
national hurricane center with
hurricane center with a
center with a google
such systems consider only
with a google map
systems consider only one
consider only one object
only one object at
one object at a
object at a time
the google map service
google map service would
map service would need
service would need to
and only individual read
would need to explicitly
only individual read and
need to explicitly support
individual read and write
to explicitly support this
read and write operations
explicitly support this sort
support this sort of
this sort of embedding
as they do not
they do not support
do not support a
not support a transactional
support a transactional interface
there are few if
are few if any
in our second life
few if any multi
our second life scenario
the visible portion of
visible portion of the
portion of the scene
of the scene the
the scene the part
these systems generally try
scene the part of
systems generally try to
the part of the
generally try to avoid
part of the texture
try to avoid staleness
of the texture being
to avoid staleness through
the texture being displayed
avoid staleness through techniques
texture being displayed will
staleness through techniques such
being displayed will often
through techniques such as
displayed will often be
techniques such as time
will often be controlled
often be controlled by
be controlled by events
controlled by events generated
by events generated by
events generated by other
generated by other live
by other live objects
other live objects that
live objects that share
objects that share the
that share the display
share the display window
perhaps under control of
under control of users
control of users running
of users running on
users running on machines
running on machines elsewhere
on machines elsewhere in
machines elsewhere in the
our work considers multi
elsewhere in the network
object transactional consistency of
these remote sources won
transactional consistency of cache
remote sources won t
consistency of cache access
sources won t fit
won t fit into
t fit into the
fit into the interaction
into the interaction model
the interaction model expected
interaction model expected by
model expected by the
expected by the minibrowser
early work on scalable
work on scalable database
on scalable database caching
scalable database caching mostly
database caching mostly ignored
caching mostly ignored transactional
mostly ignored transactional consistency
the size and shape
size and shape of
and shape of the
shape of the display
of the display window
the display window and
display window and other
window and other elements
and other elements of
other elements of the
elements of the runtime
of the runtime environment
the runtime environment should
runtime environment should be
work has been done
environment should be inherited
has been done on
should be inherited from
been done on creating
be inherited from the
done on creating consistent
inherited from the hierarchy
on creating consistent caches
from the hierarchy structure
creating consistent caches for
the hierarchy structure of
consistent caches for databases
hierarchy structure of the
structure of the object
of the object mashup
the object mashup used
object mashup used to
mashup used to create
used to create the
to create the application
thus our texture should
our texture should learn
extends a centralized database
texture should learn its
a centralized database with
should learn its size
centralized database with support
learn its size and
database with support for
its size and orientation
with support for caches
size and orientation and
support for caches that
and orientation and even
for caches that provide
orientation and even the
caches that provide snapshot
and even the gps
that provide snapshot isolation
even the gps coordinates
provide snapshot isolation semantics
the gps coordinates on
gps coordinates on which
coordinates on which to
on which to center
which to center from
albeit the snapshots seen
to center from the
the snapshots seen may
center from the parent
snapshots seen may be
from the parent object
seen may be stale
the parent object that
parent object that hosts
object that hosts it
to improve the commit
improve the commit rate
the commit rate for
commit rate for read
and similarly until we
similarly until we reach
until we reach the
we reach the root
reach the root object
the root object hosting
root object hosting the
object hosting the display
hosting the display window
a minibrowser isn t
where the cache holds
minibrowser isn t a
the cache holds several
isn t a component
cache holds several versions
holds several versions of
several versions of an
it runs the show
versions of an object
of an object and
an object and enables
object and enables the
despite all of the
and enables the cache
all of the above
enables the cache to
of the above criticism
the cache to choose
cache to choose a
to choose a version
choose a version that
a version that allows
minibrowsers retain one potential
version that allows a
retain one potential advantage
that allows a transaction
one potential advantage over
allows a transaction to
potential advantage over the
a transaction to commit
advantage over the layered
over the layered architecture
the layered architecture we
layered architecture we proposed
architecture we proposed earlier
this technique could also
technique could also be
could also be used
also be used with
be used with our
since all aspects of
used with our solution
all aspects of the
aspects of the view
of the view are
the view are optimized
view are optimized to
are optimized to run
optimized to run together
the interaction controls might
interaction controls might be
controls might be far
might be far more
be far more sophisticated
far more sophisticated and
more sophisticated and perform
sophisticated and perform potentially
and perform potentially much
perform potentially much better
potentially much better than
much better than a
better than a solution
than a solution resulting
a solution resulting from
solution resulting from mashing
resulting from mashing up
from mashing up together
mashing up together multiple
up together multiple layers
together multiple layers developed
multiple layers developed independently
in many realistic examples
many realistic examples event
also support snapshot isolation
based interfaces could get
interfaces could get fairly
but can be used
could get fairly complex
can be used with
be used with any
used with any backend
with any backend database
and difficult for most
difficult for most developers
for most developers to
including ones that are
most developers to work
ones that are sharded
developers to work with
that are sharded and
this observation highlights the
observation highlights the importance
highlights the importance of
the importance of developing
importance of developing component
of developing component interface
developing component interface and
component interface and event
interface and event standards
and event standards for
event standards for the
standards for the layered
for the layered architecture
the layered architecture we
layered architecture we ve
architecture we ve outlined
provides a transactionally consistent
a transactionally consistent cache
the task isn t
transactionally consistent cache for
task isn t really
consistent cache for the
isn t really all
cache for the jboss
t really all that
for the jboss middleware
really all that daunting
the designers of microsoft
designers of microsoft s
of microsoft s object
microsoft s object linking
s object linking and
object linking and embedding
standard faced similar challenges
support transactions on cached
transactions on cached enterprise
on cached enterprise javabeans
their ole interfaces are
ole interfaces are pervasively
interfaces are pervasively used
are pervasively used to
pervasively used to support
used to support thousands
to support thousands of
support thousands of plugins
thousands of plugins that
of plugins that implement
plugins that implement context
that implement context menus
allows update transactions to
update transactions to read
transactions to read stale
to read stale data
virtual folders and various
read stale data out
folders and various namespace
stale data out of
and various namespace extensions
data out of caches
out of caches and
of caches and provide
caches and provide bounds
and provide bounds on
and drag and drop
provide bounds on how
drag and drop technologies
bounds on how much
on how much staleness
how much staleness is
much staleness is allowed
lacking the needed standards
these techniques require fast
techniques require fast communication
require fast communication between
the live objects platform
fast communication between the
live objects platform supports
communication between the cache
objects platform supports both
between the cache and
platform supports both options
the cache and the
supports both options today
cache and the database
and the database for
the database for good
database for good performance
in addition to allowing
addition to allowing hosted
to allowing hosted content
allowing hosted content to
hosted content to be
content to be pulled
to be pulled in
in our work caches
be pulled in and
our work caches are
pulled in and exposed
work caches are asynchronously
in and exposed via
caches are asynchronously updated
and exposed via event
exposed via event interfaces
components developed by some
developed by some of
by some of our
some of our users
of our users also
which is how caches
our users also use
is how caches currently
users also use embedded
how caches currently work
also use embedded minibrowsers
caches currently work in
use embedded minibrowsers to
currently work in large
embedded minibrowsers to gain
work in large multi
minibrowsers to gain access
to gain access to
gain access to a
access to a wide
to a wide range
a wide range of
wide range of platforms
f uture d irections
uture d irections the
d irections the dependency
irections the dependency list
the dependency list sizes
dependency list sizes for
list sizes for all
sizes for all objects
for all objects in
all objects in t
cache are currently all
are currently all of
currently all of the
all of the same
of the same maximum
the same maximum length
this may not be
may not be optimal
performance evaluation central to
evaluation central to our
if the workload accesses
central to our argument
the workload accesses objects
to our argument is
workload accesses objects in
our argument is the
accesses objects in clusters
argument is the assertion
objects in clusters of
is the assertion that
in clusters of different
the assertion that hosted
clusters of different sizes
assertion that hosted event
that hosted event notification
hosted event notification solutions
event notification solutions scale
objects of larger clusters
notification solutions scale poorly
of larger clusters call
solutions scale poorly and
larger clusters call for
scale poorly and stand
clusters call for longer
poorly and stand as
call for longer dependency
and stand as a
for longer dependency lists
stand as a barrier
as a barrier to
a barrier to collaboration
barrier to collaboration applications
once appropriate real workloads
update delay as seen
appropriate real workloads are
delay as seen by
real workloads are available
as seen by individual
and that developers will
seen by individual processes
that developers will want
by individual processes during
developers will want to
individual processes during persistent
it may be possible
will want to combine
may be possible to
want to combine hosted
processes during persistent link
to combine hosted content
be possible to improve
combine hosted content with
during persistent link congestion
hosted content with p
possible to improve performance
persistent link congestion node
to improve performance by
improve performance by dynamically
performance by dynamically changing
by dynamically changing per
p protocols to overcome
protocols to overcome these
to overcome these problems
object dependency list sizes
in this section we
this section we present
section we present data
balancing between objects to
we present data to
between objects to maintain
present data to support
updates on upstream and
data to support our
on upstream and downstream
to support our claims
upstream and downstream fifo
objects to maintain the
and downstream fifo channels
to maintain the same
maintain the same overall
the same overall space
some of the results
same overall space overhead
another option is to
option is to explore
is to explore an
to explore an approach
explore an approach in
an approach in which
approach in which each
in which each type
which each type of
each type of object
type of object would
of object would have
object would have its
are drawn from a
would have its own
drawn from a widely
have its own dependency
from a widely cited
its own dependency list
a widely cited industry
own dependency list bound
widely cited industry whitepaper
agnostic and treats all
and treats all objects
treats all objects and
all objects and object
and were obtained using
objects and object relations
were obtained using a
and object relations as
obtained using a testing
object relations as equal
using a testing methodology
a testing methodology and
testing methodology and setup
methodology and setup developed
and setup developed and
using an lru policy
setup developed and published
an lru policy to
developed and published by
lru policy to trim
and published by sonic
policy to trim the
published by sonic software
to trim the list
trim the list of
the list of dependencies
there may be cases
may be cases in
be cases in which
cases in which the
in which the application
which the application could
the application could explicitly
application could explicitly inform
could explicitly inform the
explicitly inform the cache
inform the cache of
the cache of relevant
cache of relevant object
of relevant object dependencies
the remainder was produced
remainder was produced in
was produced in our
produced in our own
and those could then
in our own experiments
those could then be
could then be treated
then be treated as
be treated as more
treated as more important
as more important and
more important and retained
while other less important
other less important ones
less important ones are
important ones are managed
ones are managed by
are managed by some
managed by some other
by some other policy
some other policy such
from the industry white
other policy such as
the industry white paper
policy such as lru
analyzes the performance of
the performance of several
performance of several commercial
of several commercial enterprise
several commercial enterprise service
in a web album
commercial enterprise service bus
a web album the
web album the set
album the set of
the set of pictures
set of pictures and
of pictures and their
pictures and their acl
and their acl is
their acl is an
shown is the maximum
acl is an important
is the maximum throughput
is an important dependency
an important dependency whereas
important dependency whereas occasional
dependency whereas occasional tagging
whereas occasional tagging operations
occasional tagging operations that
tagging operations that relate
operations that relate pictures
that relate pictures to
relate pictures to users
pictures to users may
to users may be
users may be less
may be less important
it may be straightforward
may be straightforward to
be straightforward to extend
inconsistency window against gossip
straightforward to extend the
window against gossip rate
to extend the cache
against gossip rate at
extend the cache api
gossip rate at the
the cache api to
rate at the failed
cache api to allow
at the failed node
api to allow the
the experiment varies the
to allow the application
experiment varies the number
allow the application to
varies the number of
the application to specify
the number of subscribers
application to specify such
number of subscribers while
to specify such dependencies
of subscribers while using
specify such dependencies and
subscribers while using a
such dependencies and to
while using a single
dependencies and to modify
using a single publisher
and to modify t
a single publisher that
single publisher that communicates
publisher that communicates through
that communicates through a
cache to respect them
communicates through a single
through a single hosted
a single hosted message
single hosted message broker
hosted message broker on
message broker on a
broker on a single
on a single topic
c onclusion existing large
scale computing frameworks make
computing frameworks make heavy
figured for message durability
frameworks make heavy use
make heavy use of
heavy use of edge
use of edge caches
even if a subscriber
of edge caches to
if a subscriber experiences
edge caches to reduce
a subscriber experiences a
caches to reduce client
subscriber experiences a transient
to reduce client latency
experiences a transient loss
a transient loss of
transient loss of connectivity
time between node failure
but this form of
between node failure and
this form of caching
node failure and rejoin
the publisher retains and
form of caching has
publisher retains and hence
failure and rejoin as
retains and hence can
of caching has not
and hence can replay
and rejoin as number
hence can replay all
caching has not been
can replay all messages
rejoin as number of
has not been available
as number of consecutive
not been available for
number of consecutive updates
been available for transactional
of consecutive updates missed
available for transactional applications
as the number of
consecutive updates missed by
the number of subscribers
updates missed by the
number of subscribers increases
missed by the victim
by the victim node
we believe this is
believe this is one
this is one reason
is one reason that
one reason that transactions
reason that transactions are
that transactions are generally
transactions are generally not
are generally not considered
latency will also soars
generally not considered to
will also soars because
not considered to be
also soars because the
considered to be a
soars because the amount
to be a viable
because the amount of
be a viable option
the amount of time
a viable option in
amount of time the
viable option in extremely
of time the broker
option in extremely large
time the broker needs
in extremely large systems
the broker needs to
broker needs to spend
needs to spend sending
to spend sending a
spend sending a single
sending a single message
a single message increases
single message increases linearly
message increases linearly with
increases linearly with the
linearly with the number
with the number of
a variant of serializability
the number of subscribers
variant of serializability that
of serializability that is
serializability that is suitable
that is suitable for
is suitable for incoherent
suitable for incoherent caches
durability is often not
which cannot communicate with
is often not required
cannot communicate with the
communicate with the backend
with the backend database
the backend database on
backend database on every
database on every read
on every read access
we then presented t
shows throughput in an
throughput in an experiment
in an experiment in
an experiment in which
an architecture for controlling
experiment in which the
architecture for controlling transaction
in which the publisher
for controlling transaction consistency
which the publisher does
controlling transaction consistency with
the publisher does not
transaction consistency with caches
publisher does not log
does not log data
the system extends the
system extends the edge
extends the edge cache
a disconnected subscriber would
the edge cache by
disconnected subscriber would experience
edge cache by allowing
subscriber would experience a
cache by allowing it
would experience a loss
by allowing it to
allowing it to offer
it to offer a
to offer a transactional
offer a transactional interface
we find that while
find that while the
that while the maximum
while the maximum throughput
we believe that t
the maximum throughput is
maximum throughput is much
throughput is much higher
cache is the first
is the first transaction
the degradation of performance
degradation of performance is
of performance is even
performance is even more
aware caching architecture in
is even more dramatic
caching architecture in which
architecture in which caches
in which caches are
which caches are updated
caches are updated asynchronously
developers of collaboration applications
of collaboration applications that
collaboration applications that need
a lookup request only
applications that need good
lookup request only requires
that need good scalability
request only requires a
need good scalability might
only requires a round
good scalability might discover
scalability might discover that
might discover that hosted
discover that hosted esb
that hosted esb options
trip to the database
hosted esb options won
esb options won t
to the database in
options won t achieve
won t achieve this
the database in case
t achieve this goal
database in case there
in case there is
case there is a
there is a cache
is a cache miss
a cache miss there
cache miss there is
we report on some
miss there is no
report on some experiments
there is no additional
on some experiments we
is no additional traffic
some experiments we conducted
no additional traffic and
experiments we conducted on
additional traffic and delays
we conducted on our
traffic and delays to
conducted on our own
and delays to ensure
on our own at
delays to ensure cache
our own at cornell
to ensure cache coherence
focusing on scalability of
on scalability of event
scalability of event notification
of event notification platforms
event notification platforms that
cache associates dependency information
notification platforms that leverage
associates dependency information with
platforms that leverage peer
dependency information with cached
information with cached database
with cached database objects
while leaving the interaction
peer techniques for dissemination
leaving the interaction between
techniques for dissemination and
the interaction between the
for dissemination and recovery
interaction between the backend
between the backend systems
the backend systems and
backend systems and the
systems and the cache
on the first graph
and the cache otherwise
the cache otherwise unchanged
this information includes version
information includes version identifiers
includes version identifiers and
version identifiers and bounded
we compare the maximum
compare the maximum throughput
with this modest amount
the maximum throughput of
this modest amount of
maximum throughput of two
modest amount of additional
throughput of two decentralized
amount of additional information
of two decentralized reliable
two decentralized reliable multicast
decentralized reliable multicast protocols
we show that inconsistency
show that inconsistency can
that inconsistency can be
inconsistency can be greatly
can be greatly reduced
be greatly reduced or
greatly reduced or even
reduced or even completely
or even completely eliminated
even completely eliminated in
completely eliminated in some
eliminated in some cases
cache is intended for
is intended for clustered
intended for clustered workloads
a single topic and
single topic and a
topic and a single
and a single publisher
and those arise naturally
those arise naturally in
arise naturally in social
naturally in social networks
unlike in the previous
in the previous tests
mobile applications with spatial
applications with spatial locality
our experiments demonstrate t
these experiments used a
cache to be effective
to be effective in
be effective in realistic
effective in realistic workloads
in realistic workloads based
realistic workloads based on
workloads based on datasets
based on datasets from
on datasets from amazon
datasets from amazon and
from amazon and orkut
this limits the peak
limits the peak performance
using dependency lists of
the peak performance to
dependency lists of size
gossip chain inconsistency window
and was also able
was also able to
also able to increase
able to increase consistent
to increase consistent transaction
increase consistent transaction rate
consistent transaction rate by
achieves stable high throughput
with only nominal overhead
only nominal overhead on
nominal overhead on the
overhead on the database
runs at about a
at about a fifth
about a fifth that
a fifth that speed
our experiments with synthetic
experiments with synthetic workloads
with synthetic workloads showed
collapsing as the number
synthetic workloads showed that
as the number of
workloads showed that t
the number of subscribers
number of subscribers increases
cache s efficacy depends
s efficacy depends on
efficacy depends on the
depends on the clustering
on the clustering level
at small loss rates
the clustering level of
clustering level of the
level of the workload
latency in qsm is
in qsm is at
qsm is at the
is at the level
at the level of
cache adapts to dynamically
adapts to dynamically changing
to dynamically changing workloads
dynamically changing workloads where
changing workloads where clusters
workloads where clusters change
where clusters change over
clusters change over time
due to resource limitations
to resource limitations t
ms irrespectively of the
irrespectively of the number
cache maintains only a
of the number of
maintains only a short
the number of subscribers
only a short dependency
a short dependency list
when the number of
the number of topics
which is naturally imperfect
number of topics is
is naturally imperfect and
of topics is varied
naturally imperfect and does
imperfect and does not
and does not include
does not include all
not include all dependencies
qsm maintains its high
maintains its high performance
we proved that when
proved that when resources
on the second graph
that when resources are
when resources are unbounded
cache s algorithm implements
s algorithm implements cache
we report performance for
inconsistency window against gossip
window against gossip rate
against gossip rate for
gossip rate for the
rate for the whole
for the whole chain
but performance for other
performance for other group
for other group sizes
other group sizes is
group sizes is similar
jgroups performance was higher
performance was higher with
was higher with smaller
higher with smaller group
with smaller group sizes
but erodes as the
erodes as the number
as the number of
the number of topics
number of topics increases
jgroups failed when we
failed when we attempted
when we attempted to
we attempted to configure
attempted to configure it
to configure it with
configure it with more
it with more than
time between node failure
between node failure and
we look at two
node failure and rejoin
look at two scalable
failure and rejoin as
at two scalable protocols
and rejoin as number
two scalable protocols under
rejoin as number of
scalable protocols under conditions
as number of consecutive
protocols under conditions of
number of consecutive updates
under conditions of stress
of consecutive updates missed
consecutive updates missed by
updates missed by the
missed by the victim
by the victim node
with a focus on
a focus on delivery
focus on delivery latency
as a fixed message
a fixed message rate
fixed message rate is
message rate is spread
rate is spread over
is spread over varying
spread over varying numbers
over varying numbers of
varying numbers of topics
subscribers each join some
each join some number
join some number of
some number of topics
a publisher sends data
publisher sends data at
sends data at a
data at a rate
at a rate of
inconsistency window against the
window against the ratio
against the ratio between
the ratio between injection
ratio between injection rate
selecting the topic in
between injection rate and
the topic in which
injection rate and gossip
topic in which to
rate and gossip rate
in which to send
which to send at
to send at random
different update injection delay
we see that ricochet
s overload by dropping
overload by dropping updates
by dropping updates on
dropping updates on its
updates on its inbound
on its inbound and
its inbound and outbound
a cornelldeveloped protocol for
inbound and outbound fifo
cornelldeveloped protocol for low
and outbound fifo channels
outbound fifo channels according
fifo channels according to
channels according to a
according to a random
to a random distribution
a random distribution throughout
random distribution throughout the
distribution throughout the first
throughout the first three
the first three quarters
first three quarters of
three quarters of the
quarters of the experiment
as the number of
the number of topics
number of topics increases
of topics increases to
latency soars when we
soars when we repeat
when we repeat this
we repeat this with
repeat this with the
this with the industrystandard
with the industrystandard scalable
the industrystandard scalable reliable
industrystandard scalable reliable multicast
and we report on
widely used for event
used for event notification
for event notification in
event notification in their
notification in their datacenters
as can be seen
can be seen in
be seen in the
seen in the graph
updates that were initially
that were initially dropped
were initially dropped and
initially dropped and eventually
srm s recovery latency
dropped and eventually made
s recovery latency rises
and eventually made their
recovery latency rises linearly
eventually made their way
latency rises linearly in
made their way through
rises linearly in the
linearly in the figure
their way through gossip
way through gossip could
through gossip could later
gossip could later be
could later be sent
later be sent via
be sent via fifo
sent via fifo channels
scalability of commercial esbs
via fifo channels as
of commercial esbs figure
fifo channels as shown
channels as shown by
as shown by the
shown by the increasingly
by the increasingly large
the increasingly large density
increasingly large density of
large density of dark
scalability of commercial esbs
of commercial esbs number
commercial esbs number of
esbs number of topics
plots closer to the
closer to the tail
to the tail of
the tail of the
tail of the chain
as before note that
before note that the
note that the yaxes
that the yaxes have
the yaxes have different
yaxes have different scales
have different scales to
different scales to observe
scales to observe the
to observe the delays
observe the delays better
our experiments confirm that
the figures show that
figures show that even
show that even for
that even for a
hosted enterprise service bus
even for a gossip
enterprise service bus architectures
for a gossip rate
service bus architectures can
a gossip rate half
bus architectures can achieve
gossip rate half the
architectures can achieve high
rate half the injection
can achieve high levels
half the injection rate
achieve high levels of
high levels of publish
recall that this is
that this is the
subscribe performance for small
this is the rate
performance for small numbers
is the rate at
for small numbers of
the rate at which
small numbers of subscribers
rate at which digests
but performance degrades very
performance degrades very sharply
degrades very sharply as
very sharply as the
are exchanged between two
sharply as the number
exchanged between two or
as the number of
between two or more
the number of subscribers
two or more processes
number of subscribers or
of subscribers or topics
subscribers or topics grows
the epidemics could deliver
epidemics could deliver messages
the jgroups and srm
could deliver messages with
jgroups and srm platforms
deliver messages with a
messages with a delay
with a delay of
a delay of about
which don t leverage
don t leverage peer
scale poorly in the
poorly in the number
in the number of
the number of subscribers
number of subscribers or
google s globally distributed
of subscribers or topics
s globally distributed database
acm transactions on computer
transactions on computer systems
scale well in these
well in these dimensions
s for the rest
for the rest of
the rest of the
rest of the chain
of the chain during
ricochet achieved the best
the chain during a
achieved the best recovery
chain during a congestion
the best recovery latency
during a congestion that
best recovery latency when
a congestion that took
recovery latency when message
latency when message loss
when message loss is
message loss is an
loss is an issue
but at relatively high
at relatively high overhead
the plot also shows
plot also shows that
also shows that delays
not shown on these
shows that delays increased
shown on these graphs
that delays increased with
delays increased with time
therefore if congestion may
if congestion may span
congestion may span large
may span large periods
qsm at small loss
span large periods of
at small loss rates
large periods of time
small loss rates achieves
loss rates achieves similar
rates achieves similar average
achieves similar average latency
similar average latency with
the gossip rate must
average latency with considerably
gossip rate must be
latency with considerably lower
rate must be carefully
with considerably lower network
must be carefully tuned
considerably lower network overheads
be carefully tuned to
carefully tuned to compensate
tuned to compensate for
to compensate for the
but if a packet
compensate for the losses
if a packet is
for the losses induced
a packet is lost
the losses induced by
losses induced by the
induced by the congested
by the congested tcp
the congested tcp channels
it may take several
may take several seconds
take several seconds to
several seconds to recover
seconds to recover it
the second round of
second round of experiments
round of experiments quantified
of experiments quantified the
making it less appropriate
experiments quantified the average
it less appropriate for
quantified the average and
less appropriate for time
the average and maximum
average and maximum inconsistency
and maximum inconsistency window
maximum inconsistency window for
inconsistency window for a
window for a service
we don t see
don t see any
t see any single
see any single winner
any single winner here
each of the solutions
of the solutions tested
the solutions tested has
solutions tested has some
under various update injection
tested has some advantages
various update injection rates
has some advantages that
update injection rates and
some advantages that its
injection rates and gossip
advantages that its competitors
rates and gossip rates
that its competitors lack
and gossip rates respectively
we define the inconsistency
define the inconsistency window
the inconsistency window as
we re currently developing
inconsistency window as the
re currently developing new
window as the time
currently developing new p
as the time interval
the time interval during
time interval during which
interval during which queries
during which queries against
which queries against the
queries against the service
against the service return
the service return a
service return a stale
return a stale value
shows that the inconsistency
that the inconsistency window
the inconsistency window grows
it builds an overlay
inconsistency window grows slowly
builds an overlay multicast
window grows slowly as
distributed data structures over
an overlay multicast tree
data structures over a
grows slowly as the
structures over a shared
overlay multicast tree within
over a shared log
slowly as the gap
multicast tree within which
as the gap between
tree within which events
the gap between the
within which events travel
in proceedings of the
gap between the update
between the update injection
the update injection rate
update injection rate and
and is capable of
injection rate and the
is capable of selforganizing
rate and the gossip
capable of selforganizing in
and the gossip rate
of selforganizing in the
th acm symposium on
the gossip rate widens
acm symposium on operating
selforganizing in the presence
symposium on operating systems
in the presence of
on operating systems principles
the presence of firewalls
the graph s x
graph s x axis
s x axis represents
x axis represents the
axis represents the ratio
represents the ratio between
the ratio between the
ratio between the update
between the update injection
the update injection rate
update injection rate and
injection rate and gossip
rate and gossip rate
a separate project is
separate project is creating
project is creating a
is creating a protocol
creating a protocol suite
a protocol suite that
protocol suite that we
this confirms that epidemics
suite that we call
confirms that epidemics are
that we call the
that epidemics are a
we call the properties
epidemics are a robust
call the properties framework
are a robust tunable
a robust tunable mechanism
robust tunable mechanism providing
tunable mechanism providing graceful
mechanism providing graceful degradation
the inconsistency window shifts
inconsistency window shifts in
window shifts in accordance
shifts in accordance with
in accordance with the
accordance with the update
the goal is to
with the update injection
goal is to offer
the update injection rate
is to offer strong
to offer strong forms
offer strong forms of
strong forms of reliability
forms of reliability that
of reliability that can
reliability that can be
that can be customized
can be customized for
notice that the difference
be customized for special
that the difference between
customized for special needs
the difference between the
difference between the maximum
between the maximum inconsistency
the maximum inconsistency window
maximum inconsistency window and
inconsistency window and the
window and the average
speed and scalability are
and the average inconsistency
and scalability are only
the average inconsistency window
scalability are only elements
average inconsistency window is
are only elements of
inconsistency window is two
only elements of a
window is two orders
elements of a broader
is two orders of
of a broader story
two orders of magnitude
developers will need different
will need different solutions
this reflects the degree
need different solutions for
reflects the degree to
ordering transactions with prediction
different solutions for different
the degree to which
solutions for different purposes
degree to which the
transactions with prediction in
to which the victim
with prediction in distributed
which the victim node
prediction in distributed object
by offering a flexible
in distributed object stores
the victim node lags
offering a flexible yet
victim node lags the
a flexible yet structured
node lags the other
flexible yet structured component
lags the other nodes
yet structured component mashup
the other nodes during
structured component mashup environment
other nodes during the
nodes during the period
during the period before
the period before it
period before it has
live objects makes it
before it has fully
objects makes it possible
it has fully caught
th workshop on large
has fully caught up
makes it possible to
it possible to create
possible to create applications
to create applications that
scale distributed systems and
create applications that mix
distributed systems and middleware
next we evaluated the
applications that mix hosted
we evaluated the inconsistency
that mix hosted with
evaluated the inconsistency window
mix hosted with p
the inconsistency window of
inconsistency window of a
window of a service
of a service running
a service running at
service running at a
running at a particular
at a particular update
a particular update rate
and that can adapt
that can adapt their
can adapt their behavior
and for three different
for three different intervals
three different intervals in
different intervals in which
intervals in which the
in which the victim
to achieve desired properties
which the victim node
achieve desired properties in
the victim node is
desired properties in a
victim node is halted
properties in a way
in a way matched
a way matched to
way matched to the
matched to the environment
show average and maximum
average and maximum inconsistency
and maximum inconsistency windows
scalability of qsm and
maximum inconsistency windows for
of qsm and jgroups
inconsistency windows for both
windows for both the
for both the victim
both the victim and
throughput for various group
the victim and for
for various group sizes
victim and for the
and for the other
for the other processes
the other processes of
other processes of one
processes of one subservice
prior work the idea
work the idea of
the idea of integrating
the more messages the
idea of integrating web
more messages the victim
of integrating web services
messages the victim node
integrating web services with
the victim node needs
web services with peer
key transactions for key
victim node needs to
node needs to recover
the larger the inconsistency
larger the inconsistency window
peer platforms is certainly
platforms is certainly not
is certainly not new
again the difference between
the difference between the
difference between the average
between the average and
the average and maximum
average and maximum in
facebook s distributed data
s distributed data store
distributed data store for
data store for the
store for the social
for the social graph
in usenix annual technical
usenix annual technical conference
the existing work falls
existing work falls roughly
work falls roughly into
falls roughly into two
roughly into two categories
the first line of
first line of research
line of research is
of research is focused
research is focused on
is focused on the
focused on the use
on the use of
the use of peer
as a basis for
a basis for scalable
basis for scalable web
for scalable web service
scalable web service discovery
the second line of
second line of research
line of research concentrates
of research concentrates on
research concentrates on the
concentrates on the use
on the use of
the use of replication
use of replication protocols
of replication protocols at
replication protocols at the
protocols at the web
at the web service
the web service backend
web service backend to
service backend to achieve
backend to achieve fault
p platforms such as
platforms such as jxta
such as jxta are
as jxta are treated
jxta are treated not
are treated not as
treated not as means
not as means of
as means of collaboration
means of collaboration or
of collaboration or media
collaboration or media carrying
or media carrying live
media carrying live content
but rather as a
rather as a supporting
as a supporting infrastructure
a supporting infrastructure at
supporting infrastructure at the
infrastructure at the data
at the data center
the data center backend
our work is focused
work is focused on
is focused on blending
focused on blending the
on blending the content
blending the content available
the content available through
content available through p
p and web service
and web service protocols
neither technology is subordinate
technology is subordinate with
is subordinate with respect
subordinate with respect to
with respect to the
respect to the other
delivery distribution for a
distribution for a chain
scaling memcache at facebook
technologies that use peer
peer protocols to support
protocols to support live
to support live and
th usenix symposium on
support live and interactive
usenix symposium on networked
live and interactive content
symposium on networked systems
and interactive content have
on networked systems design
interactive content have existed
gossip rate left figure
content have existed earlier
networked systems design and
systems design and implementation
an excellent example of
excellent example of such
example of such technology
of such technology is
such technology is the
technology is the croquet
in which the entire
which the entire state
the entire state of
entire state of a
state of a virtual
d world is stored
world is stored in
is stored in a
stored in a peer
peer fashion and updated
fashion and updated using
and updated using a
updated using a two
on each graph left
each graph left bars
other work in this
graph left bars denote
work in this direction
left bars denote transient
in this direction includes
bars denote transient failure
right bars denote a
bars denote a transient
denote a transient failure
a transient failure corroborated
transient failure corroborated with
failure corroborated with a
corroborated with a link
with a link congestion
a link congestion phenomenon
none of these systems
link congestion phenomenon modeled
of these systems supports
congestion phenomenon modeled by
these systems supports the
systems supports the sorts
supports the sorts of
the sorts of componentized
layered architectures that we
architectures that we have
that we have advocated
we have advocated here
message drop on the
drop on the adjacent
on the adjacent fifo
the adjacent fifo channels
the types of peer
adjacent fifo channels of
fifo channels of node
peer protocols these systems
protocols these systems can
these systems can leverage
and the types of
the types of a
types of a traditional
of a traditional hosted
a traditional hosted content
traditional hosted content they
hosted content they can
content they can blend
they can blend with
can blend with their
blend with their p
our platform is designed
platform is designed from
is designed from ground
designed from ground up
from ground up with
ground up with extensibility
up with extensibility in
with extensibility in mind
every part of it
part of it can
of it can be
it can be replaced
can be replaced and
be replaced and customized
and different components within
different components within a
components within a single
within a single mashup
a single mashup application
single mashup application can
mashup application can leverage
application can leverage different
can leverage different transport
leverage different transport protocols
transactional consistency and automatic
consistency and automatic management
prior work on typed
and automatic management in
work on typed component
automatic management in an
on typed component architectures
management in an application
typed component architectures includes
in an application data
component architectures includes a
an application data cache
architectures includes a tremendous
includes a tremendous variety
a tremendous variety of
tremendous variety of programming
variety of programming languages
of programming languages and
programming languages and platforms
th usenix symposium on
usenix symposium on operating
symposium on operating systems
including early languages such
on operating systems design
early languages such as
operating systems design and
languages such as smalltalk
systems design and implementation
such as smalltalk alongside
as smalltalk alongside modern
smalltalk alongside modern component
based environments such as
environments such as java
specialized component architectures such
component architectures such figure
scalability qsm and jgroups
throughput for various numbers
for various numbers of
various numbers of topics
for srm and ricochet
srm and ricochet with
and ricochet with varying
ricochet with varying numbers
with varying numbers of
varying numbers of topics
as mit s argus
mit s argus system
flexible protocol composition stacks
protocol composition stacks such
composition stacks such as
stacks such as bast
oriented architectures such as
architectures such as juni
has been used in
been used in the
fast iterative graph computation
used in the context
iterative graph computation with
in the context of
graph computation with block
the context of integrating
computation with block updates
context of integrating service
of the vldb endowment
discussion of component integration
of component integration systems
component integration systems and
integration systems and their
systems and their relation
and their relation to
their relation to live
relation to live objects
is beyond the scope
beyond the scope of
the scope of this
scope of this paper
more details can be
details can be found
can be found in
much relevant prior work
relevant prior work consists
prior work consists of
work consists of the
consists of the scripting
of the scripting languages
the scripting languages mentioned
scripting languages mentioned in
languages mentioned in the
mentioned in the discussion
we found that less
in the discussion above
found that less than
of the messages were
the messages were delivered
messages were delivered by
our belief is that
were delivered by gossip
belief is that even
delivered by gossip for
is that even though
by gossip for the
that even though these
gossip for the nodes
even though these languages
for the nodes to
though these languages are
the nodes to the
these languages are intended
nodes to the left
languages are intended for
to the left of
are intended for fairly
concurrency control and recovery
intended for fairly general
control and recovery in
for fairly general use
the left of the
and recovery in database
left of the victim
recovery in database systems
they have evolved to
have evolved to focus
this confirms that gossip
evolved to focus on
confirms that gossip rarely
to focus on minibrowser
that gossip rarely is
focus on minibrowser situations
gossip rarely is used
on minibrowser situations in
rarely is used to
minibrowser situations in which
is used to circumvent
situations in which the
used to circumvent chain
in which the application
to circumvent chain replication
which the application lives
circumvent chain replication in
the application lives within
chain replication in the
application lives within a
replication in the normal
lives within a dedicated
in the normal case
within a dedicated browser
a dedicated browser frame
a peculiar effect is
interacts directly with the
peculiar effect is noticeable
directly with the user
effect is noticeable in
is noticeable in figure
and cannot be mixed
cannot be mixed with
be mixed with content
mixed with content from
with content from other
content from other sources
from other sources in
other sources in a
sources in a layered
in that more messages
in a layered fashion
that more messages are
more messages are delivered
messages are delivered via
are delivered via gossip
live objects can support
objects can support minibrowsers
can support minibrowsers as
support minibrowsers as objects
even in the prefix
in the prefix part
the prefix part of
prefix part of the
part of the chain
but we ve argued
we ve argued that
ve argued that by
although the effect is
argued that by modeling
the effect is also
that by modeling hosted
effect is also evident
by modeling hosted content
is also evident in
modeling hosted content at
also evident in the
hosted content at a
evident in the suffix
content at a lower
at a lower level
a lower level as
lower level as components
it is more significant
level as components that
is more significant on
as components that interact
more significant on the
components that interact via
significant on the left
that interact via events
on the left hand
interact via events and
the dynamics of viral
the left hand side
dynamics of viral marketing
via events and focusing
left hand side figure
events and focusing on
and focusing on the
focusing on the multi
acm transactions on the
transactions on the web
where the gossip rate
the gossip rate is
gossip rate is higher
layered style of mashups
style of mashups as
of mashups as opposed
mashups as opposed to
because we observed this
as opposed to the
we observed this phenomenon
opposed to the standard
observed this phenomenon only
to the standard tiled
this phenomenon only with
the standard tiled model
phenomenon only with update
only with update rates
with update rates of
conclusions to build ambitious
to build ambitious collaboration
build ambitious collaboration application
we suspect that the
suspect that the network
that the network stack
the web services community
the network stack is
web services community will
network stack is more
services community will need
stack is more efficient
community will need ways
is more efficient in
will need ways to
more efficient in dealing
need ways to combine
efficient in dealing with
in dealing with udp
dealing with udp packets
with udp packets then
udp packets then with
packets then with tcp
then with tcp ones
with tcp ones under
tcp ones under heavy
content from multiple sources
ones under heavy load
these include hosted sources
include hosted sources that
hosted sources that run
sources that run in
that run in data
run in data centers
in data centers and
data centers and support
centers and support web
and support web services
support web services interfaces
but also direct peer
peer protocols capable of
protocols capable of transporting
capable of transporting audio
whiteboard data and other
data and other content
and other content at
other content at high
content at high data
at high data rates
measurement and analysis of
a further need is
and analysis of online
further need is to
analysis of online social
need is to allow
of online social networks
is to allow disconnected
delivery distribution for a
to allow disconnected collaboration
distribution for a chain
in proceedings of the
back to data centers
th acm sigcomm conference
acm sigcomm conference on
sigcomm conference on internet
conference on internet measurement
our review of the
review of the performance
of the performance of
the performance of enterprise
performance of enterprise service
of enterprise service bus
enterprise service bus eventing
service bus eventing solutions
bus eventing solutions in
eventing solutions in the
solutions in the standard
in the standard hosted
the standard hosted web
standard hosted web services
hosted web services model
web services model made
services model made it
model made it clear
made it clear that
it clear that hosted
clear that hosted event
that hosted event channels
hosted event channels won
event channels won t
channels won t have
won t have the
t have the scalability
have the scalability and
the scalability and latency
scalability and latency properties
and latency properties needed
latency properties needed by
properties needed by many
needed by many applications
p alternatives often achieve
alternatives often achieve far
often achieve far better
achieve far better scalability
consistency windows is slightly
windows is slightly more
is slightly more than
slightly more than an
more than an order
than an order of
they also have security
an order of magnitude
also have security advantages
sampling from large graphs
the data center doesn
and this is attributable
data center doesn t
center doesn t get
in proceedings of the
doesn t get a
this is attributable to
t get a chance
get a chance to
is attributable to the
a chance to see
attributable to the victim
to the victim node
the victim node observe
th acm sigkdd international
victim node observe that
acm sigkdd international conference
node observe that the
sigkdd international conference on
observe that the two
international conference on knowledge
that the two graphs
conference on knowledge discovery
the live objects platform
on knowledge discovery and
the two graphs denoting
knowledge discovery and data
live objects platform can
two graphs denoting the
discovery and data mining
objects platform can seamlessly
graphs denoting the maximum
platform can seamlessly support
denoting the maximum inconsistency
can seamlessly support applications
the maximum inconsistency windows
seamlessly support applications that
maximum inconsistency windows for
support applications that require
inconsistency windows for the
applications that require a
windows for the victim
that require a mixture
for the victim node
require a mixture of
the victim node and
a mixture of data
victim node and for
mixture of data sources
node and for the
and for the entire
for the entire chain
the entire chain are
entire chain are identical
including both hosted and
both hosted and direct
hosted and direct p
which means that clients
means that clients perceiving
that clients perceiving significant
clients perceiving significant inconsistency
perceiving significant inconsistency are
significant inconsistency are the
inconsistency are the ones
further benefits include an
are the ones that
benefits include an easy
the ones that are
include an easy to
ones that are querying
an easy to use
that are querying the
easy to use drag
are querying the victim
querying the victim node
the victim node while
victim node while it
node while it is
while it is still
it is still recovering
is still recovering state
drop programming style that
programming style that yields
style that yields applications
that yields applications represented
yields applications represented as
finally we performed a
applications represented as xml
we performed a set
represented as xml files
performed a set of
a set of experiments
set of experiments to
of experiments to determine
which can be shared
experiments to determine the
can be shared as
to determine the distribution
be shared as files
determine the distribution of
shared as files or
the distribution of messages
as files or even
distribution of messages delivered
files or even via
of messages delivered by
or even via email
messages delivered by the
delivered by the chain
by the chain vs
the chain vs delivered
users that open such
chain vs delivered by
that open such files
vs delivered by gossip
open such files find
such files find themselves
files find themselves immersed
find themselves immersed in
themselves immersed in a
immersed in a mediarich
in a mediarich collaborative
one transient failure affects
a mediarich collaborative environment
transient failure affects the
mediarich collaborative environment that
failure affects the wall
collaborative environment that also
environment that also offers
that also offers strong
also offers strong reliability
the runs are eight
runs are eight times
are eight times longer
eight times longer than
don t settle for
times longer than the
t settle for eventual
longer than the runs
than the runs before
in the near future
scalable causal consistency for
causal consistency for wide
both in total experiment
in total experiment time
total experiment time and
experiment time and time
time and time the
area storage with cops
and time the victim
time the victim node
the victim node is
victim node is halted
most important of all
live objects are real
the platform is available
platform is available for
is available for free
available for free download
rd acm symposium on
for free download from
acm symposium on operating
free download from cornell
symposium on operating systems
on operating systems principles
show the number of
the number of messages
number of messages delivered
of messages delivered by
messages delivered by the
delivered by the chain
by the chain replication
the chain replication mechanism
chain replication mechanism and
replication mechanism and the
mechanism and the ones
and the ones delivered
the ones delivered by
ones delivered by the
delivered by the epidemics
for each of the
each of the nodes
of the nodes in
the nodes in a
nodes in a chain
again we omitted the
we omitted the head
omitted the head of
the head of the
head of the chain
of the chain node
the chain node because
chain node because its
node because its behavior
lateral error correction for
because its behavior is
error correction for time
its behavior is not
behavior is not representative
and in this experiment
in this experiment we
this experiment we have
experiment we have chains
we have chains of
have chains of length
transactional storage for geo
delivered updates by means
updates by means of
by means of the
means of the gossip
of the gossip repair
the gossip repair mechanism
as the nodes get
the nodes get further
nodes get further away
get further away from
further away from the
away from the victim
from the victim node
rd acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
more of the messages
of the messages were
the messages were delivered
messages were delivered by
were delivered by means
delivered by means of
by means of the
means of the chain
because the repair mechanism
the repair mechanism relinked
repair mechanism relinked the
mechanism relinked the chain
relinked the chain and
the chain and chain
chain and chain replication
and chain replication began
chain replication began to
replication began to function
began to function normally
the speed with which
speed with which the
with which the chain
which the chain is
the chain is restored
chain is restored depends
is restored depends on
restored depends on the
depends on the rate
on the rate of
the rate of the
rate of the fast
and on the responsiveness
on the responsiveness of
the responsiveness of the
responsiveness of the failure
of the failure detection
the failure detection mechanism
future development the current
development the current ssa
the current ssa implementation
current ssa implementation uses
ssa implementation uses gossip
implementation uses gossip in
uses gossip in situations
gossip in situations where
in situations where faster
situations where faster notifications
where faster notifications might
faster notifications might be
notifications might be helpful
exploiting gossip for self
we believe that when
believe that when a
management in scalable event
that when a node
in scalable event notification
when a node fails
scalable event notification systems
a node fails or
node fails or joins
it would be useful
would be useful to
be useful to spread
useful to spread the
replicated systems fast as
to spread the news
systems fast as possible
spread the news as
the news as quickly
news as quickly as
as quickly as possible
we realize that for
realize that for some
that for some particular
for some particular tasks
some particular tasks gossip
particular tasks gossip could
tasks gossip could be
gossip could be done
could be done more
th usenix symposium on
be done more efficiently
usenix symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
we are therefore exploring
are therefore exploring the
therefore exploring the use
semantic integration of web
exploring the use of
integration of web services
the use of ip
of web services and
use of ip multicast
web services and peer
of ip multicast for
ip multicast for dissemination
multicast for dissemination of
for dissemination of urgent
dissemination of urgent information
of urgent information as
urgent information as long
peer networks to achieve
information as long as
networks to achieve fault
as long as the
long as the physical
as the physical nodes
the physical nodes are
physical nodes are not
nodes are not on
are not on a
not on a public
on a public network
a public network segment
we plan to include
plan to include support
to include support for
include support for the
support for the partitioning
for the partitioning of
the partitioning of the
partitioning of the services
of the services by
the services by means
services by means of
by means of registering
means of registering partition
of registering partition function
registering partition function handlers
partition function handlers with
function handlers with a
handlers with a global
with a global data
flexible protocol composition in
protocol composition in bast
we have implemented only
have implemented only the
implemented only the server
only the server side
the server side load
server side load balancing
side load balancing scheme
we are considering ways
are considering ways to
considering ways to extend
ways to extend our
to extend our approach
extend our approach for
our approach for use
approach for use in
combining acid and base
for use in settings
acid and base in
use in settings where
and base in a
in settings where partitioning
base in a distributed
settings where partitioning is
in a distributed database
where partitioning is done
partitioning is done on
is done on the
done on the client
on the client side
self organizing live objects
th usenix symposium on
side access to subservice
usenix symposium on operating
access to subservice membership
symposium on operating systems
to subservice membership information
on operating systems design
subservice membership information is
operating systems design and
membership information is needed
systems design and implementation
we are also developing
are also developing a
also developing a gui
developing a gui assisted
a gui assisted automated
gui assisted automated web
assisted automated web service
automated web service deployment
web service deployment tool
focused on web service
on web service applications
developers could simply drop
could simply drop a
simply drop a wsdl
drop a wsdl service
a wsdl service description
and the system will
the system will generate
system will generate a
will generate a xml
generate a xml description
a xml description that
xml description that can
jms performance comparison for
description that can be
performance comparison for publish
that can be used
comparison for publish subscribe
can be used later
for publish subscribe messaging
be used later on
used later on to
later on to actually
on to actually deploy
to actually deploy the
fiorano software technologies pvt
actually deploy the service
deploy the service automatically
the service will be
service will be partitioned
and deployed on the
deployed on the fly
on the fly on
the fly on top
fly on top of
on top of the
top of the processing
of the processing nodes
a shared log design
shared log design for
scaling up to turn
log design for flash
up to turn the
design for flash clusters
to turn the ssa
turn the ssa into
the ssa into a
ssa into a full
into a full scale
a full scale platform
th usenix symposium on
usenix symposium on networked
one of the immediate
symposium on networked systems
of the immediate future
on networked systems design
the immediate future challenges
networked systems design and
immediate future challenges is
systems design and implementation
future challenges is the
challenges is the necessity
is the necessity of
the necessity of evaluating
necessity of evaluating a
of evaluating a full
evaluating a full raps
leveraging collaboration of peer
a full raps of
full raps of racs
raps of racs deployment
multiple partitioned and cloned
peer and web services
partitioned and cloned services
and cloned services running
cloned services running on
services running on our
running on our tightly
on our tightly coupled
our tightly coupled cluster
tightly coupled cluster would
coupled cluster would lead
cluster would lead to
would lead to a
lead to a series
to a series of
a series of other
series of other issues
of other issues that
other issues that should
issues that should be
that should be investigated
placement given a set
given a set of
a set of services
how to place the
to place the clones
place the clones on
the clones on physical
clones on physical nodes
on physical nodes in
physical nodes in order
nodes in order to
in order to satisfy
order to satisfy certain
to satisfy certain constraints
based web service composition
web service composition with
service composition with jade
composition with jade and
with jade and jxta
caching placement deciding if
placement deciding if some
deciding if some services
if some services would
some services would benefit
services would benefit if
would benefit if they
benefit if they are
if they are fitted
they are fitted with
are fitted with response
fitted with response caches
and ultimately placing the
ultimately placing the cache
placing the cache components
the cache components in
cache components in a
components in a smart
in a smart way
location placing multiple service
placing multiple service clones
multiple service clones on
service clones on the
clones on the same
on the same physical
the same physical node
same physical node to
physical node to exploit
node to exploit fast
based architecture for semanticweb
to exploit fast ipc
architecture for semanticweb service
exploit fast ipc communication
for semanticweb service automatic
fast ipc communication as
semanticweb service automatic composition
ipc communication as opposed
communication as opposed to
as opposed to network
opposed to network messages
to network messages if
network messages if the
messages if the benefits
if the benefits overweigh
the benefits overweigh the
benefits overweigh the cost
overweigh the cost incurred
the cost incurred by
cost incurred by resource
incurred by resource contention
by resource contention on
resource contention on the
contention on the shared
on the shared host
management tools developing tools
tools developing tools that
developing tools that monitor
tools that monitor service
that monitor service properties
monitor service properties such
service properties such as
properties such as response
such as response time
by restarting new clones
using vmm tricks virtual
vmm tricks virtual machines
tricks virtual machines can
virtual machines can be
machines can be used
can be used to
be used to migrate
used to migrate transparently
to migrate transparently a
migrate transparently a collection
transparently a collection of
a collection of services
collection of services on
of services on a
services on a different
on a different physical
a different physical processor
or provide isolation guarantees
provide isolation guarantees between
isolation guarantees between co
the ssa can be
ssa can be seen
can be seen as
be seen as a
seen as a platform
as a platform that
a platform that leverages
platform that leverages tradeoffs
and jong hoon ahnn
that leverages tradeoffs between
leverages tradeoffs between weaker
tradeoffs between weaker consistency
programming with live distributed
with live distributed objects
with a compensating gossip
a compensating gossip repair
compensating gossip repair mechanism
for higher availability and
higher availability and simplicity
this is an old
is an old idea
an old idea first
old idea first explored
idea first explored in
first explored in the
explored in the grapevine
and later in systems
later in systems like
in systems like bayou
which offer a broad
offer a broad operational
a broad operational spectrum
broad operational spectrum between
operational spectrum between strong
achieving reliability through distributed
reliability through distributed data
through distributed data flows
acid in the distributed
distributed data flows and
in the distributed database
data flows and recursive
the distributed database cases
flows and recursive delegation
several database and distributed
database and distributed systems
and distributed systems take
distributed systems take advantage
systems take advantage of
take advantage of the
advantage of the same
of the same tradeoff
for example allowing multiple
example allowing multiple updates
allowing multiple updates to
multiple updates to occur
updates to occur simultaneously
to occur simultaneously at
occur simultaneously at distinct
simultaneously at distinct replicas
at distinct replicas by
distinct replicas by specifying
replicas by specifying a
by specifying a maximum
specifying a maximum accepted
a maximum accepted deviation
maximum accepted deviation from
accepted deviation from strong
deviation from strong consistency
tolerating a bounded number
a bounded number of
bounded number of consistency
number of consistency violations
of consistency violations to
consistency violations to increase
violations to increase concurrency
to increase concurrency of
increase concurrency of transactions
or replication according to
replication according to the
according to the need
achieving serializability with low
serializability with low latency
with low latency in
low latency in geodistributed
latency in geodistributed storage
in geodistributed storage systems
changtao qu and wolfgang
in proceedings of the
qu and wolfgang nejdl
th acm symposium on
our work on the
acm symposium on operating
work on the ssa
symposium on operating systems
on the ssa is
on operating systems principles
the ssa is the
ssa is the first
is the first to
peer network with web
the first to apply
network with web services
first to apply such
to apply such thinking
apply such thinking to
such thinking to a
thinking to a cluster
to a cluster computing
a cluster computing environment
platform was designed to
was designed to provide
designed to provide a
to provide a cluster
provide a cluster based
a cluster based environment
cluster based environment for
based environment for scalable
environment for scalable internet
for scalable internet services
scalable internet services of
internet services of the
services of the sort
of the sort used
the sort used in
sort used in web
used in web servers
caching proxies and transformation
proxies and transformation proxies
service components are controlled
components are controlled by
are controlled by a
a scalable and ontology
controlled by a front
by a front end
a front end machine
front end machine that
end machine that acts
machine that acts as
that acts as a
p infrastructure for semantic
acts as a request
infrastructure for semantic web
as a request dispatcher
for semantic web services
a request dispatcher and
request dispatcher and incorporates
dispatcher and incorporates the
and incorporates the load
incorporates the load balancing
the load balancing and
load balancing and restart
balancing and restart logics
end processes are detected
processes are detected to
are detected to have
detected to have failed
new processes are forked
processes are forked to
are forked to take
forked to take over
to take over the
acm transactions on database
take over the load
transactions on database systems
tacc workers can be
workers can be composed
can be composed to
be composed to address
composed to address more
to address more complex
address more complex tasks
tacc stands for transformation
a collaboration system architecture
ssa can be seen
can be seen as
be seen as revisiting
seen as revisiting these
as revisiting these architectural
revisiting these architectural ideas
these architectural ideas in
architectural ideas in conjunction
ideas in conjunction with
in conjunction with chain
conjunction with chain replication
have long supported clustered
long supported clustered architectures
and were the first
were the first systems
sonic performance test suite
the first systems to
first systems to exploit
systems to exploit the
to exploit the style
exploit the style of
the style of partitioning
style of partitioning that
of partitioning that leads
partitioning that leads to
that leads to a
leads to a raps
to a raps of
a raps of racs
raps of racs solution
most database systems adhere
database systems adhere closely
systems adhere closely to
adhere closely to the
closely to the acid
to the acid model
at potentially high cost
potentially high cost in
high cost in terms
cost in terms of
in terms of reduced
terms of reduced availability
of reduced availability during
reduced availability during faults
discuss this problem in
ultimately arguing for precisely
arguing for precisely the
for precisely the weak
precisely the weak update
the weak update model
weak update model that
update model that we
model that we adopted
that we adopted here
application servers like the
servers like the j
offer persistent state support
persistent state support by
state support by wrapping
support by wrapping soft
by wrapping soft state
wrapping soft state business
soft state business logic
state business logic components
business logic components on
logic components on top
components on top of
on top of a
top of a relational
of a relational or
a relational or object
they also target large
scale highly available services
a demonstration of collaborative
and hence we believe
demonstration of collaborative web
hence we believe they
of collaborative web services
we believe they could
collaborative web services and
believe they could benefit
web services and peer
they could benefit from
could benefit from ssa
in a similar vein
shoring up persistent applications
in proceedings of the
framework makes it easy
makes it easy to
it easy to create
easy to create robust
to create robust scalable
create robust scalable services
ninja is arguably more
acm sigmod international conference
is arguably more flexible
sigmod international conference on
arguably more flexible than
international conference on management
more flexible than application
conference on management of
flexible than application servers
on management of data
than application servers in
application servers in that
servers in that it
in that it performs
that it performs connection
it performs connection management
performs connection management and
connection management and automatically
management and automatically partitions
and automatically partitions and
automatically partitions and replicates
p network based architecture
partitions and replicates persistent
network based architecture for
and replicates persistent state
based architecture for web
architecture for web service
but the framework takes
the framework takes a
framework takes a different
takes a different tiered
a different tiered approach
different tiered approach to
tiered approach to services
approach to services based
to services based on
services based on bases
active proxies and units
and represents shared state
represents shared state by
shared state by means
state by means of
by means of distributed
means of distributed data
of distributed data structures
conclusion our paper presents
our paper presents the
paper presents the scalable
presents the scalable services
the scalable services architecture
a new platform for
new platform for porting
platform for porting a
for porting a large
porting a large class
a large class of
large class of service
oriented applications onto clusters
the ssa was designed
ssa was designed to
was designed to be
designed to be as
to be as simple
be as simple as
as simple as possible
and at the core
at the core uses
the core uses just
core uses just two
uses just two primitive
just two primitive mechanisms
tcp chains that support
chains that support a
that support a variant
support a variant of
a variant of chain
variant of chain replication
and gossip epidemics which
gossip epidemics which are
epidemics which are used
which are used to
are used to manage
used to manage configuration
to manage configuration data
manage configuration data and
configuration data and initiate
data and initiate repair
and initiate repair after
initiate repair after failures
with appropriate parameter settings
given a gossip rate
a gossip rate that
gossip rate that is
rate that is sufficiently
that is sufficiently fast
is sufficiently fast relative
sufficiently fast relative to
fast relative to the
relative to the update
to the update rates
the update rates seen
update rates seen in
rates seen in the
seen in the cluster
we find that the
find that the ssa
that the ssa can
the ssa can rapidly
ssa can rapidly and
can rapidly and automatically
rapidly and automatically reconfigure
and automatically reconfigure itself
automatically reconfigure itself after
reconfigure itself after a
itself after a failure
after a failure and
a failure and can
failure and can rapidly
and can rapidly repair
can rapidly repair data
rapidly repair data inconsistencies
repair data inconsistencies that
data inconsistencies that arise
inconsistencies that arise during
that arise during the
arise during the period
during the period when
the period when the
period when the cluster
when the cluster configuration
the cluster configuration was
cluster configuration was still
configuration was still disrupted
our goal is to
goal is to make
is to make the
to make the software
make the software available
the software available to
software available to a
available to a general
to a general user
a general user community
general user community in
efficient optimistic concurrency control
optimistic concurrency control using
acknowledgments the authors are
concurrency control using loosely
the authors are grateful
control using loosely synchronized
authors are grateful to
using loosely synchronized clocks
are grateful to the
grateful to the research
to the research team
the research team at
research team at afrl
team at afrl in
at afrl in rome
for their help in
their help in understanding
help in understanding the
in understanding the challenges
understanding the challenges of
the challenges of using
challenges of using service
of using service oriented
using service oriented architectures
service oriented architectures in
oriented architectures in large
architectures in large scale
in large scale settings
and to the researchers
to the researchers at
the researchers at amazon
for helping us understand
helping us understand the
us understand the architectures
understand the architectures employed
the architectures employed in
architectures employed in very
employed in very large
in very large data
very large data centers
a scalable system for
scalable system for consistently
system for consistently caching
for consistently caching dynamic
consistently caching dynamic web
caching dynamic web data
an exercise in distributed
exercise in distributed computing
communications of the acm
a scalable web cache
scalable web cache consistency
web cache consistency architecture
sigcomm computer communications review
an architecture to support
architecture to support scalable
to support scalable online
support scalable online personalization
scalable online personalization in
online personalization in the
personalization in the web
based cache management for
the international journal on
cache management for dynamic
international journal on very
management for dynamic web
research edition where the
journal on very large
for dynamic web content
on very large data
edition where the academic
very large data bases
where the academic knights
the academic knights meet
academic knights meet the
knights meet the evil
meet the evil empire
the evil empire werner
evil empire werner vogels
empire werner vogels the
werner vogels the rivalry
vogels the rivalry in
the rivalry in the
rivalry in the operating
in the operating system
the operating system market
operating system market place
system market place has
market place has a
place has a severe
has a severe impact
a severe impact on
severe impact on the
impact on the academic
on the academic world
where in the old
in the old days
the old days intellection
old days intellection quality
days intellection quality and
intellection quality and careful
quality and careful deliberation
and careful deliberation would
careful deliberation would prevail
nowadays discussions about operating
discussions about operating systems
about operating systems research
alternative architectures and protocols
operating systems research appear
architectures and protocols for
systems research appear to
and protocols for providing
research appear to be
protocols for providing strong
appear to be more
for providing strong consistency
to be more like
providing strong consistency in
be more like the
strong consistency in dynamic
more like the battlefield
consistency in dynamic web
like the battlefield of
in dynamic web applications
the battlefield of a
battlefield of a holy
of a holy war
world wide web journal
with objectivity as its
objectivity as its main
as its main victim
we have tried to
have tried to side
tried to side step
to side step the
side step the emotional
step the emotional current
and select an operating
select an operating system
an operating system that
operating system that could
system that could bring
that could bring our
could bring our research
bring our research into
our research into the
research into the next
into the next century
based on objective technical
on objective technical and
objective technical and organizational
technical and organizational criteria
this paper describes how
paper describes how this
describes how this evaluation
how this evaluation lead
this evaluation lead to
evaluation lead to the
lead to the insight
to the insight that
the insight that microsoft
insight that microsoft s
that microsoft s windows
microsoft s windows nt
s windows nt is
windows nt is the
nt is the operating
is the operating system
the operating system that
operating system that is
system that is best
that is best prepared
is best prepared for
best prepared for the
prepared for the future
introduction until recently there
until recently there was
recently there was no
there was no doubt
was no doubt in
no doubt in academia
doubt in academia which
in academia which operating
academia which operating system
epidemic algorithms for replicated
which operating system to
algorithms for replicated database
operating system to use
for replicated database maintenance
system to use for
to use for systems
use for systems research
in proceedings of the
proceedings of the sixth
of the sixth annual
the sixth annual acm
sixth annual acm symposium
annual acm symposium on
whether it was a
acm symposium on principles
it was a bsd
symposium on principles of
was a bsd or
on principles of distributed
a bsd or system
principles of distributed computing
bsd or system v
or system v derivative
was the predominant choice
which had its roots
had its roots in
its roots in research
was used since its
used since its inception
since its inception to
its inception to investigate
inception to investigate fundamental
to investigate fundamental system
investigate fundamental system research
and the accumulated knowledge
cache coherence in distributed
the accumulated knowledge in
coherence in distributed systems
accumulated knowledge in academia
knowledge in academia about
in academia about its
academia about its internals
about its internals and
its internals and operations
internals and operations was
and operations was significant
other available operating systems
available operating systems such
operating systems such as
systems such as vms
such as vms and
as vms and mvs
had their roots in
their roots in the
roots in the commercial
in the commercial world
the commercial world and
commercial world and knowledge
world and knowledge about
and knowledge about these
knowledge about these systems
about these systems never
these systems never accumulated
systems never accumulated to
never accumulated to the
accumulated to the critical
to the critical mass
the critical mass were
critical mass were these
mass were these systems
were these systems could
these systems could be
systems could be considered
could be considered for
be considered for widespread
considered for widespread research
for widespread research tasks
although new research operating
new research operating systems
research operating systems have
operating systems have been
systems have been developed
none have found the
have found the following
found the following that
the following that the
following that the established
that the established unix
the established unix s
established unix s received
a global cache coherent
global cache coherent file
cache coherent file system
support for data sharing
for data sharing among
data sharing among mobile
sharing among mobile users
in ieee workshop on
freebsd and others continue
ieee workshop on mobile
and others continue to
workshop on mobile computing
others continue to dominate
on mobile computing systems
continue to dominate the
to dominate the academic
dominate the academic landscape
but slowly but surely
slowly but surely windows
but surely windows nt
surely windows nt is
windows nt is now
nt is now entering
is now entering the
now entering the academic
entering the academic world
the academic world as
academic world as a
world as a viable
alternative platform for research
although academia looked with
academia looked with fascination
looked with fascination at
with fascination at dave
fascination at dave cutler
at dave cutler s
dave cutler s attempt
cutler s attempt to
a distributed memory object
s attempt to build
distributed memory object caching
attempt to build a
memory object caching system
to build a new
build a new operating
a new operating system
new operating system from
operating system from the
system from the ground
from the ground up
all expected that windows
expected that windows nt
that windows nt would
windows nt would go
nt would go the
would go the same
go the same way
the same way as
same way as the
way as the other
as the other commercially
the other commercially designed
other commercially designed operating
commercially designed operating systems
designed operating systems before
operating systems before it
systems before it and
before it and remain
it and remain in
and remain in the
remain in the dark
in the dark corner
the dark corner from
dark corner from a
corner from a research
from a research use
a research use point
research use point of
use point of view
about four years ago
not long after the
distributed data structures for
long after the final
data structures for internet
after the final major
structures for internet service
the final major release
for internet service construction
final major release of
major release of academic
release of academic version
of academic version of
academic version of the
in proceedings of the
version of the unix
of the unix operating
the unix operating system
th conference on symposium
conference on symposium on
on symposium on operating
symposium on operating system
on operating system design
the farewell of the
farewell of the berkeley
of the berkeley systems
the berkeley systems werner
berkeley systems werner vogels
systems werner vogels is
werner vogels is a
vogels is a research
is a research scientist
a research scientist at
research scientist at the
scientist at the department
at the department of
the department of computer
department of computer science
of computer science of
computer science of cornell
science of cornell university
his research targets high
availability in distributed systems
with a particular focus
a particular focus on
particular focus on enterprise
focus on enterprise cluster
on enterprise cluster systems
based scalable network services
president of reliable network
of reliable network solutions
proceedings of the sixteenth
of the sixteenth acm
which specializes in building
the sixteenth acm symposium
specializes in building solutions
sixteenth acm symposium on
in building solutions for
acm symposium on operating
building solutions for very
symposium on operating systems
solutions for very large
on operating systems principles
scale reliable distributed systems
usenix windows nt symposium
his personal homepage is
personal homepage is at
homepage is at http
group and the early
and the early demise
the early demise of
early demise of mach
demise of mach as
of mach as the
mach as the last
as the last of
the last of the
last of the research
of the research operating
the research operating systems
the operating system research
operating system research world
system research world was
research world was at
world was at a
was at a crossroads
intel based personal computers
based personal computers were
personal computers were becoming
computers were becoming ubiquitous
and a myriad of
a myriad of unix
myriad of unix operating
of unix operating systems
unix operating systems was
operating systems was available
systems was available for
was available for this
available for this platform
eventually many moved to
many moved to use
moved to use linux
tier database caching for
database caching for e
a popular architectural clone
popular architectural clone of
architectural clone of the
clone of the traditional
of the traditional unix
in international conference on
international conference on management
at the computer science
conference on management of
the computer science department
on management of data
computer science department at
science department at cornell
department at cornell university
at cornell university we
cornell university we made
university we made the
we made the decision
made the decision to
the decision to conduct
decision to conduct our
to conduct our research
conduct our research on
our research on windows
research on windows nt
by that time we
that time we had
time we had learned
we had learned enough
had learned enough from
learned enough from the
enough from the early
from the early design
the early design of
early design of windows
design of windows nt
of windows nt to
windows nt to realize
nt to realize that
to realize that it
realize that it was
that it was a
it was a major
was a major step
a major step forward
major step forward in
step forward in operating
forward in operating system
in operating system design
the ninja architecture for
ninja architecture for robust
architecture for robust internet
it would provide us
would provide us with
scale systems and services
provide us with a
us with a platform
with a platform on
a platform on which
platform on which we
on which we could
which we could perform
we could perform research
could perform research more
perform research more effectively
research more effectively and
more effectively and it
effectively and it would
and it would allows
it would allows us
would allows us to
allows us to focus
us to focus on
to focus on the
focus on the future
on the future directions
the future directions without
future directions without having
directions without having to
without having to worry
having to worry whether
to worry whether the
worry whether the operating
whether the operating system
the operating system was
operating system was capable
system was capable of
was capable of supporting
capable of supporting innovation
consistent and scalable cache
and scalable cache replication
scalable cache replication for
cache replication for multi
by now our complete
now our complete educational
our complete educational operation
complete educational operation and
educational operation and the
operation and the majority
and the majority of
the majority of our
majority of our research
of our research projects
our research projects have
research projects have switched
projects have switched to
have switched to using
switched to using windows
to using windows nt
as it now officially
it now officially has
now officially has been
officially has been christened
the ride has been
ride has been rocky
has been rocky and
been rocky and fascinating
spatial gossip and resource
gossip and resource location
and resource location protocols
in this article i
in proceedings of the
proceedings of the thirty
this article i want
article i want to
i want to share
want to share some
third annual acm symposium
annual acm symposium on
to share some of
acm symposium on theory
symposium on theory of
share some of the
on theory of computing
some of the reasoning
of the reasoning behind
the reasoning behind our
reasoning behind our choice
behind our choice for
our choice for windows
choice for windows nt
for windows nt and
windows nt and to
nt and to share
and to share some
consistent and scalable caching
to share some our
and scalable caching in
share some our experiences
scalable caching in multitier
some our experiences with
caching in multitier architectures
our experiences with windows
experiences with windows nt
with windows nt as
windows nt as a
nt as a research
as a research platform
the international journal on
international journal on very
journal on very large
on very large data
very large data bases
os research as religion
research as religion the
as religion the biggest
religion the biggest hurdle
the biggest hurdle in
biggest hurdle in starting
hurdle in starting research
in starting research on
starting research on windows
research on windows nt
on windows nt was
windows nt was not
nt was not technical
it was to overcome
was to overcome the
to overcome the skepticism
overcome the skepticism of
the skepticism of our
skepticism of our colleagues
of our colleagues who
our colleagues who were
colleagues who were convinced
who were convinced that
were convinced that it
convinced that it would
that it would not
it would not be
would not be possible
not be possible to
be possible to use
possible to use windows
to use windows nt
use windows nt as
windows nt as a
nt as a good
as a good platform
a good platform for
good platform for research
the predictions were fascinating
we would turn into
would turn into a
turn into a bug
a technique for increasing
technique for increasing concurrency
for increasing concurrency in
increasing concurrency in a
concurrency in a replicated
in a replicated system
microsoft would sue the
would sue the department
sue the department for
acm transactions on database
the department for every
transactions on database systems
department for every technical
for every technical publication
microsoft would hide the
would hide the pieces
hide the pieces of
the pieces of buggy
pieces of buggy code
of buggy code from
buggy code from us
code from us or
from us or bill
us or bill gates
or bill gates would
bill gates would personally
gates would personally tell
would personally tell us
personally tell us where
tell us where and
us where and how
where and how we
and how we should
how we should do
we should do our
should do our research
the operating systems research
operating systems research community
systems research community has
research community has not
community has not remained
has not remained untouched
not remained untouched by
remained untouched by the
untouched by the market
by the market place
the market place rivalry
market place rivalry between
improving application throughput with
place rivalry between microsoft
application throughput with enterprise
rivalry between microsoft and
throughput with enterprise javabeans
between microsoft and the
with enterprise javabeans caching
microsoft and the group
and the group lead
the group lead by
group lead by sun
lead by sun microsystems
in international conference on
international conference on distributed
conference on distributed computing
on distributed computing systems
it is even more
is even more unfortunate
even more unfortunate that
more unfortunate that the
unfortunate that the positions
that the positions taken
the positions taken are
positions taken are not
taken are not based
are not based on
not based on intellectual
based on intellectual deliberation
on intellectual deliberation but
intellectual deliberation but purely
deliberation but purely on
but purely on emotional
purely on emotional grounds
many see microsoft operating
see microsoft operating systems
adaptive distributed data management
microsoft operating systems as
distributed data management with
operating systems as the
data management with weak
systems as the evil
management with weak consistent
as the evil empire
with weak consistent replicated
weak consistent replicated data
out to squash every
to squash every attempt
in proceedings of the
squash every attempt at
every attempt at innovation
and working with them
working with them is
with them is seen
them is seen as
is seen as collaboration
seen as collaboration with
as collaboration with the
collaboration with the enemy
with the enemy of
acm symposium on applied
the enemy of free
symposium on applied computing
enemy of free academic
of free academic speech
the pros and cons
pros and cons are
and cons are often
cons are often discussed
are often discussed with
often discussed with a
discussed with a righteous
with a righteous zeal
a righteous zeal that
righteous zeal that is
zeal that is frightening
our own experiences with
own experiences with microsoft
experiences with microsoft can
currency serializability for middle
with microsoft can only
microsoft can only be
can only be described
only be described as
be described as extremely
tier caching and replication
described as extremely positive
in international conference on
never before have we
international conference on management
before have we had
conference on management of
have we had such
on management of data
we had such a
had such a positive
such a positive relation
a positive relation with
positive relation with a
relation with a vendor
without any pressure from
any pressure from their
pressure from their side
we can only conclude
can only conclude that
only conclude that the
conclude that the reasons
that the reasons for
the reasons for the
reasons for the controversy
for the controversy must
the controversy must be
controversy must be found
must be found in
be found in a
found in a sort
in a sort of
a sort of traditional
sort of traditional emotional
of traditional emotional bonding
traditional emotional bonding of
emotional bonding of academia
bonding of academia with
of academia with the
academia with the underdog
with the underdog and
aware adaptable web services
the underdog and that
underdog and that no
and that no real
that no real experiences
no real experiences drive
in proceedings of the
real experiences drive the
experiences drive the discussion
a ppendix we now
gaining knowledge the foremost
ppendix we now prove
th international world wide
we now prove theorem
knowledge the foremost reasons
international world wide web
world wide web conference
the foremost reasons why
wide web conference on
foremost reasons why unix
web conference on alternate
conference on alternate track
reasons why unix was
on alternate track papers
alternate track papers and
why unix was such
track papers and posters
unix was such a
was such a powerhouse
such a powerhouse in
a powerhouse in operating
powerhouse in operating system
in operating system research
operating system research was
cache with unbounded cache
system research was the
with unbounded cache size
research was the great
unbounded cache size and
was the great amount
cache size and unbounded
the great amount of
size and unbounded dependency
great amount of knowledge
and unbounded dependency lists
amount of knowledge accumulated
unbounded dependency lists implements
of knowledge accumulated over
dependency lists implements cache
knowledge accumulated over the
accumulated over the years
over the years about
the years about the
years about the internal
about the internal operation
the internal operation of
internal operation of the
since we assume that
operation of the operating
we assume that the
of the operating system
assume that the transactional
that the transactional db
the transactional db is
transactional db is serializable
many of us had
of us had become
the operations in an
us had become gurus
operations in an execution
had become gurus about
in an execution of
become gurus about some
an execution of update
gurus about some part
execution of update transactions
about some part of
of update transactions update
some part of the
update transactions update can
part of the os
transactions update can be
of the os kernel
update can be serialized
the os kernel and
can be serialized as
os kernel and could
be serialized as some
kernel and could recite
serialized as some serial
and could recite the
as some serial execution
could recite the fields
recite the fields of
the fields of an
fields of an i
the next claim trivially
next claim trivially follows
claim trivially follows from
node structure at late
trivially follows from the
structure at late night
follows from the definition
at late night meetings
from the definition of
late night meetings or
the definition of the
night meetings or discuss
definition of the database
meetings or discuss which
of the database dependency
or discuss which data
the database dependency list
discuss which data structures
database dependency list specification
which data structures to
data structures to modify
structures to modify to
to modify to add
modify to add a
to add a new
add a new protocol
a new protocol at
new protocol at runtime
protocol at runtime over
at runtime over an
runtime over an early
over an early morning
if is a serialization
an early morning cappuccino
is a serialization of
a serialization of the
serialization of the update
of the update transactions
the update transactions of
many of us were
update transactions of an
transactions of an execution
of us were and
of an execution update
us were and still
were and still are
and still are afraid
still are afraid to
are afraid to leave
at every step in
afraid to leave this
to leave this bastion
leave this bastion of
the version dependencies of
this bastion of safety
version dependencies of every
bastion of safety behind
dependencies of every object
of safety behind and
of every object match
safety behind and trade
every object match those
behind and trade it
object match those stored
and trade it in
match those stored in
trade it in for
those stored in its
it in for working
stored in its dependency
in for working on
in its dependency list
for working on an
working on an operating
on an operating system
an operating system that
operating system that at
system that at first
that at first sight
at first sight had
first sight had nothing
sight had nothing in
had nothing in common
we first describe a
nothing in common with
first describe a routine
in common with our
describe a routine for
common with our beloved
a routine for placing
with our beloved unix
routine for placing a
for placing a read
and our annotated version
only transaction from a
our annotated version of
transaction from a cache
annotated version of the
from a cache server
version of the unix
a cache server in
of the unix version
cache server in a
server in a serialization
in a serialization of
a serialization of a
serialization of a subset
of a subset of
to form a serialization
form a serialization of
a serialization of both
serialization of both the
of both the update
both the update transaction
the update transaction and
update transaction and the
profiles for the situated
transaction and the read
for the situated web
wouldn t be of
t be of much
in proceedings of the
be of much help
proceedings of the eleventh
of the eleventh international
of much help any
the eleventh international conference
much help any more
eleventh international conference on
international conference on world
help any more either
conference on world wide
on world wide web
any more either it
more either it took
either it took more
it took more then
took more then a
more then a year
then a year of
a year of immersion
year of immersion in
of immersion in the
immersion in the technology
in the technology to
the technology to get
technology to get a
to get a level
get a level where
a level where i
level where i felt
where i felt confident
i felt confident again
felt confident again to
confident again to direct
again to direct others
to direct others in
direct others in our
others in our research
in our research group
together with the overall
with the overall organizational
the overall organizational issues
overall organizational issues i
organizational issues i think
issues i think we
i think we lost
think we lost one
we lost one and
lost one and a
one and a half
and a half year
a half year worth
half year worth of
year worth of research
worth of research time
performing this permutation is
of research time to
this permutation is one
research time to make
permutation is one step
time to make the
is one step of
to make the switch
one step of the
make the switch in
step of the routine
the switch in the
switch in the most
in the most fundamental
the most fundamental way
we repeat this step
repeat this step forming
this step forming a
step forming a series
others are making the
forming a series of
are making the switch
a series of permutations
making the switch more
the switch more gradually
switch more gradually and
van renesse and f
more gradually and are
each permutation is a
gradually and are experiencing
permutation is a serialization
and are experiencing a
is a serialization of
are experiencing a more
a serialization of update
experiencing a more smooth
a more smooth transition
and each permutes a
each permutes a range
chain replication for supporting
permutes a range of
all operation systems are
a range of the
replication for supporting high
operation systems are created
range of the transactions
for supporting high throughput
systems are created equal
of the transactions with
supporting high throughput and
are created equal our
the transactions with respect
high throughput and availability
transactions with respect to
created equal our experiences
with respect to the
respect to the previous
equal our experiences with
to the previous step
our experiences with switching
in sixth symposium on
experiences with switching to
sixth symposium on operating
with switching to windows
symposium on operating systems
switching to windows nt
on operating systems design
in each step the
operating systems design and
to windows nt have
systems design and implementation
each step the right
windows nt have made
step the right end
nt have made us
the right end of
have made us somewhat
right end of the
made us somewhat more
end of the range
us somewhat more philosophical
of the range is
somewhat more philosophical about
the range is earlier
more philosophical about the
range is earlier than
philosophical about the nature
is earlier than in
about the nature of
earlier than in the
the nature of operation
than in the previous
nature of operation systems
in the previous step
the most fundamental observation
as one or more
most fundamental observation is
one or more of
fundamental observation is that
or more of the
more of the objects
of the objects is
the objects is closer
objects is closer to
when stripped to their
is closer to the
stripped to their core
closer to the value
to the value read
the value read by
value read by t
all operating systems are
operating systems are equal
eventually we therefore reach
we therefore reach a
the functionality of the
therefore reach a permutation
functionality of the windows
reach a permutation where
of the windows nt
a permutation where at
the windows nt kernel
permutation where at the
windows nt kernel is
where at the chosen
nt kernel is just
at the chosen time
kernel is just as
the chosen time all
is just as all
chosen time all read
just as all other
time all read objects
as all other kernels
all read objects are
read objects are at
objects are at their
are at their correct
at their correct versions
it abstracts the hardware
abstracts the hardware in
the hardware in the
hardware in the usual
in the usual sense
we place t there
place t there to
t there to obtain
there to obtain the
to obtain the desired
obtain the desired serialization
the desired serialization of
desired serialization of the
process and threads hide
serialization of the update
and threads hide the
of the update transactions
threads hide the cpu
the update transactions and
hide the cpu complexity
update transactions and t
file systems and files
permutation routine let be
systems and files hide
routine let be an
and files hide the
let be an execution
files hide the storage
be an execution of
hide the storage devices
an execution of the
execution of the t
protocols hide the network
enabling scalable online personalization
and denote by update
shared memory and messages
scalable online personalization on
denote by update the
memory and messages are
online personalization on the
and messages are used
personalization on the web
messages are used to
by update the projection
are used to allow
update the projection of
used to allow sharing
the projection of on
to allow sharing of
projection of on the
in proceedings of the
of on the set
allow sharing of resources
on the set of
the set of database
set of database update
of database update transactions
nd acm conference on
acm conference on electronic
conference on electronic commerce
what we often call
we often call operating
transaction t reads objects
often call operating systems
t reads objects o
call operating systems has
operating systems has nothing
systems has nothing to
has nothing to do
nothing to do with
to do with the
do with the real
with the real core
the real core of
real core of the
core of the system
unix for most of
for most of us
most of us is
of us is a
us is a collection
is a collection of
a collection of shell
collection of shell commands
of shell commands and
shell commands and development
commands and development libraries
on with versions v
david korn s uwin
and softway s interix
take any serialization of
both show that you
any serialization of update
show that you can
that you can give
you can give users
can give users and
give users and developers
one exists according to
users and developers a
exists according to claim
and consider the first
consider the first time
the first time when
first time when all
time when all the
when all the objects
unix experience including x
all the objects the
the objects the transaction
objects the transaction reads
the transaction reads are
transaction reads are at
reads are at a
are at a version
at a version at
an architecture for well
a version at least
version at least as
at least as large
least as large as
while running on an
as large as the
running on an windows
large as the versions
on an windows nt
as the versions that
an windows nt kernel
the versions that t
versions that t reads
in symposium on operating
symposium on operating systems
windows nt for most
on operating systems principles
nt for most of
at this time at
for most of us
this time at least
most of us is
time at least one
of us is the
at least one object
us is the windows
least one object read
is the windows explorer
one object read by
the windows explorer and
object read by t
windows explorer and point
the last written according
last written according to
has the correct version
and according to microsoft
according to microsoft it
to microsoft it includes
but others might not
microsoft it includes a
it includes a web
includes a web browser
assume without loss of
without loss of generality
although i have not
loss of generality that
i have not seen
of generality that the
have not seen a
generality that the last
not seen a complete
that the last version
seen a complete re
the last version written
last version written is
version written is vn
written is vn of
is vn of object
implementation of the explorer
vn of object on
of the explorer for
of object on at
the explorer for unix
object on at step
on at step t
at step t of
denote by t the
by t the latest
t the latest time
the latest time at
latest time at which
time at which a
compatible libraries from mainsoft
at which a wrong
which a wrong version
not the one read
the one read by
one read by t
used in the port
in the port of
the port of internet
port of internet explorer
of internet explorer show
internet explorer show that
and assume wlog it
explorer show that you
assume wlog it is
show that you do
wlog it is version
that you do not
it is version vn
you do not need
the costs and limits
do not need a
costs and limits of
not need a windows
and limits of availability
need a windows nt
limits of availability for
a windows nt kernel
of availability for replicated
windows nt kernel to
availability for replicated services
k of object on
nt kernel to get
kernel to get to
to get to the
get to the same
in proceedings of the
to the same user
proceedings of the eighteenth
the same user experience
of the eighteenth acm
rather than the desired
the eighteenth acm symposium
than the desired version
eighteenth acm symposium on
the desired version vn
acm symposium on operating
symposium on operating systems
many see the rich
on operating systems principles
see the rich win
programming interface as the
interface as the native
as the native programming
the native programming model
we now describe a
native programming model for
now describe a single
programming model for windows
describe a single step
model for windows nt
a single step of
single step of the
step of the routine
and although most windows
although most windows applications
consider the transactions between
most windows applications are
the transactions between t
windows applications are designed
transactions between t and
applications are designed using
between t and t
are designed using this
designed using this interface
it is not the
is not the windows
not the windows nt
the windows nt kernel
windows nt kernel interface
divide these transactions into
these transactions into three
transactions into three sets
almost no applications are
no applications are built
applications are built using
are built using the
built using the kernel
using the kernel interface
transactions dependent on the
dependent on the transaction
on the transaction at
and you would have
the transaction at t
you would have a
would have a hard
have a hard time
a hard time finding
hard time finding the
time finding the complete
finding the complete documentation
the complete documentation for
complete documentation for all
documentation for all the
for all the system
all the system calls
transactions on which t
on which t is
describing windows nt as
which t is dependent
windows nt as a
nt as a micro
design and evaluation of
and evaluation of a
as the kernel is
evaluation of a conitbased
the kernel is certainly
of a conitbased continuous
kernel is certainly not
transactions that do not
is certainly not small
that do not belong
a conitbased continuous consistency
do not belong to
conitbased continuous consistency model
not belong to either
continuous consistency model for
belong to either group
consistency model for replicated
but it is does
model for replicated services
it is does describe
is does describe the
the following lemma states
following lemma states that
acm transactions on computer
lemma states that there
transactions on computer systems
does describe the abstraction
states that there is
that there is no
describe the abstraction correctly
there is no dependency
is no dependency among
the abstraction correctly in
no dependency among objects
abstraction correctly in which
dependency among objects in
correctly in which the
among objects in sets
in which the kernel
which the kernel provides
the kernel provides base
kernel provides base services
provides base services and
base services and the
services and the specific
and the specific application
the specific application context
specific application context is
and hence there is
application context is provided
hence there is no
context is provided through
there is no intersection
is provided through subsystem
is no intersection between
provided through subsystem servers
no intersection between the
through subsystem servers or
intersection between the sets
subsystem servers or personalities
is one of the
one of the personalities
of the personalities running
the personalities running on
personalities running on top
running on top of
on top of windows
top of windows nt
if they were dependent
then version vn of
version vn of object
vn of object on
of object on depends
and posix are others
object on depends on
posix are others delivered
on depends on version
are others delivered by
depends on version vn
others delivered by microsoft
one can run windows
can run windows nt
run windows nt without
k of object on
windows nt without these
nt without these standard
without these standard personalities
these standard personalities and
standard personalities and build
personalities and build your
and build your own
and this dependency is
this dependency is reflected
dependency is reflected in
is reflected in their
what is an operating
reflected in their t
is an operating system
this question seems to
question seems to be
seems to be on
because they are unbounded
to be on the
be on the mind
on the mind of
the mind of many
mind of many people
of many people these
many people these days
transaction t has read
t has read version
infused by the microsoft
has read version vn
by the microsoft trial
academics in general have
in general have taken
general have taken a
have taken a very
taken a very narrow
a very narrow view
very narrow view of
narrow view of what
which is older than
view of what an
is older than vn
of what an operating
what an operating system
an operating system is
david faber at microsoft
faber at microsoft trial
at microsoft trial defined
microsoft trial defined an
the read of the
trial defined an operating
read of the stale
of the stale version
defined an operating system
the stale version vn
an operating system as
operating system as the
system as the software
as the software that
the software that controls
software that controls the
that controls the execution
would have been detected
controls the execution of
have been detected by
the execution of programs
been detected by t
execution of programs on
of programs on computer
programs on computer systems
on computer systems and
computer systems and may
cache and the transaction
systems and may provide
and the transaction would
and may provide low
the transaction would have
transaction would have been
would have been aborted
level services such as
services such as resource
therefore the assumption is
such as resource allocation
the assumption is wrong
and the sets are
the sets are indeed
sets are indeed independent
output control in a
control in a form
in a form which
a form which is
form which is sufficiently
which is sufficiently simple
is sufficiently simple and
sufficiently simple and general
perhaps an empty set
simple and general so
and general so that
general so that these
so that these services
is unrelated to sets
that these services are
these services are broadly
services are broadly useful
are broadly useful to
broadly useful to software
useful to software developers
we therefore switch sets
in research community this
research community this strict
community this strict distinction
this strict distinction serves
strict distinction serves to
maintaining a serialization of
distinction serves to distinguish
a serialization of update
serves to distinguish the
to distinguish the real
distinguish the real men
the real men from
real men from the
men from the boys
consider the following serialization
researchers and hackers that
and hackers that work
hackers that work in
that work in the
work in the area
in the area defined
xi denotes a transaction
the area defined by
denotes a transaction x
area defined by this
a transaction x in
defined by this narrow
transaction x in set
by this narrow definition
x in set i
this narrow definition of
narrow definition of operating
definition of operating systems
consider themselves part of
themselves part of the
part of the select
of the select circle
the select circle of
select circle of people
cache consistency we proceed
circle of people working
consistency we proceed to
of people working on
we proceed to prove
people working on the
proceed to prove theorem
working on the core
on the core of
the core of the
core of the systems
of the systems area
the systems area of
systems area of computer
area of computer science
let be an execution
be an execution of
once you are in
an execution of the
execution of the t
you are in this
are in this circle
in this circle you
this circle you will
circle you will become
and denote by update
you will become part
denote by update the
by update the projection
will become part of
update the projection of
become part of the
the projection of on
projection of on the
part of the secret
of on the set
on the set of
of the secret society
the set of database
set of database update
the secret society that
of database update transactions
secret society that practices
society that practices the
that practices the black
practices the black art
the black art of
black art of os
art of os research
of os research and
os research and will
research and will start
and will start to
will start to regard
start to regard any
to regard any other
regard any other activity
any other activity of
other activity of systems
activity of systems development
of systems development as
systems development as irrelevant
development as irrelevant to
as irrelevant to the
irrelevant to the future
to the future of
the future of computer
future of computer science
tm a set of
a set of readonly
set of readonly transactions
of readonly transactions performed
readonly transactions performed through
for a long time
transactions performed through a
a long time the
performed through a single
long time the line
through a single t
time the line was
the line was drawn
line was drawn at
was drawn at the
drawn at the kernel
if the read sets
the read sets of
read sets of two
sets of two transactions
of two transactions include
two transactions include the
and one could only
transactions include the same
include the same object
one could only consider
the same object o
could only consider himself
only consider himself a
consider himself a true
we say the one
himself a true os
say the one that
a true os researcher
the one that read
true os researcher after
one that read a
os researcher after having
that read a larger
researcher after having developed
read a larger version
after having developed at
a larger version of
having developed at least
larger version of o
developed at least two
version of o depends
at least two device
of o depends on
least two device drivers
o depends on the
two device drivers and
depends on the other
device drivers and hacked
drivers and hacked on
and hacked on the
hacked on the terminal
on the terminal driver
the terminal driver of
all transactions access the
terminal driver of the
transactions access the same
driver of the bsd
access the same cache
and the cache is
the cache is unbounded
values are only replaced
are only replaced by
only replaced by newer
in modern operating systems
replaced by newer versions
modern operating systems such
operating systems such as
systems such as windows
such as windows nt
so it is easy
it is easy to
is easy to see
the notion of where
easy to see that
notion of where exactly
to see that there
of where exactly operating
see that there are
where exactly operating systems
that there are no
exactly operating systems services
there are no cycles
operating systems services are
are no cycles such
systems services are located
no cycles such that
services are located is
cycles such that two
are located is not
such that two transactions
located is not that
that two transactions depend
is not that simple
two transactions depend on
not that simple any
transactions depend on one
that simple any more
depend on one another
fundamental services are split
the dependency graph therefore
services are split between
dependency graph therefore describes
are split between kernel
graph therefore describes a
split between kernel and
therefore describes a partial
between kernel and user
describes a partial order
kernel and user space
a partial order of
and user space in
partial order of the
user space in attempts
order of the read
space in attempts to
in attempts to optimise
attempts to optimise their
to optimise their efficiency
optimise their efficiency and
their efficiency and avoid
efficiency and avoid uncontrolled
and avoid uncontrolled growth
and we choose an
avoid uncontrolled growth of
we choose an arbitrary
uncontrolled growth of kernel
choose an arbitrary total
growth of kernel services
an arbitrary total ordering
arbitrary total ordering that
total ordering that respects
ordering that respects this
that respects this partial
respects this partial order
the pervasiveness of distributed
pervasiveness of distributed services
of distributed services in
distributed services in modern
assume wlog the order
services in modern systems
wlog the order is
in modern systems can
the order is t
modern systems can be
systems can be considered
can be considered a
be considered a threat
considered a threat to
a threat to the
threat to the traditional
to the traditional notion
the traditional notion of
traditional notion of operating
notion of operating systems
many support services are
support services are required
services are required to
are required to make
required to make distributed
to make distributed systems
make distributed systems work
distributed systems work efficiently
systems work efficiently and
work efficiently and effectively
efficiently and effectively and
and effectively and these
effectively and these services
we take an initial
such as security and
take an initial arbitrary
as security and directory
an initial arbitrary serialization
security and directory services
and directory services or
directory services or distributed
services or distributed object
or distributed object support
of and permute it
distributed object support and
and permute it according
object support and cluster
permute it according to
support and cluster management
it according to the
according to the route
to the route above
the route above to
route above to place
above to place t
are not part of
not part of a
part of a traditional
of a traditional view
a traditional view of
traditional view of operating
view of operating systems
but they are essential
they are essential to
are essential to the
essential to the operation
to the operation of
the result is a
the operation of modern
result is a permutation
operation of modern operating
of modern operating systems
this results in that
results in that an
in that an operating
that an operating system
an operating system no
operating system no longer
system no longer is
no longer is a
longer is a simple
we take all transactions
is a simple division
take all transactions that
a simple division between
all transactions that precede
simple division between kernel
transactions that precede t
division between kernel and
between kernel and user
live network streaming with
kernel and user space
network streaming with utilities
streaming with utilities and
with utilities and cost
utilities and cost ymir
and cost ymir vigfusson
but consist of a
consist of a myriad
of a myriad of
a myriad of services
does not depend on
not depend on them
of which some are
which some are kernilized
and place them after
place them after t
some are local and
are local and others
local and others are
and others are remote
we call this permutation
operating systems that address
systems that address the
that address the needs
address the needs of
the needs of current
next we place t
needs of current and
of current and future
current and future clients
and future clients and
future clients and informatik
clients and informatik informatique
can be placed immediately
be placed immediately after
freedman school of computer
placed immediately after t
school of computer science
we place it there
place it there to
it there to form
iceland of computer science
operating systems servers no
systems servers no longer
servers no longer span
is independent of t
no longer span a
longer span a single
span a single computer
a single computer and
then all its preceding
single computer and they
all its preceding transactions
computer and they abstract
usa school of electronics
and they abstract services
school of electronics engineering
they abstract services away
of electronics engineering and
according to the dependency
electronics engineering and computer
to the dependency graph
engineering and computer science
abstract services away from
services away from physical
away from physical nodes
from physical nodes allowing
are unrelated to t
physical nodes allowing user
nodes allowing user to
allowing user to be
user to be part
to be part of
and are therefore located
be part of a
are therefore located after
part of a larger
therefore located after it
potential global operating environment
the permutations required are
permutations required are therefore
required are therefore after
are therefore after t
will the real dinosaur
the real dinosaur please
real dinosaur please come
dinosaur please come forward
until the spring of
all relevant update transactions
relevant update transactions are
update transactions are located
we were deeply committed
transactions are located after
were deeply committed to
are located after t
deeply committed to sunos
and other bsd derivatives
and therefore the permutations
therefore the permutations required
at that moment its
the permutations required are
that moment its vendor
permutations required are all
moment its vendor was
required are all after
its vendor was discontinuing
are all after t
vendor was discontinuing the
was discontinuing the operating
discontinuing the operating system
department abstract the growth
abstract the growth in
and had designated solaris
the growth in internet
since in all cases
in all cases the
growth in internet traffic
all cases the permutations
which had its root
cases the permutations are
had its root in
in internet traffic associated
its root in at
the permutations are after
internet traffic associated with
permutations are after t
traffic associated with video
associated with video streaming
t s system v
s system v as
with video streaming and
system v as the
video streaming and sharing
v as the successor
streaming and sharing of
and sharing of videos
sharing of videos is
of videos is so
they do not affect
videos is so rapid
do not affect the
this event forced us
not affect the correctness
is so rapid that
affect the correctness of
event forced us to
the correctness of t
so rapid that it
forced us to take
rapid that it may
us to take a
that it may soon
to take a step
it may soon dwarf
take a step back
may soon dwarf all
a step back and
soon dwarf all other
we take the resulting
dwarf all other forms
step back and evaluate
all other forms of
take the resulting permutation
back and evaluate our
other forms of internet
and evaluate our research
forms of internet content
the resulting permutation that
evaluate our research directions
resulting permutation that we
our research directions and
permutation that we call
research directions and our
directions and our expectations
one reason for this
and our expectations with
reason for this is
our expectations with respect
for this is that
expectations with respect to
this is that only
with respect to the
is that only some
respect to the operating
and move all transactions
to the operating systems
that only some forms
move all transactions that
only some forms of
the operating systems to
some forms of content
operating systems to use
forms of content can
all transactions that neither
of content can be
transactions that neither t
content can be cached
if one issue in
one issue in our
issue in our discussions
in our discussions was
our discussions was dominant
depend on to right
on to right after
to right after t
it was the fact
data generated in real
was the fact that
generated in real time
the fact that most
in real time such
fact that most of
real time such as
that most of the
the resulting permutation is
time such as by
most of the operating
such as by live
of the operating systems
as by live video
the operating systems we
by live video broadcasts
operating systems we were
systems we were looking
we were looking at
were looking at were
we repeat this process
looking at were actually
repeat this process until
at were actually very
this process until we
were actually very old
process until we place
actually very old fashioned
until we place all
we place all read
iptv or new episodes
or new episodes of
in structure and in
new episodes of popular
structure and in implementation
episodes of popular tv
of popular tv shows
this is a serialization
is a serialization of
most of these operating
a serialization of the
of these operating systems
serialization of the update
these operating systems had
of the update transactions
operating systems had their
the update transactions in
systems had their conception
update transactions in and
had their conception in
transactions in and all
their conception in the
in and all read
immersive virtual reality applications
virtual reality applications and
reality applications and games
applications and games typically
and games typically can
only transactions that accessed
games typically can t
transactions that accessed the
typically can t be
that accessed the same
can t be cached
accessed the same cache
t be cached at
be cached at all
we have therefore shown
have therefore shown that
and in today s
therefore shown that in
in today s systems
s and did not
shown that in any
and did not change
that in any execution
did not change much
in any execution of
not change much in
any execution of t
change much in structure
each client may pull
much in structure since
client may pull such
in structure since then
may pull such information
pull such information on
cache the update transactions
such information on its
the update transactions can
information on its own
update transactions can be
on its own point
linux could be seen
transactions can be serialized
could be seen as
can be serialized with
be seen as an
be serialized with readonly
seen as an exception
serialized with readonly transactions
as an exception since
with readonly transactions that
an exception since it
readonly transactions that accessed
exception since it was
transactions that accessed a
since it was developed
that accessed a single
it was developed in
accessed a single cache
was developed in the
developed in the second
in the second half
the second half of
second half of the
stream directly from the
which means that t
directly from the data
from the data center
cache implements cache serializability
even if large numbers
if large numbers of
large numbers of clients
numbers of clients share
of clients share interest
clients share interest in
share interest in at
interest in at least
in at least some
at least some aspects
least some aspects of
some aspects of the
aspects of the data
but its structure mirrored
its structure mirrored that
structure mirrored that of
mirrored that of the
we propose a new
that of the traditional
propose a new system
of the traditional unix
a new system called
the traditional unix systems
new system called g
system called g radient
called g radient aimed
g radient aimed at
radient aimed at reducing
and as such it
aimed at reducing the
as such it could
at reducing the load
such it could be
reducing the load on
it could be considered
the load on providers
could be considered one
load on providers of
be considered one of
on providers of such
considered one of them
providers of such and
of such and enabling
such and enabling scalable
the significant advances made
significant advances made in
bandwidthsensitive streaming service for
advances made in academic
streaming service for heterogeneous
made in academic computer
service for heterogeneous consumers
in academic computer science
the core of the
in os research and
core of the system
os research and in
of the system is
research and in system
the system is an
and in system software
system is an overlay
in system software engineering
is an overlay networking
an overlay networking architecture
overlay networking architecture intended
networking architecture intended to
architecture intended to run
have had only minimal
intended to run directly
had only minimal impact
to run directly on
only minimal impact on
run directly on a
minimal impact on the
directly on a content
impact on the design
on a content hosting
on the design and
a content hosting platform
the design and implementation
design and implementation of
and implementation of commercial
implementation of commercial operating
of commercial operating systems
and which optimizes aggregate
which optimizes aggregate bandwidth
optimizes aggregate bandwidth use
aggregate bandwidth use by
bandwidth use by transforming
the design of all
use by transforming in
design of all unix
of all unix systems
all unix systems violates
unix systems violates almost
flight data to match
systems violates almost all
data to match the
violates almost all of
to match the ideal
almost all of the
match the ideal stream
all of the software
the ideal stream quality
of the software engineering
ideal stream quality expressed
the software engineering principles
stream quality expressed as
software engineering principles presented
quality expressed as an
engineering principles presented to
expressed as an economic
principles presented to first
as an economic utility
presented to first year
an economic utility of
to first year s
economic utility of the
first year s computer
utility of the consuming
year s computer science
of the consuming client
s computer science students
the design is monolithic
design is monolithic with
is monolithic with almost
monolithic with almost no
with almost no modular
almost no modular structure
introduction recent years have
recent years have seen
years have seen skyrocketing
have seen skyrocketing demand
and the internal kernel
seen skyrocketing demand for
the internal kernel interfaces
skyrocketing demand for internet
internal kernel interfaces are
demand for internet bandwidth
kernel interfaces are not
interfaces are not strictly
are not strictly enforced
not strictly enforced which
increasingly dominated by real
strictly enforced which introduces
enforced which introduces dependencies
which introduces dependencies on
introduces dependencies on the
time streaming of short
dependencies on the actual
on the actual implementation
the actual implementation of
actual implementation of data
implementation of data structures
making it impossible to
it impossible to upgrade
impossible to upgrade or
but in many forms
to upgrade or replace
upgrade or replace modules
or replace modules without
replace modules without also
modules without also redesigning
without also redesigning several
also redesigning several other
redesigning several other modules
for example to replace
example to replace the
to replace the scheduler
if trends continue then
replace the scheduler in
trends continue then internet
the scheduler in any
continue then internet video
scheduler in any of
then internet video alone
in any of the
internet video alone will
any of the bsd
video alone will generate
of the bsd s
alone will generate almost
the bsd s one
bsd s one needs
s one needs to
one needs to spend
needs to spend two
to spend two weeks
spend two weeks searching
exabytes per month by
two weeks searching for
per month by the
weeks searching for all
month by the end
searching for all dependencies
by the end of
for all dependencies and
all dependencies and fixing
dependencies and fixing other
and fixing other sources
at the top of
the top of our
top of our long
of our long wish
our long wish list
long wish list for
wish list for an
list for an ideal
for an ideal research
an ideal research operating
ideal research operating system
were three important general
three important general points
percent of all internet
of all internet traffic
the design and implementation
design and implementation of
and implementation of the
implementation of the operating
of the operating system
faced with a competitive
the operating system should
with a competitive landscape
operating system should comply
system should comply with
should comply with modern
comply with modern software
with modern software engineering
isps and content providers
modern software engineering principles
and content providers are
content providers are exploring
providers are exploring technologies
are exploring technologies to
allowing researchers to introduce
exploring technologies to help
researchers to introduce new
technologies to help satisfy
to introduce new components
to help satisfy the
help satisfy the growing
satisfy the growing demand
the growing demand alongside
growing demand alongside the
and replace core components
demand alongside the purchase
replace core components without
alongside the purchase of
core components without redesigning
the purchase of expensive
components without redesigning the
purchase of expensive infrastructure
without redesigning the complete
redesigning the complete system
reducing the bandwidth consumption
the bandwidth consumption of
bandwidth consumption of simultaneous
consumption of simultaneous replicated
of simultaneous replicated content
simultaneous replicated content is
replicated content is a
the overall structure of
content is a challenge
overall structure of the
is a challenge which
structure of the operating
a challenge which usually
of the operating system
challenge which usually leverages
which usually leverages two
usually leverages two main
leverages two main tools
user and kernel space
and kernel space components
caching of content and
of content and multicasting
should be designed towards
be designed towards the
designed towards the future
some forms of video
forms of video content
such as downloads of
as downloads of unencrypted
downloads of unencrypted movies
of unencrypted movies or
unencrypted movies or films
movies or films where
or films where many
films where many users
should be pervasive throughout
where many users will
be pervasive throughout the
many users will share
pervasive throughout the whole
users will share the
throughout the whole system
will share the same
share the same encryption
the same encryption key
the operating system vendor
operating system vendor should
system vendor should be
a wide variety of
vendor should be open
wide variety of caching
should be open to
variety of caching options
be open to innovation
of caching options exist
our experiences in the
experiences in the past
in the past had
the past had been
past had been that
had been that vendors
been that vendors always
that vendors always ignored
vendors always ignored important
always ignored important research
ignored important research results
important research results and
research results and only
results and only followed
and only followed very
only followed very narrow
of which is the
followed very narrow paths
which is the akamai
very narrow paths of
is the akamai content
narrow paths of incremental
the akamai content distribution
paths of incremental improvements
akamai content distribution network
windows nt was the
nt was the only
was the only operating
the only operating system
is arguably the most
only operating system that
arguably the most famous
operating system that came
system that came close
that came close to
came close to matching
close to matching most
to matching most of
matching most of our
most of our requirements
with a handful of
a handful of operating
handful of operating systems
of operating systems such
operating systems such as
systems such as qnx
such as qnx and
as qnx and utah
qnx and utah s
multicast techniques can reduce
and utah s os
techniques can reduce the
can reduce the overall
reduce the overall network
the overall network traffic
overall network traffic by
network traffic by taking
traffic by taking advantage
none of the unix
by taking advantage of
of the unix based
taking advantage of the
the unix based operating
advantage of the packet
unix based operating systems
of the packet replication
based operating systems came
the packet replication and
operating systems came close
packet replication and forwarding
systems came close to
replication and forwarding within
came close to fulfilling
and forwarding within the
close to fulfilling our
forwarding within the network
to fulfilling our requirements
within the network infrastructure
as noted before the
noted before the core
before the core of
the core of those
core of those operating
the deployment of the
of those operating systems
deployment of the efficient
those operating systems is
of the efficient network
operating systems is based
systems is based on
year old designs and
old designs and these
designs and these operating
and these operating systems
these operating systems still
operating systems still treat
systems still treat computers
still treat computers as
treat computers as single
area internet has failed
computers as single entities
as single entities without
single entities without a
entities without a coherent
and so more expensive
so more expensive application
level overlays are generally
overlays are generally used
the devices used by
devices used by content
used by content subscribers
by content subscribers have
content subscribers have become
subscribers have become increasingly
have become increasingly heterogeneous
become increasingly heterogeneous mobile
increasingly heterogeneous mobile devices
are projected to consume
projected to consume over
feet high windows nt
high windows nt looked
windows nt looked like
nt looked like the
looked like the proverbial
ordering transactions with prediction
like the proverbial dinosaur
transactions with prediction in
exabytes of video per
with prediction in distributed
of video per month
prediction in distributed object
video per month in
in distributed object stores
a closer look revealed
distributed object stores ittay
closer look revealed a
object stores ittay eyal
look revealed a truly
revealed a truly modern
a truly modern operating
truly modern operating system
object oriented design is
oriented design is pervasive
design is pervasive through
is pervasive through the
pervasive through the system
through the system including
the system including the
system including the kernel
there is a complete
is a complete distributed
a complete distributed strategy
complete distributed strategy with
implying that a range
distributed strategy with at
that a range of
strategy with at its
a range of subscription
with at its core
range of subscription rates
at its core a
of subscription rates and
its core a distributed
department of computer science
subscription rates and policies
core a distributed object
rates and policies must
a distributed object technology
and policies must be
distributed object technology and
policies must be applied
object technology and includes
must be applied over
technology and includes a
be applied over the
and includes a complete
applied over the user
includes a complete integration
over the user base
a complete integration of
complete integration of distributed
integration of distributed services
of distributed services such
distributed services such as
services such as security
department of electrical engineering
even if multiple users
if multiple users are
multiple users are streaming
users are streaming the
are streaming the same
streaming the same event
israel abstract numbers of
and last no but
abstract numbers of storage
last no but least
numbers of storage nodes
such as watching the
as watching the opening
watching the opening ceremony
the opening ceremony of
opening ceremony of the
there is a real
ceremony of the olympics
when client transactions access
is a real desire
client transactions access data
a real desire by
transactions access data on
real desire by the
access data on multiple
a smartphone user will
data on multiple shards
desire by the vendor
smartphone user will need
by the vendor to
user will need a
the vendor to continuously
will need a differently
vendor to continuously innovate
need a differently transcoded
to continuously innovate its
the issue of consistency
continuously innovate its operating
issue of consistency arises
a differently transcoded version
innovate its operating system
differently transcoded version than
its operating system and
transcoded version than the
operating system and the
version than the people
system and the overall
than the people watching
and the overall services
the people watching via
people watching via internet
we would use a
watching via internet television
would use a system
use a system with
a system with acid
microsoft doesn t hesitate
system with acid transactions
doesn t hesitate to
t hesitate to incorporate
hesitate to incorporate academic
to incorporate academic results
incorporate academic results into
or on their laptops
academic results into operating
results into operating system
and is open for
is open for new
open for new directions
different consumer groups may
consumer groups may desire
groups may desire different
may desire different local
desire different local ads
different local ads or
innovation as a life
local ads or sub
as a life style
a life style microsoft
life style microsoft is
style microsoft is not
titles to be embedded
microsoft is not conservative
to be embedded into
is not conservative in
be embedded into their
not conservative in its
embedded into their video
conservative in its os
into their video streams
in its os development
because this model facilitates
this model facilitates reasoning
while most vendors only
model facilitates reasoning about
most vendors only consider
facilitates reasoning about system
vendors only consider changes
avatars in a virtual
reasoning about system properties
only consider changes to
in a virtual world
about system properties and
consider changes to their
a virtual world can
changes to their core
system properties and makes
to their core os
virtual world can be
their core os services
properties and makes possible
world can be viewed
core os services under
and makes possible a
os services under extreme
can be viewed as
services under extreme market
makes possible a variety
under extreme market pressure
be viewed as subscribers
possible a variety of
viewed as subscribers to
a variety of highassurance
as subscribers to updates
variety of highassurance guarantees
subscribers to updates about
the core of windows
to updates about objects
core of windows nt
updates about objects in
of windows nt has
about objects in their
windows nt has changed
objects in their vicinity
nt has changed significantly
has changed significantly over
the acid model is
changed significantly over the
acid model is often
significantly over the past
and may want more
model is often avoided
over the past years
is often avoided in
may want more detailed
often avoided in today
the past years to
avoided in today s
want more detailed updates
in today s large
past years to accommodate
more detailed updates for
years to accommodate the
detailed updates for objects
to accommodate the demands
updates for objects that
accommodate the demands of
for objects that are
scale systems due to
the demands of modern
systems due to efficiency
demands of modern computing
due to efficiency concerns
objects that are closer
that are closer to
are closer to them
closer to them in
to them in this
especially the upcoming release
them in this world
the upcoming release of
upcoming release of windows
while this growing heterogeneity
this growing heterogeneity of
growing heterogeneity of device
heterogeneity of device types
research on cdns has
on cdns has generally
existing approaches typically run
cdns has generally assumed
approaches typically run transactions
has generally assumed a
typically run transactions speculatively
generally assumed a homogeneous
run transactions speculatively and
assumed a homogeneous population
transactions speculatively and perform
formerly known as windows
a homogeneous population of
known as windows nt
speculatively and perform certification
homogeneous population of end
and perform certification after
perform certification after they
certification after they complete
after they complete to
they complete to preserve
complete to preserve consistency
makes that the microsoft
that the microsoft takes
the microsoft takes the
microsoft takes the operating
either committing or aborting
takes the operating system
committing or aborting each
the operating system functionality
or aborting each transaction
operating system functionality to
aborting each transaction depending
system functionality to the
each transaction depending on
functionality to the next
transaction depending on conflicts
to the next level
the advances in windows
rain an architecture for
an architecture for acid
architecture for acid transactions
for acid transactions in
acid transactions in a
transactions in a resilient
in a resilient archive
a resilient archive with
are too numerous to
resilient archive with independent
too numerous to enumerate
archive with independent nodes
numerous to enumerate here
thus most current systems
most current systems assume
they range from a
the system orders transactions
current systems assume multiple
range from a file
system orders transactions before
from a file system
systems assume multiple video
a file system cache
orders transactions before they
file system cache for
assume multiple video streams
system cache for disconnected
transactions before they begin
cache for disconnected operation
multiple video streams to
before they begin by
video streams to be
they begin by employing
streams to be sent
begin by employing predictors
which was originally developed
to be sent from
by employing predictors that
was originally developed at
be sent from the
employing predictors that estimate
originally developed at cmu
sent from the source
developed at cmu in
predictors that estimate the
from the source at
at cmu in the
that estimate the set
cmu in the coda
the source at different
in the coda project
estimate the set of
source at different resolutions
the set of objects
at different resolutions or
set of objects each
different resolutions or that
of objects each transaction
to a remote storage
resolutions or that a
objects each transaction will
a remote storage service
or that a single
each transaction will access
remote storage service that
that a single highquality
storage service that automatically
a single highquality stream
service that automatically moves
single highquality stream is
that automatically moves old
highquality stream is transcoded
such predictors can be
stream is transcoded by
predictors can be implemented
automatically moves old data
is transcoded by the
moves old data from
can be implemented with
transcoded by the receiver
be implemented with machine
by the receiver who
old data from your
the receiver who then
implemented with machine learning
receiver who then incurs
with machine learning tools
data from your hard
who then incurs cost
from your hard disk
then incurs cost for
your hard disk to
incurs cost for last
hard disk to remote
disk to remote servers
to remote servers if
remote servers if you
servers if you are
if you are running
mile traffic owing to
you are running out
traffic owing to unnecessarily
are running out of
owing to unnecessarily detailed
running out of disk
to unnecessarily detailed video
out of disk space
we pose the following
from tight security integration
pose the following question
a transaction reserves a
transaction reserves a version
how can we deliver
reserves a version of
can we deliver live
a version of each
we deliver live dynamic
version of each object
deliver live dynamic content
of each object it
each object it will
object it will use
as the dominant security
the dominant security provider
such as video broadcasts
when later accessing the
later accessing the objects
or financial stock data
to a complete integration
a complete integration of
complete integration of network
it will see these
integration of network quality
over the internet to
will see these reserved
of network quality of
see these reserved versions
the internet to large
network quality of services
internet to large number
quality of services tools
to large number of
of services tools including
large number of heterogeneous
services tools including data
number of heterogeneous users
tools including data transmission
of heterogeneous users simultaneously
including data transmission shapers
heterogeneous users simultaneously while
data transmission shapers and
users simultaneously while balancing
transmission shapers and priority
simultaneously while balancing bandwidth
shapers and priority scheduling
while balancing bandwidth costs
and priority scheduling and
leases for future object
priority scheduling and queuing
for future object versions
traffic rates and end
and from attributed based
from attributed based distributed
attributed based distributed component
leases are issued for
based distributed component programming
are issued for a
distributed component programming to
issued for a predefined
component programming to indexing
for a predefined time
programming to indexing support
a predefined time period
to indexing support integrated
live content refers to
indexing support integrated in
content refers to content
support integrated in the
refers to content streams
integrated in the file
to content streams that
in the file system
content streams that must
streams that must be
not the lease holder
that must be transmitted
must be transmitted to
be transmitted to multiple
transmitted to multiple receivers
may unilaterally decide to
to multiple receivers simultaneously
unilaterally decide to ignore
decide to ignore a
to ignore a reservation
we are witnesses of
such as a live
are witnesses of a
as a live broadcast
to run effectively at
witnesses of a unique
run effectively at large
of a unique process
effectively at large scale
never before have we
ticker updates for financial
before have we seen
updates for financial stocks
have we seen such
for financial stocks or
we seen such a
rain must tolerate performance
financial stocks or object
must tolerate performance hiccups
stocks or object updates
seen such a radical
or object updates in
such a radical overhaul
object updates in a
a radical overhaul of
updates in a virtual
radical overhaul of an
in a virtual world
overhaul of an operating
of an operating system
an operating system targeted
operating system targeted for
system targeted for the
targeted for the enterprise
all of which are
for the enterprise market
of which are common
which are common in
we are not focused
are common in such
are not focused on
common in such settings
not focused on streams
focused on streams with
in general this market
on streams with a
general this market is
streams with a pause
this market is very
with a pause or
market is very conservative
a pause or rewind
is very conservative and
pause or rewind functions
very conservative and not
or rewind functions or
conservative and not interested
rewind functions or the
and not interested in
functions or the video
progress should never depend
not interested in taking
should never depend on
interested in taking risks
never depend on the
depend on the responsiveness
on the responsiveness of
the responsiveness of any
responsiveness of any single
of any single machine
however the problems of
the problems of scale
management and distribution are
and distribution are asking
distribution are asking for
are asking for radical
the gradient cdn to
rain requires reliable entities
gradient cdn to make
requires reliable entities in
asking for radical solutions
reliable entities in cloud
cdn to make progress
for radical solutions to
to make progress towards
radical solutions to get
make progress towards the
solutions to get to
progress towards the research
to get to a
towards the research question
get to a computing
to a computing base
it is common to
a computing base that
is common to shard
computing base that can
we propose a novel
base that can bring
propose a novel networked
that can bring us
a novel networked content
can bring us into
bring us into the
novel networked content delivery
us into the next
data across large numbers
into the next century
across large numbers of
networked content delivery system
large numbers of nodes
content delivery system called
delivery system called g
one of the markets
system called g radient
atomic transactions are typically
of the markets where
transactions are typically implemented
called g radient to
are typically implemented by
the markets where we
g radient to address
typically implemented by running
markets where we will
implemented by running transactions
radient to address the
by running transactions speculatively
where we will see
to address the complex
we will see the
address the complex caching
will see the main
the complex caching and
see the main competitive
and then certifying them
complex caching and multicasting
the main competitive battle
caching and multicasting issues
main competitive battle between
and multicasting issues associated
competitive battle between microsoft
aborting ones that cause
multicasting issues associated with
ones that cause conflicts
battle between microsoft and
issues associated with live
between microsoft and others
associated with live streaming
microsoft and others will
with live streaming of
and others will be
live streaming of dynamic
others will be that
streaming of dynamic content
will be that of
of dynamic content to
in high contention scenarios
dynamic content to a
be that of the
content to a heterogeneous
that of the e
to a heterogeneous user
a heterogeneous user population
this approach has drawbacks
rather than achieving any
the systems architecture consists
web farms with hundreds
than achieving any substantial
farms with hundreds of
systems architecture consists of
with hundreds of nodes
achieving any substantial level
architecture consists of one
any substantial level of
consists of one or
substantial level of concurrency
of one or more
with support services for
one or more content
support services for load
or more content providers
services for load balancing
it prevents concurrency by
more content providers which
prevents concurrency by aborting
content providers which together
concurrency by aborting all
providers which together form
by aborting all but
which together form a
aborting all but one
together form a cooperative
all but one of
form a cooperative network
but one of the
a cooperative network of
one of the contending
cooperative network of g
of the contending transactions
network of g radient
of g radient cdn
g radient cdn nodes
our work explores a
work explores a new
explores a new option
the cdn nodes form
cdn nodes form a
nodes form a dynamic
form a dynamic overlay
a dynamic overlay over
dynamic overlay over which
overlay over which the
distributed and single image
over which the content
and single image management
ordering transactions in advance
which the content is
transactions in advance based
the content is delivered
in advance based on
advance based on the
based on the objects
on the objects they
the objects they are
and for our initial
objects they are likely
for our initial prototypes
they are likely to
are likely to access
our initial prototypes we
initial prototypes we will
are really pushing the
prototypes we will look
really pushing the envelope
we will look at
providing acid transactions in
will look at spanning
pushing the envelope of
look at spanning trees
acid transactions in a
the envelope of all
transactions in a resilient
envelope of all operating
in a resilient archive
of all operating systems
a resilient archive with
all operating systems that
resilient archive with independent
the concept of cdn
archive with independent nodes
operating systems that are
concept of cdn nodes
systems that are currently
of cdn nodes is
that are currently on
cdn nodes is general
are currently on the
currently on the market
an architecture in which
windows nt is still
architecture in which cdn
nt is still considered
in which cdn servers
is still considered to
which cdn servers are
still considered to be
cdn servers are hosted
considered to be the
this preliminary ordering decreases
servers are hosted by
preliminary ordering decreases abort
to be the new
ordering decreases abort rate
are hosted by isps
be the new kid
hosted by isps to
the new kid on
by isps to reduce
new kid on the
isps to reduce redundant
and eliminates aborts in
kid on the block
eliminates aborts in error
to reduce redundant incoming
on the block in
reduce redundant incoming bandwidth
the block in the
redundant incoming bandwidth is
block in the internet
incoming bandwidth is a
in the internet services
bandwidth is a logical
the internet services world
is a logical scenario
to allow fast recovery
allow fast recovery from
fast recovery from failures
but it is clear
recovery from failures our
and another example is
from failures our scheme
it is clear that
failures our scheme does
another example is that
our scheme does not
example is that g
scheme does not introduce
is clear that the
does not introduce any
is that g radient
not introduce any locks
clear that the risks
that g radient nodes
that the risks that
g radient nodes may
the risks that are
radient nodes may as
the system consistency and
nodes may as well
risks that are taken
may as well be
system consistency and durability
as well be integrated
that are taken now
well be integrated into
consistency and durability rely
are taken now are
be integrated into set
and durability rely on
taken now are the
durability rely on a
now are the right
rely on a single
are the right moves
on a single scalable
the right moves to
a single scalable tier
right moves to prepare
single scalable tier of
moves to prepare the
scalable tier of highly
to prepare the operating
prepare the operating system
the operating system for
operating system for operation
system for operation in
for operation in these
operation in these emerging
in these emerging massive
simulations using the transactional
these emerging massive computing
our approach to the
emerging massive computing environments
approach to the problem
to the problem resembles
the problem resembles content
ycsb workloads show the
workloads show the scalability
show the scalability and
the bugs innovation comes
the scalability and benefits
bugs innovation comes at
scalability and benefits of
innovation comes at a
and benefits of acidrain
comes at a price
and in fact the
in fact the expected
fact the expected deployment
one of the costs
the expected deployment model
of the costs of
expected deployment model would
the costs of introducing
deployment model would employ
costs of introducing a
model would employ a
of introducing a significant
would employ a geographically
introducing a significant amount
employ a geographically distributed
a significant amount of
center computing systems often
a geographically distributed set
significant amount of new
computing systems often maintain
geographically distributed set of
systems often maintain massive
amount of new code
often maintain massive data
distributed set of isps
maintain massive data sets
of new code is
set of isps or
new code is the
of isps or small
code is the number
isps or small data
is the number of
sharded over large this
the number of software
over large this work
or small data centers
number of software defects
large this work was
of software defects per
this work was funded
small data centers of
software defects per lines
data centers of the
defects per lines of
centers of the kind
per lines of codes
of the kind operated
lines of codes increases
the kind operated by
kind operated by today
operated by today s
by today s cdn
by grants from darpa
today s cdn providers
while measurements actually let
measurements actually let us
actually let us believe
let us believe that
us believe that microsoft
believe that microsoft products
and the elkin research
that microsoft products are
the elkin research fund
microsoft products are quite
whereas today s content
products are quite reliable
are quite reliable at
quite reliable at operating
reliable at operating systems
hosting sites cache objects
only at a single
at a single tier
a single tier of
single tier of the
tier of the system
of the system a
the system a set
system a set of
thousand lines of code
a set of independent
set of independent highly
of independent highly available
independent highly available logs
used in a novel
in a novel manner
fresh code has a
code has a disastrous
has a disastrous effect
our focus is on
all other entities may
a disastrous effect on
focus is on content
disastrous effect on this
other entities may fail
effect on this number
is on content that
entities may fail and
on content that cannot
may fail and can
content that cannot be
fail and can be
that cannot be usefully
and can be replaced
cannot be usefully cached
can be replaced instantly
the outlook becomes even
be replaced instantly on
outlook becomes even more
replaced instantly on failure
becomes even more worrisome
even more worrisome when
the g radient project
more worrisome when we
g radient project aims
worrisome when we realize
radient project aims to
the architecture maintains consistency
when we realize that
project aims to exploit
architecture maintains consistency even
we realize that microsoft
aims to exploit and
realize that microsoft is
maintains consistency even in
that microsoft is not
to exploit and develop
microsoft is not only
consistency even in the
is not only introducing
even in the event
not only introducing new
in the event of
only introducing new code
the event of false
exploit and develop two
event of false suspicion
and develop two techniques
develop two techniques that
two techniques that improve
but is also changing
techniques that improve on
is also changing all
that improve on existing
also changing all of
improve on existing cdns
changing all of its
all of its old
of its old code
reservations serve as suggestions
serve as suggestions a
as suggestions a reservation
suggestions a reservation that
an automated process is
a reservation that is
automated process is converting
reservation that is not
and algorithms to balance
that is not used
algorithms to balance bandwidth
process is converting all
to balance bandwidth costs
is not used because
balance bandwidth costs with
is converting all of
not used because of
converting all of the
bandwidth costs with end
all of the windows
used because of a
of the windows nt
because of a sluggish
the windows nt code
of a sluggish or
windows nt code to
a sluggish or dead
nt code to be
sluggish or dead owner
or dead owner is
dead owner is ignored
our design is focused
design is focused on
is focused on modularity
focused on modularity and
on modularity and incremental
modularity and incremental deployment
the independence of system
independence of system elements
of system elements allows
system elements allows for
elements allows for good
allows for good scalability
thousand lines of code
lines of code per
of code per day
due to the interdependence
code per day and
to the interdependence of
per day and is
the interdependence of the
day and is believed
interdependence of the log
and is believed to
of the log contents
is believed to catch
believed to catch all
to catch all pointer
catch all pointer arithmetic
all pointer arithmetic cases
dynamic content has substantial
content has substantial levels
has substantial levels of
an important question is
substantial levels of redundancy
important question is whether
has to be carefully
question is whether the
to be carefully coordinated
is whether the introduced
be carefully coordinated to
even when user interests
carefully coordinated to maintain
whether the introduced functionality
coordinated to maintain consistency
when user interests are
the introduced functionality is
user interests are relatively
introduced functionality is worth
interests are relatively heterogeneous
functionality is worth the
is worth the unavoidable
we evaluate our architecture
worth the unavoidable initial
evaluate our architecture by
the unavoidable initial instability
our architecture by simulation
widespread use of streaming
architecture by simulation with
unavoidable initial instability that
by simulation with the
use of streaming video
simulation with the transactional
initial instability that is
of streaming video occurs
instability that is bound
streaming video occurs when
that is bound to
video occurs when internet
is bound to occur
occurs when internet users
when internet users watch
internet users watch major
users watch major events
watch major events online
whenever taking risks to
taking risks to achieve
risks to achieve major
to achieve major improvements
such as superbowl or
as superbowl or the
superbowl or the olympics
there is always the
is always the down
always the down side
the down side that
and like television users
down side that there
side that there is
we contrast the effectiveness
that there is some
contrast the effectiveness of
such clients have little
there is some change
clients have little tolerance
the effectiveness of employing
is some change of
effectiveness of employing prediction
have little tolerance for
some change of failure
of employing prediction and
little tolerance for lagged
change of failure and
tolerance for lagged data
employing prediction and the
of failure and it
prediction and the scalability
failure and it is
and the scalability of
and it is likely
the scalability of acid
it is likely that
is likely that we
large numbers of users
likely that we will
numbers of users have
that we will see
rain with other approaches
of users have essentially
we will see a
users have essentially the
will see a number
have essentially the same
see a number of
essentially the same needs
a number of components
number of components of
of components of nt
components of nt coming
of nt coming under
but since they may
nt coming under intense
since they may access
coming under intense scrutiny
tm m om i
they may access the
under intense scrutiny from
may access the streams
access the streams from
the streams from a
streams from a variety
from a variety of
a variety of devices
with different screen sizes
different screen sizes and
screen sizes and resolutions
om n om i
or different connectivity properties
the current solution is
current solution is to
solution is to provide
is to provide each
to provide each user
provide each user with
each user with a
log i log n
user with a direct
i log n figure
with a direct connection
a direct connection to
direct connection to a
connection to a content
intense scrutiny from industry
scrutiny from industry and
from industry and academia
server due to the
schematic structure of acid
due to the lack
to the lack of
the lack of robust
lack of robust multicast
of robust multicast technologies
such as the directory
as the directory services
tms access multiple objects
similar issues arise for
access multiple objects per
issues arise for newscasts
multiple objects per transaction
arise for newscasts of
for newscasts of fast
may become a performance
become a performance bottleneck
a performance bottleneck in
performance bottleneck in the
objects are managed by
bottleneck in the overall
are managed by oms
in the overall distributed
the overall distributed operation
transmission of financial data
of financial data and
financial data and virtual
data and virtual on
or the wide spread
the wide spread security
wide spread security integration
spread security integration could
security integration could introduce
integration could introduce a
could introduce a critical
our insight is that
introduce a critical dependency
insight is that a
is falsely suspected to
a critical dependency on
falsely suspected to have
is that a data
suspected to have failed
critical dependency on the
dependency on the high
rich channel can be
and replaced by omi
channel can be transformed
can be transformed on
availability of the security
of the security servers
from a research point
a research point of
research point of view
network to create the
to create the dynamic
create the dynamic content
the dynamic content for
dynamic content for end
these problems do not
problems do not really
causing them to concurrently
do not really bother
them to concurrently serve
not really bother us
to concurrently serve the
concurrently serve the same
serve the same objects
the advantage of performing
advantage of performing research
we could add personalized
oms are backed by
could add personalized advertisements
of performing research on
are backed by highlyavailable
performing research on a
backed by highlyavailable logs
research on a system
subtitles or encryption keys
or encryption keys to
encryption keys to iptv
where they store tentative
which has distribution at
they store tentative transaction
keys to iptv broadcasts
store tentative transaction entries
has distribution at its
tentative transaction entries for
distribution at its core
transaction entries for serialization
at its core greatly
filters or aggregates to
its core greatly outweighs
or aggregates to financial
core greatly outweighs the
aggregates to financial stock
greatly outweighs the consequences
to financial stock updates
outweighs the consequences of
the consequences of working
consequences of working with
of working with a
working with a cutting
or reduce the update
with a cutting edge
reduce the update rate
a cutting edge operating
the update rate for
cutting edge operating system
update rate for distant
rate for distant objects
for distant objects in
distant objects in the
objects in the virtual
in the virtual world
however i must admit
the virtual world to
virtual world to which
i must admit that
world to which the
system structure the structure
to which the user
must admit that at
which the user has
structure the structure of
the user has subscribed
the structure of the
admit that at more
structure of the system
of the system is
that at more then
the system is illustrated
system is illustrated in
the same mechanism will
is illustrated in figure
at more then one
same mechanism will also
mechanism will also allow
more then one occasion
will also allow the
also allow the system
then one occasion my
allow the system to
the system to tailor
one occasion my students
system to tailor to
at the base of
to tailor to heterogeneous
the base of acid
occasion my students had
tailor to heterogeneous devices
my students had to
students had to control
rain are a set
are a set of
had to control their
a set of independent
set of independent highly
to control their murderous
control their murderous intentions
their murderous intentions towards
available logs that together
logs that together describe
murderous intentions towards the
transcoding a high definition
that together describe the
intentions towards the iis
together describe the state
a high definition broadcast
towards the iis or
describe the state of
high definition broadcast to
the iis or mts
the state of the
definition broadcast to adapt
iis or mts developers
state of the entire
broadcast to adapt its
or mts developers or
of the entire system
to adapt its resolution
mts developers or were
adapt its resolution to
developers or were they
its resolution to serve
or were they kept
each log is accessed
resolution to serve a
log is accessed through
were they kept their
is accessed through an
to serve a population
they kept their good
accessed through an object
serve a population of
through an object manager
kept their good spirits
a population of heterogeneous
their good spirits by
population of heterogeneous devices
good spirits by contemplating
of heterogeneous devices from
spirits by contemplating the
heterogeneous devices from cell
by contemplating the horrible
devices from cell phones
contemplating the horrible tortures
from cell phones to
the horrible tortures one
cell phones to tablets
horrible tortures one could
phones to tablets to
tortures one could perform
to tablets to iptv
that caches the data
one could perform on
tablets to iptv lowering
caches the data and
could perform on the
to iptv lowering overall
the data and provides
perform on the person
iptv lowering overall bandwidth
data and provides the
on the person that
lowering overall bandwidth costs
and provides the data
overall bandwidth costs without
the person that had
bandwidth costs without affecting
person that had designed
costs without affecting viewing
provides the data structure
without affecting viewing experience
that had designed the
the data structure abstraction
had designed the com
data structure abstraction exporting
designed the com security
structure abstraction exporting read
the com security architecture
abstraction exporting read and
exporting read and write
read and write operations
windows research there are
research there are some
there are some properties
network transformations will be
are some properties of
which are managed by
transformations will be applied
are managed by transaction
some properties of windows
managed by transaction managers
will be applied with
properties of windows nt
be applied with pluggable
of windows nt that
applied with pluggable serverlets
windows nt that make
with pluggable serverlets designed
nt that make it
pluggable serverlets designed to
that make it particularly
serverlets designed to execute
make it particularly suitable
designed to execute within
it particularly suitable for
to execute within the
particularly suitable for research
execute within the cdn
tms provide the atomic
suitable for research purposes
provide the atomic transaction
the atomic transaction abstraction
the operating system kernel
they receive instructions from
operating system kernel for
receive instructions from clients
system kernel for example
instructions from clients to
kernel for example is
from clients to start
for example is designed
clients to start and
example is designed with
to start and end
is designed with extensibility
start and end a
designed with extensibility in
and end a transaction
with extensibility in mind
and operations to perform
to allow developers of
operations to perform on
allow developers of hardware
to perform on individual
developers of hardware based
perform on individual objects
of hardware based services
on individual objects within
individual objects within the
objects within the transaction
new protocols and file
protocols and file systems
and file systems to
file systems to add
systems to add their
the tms predict which
to add their functionality
tms predict which objects
within the cdn nodes
add their functionality to
the cdn nodes of
their functionality to the
cdn nodes of g
predict which objects it
nodes of g radient
functionality to the system
which objects it is
to the system without
objects it is likely
the system without much
it is likely to
system without much effort
is likely to access
the serverlets encapsulate application
and reserve these object
all kernel code is
reserve these object versions
speci n ac details
kernel code is developed
n ac details such
code is developed following
ac details such as
is developed following a
details such as the
developed following a strict
such as the stream
following a strict object
as the stream data
a strict object oriented
the stream data format
strict object oriented paradigm
they speculatively perform each
object oriented paradigm and
speculatively perform each operation
oriented paradigm and its
perform each operation with
paradigm and its functionality
each operation with the
and its functionality can
operation with the help
its functionality can only
and the ways to
functionality can only be
the ways to transform
can only be accessed
with the help of
only be accessed through
ways to transform a
be accessed through interfaces
to transform a the
the help of the
transform a the data
help of the appropriate
of the appropriate oms
the appropriate oms and
none of its implementation
appropriate oms and according
rich objects into more
oms and according to
objects into more specialized
of its implementation is
into more specialized ones
and according to the
its implementation is visible
according to the order
to the order set
the order set by
order set by the
set by the reservations
open issues include understanding
one of the designs
issues include understanding what
of the designs abstractions
include understanding what kinds
the designs abstractions of
understanding what kinds of
designs abstractions of the
what kinds of content
abstractions of the windows
kinds of content may
of the windows nt
of content may be
the windows nt kernel
content may be subject
they certify the transaction
may be subject to
windows nt kernel i
certify the transaction by
be subject to such
nt kernel i find
the transaction by checking
subject to such transformation
transaction by checking for
kernel i find it
by checking for conflicts
to such transformation and
i find it particularly
such transformation and which
checking for conflicts in
transformation and which dynamic
find it particularly fascinating
and which dynamic content
for conflicts in each
which dynamic content is
it particularly fascinating to
dynamic content is not
conflicts in each log
particularly fascinating to work
fascinating to work with
to work with is
work with is the
with is the device
to assess the effect
is the device object
assess the effect of
the effect of the
effect of the transformation
of the transformation on
the transformation on quality
a device object in
transformation on quality and
device object in an
on quality and traffic
object in an instance
quality and traffic rates
membership monitors are in
in an instance created
monitors are in charge
an instance created by
are in charge of
instance created by driver
in charge of deciding
how transformation should be
created by driver objects
transformation should be meaningfully
charge of deciding and
should be meaningfully expressed
of deciding and publishing
be meaningfully expressed and
deciding and publishing which
meaningfully expressed and used
and publishing which machines
expressed and used by
which encapsulates a unit
and used by content
publishing which machines perform
used by content providers
encapsulates a unit of
which machines perform which
a unit of kernel
machines perform which roles
unit of kernel based
of kernel based software
and to learn how
to learn how computationally
learn how computationally intensive
namely which machines run
whether this is a
how computationally intensive such
which machines run the
computationally intensive such transformation
machines run the log
intensive such transformation methods
run the log and
such transformation methods can
the log and model
transformation methods can be
this is a device
methods can be without
log and model and
can be without overloading
is a device driver
be without overloading the
and model and goal
without overloading the nodes
model and goal we
and goal we assume
goal we assume unreliable
a network protocol or
we assume unreliable servers
network protocol or a
balancing bandwidth costs with
protocol or a file
bandwidth costs with end
or a file system
assume unreliable servers that
a file system filter
unreliable servers that may
servers that may crash
that may crash or
may crash or hang
these objects have the
objects have the interesting
the g radi ent
have the interesting property
g radi ent content
the interesting property that
radi ent content delivery
interesting property that they
ent content delivery system
property that they can
content delivery system is
that they can be
delivery system is currently
they can be attached
system is currently designed
can be attached to
is currently designed to
be attached to other
currently designed to use
attached to other device
designed to use a
to other device objects
to use a spanningtree
use a spanningtree overlay
to accommodate reliable storage
and as such can
as such can intercept
similar to most multicast
such can intercept and
to most multicast network
can intercept and manipulate
most multicast network architectures
intercept and manipulate all
and manipulate all requests
manipulate all requests flowing
all requests flowing to
with virtual links connecting
requests flowing to and
virtual links connecting g
flowing to and from
links connecting g radient
to and from the
connecting g radient cdn
as explained in section
g radient cdn nodes
and from the original
from the original device
the original device object
the question is to
question is to determine
is to determine what
to determine what nodes
this way it is
determine what nodes the
what nodes the in
way it is relatively
it is relatively simple
is relatively simple to
network processing and connecting
relatively simple to add
the system exposes a
processing and connecting to
system exposes a transactional
and connecting to the
exposes a transactional data
connecting to the diverse
simple to add for
to the diverse end
a transactional data store
to add for example
transactional data store supporting
add for example a
data store supporting serializable
for example a file
users should be done
store supporting serializable transactions
example a file system
a file system object
file system object that
a client invokes a
system object that compresses
client invokes a begin
object that compresses or
we need to optimize
that compresses or encrypts
need to optimize the
compresses or encrypts data
to optimize the overlay
or encrypts data before
optimize the overlay to
encrypts data before the
the overlay to deliver
data before the data
overlay to deliver the
before the data reaches
to deliver the exact
the data reaches the
deliver the exact stream
data reaches the under
the exact stream quality
reaches the under laying
exact stream quality demanded
the under laying file
stream quality demanded by
under laying file system
quality demanded by users
demanded by users while
by users while minimizing
users while minimizing bandwidth
while minimizing bandwidth costs
to redirect disk requests
redirect disk requests to
a field from a
disk requests to a
field from a table
requests to a replication
to a replication volume
we propose to apply
propose to apply an
or to trace device
to apply an economics
to trace device object
apply an economics framework
trace device object interaction
device object interaction during
object interaction during development
interaction during development phases
considering two primary inputs
two primary inputs in
primary inputs in determining
inputs in determining the
the strict object oriented
in determining the optimal
strict object oriented approach
determining the optimal network
object oriented approach is
the optimal network overlay
setting the value of
oriented approach is very
the value of a
approach is very well
value of a field
is very well done
of a field in
very well done from
a field in a
on the one hand
field in a table
well done from a
done from a design
from a design point
a design point of
design point of view
we consider the cost
consider the cost for
the cost for network
cost for network edges
for network edges to
finally the client invokes
network edges to carry
the client invokes the
edges to carry traffic
client invokes the endtransaction
style hacker s heart
invokes the endtransaction command
hacker s heart starts
s heart starts bleeding
similar to standard bandwidth
heart starts bleeding when
to standard bandwidth pricing
starts bleeding when he
and the system responds
bleeding when he or
the system responds with
when he or she
system responds with either
he or she realizes
responds with either a
or she realizes that
with either a commit
she realizes that he
either a commit or
realizes that he can
a commit or an
we leverage the perceived
commit or an abort
that he can no
leverage the perceived utility
he can no longer
the perceived utility by
can no longer do
perceived utility by end
no longer do a
longer do a quick
committed transactions form a
do a quick fix
transactions form a serializable
users for receiving the
form a serializable execution
for receiving the stream
receiving the stream at
the stream at a
stream at a given
inspect a few data
at a given quality
a few data structures
tms are equipped with
few data structures and
are equipped with predictors
data structures and secretly
equipped with predictors that
structures and secretly swivel
with predictors that foresee
and secretly swivel some
predictors that foresee which
secretly swivel some pointers
that foresee which objects
the exact solution for
foresee which objects a
swivel some pointers to
which objects a transaction
exact solution for this
objects a transaction is
some pointers to make
a transaction is likely
solution for this optimization
transaction is likely to
pointers to make things
is likely to access
for this optimization problem
likely to access on
to make things work
to access on its
this optimization problem is
access on its initiation
make things work better
optimization problem is intractable
things work better or
problem is intractable it
work better or make
is intractable it is
better or make more
intractable it is np
or make more informed
make more informed decisions
the internal kernel interfaces
internal kernel interfaces are
kernel interfaces are elaborate
in an implementation of
we have developed algorithms
but it appears there
an implementation of the
have developed algorithms that
it appears there are
developed algorithms that give
appears there are always
algorithms that give an
there are always some
that give an approximate
implementation of the system
give an approximate optimal
are always some things
an approximate optimal solution
of the system one
always some things one
the system one may
some things one cannot
system one may use
things one cannot do
one may use multiple
one cannot do as
may use multiple oms
cannot do as efficient
use multiple oms per
do as efficient as
multiple oms per log
as efficient as possible
in the case of
the case of video
case of video streams
dividing the log s
of video streams whose
the log s object
video streams whose quality
log s object set
streams whose quality and
whose quality and traffic
in four years of
quality and traffic rates
four years of nt
and traffic rates can
or the other way
traffic rates can be
the other way around
years of nt kernel
rates can be downgraded
of nt kernel hacking
can be downgraded by
nt kernel hacking only
be downgraded by g
have multiple logs report
downgraded by g radient
kernel hacking only on
by g radient cdn
multiple logs report to
hacking only on one
g radient cdn nodes
only on one occasion
logs report to a
on one occasion we
report to a single
one occasion we needed
to a single om
occasion we needed to
we have derived a
we needed to break
have derived a primaldual
needed to break through
derived a primaldual approximation
to break through the
the choice depends on
break through the standard
a primaldual approximation algorithm
through the standard kernel
choice depends on the
the standard kernel interface
primaldual approximation algorithm which
depends on the throughput
approximation algorithm which produces
on the throughput of
algorithm which produces a
the throughput of the
which produces a solution
we wanted to add
produces a solution whose
throughput of the specific
a solution whose total
wanted to add a
solution whose total cost
of the specific implementations
to add a fast
the specific implementations chosen
add a fast trap
specific implementations chosen for
a fast trap into
implementations chosen for each
fast trap into the
chosen for each service
the difference between total
trap into the kernel
difference between total network
into the kernel for
between total network traffic
the kernel for fast
total network traffic costs
kernel for fast user
in this paper we
network traffic costs and
this paper we use
traffic costs and aggregate
paper we use a
costs and aggregate end
and the pages which
the pages which hold
pages which hold the
is within a factor
which hold the trap
within a factor of
hold the trap dispatch
the trap dispatch tables
mapping for simplicity of
trap dispatch tables were
for simplicity of presentation
dispatch tables were protected
tables were protected after
were protected after the
protected after the system
after the system boot
we now describe the
now describe the operation
describe the operation of
the operation of acid
another example of what
example of what makes
of what makes windows
what makes windows nt
of the optimal in
makes windows nt particular
the optimal in the
we start with an
windows nt particular suitable
start with an overview
optimal in the worst
with an overview of
in the worst case
an overview of the
nt particular suitable for
overview of the system
particular suitable for research
of the system s
suitable for research is
the system s structure
for research is the
system s structure in
research is the fundamental
s structure in section
is the fundamental manner
the fundamental manner in
fundamental manner in which
manner in which advanced
in which advanced distributed
which advanced distributed services
advanced distributed services are
distributed services are integrated
services are integrated into
are integrated into windows
integrated into windows nt
we see that the
see that the algorithm
and proceed to describe
it allows us to
that the algorithm has
proceed to describe the
allows us to rely
the algorithm has lower
us to rely on
to describe the algorithm
algorithm has lower total
to rely on ubiquitous
describe the algorithm in
has lower total cost
rely on ubiquitous support
the algorithm in section
lower total cost compared
on ubiquitous support services
total cost compared to
ubiquitous support services and
cost compared to a
support services and concentrate
compared to a single
services and concentrate on
to a single stream
and concentrate on advancing
a single stream source
concentrate on advancing the
single stream source and
on advancing the state
stream source and a
advancing the state of
source and a minimum
the state of the
and a minimum spanning
state of the art
a minimum spanning tree
of the art where
minimum spanning tree streaming
the art where it
om for each shard
art where it is
spanning tree streaming protocol
where it is really
tree streaming protocol in
it is really needed
streaming protocol in a
and which tms are
protocol in a simulation
which tms are available
in a simulation based
a simulation based on
windows nt security provides
simulation based on a
nt security provides a
any client can access
based on a collection
security provides a complete
on a collection of
client can access any
provides a complete set
can access any tm
a collection of as
access any tm for
a complete set of
any tm for any
complete set of services
tm for any given
set of services integrated
for any given transaction
of services integrated into
services integrated into all
integrated into all sections
into all sections of
all sections of the
other than the logs
sections of the operating
of the operating system
server role assignment may
role assignment may be
researchers who are developing
assignment may be inconsistent
gradient mst naive broadcast
who are developing an
mst naive broadcast total
are developing an advanced
naive broadcast total cost
developing an advanced multi
node replicated transaction server
replicated transaction server can
transaction server can use
server can use off
is supposed to be
supposed to be managed
to be managed by
be managed by a
managed by a single
by a single om
at a given time
and encryption mechanisms into
encryption mechanisms into their
mechanisms into their system
into their system without
their system without much
system without much pain
but this may change
this may change due
may change due to
change due to an
due to an unjustified
the use of the
to an unjustified crash
use of the com
an unjustified crash suspicion
of the com object
unjustified crash suspicion whereupon
the com object model
crash suspicion whereupon an
com object model in
suspicion whereupon an object
object model in all
model in all the
in all the windows
all the windows nt
the windows nt services
windows nt services allows
nt services allows research
services allows research projects
allows research projects to
research projects to import
projects to import these
to import these services
import these services in
these services in a
services in a very
may temporarily be managed
in a very simple
temporarily be managed by
a very simple manner
be managed by two
managed by two oms
the existence of com
existence of com makes
of com makes it
com makes it trivial
makes it trivial for
it trivial for research
trivial for research projects
for research projects to
research projects to export
projects to export their
to export their interfaces
that do not know
export their interfaces in
do not know of
their interfaces in a
not know of one
interfaces in a language
know of one another
in a language independent
a language independent manner
the ensemble project for
ensemble project for example
rain uses log servers
project for example has
uses log servers for
for example has developed
log servers for reliable
example has developed a
servers for reliable storage
has developed a protocol
developed a protocol environment
a protocol environment for
protocol environment for distributed
each log server provides
environment for distributed operations
log server provides a
for distributed operations in
server provides a sequentially
distributed operations in the
provides a sequentially consistent
operations in the ml
a sequentially consistent log
in the ml programming
sequentially consistent log object
the ml programming language
and by using a
by using a com
using a com interface
a com interface are
com interface are the
interface are the services
are the services offered
the services offered by
services offered by ensemble
offered by ensemble available
update operations are linearizable
by ensemble available to
ensemble available to c
but reads may return
reads may return outdated
may return outdated results
java and vb programmers
multiple machines may append
machines may append entries
may append entries to
append entries to a
this allowed the researchers
entries to a log
allowed the researchers to
the researchers to side
machines may register to
may register to the
step the time consuming
register to the log
the time consuming development
time consuming development of
consuming development of native
development of native language
of native language interfaces
the log then sends
log then sends to
then sends to each
sends to each all
to each all entries
it helps of course
helps of course to
of course to have
course to have all
to have all the
from the first one
have all the tools
the first one in
first one in the
one in the log
the g radient optimization
g radient optimization is
radient optimization is effective
optimization is effective compared
is effective compared to
and then new entries
effective compared to a
then new entries as
compared to a centralized
new entries as they
operating system versions and
entries as they arrive
to a centralized source
system versions and their
a centralized source and
versions and their source
centralized source and a
and their source code
source and a minimum
their source code available
and a minimum spanning
an om may instruct
a minimum spanning tree
om may instruct the
may instruct the log
instruct the log to
microsoft is very generous
the log to truncate
is very generous to
log to truncate its
very generous to academia
to truncate its prefix
generous to academia and
protocol even as system
to academia and makes
even as system sizes
academia and makes all
as system sizes scale
and makes all their
system sizes scale up
makes all their tools
all their tools from
their tools from operating
tools from operating systems
from operating systems to
error bars represent one
operating systems to compilers
bars represent one standard
represent one standard deviation
one standard deviation over
algorithm we now describe
we now describe the
including tons of documentation
now describe the acid
tons of documentation as
of documentation as well
documentation as well as
as well as subscriptions
well as subscriptions to
as subscriptions to the
subscriptions to the developer
to the developer network
we explain the reservation
explain the reservation and
the reservation and certification
reservation and certification protocol
available to the departments
to the departments free
the departments free of
departments free of charge
the details are deferred
details are deferred to
are deferred to a
deferred to a full
to a full report
source code availability turned
a full report on
code availability turned out
full report on g
availability turned out to
report on g radient
turned out to be
out to be not
to be not crucial
then discuss prediction errors
and was only once
was only once used
only once used to
once used to make
used to make actual
to make actual changes
conclusion a number of
make actual changes to
a number of interesting
actual changes to the
number of interesting open
a transaction begins with
changes to the operating
transaction begins with the
of interesting open questions
begins with the tm
to the operating systems
with the tm receiving
interesting open questions remain
the tm receiving a
open questions remain the
tm receiving a begin
questions remain the focus
remain the focus of
von eicken et al
the focus of our
focus of our continued
of our continued investigation
transaction instruction from the
instruction from the client
how diverse are the
the tm assigns it
diverse are the classes
tm assigns it a
are the classes of
assigns it a unique
the classes of content
it a unique txnid
classes of content that
of content that are
content that are amenable
that are amenable to
are amenable to our
and predicts which objects
the source is extremely
predicts which objects the
source is extremely useful
which objects the transaction
is extremely useful as
objects the transaction will
extremely useful as additional
the transaction will access
useful as additional documentation
amenable to our in
it interrogates the oms
interrogates the oms about
to examine unexpected behaviour
the oms about all
examine unexpected behaviour or
oms about all these
unexpected behaviour or to
about all these objects
behaviour or to provide
how do we best
or to provide templates
do we best assess
to provide templates for
we best assess the
provide templates for similar
best assess the effect
templates for similar projects
and they respond with
assess the effect of
they respond with the
the effect of such
respond with the latest
effect of such transformations
with the latest unreserved
of such transformations on
as one can perform
the latest unreserved timestamp
such transformations on stream
latest unreserved timestamp of
transformations on stream quality
unreserved timestamp of each
one can perform complete
timestamp of each object
can perform complete source
perform complete source code
how should these transformations
complete source code level
should these transformations be
the tm chooses a
these transformations be expressed
source code level debugging
tm chooses a timestamp
code level debugging of
chooses a timestamp larger
level debugging of all
a timestamp larger than
debugging of all parts
timestamp larger than maximum
of all parts of
larger than maximum among
all parts of the
than maximum among the
parts of the operating
and utilized by the
of the operating system
maximum among the responses
the operating system including
utilized by the originating
operating system including the
by the originating content
system including the kernel
the originating content providers
originating content providers to
and asks the oms
content providers to best
asks the oms to
providers to best balance
the oms to reserve
to best balance content
source codes helps us
oms to reserve the
codes helps us to
to reserve the objects
helps us to develop
reserve the objects with
us to develop experimental
the objects with this
domain specificity with ease
objects with this timestamp
to develop experimental services
with this timestamp to
specificity with ease of
this timestamp to txnid
develop experimental services faster
with ease of development
experimental services faster and
services faster and in
faster and in tune
and in tune with
the oms confirm the
in tune with existing
how can our overlay
oms confirm the reservation
tune with existing functionality
can our overlay respond
confirm the reservation if
our overlay respond to
the reservation if no
overlay respond to churn
reservation if no concurrent
respond to churn among
if no concurrent tm
students are free to
to churn among g
no concurrent tm has
are free to work
churn among g radient
concurrent tm has reserved
free to work with
among g radient nodes
tm has reserved a
g radient nodes realistically
has reserved a larger
radient nodes realistically low
to work with the
nodes realistically low in
reserved a larger timestamp
work with the source
a larger timestamp in
realistically low in many
larger timestamp in the
with the source code
low in many common
timestamp in the meantime
in many common cases
the source code and
many common cases such
source code and are
common cases such as
code and are not
cases such as video
the tm then proceeds
such as video streaming
and are not prohibited
tm then proceeds to
are not prohibited in
then proceeds to serve
not prohibited in any
proceeds to serve transaction
prohibited in any way
to serve transaction operations
but higher in alternative
in any way from
higher in alternative deployment
serve transaction operations by
in alternative deployment scenarios
any way from applying
transaction operations by routing
way from applying the
operations by routing them
from applying the knowledge
by routing them to
applying the knowledge they
routing them to the
the knowledge they gained
them to the appropriate
knowledge they gained in
to the appropriate oms
they gained in their
gained in their later
in their later careers
each operation is sent
how do we ensure
operation is sent to
do we ensure that
is sent to the
interactions with the evil
we ensure that the
sent to the om
with the evil empire
ensure that the computational
to the om in
the evil empire microsoft
that the computational intensity
the om in charge
evil empire microsoft realizes
the computational intensity of
om in charge of
empire microsoft realizes the
computational intensity of our
in charge of the
microsoft realizes the potential
intensity of our transformations
charge of the object
realizes the potential of
of our transformations do
our transformations do not
the potential of widespread
transformations do not place
do not place too
potential of widespread adoption
not place too much
place too much load
of widespread adoption of
too much load on
much load on our
widespread adoption of windows
load on our g
on our g radient
adoption of windows nt
our g radient overlay
an example flow of
g radient overlay nodes
example flow of the
of windows nt for
flow of the algorithm
windows nt for research
nt for research purposes
for research purposes and
along with the txnid
research purposes and there
g radient contributes a
purposes and there is
radient contributes a novel
the oms order accesses
and there is dedicated
oms order accesses based
contributes a novel platform
there is dedicated academic
order accesses based on
a novel platform for
is dedicated academic relations
novel platform for continued
accesses based on timestamp
dedicated academic relations team
based on timestamp reservations
platform for continued study
academic relations team whose
for continued study and
relations team whose single
continued study and progress
team whose single task
study and progress to
and respond only when
and progress to ever
respond only when the
progress to ever more
only when the correct
to ever more effective
when the correct version
ever more effective delivery
the correct version is
whose single task it
correct version is available
more effective delivery mechanisms
single task it is
task it is to
it is to facilitate
is to facilitate the
each committed transaction is
to facilitate the technology
committed transaction is assigned
transaction is assigned a
facilitate the technology transfer
is assigned a timestamp
the technology transfer between
technology transfer between microsoft
transfer between microsoft and
between microsoft and academia
when reading an object
microsoft and academia and
and academia and vice
academia and vice versa
the timestamp of the
timestamp of the latest
of the latest transaction
the latest transaction that
source licensing is very
latest transaction that wrote
licensing is very liberal
transaction that wrote this
is very liberal compared
that wrote this object
very liberal compared to
wrote this object is
liberal compared to other
this object is returned
compared to other os
object is returned to
to other os vendors
is returned to the
other os vendors and
returned to the tm
os vendors and several
vendors and several institutions
and several institutions are
several institutions are involved
the transaction s timestamp
institutions are involved in
transaction s timestamp is
are involved in active
s timestamp is chosen
involved in active exchanges
timestamp is chosen to
in active exchanges with
is chosen to be
active exchanges with product
chosen to be larger
exchanges with product and
to be larger than
with product and research
be larger than the
product and research groups
larger than the largest
and research groups within
than the largest timestamp
research groups within microsoft
the largest timestamp returned
largest timestamp returned by
timestamp returned by its
returned by its operations
joint projects are in
projects are in progress
and not larger than
not larger than its
larger than its reserved
joint papers are starting
than its reserved timestamp
papers are starting to
are starting to appear
starting to appear and
to appear and academics
appear and academics frequently
bandwidth multicast in cooperative
and academics frequently present
multicast in cooperative environments
academics frequently present cutting
frequently present cutting edge
present cutting edge result
cutting edge result to
once a tm receives
edge result to microsoft
a tm receives an
result to microsoft developers
tm receives an end
to microsoft developers and
microsoft developers and researchers
transaction instruction from a
instruction from a client
it notifies the transaction
notifies the transaction s
the transaction s oms
detailing the transaction s
the transaction s timestamp
transaction s timestamp and
s timestamp and log
the logs in charge
logs in charge of
in charge of the
charge of the shards
of the shards it
the shards it touched
operating systems there is
systems there is a
there is a direct
is a direct impact
a direct impact of
direct impact of academia
impact of academia on
of academia on microsoft
when it receives such
academia on microsoft products
it receives such a
receives such a notification
approaching the zettabyte era
through involvement in the
an om appends to
involvement in the strategy
om appends to its
in the strategy phases
appends to its log
cisco visual networking index
the strategy phases of
to its log an
strategy phases of products
its log an entry
phases of products as
log an entry consisting
of products as well
an entry consisting of
products as well as
entry consisting of the
as well as through
consisting of the txnid
well as through academic
as through academic knowledge
through academic knowledge transfer
academic knowledge transfer into
knowledge transfer into products
transfer into products and
into products and design
products and design groups
microsoft also provides research
also provides research funding
provides research funding for
research funding for some
such logs may be
funding for some relevant
logs may be implemented
for some relevant groups
may be implemented with
some relevant groups and
be implemented with various
relevant groups and fellowship
implemented with various techniques
groups and fellowship and
and fellowship and research
fellowship and research internships
and research internships for
research internships for students
from smr to log
smr to log chains
summary four years of
four years of research
years of research on
global mobile data traffic
of research on windows
mobile data traffic forecast
research on windows nt
data traffic forecast update
on windows nt have
windows nt have taught
nt have taught us
have taught us that
taught us that we
us that we made
that we made the
we made the right
made the right choice
the right choice in
right choice in leaving
choice in leaving the
in leaving the unix
leaving the unix behind
windows nt is an
nt is an exiting
we abstract this write
years ahead of its
ahead of its competition
set with the read
with the read timestamps
in its implementation and
its implementation and in
implementation and in the
and in the actual
and assume highly available
in the actual services
assume highly available logs
the actual services offered
it took quite some
took quite some time
set with written values
quite some time to
some time to reach
time to reach the
to reach the same
reach the same level
the same level of
same level of knowledge
level of knowledge and
of knowledge and insight
knowledge and insight we
and insight we used
insight we used to
we used to have
used to have of
to have of unix
have of unix systems
action should be either
should be either committed
but now that we
be either committed or
now that we have
either committed or aborted
that we have arrived
committed or aborted in
we have arrived at
or aborted in all
have arrived at that
aborted in all its
arrived at that same
in all its logs
at that same knowledge
that same knowledge point
and therefore cannot be
is it clear that
therefore cannot be removed
it clear that our
cannot be removed from
clear that our research
be removed from any
that our research is
removed from any of
our research is making
from any of them
research is making progress
any of them before
is making progress faster
of them before the
making progress faster than
them before the result
progress faster than ever
before the result is
faster than ever before
the result is published
multicast routing in datagram
routing in datagram internetworks
in datagram internetworks and
datagram internetworks and extended
working with windows nt
internetworks and extended lans
with windows nt requires
windows nt requires certain
nt requires certain level
requires certain level of
the committing tm appends
certain level of resilience
acm transactions on computer
committing tm appends a
transactions on computer systems
tm appends a gc
appends a gc entry
not because of flaws
a gc entry to
because of flaws in
gc entry to all
of flaws in the
entry to all the
flaws in the operating
to all the transaction
in the operating system
all the transaction s
the transaction s logs
transaction s logs after
s logs after receiving
but because of the
logs after receiving an
because of the zealous
after receiving an acknowledgement
of the zealous attacks
receiving an acknowledgement that
the zealous attacks by
an acknowledgement that they
zealous attacks by colleagues
acknowledgement that they all
attacks by colleagues and
that they all registered
by colleagues and other
they all registered the
colleagues and other researchers
all registered the transaction
registered the transaction s
the transaction s result
publishing papers about research
an om can invoke
papers about research performed
om can invoke log
about research performed on
can invoke log prefix
research performed on windows
invoke log prefix truncation
performed on windows nt
log prefix truncation if
on windows nt is
prefix truncation if the
windows nt is still
truncation if the prefix
nt is still quite
if the prefix was
is still quite difficult
the prefix was summarized
still quite difficult as
quite difficult as many
difficult as many of
as many of our
and all its transactions
many of our peer
all its transactions have
of our peer still
its transactions have corresponding
transactions have corresponding gc
our peer still believe
have corresponding gc entries
peer still believe that
still believe that no
believe that no good
that no good research
then waits for the
no good research can
waits for the entry
good research can be
for the entry to
research can be performed
the entry to appear
can be performed on
entry to appear in
be performed on windows
to appear in the
performed on windows nt
appear in the log
a transaction is committed
we hope that eventually
transaction is committed if
hope that eventually the
is committed if and
that eventually the advanced
committed if and only
eventually the advanced technical
if and only if
the advanced technical nature
and only if it
advanced technical nature of
only if it is
technical nature of the
if it is written
nature of the operating
it is written to
of the operating system
is written to all
the operating system will
written to all logs
operating system will prevail
system will prevail in
will prevail in the
prevail in the discussion
and it does not
it does not conflict
does not conflict with
not conflict with previous
and that we can
conflict with previous transactions
that we can have
with previous transactions on
we can have a
previous transactions on any
can have a community
transactions on any of
have a community where
on any of them
a community where research
community where research results
where research results can
research results can be
conflicts are violations of
results can be shared
are violations of read
can be shared without
be shared without sarcasm
shared without sarcasm or
without sarcasm or the
sarcasm or the risk
or the risk of
the risk of igniting
risk of igniting yet
of igniting yet another
igniting yet another holy
yet another holy war
read or writewrite order
each om checks for
om checks for local
checks for local conflicts
for local conflicts by
local conflicts by checking
conflicts by checking timestamps
by checking timestamps in
checking timestamps in the
timestamps in the prefix
in the prefix of
the prefix of the
prefix of the log
of the log up
the log up to
log up to the
up to the transaction
to the transaction entry
and sends its local
sends its local result
and analysis of a
analysis of a peer
to the calling tm
if all return success
then the transaction has
the transaction has committed
otherwise it has aborted
the tm notifies the
tm notifies the client
notifies the client of
the client of the
client of the transaction
of the transaction result
the transaction result and
transaction result and instructs
result and instructs the
and instructs the oms
instructs the oms to
the oms to place
oms to place this
to place this result
place this result in
this result in the
result in the logs
the oms notify the
oms notify the tm
notify the tm once
the tm once the
tm once the results
once the results are
the results are logged
robustness in case of
in case of a
case of a tm
of a tm or
a tm or om
tm or om crash
or a missing result
a missing result or
missing result or gc
result or gc entry
due to message loss
another tm may read
tm may read the
may read the transaction
read the transaction entry
expert testimony of professor
the transaction entry in
testimony of professor david
transaction entry in one
of professor david j
entry in one of
in one of the
one of the logs
scaling virtual worlds with
and continue the certification
virtual worlds with a
continue the certification and
worlds with a physical
the certification and gc
with a physical metaphor
certification and gc process
if a tm places
a tm places a
tm places a transaction
places a transaction entry
a transaction entry in
transaction entry in a
entry in a strict
in a strict subset
a strict subset of
strict subset of the
subset of the transaction
of the transaction s
the transaction s log
transaction s log set
when another tm is
another tm is instructed
tm is instructed to
is instructed to fix
instructed to fix this
it cannot tell whether
cannot tell whether the
tell whether the original
whether the original tm
the original tm is
original tm is crashed
tm is crashed or
is crashed or slow
we introduce poison entries
the fixing tm places
fixing tm places a
tm places a poison
places a poison entry
a poison entry in
poison entry in the
entry in the logs
in the logs that
the logs that miss
logs that miss the
that miss the original
miss the original entry
a poison is interpreted
poison is interpreted as
is interpreted as a
interpreted as a transaction
as a transaction entry
a transaction entry with
transaction entry with a
entry with a conflict
the original entry may
original entry may either
entry may either arrive
may either arrive eventually
either arrive eventually or
arrive eventually or not
and the following are
the following are ignored
any tm can therefore
tm can therefore observe
can therefore observe the
therefore observe the log
observe the log and
the log and consistently
log and consistently determine
and consistently determine the
consistently determine the state
determine the state of
the state of the
state of the transaction
without a race hazard
prediction errors if there
errors if there are
if there are no
there are no prediction
are no prediction errors
there are no aborts
if the transaction accesses
the transaction accesses an
transaction accesses an object
accesses an object that
an object that was
object that was not
that was not predicted
uwin unix for windows
this object has no
object has no reserved
has no reserved version
no reserved version for
the usenix windows nt
reserved version for it
usenix windows nt workshop
accessing it can therefore
it can therefore result
can therefore result in
therefore result in a
result in a conflict
in a conflict of
a conflict of the
conflict of the transaction
of the transaction or
the transaction or of
transaction or of the
or of the following
of the following ones
no conflict would occur
but if one does
if one does it
one does it will
does it will be
it will be detected
will be detected at
be detected at certification
detected at certification time
and result in an
result in an abort
in an abort of
an abort of a
abort of a transaction
performance may be slightly
may be slightly reduced
but consistency is maintained
a platform for distributed
platform for distributed service
for distributed service deployment
if a transaction does
distributed service deployment in
a transaction does not
service deployment in end
transaction does not access
deployment in end user
does not access an
in end user homes
not access an object
access an object that
an object that was
object that was predicted
the tm must still
tm must still release
must still release the
still release the reservation
release the reservation when
the reservation when the
reservation when the transaction
when the transaction ends
this reservation might slow
reservation might slow the
might slow the processing
slow the processing of
the processing of other
processing of other transactions
of other transactions that
other transactions that wait
transactions that wait for
that wait for its
wait for its release
but would not break
would not break consistency
if a tm is
a tm is suspected
tm is suspected as
is suspected as failed
its reservations are revoked
this may harm performance
but cannot break consistency
th edition with source
edition with source code
evaluation we evaluate acid
rain by comparing its
by comparing its performance
comparing its performance to
its performance to the
performance to the classical
to the classical approach
the classical approach that
classical approach that does
approach that does not
that does not use
does not use prediction
not use prediction and
use prediction and compare
prediction and compare its
and compare its certification
compare its certification protocol
its certification protocol with
certification protocol with other
protocol with other certification
with other certification schemes
we use a custom
simulating each of the
each of the agents
of the agents in
the agents in the
agents in the system
in the system clients
our workloads are an
workloads are an adaptation
are an adaptation of
an adaptation of the
adaptation of the transactional
of the transactional ycsb
the transactional ycsb specification
based on the original
each transaction has a
transaction has a set
has a set of
a set of read
update operations spread along
operations spread along its
spread along its execution
object accesses follow one
accesses follow one of
follow one of two
one of two different
of two different random
two different random distributions
where each object is
each object is chosen
object is chosen uniformly
is chosen uniformly at
chosen uniformly at random
the design and implementation
design and implementation of
and implementation of the
gc logs are truncated
logs are truncated to
are truncated to conserve
truncated to conserve resources
to conserve resources and
conserve resources and to
resources and to reduce
and to reduce log
to reduce log replay
reduce log replay time
log replay time on
replay time on om
time on om recovery
each om occasionally summarizes
om occasionally summarizes the
occasionally summarizes the log
summarizes the log prefix
and places this summary
places this summary in
this summary in the
summary in the log
the presence of a
presence of a summary
of a summary of
a summary of the
summary of the log
of the log up
the log up to
log up to a
up to a certain
to a certain entry
a certain entry is
what s new in
certain entry is not
s new in windows
entry is not sufficient
is not sufficient to
not sufficient to allow
sufficient to allow truncation
to allow truncation at
allow truncation at that
truncation at that entry
this reason is that
reason is that truncation
is that truncation must
that truncation must not
truncation must not break
must not break transaction
not break transaction certification
prediction our first test
our first test scenario
first test scenario imposes
test scenario imposes a
scenario imposes a load
imposes a load substantially
a load substantially below
load substantially below the
substantially below the system
below the system s
the system s capacity
system s capacity with
each transaction reads and
transaction reads and writes
the simulation is faithful
simulation is faithful to
is faithful to the
faithful to the algorithm
rx for data center
for data center communication
data center communication scalability
with the exception of
the exception of a
exception of a small
of a small shortcut
a small shortcut oms
small shortcut oms grant
shortcut oms grant reservations
oms grant reservations by
grant reservations by arrival
reservations by arrival time
by arrival time rather
arrival time rather than
time rather than by
rather than by timestamp
this results in deadlocks
results in deadlocks in
in deadlocks in high
deadlocks in high contention
in high contention scenarios
and these are resolved
these are resolved with
are resolved with timeouts
first we vary prediction
we vary prediction accuracy
the average ratio of
average ratio of objects
ratio of objects the
of objects the predictor
objects the predictor guesses
the predictor guesses out
predictor guesses out of
guesses out of the
out of the set
of the set the
the set the transaction
set the transaction eventually
the transaction eventually accesses
is equivalent to no
equivalent to no prediction
to no prediction and
no prediction and no
prediction and no reservation
and an accuracy of
means predicting all accesses
increasing contention by decreasing
contention by decreasing the
by decreasing the number
decreasing the number of
the number of objects
nick vasilatos and werner
vasilatos and werner vogels
live streaming with utilities
do you need source
you need source with
need source with that
panel at the usenix
at the usenix windows
the usenix windows nt
load with a hot
usenix windows nt workshop
increasing contention by increasing
contention by increasing the
by increasing the hot
commit rate drops as
rate drops as contention
drops as contention rises
summary in usenix login
accurate prediction reduces or
prediction reduces or even
reduces or even eliminates
or even eliminates this
even eliminates this drop
an architecture for scalable
architecture for scalable and
for scalable and fault
in highest contention scenarios
even with moderate prediction
with moderate prediction accuracy
we obtain significant improvement
obtain significant improvement over
significant improvement over the
improvement over the classical
over the classical approach
unix application portability to
application portability to windows
portability to windows nt
we define slack to
to windows nt via
define slack to be
windows nt via an
slack to be the
nt via an alternative
to be the average
via an alternative environment
be the average ratio
an alternative environment subsystem
the average ratio between
average ratio between the
ratio between the number
between the number of
the usenix windows nt
the number of accesses
usenix windows nt workshop
number of accesses predicted
of accesses predicted and
accesses predicted and the
predicted and the number
and the number of
the number of objects
number of objects accessed
of objects accessed by
objects accessed by the
accessed by the transaction
if a transaction accesses
then with a slack
with a slack of
it would reserve another
now with uniform random
with uniform random load
uniform random load and
random load and a
load and a variable
and a variable number
a variable number of
variable number of objects
the effect of using
effect of using a
of using a perfect
using a perfect predictor
with predictors that overpredict
predictors that overpredict by
that overpredict by factors
overpredict by factors of
the impact of overprediction
impact of overprediction is
of overprediction is surprisingly
overprediction is surprisingly minor
protect the future of
the future of computing
future of computing technology
a finding that should
ordering transactions in advance
transactions in advance reduces
in advance reduces conflicts
advance reduces conflicts and
reduces conflicts and increases
conflicts and increases commit
and increases commit ratio
high conflict rates occur
conflict rates occur without
rates occur without with
occur without with uniform
without with uniform access
with uniform access to
uniform access to a
access to a small
to a small number
a small number of
small number of objects
and high probability of
high probability of accessing
probability of accessing a
of accessing a hotzone
transparent error correction for
even inaccurate prediction is
error correction for lambda
inaccurate prediction is significant
correction for lambda networks
prediction is significant in
for lambda networks mahesh
is significant in high
lambda networks mahesh balakrishnan
significant in high contention
compared to the the
to the the classical
the the classical approach
commit ratio is affected
ratio is affected if
is affected if the
affected if the predictor
if the predictor reserves
the predictor reserves unnecessary
predictor reserves unnecessary objects
reserves unnecessary objects by
unnecessary objects by a
objects by a factor
by a factor of
a factor of slack
note that when all
that when all accesses
when all accesses are
all accesses are to
accesses are to the
are to the hot
to the hot zone
abstract the global network
the global network of
global network of datacenters
network of datacenters is
of datacenters is emerging
datacenters is emerging as
is emerging as an
commit rates are lower
emerging as an important
rates are lower with
as an important distributed
are lower with imperfect
an important distributed systems
lower with imperfect prediction
important distributed systems paradigm
with imperfect prediction than
distributed systems paradigm commodity
imperfect prediction than in
systems paradigm commodity clusters
prediction than in the
paradigm commodity clusters running
than in the uniform
commodity clusters running high
in the uniform random
the uniform random case
uniform random case with
speed lambda networks across
lambda networks across hundreds
networks across hundreds of
across hundreds of milliseconds
hundreds of milliseconds of
of milliseconds of network
milliseconds of network latency
packet loss on long
haul networks can cripple
networks can cripple application
can cripple application performance
cripple application performance a
application performance a loss
performance a loss rate
a loss rate of
this is because all
is because all accesses
because all accesses to
all accesses to the
accesses to the hot
is sufficient to reduce
sufficient to reduce tcp
zone go through a
go through a single
through a single om
ip throughput by an
a single om that
throughput by an order
single om that becomes
by an order of
om that becomes a
an order of magnitude
that becomes a bottleneck
order of magnitude on
of magnitude on a
on the bright side
since object access conflicts
object access conflicts occur
access conflicts occur only
conflicts occur only at
occur only at a
only at a single
at a single shard
maelstrom is an edge
the reservations prevent deadlocks
is an edge appliance
reservations prevent deadlocks and
an edge appliance that
prevent deadlocks and result
edge appliance that masks
deadlocks and result in
appliance that masks packet
and result in perfect
that masks packet loss
result in perfect commit
masks packet loss transparently
in perfect commit ratio
packet loss transparently and
perfect commit ratio with
loss transparently and quickly
commit ratio with perfect
transparently and quickly from
ratio with perfect prediction
and quickly from inter
aggregating traffic for high
where some of the
some of the objects
of the objects belong
speed encoding and using
the objects belong to
encoding and using a
objects belong to a
and using a new
belong to a so
using a new forward
to a so called
a new forward error
a so called hot
new forward error correction
forward error correction scheme
error correction scheme to
correction scheme to handle
scheme to handle bursty
to handle bursty loss
and each access is
process communication primitives for
each access is either
communication primitives for programming
access is either to
primitives for programming distributed
is either to the
for programming distributed systems
introduction the emergence of
programming distributed systems robbert
either to the hot
the emergence of commodity
distributed systems robbert van
emergence of commodity clusters
systems robbert van renesse
of commodity clusters and
commodity clusters and datacenters
clusters and datacenters has
and datacenters has enabled
department of computer science
or outside of it
of computer science cornell
datacenters has enabled a
computer science cornell university
has enabled a new
science cornell university category
enabled a new class
chosen uniformly within each
a new class of
uniformly within each zone
new class of globally
class of globally distributed
representation the following position
of globally distributed highperformance
the following position paper
globally distributed highperformance applications
following position paper describes
distributed highperformance applications that
position paper describes a
highperformance applications that coordinate
paper describes a new
applications that coordinate over
describes a new interprocess
that coordinate over vast
a new interprocess communication
coordinate over vast geographical
over vast geographical distances
we set an average
set an average transaction
an average transaction per
average transaction per unit
primitive that is designed
that is designed to
a financial firm s
is designed to make
financial firm s new
designed to make it
firm s new york
to make it easier
s new york city
make it easier to
new york city datacenter
it easier to program
york city datacenter may
easier to program distributed
city datacenter may receive
to program distributed algorithms
datacenter may receive real
and transactions arrivals are
transactions arrivals are governed
arrivals are governed by
it is largely based
are governed by a
time updates from a
governed by a poisson
is largely based on
by a poisson process
updates from a stock
a poisson process with
from a stock exchange
poisson process with the
a stock exchange in
process with the required
stock exchange in switzerland
largely based on my
with the required tput
based on my experience
on my experience in
my experience in implementing
conduct financial transactions with
experience in implementing algorithms
financial transactions with banks
in implementing algorithms such
transactions with banks in
implementing algorithms such as
with banks in asia
algorithms such as distributed
such as distributed consensus
we are unaware of
cache data in london
are unaware of work
data in london for
unaware of work that
in london for locality
of work that uses
london for locality and
work that uses prediction
for locality and mirror
that uses prediction to
locality and mirror it
uses prediction to order
and mirror it to
prediction to order distributed
mirror it to kansas
to order distributed transactions
it to kansas for
order distributed transactions before
to kansas for disaster
distributed transactions before certification
subject to your evaluation
to your evaluation of
your evaluation of my
evaluation of my proposal
to interconnect these bandwidth
i would be happy
would be happy to
be happy to present
happy to present this
to present this idea
hungry datacenters across the
present this idea at
datacenters across the globe
this idea at the
idea at the workshop
uses static analysis to
static analysis to allow
analysis to allow separate
organizations are increasingly deploying
to allow separate workers
are increasingly deploying private
allow separate workers to
ipc allows processes to
increasingly deploying private lambda
allows processes to share
separate workers to process
processes to share information
deploying private lambda networks
to share information and
workers to process independent
share information and to
to process independent transactions
information and to synchronize
process independent transactions without
and to synchronize actions
independent transactions without synchronization
there are two classes
rain s suggestive prediction
are two classes of
two classes of ipc
gargamel determines the final
determines the final transaction
the final transaction order
and does not tolerate
does not tolerate false
not tolerate false positive
tolerate false positive prediction
false positive prediction errors
raw bandwidth is ubiquitous
bandwidth is ubiquitous and
is ubiquitous and cheaply
ubiquitous and cheaply available
and cheaply available in
cheaply available in the
mc has processes communicate
available in the form
has processes communicate send
in the form of
processes communicate send and
the form of existing
communicate send and receive
form of existing dark
send and receive messages
of existing dark fiber
it targets a different
targets a different setting
a different setting than
different setting than acid
while sm allows processes
sm allows processes to
allows processes to share
processes to share data
running and maintaining high
to share data directly
share data directly while
it is a fully
data directly while synchronizing
is a fully replicated
directly while synchronizing using
a fully replicated data
while synchronizing using such
fully replicated data store
synchronizing using such primitives
using such primitives as
free networks over this
such primitives as mutexes
networks over this fiber
primitives as mutexes and
over this fiber is
as mutexes and condition
this fiber is difficult
mutexes and condition variables
fiber is difficult and
is difficult and expensive
with a centralized scheduler
where processes are physically
capacity optical links are
processes are physically separated
optical links are almost
links are almost never
for an increasing number
are almost never congested
an increasing number of
increasing number of shards
mc is dominant as
is dominant as e
dominant as e orts
they drop packets for
as e orts to
drop packets for numerous
we run multiple simulations
packets for numerous reasons
e orts to support
for numerous reasons dirty
run multiple simulations to
orts to support the
multiple simulations to find
to support the sm
simulations to find the
support the sm paradigm
to find the maximal
the sm paradigm have
find the maximal tput
sm paradigm have not
the maximal tput the
paradigm have not been
maximal tput the system
have not been successful
tput the system can
the system can handle
examples of sm include
a global log forms
of sm include tcp
global log forms a
sm include tcp connections
log forms a bottleneck
pc with smr tms
with smr tms is
smr tms is blocked
tms is blocked by
is blocked by contention
blocked by contention much
by contention much earlier
contention much earlier than
the mc and sm
much earlier than acid
mc and sm paradigms
and sm paradigms are
sm paradigms are duals
paradigms are duals in
rain due to its
are duals in that
due to its longer
duals in that one
to its longer certification
in that one can
its longer certification time
that one can be
one can be implememted
can be implememted using
be implememted using the
implememted using the other
we briefly review here
briefly review here work
review here work related
here work related to
work related to acidrain
but they also each
related to acidrain s
they also each have
to acidrain s certification
also each have their
acidrain s certification protocol
each have their advantages
have their advantages and
their advantages and disadvantages
advantages and disadvantages when
and disadvantages when compared
one approach for certification
disadvantages when compared with
approach for certification is
when compared with one
for certification is to
compared with one another
certification is to use
is to use a
to use a single
use a single highly
it is useful to
is useful to consider
useful to consider how
available service that orders
for example and in
service that orders all
example and in different
that orders all transactions
and in different patterns
to consider how distributed
orders all transactions in
consider how distributed algorithms
all transactions in the
how distributed algorithms such
transactions in the system
ranging from singleton drops
distributed algorithms such as
from singleton drops to
algorithms such as replication
singleton drops to extended
drops to extended bursts
typically it has much
it has much to
has much to do
much to do with
to do with progress
in order for some
order for some process
for some process to
some process to be
process to be able
to be able to
be able to make
able to make a
to make a transition
a transaction commits if
transaction commits if and
commits if and only
congestion loss has been
if and only if
it needs to know
loss has been observed
and only if it
has been observed on
needs to know that
been observed on long
only if it has
to know that one
if it has no
know that one or
it has no conflicts
that one or more
has no conflicts with
haul networks as well
one or more other
no conflicts with previous
or more other processes
conflicts with previous committed
more other processes have
with previous committed transactions
other processes have reached
processes have reached a
have reached a particular
reached a particular milestone
and some data associated
some data associated with
data associated with that
associated with that milestone
transaction rate is high
a new leader in
such a global service
new leader in paxos
a global service becomes
global service becomes a
leader in paxos needs
service becomes a bottleneck
in paxos needs to
paxos needs to know
needs to know that
to know that a
know that a quorum
our system has no
that a quorum of
system has no such
has no such bottleneck
a quorum of acceptors
quorum of acceptors have
of acceptors have progressed
acceptors have progressed to
have progressed to its
progressed to its proposed
to its proposed ballot
its proposed ballot and
proposed ballot and it
ballot and it needs
and it needs to
it needs to know
needs to know what
to know what the
know what the highest
what the highest accepted
serialized all transactions when
the highest accepted proposals
all transactions when they
highest accepted proposals from
transactions when they enter
accepted proposals from those
when they enter the
proposals from those acceptors
they enter the system
from those acceptors are
enter the system to
the system to achieve
system to achieve a
to achieve a deterministic
achieve a deterministic order
many if not all
if not all distributed
not all distributed algorithms
all distributed algorithms can
despite nondeterministic operations the
distributed algorithms can be
nondeterministic operations the transactions
algorithms can be cleanly
operations the transactions take
can be cleanly expressed
be cleanly expressed this
cleanly expressed this way
as a collection of
they consider only stored
a collection of transition
consider only stored procedures
collection of transition specifications
of transition specifications that
transition specifications that specify
which enable this approach
specifications that specify under
that specify under which
specify under which conditions
under which conditions they
whereas we address long
ms w n s
which conditions they are
w n s e
we address long running
n s e figure
conditions they are enabled
address long running transactions
they are enabled and
long running transactions and
are enabled and what
running transactions and use
enabled and what state
transactions and use prediction
and what state they
and use prediction to
what state they need
use prediction to infer
state they need from
prediction to infer an
they need from other
to infer an order
example lambda network tional
need from other processes
lambda network tional lambdarail
note the similarity to
the similarity to knowledge
while the sm paradigm
the sm paradigm seems
sm paradigm seems the
transactions are also serialized
paradigm seems the best
are also serialized by
seems the best fit
also serialized by a
the best fit for
serialized by a central
best fit for this
by a central service
fit for this model
for this model of
this model of distributed
model of distributed algorithms
and then scheduled according
then scheduled according to
scheduled according to this
the paradigm is hard
according to this global
paradigm is hard to
to this global order
is hard to make
hard to make efficient
rain avoids a central
avoids a central service
and scalable in a
scalable in a physically
in a physically distributed
a physically distributed system
as has its crippling
it is notoriously errorprone
has its crippling effect
is notoriously errorprone as
its crippling effect on
notoriously errorprone as programmers
crippling effect on commodity
errorprone as programmers are
effect on commodity protocols
as programmers are having
targets a different problem
programmers are having difficulty
are having difficulty utilizing
having difficulty utilizing the
motivating research into loss
difficulty utilizing the synchronization
utilizing the synchronization primitives
the synchronization primitives correctly
resistant data transfer protocols
where it embraces non
the mc paradigm can
mc paradigm can be
paradigm can be used
can be used instead
be used instead but
determinism and separates execution
used instead but is
and separates execution from
instead but is awkward
separates execution from verification
but is awkward and
is awkward and error
the result is somewhat
result is somewhat analogous
prone as well it
is somewhat analogous to
somewhat analogous to our
as well it requires
analogous to our separation
well it requires the
to our separation of
our separation of optimistic
it requires the programmer
separation of optimistic ordering
requires the programmer to
of optimistic ordering and
optimistic ordering and conservative
the programmer to figure
ordering and conservative certification
programmer to figure out
to figure out which
figure out which processes
make it easier to
out which processes should
it easier to create
easier to create a
which processes should send
to create a practical
create a practical predictor
processes should send which
should send which data
send which data to
which data to which
certification scalability to evaluate
data to which destinations
scalability to evaluate the
to which destinations at
to evaluate the scalability
which destinations at which
evaluate the scalability of
the scalability of acid
destinations at which times
at which times in
which times in order
times in order to
rain s certification mechanism
in order to ensure
order to ensure that
to ensure that recipients
ensure that recipients of
that recipients of this
we avoid prediction and
recipients of this data
avoid prediction and measure
of this data can
prediction and measure the
this data can make
and measure the maximal
data can make progress
measure the maximal commit
the maximal commit rate
maximal commit rate it
conservative flow control mechanisms
commit rate it can
flow control mechanisms designed
rate it can accommodate
sometimes messages are lost
it can accommodate with
control mechanisms designed to
messages are lost if
can accommodate with an
mechanisms designed to deal
are lost if the
accommodate with an increasing
designed to deal with
with an increasing number
lost if the receiver
an increasing number of
to deal with the
increasing number of shards
if the receiver starts
deal with the systematic
the receiver starts execution
with the systematic congestion
receiver starts execution after
the systematic congestion of
starts execution after the
systematic congestion of the
execution after the sender
congestion of the commodity
after the sender has
of the commodity internet
the sender has started
the commodity internet react
sender has started sending
commodity internet react too
has started sending messages
internet react too sharply
started sending messages to
react too sharply to
sending messages to it
writes of objects chosen
too sharply to ephemeral
of objects chosen uniformly
sharply to ephemeral loss
objects chosen uniformly at
to ephemeral loss on
chosen uniformly at random
ephemeral loss on over
uniformly at random from
at random from a
random from a small
from a small set
a small set of
provisioned links a single
links a single packet
a single packet loss
single packet loss in
packet loss in ten
pray semantics of connectionless
loss in ten thousand
semantics of connectionless or
in ten thousand is
of connectionless or non
ten thousand is enough
thousand is enough to
is enough to reduce
enough to reduce tcp
blocking messaging primitives is
messaging primitives is one
primitives is one example
ip throughput to a
throughput to a third
to a third over
a third over a
often needless information is
needless information is sent
acidrain against two approaches
information is sent as
is sent as more
sent as more recent
as more recent information
more recent information makes
more details in section
recent information makes old
information makes old messages
makes old messages obsolete
and one in a
one in a thousand
in a thousand drops
a thousand drops it
thousand drops it by
using paxos again as
drops it by an
paxos again as an
it by an order
again as an example
by an order of
an order of magnitude
smr tms is two
in the stream of
the stream of values
stream of values that
phase commit with reliable
of values that acceptors
commit with reliable coordinators
values that acceptors accept
time applications are impacted
applications are impacted by
are impacted by the
only the most recent
impacted by the reliance
the most recent one
by the reliance of
most recent one is
the reliance of reliability
recent one is of
reliance of reliability mechanisms
one is of interest
of reliability mechanisms on
reliability mechanisms on acknowledgments
global log is an
mechanisms on acknowledgments and
log is an architecture
on acknowledgments and retransmissions
but most mc implementations
is an architecture where
most mc implementations will
an architecture where tms
mc implementations will carefully
architecture where tms submit
implementations will carefully deliver
limiting the latency of
will carefully deliver each
where tms submit all
carefully deliver each and
the latency of packet
deliver each and every
tms submit all transactions
each and every one
latency of packet recovery
submit all transactions to
of packet recovery to
all transactions to a
packet recovery to at
transactions to a single
recovery to at least
to a single global
to at least the
delaying delivery of the
a single global log
at least the round
single global log and
least the round trip
global log and check
the round trip time
delivery of the important
log and check conflicts
of the important information
and check conflicts on
the important information until
check conflicts on that
important information until all
conflicts on that single
information until all obsoleted
on that single log
until all obsoleted information
all obsoleted information has
obsoleted information has been
information has been delivered
has been delivered as
been delivered as well
if delivery is sequenced
this leads to wasting
each lost packet acts
leads to wasting resources
lost packet acts as
packet acts as a
acts as a virtual
as a virtual road
potential deadlock situations due
deadlock situations due to
situations due to flow
block in the fifo
due to flow control
in the fifo channel
to flow control leading
the fifo channel until
flow control leading to
fifo channel until it
has lower latency for
channel until it is
control leading to deadly
until it is recovered
lower latency for a
leading to deadly embrace
latency for a given
for a given throughput
and also obfuscates how
also obfuscates how the
obfuscates how the algorithms
resistant protocols is not
how the algorithms work
protocols is not an
pc since its faster
is not an alternative
since its faster certification
not an alternative in
its faster certification reduces
an alternative in corporate
faster certification reduces contention
alternative in corporate datacenters
it has no bottleneck
where standardization is the
has no bottleneck as
standardization is the key
a new class of
is the key to
new class of ipc
the key to low
no bottleneck as with
key to low and
bottleneck as with a
to low and predictable
as with a global
low and predictable maintenance
with a global log
that that tries to
and predictable maintenance costs
that tries to combine
tries to combine the
to combine the best
combine the best features
that has less overhead
the best features of
nei this work was
best features of sm
has less overhead in
features of sm and
this work was supported
of sm and mc
less overhead in small
work was supported in
overhead in small scale
was supported in part
supported in part by
in part by grants
from sm it inherits
part by grants from
sm it inherits direct
by grants from afosr
it inherits direct access
inherits direct access to
direct access to and
access to and synchro
while the parameters we
the parameters we choose
parameters we choose are
we choose are arbitrary
nization on state rather
ther is eliminating loss
on state rather than
is eliminating loss events
state rather than providing
the trends are robust
rather than providing a
eliminating loss events on
than providing a stream
loss events on a
providing a stream of
events on a network
a stream of state
on a network that
stream of state updates
choosing other parameters would
a network that could
other parameters would provide
network that could nsf
parameters would provide similar
that could nsf and
would provide similar trends
could nsf and intel
while from mc it
nsf and intel corporation
from mc it inherits
mc it inherits an
it inherits an efficient
inherits an efficient implementation
span thousands of miles
an efficient implementation over
efficient implementation over the
implementation over the existing
over the existing physical
the existing physical infrastructure
there is a need
the concept is that
is a need to
concept is that processes
a need to link
is that processes publish
need to link loss
that processes publish facts
which are information about
are information about milestones
information about milestones they
about milestones they have
milestones they have reached
side appliance locations of
and subscribe to new
appliance locations of packet
subscribe to new facts
locations of packet loss
of packet loss receive
the ipc interface is
ipc interface is similar
side appliance receiver buffer
interface is similar to
appliance receiver buffer overflow
is similar to topic
local recovery receiving end
phase commit for transaction
commit for transaction certification
the downside of these
downside of these approaches
of these approaches compared
these approaches compared to
but there are several
approaches compared to acid
there are several important
are several important semantic
several important semantic differences
kernel code no dropped
rain is that they
code no dropped packets
is that they require
no dropped packets figure
that they require a
they require a coordinator
require a coordinator that
a coordinator that performs
coordinator that performs transactions
that performs transactions to
interface is as follows
performs transactions to be
transactions to be highly
to be highly available
maelstrom communication path mask
communication path mask loss
path mask loss on
mask loss on the
loss on the link
this requires another consensus
it will be the
will be the publishers
be the publishers that
the publishers that actively
in addition to the
publishers that actively try
addition to the one
that actively try to
to the one at
actively try to push
the one at the
try to push new
one at the shard
to push new facts
at the shard itself
push new facts to
because recovery delays for
new facts to the
recovery delays for lost
facts to the subscribers
delays for lost packets
for lost packets translate
lost packets translate into
packets translate into dramatic
translate into dramatic reductions
into dramatic reductions in
dramatic reductions in application
paxos leaders publish new
leaders publish new ballots
publish new ballots and
new ballots and push
related work our transaction
ballots and push these
work our transaction ordering
and push these to
our transaction ordering protocol
push these to acceptors
transaction ordering protocol is
these to acceptors as
ordering protocol is inspired
to acceptors as acceptors
protocol is inspired by
because applications and os
acceptors as acceptors do
is inspired by a
applications and os networking
inspired by a state
as acceptors do not
and os networking stacks
acceptors do not necessarily
os networking stacks in
do not necessarily know
networking stacks in commodity
not necessarily know what
machine ordering mechanism suggested
stacks in commodity datacenters
ordering mechanism suggested by
necessarily know what the
mechanism suggested by lamport
know what the set
in commodity datacenters cannot
what the set of
commodity datacenters cannot be
the set of leaders
datacenters cannot be rewritten
set of leaders is
cannot be rewritten from
be rewritten from scratch
old ballots are automatically
ballots are automatically dropped
are automatically dropped from
automatically dropped from the
dropped from the transmission
from the transmission queue
is a promising solution
but we have generalized
a promising solution for
we have generalized the
promising solution for reliability
have generalized the protocol
it will be the
generalized the protocol to
will be the subscribers
the protocol to work
solution for reliability over
protocol to work with
be the subscribers that
to work with arbitrary
for reliability over long
work with arbitrary overlapping
the subscribers that actively
with arbitrary overlapping par
subscribers that actively poll
that actively poll the
actively poll the publishers
references the approaches of
the approaches of mdcc
leaders and learners both
and learners both subscribe
learners both subscribe to
both subscribe to acceptors
subscribe to acceptors accepting
to acceptors accepting pvalues
acceptors accepting pvalues and
accepting pvalues and poll
packet recovery latency is
pvalues and poll for
recovery latency is independent
and poll for these
latency is independent of
poll for these facts
is independent of the
independent of the rtt
of the rtt of
the rtt of the
rtt of the link
while fec codes have
fec codes have been
codes have been used
have been used for
been used for decades
used for decades within
for decades within link
are close to acid
as subscribers that su
rain s certification mechanism
subscribers that su ered
that su ered communication
su ered communication loss
faster commodity processors have
ered communication loss due
commodity processors have enabled
communication loss due to
processors have enabled packet
loss due to a
due to a network
to a network partition
a network partition or
network partition or having
level fec at end
partition or having been
rain separates the om
or having been temporarily
separates the om abstraction
having been temporarily subscribe
the om abstraction from
om abstraction from the
abstraction from the highly
leasing mechanism and fast
mechanism and fast recovery
we also address garbage
also address garbage collection
which cannot be done
cannot be done independently
due to a user
be done independently at
to a user closing
done independently at the
a user closing a
independently at the logs
user closing a laptop
will the interface requires
the interface requires that
end fec is very
interface requires that the
fec is very attractive
requires that the fact
is very attractive for
that the fact type
very attractive for inter
the fact type for
fact type for a
type for a par
continue to poll publishers
to poll publishers to
poll publishers to receive
publishers to receive facts
to receive facts they
receive facts they have
easy to deploy and
facts they have ticular
to deploy and customize
they have ticular topic
have ticular topic is
ticular topic is totally
topic is totally ordered
and does not require
does not require specialized
not require specialized equipment
require specialized equipment in
and those facts will
specialized equipment in the
those facts will missed
equipment in the network
in the network linking
the network linking the
network linking the datacenters
all this is invisible
this is invisible to
is invisible to the
invisible to the core
to the core application
the core application be
core application be delivered
application be delivered in
be delivered in order
host fec has two
fec has two major
has two major issues
two major issues first
any data can be
data can be made
can be made to
it s not transparent
requiring modification of the
modification of the end
a new paradigm for
new paradigm for building
paradigm for building scalable
but can be managed
for building scalable distributed
can be managed through
building scalable distributed systems
be managed through the
managed through the contally
through the contally ordered
the contally ordered by
contally ordered by tagging
ordered by tagging it
by tagging it with
tagging it with a
it with a sequence
with a sequence number
it s not necessarily
s not necessarily rapid
fec works best over
the hope is that
works best over high
hope is that fact
stable traffic rates and
based ipc will simplify
traffic rates and performs
ipc will simplify disbut
rates and performs poorly
will simplify disbut often
and performs poorly if
simplify disbut often times
performs poorly if the
disbut often times facts
poorly if the data
often times facts such
if the data rate
times facts such as
the data rate in
facts such as ballots
data rate in the
such as ballots are
rate in the channel
as ballots are totally
in the channel is
uses an architecture similar
the channel is low
ballots are totally ortributed
channel is low and
an architecture similar to
are totally ortributed programming
is low and sporadic
architecture similar to our
totally ortributed programming and
similar to our certification
ortributed programming and make
to our certification mechanism
programming and make it
and make it easier
make it easier to
it easier to reason
easier to reason dered
but addresses minitransactions that
to reason dered already
addresses minitransactions that are
minitransactions that are submitted
that are submitted as
are submitted as a
submitted as a whole
as in a single
in a single end
given a stream of
with no attempt to
a stream of facts
no attempt to order
stream of facts on
attempt to order potentially
of facts on some
to order potentially conflicting
facts on some topic
order potentially conflicting transactions
about safety and liveness
we address full transactions
the argument for this
we present the maelstrom
argument for this is
where the clients sequentially
for this is only
present the maelstrom error
this is only the
the clients sequentially access
is only the highest
the maelstrom error correction
clients sequentially access objects
maelstrom error correction appliance
sequentially access objects before
error correction appliance a
access objects before ending
most recent fact need
objects before ending a
correction appliance a rack
recent fact need be
before ending a transaction
appliance a rack of
fact need be delivered
a rack of proxies
need be delivered that
rack of proxies residing
be delivered that the
of proxies residing between
and use prediction to
proxies residing between a
delivered that the paradigm
residing between a datacenter
use prediction to order
between a datacenter and
prediction to order them
a datacenter and its
to order them in
datacenter and its wan
order them in advance
and its wan link
that the paradigm allows
the paradigm allows the
paradigm allows the programmer
allows the programmer to
the programmer to clearly
we believe our techniques
programmer to clearly eventually
believe our techniques could
our techniques could be
techniques could be used
could be used to
while older facts can
be used to reduce
older facts can be
used to reduce abort
facts can be dropped
to reduce abort rates
reduce abort rates of
abort rates of systems
maelstrom encodes fec packets
rates of systems using
also specify transitions and
encodes fec packets over
of systems using sinfonia
specify transitions and under
systems using sinfonia or
transitions and under which
using sinfonia or a
fec packets over traffic
sinfonia or a similar
and under which conditions
packets over traffic flowing
or a similar certification
under which conditions they
over traffic flowing through
which conditions they di
traffic flowing through it
a similar certification mechanism
flowing through it and
conditions they di erent
through it and routes
they di erent from
it and routes them
di erent from pub
and routes them to
routes them to a
them to a corresponding
to a corresponding appliance
a corresponding appliance at
corresponding appliance at the
appliance at the destination
at the destination datacenter
if no more facts
no more facts are
more facts are enabled
which decodes them and
facts are enabled without
decodes them and recovers
are enabled without having
them and recovers lost
enabled without having to
and recovers lost data
without having to worry
having to worry much
to worry much about
worry much about how
much about how are
maelstrom is completely transparent
about how are published
is completely transparent it
how are published but
completely transparent it does
are published but some
transparent it does not
published but some process
it does not require
but some process later
does not require modification
some process later subscribes
not require modification of
require modification of end
it these conditions are
these conditions are discovered
host software and is
software and is agnostic
and is agnostic to
is agnostic to the
agnostic to the network
will eventually receive the
to the network connecting
eventually receive the most
the network connecting the
receive the most recent
network connecting the datacenter
the most recent fact
assuming both publisher and
both publisher and subscriber
publisher and subscriber are
and subscriber are correct
it eliminates the dependence
eliminates the dependence of
the dependence of fec
dependence of fec recovery
of fec recovery latency
fec recovery latency on
these semantics are similar
recovery latency on the
semantics are similar to
latency on the data
are similar to the
on the data rate
similar to the anti
the data rate in
data rate in any
rate in any single
in any single node
entropy style of gossip
style of gossip protocols
but the underlying implementation
the underlying implementation can
node channel by encoding
underlying implementation can be
channel by encoding over
implementation can be anything
by encoding over the
encoding over the aggregated
over the aggregated traffic
the aggregated traffic leaving
there is also a
aggregated traffic leaving the
is also a control
traffic leaving the datacenter
also a control interface
a control interface that
control interface that controls
interface that controls routing
that controls routing of
controls routing of facts
routing of facts for
of facts for a
facts for a particular
maelstrom uses a new
for a particular topic
uses a new encoding
a new encoding scheme
new encoding scheme called
encoding scheme called layered
scheme called layered interleaving
paxos acceptors subscribe to
designed especially for time
acceptors subscribe to ballots
subscribe to ballots and
to ballots and to
ballots and to new
and to new proposals
sensitive packet recovery in
to new proposals from
packet recovery in the
new proposals from leaders
recovery in the presence
in the presence of
the presence of bursty
presence of bursty loss
when the leader publishes
the leader publishes one
leader publishes one of
publishes one of these
the contributions of this
contributions of this paper
of this paper are
this paper are as
paper are as follows
it is transmitted to
is transmitted to all
transmitted to all subscribers
and the underlying communication
the underlying communication layer
underlying communication layer will
highly available storage for
communication layer will continue
available storage for interactive
end fec for long
storage for interactive services
layer will continue retransmission
will continue retransmission until
continue retransmission until either
retransmission until either acknowledged
distance communication between datacenters
until either acknowledged or
either acknowledged or another
acknowledged or another fact
or another fact renders
another fact renders it
fact renders it obsolete
and argue that the
argue that the rate
that the rate sensitivity
the rate sensitivity of
rate sensitivity of fec
sensitivity of fec codes
of fec codes and
fec codes and the
codes and the opacity
and the opacity of
the opacity of their
opacity of their implementations
of their implementations present
their implementations present major
implementations present major obstacles
present major obstacles to
major obstacles to their
obstacles to their usage
a gateway appliance that
gateway appliance that transparently
appliance that transparently aggregates
that transparently aggregates traffic
transparently aggregates traffic and
aggregates traffic and encodes
traffic and encodes over
and encodes over the
encodes over the resulting
over the resulting high
we describe layered interleaving
a new fec scheme
new fec scheme used
fec scheme used by
scheme used by maelstrom
used by maelstrom where
by maelstrom where for
maelstrom where for constant
where for constant encoding
for constant encoding overhead
constant encoding overhead the
encoding overhead the latency
overhead the latency of
the latency of packet
latency of packet recovery
of packet recovery degrades
packet recovery degrades gracefully
recovery degrades gracefully as
a transactional record manager
degrades gracefully as losses
transactional record manager for
gracefully as losses get
record manager for shared
as losses get burstier
manager for shared flash
we discuss implementation considerations
we built two versions
built two versions of
two versions of maelstrom
one runs in user
runs in user mode
while the other runs
the other runs within
other runs within the
runs within the linux
within the linux kernel
we evaluate maelstrom on
evaluate maelstrom on emulab
and show that it
show that it provides
that it provides near
it provides near lossless
provides near lossless tcp
ip throughput and latency
throughput and latency over
swift institute swift institute
and latency over lossy
institute swift institute working
latency over lossy links
swift institute working paper
institute working paper no
and recovers packets with
recovers packets with latency
packets with latency independent
with latency independent of
latency independent of the
independent of the rtt
of the rtt of
the rtt of the
rtt of the link
of the link and
a middleware for highperformance
the link and the
middleware for highperformance transaction
link and the rate
for highperformance transaction processing
and the rate in
the rate in any
rate in any single
in any single channel
model our focus is
our focus is on
focus is on pairs
is on pairs of
on pairs of geographically
pairs of geographically distant
of geographically distant datacenters
geographically distant datacenters that
distant datacenters that coordinate
datacenters that coordinate with
that coordinate with each
coordinate with each other
with each other in
each other in real
s dilemma ittay eyal
dilemma ittay eyal publication
ittay eyal publication date
this has long been
has long been a
long been a critical
been a critical distributed
a critical distributed computing
critical distributed computing paradigm
distributed computing paradigm in
computing paradigm in application
paradigm in application domains
in application domains such
application domains such as
domains such as finance
such as finance and
as finance and aerospace
similar requirements are arising
requirements are arising across
are arising across the
arising across the board
across the board as
the board as globalized
board as globalized enterprises
as globalized enterprises rely
globalized enterprises rely on
electronic copy available at
enterprises rely on networks
rely on networks for
on networks for high
speed communication and collaboration
boosting dbms performance by
dbms performance by parallelising
performance by parallelising write
by parallelising write transactions
the most general case
most general case of
general case of inter
cluster communication is one
communication is one where
is one where any
one where any node
where any node in
any node in one
node in one cluster
in one cluster can
one cluster can communicate
cluster can communicate with
can communicate with any
communicate with any node
with any node in
any node in the
node in the other
in the other cluster
we make no assumptions
make no assumptions about
no assumptions about the
assumptions about the type
about the type of
prediction of transaction behavior
the type of traffic
of transaction behavior has
type of traffic flowing
transaction behavior has the
of traffic flowing through
behavior has the potential
traffic flowing through the
has the potential to
flowing through the link
the potential to significantly
potential to significantly decrease
the miner s dilemma
to significantly decrease abort
miner s dilemma ittay
significantly decrease abort rates
s dilemma ittay eyal
decrease abort rates in
dilemma ittay eyal cornell
critical applications could send
abort rates in large
applications could send dynamically
ittay eyal cornell university
rates in large scale
could send dynamically generated
eyal cornell university abstract
in large scale transactional
send dynamically generated real
cornell university abstract an
large scale transactional systems
university abstract an open
scale transactional systems with
abstract an open distributed
transactional systems with high
time data such as
an open distributed system
data such as stock
systems with high contention
open distributed system can
such as stock quotes
distributed system can be
system can be secured
can be secured by
be secured by requiring
financial transactions and battleground
secured by requiring participants
transactions and battleground location
by requiring participants to
and battleground location updates
rain we employ prediction
requiring participants to present
we employ prediction to
participants to present proof
employ prediction to obtain
to present proof of
while enterprise applications could
present proof of work
enterprise applications could send
proof of work and
applications could send voip
of work and rewarding
could send voip streams
prediction to obtain soft
work and rewarding them
to obtain soft reservations
and rewarding them for
obtain soft reservations and
rewarding them for participation
ssh sessions and synchronous
soft reservations and implement
sessions and synchronous file
reservations and implement atomic
and synchronous file updates
and implement atomic transactions
synchronous file updates between
implement atomic transactions while
the bitcoin digital currency
file updates between offices
bitcoin digital currency introduced
atomic transactions while requiring
digital currency introduced this
transactions while requiring high
currency introduced this mechanism
while requiring high availability
requiring high availability only
high availability only in
availability only in a
only in a single
which is adopted by
packet loss typically occurs
in a single tier
loss typically occurs at
a single tier of
typically occurs at two
is adopted by almost
occurs at two points
single tier of independent
at two points in
adopted by almost all
two points in an
tier of independent logs
points in an end
by almost all contemporary
almost all contemporary digital
all contemporary digital currencies
contemporary digital currencies and
digital currencies and related
this allows for low
currencies and related services
end communication path between
communication path between two
path between two datacenters
a natural process leads
natural process leads participants
process leads participants of
leads participants of such
as shown in figure
participants of such systems
of such systems to
such systems to form
systems to form pools
rain s operations never
s operations never depend
where members aggregate their
operations never depend on
area network connecting them
never depend on a
network connecting them and
depend on a single
members aggregate their power
on a single machine
aggregate their power and
connecting them and at
a single machine by
them and at the
their power and share
and at the receiving
single machine by allowing
at the receiving end
power and share the
machine by allowing fast
and share the rewards
by allowing fast recovery
allowing fast recovery from
fast recovery from failures
recovery from failures and
from failures and performance
experience with bitcoin shows
failures and performance hiccups
with bitcoin shows that
loss in the lambda
bitcoin shows that the
in the lambda link
shows that the largest
the lambda link can
that the largest pools
lambda link can occur
the largest pools are
link can occur for
largest pools are often
can occur for many
pools are often open
occur for many reasons
allowing anyone to join
it has long been
has long been known
dirty or degraded fiber
long been known that
been known that a
known that a member
that a member can
malfunctioning or misconfigured equipment
a member can sabotage
member can sabotage an
can sabotage an open
sabotage an open pool
low receiver power and
an open pool by
receiver power and burst
open pool by seemingly
power and burst switching
pool by seemingly joining
and burst switching contention
by seemingly joining it
burst switching contention are
seemingly joining it but
switching contention are some
joining it but never
contention are some reasons
it but never sharing
but never sharing its
never sharing its proofs
sharing its proofs of
its proofs of work
the pool shares its
pool shares its revenue
shares its revenue with
its revenue with the
revenue with the attacker
and so each of
so each of its
each of its participants
of its participants earns
its participants earns less
we define and analyze
define and analyze a
and analyze a game
analyze a game where
benchmarking cloud serving systems
a game where pools
cloud serving systems with
game where pools use
serving systems with ycsb
where pools use some
pools use some of
use some of their
some of their participants
of their participants to
their participants to infiltrate
participants to infiltrate other
to infiltrate other pools
infiltrate other pools and
other pools and perform
pools and perform such
and perform such an
perform such an attack
with any number of
any number of pools
loss can also occur
can also occur at
attacks is not a
also occur at receiving
is not a nash
occur at receiving endhosts
not a nash equilibrium
at receiving endhosts within
receiving endhosts within the
endhosts within the destination
within the destination datacenter
we study the special
study the special cases
the special cases where
these are usually cheap
special cases where either
are usually cheap commodity
cases where either two
usually cheap commodity machines
where either two pools
cheap commodity machines prone
either two pools or
commodity machines prone to
two pools or any
machines prone to temporary
pools or any number
prone to temporary overloads
or any number of
to temporary overloads that
any number of identical
temporary overloads that cause
number of identical pools
overloads that cause packets
of identical pools play
that cause packets to
identical pools play the
cause packets to be
pools play the game
packets to be dropped
play the game and
to be dropped by
the game and the
be dropped by the
game and the rest
dropped by the kernel
and the rest of
by the kernel in
the rest of the
the kernel in bursts
rest of the participants
of the participants are
the participants are uninvolved
in both of these
both of these cases
of these cases there
this loss mode occurs
loss mode occurs with
these cases there exists
mode occurs with udp
cases there exists an
there exists an equilibrium
exists an equilibrium that
based traffic but not
traffic but not with
an equilibrium that constitutes
but not with tcp
equilibrium that constitutes a
that constitutes a tragedy
constitutes a tragedy of
a tragedy of the
tragedy of the commons
which advertises receiver windows
of the commons where
advertises receiver windows to
receiver windows to prevent
the commons where the
windows to prevent end
commons where the participating
we plan to build
where the participating pools
plan to build on
the participating pools attack
to build on our
participating pools attack one
build on our simulation
pools attack one another
on our simulation results
attack one another and
what are typical loss
our simulation results by
are typical loss rates
one another and earn
typical loss rates on
simulation results by implementing
loss rates on long
another and earn less
results by implementing acid
and earn less than
earn less than they
less than they would
than they would have
they would have if
would have if none
rain and exploring the
have if none had
and exploring the different
one source of information
if none had attacked
source of information is
exploring the different aspects
of information is teragrid
the different aspects of
different aspects of its
aspects of its performance
of its performance in
its performance in realistic
performance in realistic settings
the decision whether or
decision whether or not
of particular interest are
whether or not to
or not to attack
not to attack is
to attack is the
attack is the miner
is the miner s
an optical network interconnecting
the miner s dilemma
optical network interconnecting major
network interconnecting major supercomputing
interconnecting major supercomputing sites
major supercomputing sites in
supercomputing sites in the
different network topologies with
an instance of the
sites in the us
instance of the iterative
network topologies with a
of the iterative prisoner
topologies with a single
the iterative prisoner s
with a single datacenter
iterative prisoner s dilemma
a single datacenter and
teragrid has a monitoring
single datacenter and with
has a monitoring framework
datacenter and with multiple
a monitoring framework within
the game is played
and with multiple datacenters
game is played daily
monitoring framework within which
is played daily by
framework within which ten
played daily by the
within which ten sites
daily by the active
which ten sites periodically
by the active bitcoin
ten sites periodically send
the active bitcoin pools
sites periodically send each
periodically send each other
which apparently choose not
apparently choose not to
gbps streams of udp
choose not to attack
behavior in face of
streams of udp packets
in face of high
of udp packets and
face of high contention
udp packets and measure
if this balance breaks
packets and measure the
and measure the resulting
measure the resulting loss
the resulting loss rate
the revenue of open
revenue of open pools
rain should prove efficient
of open pools might
open pools might diminish
making them unattractive to
them unattractive to participants
where its overhead may
its overhead may be
overhead may be wasteful
each site measures the
site measures the loss
measures the loss rate
the loss rate to
loss rate to every
rate to every other
to every other site
every other site once
other site once an
site once an hour
resulting in a total
in a total of
is a digital currency
behavior in error prone
a digital currency that
in error prone scenarios
digital currency that is
currency that is gaining
that is gaining acceptance
loss rate measurements collected
rate measurements collected across
measurements collected across the
collected across the network
across the network every
the network every hour
performance with predictors of
with predictors of different
predictors of different qualities
with an estimated market
an estimated market capitalization
estimated market capitalization of
market capitalization of over
lightweight elasticity in shared
elasticity in shared storage
in shared storage databases
shared storage databases for
storage databases for the
databases for the cloud
for the cloud using
the cloud using live
of all such measurements
cloud using live data
bitcoin s security stems
using live data migration
all such measurements were
s security stems from
such measurements were over
security stems from a
stems from a robust
from a robust incentive
a robust incentive system
participants are required to
are required to provide
required to provide expensive
to provide expensive proofs
provide expensive proofs of
expensive proofs of work
and they are rewarded
they are rewarded according
are rewarded according to
rewarded according to their
according to their efforts
this architecture has proved
architecture has proved both
has proved both stable
proved both stable and
both stable and scalable
of them were over
and it is used
it is used by
is used by most
used by most contemporary
by most contemporary digital
most contemporary digital currencies
contemporary digital currencies and
digital currencies and related
currencies and related services
after eliminating a single
eliminating a single site
that dropped incoming packets
dropped incoming packets steadily
incoming packets steadily at
packets steadily at a
steadily at a rate
at a rate of
live migration in shared
migration in shared nothing
in shared nothing databases
shared nothing databases for
nothing databases for elastic
databases for elastic cloud
for elastic cloud platforms
of the remainder were
the remainder were over
our results apply to
results apply to all
apply to all such
to all such incentive
all such incentive systems
but we use bitcoin
we use bitcoin terminology
use bitcoin terminology and
bitcoin terminology and examples
terminology and examples since
and examples since it
examples since it serves
these numbers reflect the
since it serves as
numbers reflect the loss
it serves as an
reflect the loss rate
serves as an active
the loss rate experienced
as an active and
loss rate experienced for
an active and archetypal
rate experienced for udp
active and archetypal example
experienced for udp traffic
for udp traffic on
udp traffic on an
traffic on an end
bitcoin implements its incentive
implements its incentive systems
its incentive systems with
incentive systems with a
systems with a data
with a data structure
a data structure called
end path and may
data structure called the
path and may not
structure called the blockchain
and may not generalize
may not generalize to
not generalize to tcp
generalize to tcp packets
the blockchain is a
blockchain is a serialization
is a serialization of
a serialization of all
serialization of all bitcoin
of all bitcoin transactions
we do not know
do not know if
not know if packets
it is a single
know if packets were
is a single global
if packets were dropped
a single global ledger
packets were dropped within
single global ledger maintained
were dropped within the
global ledger maintained by
dropped within the optical
ledger maintained by an
within the optical network
maintained by an open
the optical network or
by an open distributed
optical network or at
an open distributed system
network or at intermediate
or at intermediate devices
at intermediate devices within
intermediate devices within either
devices within either datacenter
since anyone can join
anyone can join the
can join the open
join the open system
the open system and
though it s unlikely
open system and participate
it s unlikely that
system and participate in
s unlikely that they
and participate in maintaining
unlikely that they were
participate in maintaining the
that they were dropped
in maintaining the blockchain
they were dropped at
were dropped at the
dropped at the end
bitcoin uses a proof
uses a proof of
a proof of work
proof of work mechanism
of work mechanism to
work mechanism to deter
many of the mea
mechanism to deter attacks
surements lost just one
lost just one or
participation requires exerting significant
just one or two
requires exerting significant computational
one or two packets
exerting significant computational resources
or two packets whereas
two packets whereas kernel
a participant who proves
nic losses are known
losses are known to
participant who proves she
are known to be
known to be bursty
who proves she has
proves she has exerted
she has exerted enough
has exerted enough resources
the dangers of replication
exerted enough resources with
dangers of replication and
enough resources with a
of replication and d
resources with a proof
with a proof of
a proof of work
proof of work is
of work is allowed
work is allowed to
is allowed to take
allowed to take a
to take a step
take a step in
a step in the
loss occurred on paths
step in the protocol
fast distributed transactions a
in the protocol by
occurred on paths where
the protocol by generating
distributed transactions a solution
protocol by generating a
on paths where levels
by generating a block
paths where levels of
where levels of optical
levels of optical link
of optical link utilization
participants are compensated for
are compensated for their
compensated for their efforts
for their efforts with
their efforts with newly
efforts with newly minted
with newly minted bitcoins
the process of creating
process of creating a
of creating a block
creating a block is
a block is called
block is called mining
were consistently lower than
and the participants miners
for partitioned database systems
in order to win
order to win the
to win the reward
many miners try to
miners try to generate
try to generate blocks
ruling out congestion as
out congestion as a
congestion as a possible
as a possible cause
the system automatically adjusts
system automatically adjusts the
automatically adjusts the difficulty
adjusts the difficulty of
a conclusion supported by
the difficulty of block
conclusion supported by dialogue
difficulty of block generation
supported by dialogue with
by dialogue with the
dialogue with the network
with the network administrators
such that one block
that one block is
one block is added
block is added every
minutes to the blockchain
this means that each
means that each miner
that each miner seldom
each miner seldom generates
miner seldom generates a
seldom generates a block
points are provided by
are provided by the
provided by the back
although its revenue may
its revenue may be
revenue may be positive
bone networks of tier
may be positive in
be positive in expectation
a miner may have
miner may have to
may have to wait
have to wait for
to wait for an
global crossing reports average
wait for an extended
crossing reports average loss
for an extended period
reports average loss rates
an extended period to
average loss rates between
extended period to create
period to create a
to create a block
create a block and
a block and earn
block and earn the
and earn the actual
earn the actual bitcoins
distributed main memory transaction
main memory transaction processing
memory transaction processing system
miners form mining pools
where all members mine
all members mine concurrently
members mine concurrently and
mine concurrently and they
concurrently and they share
and they share their
they share their revenue
share their revenue whenever
their revenue whenever one
revenue whenever one of
whenever one of them
one of them creates
of them creates a
them creates a block
on four of its
four of its six
of its six inter
pools are typically implemented
are typically implemented as
typically implemented as a
haul links for the
implemented as a pool
links for the month
as a pool manager
for the month of
a pool manager and
the month of december
pool manager and a
manager and a cohort
and a cohort of
a cohort of miners
the pool manager joins
pool manager joins the
manager joins the bitcoin
joins the bitcoin system
the bitcoin system as
bitcoin system as a
system as a single
as a single miner
instead of generating proof
of generating proof of
generating proof of work
it outsources the work
outsources the work to
the work to the
work to the miners
qwest reports loss rates
reports loss rates of
in order to evaluate
order to evaluate the
to evaluate the miners
evaluate the miners efforts
the pool manager accepts
pool manager accepts partial
manager accepts partial proof
accepts partial proof of
partial proof of work
proof of work and
of work and estimates
work and estimates each
and estimates each miner
estimates each miner s
each miner s power
miner s power according
s power according to
power according to the
according to the rate
to the rate with
the rate with which
rate with which it
with which it submits
which it submits such
it submits such partial
submits such partial proof
such partial proof of
partial proof of work
in either direction on
either direction on its
direction on its trans
when a miner generates
a miner generates a
pacific link for the
miner generates a full
verify replication for multi
generates a full proof
link for the same
a full proof of
for the same month
full proof of work
it sends it to
sends it to the
it to the pool
to the pool manager
the pool manager which
pool manager which publishes
manager which publishes this
which publishes this proof
publishes this proof of
this proof of work
proof of work to
we expect privately managed
of work to the
expect privately managed lambdas
work to the bitcoin
privately managed lambdas to
to the bitcoin system
managed lambdas to exhibit
lambdas to exhibit higher
to exhibit higher loss
exhibit higher loss rates
higher loss rates due
loss rates due to
the pool manager thus
rates due to the
due to the inherent
pool manager thus receives
to the inherent trade
manager thus receives the
thus receives the full
receives the full revenue
the full revenue of
full revenue of the
revenue of the block
of the block and
equipment quality and cost
the block and distributes
block and distributes it
and distributes it fairly
distributes it fairly according
it fairly according to
fairly according to its
according to its members
to its members power
many of the pools
of the pools are
the pools are open
pools are open they
are open they allow
open they allow any
as well as the
they allow any miner
well as the difficulty
allow any miner to
as the difficulty of
any miner to join
the difficulty of performing
miner to join them
difficulty of performing routine
to join them using
of performing routine maintenance
join them using a
performing routine maintenance on
them using a public
routine maintenance on longdistance
using a public internet
maintenance on longdistance links
a public internet interface
such open pools are
open pools are susceptible
pools are susceptible to
are susceptible to the
susceptible to the classical
to the classical block
the classical block withholding
classical block withholding attack
end paths as dropping
paths as dropping packets
as dropping packets at
dropping packets at rates
packets at rates of
where a miner sends
a miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
proof of work to
of work to the
work to the pool
to the pool manager
the pool manager and
pool manager and discards
manager and discards full
and discards full proof
discards full proof of
full proof of work
to capture a wide
capture a wide range
a wide range of
wide range of deployed
range of deployed networks
due to the partial
to the partial proof
the partial proof of
partial proof of work
proof of work it
of work it sends
work it sends to
it sends to the
sends to the pool
existing reliability options tcp
the miner is considered
ip is the default
miner is considered a
is the default reliable
is considered a regular
the default reliable communication
considered a regular pool
default reliable communication option
a regular pool member
reliable communication option for
regular pool member and
communication option for contemporary
pool member and the
option for contemporary networked
member and the pool
for contemporary networked applications
and the pool can
the pool can estimate
pool can estimate its
can estimate its power
exclusive embeddings in commodity
embeddings in commodity operating
in commodity operating systems
the attacker shares the
commodity operating systems and
attacker shares the revenue
operating systems and networking
shares the revenue obtained
systems and networking apis
the revenue obtained by
revenue obtained by the
obtained by the other
by the other pool
the other pool members
using time instead of
time instead of timeout
instead of timeout for
of timeout for fault
but does not contribute
most applications requiring reliable
applications requiring reliable communication
requiring reliable communication over
reliable communication over any
communication over any form
it reduces the revenue
over any form of
reduces the revenue of
any form of network
the revenue of the
form of network use
revenue of the other
of network use tcp
of the other members
but also its own
we provide necessary background
provide necessary background on
necessary background on the
background on the bitcoin
on the bitcoin protocol
pools and the classical
the problem with commodity
and the classical block
problem with commodity tcp
the classical block withholding
classical block withholding attack
block withholding attack in
withholding attack in section
attack in section ii
and specify our model
specify our model in
our model in section
model in section iii
for a broader view
a broader view of
broader view of the
view of the protocol
ip uses positive acknowledgments
of the protocol and
uses positive acknowledgments and
the protocol and ecosystem
positive acknowledgments and retransmissions
protocol and ecosystem the
acknowledgments and retransmissions to
and ecosystem the reader
and retransmissions to ensure
ecosystem the reader may
retransmissions to ensure reliability
the reader may refer
to ensure reliability the
reader may refer to
ensure reliability the sender
may refer to the
reliability the sender buffers
refer to the survey
the sender buffers packets
to the survey by
sender buffers packets until
the survey by bonneau
buffers packets until their
survey by bonneau et
packets until their receipt
by bonneau et al
until their receipt is
their receipt is acknowledged
receipt is acknowledged by
is acknowledged by the
acknowledged by the receiver
and resends if an
resends if an acknowledgment
if an acknowledgment is
an acknowledgment is not
acknowledgment is not received
is not received within
not received within some
received within some time
within some time period
in this work we
this work we analyze
work we analyze block
a lost packet is
we analyze block withholding
lost packet is received
analyze block withholding attacks
packet is received in
block withholding attacks among
is received in the
withholding attacks among pools
received in the form
in the form of
the form of a
form of a retransmission
of a retransmission that
a pool that employs
a retransmission that arrives
pool that employs the
retransmission that arrives no
that employs the pool
that arrives no earlier
employs the pool block
arrives no earlier than
the pool block withholding
pool block withholding attack
block withholding attack registers
withholding attack registers with
attack registers with the
registers with the victim
with the victim pool
the victim pool as
victim pool as a
pool as a regular
as a regular miner
rtts after the original
after the original send
the original send event
it receives tasks from
receives tasks from the
tasks from the victim
the sender has to
from the victim pool
sender has to buffer
the victim pool and
has to buffer each
victim pool and transfers
to buffer each packet
pool and transfers them
buffer each packet until
and transfers them to
each packet until it
transfers them to some
packet until it s
them to some of
until it s acknowledged
to some of its
some of its own
of its own miners
we call these infiltrating
call these infiltrating miners
rtt in lossless operation
and the mining power
and it has to
the mining power spent
it has to perform
mining power spent by
has to perform additional
power spent by a
to perform additional work
spent by a pool
perform additional work to
by a pool the
additional work to retransmit
from paxos to corfu
work to retransmit the
a pool the infiltration
to retransmit the packet
pool the infiltration rate
retransmit the packet if
the packet if it
packet if it does
if it does not
it does not receive
does not receive the
when electronic copy available
not receive the acknowledgment
electronic copy available at
any packets that arrive
packets that arrive with
that arrive with higher
arrive with higher sequence
with higher sequence numbers
higher sequence numbers than
sequence numbers than that
numbers than that of
than that of a
that of a lost
of a lost packet
a lost packet must
lost packet must be
packet must be queued
must be queued while
be queued while the
queued while the receiver
while the receiver waits
the receiver waits for
receiver waits for the
waits for the lost
for the lost packet
the lost packet to
lost packet to arrive
throughput financial banking application
financial banking application running
banking application running in
application running in a
running in a datacenter
in a datacenter in
a datacenter in new
datacenter in new york
in new york city
sending updates to a
the attacking pool s
updates to a sister
attacking pool s infiltrating
to a sister site
pool s infiltrating miners
a sister site in
s infiltrating miners deliver
sister site in switzerland
infiltrating miners deliver partial
miners deliver partial proofs
deliver partial proofs of
partial proofs of work
the rtt value between
rtt value between these
value between these two
between these two centers
the attacker transfers them
these two centers is
attacker transfers them to
two centers is typically
transfers them to the
them to the victim
to the victim pool
letting the attacked pool
the attacked pool estimate
attacked pool estimate their
pool estimate their power
when the infiltrating miners
the infiltrating miners deliver
infiltrating miners deliver a
miners deliver a full
deliver a full proof
a full proof of
full proof of work
the attacking pool discards
attacking pool discards it
in the case of
the case of a
case of a lost
of a lost packet
this attack affects the
concurrency control and availability
attack affects the revenues
control and availability in
affects the revenues of
and availability in multi
the revenues of the
all packets received within
revenues of the pools
packets received within the
of the pools in
the pools in several
pools in several ways
the victim pool s
victim pool s effective
pool s effective mining
s effective mining rate
effective mining rate is
mining rate is unchanged
milliseconds between the original
between the original packet
the original packet send
original packet send and
packet send and the
but its total revenue
send and the a
its total revenue is
total revenue is divided
revenue is divided among
is divided among more
divided among more miners
the attacker s mining
attacker s mining power
s mining power is
mining power is reduced
since some of its
some of its miners
of its miners are
its miners are used
miners are used for
are used for block
used for block withholding
h ets are generated
ets are generated from
are generated from alternate
generated from alternate disjoint
but it earns additional
from alternate disjoint sub
it earns additional revenue
earns additional revenue through
additional revenue through its
revenue through its infiltration
through its infiltration of
streams of data rather
its infiltration of the
of data rather than
infiltration of the other
data rather than from
of the other pool
rather than from consecutive
than from consecutive packets
the total effective mining
with an interleave index
total effective mining power
an interleave index of
effective mining power in
mining power in the
power in the system
in the system is
the system is reduced
the encoder would a
causing the bitcoin protocol
the bitcoin protocol to
bitcoin protocol to reduce
protocol to reduce the
to reduce the difficulty
on predictive modeling for
predictive modeling for optimizing
modeling for optimizing transaction
taking all these factors
for optimizing transaction execution
all these factors into
optimizing transaction execution in
these factors into account
transaction execution in parallel
g create correction packets
execution in parallel oltp
create correction packets separately
in parallel oltp systems
correction packets separately from
packets separately from three
we observe that a
separately from three disjoint
observe that a pool
from three disjoint sub
that a pool might
a pool might be
pool might be able
might be able to
be able to increase
able to increase its
to increase its revenue
increase its revenue by
its revenue by attacking
the first containing data
revenue by attacking other
first containing data packets
by attacking other pools
containing data packets numbered
data packets numbered a
packets numbered a c
numbered a c e
a c e g
c e g x
e g x x
each pool therefore makes
pool therefore makes a
therefore makes a choice
makes a choice of
a choice of whether
choice of whether to
of whether to attack
whether to attack each
to attack each of
attack each of the
each of the other
of the other pools
the other pools in
other pools in the
pools in the system
and with what infiltration
with what infiltration rate
this gives rise to
gives rise to the
rise to the pool
to the pool game
we specify this game
specify this game and
this game and provide
game and provide initial
and provide initial analysis
provide initial analysis in
initial analysis in section
analysis in section iv
in section v we
section v we analyze
v we analyze the
we analyze the scenario
analyze the scenario where
the scenario where exactly
scalable deferred update replication
scenario where exactly two
where exactly two of
exactly two of the
the second with data
two of the pools
second with data packets
of the pools take
with data packets numb
the pools take part
data packets numb d
pools take part in
packets numb d f
take part in the
numb d f h
part in the game
d f h x
in the game and
f h x x
the game and only
h x x bered
game and only one
and only one can
only one can attack
one can attack the
can attack the other
the attacker can always
attacker can always increase
can always increase its
always increase its revenue
increase its revenue by
its revenue by attacking
we conclude that in
conclude that in the
that in the general
in the general case
with any number of
any number of pools
attacks is not a
is not a nash
not a nash equilibrium
section vi deals with
vi deals with the
deals with the case
the case for determinism
with the case of
case for determinism in
the case of two
for determinism in database
case of two pools
determinism in database systems
and the third with
the third with data
third with data b
where each can attack
each can attack the
can attack the other
analysis becomes more complicated
becomes more complicated in
more complicated in two
complicated in two ways
the revenue of each
revenue of each pool
of each pool affects
each pool affects the
pool affects the revenue
affects the revenue of
the revenue of the
revenue of the other
of the other through
the other through the
other through the infiltrating
through the infiltrating miners
we prove that for
prove that for a
that for a static
for a static choice
a static choice of
static choice of infiltration
choice of infiltration rates
of infiltration rates the
infiltration rates the pool
rates the pool revenues
the pool revenues converge
once one pool changes
one pool changes its
pool changes its infiltration
changes its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the other
the latter may prefer
latter may prefer to
may prefer to change
prefer to change its
to change its infiltration
change its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the former
therefore the game itself
the game itself takes
interleaving adds burst tolerance
game itself takes multiple
adds burst tolerance to
itself takes multiple rounds
burst tolerance to fec
takes multiple rounds to
tolerance to fec but
multiple rounds to converge
to fec but exacerbates
fec but exacerbates its
but exacerbates its sensitivfigure
we show analytically that
show analytically that the
analytically that the game
that the game has
the game has a
game has a single
has a single nash
a single nash equilibrium
single nash equilibrium and
nash equilibrium and numerically
equilibrium and numerically study
and numerically study the
numerically study the equilibrium
separate encoding for ity
study the equilibrium points
encoding for ity to
the equilibrium points for
for ity to sending
equilibrium points for different
ity to sending rate
points for different pool
to sending rate with
for different pool sizes
sending rate with an
rate with an interleave
with an interleave index
an interleave index of
interleave index of i
for pools smaller than
index of i and
of i and an
i and an encoding
and an encoding rate
an encoding rate of
at the equilibrium point
the equilibrium point both
equilibrium point both pools
point both pools earn
both pools earn less
the sender would have
pools earn less than
sender would have to
earn less than they
would have to wait
less than they would
have to wait for
than they would have
to wait for odd
they would have in
wait for odd and
would have in the
for odd and even
have in the nonequilibrium
odd and even packets
in the nonequilibrium no
and even packets i
since pools can decide
pools can decide to
can decide to start
decide to start or
to start or stop
start or stop attacking
or stop attacking at
stop attacking at any
packets before sending any
attacking at any point
before sending any redundancy
sending any redundancy information
this can be modeled
can be modeled as
receipt of its retransmission
be modeled as the
of its retransmission have
modeled as the miner
its retransmission have to
as the miner s
retransmission have to be
the miner s dilemma
have to be buffered
miner s dilemma an
to be buffered at
s dilemma an instance
be buffered at the
dilemma an instance of
buffered at the rethese
an instance of the
at the rethese two
instance of the iterative
the rethese two obstacles
of the iterative prisoner
rethese two obstacles to
the iterative prisoner s
two obstacles to using
iterative prisoner s dilemma
obstacles to using fec
to using fec in
using fec in time
attacking is the dominant
is the dominant strategy
the dominant strategy in
tings rate sensitivity and
dominant strategy in each
rate sensitivity and burst
strategy in each iteration
sensitivity and burst susceptibility
and burst susceptibility are
burst susceptibility are innotice
susceptibility are innotice that
are innotice that for
but if the pools
innotice that for this
if the pools can
that for this commonplace
the pools can agree
for this commonplace scenario
pools can agree not
can agree not to
agree not to attack
the loss of terlinked
loss of terlinked through
both benefit in the
of terlinked through the
benefit in the long
terlinked through the tuning
in the long run
through the tuning knobs
an interleave of i
interleave of i and
of i and a
we address in section
i and a single
address in section vii
and a single packet
in section vii the
a single packet stops
section vii the case
single packet stops all
vii the case where
packet stops all traffic
the case where the
stops all traffic in
case where the participants
all traffic in the
where the participants are
traffic in the channel
the participants are an
in the channel to
participants are an arbitrary
the channel to the
are an arbitrary number
channel to the apa
an arbitrary number of
to the apa rate
arbitrary number of identical
the apa rate of
number of identical pools
there exists a symmetric
exists a symmetric equilibrium
a symmetric equilibrium in
symmetric equilibrium in which
equilibrium in which each
in which each participating
provides tolerance to a
which each participating pool
tolerance to a burst
each participating pool attacks
to a burst of
participating pool attacks each
a burst of up
pool attacks each of
burst of up to
attacks each of the
of up to c
each of the other
up to c i
of the other participating
to c i plication
the other participating pools
c i plication for
i plication for a
plication for a seventh
for a seventh of
a seventh of a
seventh of a second
as in the minority
in the minority two
a sequence of such
sequence of such consecutive
here too at equilibrium
of such consecutive packets
too at equilibrium all
at equilibrium all pools
equilibrium all pools earn
all pools earn less
pools earn less than
earn less than with
less than with the
than with the no
the burst tolerance of
burst tolerance of blocks
tolerance of blocks can
of blocks can have
blocks can have devastating
can have devastating effect
have devastating effect on
devastating effect on a
effect on a high
our results imply that
results imply that block
throughput an fec code
imply that block withholding
an fec code can
that block withholding by
fec code can be
block withholding by pools
code can be changed
withholding by pools leads
can be changed by
by pools leads to
be changed by modulating
pools leads to an
changed by modulating either
leads to an unfavorable
by modulating either the
to an unfavorable equilibrium
modulating either the c
either the c system
the c system where
c system where every
system where every spare
where every spare cycle
every spare cycle counts
due to the anonymity
to the anonymity of
the anonymity of miners
in applior the i
a single pool might
applior the i parameters
single pool might be
pool might be tempted
might be tempted to
be tempted to attack
increasing c enhances burst
c enhances burst tolercations
enhances burst tolercations with
leading the other pools
burst tolercations with many
the other pools to
tolercations with many fine
other pools to attack
pools to attack as
to attack as well
the implications might be
implications might be devastating
a lost packet ance
might be devastating for
lost packet ance at
be devastating for open
packet ance at the
devastating for open pools
ance at the cost
at the cost of
the cost of network
cost of network and
of network and encoding
if their revenues are
network and encoding overhead
their revenues are reduced
miners will prefer to
potencan potentially trigger a
will prefer to form
potentially trigger a butterfly
prefer to form closed
trigger a butterfly effect
to form closed pools
a butterfly effect of
form closed pools that
butterfly effect of missed
closed pools that cannot
effect of missed deadtially
pools that cannot be
of missed deadtially worsening
that cannot be attacked
missed deadtially worsening the
cannot be attacked in
deadtially worsening the packet
be attacked in this
worsening the packet loss
attacked in this manner
the packet loss experienced
packet loss experienced and
loss experienced and reducing
experienced and reducing lines
and reducing lines along
though this may be
reducing lines along a
this may be conceived
lines along a distributed
may be conceived as
along a distributed workflow
be conceived as bad
conceived as bad news
as bad news for
bad news for public
news for public mining
for public mining pools
on the whole it
the whole it may
whole it may be
it may be good
may be good news
be good news to
good news to the
news to the bitcoin
increasing i trades off
to the bitcoin system
i trades off recovery
trades off recovery periods
off recovery periods market
which prefers small pools
recovery periods market crashes
periods market crashes at
market crashes at stock
crashes at stock exchanges
we examine the practicality
examine the practicality of
the practicality of the
christmas latency for better
practicality of the attack
latency for better burst
of the attack in
for better burst tolerance
the attack in section
better burst tolerance without
attack in section viii
burst tolerance without adding
in section viii and
tolerance without adding overhead
section viii and discuss
without adding overhead sales
viii and discuss implications
adding overhead sales at
and discuss implications and
overhead sales at online
discuss implications and model
sales at online stores
implications and model extensions
and model extensions in
model extensions in section
extensions in section ix
winter storms at air
traffic control as mentioned
our contributions are the
contributions are the following
for higher values of
higher values of i
the encoder has to
encoder has to centers
has to centers overloaded
to centers overloaded networks
centers overloaded networks and
overloaded networks and end
definition of the pool
of the pool game
the pool game where
pool game where pools
game where pools in
where pools in a
hosts can exhibit wait
pools in a proof
can exhibit wait for
exhibit wait for more
wait for more data
for more data packets
more data packets to
ofwork secured system attack
data packets to be
secured system attack one
packets to be transmitted
system attack one another
to be transmitted before
attack one another with
be transmitted before it
one another with a
transmitted before it can
another with a pool
before it can continuous
with a pool block
it can continuous packet
a pool block withholding
can continuous packet loss
pool block withholding attack
with each lost packet
each lost packet driving
lost packet driving the
packet driving the send
driving the send error
the send error correction
send error correction packets
in the general case
system further and further
further and further out
and further out of
further out of sync
out of sync with
of sync with respect
sync with respect to
with respect to its
respect to its importantly
attacks is not an
is not an equilibrium
once the fec encoding
the fec encoding is
fec encoding is parameterized
encoding is parameterized real
with two minority pools
two minority pools participating
with a rate and
a rate and an
rate and an interleave
and an interleave to
an interleave to tolerate
the only nash equilibrium
interleave to tolerate a
only nash equilibrium is
to tolerate a certain
nash equilibrium is when
tolerate a certain burst
equilibrium is when the
a certain burst sensitive
is when the pools
certain burst sensitive flow
when the pools attack
burst sensitive flow control
the pools attack one
pools attack one another
and both earn less
both earn less than
earn less than if
less than if none
ip is unable to
than if none had
is unable to distinguish
if none had attacked
unable to distinguish length
to distinguish length b
miners therefore face the
therefore face the miner
face the miner s
the miner s dilemma
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
repeatedly choosing between attack
choosing between attack and
between attack and no
with multiple pools of
to between ephemeral loss
multiple pools of equal
between ephemeral loss modes
pools of equal size
ephemeral loss modes due
of equal size there
loss modes due to
equal size there is
modes due to transient
size there is a
due to transient contolerate
there is a symmetric
to transient contolerate a
is a symmetric nash
transient contolerate a burst
a symmetric nash equilibrium
contolerate a burst of
a burst of length
where all pools earn
all pools earn less
pools earn less than
earn less than if
less than if none
than if none had
if none had attacked
inefficient equilibria for open
equilibria for open pools
for open pools may
open pools may serve
all losses occurring gestion
pools may serve the
may serve the system
serve the system by
the system by reducing
system by reducing their
by reducing their attraction
reducing their attraction and
their attraction and pushing
or dirty fiber and
attraction and pushing miners
dirty fiber and persistent
and pushing miners towards
fiber and persistent in
pushing miners towards smaller
and persistent in bursts
miners towards smaller closed
persistent in bursts of
towards smaller closed pools
in bursts of size
bursts of size less
of size less than
size less than or
less than or equal
the classical block withholding
than or equal to
classical block withholding attack
or equal to b
block withholding attack is
equal to b are
withholding attack is as
to b are recovered
attack is as old
b are recovered with
is as old as
are recovered with congestion
as old as pools
old as pools themselves
the loss of one
but its use by
loss of one packet
its use by pools
of one packet out
use by pools has
one packet out of
by pools has not
packet out of ten
pools has not been
out of ten thousand
has not been suggested
of ten thousand is
not been suggested until
ten thousand is sufficient
been suggested until recently
thousand is sufficient to
is sufficient to reduce
sufficient to reduce tcp
we overview related attacks
overview related attacks and
related attacks and prior
ip throughput to a
attacks and prior work
throughput to a third
and prior work in
to a third of
prior work in section
a third of its
work in section x
third of its the
of its the same
its the same latency
the same latency and
same latency and this
and conclude with final
latency and this latency
conclude with final remarks
and this latency depends
with final remarks in
this latency depends on
final remarks in section
latency depends on the
remarks in section xi
depends on the i
on the i palossless
the i palossless maximum
if one packet is
one packet is lost
packet is lost out
p reliminaries b itcoin
is lost out of
reliminaries b itcoin and
lost out of a
b itcoin and p
out of a thousand
itcoin and p ooled
and p ooled m
p ooled m ining
ooled m ining bitcoin
m ining bitcoin is
ining bitcoin is a
bitcoin is a distributed
we d like to
d like to parameterize
like to parameterize the
to parameterize the encoding
parameterize the encoding to
the encoding to tolerate
encoding to tolerate a
to tolerate a maximum
tolerate a maximum burst
a maximum burst length
maximum burst length and
burst length and then
length and then have
and then have recovthroughput
then have recovthroughput collapses
have recovthroughput collapses to
recovthroughput collapses to a
collapses to a thirtieth
to a thirtieth of
a thirtieth of the
thirtieth of the maximum
ery latency depend on
latency depend on the
depend on the actual
on the actual burstiness
the actual burstiness of
actual burstiness of the
burstiness of the loss
at the same time
we would like the
would like the encoding
like the encoding to
the encoding to have
encoding to have a
fec constant rate for
clients use the system
constant rate for network
use the system by
rate for network provisioning
the system by issuing
for network provisioning and
system by issuing transactions
network provisioning and stability
and the system s
the system s only
system s only task
an fec scheme is
s only task is
fec scheme is required
only task is to
scheme is required where
task is to serialize
is required where latency
is to serialize transactions
required where latency of
to serialize transactions in
where latency of fec
serialize transactions in a
latency of fec encoders
transactions in a single
of fec encoders are
in a single ledger
fec encoders are typically
a single ledger and
encoders are typically parameterized
single ledger and reject
are typically parameterized with
ledger and reject transactions
typically parameterized with an
and reject transactions that
reject transactions that cannot
transactions that cannot be
that cannot be serialized
cannot be serialized due
be serialized due to
serialized due to conflicts
due to conflicts with
to conflicts with previous
conflicts with previous transactions
recovery degrades gracefully as
degrades gracefully as losses
gracefully as losses get
as losses get burstier
bitcoin transactions are protected
transactions are protected with
are protected with cryptographic
protected with cryptographic techniques
even tuple for each
with cryptographic techniques that
tuple for each outgoing
cryptographic techniques that ensure
for each outgoing sequence
techniques that ensure that
each outgoing sequence of
that ensure that only
outgoing sequence of r
ensure that only the
sequence of r data
that only the rightful
of r data packets
only the rightful owner
the rightful owner of
rightful owner of a
owner of a bitcoin
of a bitcoin can
a as the encoding
a bitcoin can transfer
as the encoding overhead
bitcoin can transfer it
the encoding overhead stays
encoding overhead stays constant
the transaction ledger is
transaction ledger is stored
ledger is stored by
is stored by a
stored by a network
c data and error
by a network of
data and error correction
a network of miners
and error correction packets
network of miners in
error correction packets are
of miners in a
correction packets are sent
miners in a data
in a data structure
a data structure caller
data structure caller the
structure caller the blockchain
redundancy information cannot be
revenue for proof of
information cannot be generated
for proof of work
cannot be generated and
proof of work the
be generated and sent
of work the blockchain
generated and sent until
work the blockchain records
and sent until all
the blockchain records the
sent until all r
blockchain records the transactions
until all r data
records the transactions in
all r data packets
the transactions in units
r data packets are
transactions in units of
data packets are available
in units of blocks
packets are available for
are available for sending
dubbed the genesis block
the latency of packet
latency of packet recovery
of packet recovery is
is defined as part
packet recovery is determined
defined as part of
recovery is determined by
as part of the
is determined by the
part of the protocol
determined by the rate
by the rate at
the rate at which
rate at which the
at which the sender
which the sender transmits
a valid block contains
the sender transmits data
valid block contains the
block contains the hash
contains the hash of
the hash of the
hash of the previous
of the previous block
generating error correction packets
the hash of the
hash of the transactions
maelstrom design and implemenfrom
of the transactions in
design and implemenfrom less
the transactions in the
transactions in the current
and implemenfrom less than
in the current block
implemenfrom less than r
less than r data
than r data packets
and a bitcoin address
r data packets at
a bitcoin address which
data packets at the
bitcoin address which is
packets at the sender
address which is to
at the sender is
which is to be
the sender is not
is to be credited
sender is not a
to be credited with
is not a viable
be credited with a
not a viable tation
credited with a reward
a viable tation option
with a reward for
viable tation option even
a reward for generating
tation option even though
reward for generating the
option even though the
for generating the block
even though the data
though the data rate
the data rate in
data rate in this
rate in this channel
in this channel is
any miner may add
this channel is low
miner may add a
may add a valid
add a valid block
a valid block to
valid block to the
block to the chain
to the chain by
or network could be
network could be operating
could be operating at
proving that it has
be operating at near
that it has spent
operating at near full
it has spent a
at near full capacity
has spent a certain
near full capacity with
spent a certain amount
full capacity with data
a certain amount of
capacity with data from
certain amount of work
with data from other
amount of work and
data from other senders
of work and publishing
work and publishing the
and publishing the block
publishing the block with
the block with the
we describe the maelstrom
block with the proof
describe the maelstrom appliance
with the proof over
the maelstrom appliance as
the proof over an
maelstrom appliance as a
proof over an overlay
appliance as a single
over an overlay network
as a single machine
an overlay network to
a single machine fec
overlay network to all
single machine fec is
network to all other
machine fec is also
to all other miners
fec is also very
is also very susceptible
also very susceptible to
very susceptible to bursty
susceptible to bursty losses
when a miner creates
a miner creates a
miner creates a block
it is compensated for
is compensated for its
compensated for its efforts
for its efforts with
its efforts with bitcoins
this compensation includes a
compensation includes a per
transaction fee paid by
fee paid by the
paid by the users
by the users electronic
the users electronic copy
users electronic copy available
we will show how
electronic copy available at
will show how more
show how more machines
how more machines can
more machines can be
machines can be added
can be added to
be added to terleaving
is a standard encoding
a standard encoding technique
standard encoding technique used
encoding technique used the
technique used the appliance
used the appliance to
the appliance to balance
appliance to balance encoding
to balance encoding load
balance encoding load and
encoding load and scale
load and scale to
and scale to multo
scale to multo combat
to multo combat bursty
multo combat bursty loss
where error correction pack
tiple gigabits per second
gigabits per second of
per second of traffic
whose transactions are included
a b c d
b c d x
c d x x
d x x e
and an amount of
x x e f
an amount of minted
x e f g
amount of minted bitcoins
e f g h
of minted bitcoins that
f g h x
minted bitcoins that are
g h x x
bitcoins that are thus
h x x appliance
that are thus introduced
are thus introduced into
thus introduced into the
introduced into the system
the work which a
work which a miner
which a miner is
a miner is required
miner is required to
is required to do
required to do is
to do is to
do is to repeatedly
is to repeatedly calculate
to repeatedly calculate a
repeatedly calculate a a
calculate a a hash
a a hash function
a hash function specifically
hash function specifically the
function specifically the sha
of a block header
lan mtu lambda jumbo
mtu lambda jumbo mtu
to indicate that he
lambda jumbo mtu recipe
indicate that he has
jumbo mtu recipe list
that he has performed
he has performed this
has performed this work
the miner provides a
miner provides a probabilistic
provides a probabilistic proof
a probabilistic proof as
probabilistic proof as follows
the generated block has
generated block has a
block has a nonce
has a nonce field
which can contain any
can contain any value
the miner places different
miner places different values
places different values in
different values in this
values in this field
in this field and
this field and calculates
field and calculates the
and calculates the hash
calculates the hash for
the hash for each
hash for each value
if the result of
the result of the
result of the hash
of the hash is
the hash is smaller
hash is smaller than
is smaller than a
smaller than a target
than a target value
the nonce is considered
nonce is considered a
is considered a solution
and the block is
the block is valid
the number of attempts
number of attempts to
of attempts to find
attempts to find a
to find a single
find a single hash
a single hash is
single hash is therefore
hash is therefore random
is therefore random with
therefore random with a
random with a geometric
with a geometric distribution
as each attempt is
each attempt is a
attempt is a bernoulli
is a bernoulli trial
a bernoulli trial with
bernoulli trial with a
trial with a success
with a success probability
a success probability determined
success probability determined by
probability determined by the
determined by the target
by the target value
at the existing huge
the existing huge hashing
existing huge hashing rates
huge hashing rates and
hashing rates and small
rates and small target
and small target values
the time to find
time to find a
to find a single
find a single hash
a single hash can
single hash can be
hash can be approximated
can be approximated by
be approximated by an
approximated by an exponential
by an exponential distribution
the average time for
average time for a
repair packets are injected
time for a miner
packets are injected into
for a miner to
are injected into stream
a miner to find
injected into stream transparently
miner to find a
to find a solution
find a solution is
a solution is therefore
solution is therefore proportional
is therefore proportional to
therefore proportional to its
proportional to its hashing
to its hashing rate
its hashing rate or
hashing rate or mining
rate or mining power
basic mechanism the basic
mechanism the basic operation
the basic operation of
basic operation of maelstrom
to maintain a constant
operation of maelstrom is
maintain a constant rate
of maelstrom is shown
a constant rate of
maelstrom is shown in
constant rate of bitcoin
is shown in figure
rate of bitcoin generation
and as part of
as part of its
part of its defense
of its defense against
its defense against denial
defense against denial of
against denial of service
denial of service and
of service and other
it intercepts outgoing data
service and other attacks
intercepts outgoing data packets
outgoing data packets and
data packets and routes
packets and routes them
and routes them to
the system normalizes the
routes them to the
system normalizes the rate
them to the destination
normalizes the rate of
to the destination datacenter
the rate of block
rate of block generation
generating and injecting fec
and injecting fec repair
injecting fec repair packets
fec repair packets into
repair packets into the
packets into the stream
the protocol deterministically defines
into the stream in
the stream in their
protocol deterministically defines the
stream in their wake
deterministically defines the target
defines the target value
the target value for
target value for each
value for each block
a repair packet consists
for each block according
repair packet consists of
each block according to
packet consists of a
block according to the
consists of a recipe
according to the time
of a recipe list
to the time required
a recipe list of
the time required to
recipe list of data
time required to generate
list of data packet
required to generate recent
of data packet identifiers
to generate recent blocks
data packet identifiers and
packet identifiers and fec
identifiers and fec information
and fec information generated
fec information generated from
information generated from these
generated from these packets
in the example in
the example in figure
is updated once every
this information is a
information is a simple
is a simple xor
the size of the
blocks such that the
size of the xor
such that the average
of the xor is
that the average time
the xor is equal
the average time for
xor is equal to
average time for each
is equal to the
time for each block
equal to the mtu
for each block to
to the mtu of
each block to be
the mtu of the
block to be found
mtu of the datacenter
to be found is
of the datacenter network
and to avoid fragmentation
to avoid fragmentation of
avoid fragmentation of repair
fragmentation of repair packets
of repair packets we
repair packets we require
packets we require that
note that the exponential
we require that the
that the exponential distribution
require that the mtu
the exponential distribution is
that the mtu of
exponential distribution is memoryless
the mtu of the
mtu of the long
if all miners mine
all miners mine for
miners mine for block
haul network be set
mine for block number
network be set to
for block number b
be set to a
set to a slightly
to a slightly larger
a slightly larger value
once the block is
the block is found
block is found at
is found at time
found at time t
this requirement is usually
requirement is usually satisfied
is usually satisfied in
usually satisfied in practical
all miners switch to
satisfied in practical deployments
miners switch to mine
switch to mine for
to mine for the
mine for the subsequent
for the subsequent block
the subsequent block b
since gigabit links very
gigabit links very often
links very often use
very often use jumbo
often use jumbo frames
use jumbo frames of
jumbo frames of up
frames of up to
at t without changing
t without changing their
without changing their probability
changing their probability distribution
their probability distribution of
probability distribution of finding
distribution of finding a
of finding a block
finding a block after
a block after t
the probability that a
probability that a miner
that a miner i
a miner i with
miner i with mining
i with mining power
with mining power mi
mining power mi finds
power mi finds the
while lan networks have
mi finds the next
lan networks have standard
finds the next block
networks have standard mtus
the next block is
have standard mtus of
next block is its
block is its ratio
is its ratio out
its ratio out of
ratio out of the
out of the total
of the total mining
the total mining power
total mining power m
mining power m in
power m in the
m in the system
at the receiving datacenter
miner miner miner pool
the appliance examines incoming
miner miner miner pool
appliance examines incoming repair
examines incoming repair packets
incoming repair packets and
repair packets and uses
packets and uses them
and uses them to
uses them to recover
them to recover missing
to recover missing data
recover missing data packets
the data packet is
data packet is injected
packet is injected transparently
is injected transparently into
injected transparently into the
transparently into the stream
into the stream to
the stream to the
stream to the receiving
to the receiving end
recovered data packets will
data packets will typically
packets will typically arrive
will typically arrive out
but this behavior is
and one miner mines
this behavior is expected
one miner mines solo
behavior is expected by
is expected by communication
expected by communication stacks
by communication stacks designed
communication stacks designed for
stacks designed for the
designed for the commodity
for the commodity internet
pools datacenters are built
datacenters are built around
are built around the
built around the world
flow control while relaying
control while relaying tcp
maelstrom has two flow
has two flow control
two flow control modes
mining is only profitable
is only profitable using
only profitable using dedicated
profitable using dedicated hardware
using dedicated hardware in
dedicated hardware in cutting
hardware in cutting edge
in cutting edge mining
cutting edge mining rigs
otherwise the energy costs
the energy costs exceed
energy costs exceed the
costs exceed the expected
exceed the expected revenue
the appliance routes packets
appliance routes packets through
routes packets through without
packets through without modification
although expected revenue from
expected revenue from mining
revenue from mining is
from mining is proportional
mining is proportional to
is proportional to the
proportional to the power
to the power of
control between the endhosts
the power of the
power of the mining
of the mining rigs
the mining rigs used
the appliance acts as
a single home miner
appliance acts as a
single home miner using
acts as a tcp
home miner using a
miner using a small
using a small rig
a small rig is
small rig is unlikely
rig is unlikely to
is unlikely to mine
unlikely to mine a
to mine a block
terminating connections and sending
mine a block for
connections and sending back
a block for years
and sending back acks
sending back acks immediately
back acks immediately before
acks immediately before relaying
immediately before relaying data
before relaying data on
relaying data on appliance
this is particularly useful
is particularly useful for
particularly useful for applications
useful for applications with
for applications with short
miners often organize themselves
lived flows that need
often organize themselves into
flows that need to
organize themselves into mining
that need to ramp
themselves into mining pools
need to ramp up
to ramp up throughput
ramp up throughput quickly
up throughput quickly and
throughput quickly and avoid
quickly and avoid the
and avoid the slow
a pool is a
pool is a group
is a group of
start effects of tcp
a group of miners
group of miners that
of miners that share
miners that share their
ip on a long
that share their revenues
on a long link
share their revenues when
their revenues when one
revenues when one of
when one of them
one of them successfully
the performance advantages of
of them successfully mines
performance advantages of splitting
them successfully mines a
advantages of splitting longdistance
successfully mines a block
of splitting longdistance connections
splitting longdistance connections into
longdistance connections into multiple
connections into multiple hops
into multiple hops are
for each block found
multiple hops are well
hops are well known
the revenue is distributed
revenue is distributed among
is distributed among the
distributed among the pool
among the pool members
the pool members in
pool members in proportion
members in proportion to
in proportion to their
and orthogonal to this
proportion to their mining
orthogonal to this work
to their mining power
we are primarily interested
are primarily interested in
primarily interested in isolating
interested in isolating the
the expected revenue of
in isolating the impact
expected revenue of a
isolating the impact of
revenue of a pool
the impact of rapid
of a pool member
impact of rapid and
a pool member is
of rapid and transparent
pool member is therefore
rapid and transparent recovery
member is therefore the
and transparent recovery of
is therefore the same
transparent recovery of lost
therefore the same as
recovery of lost packets
the same as its
of lost packets by
same as its revenue
lost packets by maelstrom
as its revenue had
packets by maelstrom on
its revenue had it
by maelstrom on tcp
revenue had it mined
had it mined solo
rather than the buffering
than the buffering and
due to the large
the buffering and slow
to the large power
the large power of
large power of the
power of the pool
start avoidance benefits of
avoidance benefits of generic
benefits of generic performance
it finds blocks at
finds blocks at a
blocks at a much
at a much higher
a much higher rate
in the remainder of
the remainder of the
and so the frequency
remainder of the paper
so the frequency of
the frequency of revenue
frequency of revenue collection
of revenue collection is
revenue collection is higher
we describe maelstrom with
describe maelstrom with end
allowing for a stable
for a stable daily
a stable daily or
stable daily or weekly
daily or weekly income
most pools are controlled
pools are controlled by
are controlled by a
controlled by a centralized
by a centralized pool
a centralized pool manager
while maelstrom respects end
miners register with the
register with the pool
end flow control connections
with the pool manager
the pool manager and
pool manager and mine
manager and mine on
and mine on its
mine on its behalf
or splits them and
splits them and implements
them and implements its
and implements its own
implements its own proxy
the pool manager generates
pool manager generates tasks
manager generates tasks and
generates tasks and the
tasks and the miners
and the miners search
proxy flow control as
the miners search for
flow control as described
miners search for solutions
control as described above
search for solutions based
for solutions based on
solutions based on these
based on these tasks
on these tasks that
these tasks that can
tasks that can serve
that can serve as
can serve as proof
it is not designed
serve as proof of
is not designed for
as proof of work
not designed for routinely
designed for routinely congested
for routinely congested networks
once they find a
they find a solution
the addition of fec
addition of fec under
of fec under tcp
they send it to
send it to the
it to the pool
to the pool manager
ip flow control allows
flow control allows it
control allows it to
allows it to steal
the pool manager behaves
it to steal bandwidth
pool manager behaves as
to steal bandwidth from
manager behaves as a
steal bandwidth from other
behaves as a single
bandwidth from other competing
as a single miner
from other competing flows
a single miner in
other competing flows running
single miner in the
competing flows running without
miner in the bitcoin
flows running without fec
in the bitcoin system
running without fec in
without fec in the
fec in the link
once it obtains a
it obtains a legitimate
obtains a legitimate block
though maintaining fairness versus
a legitimate block from
maintaining fairness versus similarly
legitimate block from one
fairness versus similarly fec
block from one of
from one of its
one of its miners
the block transfers the
block transfers the revenue
transfers the revenue to
the revenue to the
revenue to the control
to the control of
the control of the
control of the pool
of the pool manager
the pool manager then
pool manager then distributes
manager then distributes the
friendliness with conventional tcp
then distributes the revenue
distributes the revenue among
the revenue among the
revenue among the miners
among the miners according
ip flows is not
the miners according to
flows is not a
miners according to their
is not a primary
according to their mining
not a primary protocol
to their mining power
a primary protocol design
primary protocol design goal
protocol design goal on
design goal on over
the architecture is illustrated
architecture is illustrated in
is illustrated in figure
which are often dedicated
in order to estimate
are often dedicated to
order to estimate the
often dedicated to specific
to estimate the mining
dedicated to specific highvalue
estimate the mining power
to specific highvalue applications
the mining power of
mining power of a
power of a miner
we see evidence for
see evidence for this
evidence for this assertion
the pool manager sets
for this assertion in
pool manager sets a
this assertion in the
manager sets a partial
assertion in the routine
sets a partial target
in the routine use
a partial target for
the routine use of
partial target for each
routine use of parallel
target for each member
use of parallel flows
and udp blast protocols
than the target of
the target of the
target of the bitcoin
of the bitcoin system
each miner is required
miner is required to
is required to send
required to send the
to send the pool
send the pool manager
the pool manager blocks
pool manager blocks that
manager blocks that are
blocks that are correct
both in commercial deployments
that are correct according
in commercial deployments and
are correct according to
commercial deployments and by
correct according to the
deployments and by researchers
according to the partial
and by researchers seeking
to the partial target
by researchers seeking to
researchers seeking to transfer
seeking to transfer large
to transfer large amounts
transfer large amounts of
large amounts of data
amounts of data over
of data over high
the partial target is
partial target is chosen
target is chosen to
is chosen to be
chosen to be large
such that partial solutions
that partial solutions arrive
partial solutions arrive frequently
solutions arrive frequently enough
arrive frequently enough for
frequently enough for the
enough for the manager
for the manager to
the manager to accurately
manager to accurately estimate
layered interleaving in layered
to accurately estimate the
interleaving in layered interleaving
accurately estimate the power
estimate the power of
the power of the
power of the miner
an fec protocol with
fec protocol with rate
to reduce management overhead
is produced by running
produced by running c
by running c multiple
running c multiple instances
as the value of
c multiple instances of
the value of bitcoin
multiple instances of an
value of bitcoin rose
bitcoin mining has become
mining has become a
has become a rapidly
become a rapidly advancing
a rapidly advancing industry
technological advancements lead to
advancements lead to ever
fec protocol simultaneously with
lead to ever more
protocol simultaneously with increasing
to ever more efficient
simultaneously with increasing interleave
ever more efficient hashing
with increasing interleave indices
more efficient hashing asics
increasing interleave indices i
this is a simplification
is a simplification that
a simplification that is
simplification that is sufficient
that is sufficient for
is sufficient for our
sufficient for our analysis
the intricacies of reward
intricacies of reward systems
of reward systems are
reward systems are explained
systems are explained in
a notable exception is
notable exception is p
which we discuss in
we discuss in section
discuss in section ix
forks block propagation in
block propagation in the
propagation in the overlay
in the overlay network
the overlay network takes
overlay network takes seconds
therefore it is possible
it is possible for
is possible for two
possible for two distant
for two distant miners
two distant miners to
distant miners to generate
miners to generate competing
to generate competing blocks
both of which name
of which name the
which name the same
name the same block
the same block as
same block as their
block as their predecessor
are rare since the
rare since the average
since the average mining
the average mining interval
average mining interval is
three instances of an
and they occur on
they occur on average
occur on average once
on average once every
the first instance with
first instance with interleave
instance with interleave i
the system has a
system has a mechanism
has a mechanism to
a mechanism to solve
mechanism to solve forks
to solve forks when
solve forks when they
forks when they do
the second with interleave
when they do occur
second with interleave i
causing one of the
one of the blocks
of the blocks to
the blocks to be
blocks to be discarded
we ignore bifurcations for
ignore bifurcations for the
bifurcations for the sake
for the sake of
and the third with
the sake of simplicity
the third with interleave
third with interleave i
since the choice of
the choice of the
choice of the discarded
of the discarded block
the discarded block on
discarded block on bifurcation
block on bifurcation is
on bifurcation is random
one may incorporate this
may incorporate this event
incorporate this event into
this event into the
event into the probability
into the probability of
the probability of finding
probability of finding a
of finding a block
and consider instead the
consider instead the probability
instead the probability of
the probability of finding
probability of finding a
of finding a block
finding a block that
a block that is
block that is not
that is not discarded
fec encoding is simply
encoding is simply an
pools often charge a
is simply an xor
often charge a small
simply an xor of
charge a small percentage
an xor of the
a small percentage of
xor of the r
small percentage of the
of the r data
percentage of the revenue
the r data packets
of the revenue as
r data packets hence
the revenue as fee
in layered interleaving each
we discuss in section
layered interleaving each data
discuss in section ix
interleaving each data packet
in section ix the
each data packet is
section ix the implications
data packet is included
ix the implications of
packet is included in
the implications of such
is included in c
implications of such fees
included in c xors
of such fees to
such fees to our
fees to our analysis
each of which is
of which is generated
many pools are open
which is generated at
pools are open and
is generated at different
are open and accept
generated at different interleaves
open and accept any
at different interleaves from
and accept any interested
different interleaves from the
accept any interested miner
interleaves from the original
from the original data
the original data stream
a pool interface is
pool interface is typically
interface is typically comprised
is typically comprised of
typically comprised of a
comprised of a web
as we shall describe
of a web interface
we shall describe shortly
a web interface for
web interface for registration
interface for registration and
for registration and a
registration and a miner
ensures that the c
and a miner interface
that the c xors
a miner interface for
the c xors containing
miner interface for the
c xors containing a
interface for the mining
xors containing a data
for the mining software
containing a data packet
a data packet do
data packet do not
packet do not have
do not have any
not have any other
in order to mine
order to mine for
to mine for a
mine for a pool
a miner registers with
miner registers with the
registers with the web
with the web interface
supplies a bitcoin address
a bitcoin address to
bitcoin address to receive
address to receive its
to receive its future
receive its future shares
its future shares of
future shares of the
shares of the revenue
and receives from the
receives from the pool
from the pool credentials
the pool credentials for
pool credentials for mining
then he feeds his
he feeds his credentials
feeds his credentials and
his credentials and the
credentials and the pool
and the pool s
the pool s address
pool s address to
s address to its
address to its mining
to its mining rig
the mining rig obtains
mining rig obtains its
rig obtains its tasks
obtains its tasks from
its tasks from the
tasks from the pool
from the pool and
the pool and sends
pool and sends partial
and sends partial and
sends partial and full
partial and full proof
and full proof of
full proof of work
typically with the stratum
with the stratum protocol
as it finds blocks
the pool manager credits
pool manager credits the
manager credits the miner
credits the miner s
the miner s account
miner s account according
s account according to
account according to its
according to its share
to its share of
its share of the
share of the work
and transfers these funds
transfers these funds either
these funds either on
funds either on request
either on request or
on request or automatically
request or automatically to
or automatically to the
automatically to the aforementioned
to the aforementioned bitcoin
the aforementioned bitcoin address
too big pools despite
big pools despite their
pools despite their important
despite their important role
their important role of
important role of enabling
role of enabling small
pools can constitute a
can constitute a threat
constitute a threat to
data packet in common
a threat to the
threat to the bitcoin
to the bitcoin system
the bitcoin system if
bitcoin system if their
system if their size
the resulting protocol effectively
if their size is
resulting protocol effectively has
their size is too
protocol effectively has a
size is too large
effectively has a rate
has a rate of
if one pool controls
one pool controls the
pool controls the majority
controls the majority of
the majority of mining
majority of mining power
the system becomes unstable
with each xor generated
each xor generated from
xor generated from r
generated from r data
from r data packets
r data packets and
data packets and each
packets and each data
and each data packet
each data packet included
data packet included in
packet included in c
included in c xors
illustrates layered interleaving for
layered interleaving for a
warns that the system
that the system is
the system is unstable
system is unstable with
is unstable with even
unstable with even smaller
with even smaller pools
in realistic scenarios of
realistic scenarios of the
scenarios of the bitcoin
of the bitcoin system
the bitcoin system no
bitcoin system no pool
system no pool controls
no pool controls a
pool controls a majority
controls a majority of
a majority of the
majority of the mining
of the mining power
for one day in
one day in june
standard fec schemes can
fec schemes can be
schemes can be made
can be made resistant
be made resistant to
made resistant to a
resistant to a certain
to a certain loss
a certain loss burst
certain loss burst length
a single pool called
loss burst length at
single pool called ghash
burst length at the
length at the cost
at the cost of
the cost of increased
cost of increased recovery
of increased recovery latency
increased recovery latency for
recovery latency for all
latency for all lost
for all lost packets
including smaller bursts and
smaller bursts and singleton
of the blocks in
bursts and singleton drops
the blocks in the
blocks in the bitcoin
in the bitcoin main
the bitcoin main chain
the bitcoin community backlashed
bitcoin community backlashed at
layered interleaving provides graceful
community backlashed at the
backlashed at the pool
interleaving provides graceful degradation
provides graceful degradation in
graceful degradation in the
which has done nothing
degradation in the face
has done nothing worse
in the face of
done nothing worse than
the face of bursty
nothing worse than being
face of bursty loss
worse than being extremely
of bursty loss for
than being extremely successful
bursty loss for constant
loss for constant encoding
for constant encoding overhead
constant encoding overhead singleton
encoding overhead singleton random
overhead singleton random losses
singleton random losses are
random losses are recovered
losses are recovered as
are recovered as quickly
io reduced its relative
recovered as quickly as
reduced its relative mining
as quickly as possible
its relative mining power
relative mining power and
mining power and publicly
power and publicly committed
and publicly committed to
publicly committed to stay
by xors generated with
committed to stay away
xors generated with an
to stay away from
generated with an interleave
stay away from the
with an interleave of
and each successive layer
each successive layer of
successive layer of xors
layer of xors generated
of xors generated at
xors generated at a
generated at a higher
at a higher interleave
a higher interleave catches
block withholding and its
higher interleave catches larger
withholding and its detection
interleave catches larger bursts
and its detection classical
catches larger bursts missed
its detection classical block
larger bursts missed by
detection classical block withholding
bursts missed by the
missed by the previous
by the previous layer
the implementation of this
implementation of this algorithm
of this algorithm is
this algorithm is simple
algorithm is simple and
is simple and shown
simple and shown in
and shown in figure
is an attack performed
an attack performed by
attack performed by a
performed by a pool
by a pool member
a pool member against
pool member against the
member against the other
against the other pool
the other pool members
a set of repair
set of repair bins
of repair bins is
repair bins is maintained
bins is maintained for
the attacking miner registers
is maintained for each
attacking miner registers with
maintained for each layer
miner registers with the
registers with the pool
with the pool and
the pool and apparently
with i bins for
pool and apparently starts
i bins for a
and apparently starts mining
bins for a layer
apparently starts mining honestly
for a layer with
starts mining honestly it
a layer with interleave
mining honestly it regularly
layer with interleave i
honestly it regularly sends
it regularly sends the
regularly sends the pool
sends the pool partial
the pool partial proof
a repair bin consists
pool partial proof of
repair bin consists of
partial proof of work
bin consists of a
consists of a partially
of a partially constructed
a partially constructed repair
partially constructed repair packet
the attacking miner sends
an xor and the
attacking miner sends only
xor and the recipe
miner sends only partial
and the recipe list
sends only partial proof
the recipe list of
only partial proof of
recipe list of identifiers
partial proof of work
list of identifiers of
of identifiers of data
identifiers of data packets
of data packets that
data packets that compose
if it finds a
packets that compose the
it finds a full
that compose the xor
finds a full solution
a full solution that
full solution that constitutes
solution that constitutes a
that constitutes a full
each intercepted data packet
constitutes a full proof
intercepted data packet is
a full proof of
data packet is added
full proof of work
packet is added to
proof of work it
is added to each
of work it discards
added to each layer
work it discards the
to each layer where
it discards the solution
each layer where adding
layer where adding to
where adding to a
adding to a layer
reducing the pool s
to a layer simply
the pool s total
a layer simply means
pool s total revenue
layer simply means choosing
simply means choosing a
means choosing a repair
choosing a repair bin
a repair bin from
repair bin from the
bin from the layer
from the layer s
the layer s set
this attack is illustrated
attack is illustrated in
is illustrated in figure
incrementally updating the xor
updating the xor with
the xor with the
xor with the new
with the new data
the new data packet
the attacker does not
attacker does not change
does not change the
not change the pool
change the pool s
and adding the data
the pool s effective
adding the data packet
pool s effective mining
the data packet s
s effective mining power
data packet s header
packet s header to
s header to the
header to the recipe
to the recipe list
and does not affect
does not affect directly
not affect directly the
affect directly the revenue
directly the revenue of
a counter is incremented
the revenue of other
counter is incremented as
revenue of other pools
is incremented as each
incremented as each data
as each data packet
each data packet arrives
data packet arrives at
packet arrives at the
arrives at the appliance
the attacked pool shares
attacked pool shares its
pool shares its revenue
and choosing the repair
shares its revenue with
choosing the repair bin
its revenue with the
revenue with the attacker
the repair bin from
repair bin from the
bin from the layer
from the layer s
therefore each miner earns
the layer s set
each miner earns less
layer s set is
s set is done
set is done by
is done by taking
as the same revenue
done by taking the
the same revenue is
by taking the modulo
same revenue is distributed
taking the modulo of
revenue is distributed among
the modulo of the
is distributed among more
modulo of the counter
distributed among more miners
of the counter with
the counter with the
counter with the number
with the number of
the number of bins
recall that the proof
number of bins in
that the proof of
of bins in each
the proof of work
bins in each layer
proof of work is
of work is only
work is only valid
is only valid for
only valid for a
valid for a specific
for a layer with
for a specific block
a layer with interleave
as it is the
it is the nonce
is the nonce with
the nonce with which
nonce with which the
with which the block
which the block s
the block s hash
block s hash is
the xth intercepted packet
s hash is smaller
xth intercepted packet is
hash is smaller than
intercepted packet is added
is smaller than its
packet is added to
smaller than its target
is added to the
the attacking miner cannot
attacking miner cannot use
miner cannot use it
although the term block
the term block withholding
term block withholding has
block withholding has become
withholding has become canonical
when a repair bin
a repair bin fills
note that the block
repair bin fills up
that the block is
bin fills up its
the block is discarded
fills up its recipe
block is discarded and
up its recipe list
is discarded and never
its recipe list contains
discarded and never introduced
recipe list contains r
and never introduced into
list contains r data
never introduced into the
contains r data packets
introduced into the system
r data packets it
into the system as
data packets it fires
the system as the
system as the name
as the name block
the name block withholding
name block withholding implies
a repair packet is
repair packet is generated
packet is generated consisting
is generated consisting of
generated consisting of the
consisting of the xor
of the xor and
miners miners miners pool
the xor and the
xor and the recipe
and the recipe list
the recipe list and
recipe list and is
list and is scheduled
and is scheduled for
is scheduled for sending
while the repair bin
classical block withholding attack
the repair bin is
repair bin is re
a group of miners
group of miners attack
initialized with an empty
of miners attack pool
with an empty recipe
an empty recipe list
empty recipe list and
recipe list and blank
list and blank xor
with a block withholding
a block withholding attack
denoted by a dashed
by a dashed red
a dashed red arrow
incoming repair packets are
repair packets are processed
packets are processed as
are processed as follows
this attack reduces the
attack reduces the attacker
reduces the attacker s
if all the data
the attacker s revenue
all the data packets
attacker s revenue compared
the data packets contained
s revenue compared to
data packets contained in
revenue compared to solo
packets contained in the
compared to solo mining
contained in the repair
to solo mining or
in the repair s
solo mining or honest
the repair s recipe
mining or honest pool
repair s recipe list
or honest pool participation
s recipe list have
recipe list have been
list have been received
have been received successfully
it suffers from the
suffers from the reduced
from the reduced revenue
the repair packet is
the reduced revenue like
repair packet is discarded
reduced revenue like the
revenue like the other
like the other pool
the other pool participants
if the repair s
the repair s recipe
repair s recipe list
s recipe list contains
and its revenue is
recipe list contains a
its revenue is less
list contains a single
revenue is less than
contains a single missing
is less than its
a single missing data
less than its share
single missing data packet
than its share of
its share of the
share of the total
of the total mining
the total mining power
total mining power in
recovery can occur immediately
mining power in the
can occur immediately by
power in the system
occur immediately by combining
immediately by combining the
by combining the xor
combining the xor in
the xor in the
xor in the repair
the classical block withholding
in the repair with
classical block withholding attack
the repair with layer
block withholding attack can
withholding attack can therefore
attack can therefore only
can therefore only be
therefore only be used
only be used for
be used for sabotage
at a cost to
a cost to the
cost to the attacker
even if a pool
if a pool detects
a pool detects that
pool detects that it
detects that it is
that it is under
it is under a
is under a block
under a block withholding
a block withholding attack
it might not be
might not be able
not be able to
be able to detect
able to detect which
to detect which of
detect which of its
which of its registered
of its registered miners
its registered miners are
registered miners are the
miners are the perpetrators
a pool can estimate
pool can estimate its
can estimate its expected
estimate its expected mining
its expected mining power
expected mining power and
mining power and its
power and its actual
and its actual mining
its actual mining power
actual mining power by
mining power by the
power by the rates
by the rates of
the rates of partial
rates of partial proofs
of partial proofs of
partial proofs of work
proofs of work and
of work and full
work and full proofs
and full proofs of
full proofs of work
supplied by its miners
a difference above a
difference above a set
above a set confidence
a set confidence interval
set confidence interval indicates
confidence interval indicates an
interval indicates an attack
to detect whether a
detect whether a single
whether a single miner
a single miner is
single miner is attacking
miner is attacking it
the pool must use
pool must use a
must use a similar
use a similar technique
comparing the estimated mining
the estimated mining power
estimated mining power of
mining power of the
power of the attacker
of the attacker based
the attacker based on
attacker based on its
based on its partial
on its partial proof
its partial proof of
partial proof of work
proof of work with
of work with the
work with the fact
with the fact it
the fact it never
fact it never supplies
it never supplies a
never supplies a full
layer with interleave of
supplies a full proof
a full proof of
full proof of work
if the attacker has
the attacker has a
attacker has a small
has a small mining
a small mining power
it will send frequent
will send frequent partial
send frequent partial proofs
frequent partial proofs of
partial proofs of work
but the pool will
the pool will only
pool will only expect
will only expect to
only expect to see
expect to see a
to see a full
see a full proof
a full proof of
full proof of work
proof of work at
of work at very
work at very low
at very low frequency
it cannot obtain statistically
cannot obtain statistically significant
obtain statistically significant results
statistically significant results that
significant results that would
results that would indicate
that would indicate an
would indicate an attack
an attacker can use
attacker can use multiple
can use multiple small
use multiple small block
multiple small block withholding
small block withholding miners
block withholding miners and
withholding miners and replace
miners and replace them
and replace them frequently
a small miner is
a miner whose expected
miner whose expected full
whose expected full proof
expected full proof of
full proof of work
proof of work frequency
of work frequency is
work frequency is yearly
such a miner will
a miner will see
miner will see a
will see a non
negligible average daily revenue
if the attacker replaces
the attacker replaces such
attacker replaces such a
replaces such a small
such a small miner
a small miner every
small miner every month
he will collect about
will collect about b
at the end of
the end of each
end of each month
the pool must decide
pool must decide within
the other successfully received
must decide within this
other successfully received data
decide within this month
successfully received data packets
within this month whether
this month whether the
month whether the miner
whether the miner is
if the repair contains
the miner is an
the repair contains multiple
miner is an attacker
repair contains multiple missing
contains multiple missing data
multiple missing data packets
and revoke its earnings
it cannot be used
cannot be used immediately
be used immediately for
used immediately for recovery
or just an unlucky
immediately for recovery it
just an unlucky honest
for recovery it is
an unlucky honest miner
recovery it is instead
it is instead stored
is instead stored in
instead stored in a
stored in a table
since an honest miner
in a table that
an honest miner of
a table that maps
honest miner of this
table that maps missing
miner of this power
that maps missing data
of this power is
maps missing data packets
this power is unlikely
missing data packets to
power is unlikely to
data packets to repair
is unlikely to find
packets to repair packets
unlikely to find a
to find a full
find a full proof
a full proof of
full proof of work
proof of work within
whenever a data packet
of work within a
a data packet is
work within a month
data packet is subsequently
packet is subsequently received
is subsequently received or
subsequently received or recovered
this table is checked
table is checked to
is checked to see
according to the exponential
to the exponential distribution
checked to see if
to see if any
see if any xors
if any xors now
a pool that rejects
any xors now have
pool that rejects miners
xors now have singleton
that rejects miners based
now have singleton losses
rejects miners based on
have singleton losses due
miners based on this
singleton losses due to
based on this criterion
losses due to the
on this criterion would
due to the presence
this criterion would reject
to the presence of
criterion would reject the
the presence of the
would reject the majority
presence of the new
reject the majority of
of the new packet
the majority of its
the new packet and
majority of its honest
new packet and can
of its honest miners
packet and can be
and can be used
can be used for
be used for recovering
used for recovering other
for recovering other missing
the alternative of rejecting
recovering other missing packets
alternative of rejecting small
of rejecting small miners
rejecting small miners in
small miners in general
miners in general or
in general or distributing
general or distributing revenue
xors received from different
or distributing revenue on
received from different layers
distributing revenue on a
from different layers interact
revenue on a yearly
different layers interact to
on a yearly basis
layers interact to recover
a yearly basis contradicts
interact to recover missing
yearly basis contradicts the
to recover missing data
basis contradicts the goal
recover missing data packets
contradicts the goal of
the goal of pooled
goal of pooled mining
since an xor received
an xor received at
xor received at a
received at a higher
at a higher interleave
m odel and s
a higher interleave can
odel and s tandard
higher interleave can recover
and s tandard o
interleave can recover a
s tandard o peration
can recover a packet
tandard o peration we
recover a packet that
o peration we specify
a packet that makes
peration we specify the
packet that makes an
we specify the basic
that makes an earlier
specify the basic model
makes an earlier xor
the basic model in
an earlier xor at
basic model in which
earlier xor at a
model in which participants
xor at a lower
in which participants operate
at a lower interleave
which participants operate in
a lower interleave usable
participants operate in section
lower interleave usable hence
operate in section iii
though layered interleaving is
layered interleaving is equivalent
proceed to describe how
interleaving is equivalent to
to describe how honest
is equivalent to c
describe how honest miners
equivalent to c different
how honest miners operate
honest miners operate in
miners operate in this
operate in this environment
in this environment in
this environment in sections
environment in sections iii
instances in terms of
in terms of overhead
and how the classical
terms of overhead and
how the classical block
of overhead and design
the classical block withholding
classical block withholding attack
block withholding attack is
withholding attack is implemented
attack is implemented with
its recovery power is
is implemented with our
recovery power is much
implemented with our model
power is much higher
with our model in
is much higher and
our model in section
much higher and comes
model in section iii
higher and comes close
and comes close to
comes close to standard
model the system is
the system is comprised
system is comprised of
is comprised of the
comprised of the bitcoin
of the bitcoin network
the bitcoin network and
bitcoin network and nodes
network and nodes with
and nodes with unique
nodes with unique ids
and progresses in steps
a node i generates
node i generates tasks
i generates tasks which
generates tasks which are
tasks which are associated
which are associated with
are associated with its
associated with its id
with its id i
a node can work
node can work on
can work on a
work on a task
on a task for
a task for the
task for the duration
for the duration of
the duration of a
duration of a step
the result of this
result of this work
of this work is
this work is a
work is a set
is a set of
a set of partial
set of partial proofs
of partial proofs of
partial proofs of work
proofs of work and
of work and a
work and a set
and a set of
a set of full
set of full proofs
of full proofs of
full proofs of work
the number of proofs
number of proofs in
of proofs in each
proofs in each set
in each set has
each set has a
set has a poisson
has a poisson distribution
partial proofs with a
proofs with a large
with a large mean
a large mean and
large mean and full
mean and full proofs
and full proofs with
full proofs with a
proofs with a small
with a small mean
nodes that work on
that work on tasks
work on tasks are
on tasks are called
tasks are called a
are called a miners
miners have identical power
and hence identical probabilities
hence identical probabilities to
identical probabilities to generate
probabilities to generate proofs
to generate proofs of
generate proofs of work
the bitcoin network pays
bitcoin network pays for
second set of rsized
network pays for full
set of rsized xors
pays for full proofs
of rsized xors staggered
for full proofs of
rsized xors staggered start
full proofs of work
xors staggered start xors
to acquire this payoff
acquire this payoff an
this payoff an entity
payoff an entity publishes
an entity publishes a
entity publishes a task
publishes a task task
a task task and
task task and its
task and its corresponding
and its corresponding proof
its corresponding proof of
corresponding proof of work
proof of work to
of work to the
work to the network
the payoff goes to
payoff goes to the
goes to the id
to the id associated
the id associated with
id associated with task
the bitcoin protocol normalizes
bitcoin protocol normalizes revenue
protocol normalizes revenue such
normalizes revenue such that
revenue such that the
such that the average
that the average total
the average total revenue
average total revenue distributed
total revenue distributed in
revenue distributed in each
distributed in each step
in each step is
each step is a
step is a constant
is a constant throughout
a constant throughout the
constant throughout the execution
throughout the execution of
the execution of the
execution of the system
any node can transact
node can transact bitcoins
can transact bitcoins to
transact bitcoins to another
bitcoins to another node
to another node by
another node by issuing
node by issuing a
by issuing a bitcoin
issuing a bitcoin transaction
nodes that generate tasks
that generate tasks but
generate tasks but outsource
tasks but outsource the
but outsource the work
outsource the work are
the work are called
work are called pools
pools send tasks to
send tasks to miners
tasks to miners over
to miners over the
miners over the network
the miners receive the
miners receive the tasks
and send the partial
send the partial and
the partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work to
of work to the
work to the pool
apart from working on
from working on tasks
and receipt are instantaneous
we assume that the
assume that the number
that the number of
the number of miners
number of miners is
of miners is large
miners is large enough
is large enough such
large enough such that
enough such that mining
such that mining power
that mining power can
mining power can be
power can be split
can be split arbitrarily
be split arbitrarily without
split arbitrarily without resolution
arbitrarily without resolution constraints
denote the number of
the number of pools
number of pools with
of pools with p
the total number of
total number of mining
number of mining power
of mining power in
mining power in the
power in the system
in the system with
the system with m
system with m and
with m and the
m and the miners
and the miners participating
the miners participating in
miners participating in pool
participating in pool i
we use a quasistatic
use a quasistatic analysis
a quasistatic analysis where
quasistatic analysis where miner
analysis where miner participation
where miner participation in
miner participation in a
participation in a pool
in a pool does
a pool does not
pool does not change
does not change over
not change over time
solo mining a solo
mining a solo miner
a solo miner is
solo miner is a
miner is a node
is a node that
a node that generates
node that generates its
that generates its own
generates its own tasks
in every step it
every step it generates
step it generates a
it generates a task
works on it for
on it for the
it for the duration
for the duration of
the duration of the
duration of the step
of the step and
the step and if
step and if it
and if it finds
if it finds a
it finds a full
finds a full proof
a full proof of
full proof of work
it publishes this proof
publishes this proof of
this proof of work
proof of work to
of work to earn
work to earn the
to earn the payoff
pools a pool is
a pool is a
pool is a node
is a node that
a node that serves
node that serves as
that serves as a
serves as a coordinator
as a coordinator and
a coordinator and multiple
coordinator and multiple miners
and multiple miners can
multiple miners can register
miners can register to
can register to a
register to a pool
to a pool and
a pool and work
pool and work for
and work for it
in every step it
every step it generates
step it generates a
it generates a task
generates a task for
a task for each
task for each registered
for each registered miner
each registered miner and
registered miner and sends
miner and sends it
and sends it over
sends it over the
it over the network
each miner receives its
miner receives its task
receives its task and
its task and works
task and works on
and works on it
works on it for
on it for the
it for the duration
for the duration of
the duration of the
duration of the step
at the end of
the end of the
end of the step
the miner sends the
miner sends the pool
sends the pool the
the pool the full
pool the full and
the full and the
full and the partial
and the partial proofs
the partial proofs of
partial proofs of work
proofs of work it
of work it has
work it has found
the pool receives the
pool receives the proofs
receives the proofs of
the proofs of work
proofs of work of
of work of all
work of all its
of all its miners
registers the partial proofs
the partial proofs of
partial proofs of work
proofs of work and
of work and publishes
work and publishes the
and publishes the full
publishes the full proofs
it calculates its overall
calculates its overall revenue
and proceeds to distribute
proceeds to distribute it
to distribute it among
distribute it among its
it among its miners
each miner receives revenue
miner receives revenue proportional
receives revenue proportional to
revenue proportional to its
proportional to its success
to its success in
its success in the
success in the current
in the current step
namely the ratio of
the ratio of its
ratio of its partial
of its partial proofs
its partial proofs of
partial proofs of work
proofs of work out
of work out of
work out of all
out of all partial
of all partial proofs
all partial proofs of
partial proofs of work
proofs of work the
of work the pool
work the pool received
we assume that pools
assume that pools do
that pools do not
pools do not collect
do not collect fees
not collect fees of
collect fees of the
fees of the revenue
pool fees and their
fees and their implications
and their implications on
their implications on our
implications on our analysis
on our analysis are
our analysis are discussed
analysis are discussed in
are discussed in section
discussed in section ix
block withholding miner a
withholding miner a miner
miner a miner registered
a miner registered at
miner registered at a
registered at a pool
at a pool can
a pool can perform
pool can perform the
can perform the classical
perform the classical block
the classical block withholding
classical block withholding attack
an attacker miner operates
attacker miner operates as
miner operates as if
operates as if it
as if it worked
if it worked for
it worked for the
worked for the pool
it receives its tasks
receives its tasks and
its tasks and works
tasks and works on
and works on them
only at the end
at the end of
the end of each
end of each round
of each round it
each round it sends
round it sends only
it sends only its
sends only its partial
only its partial proofs
its partial proofs of
partial proofs of work
and omits full proofs
omits full proofs of
full proofs of work
proofs of work if
of work if it
work if it had
if it had found
it had found any
the pool registers the
pool registers the miner
registers the miner s
the miner s partial
miner s partial proofs
but cannot distinguish between
cannot distinguish between miners
distinguish between miners running
between miners running honestly
miners running honestly and
running honestly and block
honestly and block withholding
and block withholding miners
the implications are that
implications are that a
are that a miner
that a miner that
a miner that engages
miner that engages in
that engages in block
engages in block withholding
in block withholding does
block withholding does not
withholding does not contribute
does not contribute to
not contribute to the
contribute to the pool
to the pool s
the pool s overall
pool s overall mining
s overall mining power
but still shares the
still shares the pool
shares the pool s
the pool s revenue
pool s revenue according
s revenue according to
revenue according to its
according to its sent
to its sent partial
its sent partial proofs
sent partial proofs of
partial proofs of work
to reason about a
reason about a pool
about a pool s
a pool s efficiency
pool s efficiency we
s efficiency we define
efficiency we define its
we define its per
miner revenue as follows
the revenue density of
revenue density of a
density of a pool
of a pool is
a pool is the
pool is the ratio
is the ratio between
the ratio between the
ratio between the average
between the average revenue
the average revenue a
average revenue a pool
revenue a pool member
a pool member earns
pool member earns and
member earns and the
earns and the average
and the average revenue
the average revenue it
average revenue it would
revenue it would have
it would have earned
would have earned as
have earned as a
earned as a solo
as a solo miner
the revenue density of
revenue density of a
density of a solo
of a solo miner
and that of a
that of a miner
of a miner working
a miner working with
miner working with an
working with an unattacked
with an unattacked pool
an unattacked pool are
unattacked pool are one
if a pool is
a pool is attacked
pool is attacked with
is attacked with block
attacked with block withholding
its revenue density decreases
continuous analysis because our
analysis because our analysis
because our analysis will
our analysis will be
analysis will be of
will be of the
be of the average
of the average revenue
we will consider proofs
will consider proofs of
consider proofs of work
both full and partial
as continuous deterministic sizes
according to their probability
work on a task
on a task therefore
a task therefore results
task therefore results in
therefore results in a
results in a deterministic
in a deterministic fraction
a deterministic fraction of
deterministic fraction of proof
fraction of proof of
of proof of work
t he p ool
he p ool g
p ool g ame
ool g ame a
the pool block withholding
pool block withholding attack
block withholding attack just
withholding attack just as
attack just as a
just as a miner
as a miner can
comparison of packet recovery
a miner can perform
of packet recovery probability
miner can perform block
can perform block withholding
perform block withholding on
block withholding on a
withholding on a pool
on a pool j
a pool i can
pool i can use
i can use some
can use some of
use some of its
some of its mining
of its mining power
its mining power to
mining power to infiltrate
power to infiltrate a
to infiltrate a pool
infiltrate a pool j
a pool j and
pool j and perform
j and perform a
and perform a block
perform a block withholding
a block withholding attack
block withholding attack on
withholding attack on j
denote the amount of
the amount of such
amount of such infiltrating
of such infiltrating mining
such infiltrating mining power
infiltrating mining power at
mining power at step
power at step t
at step t by
step t by xi
optimizations staggered start for
staggered start for rate
limiting in the naive
in the naive implementation
the naive implementation of
naive implementation of the
implementation of the layered
of the layered interleaving
the layered interleaving algorithm
miners working for pool
working for pool i
repair packets are transmitted
packets are transmitted as
either mining honestly or
are transmitted as soon
mining honestly or used
transmitted as soon as
honestly or used for
as soon as repair
or used for infiltrating
soon as repair bins
used for infiltrating pool
as repair bins fill
for infiltrating pool j
repair bins fill and
bins fill and allow
fill and allow them
and allow them to
allow them to be
are loyal to pool
them to be constructed
loyal to pool i
at the end of
the end of a
end of a round
all the repair bins
the repair bins in
repair bins in a
pool i aggregates its
bins in a layer
i aggregates its revenue
in a layer fill
aggregates its revenue from
a layer fill in
its revenue from mining
layer fill in quick
revenue from mining in
fill in quick succession
from mining in the
mining in the current
in the current round
the current round and
current round and from
round and from its
and from its infiltration
from its infiltration in
its infiltration in the
infiltration in the previous
in the previous round
the arrival of packets
it distributes the revenue
distributes the revenue evenly
the revenue evenly among
revenue evenly among all
evenly among all its
among all its loyal
all its loyal miners
its loyal miners according
loyal miners according to
miners according to their
according to their partial
to their partial proofs
their partial proofs of
partial proofs of work
the pool s miners
pool s miners are
s miners are oblivious
miners are oblivious to
are oblivious to their
oblivious to their role
to their role and
their role and they
role and they operate
and they operate as
they operate as regular
operate as regular honest
as regular honest miners
will successively fill the
successively fill the four
fill the four repair
the four repair bins
four repair bins in
repair bins in layer
this behavior leads to
behavior leads to a
leads to a large
revenue convergence note that
to a large number
convergence note that pool
a large number of
note that pool j
large number of repair
that pool j sends
number of repair packets
pool j sends its
of repair packets being
j sends its revenue
repair packets being generated
sends its revenue to
packets being generated and
its revenue to infiltrators
being generated and sent
revenue to infiltrators from
generated and sent within
to infiltrators from pool
and sent within a
infiltrators from pool i
sent within a short
from pool i at
within a short period
pool i at the
a short period of
i at the end
short period of time
at the end of
the end of the
end of the step
which results in undesirable
results in undesirable overhead
in undesirable overhead and
undesirable overhead and traffic
and this revenue is
overhead and traffic spikes
this revenue is calculated
revenue is calculated in
is calculated in pool
calculated in pool i
in pool i at
pool i at the
i at the beginning
at the beginning of
the beginning of the
we would like to
beginning of the subsequent
would like to rate
of the subsequent step
limit transmissions of repair
if there is a
transmissions of repair packets
there is a chain
of repair packets to
is a chain of
repair packets to one
a chain of pools
packets to one for
to one for every
one for every r
for every r data
every r data packets
this problem is fixed
problem is fixed by
is fixed by staggering
fixed by staggering the
by staggering the starting
staggering the starting sizes
the starting sizes of
starting sizes of the
sizes of the bins
analogous to the starting
to the starting positions
the starting positions of
starting positions of runners
positions of runners in
of runners in a
runners in a sprint
the very first time
very first time bin
first time bin number
where each pool infiltrates
time bin number x
each pool infiltrates the
bin number x in
pool infiltrates the previous
number x in a
infiltrates the previous one
x in a layer
in a layer of
a layer of interleave
layer of interleave i
of interleave i fires
the pool revenue will
pool revenue will not
revenue will not be
will not be static
it does so at
does so at size
so at size x
at size x mod
size x mod r
since the revenue from
the revenue from infiltration
revenue from infiltration takes
from infiltration takes one
infiltration takes one step
takes one step to
one step to take
step to take each
to take each hop
from the first step
the first repair bin
first repair bin in
the revenue of pool
repair bin in the
bin in the second
in the second layer
the second layer with
second layer with interleave
since it is only
would fire at size
it is only infiltrated
is only infiltrated and
only infiltrated and loses
infiltrated and loses some
and loses some of
loses some of its
some of its revenue
of its revenue for
its revenue for pool
the second would fire
second would fire at
would fire at size
starting from the second
from the second step
the revenue of pool
for the first i
the first i data
first i data packets
i data packets added
data packets added to
comprised of its own
packets added to a
of its own mining
added to a layer
its own mining and
to a layer with
own mining and its
a layer with interleave
mining and its revenue
layer with interleave i
and its revenue from
its revenue from the
revenue from the infiltration
from the infiltration of
the infiltration of pool
r fire immediately with
fire immediately with just
immediately with just one
with just one packet
just one packet in
with some revenue lost
one packet in them
some revenue lost due
revenue lost due to
lost due to its
due to its infiltration
to its infiltration by
for the next i
its infiltration by pool
the next i data
next i data packets
i data packets added
starting from the third
from the third step
r fire immediately with
fire immediately with two
immediately with two data
the revenue of pool
with two data packets
two data packets in
data packets in them
and so on until
so on until r
on until r i
until r i data
r i data packets
i data packets have
data packets have been
packets have been added
max is the longest
have been added to
is the longest chain
been added to the
the longest chain in
added to the layer
longest chain in the
to the layer and
chain in the system
the layer and all
layer and all bins
and all bins have
all bins have fired
bins have fired exactly
have fired exactly once
the revenue stabilizes after
all bins fire at
if there are loops
bins fire at size
there are loops in
fire at size r
are loops in the
loops in the infiltration
in the infiltration graph
the system will converge
system will converge to
now that they have
will converge to a
that they have been
converge to a certain
they have been staggered
to a certain revenue
have been staggered at
been staggered at the
staggered at the start
as stated in the
stated in the following
in the following lemma
r fire for any
fire for any i
for any i data
any i data packets
the outlined scheme works
outlined scheme works when
scheme works when i
works when i is
when i is greater
i is greater than
is greater than or
greater than or equal
than or equal to
if infiltration rates are
or equal to r
infiltration rates are constant
as is usually the
the pool revenues converge
is usually the case
pool revenues converge to
revenues converge to a
converge to a limit
to a limit as
a limit as time
if i is smaller
limit as time progresses
i is smaller than
is smaller than r
the bin with index
bin with index x
with index x fires
index x fires at
denote the revenue density
the revenue density of
revenue density of pool
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
end of step t
of step t by
step t by ri
and define the revenue
define the revenue density
the revenue density vector
revenue density vector r
the initial firing sizes
initial firing sizes would
firing sizes would be
for the first bin
the first bin and
for the second bin
if r and i
r and i are
and i are not
i are not integral
are not integral multiples
not integral multiples of
integral multiples of each
multiples of each other
limiting still works but
still works but is
works but is slightly
but is slightly less
is slightly less effective
slightly less effective due
less effective due to
effective due to rounding
due to rounding errors
delaying xors in the
xors in the naive
in the naive implementation
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
as soon as they
soon as they are
the revenues at all
as they are generated
revenues at all pools
at all pools converge
all pools converge as
pools converge as follows
this results in the
results in the repair
in the repair packet
the repair packet leaving
repair packet leaving immediately
packet leaving immediately after
leaving immediately after the
immediately after the last
after the last data
the last data packet
last data packet that
data packet that was
packet that was added
that was added to
was added to it
which lowers burst tolerance
lowers burst tolerance if
burst tolerance if the
tolerance if the repair
if the repair packet
the repair packet was
repair packet was generated
packet was generated at
was generated at interleave
generated at interleave i
the resulting protocol can
resulting protocol can tolerate
protocol can tolerate a
can tolerate a burst
tolerate a burst of
a burst of i
burst of i lost
of i lost data
i lost data packets
lost data packets excluding
data packets excluding the
packets excluding the repair
but the burst could
the burst could swallow
burst could swallow both
could swallow both the
swallow both the repair
both the repair and
the repair and the
repair and the last
and the last data
the last data packet
last data packet in
data packet in it
packet in it as
in it as they
it as they are
as they are not
they are not separated
are not separated by
not separated by the
separated by the requisite
by the requisite interleave
the solution to this
p in every round
solution to this is
to this is simple
this is simple delay
is simple delay sending
pool i uses its
i uses its mining
simple delay sending the
uses its mining power
its mining power of
delay sending the repair
mining power of m
sending the repair packet
the repair packet generated
repair packet generated by
packet generated by a
generated by a repair
by a repair bin
a repair bin until
repair bin until the
bin until the next
until the next time
the next time a
j used for direct
next time a data
used for direct mining
time a data packet
for direct mining p
a data packet is
data packet is added
packet is added to
is added to the
added to the now
to the now empty
the now empty bin
and shares it among
which happens i packets
shares it among its
it among its m
happens i packets later
i packets later and
packets later and introduces
later and introduces the
and introduces the required
introduces the required interleave
the required interleave between
required interleave between the
interleave between the repair
between the repair packet
the repair packet and
repair packet and the
packet and the last
and the last data
the last data packet
last data packet included
data packet included in
packet included in it
all sums are over
notice that although transmitting
sums are over the
that although transmitting the
are over the range
although transmitting the xor
transmitting the xor immediately
the xor immediately results
xor immediately results in
immediately results in faster
results in faster recovery
doing so also reduces
so also reduces the
also reduces the probability
reduces the probability of
the probability of a
probability of a lost
of a lost packet
a lost packet being
lost packet being recovered
off results in a
results in a minor
in a minor control
a minor control knob
minor control knob permitting
control knob permitting us
denote the direct mining
knob permitting us to
the direct mining revenue
permitting us to balance
direct mining revenue density
us to balance speed
mining revenue density of
to balance speed against
revenue density of each
balance speed against burst
density of each pool
speed against burst tolerance
our default configuration is
default configuration is to
configuration is to transmit
is to transmit the
which is a constant
to transmit the xor
is a constant factor
transmit the xor immediately
envelope analysis to start
analysis to start with
we note that no
note that no two
that no two repair
no two repair packets
two repair packets generated
repair packets generated at
packets generated at different
generated at different interleaves
at different interleaves i
will have more than
have more than one
more than one data
than one data packet
one data packet in
data packet in common
packet in common as
in common as long
common as long as
as long as the
long as the least
as the least common
the least common multiple
the pool game in
pool game in the
game in the pool
in the pool game
the pool game pools
pool game pools try
game pools try to
of the interleaves is
pools try to optimize
the interleaves is greater
try to optimize their
interleaves is greater than
to optimize their infiltration
is greater than r
optimize their infiltration rates
greater than r i
their infiltration rates of
infiltration rates of other
rates of other pools
of other pools to
other pools to maximize
pools to maximize their
to maximize their revenue
pairings of repair bins
of repair bins in
repair bins in two
bins in two different
the overall number of
in two different layers
overall number of miners
two different layers with
number of miners and
different layers with interleaves
of miners and the
layers with interleaves i
miners and the number
and the number of
the number of miners
number of miners loyal
of miners loyal to
miners loyal to each
loyal to each pool
to each pool remain
each pool remain constant
pool remain constant throughout
remain constant throughout the
constant throughout the game
time progresses in rounds
let s be a
s be a constant
be a constant integer
a constant integer large
constant integer large enough
integer large enough that
large enough that revenue
enough that revenue can
that revenue can be
revenue can be approximated
can be approximated as
be approximated as its
approximated as its convergence
as its convergence limit
a good rule of
good rule of thumb
rule of thumb is
of thumb is to
in each round the
thumb is to select
each round the system
is to select interleaves
round the system takes
to select interleaves that
the system takes s
select interleaves that are
system takes s steps
interleaves that are relatively
takes s steps and
that are relatively prime
s steps and then
are relatively prime to
steps and then a
relatively prime to maximize
and then a single
prime to maximize their
then a single pool
to maximize their lcm
picked with a round
and also ensure that
also ensure that the
ensure that the larger
that the larger interleave
the larger interleave is
larger interleave is greater
interleave is greater than
is greater than r
may change its infiltration
change its infiltration rates
its infiltration rates of
infiltration rates of all
rates of all other
of all other pools
let us assume that
us assume that packets
assume that packets are
that packets are dropped
packets are dropped with
the total revenue of
are dropped with uniform
total revenue of each
revenue of each step
of each step is
each step is normalized
step is normalized to
given a lost data
a lost data packet
what is the probability
is the probability that
so the revenue per
the probability that we
the revenue per round
probability that we can
revenue per round is
that we can recover
per round is one
we can recover it
the pool taking a
pool taking a step
we can recover a
taking a step knows
can recover a data
a step knows the
recover a data packet
step knows the rate
a data packet if
knows the rate of
data packet if at
the rate of infiltrators
packet if at least
rate of infiltrators attacking
if at least one
of infiltrators attacking it
at least one of
least one of the
one of the c
of the c xors
the c xors containing
though not their identity
c xors containing it
xors containing it is
containing it is re
and the revenue rates
the revenue rates of
revenue rates of each
rates of each of
of each of the
each of the other
of the other pools
this knowledge is required
knowledge is required to
is required to optimize
required to optimize a
local recovery for receiver
to optimize a pool
recovery for receiver loss
optimize a pool s
for receiver loss ceived
a pool s revenue
receiver loss ceived correctly
loss ceived correctly and
ceived correctly and usable
as we see next
we explain in section
explain in section viii
in section viii how
section viii how a
viii how a pool
how a pool can
all the other data
a pool can technically
the other data packets
pool can technically obtain
other data packets in
can technically obtain this
data packets in it
technically obtain this knowledge
packets in it have
in it have also
it have also been
have also been received
also been received correctly
general analysis recall that
analysis recall that mi
the probability of in
recall that mi is
probability of in the
that mi is the
of in the absence
mi is the number
in the absence of
is the number of
the absence of intelligent
the number of miners
absence of intelligent flow
number of miners loyal
of intelligent flow control
of miners loyal to
intelligent flow control mechanisms
miners loyal to pool
flow control mechanisms like
loyal to pool i
control mechanisms like which
mechanisms like which is
like which is simply
is the number of
the number of miners
number of miners used
of miners used by
miners used by pool
used by pool i
by pool i to
pool i to infiltrate
the probability of a
i to infiltrate pool
probability of a received
to infiltrate pool j
of a received tcp
infiltrate pool j at
pool j at step
j at step t
the mining rate of
mining rate of pool
rate of pool i
of pool i is
pool i is therefore
inexpensive xor being unusable
i is therefore the
xor being unusable is
is therefore the number
being unusable is the
therefore the number of
unusable is the complement
the number of its
number of its loyal
of its loyal miners
its loyal miners minus
loyal miners minus the
miners minus the miners
minus the miners it
the miners it uses
miners it uses for
it uses for infiltration
this effective mining rate
effective mining rate is
mining rate is divided
rate is divided by
is divided by the
divided by the total
by the total mining
the total mining rate
total mining rate in
mining rate in the
rate in the system
namely the number of
the number of all
number of all miners
of all miners that
all miners that do
miners that do not
that do not engage
do not engage in
not engage in block
engage in block withholding
hosts can be easily
can be easily overwhelmed
be easily overwhelmed and
easily overwhelmed and drop
overwhelmed and drop packets
and drop packets during
drop packets during traffic
packets during traffic spikes
during traffic spikes or
denote the direct mining
traffic spikes or cpu
the direct mining rate
direct mining rate of
mining rate of pool
rate of pool i
of pool i at
pool i at step
i at step t
at step t by
step t by pp
t by pp mi
by pp mi j
the probability x of
probability x of a
x of a sent
of a sent xor
a sent xor being
sent xor being nance
xor being nance tasks
being nance tasks like
nance tasks like garbage
tasks like garbage collection
reliable applicationdropped or unusable
applicationdropped or unusable is
or unusable is the
unusable is the sum
is the sum of
the sum of the
sum of the probability
of the probability that
the probability that it
probability that it level
that it level protocols
it level protocols layered
level protocols layered over
protocols layered over udp
layered over udp for
over udp for reliable
udp for reliable multiwas
for reliable multiwas dropped
reliable multiwas dropped and
multiwas dropped and the
dropped and the probability
and the probability that
the probability that it
probability that it was
that it was received
it was received and
was received and cast
k the revenue of
the revenue of pool
revenue of pool i
of pool i in
pool i in step
i in step t
in step t taken
step t taken through
t taken through infiltration
taken through infiltration from
through infiltration from pool
infiltration from pool j
from pool j s
or high speed data
pool j s revenue
high speed data transfer
j s revenue in
s revenue in step
revenue in step t
pool i distributes this
i distributes this revenue
distributes this revenue among
this revenue among its
revenue among its mi
i members loyal and
members loyal and infiltrators
define the p p
the p p infiltration
p p infiltration matrix
p infiltration matrix by
infiltration matrix by its
matrix by its i
i ij the revenue
ij the revenue density
the revenue density of
revenue density of pool
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
end of step t
of step t is
step t is its
t is its revenue
is its revenue from
its revenue from direct
revenue from direct mining
would ordinarily go back
from direct mining together
ordinarily go back to
direct mining together with
go back to the
mining together with its
back to the sender
together with its revenue
to the sender to
with its revenue from
the sender to retrieve
its revenue from infiltrated
sender to retrieve the
revenue from infiltrated pools
to retrieve the lost
retrieve the lost packet
divided by the number
by the number of
even though it was
the number of its
number of its loyal
though it was dropped
of its loyal miners
its loyal miners together
it was dropped at
loyal miners together with
miners together with block
was dropped at the
dropped at the receiver
at the receiver after
the receiver after since
withholding infiltrators that attack
receiver after since it
infiltrators that attack it
after since it is
since it is easy
it is easy to
is easy to ensure
easy to ensure that
to ensure that no
ensure that no two
that no two xors
no two xors share
two xors share covering
xors share covering the
share covering the entire
covering the entire geographical
the entire geographical distance
more than one data
than one data packet
the usability probabilities of
usability probabilities of the
probabilities of the maelstrom
of the maelstrom proxy
the maelstrom proxy acts
maelstrom proxy acts as
proxy acts as a
acts as a local
as a local packet
a local packet cache
stordifferent xors are independent
the probability of all
probability of all ing
of all ing incoming
all ing incoming packets
ing incoming packets for
incoming packets for a
packets for a short
for a short period
a short period of
short period of time
period of time and
of time and prothe
time and prothe c
and prothe c xors
prothe c xors being
c xors being dropped
xors being dropped or
being dropped or unusable
dropped or unusable is
or unusable is xc
viding hooks that allow
hooks that allow protocols
that allow protocols to
allow protocols to first
protocols to first query
to first query the
first query the cache
query the cache the
the cache the probability
cache the probability of
the probability of correctly
probability of correctly receiving
of correctly receiving at
correctly receiving at least
and the revenue vector
receiving at least one
the revenue vector at
at least one usable
revenue vector at step
least one usable to
vector at step t
one usable to locate
at step t is
usable to locate missing
step t is hereinafter
to locate missing packets
t is hereinafter we
locate missing packets before
is hereinafter we move
missing packets before sending
hereinafter we move to
packets before sending retransmission
we move to a
before sending retransmission xor
move to a static
sending retransmission xor is
to a static state
a static state analysis
static state analysis and
state analysis and omit
analysis and omit the
and omit the t
omit the t argument
the t argument in
t argument in the
argument in the expressions
the probability of recovrequests
probability of recovrequests back
of recovrequests back to
recovrequests back to the
back to the sender
future versions of maelstrom
versions of maelstrom ering
of maelstrom ering the
maelstrom ering the lost
ering the lost data
the lost data packet
lost data packet is
which expands to could
expands to could potentially
to could potentially use
could potentially use knowledge
potentially use knowledge of
use knowledge of protocol
knowledge of protocol internals
of protocol internals to
since the row sums
the row sums of
row sums of the
sums of the infiltration
of the infiltration matrix
the infiltration matrix are
infiltration matrix are smaller
matrix are smaller than
are smaller than one
its largest eigenvalue is
largest eigenvalue is smaller
eigenvalue is smaller than
by intercepting and this
recall that difficulty is
intercepting and this closed
that difficulty is only
difficulty is only adjusted
is only adjusted periodically
form formula only gives
formula only gives us
and there are transient
only gives us a
there are transient effects
gives us a lower
are transient effects that
us a lower bound
transient effects that are
a lower bound satisfying
effects that are not
lower bound satisfying retransmission
that are not covered
bound satisfying retransmission requests
are not covered by
satisfying retransmission requests sent
not covered by this
retransmission requests sent by
covered by this stable
requests sent by the
sent by the receiver
by the receiver in
the receiver in on
receiver in on the
in on the recovery
on the recovery probability
we discuss this in
discuss this in section
this in section viii
since the xor usability
the xor usability for
miners miners miners the
miners miners the revenue
miners the revenue its
the revenue its infiltrators
revenue its infiltrators obtained
its infiltrators obtained from
infiltrators obtained from pool
or by resending packets
by resending packets when
resending packets when acmula
packets when acmula does
when acmula does not
acmula does not factor
does not factor in
not factor in the
factor in the probability
in the probability of
the probability of the
probability of the other
of the other data
the other data knowledgments
other data knowledgments are
data knowledgments are not
knowledgments are not observed
are not observed within
not observed within a
the revenue per loyal
observed within a certain
revenue per loyal pool
within a certain time
a certain time period
certain time period in
time period in an
period in an ack
miner is therefore r
packets in the xor
in the xor being
the xor being dropped
xor being dropped and
being dropped and recovered
we extend the analysis
extend the analysis to
the analysis to bursty
analysis to bursty losses
if the lost data
the lost data packet
controls its infiltration rate
its infiltration rate of
lost data packet was
infiltration rate of pool
data packet was part
packet was part of
was part of a
part of a loss
of a loss burst
a loss burst of
loss burst of size
burst of size b
repair packets generated at
packets generated at interleaves
generated at interleaves less
at interleaves less than
interleaves less than b
less than b are
than b are dropped
b are dropped or
are dropped or useless
dropped or useless with
or useless with high
useless with high probability
and will choose the
will choose the value
choose the value that
the value that maximizes
and we can discount
value that maximizes the
we can discount them
that maximizes the revenue
maximizes the revenue density
probability of recovering the
of recovering the data
recovering the data packet
the data packet is
data packet is then
on the first round
the first round of
first round of the
round of the pool
of the pool game
is the number of
the value of r
the number of xors
number of xors generated
of xors generated at
xors generated at interleaves
generated at interleaves greater
at interleaves greater than
is maximized at a
interleaves greater than b
maximized at a single
at a single point
a single point in
single point in the
point in the feasible
the formulae derived for
in the feasible range
formulae derived for xor
derived for xor usability
for xor usability still
xor usability still hold
since packet losses with
packet losses with more
losses with more than
with more than b
more than b intervening
than b intervening packets
b intervening packets between
intervening packets between them
packets between them have
between them have independent
them have independent probability
there is only correlation
is only correlation within
only correlation within the
correlation within the bursts
cannot not react to
not react to pool
how does this compare
does this compare to
this compare to traditional
this point is the
point is the stable
is the stable state
the stable state of
stable state of the
state of the system
and we denote the
codes such as reed
we denote the value
denote the value of
the value of x
c repair packets are
repair packets are generated
packets are generated and
are generated and sent
generated and sent for
and sent for every
sent for every r
for every r data
every r data packets
and the correct delivery
the correct delivery of
correct delivery of any
delivery of any r
of any r of
any r of the
r of the r
and the values of
the values of the
c packets transmitted is
values of the corresponding
packets transmitted is sufficient
of the corresponding revenues
transmitted is sufficient to
the corresponding revenues of
is sufficient to reconstruct
corresponding revenues of the
sufficient to reconstruct the
revenues of the pools
to reconstruct the original
of the pools with
reconstruct the original r
the pools with r
the original r data
original r data packets
given a lost data
a lost data packet
substituting the stable value
the stable value x
we can recover it
can recover it if
recover it if at
it if at least
if at least r
at least r packets
least r packets are
r packets are received
packets are received correctly
are received correctly in
we obtain the revenues
received correctly in the
obtain the revenues of
correctly in the encoding
the revenues of the
in the encoding set
revenues of the two
the encoding set of
of the two pools
encoding set of r
all are given in
c data and repair
are given in figure
data and repair packets
and repair packets that
repair packets that the
packets that the lost
that the lost packet
the lost packet belongs
lost packet belongs to
the probability of recovering
probability of recovering a
to simplify the expressions
of recovering a lost
recovering a lost packet
a lost packet is
lost packet is equivalent
packet is equivalent to
is equivalent to the
equivalent to the probability
to the probability of
the probability of losing
probability of losing c
or less packets from
less packets from the
packets from the total
from the total r
no attack if no
attack if no pool
since the number of
if no pool engages
the number of other
no pool engages in
number of other lost
pool engages in block
of other lost packets
engages in block withholding
other lost packets in
lost packets in the
packets in the xor
in the xor is
the xor is a
xor is a random
is a random variable
a random variable y
random variable y and
variable y and has
y and has a
and has a binomial
has a binomial distribution
a binomial distribution with
binomial distribution with parameters
and we have i
is the summation z
the summation z c
each miner s revenue
miner s revenue is
s revenue is proportional
revenue is proportional to
is proportional to its
proportional to its power
be it in a
it in a pool
in a pool or
a pool or working
pool or working solo
o ne attacker we
ne attacker we begin
we plot the recovery
attacker we begin our
plot the recovery probability
we begin our analysis
the recovery probability curves
begin our analysis with
recovery probability curves for
our analysis with a
probability curves for layered
analysis with a simplified
curves for layered interleaving
with a simplified game
for layered interleaving and
a simplified game of
layered interleaving and reed
simplified game of two
game of two pools
solomon against uniformly random
against uniformly random loss
uniformly random loss rate
note that the curves
that the curves are
the curves are very
curves are very close
are very close to
very close to each
close to each other
especially in the loss
miners outside both pools
in the loss range
outside both pools mine
the loss range of
both pools mine solo
loss range of interest
range of interest between
or with closed pools
with closed pools that
closed pools that do
pools that do not
that do not attack
do not attack and
not attack and cannot
attack and cannot be
and cannot be attacked
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the dashed red arrow
dashed red arrow indicates
red arrow indicates that
arrow indicates that x
implementation details we initially
details we initially implemented
we initially implemented and
initially implemented and evaluated
implemented and evaluated maelstrom
and evaluated maelstrom as
evaluated maelstrom as a
maelstrom as a user
s mining power infiltrates
performance turned out to
mining power infiltrates pool
turned out to be
out to be limited
to be limited by
be limited by copying
limited by copying and
with a block withholding
by copying and context
a block withholding attack
and we subsequently reimplemented
does not engage in
we subsequently reimplemented the
not engage in block
subsequently reimplemented the system
engage in block withholding
reimplemented the system as
the system as a
system as a module
as a module that
a module that runs
all of its m
module that runs within
that runs within the
runs within the linux
loyal miners work on
miners work on its
work on its behalf
on the other hand
the other hand does
other hand does not
hand does not employ
does not employ x
at an encoding rate
an encoding rate of
of its loyal miners
and its direct mining
its direct mining power
direct mining power is
mining power is only
power is only m
the experimental prototype of
experimental prototype of the
prototype of the kernel
of the kernel version
the kernel version reaches
kernel version reaches output
version reaches output speeds
reaches output speeds close
output speeds close to
gigabit per second of
the bitcoin system normalizes
per second of combined
bitcoin system normalizes these
second of combined data
system normalizes these rates
of combined data and
normalizes these rates by
combined data and fec
these rates by the
data and fec traffic
rates by the total
by the total number
the total number of
total number of miners
limited only by the
number of miners that
only by the capacity
of miners that publish
by the capacity of
miners that publish full
the capacity of the
that publish full proofs
capacity of the outbound
of the outbound network
the outbound network card
namely all miners but
all miners but x
lambda networks are already
networks are already reaching
are already reaching speeds
already reaching speeds of
the pools direct revenues
pools direct revenues are
and higher speeds are
direct revenues are therefore
higher speeds are a
revenues are therefore m
speeds are a certainty
are a certainty down
a certainty down the
certainty down the road
we envision maelstrom as
envision maelstrom as a
maelstrom as a small
as a small rack
style cluster of blade
each acting as an
acting as an individual
as an individual proxy
traffic would be distributed
would be distributed over
be distributed over such
distributed over such a
over such a rack
such a rack by
a rack by partitioning
rack by partitioning the
by partitioning the address
partitioning the address space
the address space of
address space of the
space of the remote
of the remote datacenter
the remote datacenter and
remote datacenter and routing
datacenter and routing different
and routing different segments
routing different segments of
different segments of the
segments of the space
of the space through
the space through distinct
space through distinct maelstrom
through distinct maelstrom appliance
distinct maelstrom appliance pairs
divides its revenue among
its revenue among its
revenue among its loyal
among its loyal miners
its loyal miners and
loyal miners and the
we plan to experiment
miners and the miners
plan to experiment with
and the miners that
to experiment with such
the miners that infiltrated
experiment with such configurations
miners that infiltrated it
which would also permit
its revenue density is
would also permit us
revenue density is therefore
also permit us to
density is therefore r
permit us to explore
us to explore faulttolerance
to explore faulttolerance issues
if a maelstrom blade
a maelstrom blade fails
and to support load
balancing schemes that might
schemes that might vary
that might vary the
might vary the ip
vary the ip address
the ip address space
ip address space partitioning
address space partitioning dynamically
space partitioning dynamically to
partitioning dynamically to spread
dynamically to spread the
to spread the encoding
spread the encoding load
the encoding load over
encoding load over multiple
load over multiple machines
we present the implementation
present the implementation and
the implementation and performance
implementation and performance of
and performance of a
performance of a single
the kernel implementation is
kernel implementation is a
implementation is a module
is a module for
a module for linux
with hooks into the
hooks into the kernel
into the kernel packet
the kernel packet filter
maelstrom proxies work in
proxies work in pairs
one on each side
on each side of
each side of the
side of the long
of the long haul
the long haul link
game progress bitcoin network
progress bitcoin network figure
each proxy acts both
proxy acts both as
acts both as an
both as an ingress
as an ingress and
an ingress and egress
ingress and egress temporarily
in case all but
case all but one
all but one of
but one of the
one of the missing
we obtain the expression
of the missing packets
obtain the expression for
the expression for r
the missing packets are
missing packets are router
packets are router at
are router at the
router at the same
at the same time
the same time since
same time since they
time since they handle
since they handle duplex
they handle duplex traffic
handle duplex traffic in
duplex traffic in received
traffic in received later
in received later or
received later or recovered
later or recovered through
or recovered through other
recovered through other xors
allowing the following manner
the recovery of the
recovery of the remaining
of the remaining missing
the remaining missing packet
remaining missing packet from
missing packet from this
packet from this xor
in practice we stored
practice we stored data
we stored data and
stored data and xor
data and xor packets
and xor packets in
xor packets in dou
packets in dou the
in dou the egress
dou the egress router
the egress router captures
egress router captures ip
router captures ip packets
captures ip packets and
ip packets and creates
packets and creates re
ble buffered red black
buffered red black trees
red black trees for
byte packets and dundant
packets and dundant fec
and dundant fec packets
divides its revenue among
its revenue among its
revenue among its registered
among its registered miners
the original ip packets
original ip packets are
the revenue includes both
revenue includes both its
includes both its direct
both its direct mining
its direct mining revenue
direct mining revenue and
mining revenue and b
numerical analysis we analyze
analysis we analyze this
we analyze this game
entries this occupies around
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
by finding the x
routed through unaltered as
through unaltered as they
unaltered as they would
as they would have
they would have been
would have been at
have been at the
been at the send
and substituting this value
substituting this value for
this value for r
the repair bins in
repair bins in the
bins in the layered
in the layered interoriginally
the redundant packets are
redundant packets are then
packets are then forwarded
we vary the sizes
are then forwarded leaving
vary the sizes of
then forwarded leaving scheme
the sizes of the
forwarded leaving scheme store
sizes of the pools
leaving scheme store incrementally
of the pools through
scheme store incrementally computed
the pools through the
store incrementally computed xors
pools through the entire
incrementally computed xors and
through the entire feasible
computed xors and to
the entire feasible range
xors and to the
entire feasible range and
and to the remote
feasible range and depict
to the remote ingress
range and depict the
the remote ingress router
and depict the optimal
remote ingress router via
depict the optimal x
ingress router via a
router via a udp
via a udp channel
lists of data packet
of data packet headers
and the corresponding revenues
without the data packet
the corresponding revenues in
the data packet payloads
corresponding revenues in figure
resulting in low storage
in low storage overheads
low storage overheads for
each point in each
storage overheads for each
point in each graph
overheads for each layer
in each graph represents
for each layer the
each graph represents the
each layer the ingress
graph represents the equilibrium
layer the ingress router
represents the equilibrium point
the ingress router captures
the equilibrium point of
ingress router captures and
equilibrium point of a
router captures and stores
point of a game
captures and stores ip
of a game with
and stores ip packets
a game with the
stores ip packets that
game with the corresponding
ip packets that rise
with the corresponding m
packets that rise linearly
that rise linearly with
rise linearly with the
linearly with the value
with the value of
the value of the
value of the interleave
where we normalize m
the coming from the
coming from the direction
from the direction of
the direction of the
direction of the egress
of the egress router
upon memory footprint for
memory footprint for a
footprint for a long
the top right half
top right half of
right half of the
half of the range
running proxy was around
of the range in
proxy was around receipt
the range in all
was around receipt of
range in all graphs
around receipt of a
in all graphs is
receipt of a redundant
all graphs is not
of a redundant packet
graphs is not feasible
an ip packet is
as the sum of
ip packet is recov
the sum of m
mb in our experiments
ered if there is
if there is an
there is an opportunity
is an opportunity to
we use this range
an opportunity to do
use this range as
opportunity to do so
this range as a
range as a reference
as a reference color
redundant packets that can
packets that can be
and we use a
that can be used
we use a dashed
can be used at
use a dashed line
be used at a
a dashed line to
used at a later
dashed line to show
at a later time
line to show the
a later time are
to show the bound
later time are stored
show the bound between
the bound between this
bound between this value
between this value within
this value within the
value within the feasible
if the redundant packet
within the feasible range
the redundant packet is
redundant packet is useless
packet is useless it
is useless it is
useless it is immediately
it is immediately dis
a shows the optimal
shows the optimal infiltration
the optimal infiltration rate
in the entire feasible
the entire feasible range
entire feasible range we
feasible range we see
range we see that
we see that pool
other performance enhancing roles
performance enhancing roles carded
chooses a strictly positive
a strictly positive value
strictly positive value for
positive value for x
upon recovery the ip
recovery the ip packet
the ip packet is
ip packet is sent
packet is sent through
is sent through maelstrom
sent through maelstrom appliances
through maelstrom appliances can
maelstrom appliances can optionally
appliances can optionally aggregate
can optionally aggregate small
optionally aggregate small suba
aggregate small suba raw
small suba raw socket
suba raw socket to
raw socket to its
the revenue of pool
socket to its intended
to its intended destination
is depicted in figure
kilobyte packets from different
packets from different flows
b and in the
from different flows into
and in the entire
different flows into larger
in the entire feasible
flows into larger ones
the entire feasible region
into larger ones for
entire feasible region it
larger ones for using
feasible region it is
ones for using fec
region it is strictly
for using fec requires
it is strictly larger
using fec requires that
is strictly larger than
fec requires that each
requires that each data
that each data packet
each data packet have
data packet have a
packet have a unique
have a unique better
a unique better communication
which the pool would
unique better communication efficiency
the pool would have
better communication efficiency over
pool would have gotten
communication efficiency over the
would have gotten without
efficiency over the long
have gotten without attacking
distance identifier that the
identifier that the receiver
that the receiver can
the receiver can use
receiver can use to
can use to keep
use to keep track
to keep track of
keep track of re
in split flow control
split flow control mode
flow control mode they
control mode they can
mode they can ceived
they can ceived data
can ceived data packets
ceived data packets and
data packets and to
c depicts the revenue
packets and to identify
depicts the revenue of
and to identify missing
the revenue of pool
to identify missing data
identify missing data packets
missing data packets perform
data packets perform send
side buffering of in
which is strictly smaller
is strictly smaller than
flight data for multiin
data for multiin a
in the entire range
for multiin a repair
multiin a repair packet
if we had access
we had access to
had access to end
note that the total
that the total system
the total system mining
total system mining power
system mining power is
mining power is reduced
power is reduced when
is reduced when pool
we gigabyte flows that
gigabyte flows that exceed
flows that exceed the
that exceed the sending
chooses to infiltrate pool
exceed the sending end
host s buffercould have
s buffercould have added
buffercould have added a
have added a header
added a header to
a header to each
header to each packet
the revenue of third
to each packet with
revenue of third parties
each packet with a
packet with a unique
with a unique ing
a unique ing capacity
miners not in either
not in either pool
maelstrom appliances can act
appliances can act as
can act as mulsequence
act as mulsequence number
we intercept traffic trans
appliances send multicast packparently
send multicast packparently and
multicast packparently and need
packparently and need to
and need to route
therefore pays for the
need to route it
pays for the increased
to route it without
for the increased revenue
route it without modification
the increased revenue of
it without modification or
increased revenue of its
without modification or addi
revenue of its attacker
of its attacker and
its attacker and everyone
attacker and everyone else
and everyone else in
ets to each other
everyone else in the
to each other across
else in the system
each other across the
other across the long
implications to the general
to the general case
the general case consider
general case consider the
case consider the case
consider the case of
the case of p
case of p pools
for any choice of
any choice of the
choice of the pools
we identify ip multicast
of the pools sizes
the pools sizes m
to spread them within
spread them within their
them within their datacenters
ip packets by a
packets by a tuple
by a tuple consisting
a tuple consisting of
tuple consisting of the
at least one pool
consisting of the source
least one pool will
of the source and
one pool will choose
the source and des
pool will choose to
will choose to perform
choose to perform block
to perform block withholding
appliances can take on
can take on other
take on other existing
on other existing roles
other existing roles in
existing roles in the
roles in the tination
in the tination ip
the tination ip address
size of the ip
of the ip datacenter
acting as security and
as security and vpn
security and vpn gateways
and vpn gateways and
vpn gateways and as
gateways and as header
and as header plus
as header plus data
and a checksum over
a checksum over the
checksum over the ip
over the ip data
the ip data pay
conventional performance enhancing proxies
the checksum over the
checksum over the payload
over the payload is
the payload is necessary
payload is necessary since
is necessary since the
necessary since the ip
since the ip identification
the ip identification field
ip identification field is
identification field is only
bits long and a
long and a single
and a single pair
a single pair of
single pair of end
hosts communicating at high
communicating at high speeds
at high speeds will
evaluation use the same
use the same identifier
the same identifier for
same identifier for different
identifier for different data
for different data packets
different data packets within
data packets within a
packets within a fairly
within a fairly short
a fairly short interval
fairly short interval unless
short interval unless the
interval unless the checksum
unless the checksum is
the checksum is added
checksum is added to
is added to we
added to we evaluated
to we evaluated maelstrom
we evaluated maelstrom on
evaluated maelstrom on the
maelstrom on the emulab
on the emulab testbed
the emulab testbed at
emulab testbed at utah
testbed at utah differentiate
at utah differentiate between
utah differentiate between them
for all the experiments
we used a dumbbell
used a dumbbell topoltifiers
a dumbbell topoltifiers result
dumbbell topoltifiers result in
topoltifiers result in garbled
result in garbled recovery
in garbled recovery by
garbled recovery by maelstrom
an event ogy of
event ogy of two
ogy of two clusters
of two clusters of
two clusters of nodes
clusters of nodes connected
of nodes connected via
nodes connected via routing
connected via routing nodes
via routing nodes which
routing nodes which will
nodes which will be
which will be caught
will be caught by
be caught by higher
caught by higher level
by higher level checksums
higher level checksums designed
level checksums designed with
checksums designed with a
designed with a high
latency link in between
link in between them
designed to emto deal
to emto deal with
emto deal with tranmission
deal with tranmission errors
with tranmission errors on
tranmission errors on commodity
errors on commodity networks
on commodity networks ulate
commodity networks ulate the
networks ulate the setup
ulate the setup in
the setup in figure
and ran the proxy
ran the proxy code
the proxy code on
proxy code on and
code on and hence
on and hence does
and hence does not
hence does not have
does not have significant
not have significant consequences
have significant consequences unless
significant consequences unless the
consequences unless the routers
shows the performance of
the performance of the
performance of the kernel
of the kernel version
the kernel version at
kernel version at gigabit
version at gigabit speeds
the remainder of the
remainder of the graphs
of the graphs it
the graphs it occurs
graphs it occurs frequently
the kernel version of
kernel version of maelstrom
version of maelstrom can
of maelstrom can generate
maelstrom can generate up
can generate up to
generate up to a
up to a show
to a show the
a show the performance
show the performance of
the performance of the
performance of the user
space version at slower
version at slower gigabit
at slower gigabit per
slower gigabit per second
gigabit per second of
per second of data
second of data and
of data and fec
data and fec traffic
to emulate the mtu
emulate the mtu difference
the mtu difference between
mtu difference between the
difference between the longput
between the longput data
the longput data rate
longput data rate depending
data rate depending on
rate depending on the
depending on the encoding
on the encoding rate
haul link and the
link and the datacenter
and the datacenter network
stable state where only
state where only pool
we were able to
were able to saturate
able to saturate the
to saturate the outgoing
saturate the outgoing card
the outgoing card at
outgoing card at set
card at set an
at set an mtu
set an mtu of
bytes on the network
on the network connecting
the network connecting the
network connecting the rates
connecting the rates as
the rates as high
rates as high as
with cpu overload occurring
cpu overload occurring at
two pools where one
overload occurring at end
pools where one infiltrates
where one infiltrates the
one infiltrates the other
hosts to the proxy
to the proxy and
the proxy and an
optimal infiltration rate x
proxy and an mtu
and an mtu of
as a function of
a function of pool
function of pool sizes
where each incoming data
each incoming data packet
incoming data packet had
data packet had to
packet had to be
had to be xored
to be xored long
haul link between proxies
the only exception is
only exception is figure
and the lines in
where we maintained equal
we maintained equal mtus
maintained equal mtus of
show the revenue density
the revenue density of
in a system with
a system with p
system with p pools
throughput metrics at the
is not an equilibrium
metrics at the receive
assume towards negation this
incoming data packets are
towards negation this is
data packets are buffered
negation this is not
packets are buffered so
this is not the
are buffered so that
is not the case
buffered so that they
so that they can
that they can be
they can be used
can be used in
be used in conjunction
used in conjunction with
in conjunction with figures
show that commodity tcp
is an equilibrium point
ip throughxors to recover
now consider a setting
throughxors to recover missing
consider a setting with
to recover missing data
a setting with only
recover missing data packets
setting with only pools
any received put collapses
received put collapses in
put collapses in the
collapses in the presence
in the presence of
the presence of non
and treat the other
treat the other pools
the other pools as
other pools as independent
pools as independent miners
and xor that is
this is the setting
xor that is missing
is the setting analyzed
that is missing more
the setting analyzed above
is missing more than
setting analyzed above and
missing more than one
analyzed above and we
more than one data
above and we have
than one data packet
and we have seen
one data packet is
we have seen there
data packet is stored
have seen there that
packet is stored that
seen there that pool
is stored that maelstrom
stored that maelstrom successfully
that maelstrom successfully masks
maelstrom successfully masks loss
successfully masks loss and
can increase its revenue
masks loss and prevents
increase its revenue by
loss and prevents this
its revenue by performing
revenue by performing a
by performing a block
performing a block withholding
a block withholding attack
block withholding attack on
withholding attack on pool
s infiltration rate by
infiltration rate by x
take this values back
this values back to
values back to the
back to the setting
to the setting at
the setting at hand
setting at hand with
at hand with p
hand with p pools
the revenue of pool
is better when x
ip no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
name size discusfish antpool
size discusfish antpool ghash
io btchine btcguild eligius
btchine btcguild eligius others
the six largest open
six largest open pool
largest open pool sizes
open pool sizes as
pool sizes as of
sizes as of january
their optimal infiltration rates
of each pool as
each pool as a
pool as a fraction
as a fraction of
a fraction of its
fraction of its size
if it attacked all
it attacked all others
attacked all others without
all others without reciprocation
and their revenue density
their revenue density when
revenue density when attacking
can improve its revenue
improve its revenue by
its revenue by attacking
revenue by attacking pool
attacks is not an
is not an equilibrium
not an equilibrium point
case as a test
as a test case
we take the pool
take the pool distribution
the pool distribution in
pool distribution in january
tcp no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
we analyze the cases
analyze the cases where
the cases where each
cases where each of
where each of the
each of the pools
of the pools attacks
the pools attacks all
pools attacks all other
attacks all other open
all other open pools
all of which behave
of which behave honestly
note that attacking all
that attacking all pools
attacking all pools with
all pools with force
pools with force proportional
with force proportional to
force proportional to their
proportional to their size
to their size yields
their size yields the
size yields the same
yields the same results
the same results as
same results as attacking
results as attacking a
as attacking a single
attacking a single pool
a single pool of
single pool of their
pool of their aggregate
of their aggregate size
plugging in the numbers
in the numbers into
the numbers into the
numbers into the analysis
into the analysis above
the analysis above shows
analysis above shows that
above shows that a
shows that a larger
that a larger pool
a larger pool needs
larger pool needs to
pool needs to use
needs to use a
to use a smaller
use a smaller ratio
a smaller ratio of
smaller ratio of its
ratio of its mining
of its mining power
its mining power for
mining power for infiltration
power for infiltration and
for infiltration and can
infiltration and can increase
and can increase its
can increase its revenue
increase its revenue density
its revenue density more
revenue density more than
density more than a
more than a small
than a small pool
achieves its optimum attack
its optimum attack rate
optimum attack rate at
of the pool s
the pool s mining
pool s mining power
increasing its revenue by
its revenue by almost
one way link latency
this amounts to a
amounts to a daily
to a daily revenue
a daily revenue increase
daily revenue increase of
revenue increase of b
usd at the exchange
at the exchange rate
the exchange rate on
exchange rate on that
rate on that date
this represents a considerable
represents a considerable increase
a considerable increase of
way latency collapse from
considerable increase of the
latency collapse from occurring
increase of the pools
of the pools net
the pools net revenue
shows the performance of
the performance of the
performance of the user
for the smallest pool
space version on a
the attack is much
attack is much less
is much less profitable
to reach the optimum
mbps link and figure
reach the optimum it
the optimum it needs
optimum it needs almost
it needs almost a
needs almost a third
almost a third of
a third of its
shows the kernel version
third of its power
the kernel version on
of its power for
kernel version on a
its power for attacking
power for attacking but
for attacking but increases
attacking but increases its
but increases its revenue
increases its revenue density
its revenue density by
revenue density by merely
the experiment in each
experiment in each case
in each case involves
each case involves running
case involves running iperf
flows from one node
from one node to
one node to another
node to another across
to another across the
another across the long
distance link with and
link with and without
with and without intermediary
and without intermediary maelstrom
without intermediary maelstrom proxies
intermediary maelstrom proxies and
maelstrom proxies and measuring
proxies and measuring obtained
and measuring obtained throughput
measuring obtained throughput while
obtained throughput while varying
throughput while varying loss
while varying loss rate
left graph on each
graph on each figure
the error bars on
error bars on the
bars on the graphs
on the graphs to
the graphs to the
graphs to the left
to the left are
the left are standard
left are standard errors
are standard errors of
standard errors of the
errors of the throughput
of the throughput over
the throughput over ten
throughput over ten runs
ip s cache of
s cache of tuning
cache of tuning parameters
of tuning parameters to
tuning parameters to allow
parameters to allow for
to allow for repeatable
allow for repeatable results
the clients in the
clients in the experiment
in the experiment are
the experiment are running
experiment are running tcp
two attacking pools system
ip reno on a
reno on a linux
the maelstrom parameters used
maelstrom parameters used are
parameters used are r
as a function of
a function of pool
function of pool sizes
space version involved running
version involved running a
involved running a single
second iperf flow from
iperf flow from one
flow from one node
from one node to
one node to another
node to another with
to another with and
another with and without
with and without maelstrom
and without maelstrom running
without maelstrom running on
maelstrom running on the
running on the routers
on the routers and
the routers and measuring
routers and measuring throughput
and measuring throughput while
measuring throughput while varying
throughput while varying the
while varying the random
varying the random loss
the random loss rate
random loss rate on
loss rate on the
rate on the link
on the link and
the link and the
link and the one
to test the kernel
test the kernel version
the kernel version at
kernel version at gigabit
version at gigabit speeds
t wo p ools
wo p ools we
we ran eight parallel
p ools we proceed
ran eight parallel iperf
ools we proceed to
eight parallel iperf flows
we proceed to analyze
parallel iperf flows from
proceed to analyze the
iperf flows from one
to analyze the case
flows from one node
from one node to
analyze the case where
one node to another
node to another for
the case where two
case where two pools
where two pools may
two pools may attack
pools may attack each
may attack each other
attack each other and
each other and the
other and the other
and the other miners
the other miners mine
other miners mine solo
the curves obtained from
again we have pool
curves obtained from the
obtained from the two
from the two versions
the two versions are
two versions are almost
versions are almost identical
we present both to
present both to show
both to show that
to show that the
show that the kernel
that the kernel version
the kernel version successfully
kernel version successfully scales
version successfully scales up
successfully scales up the
scales up the performance
up the performance of
the performance of the
performance of the user
controls its infiltration rate
its infiltration rate x
space version to hundreds
version to hundreds of
to hundreds of megabits
hundreds of megabits of
of megabits of traffic
megabits of traffic per
of traffic per second
also controls its infiltration
controls its infiltration rate
its infiltration rate x
we show how tcp
ip performance degrades on
performance degrades on a
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the total mining power
total mining power in
ms link as the
mining power in the
link as the loss
power in the system
as the loss rate
in the system is
the loss rate is
the system is m
loss rate is increased
system is m x
rate is increased from
the direct revenues r
maelstrom masks loss up
masks loss up to
of the pools from
the pools from mining
pools from mining are
from mining are their
mining are their effective
are their effective mining
their effective mining rates
without significant throughput degradation
without infiltrating mining power
with the kernel version
the kernel version achieving
divided by the total
kernel version achieving two
by the total mining
version achieving two orders
the total mining rate
achieving two orders of
two orders of magnitude
orders of magnitude higher
of magnitude higher throughput
magnitude higher throughput that
higher throughput that conventional
throughput that conventional tcp
the graphs on the
graphs on the right
on the right side
the right side of
right side of figures
ip throughput declining on
throughput declining on a
declining on a link
on a link of
a link of increasing
link of increasing length
of increasing length when
increasing length when subjected
length when subjected to
when subjected to uniform
subjected to uniform loss
to uniform loss rates
uniform loss rates of
the top line in
top line in the
line in the graphs
in the graphs is
the graphs is the
graphs is the performance
is the performance of
the performance of tcp
ip without loss and
without loss and provides
loss and provides an
and provides an upper
provides an upper bound
an upper bound for
upper bound for performance
bound for performance on
for performance on the
performance on the link
space and kernel versions
the total revenue of
total revenue of each
revenue of each pool
of each pool is
maelstrom masks packet loss
each pool is its
masks packet loss and
pool is its direct
packet loss and tracks
is its direct mining
loss and tracks the
its direct mining revenue
and tracks the lossless
tracks the lossless line
the lossless line closely
lagging only when the
only when the link
when the link latency
the link latency is
link latency is low
latency is low and
is low and tcp
ip s throughput is
s throughput is very
throughput is very high
ip to attain very
to attain very high
attain very high speeds
very high speeds on
high speeds on the
speeds on the gi
two pools infiltrating each
pools infiltrating each other
and the infiltration revenue
the infiltration revenue from
infiltration revenue from the
revenue from the previous
from the previous round
which is the attacked
is the attacked pool
the attacked pool s
attacked pool s total
pool s total revenue
s total revenue multiplied
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
is divided among its
divided among its loyal
among its loyal miners
its loyal miners and
loyal miners and miners
miners and miners that
and miners that infiltrated
miners that infiltrated it
at stable state this
stable state this is
state this is r
we obtain the following
obtain the following closed
the following closed expressions
following closed expressions for
closed expressions for each
we express the revenues
express the revenues as
the revenues as functions
revenues as functions of
as functions of x
way delivery latency against
delivery latency against loss
latency against loss rate
each pool controls only
pool controls only its
controls only its own
only its own infiltration
its own infiltration rate
in each round of
each round of the
round of the pool
of the pool game
each pool will optimize
pool will optimize its
will optimize its infiltration
optimize its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the other
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with r
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with x
an equilibrium exists where
equilibrium exists where neither
exists where neither pool
can improve its revenue
improve its revenue by
its revenue by changing
revenue by changing its
by changing its infiltration
changing its infiltration rate
any pair of values
pair of values x
such that arg maxx
packet delivery latencies gabit
delivery latencies gabit link
we had to set
had to set the
to set the mtu
set the mtu of
the mtu of the
mtu of the entire
of the entire path
the entire path to
entire path to be
path to be the
to be the maximum
which meant that the
meant that the longhaul
that the longhaul link
the longhaul link had
longhaul link had the
link had the same
had the same mtu
the same mtu as
same mtu as the
mtu as the inter
this resulted in the
resulted in the fragmentation
in the fragmentation of
the fragmentation of repair
fragmentation of repair packets
of repair packets sent
repair packets sent over
packets sent over udp
sent over udp on
over udp on the
udp on the long
haul link into two
link into two ip
into two ip packet
two ip packet fragments
since the loss of
the loss of a
loss of a single
of a single fragment
a single fragment resulted
single fragment resulted in
fragment resulted in the
resulted in the loss
in the loss of
the loss of the
loss of the repair
we observed a higher
observed a higher loss
a higher loss rate
higher loss rate for
loss rate for repairs
rate for repairs than
for repairs than for
repairs than for data
than for data packets
we expect performance to
expect performance to be
performance to be better
to be better on
be better on a
better on a network
on a network where
a network where the
network where the mtu
where the mtu of
the mtu of the
mtu of the long
haul link is truly
link is truly larger
is truly larger than
truly larger than the
larger than the mtu
than the mtu within
the mtu within each
mtu within each cluster
the feasible region for
feasible region for the
region for the pool
for the pool sizes
the pool sizes is
pool sizes is m
latency metrics to measure
metrics to measure the
to measure the latency
measure the latency effects
the latency effects of
latency effects of tcp
mbps stream between two
stream between two nodes
between two nodes over
two nodes over a
the revenue function for
revenue function for ri
function for ri is
for ri is concave
ri is concave in
is concave in xi
concave in xi for
in xi for all
xi for all feasible
and simultaneously ran a
for all feasible values
all feasible values of
feasible values of the
values of the variables
mbps flow alongside on
flow alongside on the
alongside on the same
on the same link
the same link to
same link to simulate
link to simulate a
to simulate a real
time stream combined with
stream combined with other
combined with other intercluster
with other intercluster traffic
therefore the solutions for
the solutions for equations
shows the average delivery
the average delivery latency
average delivery latency of
are unique and are
level packets in the
unique and are either
and are either at
are either at the
either at the borders
at the borders of
the borders of the
borders of the feasible
of the feasible region
the feasible region or
feasible region or where
region or where ri
as loss rates go
loss rates go up
from section v we
section v we know
v we know that
we know that no
shows the same scenario
attack is not an
the same scenario with
is not an equilibrium
same scenario with a
not an equilibrium point
scenario with a constant
with a constant uniformly
a constant uniformly random
constant uniformly random loss
uniformly random loss rate
random loss rate of
since each pool can
each pool can increase
pool can increase its
can increase its revenue
increase its revenue by
its revenue by choosing
revenue by choosing a
by choosing a strictly
choosing a strictly positive
a strictly positive infiltration
strictly positive infiltration rate
and varying oneway latency
maelstrom s delivery latency
s delivery latency is
delivery latency is almost
latency is almost exactly
is almost exactly equal
almost exactly equal to
exactly equal to the
equal to the one
way latency on the
latency on the link
ip takes more than
takes more than twice
more than twice as
than twice as long
twice as long once
as long once one
way latencies go past
is not a solution
not a solution to
a solution to equations
plots delivery latency against
nash equilibrium therefore exists
delivery latency against message
equilibrium therefore exists with
latency against message identifier
therefore exists with x
the spikes in latency
spikes in latency are
in latency are triggered
latency are triggered by
are triggered by losses
triggered by losses that
by losses that lead
losses that lead to
that lead to packets
lead to packets piling
to packets piling up
packets piling up at
piling up at the
up at the receiver
a key point is
key point is that
point is that we
is that we are
that we are plotting
we are plotting the
are plotting the delivery
plotting the delivery latency
the delivery latency of
delivery latency of all
latency of all packets
not just lost ones
ip delays correctly received
delays correctly received packets
correctly received packets while
received packets while waiting
packets while waiting for
while waiting for missing
waiting for missing packets
for missing packets sequenced
missing packets sequenced earlier
packets sequenced earlier by
sequenced earlier by the
earlier by the sender
by the sender the
the sender the effect
sender the effect of
the effect of this
effect of this is
of this is shown
this is shown in
is shown in figure
where single packet losses
single packet losses cause
packet losses cause spikes
losses cause spikes in
cause spikes in delivery
spikes in delivery latency
in delivery latency that
delivery latency that last
latency that last for
that last for hundreds
last for hundreds of
for hundreds of packets
the low data rate
low data rate in
data rate in the
rate in the flow
in the flow of
the flow of roughly
kb packets per rtt
packets per rtt makes
per rtt makes tcp
ip flow control delays
flow control delays at
control delays at the
delays at the sender
at the sender unlikely
given that the congestion
that the congestion control
the congestion control algorithm
congestion control algorithm is
control algorithm is reno
which implements fast recovery
implements fast recovery and
fast recovery and halves
recovery and halves the
and halves the congestion
halves the congestion window
the congestion window on
congestion window on packet
window on packet loss
on packet loss rather
packet loss rather than
loss rather than resetting
rather than resetting it
than resetting it completely
using symbolic computation tools
we see that there
see that there is
that there is a
there is a single
is a single pair
a single pair of
the maelstrom configuration used
single pair of values
maelstrom configuration used is
pair of values for
of values for which
values for which equation
holds for any feasible
for any feasible choice
any feasible choice of
feasible choice of m
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
analysis confirms these observations
we simulate the pool
simulate the pool game
the pool game for
pool game for a
game for a range
for a range of
a range of pool
range of pool sizes
for each choice of
each choice of pool
choice of pool sizes
we start the simulation
start the simulation when
the simulation when both
simulation when both pools
when both pools do
both pools do not
pools do not infiltrate
do not infiltrate each
not infiltrate each other
and the revenue densities
the revenue densities are
revenue densities are r
at each round one
each round one pool
round one pool chooses
one pool chooses its
pool chooses its optimal
chooses its optimal infiltration
its optimal infiltration rate
optimal infiltration rate based
infiltration rate based on
rate based on the
based on the pool
on the pool sizes
the pool sizes and
pool sizes and the
sizes and the rate
and the rate with
the rate with which
rate with which it
with which it is
which it is infiltrated
and we calculate the
we calculate the revenue
calculate the revenue after
the revenue after convergence
revenue after convergence with
after convergence with equation
recall the players in
the players in the
players in the pool
in the pool game
the pool game are
pool game are chosen
game are chosen with
are chosen with the
chosen with the round
with the round robin
the round robin policy
so the pools take
the pools take turns
and we let the
we let the game
let the game run
the game run until
game run until convergence
the results are illustrated
results are illustrated in
are illustrated in figure
each run with some
run with some m
values results in a
results in a single
in a single point
a single point in
single point in each
point in each graph
in each graph in
each graph in figure
we depict the infiltration
depict the infiltration rates
the infiltration rates of
infiltration rates of both
rates of both pools
of both pools x
relatively prime interleaves offer
prime interleaves offer better
interleaves offer better performance
offer better performance r
b and the pools
and the pools revenue
the pools revenue densities
pools revenue densities r
for each choice of
each choice of m
the values of x
layered interleaving and bursty
interleaving and bursty loss
and bursty loss thus
bursty loss thus far
loss thus far we
thus far we have
far we have shown
we have shown how
have shown how maelstrom
shown how maelstrom effectively
how maelstrom effectively hides
maelstrom effectively hides loss
effectively hides loss from
hides loss from tcp
ip for packets dropped
for packets dropped with
packets dropped with uniform
dropped with uniform randomness
are the points in
the points in each
points in each of
in each of the
each of the graphs
we examine the performance
of the graphs with
examine the performance of
the graphs with the
the performance of the
graphs with the respective
performance of the layered
with the respective coordinates
of the layered interleaving
the layered interleaving algorithm
showing how different parameterizations
how different parameterizations handle
different parameterizations handle bursty
j graphs we draw
parameterizations handle bursty loss
graphs we draw a
handle bursty loss patterns
we draw a border
draw a border around
a border around the
border around the region
around the region where
the region where there
we use a loss
region where there is
use a loss model
where there is no
a loss model where
loss model where packets
model where packets are
where packets are dropped
packets are dropped in
are dropped in bursts
attack by i in
dropped in bursts of
by i in equilibrium
in bursts of fixed
bursts of fixed length
for the ri graphs
the ri graphs we
ri graphs we draw
allowing us to study
graphs we draw a
us to study the
we draw a line
to study the impact
draw a line around
study the impact of
a line around the
the impact of burst
line around the region
impact of burst length
around the region where
of burst length on
the region where the
burst length on performance
region where the revenue
where the revenue is
the revenue is the
revenue is the same
is the same as
the link has a
the same as in
link has a one
same as in the
as in the no
ms and a loss
and a loss rate
a loss rate of
we first observe that
first observe that only
observe that only in
that only in extreme
only in extreme cases
in extreme cases a
extreme cases a pool
cases a pool does
a pool does not
pool does not attack
does not attack its
not attack its counterpart
at equilibrium a pool
equilibrium a pool will
a pool will refrain
pool will refrain from
will refrain from attacking
refrain from attacking only
from attacking only if
attacking only if the
only if the other
where it is varied
if the other pool
the other pool is
other pool is larger
pool is larger than
is larger than about
of the total mining
mbps flow of udp
the total mining power
flow of udp packets
of udp packets is
udp packets is sent
packets is sent over
is sent over it
we observe that a
observe that a pool
that a pool improves
a pool improves its
pool improves its revenue
we show that our
improves its revenue compared
show that our observation
its revenue compared to
that our observation in
revenue compared to the
our observation in section
compared to the no
attacks scenario only when
scenario only when it
only when it controls
is correct for high
when it controls a
correct for high loss
it controls a strict
for high loss rates
controls a strict majority
high loss rates if
a strict majority of
loss rates if the
strict majority of the
rates if the interleaves
majority of the total
if the interleaves are
of the total mining
the interleaves are relatively
the total mining power
interleaves are relatively prime
these are the small
performance improves substantially when
are the small triangular
improves substantially when loss
the small triangular regions
substantially when loss rates
small triangular regions in
when loss rates are
triangular regions in figures
loss rates are high
rates are high and
are high and losses
high and losses are
and losses are bursty
the graph plots the
graph plots the percentage
plots the percentage of
the percentage of lost
in the rest of
percentage of lost packets
the rest of the
of lost packets successfully
rest of the space
lost packets successfully recovered
packets successfully recovered on
successfully recovered on the
recovered on the y
the trapezoids in the
trapezoids in the figures
axis against an x
the revenue of the
revenue of the pool
axis of loss rates
of the pool is
of loss rates on
the pool is inferior
loss rates on a
pool is inferior compared
rates on a log
is inferior compared to
on a log scale
inferior compared to the
compared to the no
the maelstrom configuration used
maelstrom configuration used is
configuration used is r
the prisoner s dilemma
prisoner s dilemma in
s dilemma in a
dilemma in a healthy
in a healthy bitcoin
a healthy bitcoin environment
where neither pool controls
neither pool controls a
pool controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the mining
of the mining power
both pools will earn
pools will earn less
will earn less at
earn less at equilibrium
less at equilibrium than
at equilibrium than if
equilibrium than if both
than if both pools
if both pools ran
both pools ran without
pools ran without attacking
we can analyze in
can analyze in this
analyze in this case
in this case a
this case a game
case a game where
a game where each
game where each pool
where each pool chooses
each pool chooses either
pool chooses either to
chooses either to attack
either to attack and
to attack and optimize
attack and optimize its
and optimize its revenue
or to refrain from
to refrain from attacking
without loss of generality
as we have seen
we have seen in
have seen in section
seen in section v
can increase its revenue
we show the ability
increase its revenue above
show the ability of
the ability of layered
ability of layered interleaving
of layered interleaving to
layered interleaving to provide
interleaving to provide gracefully
to provide gracefully degrading
provide gracefully degrading performance
gracefully degrading performance in
degrading performance in the
does attack but pool
performance in the face
in the face of
the face of bursty
face of bursty loss
we denote the revenue
denote the revenue of
the revenue of pool
we plot the percentage
plot the percentage of
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
packets successfully recovered against
successfully recovered against the
the exact value of
recovered against the length
exact value of r
against the length of
the length of loss
length of loss bursts
of loss bursts for
loss bursts for two
depends on the values
bursts for two different
on the values of
for two different sets
the values of m
two different sets of
different sets of interleaves
and in the bottom
in the bottom graph
the bottom graph we
bottom graph we plot
graph we plot the
we plot the average
but it is always
plot the average latency
it is always smaller
the average latency at
is always smaller than
average latency at which
always smaller than one
latency at which the
at which the packets
which the packets were
the packets were recovered
as we have seen
we have seen above
recovery latency is defined
latency is defined as
is defined as the
defined as the difference
as the difference between
does choose to attack
the difference between the
difference between the eventual
between the eventual delivery
the eventual delivery time
eventual delivery time of
delivery time of the
time of the recovered
of the recovered packet
the recovered packet and
but does not surpass
recovered packet and the
does not surpass one
packet and the one
the game is summarized
way latency of the
game is summarized in
latency of the link
is summarized in figure
we confirmed that the
confirmed that the emulab
that the emulab link
the emulab link had
emulab link had almost
link had almost no
had almost no jitter
almost no jitter on
this is the classical
no jitter on correctly
is the classical prisoner
jitter on correctly delivered
the classical prisoner s
on correctly delivered packets
classical prisoner s dilemma
attack is the dominant
is the dominant strategy
way latency an accurate
latency an accurate estimate
an accurate estimate of
accurate estimate of expected
estimate of expected lossless
of expected lossless delivery
chooses to attack or
expected lossless delivery time
to attack or not
the revenue of pool
is larger when attacking
larger when attacking than
when attacking than when
attacking than when refraining
increasing the interleaves results
than when refraining from
the interleaves results in
when refraining from attack
interleaves results in much
results in much higher
in much higher recovery
much higher recovery percentages
higher recovery percentages at
and the same for
recovery percentages at large
the same for xxx
percentages at large burst
same for xxx xxx
at large burst sizes
for xxx xxx pool
no attack xxx pool
but percentage of packets
percentage of packets recovered
percentage of packets recovered
prisoner s dilemma for
s dilemma for two
dilemma for two pools
the revenue density of
revenue density of each
density of each pool
of each pool is
each pool is determined
pool is determined by
is determined by the
determined by the decision
by the decision of
the decision of both
decision of both pools
of both pools whether
both pools whether to
pools whether to attack
whether to attack or
to attack or not
the dominant strategy of
dominant strategy of each
strategy of each player
of each player is
each player is to
player is to attack
however the payoff of
the payoff of both
payoff of both would
of both would be
both would be larger
would be larger if
be larger if they
larger if they both
if they both refrain
they both refrain from
both refrain from attacking
at equilibrium of this
equilibrium of this attack
when both pools attack
the revenue of each
revenue of each pool
of each pool is
each pool is smaller
pool is smaller than
is smaller than its
smaller than its revenue
than its revenue if
its revenue if neither
revenue if neither pool
if neither pool attacked
the game is not
game is not played
is not played once
where each pool can
each pool can change
pool can change its
can change its strategy
change its strategy between
its strategy between attack
strategy between attack and
between attack and no
the pools can agree
to refrain from attacking
and in each round
in each round a
each round a pool
round a pool can
a pool can detect
pool can detect whether
can detect whether it
detect whether it is
whether it is being
it is being attacked
is being attacked and
being attacked and deduce
attacked and deduce that
and deduce that the
deduce that the other
that the other pool
the other pool is
other pool is violating
pool is violating the
is violating the agreement
cooperation where neither pool
where neither pool attacks
neither pool attacks is
pool attacks is a
attacks is a possible
is a possible stable
a possible stable state
despite the fact that
the fact that the
fact that the single
that the single nash
the single nash equilibrium
single nash equilibrium in
nash equilibrium in every
equilibrium in every round
in every round is
every round is to
round is to attack
layered interleaving recovery percentage
interleaving recovery percentage and
recovery percentage and latency
percentage and latency comes
and latency comes at
case as an example
latency comes at the
as an example we
comes at the cost
an example we take
at the cost of
example we take again
the cost of higher
we take again the
cost of higher recovery
take again the pool
of higher recovery latency
again the pool sizes
the pool sizes shown
pool sizes shown in
sizes shown in figure
and study the case
study the case where
the case where the
case where the two
where the two largest
the two largest pools
the optimal infiltration rates
out of the total
of the total system
the total system mining
total system mining power
set of interleaves catches
of interleaves catches almost
interleaves catches almost all
catches almost all packets
almost all packets in
all packets in an
packets in an extended
in an extended burst
an extended burst of
packets at an average
at an average latency
an average latency of
average latency of around
and the pools would
the pools would lose
while repairing all random
repairing all random singleton
all random singleton losses
random singleton losses within
the graphs also show
graphs also show recovery
also show recovery latency
show recovery latency rising
recovery latency rising gracefully
compared to the no
latency rising gracefully with
rising gracefully with the
gracefully with the increase
with the increase in
the increase in loss
increase in loss burst
in loss burst length
the longer the burst
q i dentical p
i dentical p ools
dentical p ools let
the longer it takes
p ools let there
longer it takes to
ools let there be
it takes to recover
let there be q
takes to recover the
there be q pools
to recover the lost
be q pools of
recover the lost packets
q pools of identical
pools of identical size
of identical size that
identical size that engage
the maelstrom configuration used
size that engage in
maelstrom configuration used is
that engage in block
configuration used is r
engage in block withholding
in block withholding against
block withholding against one
withholding against one another
other miners neither attack
miners neither attack nor
neither attack nor are
attack nor are being
nor are being attacked
in this case there
this case there exists
case there exists a
there exists a symmetric
exists a symmetric equilibrium
without loss of generality
a step of pool
it controls its attack
controls its attack rates
its attack rates each
attack rates each of
rates each of the
each of the other
of the other pools
and due to symmetry
due to symmetry they
to symmetry they are
symmetry they are all
they are all the
are all the same
the attack rate of
attack rate of pool
against any other pool
each of the other
of the other pools
the other pools can
other pools can attack
pools can attack its
can attack its peers
attack its peers as
its peers as well
all attack rates by
attack rates by all
rates by all attackers
by all attackers are
all attackers are identical
we show histograms of
show histograms of recovery
histograms of recovery latencies
of recovery latencies for
recovery latencies for the
latencies for the two
for the two interleave
the two interleave configurations
two interleave configurations under
the attack rate of
interleave configurations under different
attack rate of any
configurations under different burst
rate of any pool
under different burst lengths
of any pool other
any pool other than
the histograms confirm the
against any other pool
histograms confirm the trends
confirm the trends described
the trends described above
packet recoveries take longer
recoveries take longer from
take longer from left
longer from left to
from left to right
left to right as
to right as we
right as we increase
as we increase loss
we increase loss burst
increase loss burst length
and from top to
from top to bottom
top to bottom as
to bottom as we
bottom as we increase
as we increase the
we increase the interleave
increase the interleave values
the direct revenue of
direct revenue of each
revenue of each of
of each of the
each of the other
of the other pools
similarly denote by r
illustrates the difference between
the difference between a
difference between a traditional
between a traditional fec
a traditional fec code
traditional fec code and
fec code and layered
code and layered interleaving
the revenue densities of
and layered interleaving by
revenue densities of pool
layered interleaving by plotting
interleaving by plotting a
element moving average of
moving average of recovery
average of recovery latencies
of recovery latencies for
recovery latencies for both
latencies for both codes
are instantiated to mi
the channel is configured
channel is configured to
is configured to lose
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
singleton packets randomly at
packets randomly at a
randomly at a loss
at a loss rate
a loss rate of
and additionally lose long
additionally lose long bursts
lose long bursts of
packets at occasional intervals
both codes recovery latency
reed solomon layered interleaving
solomon versus layered interleaving
versus layered interleaving are
layered interleaving are configured
interleaving are configured with
are configured with r
and recover all lost
recover all lost packets
all lost packets reed
solomon uses an interleave
uses an interleave of
and layered interleaving uses
layered interleaving uses interleaves
interleaving uses interleaves of
and consequently both have
consequently both have a
both have a maximum
have a maximum tolerable
a maximum tolerable burst
maximum tolerable burst length
tolerable burst length of
we use a publicly
use a publicly available
a publicly available implementation
publicly available implementation of
available implementation of a
implementation of a reed
solomon code based on
code based on vandermonde
based on vandermonde matrices
the code is plugged
code is plugged into
is plugged into maelstrom
plugged into maelstrom instead
into maelstrom instead of
maelstrom instead of layered
instead of layered interleaving
showing that we can
that we can use
we can use new
can use new encodings
use new encodings within
new encodings within the
encodings within the same
within the same framework
the same framework seamlessly
solomon code recovers all
code recovers all lost
recovers all lost packets
all lost packets with
lost packets with roughly
packets with roughly the
with roughly the same
roughly the same latency
the same latency whereas
same latency whereas layered
latency whereas layered interleaving
whereas layered interleaving recovers
layered interleaving recovers singleton
interleaving recovers singleton losses
recovers singleton losses almost
singleton losses almost immediately
losses almost immediately and
almost immediately and exhibits
immediately and exhibits latency
and exhibits latency spikes
exhibits latency spikes whenever
latency spikes whenever the
spikes whenever the longer
whenever the longer loss
the longer loss burst
longer loss burst occurs
related work a significant
and solving we obtain
work a significant body
solving we obtain a
a significant body of
we obtain a single
significant body of work
obtain a single expression
body of work on
a single expression for
of work on application
single expression for any
work on application and
expression for any ri
on application and tcp
since in the symmetric
ip performance over high
in the symmetric case
the symmetric case we
symmetric case we have
case we have r
distance networks exists in
networks exists in the
exists in the context
in the context of
the context of high
the expression is shown
expression is shown in
is shown in equation
the use of parallel
use of parallel sockets
of parallel sockets for
parallel sockets for higher
sockets for higher throughput
for higher throughput in
higher throughput in the
throughput in the face
in the face of
the face of non
congestion loss was proposed
loss was proposed in
was proposed in psockets
given any value of
any value of q
value of q and
of q and mi
a number of protocols
number of protocols have
of protocols have been
protocols have been suggested
have been suggested as
been suggested as replacements
suggested as replacements for
as replacements for tcp
the feasible range of
ip in such settings
feasible range of the
in such settings xcp
range of the infiltration
of the infiltration rates
the infiltration rates is
within this range ri
this range ri is
range ri is continuous
and concave in x
the optimal point for
optimal point for pool
are a few but
a few but all
few but all require
but all require modifications
all require modifications to
require modifications to end
or the intervening network
some approaches seek to
approaches seek to differentiate
seek to differentiate between
to differentiate between congestion
differentiate between congestion and
since the function is
between congestion and non
the function is concave
function is concave the
is concave the equation
concave the equation yields
the equation yields a
equation yields a single
yields a single feasible
a single feasible solution
which is a function
is a function of
a function of the
function of the attack
of the attack rates
the attack rates of
attack rates of the
maelstrom is a transparent
rates of the other
is a transparent performance
of the other pools
a transparent performance enhancing
transparent performance enhancing proxy
as defined in rfc
to find a symmetric
find a symmetric equilibrium
numerous implementations of peps
implementations of peps exist
of peps exist for
peps exist for improving
exist for improving tcp
for improving tcp performance
improving tcp performance on
tcp performance on satellite
and obtain a single
but we are not
obtain a single feasible
we are not aware
a single feasible solution
are not aware of
not aware of any
aware of any peps
of any peps that
any peps that use
the equilibrium infiltration rate
peps that use fec
equilibrium infiltration rate and
that use fec to
infiltration rate and the
use fec to mask
rate and the matching
fec to mask errors
and the matching revenues
to mask errors on
the matching revenues are
mask errors on long
matching revenues are shown
revenues are shown in
are shown in equation
based fec for reliable
fec for reliable communication
for reliable communication was
reliable communication was first
communication was first explored
was first explored by
first explored by rizzo
as in the two
the revenue at the
revenue at the symmetric
at the symmetric equilibrium
the symmetric equilibrium is
symmetric equilibrium is inferior
equilibrium is inferior to
is inferior to the
inferior to the no
suggested the use of
the use of fec
use of fec for
of fec for tcp
up our analysis addresses
our analysis addresses the
analysis addresses the eventual
addresses the eventual revenue
the eventual revenue of
ip retransmissions over aggregated
eventual revenue of the
retransmissions over aggregated traffic
revenue of the pools
over aggregated traffic within
aggregated traffic within an
traffic within an overlay
within an overlay network
an overlay network in
assuming the mining difficulty
overlay network in the
the mining difficulty is
network in the commodity
mining difficulty is set
in the commodity internet
difficulty is set based
is set based on
set based on the
based on the effective
on the effective mining
the effective mining power
not including mining power
including mining power used
mining power used for
power used for withholding
uses fec for real
difficulty is updated only
is updated only periodically
updated only periodically every
modulating the rate of
the rate of encoding
rate of encoding adaptively
the use of end
host fec under tcp
when mining power in
mining power in the
power in the system
in the system is
ip has been explored
the system is regularly
has been explored in
system is regularly increasing
which has been true
has been true for
been true for the
true for the majority
for the majority of
the majority of bitcoin
majority of bitcoin s
of bitcoin s history
a multitude of different
multitude of different fec
of different fec encodings
different fec encodings exist
fec encodings exist in
encodings exist in literature
they can broadly be
can broadly be categorized
broadly be categorized into
no adjustment may be
be categorized into optimal
adjustment may be necessary
categorized into optimal erasure
into optimal erasure codes
optimal erasure codes and
erasure codes and near
if an attacker purchases
an attacker purchases new
attacker purchases new mining
purchases new mining hardware
new mining hardware and
mining hardware and employs
known optimal code is
hardware and employs it
optimal code is reed
and employs it directly
employs it directly for
it directly for block
directly for block withholding
which we described previously
this mining power is
we described previously as
mining power is never
described previously as generating
power is never included
previously as generating c
is never included in
as generating c repair
never included in the
generating c repair packets
included in the difficulty
c repair packets from
in the difficulty calculation
repair packets from r
the difficulty calculation the
packets from r source
difficulty calculation the system
from r source packets
calculation the system is
the system is never
system is never aware
is never aware of
never aware of it
any r of the
r of the resulting
of the resulting r
the difficulty is therefore
difficulty is therefore already
c packets can be
is therefore already correctly
packets can be used
therefore already correctly calculated
can be used to
already correctly calculated and
be used to reconstruct
correctly calculated and the
used to reconstruct the
calculated and the attack
to reconstruct the r
and the attack is
reconstruct the r source
the attack is profitable
the r source packets
attack is profitable immediately
optimal codes such as
if the mining power
codes such as tornado
the mining power is
such as tornado and
mining power is static
as tornado and lt
the attack becomes profitable
attack becomes profitable only
becomes profitable only after
profitable only after the
only after the bitcoin
after the bitcoin system
the bitcoin system has
bitcoin system has normalized
system has normalized the
has normalized the revenues
normalized the revenues by
the revenues by adjusting
revenues by adjusting difficulty
off encoding speed for
encoding speed for large
speed for large data
for large data sizes
large data sizes against
the revenue of an
data sizes against a
revenue of an attacking
sizes against a loss
of an attacking pool
against a loss of
an attacking pool is
a loss of optimality
attacking pool is reduced
loss of optimality the
pool is reduced due
of optimality the receiver
is reduced due to
optimality the receiver needs
reduced due to the
the receiver needs to
due to the reduction
receiver needs to receive
to the reduction in
needs to receive slightly
the reduction in block
to receive slightly more
reduction in block generation
receive slightly more than
in block generation of
slightly more than r
block generation of both
more than r source
generation of both the
than r source or
of both the attacking
r source or repair
both the attacking and
source or repair packets
the attacking and attacked
or repair packets to
attacking and attacked pools
repair packets to regenerate
packets to regenerate the
to regenerate the original
regenerate the original r
the original r data
original r data packets
optimal codes are extremely
codes are extremely fast
are extremely fast for
extremely fast for encoding
fast for encoding over
for encoding over large
encoding over large sets
over large sets of
large sets of data
sets of data but
of data but not
data but not of
but not of significant
not of significant importance
of significant importance for
significant importance for real
since optimal codes perform
optimal codes perform equally
codes perform equally well
perform equally well with
equally well with small
well with small data
with small data sizes
of particular relevance are
particular relevance are growth
relevance are growth codes
which use multiple encoding
use multiple encoding rates
multiple encoding rates for
encoding rates for different
rates for different overhead
for different overhead levels
layered interleaving uses multiple
interleaving uses multiple interleaves
uses multiple interleaves for
multiple interleaves for different
interleaves for different burst
for different burst resilience
different burst resilience levels
burst resilience levels without
resilience levels without modulating
levels without modulating the
without modulating the encoding
modulating the encoding rate
the effect of random
effect of random losses
of random losses on
random losses on tcp
ip has been studied
has been studied in
been studied in depth
studied in depth by
in depth by lakshman
padhye s analytical model
provides a means to
a means to gauge
means to gauge the
to gauge the impact
gauge the impact of
the impact of packet
impact of packet loss
of packet loss on
packet loss on tcp
while most published studies
most published studies of
published studies of packet
studies of packet loss
of packet loss are
packet loss are based
loss are based on
are based on the
based on the commodity
on the commodity internet
the commodity internet rather
commodity internet rather than
internet rather than highspeed
rather than highspeed lambda
than highspeed lambda links
study the sprint backbone
the sprint backbone and
sprint backbone and make
backbone and make two
and make two observations
make two observations that
two observations that could
observations that could be
that could be explained
could be explained by
be explained by non
links are rarely loaded
are rarely loaded at
rarely loaded at more
loaded at more than
of capacity and b
packet reordering events occur
reordering events occur for
events occur for some
occur for some flows
possibly indicating packet loss
indicating packet loss followed
packet loss followed by
loss followed by retransmissions
expression for ri in
future work scaling maelstrom
for ri in a
work scaling maelstrom to
ri in a system
scaling maelstrom to multiple
in a system with
maelstrom to multiple gigabits
a system with pools
to multiple gigabits per
system with pools of
multiple gigabits per second
with pools of equal
gigabits per second of
pools of equal size
per second of traffic
second of traffic will
of traffic will require
traffic will require small
will require small rack
style clusters of tens
clusters of tens of
of tens of machines
tens of machines to
of machines to distribute
machines to distribute encoding
to distribute encoding load
distribute encoding load over
we need to design
need to design intelligent
to design intelligent load
over mechanisms for such
mechanisms for such a
for such a scheme
we have described layered
have described layered interleaving
described layered interleaving with
layered interleaving with fixed
and the next step
the next step in
next step in extending
step in extending this
in extending this protocol
extending this protocol is
this protocol is to
protocol is to make
is to make it
to make it adaptive
changing interleaves and rate
interleaves and rate as
and rate as loss
rate as loss patterns
as loss patterns in
loss patterns in the
patterns in the link
in the link change
q mi q mi
conclusion modern distributed systems
modern distributed systems are
distributed systems are compelled
systems are compelled by
are compelled by real
world imperatives to coordinate
imperatives to coordinate across
to coordinate across datacenters
coordinate across datacenters separated
across datacenters separated by
q symmetric equilibrium values
symmetric equilibrium values for
equilibrium values for a
values for a system
for a system of
a system of q
system of q pools
of q pools of
q pools of equal
pools of equal sizes
countermeasures in order to
in order to choose
order to choose its
to choose its optimal
choose its optimal infiltration
its optimal infiltration rate
a pool has to
pool has to know
has to know the
to know the rate
know the rate at
the rate at which
rate at which it
at which it is
which it is attacked
and the revenue density
the revenue density of
revenue density of potential
density of potential victim
of potential victim pools
a pool can estimate
pool can estimate the
can estimate the rate
estimate the rate with
the rate with which
rate with which it
with which it is
which it is attacked
it is attacked by
is attacked by comparing
attacked by comparing the
by comparing the rates
comparing the rates of
the rates of partial
rates of partial and
of partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work it
of work it receives
work it receives from
it receives from its
receives from its miners
as explained in section
explained in section ii
in order to estimate
order to estimate the
to estimate the revenue
estimate the revenue densities
the revenue densities of
revenue densities of the
densities of the other
of the other pools
a pool can use
pool can use one
can use one of
use one of two
one of two methods
pools often publish this
often publish this data
publish this data to
this data to demonstrate
data to demonstrate their
to demonstrate their honesty
demonstrate their honesty to
their honesty to their
honesty to their miners
a pool can infiltrate
pool can infiltrate each
can infiltrate each of
infiltrate each of the
each of the other
of the other pools
the other pools with
other pools with some
pools with some nominal
with some nominal probing
some nominal probing mining
nominal probing mining power
probing mining power and
mining power and measure
power and measure the
and measure the revenue
measure the revenue density
the revenue density directly
revenue density directly by
density directly by monitoring
directly by monitoring the
by monitoring the probe
monitoring the probe s
the probe s rewards
probe s rewards from
s rewards from the
rewards from the pool
as in the case
in the case of
the case of classical
case of classical block
of classical block withholding
classical block withholding explained
block withholding explained in
withholding explained in section
explained in section ii
a pool might detect
pool might detect that
might detect that it
detect that it is
that it is being
it is being attacked
but cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners is
its miners is the
miners is the attacker
therefore a pool cannot
a pool cannot block
pool cannot block or
cannot block or punish
block or punish withholding
or punish withholding miners
various techniques can be
techniques can be used
can be used to
be used to encourage
used to encourage miners
to encourage miners to
encourage miners to submit
miners to submit full
to submit full blocks
a pool can pay
pool can pay a
can pay a bonus
pay a bonus for
a bonus for submitting
bonus for submitting a
for submitting a full
submitting a full proof
a full proof of
full proof of work
this would increase the
would increase the revenue
increase the revenue of
the revenue of the
revenue of the miner
of the miner that
the miner that found
miner that found a
that found a block
found a block while
a block while reducing
block while reducing the
while reducing the revenue
reducing the revenue of
the revenue of the
revenue of the other
of the other miners
the other miners from
other miners from this
miners from this block
while the average revenue
the average revenue of
average revenue of each
revenue of each miner
of each miner would
each miner would stay
miner would stay the
would stay the same
small miners will suffer
miners will suffer from
will suffer from higher
suffer from higher variance
from higher variance in
higher variance in revenue
another approach is to
approach is to introduce
latency histograms for i
is to introduce a
to introduce a joining
introduce a joining fee
a joining fee by
joining fee by paying
fee by paying new
by paying new miners
paying new miners less
new miners less for
miners less for their
less for their work
for their work until
their work until they
work until they have
until they have established
they have established a
have established a reputation
established a reputation with
a reputation with the
reputation with the pool
miners that seek flexibility
that seek flexibility may
seek flexibility may not
flexibility may not accept
may not accept this
not accept this policy
accept this policy and
this policy and choose
policy and choose another
and choose another pool
the pool can use
pool can use a
can use a honeypot
use a honeypot trap
a honeypot trap by
honeypot trap by sending
trap by sending the
by sending the miners
sending the miners tasks
the miners tasks which
miners tasks which it
tasks which it knows
which it knows will
it knows will result
knows will result in
will result in a
result in a full
in a full proof
a full proof of
full proof of work
if a miner fails
a miner fails to
miner fails to submit
fails to submit the
to submit the full
submit the full proof
the full proof of
full proof of work
proof of work it
of work it is
work it is tagged
it is tagged as
is tagged as an
tagged as an attacker
to prevent the attacker
prevent the attacker from
the attacker from learning
attacker from learning them
the honeypot tasks have
honeypot tasks have to
tasks have to be
have to be regularly
to be regularly refreshed
pools can also incorporate
can also incorporate out
also incorporate out of
incorporate out of band
out of band mechanisms
of band mechanisms to
band mechanisms to deter
mechanisms to deter attacks
such as verifying the
as verifying the identity
verifying the identity of
the identity of miners
identity of miners or
of miners or using
miners or using trusted
or using trusted computing
using trusted computing technologies
that assure no block
assure no block withholding
no block withholding is
block withholding is taking
withholding is taking place
this would require miners
would require miners to
require miners to use
miners to use specialized
to use specialized hardware
use specialized hardware and
specialized hardware and software
an overhead miners may
overhead miners may not
miners may not accept
there is no known
is no known silver
no known silver bullet
all these techniques reduce
these techniques reduce the
techniques reduce the pool
reduce the pool s
the pool s attractiveness
pool s attractiveness and
s attractiveness and deter
attractiveness and deter miners
block withholding recycling we
withholding recycling we assume
recycling we assume that
we assume that the
assume that the infiltrating
that the infiltrating miners
the infiltrating miners are
infiltrating miners are loyal
miners are loyal to
are loyal to the
loyal to the attacker
some of the pool
of the pool s
the pool s members
pool s members may
s members may be
members may be disloyal
may be disloyal infiltrators
when sending disloyal miners
sending disloyal miners to
disloyal miners to perform
miners to perform block
to perform block withholding
perform block withholding at
block withholding at other
withholding at other pools
latency histograms for i
an attacker takes a
attacker takes a significant
takes a significant risk
can use a loyal
use a loyal miner
a loyal miner w
loyal miner w to
miner w to infiltrate
w to infiltrate pool
thinking the miner is
the miner is loyal
miner is loyal to
is loyal to it
might use it to
use it to attack
it to attack pool
the miner m can
miner m can perform
m can perform honest
can perform honest mining
perform honest mining for
honest mining for pool
rather than withhold its
than withhold its blocks
and not return any
not return any revenue
return any revenue to
any revenue to pool
it will take its
packet loss cripples the
will take its share
loss cripples the performance
take its share of
cripples the performance notes
its share of pool
the performance notes of
performance notes of such
notes of such systems
and reliability and flow
which thinks the miner
thinks the miner is
the miner is loyal
miner is loyal to
is loyal to it
and deliver it back
deliver it back to
it back to pool
to avoid such a
avoid such a risk
a pool needs a
pool needs a sufficient
needs a sufficient number
a sufficient number of
sufficient number of verified
number of verified miners
of verified miners miners
verified miners miners that
miners miners that it
miners that it knows
that it knows to
it knows to be
are increasingly popular and
knows to be loyal
increasingly popular and designed
popular and designed for
and designed for lans
designed for lans and
or the commodity internet
the optimal infiltration rate
the commodity internet fail
optimal infiltration rate may
commodity internet fail to
infiltration rate may be
internet fail to used
rate may be as
fail to used for
may be as high
to used for applications
be as high as
used for applications such
for applications such as
applications such as efficiently
such as efficiently distributing
as efficiently distributing bulk
efficiently distributing bulk data
of the pool size
but this is only
this is only in
is only in extreme
only in extreme cases
in extreme cases when
extreme cases when pools
achieve optimal performance on
cases when pools are
optimal performance on the
when pools are large
performance on the high
for practical pool sizes
a pool may need
it is not obvious
pool may need up
is not obvious that
may need up to
not obvious that these
obvious that these have
that these have utility
these have utility in
have utility in real
time communi lambda networks
communi lambda networks linking
lambda networks linking datacenters
of its mining power
its mining power for
mining power for infiltration
protocols is not an
is not an option
not an option for
pools typically have loyal
an option for commodity
typically have loyal mining
option for commodity clusters
have loyal mining power
for commodity clusters where
loyal mining power either
commodity clusters where standardization
mining power either run
clusters where standardization is
power either run directly
where standardization is critical
either run directly by
standardization is critical for
run directly by the
is critical for cost
directly by the pool
critical for cost mitigation
by the pool owners
the pool owners or
pool owners or sold
owners or sold as
or sold as a
maelstrom is an edge
sold as a service
is an edge appliance
as a service but
an edge appliance that
a service but run
edge appliance that uses
service but run on
appliance that uses forward
but run on the
that uses forward error
run on the pool
uses forward error correction
on the pool owners
forward error correction references
the pool owners hardware
error correction references to
correction references to mask
references to mask packet
to mask packet loss
mask packet loss from
packet loss from end
global crossing current network
crossing current network performance
however the size of
the size of this
size of this mining
of this mining power
this mining power is
mining power is considered
power is considered a
is considered a trade
considered a trade secret
a trade secret and
trade secret and is
secret and is not
and is not published
block withholding in practice
withholding in practice long
in practice long term
practice long term block
long term block withholding
term block withholding attacks
ip throughput and latency
block withholding attacks are
throughput and latency by
withholding attacks are difficult
and latency by orders
attacks are difficult to
latency by orders of
are difficult to hide
by orders of magninetwork
since miners using an
miners using an attacked
using an attacked pool
an attacked pool would
attacked pool would notice
pool would notice the
would notice the reduced
notice the reduced revenue
the reduced revenue density
last tude when loss
tude when loss occurs
such attacks are rarely
maelstrom is easy to
attacks are rarely reported
is easy to install
easy to install and
to install and accessed
install and accessed feb
and we can therefore
we can therefore conclude
can therefore conclude that
therefore conclude that they
conclude that they are
that they are indeed
they are indeed rare
a recent exception is
recent exception is an
exception is an attack
is an attack on
an attack on the
attack on the eligius
on the eligius pool
the eligius pool performed
eligius pool performed in
pool performed in may
performed in may and
in may and june
and is completely transparent
is completely transparent to
completely transparent to applications
transparent to applications and
qwest ip network statistics
protocols literally providing reliability
literally providing reliability in
bitcoin before detecting the
providing reliability in an
before detecting the attack
reliability in an inexpennet
at which point payouts
which point payouts to
point payouts to the
payouts to the attackers
to the attackers were
the attackers were blocked
the attackers continued the
attackers continued the attack
more bitcoin before realizing
bitcoin before realizing they
before realizing they were
realizing they were not
they were not receiving
were not receiving their
not receiving their payout
the reasons the attack
reasons the attack was
the attack was so
attack was so easily
was so easily subverted
so easily subverted is
acknowledgments we would like
easily subverted is the
we would like to
subverted is the limited
would like to thank
is the limited efforts
like to thank our
the limited efforts of
to thank our shepherd
limited efforts of the
thank our shepherd robert
efforts of the attackers
our shepherd robert morris
of the attackers to
shepherd robert morris and
the attackers to hide
robert morris and the
attackers to hide themselves
morris and the other
and the other reviewers
the other reviewers for
other reviewers for extensive
they have only used
reviewers for extensive comments
have only used two
for extensive comments that
only used two payout
extensive comments that significantly
used two payout addresses
comments that significantly shaped
two payout addresses to
that significantly shaped the
payout addresses to collect
significantly shaped the final
addresses to collect their
shaped the final version
to collect their payouts
the final version of
final version of the
version of the paper
and so it was
so it was possible
it was possible for
was possible for the
possible for the alert
for the alert pool
the alert pool manager
alert pool manager to
pool manager to cluster
manager to cluster the
to cluster the attacking
cluster the attacking miners
the attacking miners and
attacking miners and obtain
miners and obtain a
and obtain a statistically
obtain a statistically significant
a statistically significant proof
statistically significant proof of
significant proof of their
proof of their wrongdoing
vidhyashankar venkataraman and vivek
venkataraman and vivek vishnumurthy
it is unknown whether
and vivek vishnumurthy provided
is unknown whether this
vivek vishnumurthy provided useful
unknown whether this was
vishnumurthy provided useful comments
whether this was a
this was a classical
was a classical block
a classical block withholding
classical block withholding attack
tom boures provided valuable
boures provided valuable insight
provided valuable insight into
with the goal of
valuable insight into the
the goal of sabotage
insight into the quality
into the quality of
the quality of existing
quality of existing fiber
of existing fiber links
or a more elaborate
a more elaborate scheme
stanislav shalunov provided information
shalunov provided information on
to verify the effectiveness
provided information on loss
verify the effectiveness of
information on loss rates
the effectiveness of block
on loss rates on
effectiveness of block withholding
loss rates on internet
of block withholding for
block withholding for profit
and paul wefel gave
paul wefel gave us
wefel gave us access
gave us access to
us access to teragrid
access to teragrid loss
to teragrid loss measurements
implemented an experimental bitcoin
an experimental bitcoin test
experimental bitcoin test network
bitcoin test network and
test network and demonstrated
network and demonstrated the
and demonstrated the practicality
demonstrated the practicality of
the practicality of the
practicality of the attack
bitcoin s health large
s health large pools
health large pools hinder
large pools hinder bitcoin
pools hinder bitcoin s
hinder bitcoin s distributed
bitcoin s distributed nature
s distributed nature as
distributed nature as they
nature as they put
as they put a
they put a lot
put a lot of
a lot of mining
lot of mining power
of mining power in
mining power in the
power in the hands
in the hands of
the hands of a
hands of a few
of a few pool
a few pool managers
this has been mostly
has been mostly addressed
been mostly addressed by
mostly addressed by community
addressed by community pressure
by community pressure on
community pressure on miners
pressure on miners to
on miners to avoid
miners to avoid forming
to avoid forming large
avoid forming large pools
nat and packet mangling
and packet mangling for
packet mangling for linux
however such recommendations had
such recommendations had only
recommendations had only had
had only had limited
only had limited success
and mining is still
mining is still dominated
is still dominated by
still dominated by a
dominated by a small
by a small number
a small number of
small number of large
number of large pools
as a characteristic example
in the period of
the period of november
three pools generated over
of the proofs of
the proofs of work
the fact that block
fact that block withholding
that block withholding attacks
block withholding attacks are
withholding attacks are rarely
attacks are rarely observed
are rarely observed may
rarely observed may indicate
observed may indicate that
may indicate that the
indicate that the active
that the active pools
the active pools have
active pools have reached
pools have reached an
have reached an implicit
reached an implicit or
an implicit or explicit
implicit or explicit agreement
or explicit agreement not
explicit agreement not to
agreement not to attack
not to attack one
to attack one another
an attacked pool cannot
attacked pool cannot detect
pool cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners are
its miners are attacking
miners are attacking it
lateral error correction for
error correction for timecritical
let alone which pool
correction for timecritical multicast
alone which pool controls
which pool controls the
pool controls the miners
at some point a
some point a pool
point a pool might
a pool might miscalculate
pool might miscalculate and
might miscalculate and decide
miscalculate and decide to
and decide to try
decide to try to
to try to increase
try to increase its
to increase its revenue
one pool might be
fourth usenix symposium on
pool might be enough
usenix symposium on networked
might be enough to
symposium on networked systems
be enough to break
on networked systems design
enough to break the
networked systems design and
to break the agreement
systems design and implementation
possibly leading to a
leading to a constant
to a constant rate
a constant rate of
constant rate of attacks
rate of attacks among
of attacks among pools
attacks among pools and
among pools and a
pools and a reduced
and a reduced revenue
if open pools reach
open pools reach a
pools reach a state
reach a state where
a state where their
state where their revenue
where their revenue density
their revenue density is
revenue density is reduced
density is reduced due
is reduced due to
reduced due to attacks
miners will leave them
will leave them in
leave them in favor
them in favor of
in favor of other
favor of other available
of other available options
miners of sufficient size
of sufficient size can
sufficient size can mine
size can mine solo
smaller miners can form
miners can form private
can form private pools
form private pools with
private pools with closed
pools with closed access
limited to trusted participants
such a change may
a change may be
change may be in
may be in favor
be in favor of
in favor of bitcoin
favor of bitcoin as
performance enhancing proxies intended
of bitcoin as a
enhancing proxies intended to
bitcoin as a whole
proxies intended to mitigate
intended to mitigate link
since they require such
they require such intimate
require such intimate trust
private pools are likely
pools are likely to
are likely to be
likely to be smaller
and form a fine
form a fine grained
a fine grained distribution
fine grained distribution of
grained distribution of mining
distribution of mining power
of mining power with
mining power with many
power with many small
with many small pools
many small pools and
small pools and solo
pools and solo miners
a pool may engage
pool may engage in
may engage in an
engage in an attack
in an attack against
an attack against another
attack against another pool
against another pool not
another pool not to
pool not to increase
not to increase its
to increase its absolute
increase its absolute revenue
but rather to attract
rather to attract miners
to attract miners by
attract miners by temporarily
miners by temporarily increasing
by temporarily increasing its
temporarily increasing its revenue
increasing its revenue relative
its revenue relative to
revenue relative to a
relative to a competing
to a competing pool
enhanced loss differentiation algorithms
loss differentiation algorithms for
recent work has investigated
differentiation algorithms for use
work has investigated the
algorithms for use in
has investigated the motivation
for use in tcp
investigated the motivation of
use in tcp sources
the motivation of pools
in tcp sources over
motivation of pools to
tcp sources over heterogeneous
of pools to utilize
sources over heterogeneous wireless
pools to utilize part
over heterogeneous wireless networks
to utilize part of
utilize part of their
part of their resources
of their resources towards
their resources towards sabotage
resources towards sabotage attacks
towards sabotage attacks against
sabotage attacks against each
attacks against each other
ieee global telecommunications conference
the model of those
model of those works
of those works is
those works is different
works is different from
is different from the
different from the pool
from the pool game
the pool game model
pool game model in
game model in two
model in two major
in two major ways
two major ways a
major ways a sabotage
ways a sabotage attack
a sabotage attack does
sabotage attack does not
attack does not transfer
does not transfer revenue
not transfer revenue from
transfer revenue from victim
revenue from victim to
from victim to attacker
and migrating miners switch
migrating miners switch to
miners switch to less
switch to less attacked
to less attacked pools
changing pool sizes and
pool sizes and hence
sizes and hence revenues
and hence revenues until
flow aggregation for enhanced
hence revenues until convergence
aggregation for enhanced tcp
for enhanced tcp over
enhanced tcp over wide
tcp over wide area
over wide area wireless
the model is parametrized
model is parametrized by
is parametrized by the
parametrized by the cost
by the cost of
the cost of the
cost of the attack
of the attack and
the attack and by
attack and by the
and by the mobility
by the mobility of
the mobility of the
mobility of the miners
and the analysis demonstrates
the analysis demonstrates that
analysis demonstrates that when
demonstrates that when considering
that when considering only
when considering only sabotage
considering only sabotage attacks
only sabotage attacks there
sabotage attacks there are
attacks there are regions
there are regions where
are regions where no
attack is the best
is the best strategy
the miner s dilemma
miner s dilemma is
s dilemma is therefore
dilemma is therefore not
is therefore not manifested
therefore not manifested in
not manifested in that
manifested in that model
vice president of research
president of research and
of research and t
pool competition for miners
competition for miners is
for miners is an
miners is an incentive
is an incentive in
an incentive in and
incentive in and of
in and of its
and of its own
of its own for
its own for mutual
own for mutual attacks
and a pool may
a pool may therefore
pool may therefore choose
may therefore choose to
therefore choose to perform
choose to perform block
to perform block withholding
perform block withholding even
block withholding even if
withholding even if its
even if its revenue
if its revenue would
its revenue would increase
revenue would increase only
would increase only after
increase only after the
only after the next
after the next difficult
the next difficult adjustment
the two models are
two models are therefore
models are therefore complementary
the analysis of their
analysis of their combination
of their combination is
their combination is left
combination is left for
is left for future
left for future work
we assumed in our
assumed in our analysis
in our analysis that
our analysis that pools
analysis that pools do
that pools do not
pools do not charge
multicast routing in datagram
do not charge fees
routing in datagram internetworks
not charge fees from
in datagram internetworks and
charge fees from their
datagram internetworks and extended
fees from their members
internetworks and extended lans
from their members since
their members since such
members since such fees
since such fees are
such fees are typically
fees are typically nominal
of a pool s
a pool s revenue
the model can be
model can be extended
can be extended to
be extended to include
extended to include pools
to include pools fees
fees would add a
would add a friction
add a friction element
a friction element to
friction element to the
element to the flow
to the flow of
the flow of revenue
flow of revenue among
of revenue among infiltrated
revenue among infiltrated and
among infiltrated and infiltrating
infiltrated and infiltrating pools
would change to take
change to take into
to take into account
take into account a
into account a pool
account a pool fee
a pool fee of
pool fee of f
fee of f pp
of f pp ri
level traffic measurements from
traffic measurements from the
measurements from the sprint
from the sprint ip
the sprint ip backbone
a pool with a
pool with a fee
with a fee of
a fee of f
fee of f is
of f is a
f is a less
is a less attractive
a less attractive target
less attractive target for
attractive target for block
target for block withholding
since the attacker s
the attacker s revenue
attacker s revenue is
s revenue is reduced
revenue is reduced by
is reduced by f
however it is also
it is also less
is also less attractive
also less attractive for
less attractive for miners
attractive for miners in
for miners in general
trading off the two
off the two for
the two for best
two for best protection
for best protection is
best protection is left
protection is left for
is left for future
left for future work
as part of the
part of the treatment
of the treatment of
the treatment of the
treatment of the miner
r elated w ork
elated w ork a
the block withholding attack
block withholding attack the
a transport protocol for
withholding attack the danger
transport protocol for grid
attack the danger of
protocol for grid computing
the danger of a
danger of a block
of a block withholding
a block withholding attack
block withholding attack is
journal of grid computing
withholding attack is as
attack is as old
is as old as
as old as bitcoin
old as bitcoin pools
the attack was described
attack was described by
was described by rosenfeld
as pools were becoming
pools were becoming a
were becoming a dominant
becoming a dominant player
a dominant player in
dominant player in the
player in the bitcoin
in the bitcoin world
the paper described the
paper described the standard
described the standard attack
used by a miner
by a miner to
a miner to sabotage
miner to sabotage a
to sabotage a pool
sabotage a pool at
a pool at the
pool at the cost
at the cost of
the cost of reducing
cost of reducing its
of reducing its own
reducing its own revenue
a more general view
more general view of
general view of fairness
view of fairness in
of fairness in proof
fairness in proof of
in proof of work
proof of work schemes
of work schemes was
work schemes was discussed
schemes was discussed in
optical domain performance monitoring
in the context of
the context of the
context of the hashcash
optical fiber communication conference
of the hashcash system
early work did not
work did not address
did not address the
not address the possibility
address the possibility of
the possibility of pools
possibility of pools infiltrating
of pools infiltrating other
pools infiltrating other pools
infiltrating other pools for
other pools for block
pools for block withholding
experimentally demonstrate that block
demonstrate that block withholding
that block withholding can
block withholding can increase
withholding can increase the
can increase the attacker
increase the attacker s
the attacker s revenue
they do not address
end performance effects of
do not address the
performance effects of parallel
not address the question
effects of parallel tcp
address the question of
of parallel tcp sockets
the question of mutual
parallel tcp sockets on
question of mutual attacks
tcp sockets on a
sockets on a lossy
on a lossy wide
have recently noted that
recently noted that a
noted that a pool
that a pool can
a pool can increase
pool can increase its
can increase its overall
increase its overall revenue
its overall revenue with
overall revenue with block
revenue with block withholding
with block withholding if
block withholding if all
withholding if all other
if all other mining
all other mining is
other mining is performed
mining is performed by
is performed by honest
performed by honest pools
we consider the general
consider the general case
the general case where
general case where not
case where not all
where not all mining
not all mining is
all mining is performed
mining is performed through
is performed through public
performed through public pools
and analyze situations where
analyze situations where pools
situations where pools can
where pools can attack
pools can attack one
can attack one another
the discrepancy between the
discrepancy between the calculations
between the calculations of
the effects of systemic
effects of systemic packet
of systemic packet loss
systemic packet loss on
packet loss on aggregate
loss on aggregate tcp
on aggregate tcp flows
for the special case
the special case analyzed
special case analyzed there
case analyzed there and
analyzed there and our
there and our results
and our results can
our results can be
results can be explained
can be explained by
be explained by the
explained by the strong
by the strong approximations
the strong approximations in
strong approximations in that
approximations in that work
we calculate exactly how
calculate exactly how infiltrating
exactly how infiltrating miners
how infiltrating miners reduce
infiltrating miners reduce the
miners reduce the revenue
reduce the revenue density
ieee conference on supercomputing
the revenue density of
revenue density of the
density of the infiltrated
of the infiltrated pool
temporary block withholding in
block withholding in the
withholding in the block
in the block withholding
the block withholding attack
block withholding attack discussed
withholding attack discussed in
attack discussed in this
discussed in this work
in this work the
this work the withheld
work the withheld blocks
the withheld blocks are
withheld blocks are never
blocks are never published
blocks can be withheld
can be withheld temporarily
not following the bitcoin
following the bitcoin protocol
to improve an attacker
improve an attacker s
an attacker s revenue
a miner or a
miner or a pool
or a pool can
a pool can perform
pool can perform a
can perform a selfish
perform a selfish mining
a selfish mining attack
predictable high performance bulk
high performance bulk data
performance bulk data transfer
with selfish mining the
ieee international conference on
selfish mining the attacker
international conference on cluster
conference on cluster computing
mining the attacker increases
the attacker increases its
attacker increases its revenue
increases its revenue by
its revenue by temporarily
revenue by temporarily withholding
by temporarily withholding its
temporarily withholding its blocks
withholding its blocks and
its blocks and publishing
blocks and publishing them
and publishing them in
publishing them in response
them in response to
in response to block
response to block publication
to block publication by
block publication by other
publication by other pools
by other pools and
other pools and miners
this attack is independent
attack is independent of
is independent of the
independent of the block
of the block withholding
the block withholding attack
block withholding attack we
withholding attack we discuss
attack we discuss here
we discuss here and
discuss here and the
here and the two
and the two can
the two can be
the case for packet
two can be performed
case for packet level
can be performed in
for packet level fec
be performed in concert
an attacker can also
attacker can also perform
can also perform a
also perform a double
perform a double spending
a double spending attack
double spending attack as
spending attack as follows
proceedings of the tc
he intentionally generates two
intentionally generates two conflicting
generates two conflicting transactions
places one in a
one in a block
in a block it
a block it withholds
and publishes the other
publishes the other transaction
fifth international workshop on
international workshop on protocols
workshop on protocols for
on protocols for high
after the recipient sees
the recipient sees the
recipient sees the published
sees the published transaction
the attacker publishes the
attacker publishes the withheld
publishes the withheld block
the withheld block to
withheld block to revoke
block to revoke the
to revoke the former
revoke the former transaction
this attack is performed
attack is performed by
is performed by miners
performed by miners or
by miners or pools
miners or pools against
or pools against service
pools against service providers
against service providers that
service providers that accept
providers that accept bitcoin
and it not directly
it not directly related
not directly related to
directly related to this
related to this work
block withholding defense most
withholding defense most crypto
currencies use a proof
work architecture similar to
architecture similar to bitcoin
where finding proof of
finding proof of work
proof of work is
of work is the
work is the result
is the result of
the result of solution
result of solution guessing
of solution guessing and
solution guessing and checking
all of the algorithms
of the algorithms we
the algorithms we are
algorithms we are aware
we are aware of
are aware of are
aware of are susceptible
of are susceptible to
are susceptible to the
susceptible to the block
to the block withholding
the block withholding attack
as in all of
in all of them
all of them the
of them the miner
them the miner can
the miner can check
miner can check whether
can check whether she
check whether she found
whether she found a
she found a full
found a full or
a full or a
full or a partial
or a partial proof
a partial proof of
partial proof of work
gigabit ethernet on commodity
ethernet on commodity systems
prominent examples are litecoin
it is possible to
is possible to use
possible to use an
to use an alternative
use an alternative proof
an alternative proof of
alternative proof of work
proof of work mechanism
of work mechanism in
work mechanism in which
mechanism in which miners
in which miners would
which miners would not
miners would not be
would not be able
not be able to
be able to distinguish
able to distinguish partial
to distinguish partial from
distinguish partial from full
partial from full proofs
from full proofs of
full proofs of work
where did my performance
did my performance go
rate limiting rears its
limiting rears its ugly
rears its ugly head
such a solution could
a solution could reduce
solution could reduce or
could reduce or remove
reduce or remove the
or remove the danger
remove the danger of
the danger of block
danger of block withholding
making such a change
such a change may
a change may not
change may not be
may not be in
not be in the
be in the interest
in the interest of
the interest of the
interest of the community
or even its potential
could lead to a
lead to a reduction
to a reduction of
a reduction of pool
reduction of pool sizes
as explained in section
explained in section ix
decentralized pools although most
pools although most pools
although most pools use
most pools use a
pools use a centralized
use a centralized manager
a prominent exception is
prominent exception is p
pool a distributed pool
a distributed pool architecture
distributed pool architecture with
pool architecture with no
architecture with no central
with no central manager
isn t quite enough
but the question of
the question of whether
question of whether a
of whether a pool
whether a pool is
a pool is run
pool is run by
is run by a
run by a centralized
by a centralized manager
a centralized manager or
centralized manager or with
manager or with a
or with a decentralized
with a decentralized architecture
a decentralized architecture is
decentralized architecture is almost
architecture is almost immaterial
is almost immaterial for
almost immaterial for the
immaterial for the attack
for the attack we
the attack we describe
pool group can be
group can be infiltrated
can be infiltrated and
be infiltrated and attacked
pool code can be
code can be changed
can be changed to
be changed to support
changed to support attacks
to support attacks against
support attacks against other
attacks against other pools
on the other hand
pool can be used
can be used by
be used by groups
used by groups of
by groups of miners
groups of miners to
of miners to easily
miners to easily form
to easily form closed
easily form closed pools
modified tcp congestion avoidance
tcp congestion avoidance algorithm
these do not accept
do not accept untrusted
not accept untrusted miners
and are therefore protected
are therefore protected against
therefore protected against block
protected against block withholding
c onclusion we explored
onclusion we explored a
we explored a block
explored a block withholding
a block withholding attack
block withholding attack among
withholding attack among bitcoin
attack among bitcoin mining
among bitcoin mining pools
bitcoin mining pools an
mining pools an attack
pools an attack that
an attack that is
attack that is possible
that is possible in
is possible in any
possible in any similar
in any similar system
any similar system that
similar system that rewards
system that rewards for
that rewards for proof
rewards for proof of
for proof of work
such systems are gaining
systems are gaining popularity
running most digital currencies
most digital currencies and
digital currencies and related
currencies and related services
we observe that no
attacks is not a
is not a nash
not a nash equilibrium
if none of the
none of the other
of the other pools
the other pools attack
physical layer impact upon
layer impact upon packet
impact upon packet errors
a pool can increase
pool can increase its
can increase its revenue
increase its revenue by
passive and active measurement
its revenue by attacking
and active measurement workshop
revenue by attacking the
by attacking the others
when two pools can
two pools can attack
pools can attack each
can attack each other
they face a version
face a version of
a version of the
version of the prisoner
of the prisoner s
the prisoner s dilemma
if one pool chooses
one pool chooses to
pool chooses to attack
the victim s revenue
victim s revenue is
s revenue is reduced
and it can retaliate
it can retaliate by
can retaliate by attacking
retaliate by attacking and
by attacking and increase
attacking and increase its
and increase its revenue
at nash equilibrium both
nash equilibrium both earn
equilibrium both earn less
both earn less than
earn less than they
less than they would
than they would have
they would have if
would have if neither
have if neither attacked
with multiple pools of
multiple pools of equal
pools of equal size
of equal size a
equal size a similar
size a similar situation
a similar situation arises
similar situation arises with
situation arises with a
arises with a symmetric
with a symmetric equilibrium
the fact that block
fact that block withholding
that block withholding is
block withholding is not
withholding is not common
maximizing sensor network data
is not common may
sensor network data persistence
not common may be
common may be explained
may be explained by
be explained by modeling
in proceedings of acm
explained by modeling the
proceedings of acm sigcomm
by modeling the attack
modeling the attack decisions
the attack decisions as
attack decisions as an
decisions as an iterative
as an iterative prisoner
an iterative prisoner s
iterative prisoner s dilemma
we argue that the
argue that the situation
that the situation is
the situation is unstable
situation is unstable since
is unstable since the
unstable since the attack
since the attack can
the attack can be
attack can be done
can be done anonymously
one pool may decide
pool may decide to
may decide to increase
decide to increase its
to increase its revenue
increase its revenue and
its revenue and drag
revenue and drag the
and drag the others
drag the others to
the others to attack
others to attack as
to attack as well
ending with a reduced
with a reduced revenue
a reduced revenue for
reduced revenue for all
the inferior revenue would
inferior revenue would push
revenue would push miners
would push miners to
push miners to join
miners to join private
to join private pools
congestion control for high
control for high bandwidth
which can verify that
can verify that their
verify that their registered
that their registered miners
their registered miners do
registered miners do not
miners do not withhold
do not withhold blocks
this would lead to
would lead to smaller
lead to smaller pools
and so ultimately to
so ultimately to a
ultimately to a better
to a better environment
a better environment for
better environment for bitcoin
environment for bitcoin as
for bitcoin as a
bitcoin as a whole
for their valuable advice
and protocols for computer
protocols for computer communications
the author is grateful
author is grateful to
is grateful to ken
grateful to ken birman
emin gu n sirer
and the paper shepherd
the paper shepherd joseph
paper shepherd joseph bonneau
peer electronic cash system
ebay s paypal unit
s paypal unit to
paypal unit to start
unit to start accepting
to start accepting bitcoin
start accepting bitcoin payments
journal of lightwave technology
google adds bitcoin currency
adds bitcoin currency conversion
bitcoin currency conversion to
currency conversion to search
a cross layer study
cross layer study of
layer study of packet
study of packet loss
of packet loss in
packet loss in all
the performance of tcp
ip for networks with
for networks with high
networks with high bandwidth
delay products and random
products and random loss
acm transactions on networking
repurposing bitcoin work for
bitcoin work for data
work for data preservation
in proceedings of the
proceedings of the ieee
of the ieee symposium
the ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
rd annual ieee symposium
annual ieee symposium on
ieee symposium on foundations
symposium on foundations of
on foundations of computer
foundations of computer science
namecoin dns dotbit project
end forward error correction
international zurich seminar on
zurich seminar on communications
a next generation smart
next generation smart contract
rateless codes and big
codes and big downloads
analysis of bitcoin pooled
of bitcoin pooled mining
paritybased loss recovery for
bitcoin pooled mining reward
loss recovery for reliable
pooled mining reward systems
recovery for reliable multicast
for reliable multicast transmission
in proceedings of the
proceedings of the acm
of the acm sigcomm
a simple model and
simple model and its
research perspectives on bitcoin
model and its empirical
perspectives on bitcoin and
and its empirical validation
on bitcoin and secondgeneration
bitcoin and secondgeneration cryptocurrencies
in ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
an adaptive forward error
adaptive forward error correction
forward error correction protocol
error correction protocol for
correction protocol for end
computer communications and networks
th international conference on
businesses see the light
information propagation in the
propagation in the bitcoin
in the bitcoin network
th ieee international conference
ieee international conference on
international conference on peer
bitcoin and the age
and the age of
the age of bespoke
age of bespoke silicon
in proceedings of the
international conference on compilers
architectures and synthesis for
and synthesis for embedded
synthesis for embedded systems
into the bitcoin mines
effective erasure codes for
erasure codes for reliable
codes for reliable computer
for reliable computer communication
reliable computer communication protocols
on the feasibility of
the feasibility of software
feasibility of software fec
the case for application
level network striping for
network striping for data
striping for data intensive
for data intensive applications
data intensive applications using
intensive applications using high
applications using high speed
using high speed wide
high speed wide area
speed wide area networks
ieee conference on supercomputing
google s secret plans
s secret plans for
secret plans for all
plans for all that
for all that dark
all that dark fiber
how a mining monopoly
a mining monopoly can
mining monopoly can attack
monopoly can attack bitcoin
an overlay based architecture
overlay based architecture for
based architecture for enhancing
architecture for enhancing internet
for enhancing internet qos
first usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
udp bandwidth measurement tool
majority is not enough
bitcoin mining is vulnerable
in financial cryptography and
financial cryptography and data
cryptography and data security
a tcp performance enhancing
tcp performance enhancing proxy
performance enhancing proxy for
enhancing proxy for satellite
proxy for satellite links
proceedings of the second
of the second international
the second international ifip
networking conference on networking
conference on networking technologies
performance of computer and
of computer and communication
computer and communication networks
and mobile and wireless
mobile and wireless communications
cooperative equilibrium for supergames
the review of economic
review of economic studies
tsunami file transfer protocol
workshop on protocols for
on protocols for fast
protocols for fast longdistance
for fast longdistance networks
term competition a game
the university of illinois
university of illinois national
of illinois national center
illinois national center for
national center for supercomputing
center for supercomputing applications
an integrated experimental environment
integrated experimental environment for
experimental environment for distributed
environment for distributed systems
for distributed systems and
distributed systems and networks
of the fifth symposium
the fifth symposium on
fifth symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
io bitcoin mining pool
solomon codes and their
codes and their applications
kncminer bitcoin mining cloud
bitcoin mining cloud mining
an authorization architecture for
authorization architecture for trustworthy
architecture for trustworthy computing
in proceedings of the
proceedings of the twenty
third acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
on power splitting games
power splitting games in
splitting games in distributed
games in distributed computation
the case of bitcoin
case of bitcoin pooled
of bitcoin pooled mining
weekly bitcoin network statistics
theoretic analysis of ddos
analysis of ddos attacks
of ddos attacks against
ddos attacks against bitcoin
attacks against bitcoin mining
against bitcoin mining pools
in workshop on bitcoin
workshop on bitcoin research
when bitcoin mining pools
bitcoin mining pools run
mining pools run dry
in workshop on bitcoin
workshop on bitcoin research
comparison of mining pools
comparison of mining pools
hashcash amortizable publicly auditable
amortizable publicly auditable cost
hashcash a denial of
a denial of service
denial of service counter
on subversive miner strategies
subversive miner strategies and
miner strategies and block
strategies and block withholding
and block withholding attack
block withholding attack in
withholding attack in bitcoin
attack in bitcoin digital
in bitcoin digital currency
how to disincentivize large
to disincentivize large bitcoin
disincentivize large bitcoin mining
large bitcoin mining pools
the: 7744
of: 4121
a: 3489
to: 3267
and: 3193
in: 2417
is: 1914
for: 1353
that: 1296
with: 990
on: 965
are: 940
we: 925
as: 917
it: 771
by: 745
be: 695
this: 681
data: 659
pool: 659
s: 654
an: 631
at: 630
can: 574
system: 559
its: 497
from: 483
not: 466
or: 452
r: 429
which: 418
each: 404
file: 401
all: 377
systems: 372
m: 368
if: 362
figure: 357
x: 343
one: 338
time: 335
nodes: 332
pools: 325
revenue: 325
t: 325
packets: 320
rate: 320
other: 317
cache: 310
but: 309
our: 291
have: 289
work: 287
i: 282
performance: 281
such: 271
when: 268
loss: 258
p: 258
miners: 257
has: 252
bandwidth: 251
packet: 244
c: 243
network: 242
their: 236
will: 232
attack: 230
block: 230
mining: 230
j: 228
these: 223
than: 222
only: 221
end: 220
use: 220
they: 218
more: 216
node: 209
bitcoin: 204
no: 204
high: 203
number: 202
services: 200
latency: 197
b: 196
may: 193
transactions: 192
would: 192
server: 190
two: 188
where: 188
update: 187
power: 182
between: 180
used: 177
based: 174
d: 173
over: 171
any: 170
different: 169
distributed: 166
miner: 164
new: 164
single: 164
also: 162
client: 161
some: 161
large: 159
tcp: 159
was: 157
web: 157
since: 153
objects: 152
application: 150
ip: 150
service: 150
using: 149
updates: 146
e: 144
protocol: 144
them: 144
set: 140
read: 139
access: 138
applications: 137
process: 137
files: 134
transaction: 133
maelstrom: 132
traffic: 132
there: 131
operating: 130
gossip: 129
however: 129
into: 129
section: 129
withholding: 129
rates: 128
example: 127
mfs: 127
so: 127
communication: 124
consistency: 124
both: 122
same: 122
size: 122
object: 121
priorities: 120
repair: 120
even: 119
peer: 119
throughput: 119
chain: 118
g: 116
control: 114
failure: 114
information: 113
while: 113
first: 112
recovery: 112
were: 112
results: 111
database: 110
protocols: 110
case: 109
acm: 106
link: 106
low: 106
therefore: 106
then: 105
without: 105
rpcs: 104
small: 104
clients: 103
writes: 103
networks: 102
could: 101
second: 101
ms: 100
rpc: 99
do: 98
many: 98
asynchronous: 97
writeback: 97
log: 96
model: 96
within: 96
group: 95
send: 95
does: 94
proof: 94
most: 93
up: 93
memory: 92
state: 91
user: 91
average: 90
content: 90
version: 90
level: 89
order: 89
back: 87
been: 87
support: 87
less: 86
through: 85
windows: 85
available: 84
groups: 84
long: 84
out: 84
see: 84
after: 83
another: 83
approach: 83
fec: 83
full: 83
how: 83
against: 82
architecture: 82
infiltration: 82
message: 82
o: 82
disk: 81
k: 81
messages: 81
need: 81
qsm: 81
about: 80
kb: 80
multicast: 80
sender: 80
uses: 80
management: 79
n: 79
q: 79
way: 79
delivery: 78
total: 78
disks: 77
experiments: 77
possible: 77
write: 77
design: 76
higher: 76
delay: 75
increase: 75
layer: 75
local: 75
research: 75
scale: 75
upload: 75
computer: 74
f: 74
implementation: 74
might: 74
source: 74
analysis: 73
burst: 73
live: 73
probability: 73
workloads: 73
accesses: 72
because: 72
every: 72
lost: 72
solution: 71
cost: 70
due: 70
step: 70
v: 70
value: 70
equilibrium: 69
like: 69
multiple: 69
manager: 68
per: 68
priority: 68
well: 68
list: 67
overhead: 67
computing: 66
load: 66
running: 66
cornell: 65
http: 65
mechanism: 65
opportunistic: 65
run: 65
should: 65
under: 65
attacking: 64
cluster: 64
operations: 64
proceedings: 64
servers: 64
show: 64
shown: 64
test: 64
attacks: 63
layered: 63
much: 63
paper: 63
partial: 63
received: 63
stream: 63
attacker: 62
dependency: 62
kernel: 62
point: 62
solutions: 62
event: 61
l: 61
maximum: 61
must: 61
scheme: 61
shows: 61
sizes: 61
code: 60
game: 60
interleave: 60
prefetching: 60
proofs: 60
replication: 60
result: 60
round: 60
storage: 60
us: 60
perform: 59
sending: 59
very: 59
inconsistency: 58
once: 58
provide: 58
threshold: 58
users: 58
workload: 58
flow: 57
scalable: 57
sent: 57
similar: 57
streaming: 57
being: 56
conference: 56
symposium: 56
download: 55
nt: 55
problem: 55
random: 55
receiver: 55
reduce: 55
requests: 55
until: 55
before: 54
correct: 54
factor: 54
global: 54
graph: 54
interleaving: 54
larger: 54
open: 54
processes: 54
range: 54
retrieved: 54
among: 53
auditing: 53
caching: 53
cannot: 53
h: 53
scenario: 53
center: 52
fetch: 52
mode: 52
real: 52
synchronous: 52
take: 52
transactional: 52
according: 51
form: 51
ieee: 51
increasing: 51
internet: 51
make: 51
present: 51
reads: 51
xor: 51
able: 50
algorithm: 50
current: 50
had: 50
inconsistencies: 50
mobile: 50
store: 50
components: 49
contention: 49
either: 49
existing: 49
hence: 49
mechanisms: 49
mi: 49
now: 49
three: 49
whether: 49
encoding: 48
general: 48
host: 48
implemented: 48
own: 48
prefetch: 48
recovered: 48
reliable: 48
values: 48
although: 47
important: 47
pp: 47
side: 47
w: 47
behavior: 46
execution: 46
fixed: 46
function: 46
generated: 46
graphs: 46
operation: 46
platform: 46
request: 46
speed: 46
th: 46
consider: 45
designed: 45
shared: 45
significant: 45
university: 45
victim: 45
window: 45
attacked: 44
blocks: 44
com: 44
community: 44
delays: 44
density: 44
error: 44
future: 44
hosted: 44
kbps: 44
left: 44
pages: 44
smaller: 44
standard: 44
wide: 44
appliance: 43
changes: 43
component: 43
costs: 43
events: 43
fig: 43
here: 43
makes: 43
ratio: 43
required: 43
right: 43
thus: 43
y: 43
allows: 42
amount: 42
change: 42
developers: 42
distribution: 42
experiment: 42
just: 42
often: 42
rather: 42
scalability: 42
seen: 42
start: 42
tasks: 42
uniform: 42
what: 42
cloud: 41
effect: 41
mafs: 41
missing: 41
numbers: 41
optimal: 41
reduced: 41
simple: 41
ssa: 41
strategy: 41
across: 40
address: 40
detection: 40
down: 40
further: 40
given: 40
hosts: 40
lower: 40
next: 40
non: 40
receive: 40
sends: 40
software: 40
token: 40
typically: 40
allow: 39
caches: 39
cases: 39
congestion: 39
directly: 39
entire: 39
increases: 39
independent: 39
interface: 39
length: 39
original: 39
overheads: 39
part: 39
structure: 39
times: 39
compared: 38
described: 38
direct: 38
during: 38
microsoft: 38
region: 38
require: 38
revenues: 38
world: 38
accessed: 37
al: 37
birman: 37
centers: 37
codes: 37
effective: 37
enough: 37
et: 37
improve: 37
losses: 37
membership: 37
provides: 37
xors: 37
better: 36
clusters: 36
consistent: 36
describe: 36
expected: 36
fact: 36
fast: 36
loyal: 36
previous: 36
related: 36
relative: 36
techniques: 36
today: 36
types: 36
adaptation: 35
additional: 35
almost: 35
commodity: 35
environment: 35
https: 35
international: 35
last: 35
links: 35
longer: 35
minimum: 35
needs: 35
org: 35
performed: 35
proxy: 35
reliability: 35
still: 35
though: 35
above: 34
acid: 34
earlier: 34
evaluation: 34
factors: 34
injection: 34
interleaves: 34
ken: 34
levels: 34
managed: 34
percentage: 34
remote: 34
sets: 34
several: 34
virtual: 34
www: 34
constant: 33
denote: 33
limited: 33
note: 33
overall: 33
particular: 33
receiving: 33
top: 33
working: 33
assume: 32
become: 32
clustered: 32
detect: 32
find: 32
including: 32
period: 32
replicated: 32
scenarios: 32
seconds: 32
space: 32
stable: 32
table: 32
technologies: 32
technology: 32
those: 32
trace: 32
versions: 32
added: 31
ensure: 31
evaluate: 31
finally: 31
follows: 31
immediately: 31
invalidations: 31
least: 31
mb: 31
overlay: 31
prediction: 31
principles: 31
receivers: 31
requires: 31
runs: 31
sirp: 31
target: 31
udp: 31
achieve: 30
adaptive: 30
amazon: 30
auditors: 30
collaboration: 30
correction: 30
dropped: 30
good: 30
incoming: 30
lists: 30
members: 30
performs: 30
policy: 30
recent: 30
ri: 30
schemes: 30
security: 30
share: 30
third: 30
usenix: 30
z: 30
associated: 29
availability: 29
close: 29
commit: 29
complete: 29
delivered: 29
edu: 29
head: 29
key: 29
later: 29
platforms: 29
pull: 29
receives: 29
recover: 29
reducing: 29
science: 29
settings: 29
task: 29
varying: 29
xi: 29
best: 28
configuration: 28
core: 28
dilemma: 28
feasible: 28
implements: 28
issues: 28
making: 28
never: 28
obtain: 28
occur: 28
others: 28
repository: 28
resulting: 28
style: 28
tools: 28
transport: 28
type: 28
area: 27
async: 27
build: 27
building: 27
cached: 27
capacity: 27
collection: 27
failures: 27
following: 27
forward: 27
framework: 27
increased: 27
instance: 27
major: 27
mbps: 27
needed: 27
neighbors: 27
nov: 27
participants: 27
reader: 27
resources: 27
solo: 27
speedup: 27
stored: 27
tm: 27
vn: 27
writer: 27
abort: 26
basic: 26
becomes: 26
benefit: 26
bin: 26
bins: 26
certain: 26
channel: 26
classical: 26
common: 26
consumption: 26
controls: 26
discuss: 26
entry: 26
fault: 26
haul: 26
instead: 26
means: 26
mostly: 26
online: 26
os: 26
solomon: 26
sources: 26
tolerance: 26
vol: 26
allowing: 25
backend: 25
bursts: 25
bursty: 25
choice: 25
conditions: 25
considered: 25
contribution: 25
copy: 25
cs: 25
difficulty: 25
distance: 25
estimate: 25
figures: 25
flows: 25
found: 25
goal: 25
hardware: 25
invalidation: 25
machines: 25
observed: 25
properties: 25
queue: 25
rain: 25
reduces: 25
report: 25
spent: 25
split: 25
takes: 25
transmission: 25
abstract: 24
algorithms: 24
around: 24
blockchain: 24
cause: 24
closed: 24
committed: 24
contrast: 24
correctly: 24
corresponding: 24
critical: 24
datacenters: 24
demand: 24
developed: 24
done: 24
equal: 24
experimental: 24
front: 24
having: 24
idea: 24
individual: 24
infiltrating: 24
knowledge: 24
limit: 24
lock: 24
logs: 24
ny: 24
observe: 24
oriented: 24
peers: 24
place: 24
processing: 24
strategies: 24
streams: 24
structured: 24
too: 24
view: 24
again: 23
approaches: 23
called: 23
choose: 23
create: 23
datacenter: 23
detected: 23
duration: 23
include: 23
layers: 23
likely: 23
majority: 23
member: 23
monitoring: 23
ones: 23
powered: 23
product: 23
reed: 23
sufficient: 23
sync: 23
traditional: 23
unix: 23
ways: 23
workshop: 23
york: 23
alternative: 22
always: 22
avoid: 22
built: 22
certification: 22
connected: 22
consequently: 22
context: 22
defined: 22
dependencies: 22
development: 22
efficient: 22
generate: 22
handle: 22
he: 22
made: 22
maintain: 22
mtu: 22
net: 22
occurs: 22
off: 22
optical: 22
parameters: 22
patterns: 22
popular: 22
problems: 22
revision: 22
starts: 22
via: 22
who: 22
wireless: 22
bandwidths: 21
buffers: 21
centralized: 21
configurations: 21
contains: 21
dynamic: 21
easily: 21
easy: 21
equation: 21
etc: 21
garbage: 21
hand: 21
hash: 21
identical: 21
iii: 21
index: 21
let: 21
life: 21
line: 21
mashup: 21
milliseconds: 21
old: 21
path: 21
private: 21
project: 21
proxies: 21
reasons: 21
response: 21
short: 21
significantly: 21
social: 21
staleness: 21
video: 21
vogels: 21
wait: 21
writing: 21
aggregate: 20
analyze: 20
architectures: 20
benefits: 20
buffering: 20
changing: 20
choosing: 20
consists: 20
four: 20
generates: 20
google: 20
grep: 20
honest: 20
inter: 20
interest: 20
interfaces: 20
library: 20
machine: 20
manner: 20
minibrowser: 20
multi: 20
none: 20
potentially: 20
presence: 20
proc: 20
quality: 20
queued: 20
racs: 20
rapidly: 20
references: 20
respectively: 20
simply: 20
site: 20
stale: 20
together: 20
traces: 20
updated: 20
usa: 20
usage: 20
yet: 20
actually: 19
adding: 19
appropriate: 19
clear: 19
convergence: 19
course: 19
currently: 19
digital: 19
expect: 19
explained: 19
extended: 19
extremely: 19
faster: 19
features: 19
inconsistent: 19
investigation: 19
issue: 19
kind: 19
know: 19
mine: 19
month: 19
natural: 19
networking: 19
om: 19
partition: 19
periods: 19
potential: 19
propagation: 19
proposed: 19
query: 19
quickly: 19
re: 19
recipe: 19
reply: 19
sequence: 19
serializability: 19
soc: 19
speeds: 19
subscribers: 19
taken: 19
towards: 19
transfer: 19
transient: 19
upon: 19
whereas: 19
works: 19
active: 18
aggregation: 18
aware: 18
background: 18
bad: 18
chooses: 18
cpu: 18
databases: 18
difficult: 18
divided: 18
drop: 18
earn: 18
effectiveness: 18
employ: 18
eventually: 18
exchange: 18
failed: 18
feb: 18
fiber: 18
foreground: 18
generation: 18
get: 18
gigabit: 18
heavy: 18
history: 18
identify: 18
includes: 18
initial: 18
itself: 18
known: 18
lambda: 18
latencies: 18
logging: 18
moreover: 18
nash: 18
neither: 18
noted: 18
participating: 18
propose: 18
publish: 18
queries: 18
repositories: 18
roundtrip: 18
sigcomm: 18
specific: 18
study: 18
subversion: 18
summary: 18
switching: 18
synthetic: 18
tokens: 18
topics: 18
unique: 18
varied: 18
various: 18
vary: 18
actual: 17
automatically: 17
chosen: 17
coda: 17
communications: 17
developer: 17
device: 17
devices: 17
don: 17
early: 17
enabled: 17
environments: 17
errors: 17
experience: 17
focus: 17
fraction: 17
functionality: 17
grows: 17
highest: 17
highly: 17
hosting: 17
ii: 17
impact: 17
implement: 17
infrastructure: 17
lines: 17
maintains: 17
modified: 17
module: 17
necessary: 17
offer: 17
partitioning: 17
periodically: 17
products: 17
progress: 17
projects: 17
ran: 17
raps: 17
reach: 17
remain: 17
setting: 17
sharing: 17
simultaneous: 17
specifically: 17
standards: 17
subservice: 17
successfully: 17
supported: 17
switch: 17
symmetric: 17
term: 17
transmitted: 17
van: 17
variety: 17
years: 17
acts: 16
already: 16
axis: 16
believe: 16
buffer: 16
bytes: 16
call: 16
chainsaw: 16
clustering: 16
compare: 16
configured: 16
conflicts: 16
connectivity: 16
contents: 16
conventional: 16
created: 16
define: 16
demonstrate: 16
difference: 16
efficacy: 16
examples: 16
fees: 16
few: 16
ghash: 16
go: 16
hard: 16
illustrated: 16
implications: 16
indeed: 16
infiltrate: 16
integration: 16
io: 16
kinds: 16
lead: 16
limiting: 16
linux: 16
little: 16
main: 16
market: 16
measurements: 16
modes: 16
operate: 16
options: 16
page: 16
parallel: 16
physical: 16
points: 16
prisoner: 16
publishes: 16
registered: 16
requirements: 16
serialization: 16
simulation: 16
simultaneously: 16
status: 16
strong: 16
sub: 16
subsystem: 16
themselves: 16
timestamp: 16
topic: 16
transparently: 16
typical: 16
accessing: 15
adapt: 15
applied: 15
arrive: 15
atp: 15
attempt: 15
bar: 15
bc: 15
comparison: 15
containing: 15
contribute: 15
corba: 15
department: 15
describes: 15
diff: 15
edge: 15
effects: 15
exists: 15
fire: 15
gc: 15
greater: 15
idle: 15
included: 15
infiltrated: 15
info: 15
june: 15
latter: 15
linear: 15
maintaining: 15
namely: 15
november: 15
oms: 15
optimize: 15
outgoing: 15
paths: 15
performing: 15
practice: 15
predictable: 15
programming: 15
regions: 15
regular: 15
renesse: 15
represents: 15
respond: 15
sense: 15
sirer: 15
slightly: 15
slow: 15
statistics: 15
stores: 15
supercomputing: 15
teragrid: 15
thousands: 15
tier: 15
underlying: 15
uniformly: 15
whole: 15
accept: 14
addition: 14
arise: 14
balancing: 14
bounded: 14
channels: 14
class: 14
combined: 14
commits: 14
conclusion: 14
concurrency: 14
currency: 14
decrease: 14
deliver: 14
destination: 14
detects: 14
differentiated: 14
directory: 14
dissemination: 14
distinct: 14
drops: 14
engineering: 14
entries: 14
exactly: 14
explore: 14
fail: 14
fifo: 14
financial: 14
finding: 14
growing: 14
guarantees: 14
handling: 14
help: 14
improves: 14
infiltrators: 14
integrated: 14
interested: 14
involves: 14
malicious: 14
modern: 14
option: 14
perfect: 14
policies: 14
prevent: 14
previously: 14
prior: 14
program: 14
providing: 14
published: 14
question: 14
relatively: 14
sabotage: 14
search: 14
singleton: 14
soon: 14
spread: 14
starting: 14
temporarily: 14
thread: 14
tolerate: 14
turn: 14
useful: 14
xj: 14
zookeeper: 14
achieved: 13
add: 13
afs: 13
annual: 13
avg: 13
balance: 13
bound: 13
collaborative: 13
collect: 13
compile: 13
completely: 13
computation: 13
concurrent: 13
consisting: 13
constraints: 13
decreases: 13
depends: 13
determine: 13
determined: 13
did: 13
digests: 13
discarded: 13
dominant: 13
dynamically: 13
embedded: 13
epidemic: 13
exception: 13
eyal: 13
face: 13
far: 13
field: 13
free: 13
frequently: 13
fundamental: 13
generating: 13
gives: 13
grained: 13
growth: 13
his: 13
hit: 13
instances: 13
intended: 13
interactive: 13
interval: 13
intervals: 13
introduction: 13
join: 13
lack: 13
location: 13
magnitude: 13
measure: 13
mentioned: 13
missed: 13
modeless: 13
nfm: 13
normal: 13
notice: 13
ntfs: 13
overview: 13
paradigm: 13
positive: 13
proportional: 13
provided: 13
public: 13
radient: 13
receipt: 13
registers: 13
relevant: 13
remains: 13
researchers: 13
robust: 13
rtt: 13
semantics: 13
setup: 13
shares: 13
situations: 13
special: 13
static: 13
structures: 13
subscribe: 13
thousand: 13
tool: 13
track: 13
trade: 13
tree: 13
unbounded: 13
written: 13
aborted: 12
academic: 12
acceptable: 12
account: 12
accurate: 12
balakrishnan: 12
base: 12
below: 12
ca: 12
capable: 12
caused: 12
challenges: 12
classes: 12
conclude: 12
copies: 12
creating: 12
cumulative: 12
date: 12
decentralized: 12
decide: 12
dedicated: 12
definition: 12
delayed: 12
despite: 12
efficiency: 12
element: 12
enterprise: 12
facts: 12
fairly: 12
footprint: 12
generally: 12
half: 12
hashcash: 12
html: 12
ing: 12
interactions: 12
introduced: 12
iv: 12
ix: 12
jan: 12
java: 12
keep: 12
leads: 12
lfs: 12
li: 12
limitations: 12
locking: 12
maintained: 12
near: 12
obtained: 12
opportunity: 12
oracle: 12
ordering: 12
orders: 12
otherwise: 12
overlap: 12
particularly: 12
past: 12
practical: 12
primary: 12
purposes: 12
push: 12
reason: 12
recently: 12
redundant: 12
rescue: 12
review: 12
roles: 12
roughly: 12
sort: 12
specify: 12
spikes: 12
stack: 12
subset: 12
taking: 12
technique: 12
ten: 12
tms: 12
unif: 12
whenever: 12
you: 12
achieving: 11
acknowledgments: 11
activity: 11
advance: 11
aggregated: 11
argue: 11
authors: 11
automated: 11
basis: 11
begin: 11
callback: 11
complex: 11
converge: 11
crash: 11
deal: 11
deployed: 11
detail: 11
details: 11
detecting: 11
discussion: 11
energy: 11
ensures: 11
equivalent: 11
evict: 11
fa: 11
fee: 11
fetches: 11
fetching: 11
finds: 11
flexible: 11
focused: 11
heterogeneous: 11
hot: 11
hundreds: 11
identifiers: 11
illustrates: 11
implementing: 11
improvements: 11
incorporates: 11
increasingly: 11
indicate: 11
insufficient: 11
interact: 11
introduce: 11
involved: 11
ithaca: 11
largest: 11
layout: 11
linearly: 11
logged: 11
maintenance: 11
measurement: 11
metadata: 11
modal: 11
moving: 11
name: 11
orkut: 11
osdi: 11
pair: 11
parameter: 11
partitioned: 11
prefetches: 11
privacy: 11
processed: 11
prove: 11
providers: 11
randomly: 11
readers: 11
realistic: 11
recovers: 11
replace: 11
replicas: 11
requiring: 11
responsible: 11
retransmission: 11
role: 11
routine: 11
sample: 11
scheduling: 11
sensitive: 11
sep: 11
separate: 11
serve: 11
simplicity: 11
stock: 11
strictly: 11
subsequent: 11
supporting: 11
supports: 11
true: 11
trusted: 11
try: 11
unlikely: 11
unshared: 11
valid: 11
ve: 11
white: 11
whose: 11
xml: 11
accuracy: 10
ack: 10
additionally: 10
along: 10
appear: 10
arg: 10
assumption: 10
asynchronously: 10
becoming: 10
bitcoins: 10
bottleneck: 10
cc: 10
cdn: 10
check: 10
checks: 10
compares: 10
conflict: 10
constructed: 10
continuous: 10
dec: 10
decision: 10
decisions: 10
degenerate: 10
degree: 10
depend: 10
desired: 10
detailed: 10
discussed: 10
distinguish: 10
distributes: 10
effectively: 10
efforts: 10
elements: 10
enable: 10
enhancing: 10
epidemics: 10
especially: 10
evaluated: 10
eventual: 10
examine: 10
expensive: 10
experienced: 10
fairness: 10
false: 10
final: 10
fine: 10
forms: 10
give: 10
gracefully: 10
ideal: 10
improving: 10
infiltrates: 10
injected: 10
ipc: 10
isn: 10
journal: 10
language: 10
leverage: 10
map: 10
maps: 10
mesh: 10
methods: 10
microbenchmarks: 10
minutes: 10
miss: 10
networked: 10
nevertheless: 10
news: 10
novel: 10
overlapping: 10
paxos: 10
pending: 10
possibility: 10
presented: 10
presents: 10
proceed: 10
pushing: 10
rapid: 10
really: 10
recall: 10
remainder: 10
reported: 10
reports: 10
representing: 10
rest: 10
return: 10
rise: 10
robbert: 10
router: 10
routes: 10
routing: 10
runtime: 10
sampling: 10
scales: 10
segment: 10
situation: 10
studies: 10
subject: 10
success: 10
synchrony: 10
tail: 10
team: 10
technical: 10
tests: 10
theorem: 10
think: 10
thresholds: 10
throughout: 10
tion: 10
transparent: 10
unlike: 10
unstable: 10
usually: 10
utility: 10
variant: 10
visible: 10
volume: 10
widely: 10
zone: 10
achieves: 9
advantages: 9
alarm: 9
allowed: 9
appliances: 9
apply: 9
assigned: 9
assigns: 9
assumed: 9
attackers: 9
august: 9
behave: 9
beneficial: 9
break: 9
causing: 9
central: 9
changed: 9
co: 9
commercial: 9
companies: 9
comparing: 9
competing: 9
compute: 9
computers: 9
confidence: 9
connections: 9
continue: 9
curves: 9
daily: 9
default: 9
degradation: 9
depending: 9
deterministic: 9
developing: 9
dirty: 9
discards: 9
disconnected: 9
domain: 9
ec: 9
ee: 9
efficiently: 9
eliminate: 9
en: 9
entirely: 9
execute: 9
explicit: 9
explored: 9
expression: 9
fails: 9
fashion: 9
fd: 9
force: 9
forming: 9
forwarding: 9
frequency: 9
fully: 9
functions: 9
grant: 9
grow: 9
gw: 9
hide: 9
hierarchy: 9
hold: 9
id: 9
ideally: 9
identifier: 9
importance: 9
incentive: 9
inexpensive: 9
infocom: 9
initially: 9
intel: 9
investigate: 9
iperf: 9
iterative: 9
john: 9
kept: 9
knows: 9
leaving: 9
loads: 9
lose: 9
lossless: 9
lowest: 9
maximize: 9
media: 9
merlin: 9
middle: 9
middleware: 9
minor: 9
modifications: 9
modify: 9
modules: 9
nsdi: 9
owner: 9
pattern: 9
permutation: 9
places: 9
plan: 9
profitable: 9
programmer: 9
prone: 9
proportion: 9
quite: 9
reached: 9
reading: 9
records: 9
reflect: 9
respect: 9
retry: 9
ricochet: 9
rings: 9
risk: 9
rounds: 9
rw: 9
sampled: 9
sd: 9
sec: 9
segments: 9
selected: 9
self: 9
session: 9
shall: 9
showing: 9
sigmod: 9
sosp: 9
specialized: 9
steps: 9
susceptible: 9
terms: 9
threads: 9
tolerant: 9
topology: 9
transfers: 9
transformation: 9
transitions: 9
transmitting: 9
trip: 9
ttl: 9
unacknowledged: 9
unless: 9
upcall: 9
vi: 9
viii: 9
want: 9
werner: 9
academia: 8
accordingly: 8
activities: 8
adds: 8
advantage: 8
affect: 8
affects: 8
afrl: 8
aggregates: 8
allocation: 8
amounts: 8
api: 8
arbitrary: 8
arrays: 8
arxiv: 8
aspects: 8
attributes: 8
auditor: 8
automatic: 8
away: 8
backup: 8
behind: 8
beyond: 8
breaks: 8
buffered: 8
byte: 8
cbcb: 8
challenge: 8
charge: 8
checking: 8
clock: 8
collected: 8
combine: 8
come: 8
competition: 8
compromised: 8
concurrently: 8
confirm: 8
congested: 8
connecting: 8
consecutive: 8
contributing: 8
coordinator: 8
corresponds: 8
creates: 8
currencies: 8
dark: 8
david: 8
de: 8
degrades: 8
densities: 8
deploy: 8
deployment: 8
detectors: 8
differs: 8
dogecoin: 8
drag: 8
driven: 8
earns: 8
eligius: 8
employed: 8
engage: 8
equations: 8
equipment: 8
essentially: 8
ever: 8
exact: 8
executed: 8
exist: 8
extensions: 8
external: 8
extreme: 8
favor: 8
filesystem: 8
gib: 8
greatly: 8
header: 8
histograms: 8
honestly: 8
ideas: 8
improvement: 8
input: 8
insight: 8
interaction: 8
jgroups: 8
largely: 8
leader: 8
leading: 8
leave: 8
lemma: 8
light: 8
limits: 8
litecoin: 8
look: 8
mashups: 8
masks: 8
massive: 8
match: 8
max: 8
mc: 8
measuring: 8
method: 8
minimize: 8
misbehaving: 8
mixed: 8
modeled: 8
models: 8
modification: 8
move: 8
neighbor: 8
nominal: 8
nor: 8
notification: 8
notifications: 8
oct: 8
offers: 8
ordered: 8
papers: 8
participation: 8
payoff: 8
perhaps: 8
perturbed: 8
placed: 8
played: 8
plot: 8
portion: 8
prioritised: 8
purpose: 8
put: 8
react: 8
recovering: 8
refer: 8
refrain: 8
replaced: 8
reservation: 8
reservations: 8
retransmissions: 8
returned: 8
reward: 8
robin: 8
sdn: 8
sections: 8
senders: 8
september: 8
series: 8
serves: 8
similarly: 8
simulate: 8
sink: 8
sm: 8
solve: 8
sometimes: 8
span: 8
specification: 8
specified: 8
stacks: 8
staggered: 8
stepwise: 8
strict: 8
subsequently: 8
substituting: 8
suitable: 8
surprisingly: 8
timer: 8
turns: 8
twice: 8
unusable: 8
verify: 8
views: 8
wang: 8
weak: 8
weather: 8
weekly: 8
wiki: 8
ws: 8
xc: 8
aborting: 7
abstraction: 7
acceptors: 7
acknowledged: 7
air: 7
apache: 7
applying: 7
architectural: 7
arises: 7
array: 7
attractive: 7
belongs: 7
big: 7
broadcast: 7
bsd: 7
byzantine: 7
calculate: 7
card: 7
causes: 7
cb: 7
characteristics: 7
cisco: 7
claim: 7
cleaning: 7
cleanup: 7
clearly: 7
closer: 7
collapse: 7
communities: 7
completion: 7
complexity: 7
concept: 7
conflicting: 7
connection: 7
considering: 7
consistently: 7
construct: 7
contemporary: 7
contributions: 7
cooperative: 7
counter: 7
creation: 7
dashed: 7
december: 7
decoupling: 7
degraded: 7
delaying: 7
demers: 7
deploying: 7
dept: 7
derived: 7
designs: 7
deter: 7
determining: 7
display: 7
disrupt: 7
doesn: 7
doing: 7
dolev: 7
downstream: 7
easier: 7
elapsed: 7
electronic: 7
eliminated: 7
eliminates: 7
employs: 7
empty: 7
emulab: 7
enabling: 7
equally: 7
everything: 7
exchanges: 7
experiences: 7
exploit: 7
exponential: 7
extend: 7
feature: 7
feedback: 7
feeds: 7
fires: 7
fit: 7
follow: 7
furthermore: 7
gaining: 7
gray: 7
guarantee: 7
handles: 7
hour: 7
huge: 7
ignored: 7
image: 7
implementations: 7
importantly: 7
incoherent: 7
incorporate: 7
inferior: 7
introduces: 7
inventory: 7
isis: 7
isolation: 7
january: 7
joseph: 7
keys: 7
latest: 7
lbfs: 7
located: 7
locations: 7
ma: 7
mahesh: 7
mapping: 7
mica: 7
mines: 7
ml: 7
mod: 7
modeling: 7
modifying: 7
motivation: 7
multicasts: 7
nature: 7
negligible: 7
nothing: 7
nsf: 7
oblivious: 7
observation: 7
obvious: 7
october: 7
operator: 7
optimistic: 7
overloaded: 7
partitions: 7
percentile: 7
persistent: 7
plus: 7
poorly: 7
population: 7
pre: 7
prefer: 7
press: 7
prime: 7
programs: 7
propagated: 7
prototype: 7
publishing: 7
rack: 7
rarely: 7
rc: 7
reaches: 7
record: 7
reflects: 7
regarding: 7
register: 7
regularly: 7
relaying: 7
rely: 7
repeated: 7
represent: 7
represented: 7
requesting: 7
resistant: 7
restart: 7
retailer: 7
retrieve: 7
rich: 7
route: 7
routers: 7
san: 7
savings: 7
scaling: 7
seamlessly: 7
seek: 7
sharply: 7
she: 7
simplify: 7
simulations: 7
simulator: 7
sites: 7
socket: 7
sockets: 7
springer: 7
stop: 7
storing: 7
subservices: 7
substantially: 7
successful: 7
timeout: 7
tradeoff: 7
trans: 7
transition: 7
transmit: 7
treat: 7
treated: 7
trees: 7
trust: 7
twenty: 7
u: 7
ubiquitous: 7
unaware: 7
unchanged: 7
useless: 7
utilization: 7
validation: 7
variation: 7
vendor: 7
vendors: 7
versus: 7
vii: 7
violating: 7
wan: 7
year: 7
yield: 7
yields: 7
yu: 7
accommodate: 6
achievable: 6
acknowledgement: 6
act: 6
acting: 6
addressed: 6
addresses: 6
adjustment: 6
administrators: 6
affected: 6
afosr: 6
agreement: 6
alternatives: 6
analyzed: 6
apparently: 6
appropriately: 6
argument: 6
arrives: 6
assumptions: 6
atomic: 6
averages: 6
avoids: 6
bars: 6
begins: 6
berkeley: 6
bonneau: 6
bottom: 6
boundaries: 6
broadly: 6
bullet: 6
california: 6
calls: 6
catch: 6
checkpoint: 6
checksum: 6
chen: 6
closely: 6
clouds: 6
clr: 6
coherent: 6
combination: 6
combines: 6
comes: 6
command: 6
comprised: 6
comput: 6
concave: 6
conducted: 6
conjunction: 6
consensus: 6
conservative: 6
considerable: 6
contain: 6
controlled: 6
coordinate: 6
copying: 6
corporation: 6
costly: 6
coupled: 6
crashed: 6
cross: 6
curve: 6
customize: 6
darpa: 6
dates: 6
db: 6
debian: 6
denotes: 6
dependent: 6
deployments: 6
description: 6
detector: 6
determines: 6
develop: 6
digest: 6
discusfish: 6
disjoint: 6
disseminate: 6
divides: 6
document: 6
draw: 6
druschel: 6
durability: 6
earth: 6
ed: 6
effort: 6
egress: 6
eliminating: 6
email: 6
erasure: 6
established: 6
expressions: 6
facebook: 6
feasibility: 6
feed: 6
fifth: 6
fill: 6
focuses: 6
forced: 6
forks: 6
former: 6
foundation: 6
frame: 6
france: 6
gbps: 6
generic: 6
hashing: 6
heartbeat: 6
hidden: 6
histories: 6
hop: 6
huang: 6
imposed: 6
improved: 6
inc: 6
indicates: 6
industry: 6
ingress: 6
intensive: 6
intercepted: 6
intermediate: 6
issued: 6
issuing: 6
kncminer: 6
krzysztof: 6
lacking: 6
lamport: 6
lan: 6
lans: 6
lcm: 6
ledger: 6
loaded: 6
locally: 6
logical: 6
lt: 6
luu: 6
manage: 6
master: 6
matching: 6
maxx: 6
mean: 6
measured: 6
min: 6
mission: 6
modifies: 6
moment: 6
moves: 6
mp: 6
multicasting: 6
my: 6
naturally: 6
nd: 6
nearly: 6
necessarily: 6
noble: 6
nonce: 6
normalizes: 6
notion: 6
numbered: 6
numerical: 6
numerous: 6
occurring: 6
older: 6
operators: 6
optimized: 6
oscillatory: 6
ostrowski: 6
outlined: 6
outperforms: 6
output: 6
overload: 6
pareto: 6
parties: 6
passive: 6
pdf: 6
perfectly: 6
permit: 6
perspective: 6
phase: 6
play: 6
pooled: 6
possibly: 6
powerful: 6
predict: 6
prefix: 6
price: 6
primarily: 6
procedure: 6
produced: 6
publicly: 6
publisher: 6
pulls: 6
punish: 6
questions: 6
queuing: 6
qwest: 6
reachable: 6
red: 6
reduction: 6
redundancy: 6
reject: 6
repeatedly: 6
replay: 6
replicate: 6
resource: 6
resulted: 6
returns: 6
reveals: 6
rewards: 6
rig: 6
ring: 6
rj: 6
rules: 6
samples: 6
satyanarayanan: 6
say: 6
seattle: 6
seems: 6
select: 6
sensitivity: 6
serialized: 6
six: 6
slowly: 6
snapshot: 6
solving: 6
somewhat: 6
sorts: 6
standardized: 6
states: 6
straightforward: 6
stratum: 6
suggested: 6
summarize: 6
sun: 6
super: 6
supplies: 6
switzerland: 6
synchronization: 6
targeted: 6
tat: 6
thank: 6
theory: 6
timeouts: 6
tit: 6
toolkit: 6
tracking: 6
transmits: 6
trigger: 6
trying: 6
txnid: 6
ultimately: 6
understand: 6
unfortunately: 6
unreliable: 6
usability: 6
usable: 6
validate: 6
variability: 6
variations: 6
vast: 6
vector: 6
vldb: 6
welsh: 6
why: 6
withheld: 6
won: 6
workers: 6
worse: 6
xxx: 6
yahoo: 6
zhang: 6
zhu: 6
ability: 5
absence: 5
absolute: 5
acknowledgements: 5
acknowledgment: 5
acl: 5
adapting: 5
adjusting: 5
ago: 5
agree: 5
ahead: 5
allocated: 5
anyone: 5
append: 5
approximate: 5
arbitrarily: 5
arguably: 5
arrival: 5
assuming: 5
atkin: 5
atomicity: 5
attempts: 5
author: 5
avoiding: 5
award: 5
backed: 5
band: 5
behalf: 5
behaves: 5
belong: 5
bit: 5
bits: 5
blocking: 5
brevity: 5
brewer: 5
broken: 5
broker: 5
buildings: 5
bus: 5
calculated: 5
calculates: 5
capture: 5
carry: 5
catches: 5
caught: 5
chains: 5
cheap: 5
cheriton: 5
classified: 5
cloned: 5
collapses: 5
comments: 5
communicate: 5
communicates: 5
compose: 5
concern: 5
concerns: 5
consequence: 5
considerations: 5
constitutes: 5
constrained: 5
consume: 5
consuming: 5
contact: 5
continuously: 5
coolstreaming: 5
cope: 5
count: 5
counts: 5
crashes: 5
credentials: 5
crossing: 5
customers: 5
danny: 5
datagram: 5
day: 5
dealing: 5
defense: 5
demands: 5
demonstrated: 5
denial: 5
denoted: 5
depict: 5
describing: 5
df: 5
dialog: 5
direction: 5
division: 5
dramatic: 5
dsn: 5
edition: 5
eferences: 5
eight: 5
elaborate: 5
elated: 5
embedding: 5
emerging: 5
employing: 5
encourage: 5
encryption: 5
enforce: 5
ephemeral: 5
estimated: 5
ethernet: 5
exceed: 5
except: 5
exhibit: 5
explain: 5
explicitly: 5
exploiting: 5
exploring: 5
expressed: 5
falls: 5
faults: 5
faulty: 5
filtering: 5
firing: 5
flexibility: 5
forces: 5
forwarded: 5
frames: 5
freebsd: 5
frequent: 5
gap: 5
generality: 5
geo: 5
geographical: 5
gigabits: 5
gribble: 5
grid: 5
ground: 5
gu: 5
hacker: 5
health: 5
hierarchical: 5
highperformance: 5
hints: 5
hooks: 5
human: 5
identification: 5
illustrate: 5
imagine: 5
implicit: 5
implies: 5
inaccurate: 5
incorrect: 5
incrementally: 5
incurs: 5
independently: 5
informatik: 5
informatique: 5
innovation: 5
instantly: 5
integrating: 5
interesting: 5
interference: 5
internal: 5
interoperability: 5
invalidate: 5
investigated: 5
investigator: 5
iptv: 5
isps: 5
ittay: 5
johnson: 5
joining: 5
joins: 5
katz: 5
kleinberg: 5
lakshmi: 5
languages: 5
layouts: 5
learn: 5
leases: 5
lengths: 5
lightweight: 5
linking: 5
liu: 5
locality: 5
locks: 5
logic: 5
looking: 5
lossy: 5
mar: 5
marketing: 5
mask: 5
messaging: 5
metrics: 5
minibrowsers: 5
minority: 5
monitors: 5
monthly: 5
moved: 5
mutual: 5
national: 5
normally: 5
ntroduction: 5
observations: 5
obtains: 5
occasional: 5
occurred: 5
offered: 5
omit: 5
omitted: 5
onclusion: 5
onon: 5
optimization: 5
optimizations: 5
optimizes: 5
organization: 5
organizations: 5
organized: 5
originally: 5
orthogonal: 5
outside: 5
overcome: 5
pairs: 5
partially: 5
passed: 5
pause: 5
pay: 5
pays: 5
peerto: 5
people: 5
percentages: 5
permitting: 5
personal: 5
pf: 5
phenomenon: 5
placement: 5
plots: 5
poison: 5
positives: 5
precisely: 5
predictor: 5
predictors: 5
probabilistic: 5
proceeds: 5
progresses: 5
property: 5
proprietary: 5
protected: 5
proved: 5
punished: 5
quick: 5
raise: 5
rare: 5
raw: 5
rd: 5
reaching: 5
regardless: 5
release: 5
reliance: 5
remaining: 5
remove: 5
repairs: 5
repeat: 5
requested: 5
requirement: 5
resilience: 5
resolve: 5
respects: 5
responsiveness: 5
restrictions: 5
reveal: 5
rizzo: 5
road: 5
robustness: 5
satisfactory: 5
satisfied: 5
save: 5
saving: 5
scheduled: 5
schneider: 5
seem: 5
sees: 5
selecting: 5
sensors: 5
separated: 5
separately: 5
sequenced: 5
serializable: 5
sessions: 5
shard: 5
shards: 5
signal: 5
simulated: 5
sized: 5
slack: 5
slower: 5
sophisticated: 5
soule: 5
speculative: 5
sprint: 5
stated: 5
stay: 5
studied: 5
submit: 5
substantial: 5
subsystems: 5
suffer: 5
sum: 5
summarized: 5
suspicion: 5
switched: 5
switches: 5
tech: 5
tell: 5
temporary: 5
texture: 5
thinking: 5
tightly: 5
timely: 5
timestamps: 5
tocs: 5
topologies: 5
tracks: 5
transform: 5
transformations: 5
trap: 5
treating: 5
trend: 5
trends: 5
triggers: 5
tune: 5
tuning: 5
turned: 5
unable: 5
unexpected: 5
unit: 5
unpredictable: 5
untrusted: 5
updating: 5
upper: 5
ut: 5
utilisation: 5
verifying: 5
viewed: 5
volatile: 5
vs: 5
waiting: 5
walk: 5
wall: 5
wants: 5
win: 5
wired: 5
writers: 5
ycsb: 5
yx: 5
ab: 4
abbadi: 4
ac: 4
accepted: 4
acks: 4
action: 4
actions: 4
adopted: 4
advanced: 4
advances: 4
agrawal: 4
alone: 4
alongside: 4
alternate: 4
alvisi: 4
amir: 4
amortizable: 4
analogous: 4
andrew: 4
answer: 4
antpool: 4
applicable: 4
approximated: 4
april: 4
archive: 4
arrow: 4
aspect: 4
assign: 4
assumes: 4
athey: 4
awkward: 4
bahack: 4
ballots: 4
banking: 4
behaviour: 4
benchmark: 4
bernstein: 4
biersack: 4
bifurcations: 4
bitcointalk: 4
blade: 4
blast: 4
blend: 4
blocked: 4
blogspot: 4
border: 4
boxes: 4
brief: 4
briefly: 4
broadcasts: 4
broader: 4
bulk: 4
burstier: 4
calculator: 4
callbacks: 4
caller: 4
capitalization: 4
captures: 4
carefully: 4
certainly: 4
charts: 4
chat: 4
city: 4
clean: 4
clones: 4
closes: 4
cms: 4
collecting: 4
collector: 4
combining: 4
coming: 4
comparable: 4
compensated: 4
compiles: 4
completed: 4
complicated: 4
componentized: 4
composition: 4
comprehensive: 4
compromise: 4
conduct: 4
confirms: 4
consequences: 4
consist: 4
contained: 4
continued: 4
converges: 4
cooperation: 4
correlated: 4
correlation: 4
courtois: 4
crucial: 4
cryptography: 4
cutting: 4
cycle: 4
danger: 4
das: 4
debugging: 4
decades: 4
decided: 4
declining: 4
deep: 4
deferred: 4
defines: 4
demonstrates: 4
desktop: 4
devastating: 4
di: 4
differences: 4
differentiate: 4
differently: 4
directed: 4
directions: 4
directories: 4
disaster: 4
discovery: 4
discussions: 4
disloyal: 4
disrupted: 4
disruption: 4
distant: 4
distribute: 4
distributions: 4
double: 4
ease: 4
ebay: 4
economic: 4
editor: 4
educause: 4
elsewhere: 4
emin: 4
emulate: 4
encoder: 4
encodes: 4
endhosts: 4
enforcing: 4
engages: 4
engineer: 4
enhanced: 4
enormous: 4
enter: 4
envelope: 4
epi: 4
eprint: 4
esb: 4
evenly: 4
evicting: 4
evidence: 4
evil: 4
ex: 4
examines: 4
exchanged: 4
exclusive: 4
executing: 4
existence: 4
export: 4
exposed: 4
extensive: 4
faber: 4
faced: 4
familiar: 4
february: 4
filter: 4
firewalls: 4
five: 4
fixing: 4
flowing: 4
flush: 4
flushes: 4
focusing: 4
followed: 4
formula: 4
foster: 4
fourth: 4
fragmentation: 4
francis: 4
francisco: 4
freedman: 4
friendly: 4
gain: 4
games: 4
gateways: 4
gathered: 4
gets: 4
globally: 4
goes: 4
going: 4
graceful: 4
grants: 4
grateful: 4
grossklags: 4
hackingdistributed: 4
hakim: 4
heartbeats: 4
heavily: 4
helps: 4
hint: 4
holds: 4
home: 4
honeypot: 4
hope: 4
horus: 4
hweather: 4
identified: 4
identifying: 4
identity: 4
ids: 4
ignore: 4
images: 4
impacted: 4
impossible: 4
inaccessible: 4
incorporating: 4
incurred: 4
incurring: 4
inform: 4
initiated: 4
initiative: 4
inquiry: 4
integral: 4
integrate: 4
intelligent: 4
intend: 4
interacts: 4
interrupted: 4
intervening: 4
intrinsically: 4
introducing: 4
invalidated: 4
invalidating: 4
isbn: 4
javascript: 4
jboss: 4
jelasity: 4
joint: 4
jose: 4
july: 4
jumbo: 4
jxta: 4
kaashoek: 4
keeping: 4
keidar: 4
kermarrec: 4
kj: 4
korn: 4
lacks: 4
lakshman: 4
laszka: 4
leaders: 4
learning: 4
leaves: 4
letting: 4
leveraging: 4
libraries: 4
lies: 4
listed: 4
lived: 4
ll: 4
logsim: 4
longdistance: 4
looked: 4
lru: 4
maid: 4
malfunctioning: 4
managing: 4
marked: 4
matched: 4
matrix: 4
maximizes: 4
measures: 4
merely: 4
methodology: 4
miles: 4
military: 4
miller: 4
mind: 4
minimal: 4
minted: 4
minute: 4
misconfigured: 4
misses: 4
mix: 4
mixture: 4
mobility: 4
modulating: 4
monitor: 4
monopoly: 4
moore: 4
msg: 4
mtus: 4
naive: 4
nak: 4
namecoin: 4
narrow: 4
netfilter: 4
normalized: 4
notable: 4
notify: 4
numerically: 4
obstacles: 4
obtaining: 4
offering: 4
ools: 4
operates: 4
optimum: 4
organofcorti: 4
ork: 4
outstanding: 4
owners: 4
ownership: 4
packages: 4
parameterized: 4
participate: 4
parts: 4
patient: 4
paul: 4
payments: 4
payout: 4
payouts: 4
peak: 4
penalty: 4
peps: 4
periodic: 4
permacoin: 4
permutations: 4
person: 4
perspectives: 4
pfldnet: 4
phenomena: 4
php: 4
pi: 4
picked: 4
pictures: 4
placing: 4
player: 4
plotting: 4
podc: 4
poll: 4
polling: 4
positions: 4
practicality: 4
predicted: 4
preferred: 4
preprint: 4
pressure: 4
prevents: 4
pricing: 4
primitives: 4
principle: 4
probabilities: 4
probably: 4
prominent: 4
promising: 4
protect: 4
provisioned: 4
provisioning: 4
pub: 4
publication: 4
pulled: 4
purely: 4
qi: 4
qp: 4
quantities: 4
quantum: 4
querying: 4
readset: 4
reality: 4
realize: 4
reasonable: 4
reference: 4
reflected: 4
regional: 4
rejoin: 4
relation: 4
relations: 4
reliably: 4
removed: 4
reno: 4
repairing: 4
replacement: 4
replicating: 4
repo: 4
reserved: 4
residing: 4
resilient: 4
resolution: 4
resolved: 4
responding: 4
responses: 4
retailers: 4
retransmit: 4
rev: 4
revoke: 4
rigs: 4
rk: 4
robert: 4
root: 4
rosenfeld: 4
routed: 4
rover: 4
rowstron: 4
rule: 4
safety: 4
saturate: 4
saw: 4
scan: 4
secondary: 4
secret: 4
secure: 4
secured: 4
seeks: 4
selective: 4
selfish: 4
separates: 4
sequences: 4
sequentially: 4
sha: 4
shasha: 4
shenker: 4
shift: 4
shut: 4
silver: 4
situational: 4
sixteenth: 4
smalltalk: 4
smart: 4
smr: 4
sold: 4
spanning: 4
spun: 4
srm: 4
standardization: 4
statistically: 4
steadily: 4
steady: 4
stress: 4
stronger: 4
strongly: 4
students: 4
subjected: 4
subsection: 4
successes: 4
suffers: 4
sums: 4
suspected: 4
symmetry: 4
synchronized: 4
tackle: 4
tailored: 4
technological: 4
tens: 4
terminology: 4
terrain: 4
terry: 4
tested: 4
theoretic: 4
things: 4
threaded: 4
took: 4
tornado: 4
touched: 4
towsley: 4
traced: 4
tradeoffs: 4
trading: 4
translate: 4
travel: 4
treats: 4
tremendous: 4
trial: 4
truly: 4
tuple: 4
understanding: 4
undesirable: 4
units: 4
unknown: 4
unusual: 4
upstream: 4
usd: 4
usual: 4
utilities: 4
vahdat: 4
valuable: 4
variable: 4
variants: 4
varies: 4
vfs: 4
viable: 4
vice: 4
visual: 4
von: 4
vulnerable: 4
waits: 4
walsh: 4
washington: 4
weakly: 4
weatherspoon: 4
weight: 4
wish: 4
withhold: 4
worked: 4
worst: 4
worth: 4
writeset: 4
wrong: 4
xk: 4
xkj: 4
yearly: 4
your: 4
abadi: 3
aborts: 3
accepting: 3
accepts: 3
accountable: 3
accumulated: 3
accusations: 3
acidrain: 3
acknowledge: 3
acquire: 3
actively: 3
adapts: 3
adequate: 3
adjust: 3
advancing: 3
advantageous: 3
advertisements: 3
afec: 3
affecting: 3
aggregating: 3
agnostic: 3
aguilera: 3
aimed: 3
aircraft: 3
alan: 3
albeit: 3
alberta: 3
album: 3
alert: 3
alerts: 3
alleviate: 3
amenable: 3
analytical: 3
analytically: 3
anomaly: 3
anything: 3
app: 3
apparent: 3
appears: 3
ar: 3
areas: 3
aren: 3
argued: 3
arising: 3
arla: 3
assertion: 3
assess: 3
assigning: 3
assignment: 3
association: 3
assure: 3
attribute: 3
auditable: 3
aug: 3
authorization: 3
avatars: 3
avoided: 3
backbone: 3
balancer: 3
baltimore: 3
banks: 3
bases: 3
basically: 3
batch: 3
bayou: 3
beginning: 3
bianchini: 3
black: 3
boards: 3
bone: 3
boston: 3
boures: 3
breaking: 3
bring: 3
browser: 3
builds: 3
busy: 3
calling: 3
cambridge: 3
camera: 3
cap: 3
care: 3
carries: 3
categories: 3
chandra: 3
characteristic: 3
checked: 3
children: 3
chronous: 3
chubby: 3
churn: 3
circumvent: 3
claims: 3
clement: 3
closing: 3
colleagues: 3
colorado: 3
column: 3
combinations: 3
commands: 3
commerce: 3
commonly: 3
commun: 3
communicating: 3
company: 3
compatible: 3
compete: 3
competitive: 3
compilers: 3
compiling: 3
completes: 3
composed: 3
compound: 3
comprises: 3
compulsory: 3
computational: 3
computed: 3
con: 3
conceived: 3
concentrate: 3
concluded: 3
conclusions: 3
condition: 3
configurable: 3
confirmed: 3
conservation: 3
conserve: 3
consideration: 3
constructing: 3
construction: 3
consumed: 3
consumes: 3
continues: 3
convinced: 3
convoy: 3
cooperate: 3
coordinates: 3
coordination: 3
copper: 3
corbett: 3
corfu: 3
corporate: 3
correcting: 3
correctness: 3
correlate: 3
criterion: 3
culler: 3
culprit: 3
cumulus: 3
curious: 3
custer: 3
custom: 3
customer: 3
customized: 3
cycles: 3
dahlin: 3
dangers: 3
davis: 3
ddos: 3
deadline: 3
deadlines: 3
deals: 3
decade: 3
deciding: 3
decker: 3
decreasing: 3
deering: 3
degrade: 3
demonstrating: 3
dependable: 3
designers: 3
desire: 3
determinism: 3
deviation: 3
dialogue: 3
differentiation: 3
dis: 3
discover: 3
discrepancy: 3
disruptions: 3
disruptive: 3
disseminated: 3
distributing: 3
dns: 3
documentation: 3
documents: 3
dollars: 3
dominated: 3
dos: 3
drawn: 3
driver: 3
dropping: 3
drpm: 3
dying: 3
economics: 3
eded: 3
edward: 3
eicken: 3
el: 3
elastic: 3
elastras: 3
election: 3
electrical: 3
elegant: 3
else: 3
emergence: 3
emotional: 3
empire: 3
encodings: 3
encouraging: 3
ending: 3
endpoint: 3
endto: 3
enhances: 3
ensuring: 3
enterprises: 3
entities: 3
entity: 3
essay: 3
essential: 3
evaluates: 3
evaluating: 3
eventing: 3
evident: 3
evolution: 3
evolved: 3
exacerbates: 3
excellent: 3
excluding: 3
executes: 3
expands: 3
expelled: 3
experimentally: 3
experimented: 3
expires: 3
explorer: 3
exposes: 3
extends: 3
extension: 3
extent: 3
extra: 3
extracted: 3
fascinating: 3
fewer: 3
fg: 3
fields: 3
fifteenth: 3
finite: 3
firm: 3
flash: 3
flat: 3
fledged: 3
flight: 3
folder: 3
folders: 3
forest: 3
format: 3
formation: 3
franklin: 3
freeloaders: 3
french: 3
friend: 3
fs: 3
ganesh: 3
gargamel: 3
gather: 3
geographically: 3
gf: 3
gfgf: 3
goals: 3
gossiped: 3
government: 3
gps: 3
graphically: 3
great: 3
greatest: 3
grids: 3
grossman: 3
gt: 3
guaranteed: 3
gui: 3
gummadi: 3
guo: 3
gurumurthi: 3
hall: 3
handlers: 3
handley: 3
happen: 3
happy: 3
hauser: 3
haven: 3
heap: 3
helland: 3
helping: 3
hibernator: 3
hierarchically: 3
hierarchies: 3
highspeed: 3
homogeneous: 3
howard: 3
hypothesis: 3
ibm: 3
icdcs: 3
ics: 3
ignores: 3
ignoring: 3
il: 3
immersed: 3
implicitly: 3
impose: 3
imposes: 3
incentives: 3
income: 3
incorporated: 3
incorrectly: 3
incremental: 3
incremented: 3
incur: 3
indiana: 3
indicating: 3
informed: 3
inherits: 3
initiate: 3
innovations: 3
inside: 3
insights: 3
instability: 3
instantaneous: 3
institute: 3
intent: 3
interacting: 3
intercept: 3
intercepting: 3
intercepts: 3
interconnect: 3
interconnected: 3
internals: 3
internetworks: 3
interplay: 3
intervene: 3
inversion: 3
irregular: 3
iteration: 3
jbosscache: 3
jim: 3
jitter: 3
keeps: 3
kenneth: 3
knowing: 3
kuenning: 3
landscape: 3
laptops: 3
larson: 3
late: 3
lateral: 3
lesson: 3
linkage: 3
linked: 3
lions: 3
lloyd: 3
logically: 3
london: 3
looks: 3
loop: 3
losing: 3
lot: 3
luby: 3
mainframe: 3
mainsoft: 3
mainwin: 3
malkhi: 3
malo: 3
managers: 3
marian: 3
markets: 3
marks: 3
mashed: 3
matter: 3
mazie: 3
mckusick: 3
meanwhile: 3
memcached: 3
michael: 3
microbenchmark: 3
mid: 3
migration: 3
minimizing: 3
mirror: 3
mitigate: 3
modular: 3
montresor: 3
motivated: 3
motivates: 3
mountain: 3
movies: 3
multithreaded: 3
nat: 3
native: 3
neighborhood: 3
ninja: 3
nonetheless: 3
noticeable: 3
null: 3
observing: 3
obstruction: 3
occasionally: 3
odel: 3
oneway: 3
onto: 3
opened: 3
operational: 3
opposed: 3
optimizing: 3
optionally: 3
organize: 3
orientation: 3
ousterhout: 3
outbound: 3
outdated: 3
overflows: 3
overlapped: 3
overloads: 3
overwhelmed: 3
pacific: 3
padhye: 3
pai: 3
paid: 3
parameterize: 3
participant: 3
passing: 3
paying: 3
payload: 3
pc: 3
pedone: 3
penalties: 3
perceived: 3
percent: 3
perez: 3
personalities: 3
personalization: 3
pervasive: 3
peter: 3
phone: 3
pinheiro: 3
pisa: 3
players: 3
pleisch: 3
poisson: 3
polls: 3
poor: 3
popek: 3
popularity: 3
portions: 3
pose: 3
posed: 3
positioning: 3
prabhakaran: 3
prebuilt: 3
precedence: 3
predominate: 3
preferentially: 3
prefetched: 3
presentation: 3
preserved: 3
president: 3
preventing: 3
principal: 3
probing: 3
processor: 3
produce: 3
productivity: 3
programmers: 3
promise: 3
propagate: 3
properly: 3
protection: 3
proves: 3
provider: 3
psockets: 3
publishers: 3
punishment: 3
purchases: 3
pushed: 3
putting: 3
qpqp: 3
quanta: 3
queueing: 3
queues: 3
raises: 3
ramp: 3
ranging: 3
rao: 3
raptor: 3
reacting: 3
readonly: 3
realizing: 3
reasoning: 3
recipient: 3
recognize: 3
recommendations: 3
reconstruct: 3
recoveries: 3
reflecting: 3
rejoins: 3
relate: 3
relates: 3
released: 3
releases: 3
remarkably: 3
removing: 3
replaces: 3
replacing: 3
replayed: 3
replica: 3
replies: 3
representation: 3
representative: 3
res: 3
reserve: 3
resort: 3
resp: 3
respective: 3
responds: 3
restarting: 3
restored: 3
restricted: 3
retain: 3
retransmitted: 3
retrieves: 3
revisions: 3
rewarding: 3
rfc: 3
rises: 3
risks: 3
safely: 3
saint: 3
satisfies: 3
satisfy: 3
satisfying: 3
scaled: 3
scene: 3
school: 3
scope: 3
script: 3
semantic: 3
sensor: 3
separation: 3
sequential: 3
served: 3
seventeenth: 3
seventh: 3
severe: 3
sharded: 3
shepherd: 3
showed: 3
sight: 3
simpler: 3
simplest: 3
sinfonia: 3
situated: 3
sixth: 3
sleep: 3
slight: 3
smallest: 3
soft: 3
song: 3
sorrosal: 3
sound: 3
spanner: 3
spare: 3
spatial: 3
specifications: 3
speculatively: 3
splitstream: 3
splitting: 3
sporadic: 3
spot: 3
sprite: 3
sr: 3
ssrn: 3
stability: 3
standardize: 3
started: 3
stays: 3
stems: 3
streamed: 3
struggled: 3
subnet: 3
subscriber: 3
substrate: 3
successive: 3
suddenly: 3
sufficiently: 3
suggests: 3
suite: 3
supplied: 3
surprising: 3
suspicions: 3
symbolic: 3
symbols: 3
synchronously: 3
sys: 3
syst: 3
tables: 3
tacc: 3
tagging: 3
talk: 3
tape: 3
targets: 3
taylor: 3
teams: 3
television: 3
tends: 3
terminating: 3
testing: 3
text: 3
thin: 3
thinks: 3
thirty: 3
thomson: 3
threat: 3
tight: 3
tiled: 3
tolerable: 3
ton: 3
tput: 3
tr: 3
traditionally: 3
train: 3
transferred: 3
transferring: 3
transmissions: 3
triggered: 3
triggering: 3
trivial: 3
trouble: 3
truncation: 3
tsunami: 3
tudor: 3
tudorm: 3
turning: 3
uk: 3
unacceptable: 3
unavailable: 3
unblocks: 3
uncommittable: 3
undetected: 3
unexpectedly: 3
unfairly: 3
unmanaged: 3
unperturbed: 3
unrelated: 3
utah: 3
utilize: 3
uwin: 3
validated: 3
valuation: 3
variables: 3
variance: 3
verified: 3
verlag: 3
viewing: 3
vigfusson: 3
visualization: 3
vt: 3
wake: 3
walli: 3
wanted: 3
warns: 3
watch: 3
wefel: 3
wei: 3
whatever: 3
widespread: 3
winner: 3
wisdom: 3
wobber: 3
worlds: 3
worry: 3
wv: 3
yxyx: 3
zero: 3
zhao: 3
zurich: 3
abandon: 2
abc: 2
abilene: 2
abstractions: 2
academics: 2
acceptance: 2
accessible: 2
accomplished: 2
accordance: 2
accounting: 2
accumulating: 2
accurately: 2
accusation: 2
accused: 2
acquisition: 2
adam: 2
addison: 2
addressing: 2
adjusted: 2
adjusts: 2
administrative: 2
adopt: 2
advancements: 2
advent: 2
adversary: 2
advertises: 2
advice: 2
advocated: 2
aegis: 2
affinity: 2
aforementioned: 2
age: 2
agents: 2
aggregator: 2
aggressive: 2
aict: 2
aim: 2
ajax: 2
akamai: 2
alaska: 2
alberto: 2
albums: 2
alive: 2
alleviating: 2
allocates: 2
allocating: 2
alloscomp: 2
alternatively: 2
altruistic: 2
ame: 2
amortizes: 2
amounting: 2
analyzes: 2
anchorage: 2
anderson: 2
andresen: 2
anomalies: 2
anonymity: 2
anonymously: 2
anti: 2
anticipate: 2
antony: 2
apart: 2
apis: 2
appealing: 2
appeared: 2
appends: 2
applicationindependent: 2
approximately: 2
approximation: 2
approximations: 2
apr: 2
archetypal: 2
argues: 2
arguing: 2
arithmetic: 2
arose: 2
arraystructured: 2
arrived: 2
art: 2
article: 2
articles: 2
asia: 2
asics: 2
asks: 2
asp: 2
aspx: 2
assists: 2
assurance: 2
astonishingly: 2
asynch: 2
atm: 2
attach: 2
attached: 2
attain: 2
attempted: 2
attempting: 2
attestation: 2
attract: 2
attraction: 2
attractiveness: 2
audio: 2
aumann: 2
authentication: 2
automate: 2
autonomous: 2
autotuning: 2
avoidance: 2
ba: 2
baa: 2
babaoglu: 2
bach: 2
backlashed: 2
bailey: 2
baker: 2
ban: 2
barb: 2
barr: 2
barrier: 2
bast: 2
basu: 2
began: 2
behaved: 2
behaving: 2
belonging: 2
benjamin: 2
berlin: 2
bernoulli: 2
besides: 2
bespoke: 2
bhargava: 2
bifurcation: 2
billion: 2
binary: 2
binomial: 2
birrell: 2
bitcoinfoundation: 2
bjornstad: 2
blank: 2
bloomberg: 2
blow: 2
blumenthal: 2
boils: 2
bolton: 2
bonus: 2
borders: 2
box: 2
boycott: 2
bridge: 2
brings: 2
brokerage: 2
bronson: 2
browsers: 2
bruijn: 2
btcguild: 2
btchine: 2
buf: 2
bulpin: 2
burden: 2
burstiness: 2
business: 2
businesses: 2
buterin: 2
butterfly: 2
bypass: 2
caja: 2
calculation: 2
calculations: 2
calvin: 2
came: 2
canada: 2
candidates: 2
canonical: 2
capabilities: 2
carey: 2
carolina: 2
carrera: 2
cash: 2
castro: 2
casual: 2
casually: 2
category: 2
cation: 2
cdns: 2
cease: 2
ceases: 2
ceived: 2
census: 2
centralization: 2
century: 2
certainty: 2
cfm: 2
challenging: 2
chance: 2
characterise: 2
cheaply: 2
checkout: 2
checksums: 2
chemical: 2
chicago: 2
chief: 2
china: 2
chowdhry: 2
cidr: 2
circle: 2
circulate: 2
circulates: 2
circumstances: 2
cited: 2
clark: 2
click: 2
cloudviews: 2
coarse: 2
coexist: 2
coherence: 2
cohort: 2
colarelli: 2
colocated: 2
color: 2
combat: 2
comer: 2
committing: 2
commons: 2
communicated: 2
compelled: 2
compensate: 2
compensation: 2
complement: 2
composing: 2
computes: 2
concentrated: 2
concert: 2
conclusive: 2
confident: 2
confined: 2
connect: 2
cons: 2
considerably: 2
considers: 2
constitute: 2
constraint: 2
contacted: 2
contexts: 2
contract: 2
contradicts: 2
controlling: 2
conversion: 2
converted: 2
converting: 2
cooling: 2
cooper: 2
cording: 2
corner: 2
correspond: 2
countermeasures: 2
counterpart: 2
covered: 2
covering: 2
cox: 2
cpus: 2
credited: 2
credits: 2
cripple: 2
cripples: 2
criticism: 2
croquet: 2
crypto: 2
cryptocurrencies: 2
cryptographic: 2
cryptology: 2
ct: 2
cubic: 2
cypherspace: 2
cz: 2
damage: 2
dan: 2
dangerous: 2
daniel: 2
dast: 2
datasets: 2
datta: 2
days: 2
dbms: 2
dce: 2
dd: 2
deadlocks: 2
dealbook: 2
deceased: 2
decodes: 2
deduce: 2
deeper: 2
deeply: 2
defanti: 2
defects: 2
defer: 2
degradations: 2
degrading: 2
deleting: 2
deliberately: 2
deliberation: 2
delivering: 2
delta: 2
demanding: 2
dentical: 2
dependence: 2
depicted: 2
depicts: 2
deplist: 2
deplistcurr: 2
derive: 2
descriptor: 2
designing: 2
deterministically: 2
deviate: 2
devise: 2
dfreedman: 2
didn: 2
differentiable: 2
diminish: 2
dinosaur: 2
diot: 2
disabled: 2
disadvantage: 2
disadvantages: 2
discount: 2
disincentivize: 2
disrupting: 2
disseminates: 2
dissertation: 2
distances: 2
distinction: 2
diverse: 2
divide: 2
dividing: 2
doi: 2
dok: 2
dominate: 2
dot: 2
dotbit: 2
doubt: 2
downloaded: 2
downloads: 2
downside: 2
drives: 2
driving: 2
dry: 2
ds: 2
dubbed: 2
dugan: 2
dumbbell: 2
duplex: 2
duplicating: 2
dutta: 2
eagerly: 2
earned: 2
earnings: 2
ebling: 2
echo: 2
ecoop: 2
ecosystem: 2
eigenvalue: 2
eighteenth: 2
einar: 2
einstein: 2
elmore: 2
embeddings: 2
emphasis: 2
empirical: 2
enables: 2
encapsulate: 2
encapsulated: 2
encoders: 2
encounter: 2
encountered: 2
encrypted: 2
endhost: 2
ends: 2
ensemble: 2
ent: 2
enters: 2
envision: 2
equate: 2
equilibria: 2
era: 2
ered: 2
esbs: 2
escriva: 2
esign: 2
establishing: 2
estimates: 2
ethereum: 2
ethereumwhitepaper: 2
ets: 2
european: 2
eurosys: 2
ev: 2
eva: 2
eve: 2
eventbased: 2
everyone: 2
eviction: 2
evictions: 2
evolve: 2
exabytes: 2
exceeds: 2
exceptionally: 2
excessively: 2
executions: 2
exerted: 2
exerting: 2
exhibits: 2
expectation: 2
expectations: 2
expedite: 2
explains: 2
explores: 2
exponentially: 2
exports: 2
express: 2
expurging: 2
extensibility: 2
extremes: 2
eyes: 2
facilitate: 2
facto: 2
fair: 2
fall: 2
falling: 2
farms: 2
faulttolerance: 2
featuring: 2
fekete: 2
felser: 2
felten: 2
feng: 2
ferguson: 2
fetched: 2
fills: 2
finer: 2
finished: 2
finishes: 2
fired: 2
firewalling: 2
firoiu: 2
fits: 2
fix: 2
fl: 2
flag: 2
flexibly: 2
fluctuations: 2
fluid: 2
flushed: 2
fold: 2
forbes: 2
forcing: 2
forgo: 2
formats: 2
formulae: 2
forrestv: 2
forth: 2
foundations: 2
fox: 2
fragment: 2
fragments: 2
fraleigh: 2
frameworks: 2
fred: 2
fresh: 2
friction: 2
friedman: 2
friendliness: 2
frobenius: 2
fundamentally: 2
funded: 2
funds: 2
furman: 2
gained: 2
gaps: 2
garbled: 2
gateway: 2
gehrke: 2
generalize: 2
generations: 2
genesis: 2
geometric: 2
ghz: 2
gibbs: 2
gibson: 2
gigabyte: 2
github: 2
glick: 2
globalcrossing: 2
globe: 2
gossiper: 2
gossips: 2
gotten: 2
gr: 2
gradient: 2
gradually: 2
granted: 2
grapevine: 2
grasp: 2
greene: 2
griner: 2
guerraoui: 2
guesses: 2
guessing: 2
gupta: 2
guruprasad: 2
habel: 2
hackers: 2
halfway: 2
halted: 2
handful: 2
hands: 2
happens: 2
harder: 2
harley: 2
harm: 2
hashrate: 2
headers: 2
healthy: 2
heidelberg: 2
height: 2
held: 2
helpful: 2
hereinafter: 2
heterogenous: 2
hey: 2
hibler: 2
hiccups: 2
hides: 2
highlight: 2
highvalue: 2
hinder: 2
histogram: 2
hits: 2
hoarding: 2
hobor: 2
holy: 2
homepage: 2
honesty: 2
honeyman: 2
hops: 2
hotcloud: 2
huitema: 2
hundred: 2
hungry: 2
hurdle: 2
hurwitz: 2
huston: 2
iacr: 2
ic: 2
iciw: 2
icmp: 2
identities: 2
idit: 2
ie: 2
ifip: 2
ih: 2
ij: 2
ill: 2
illinois: 2
im: 2
imagined: 2
immaterial: 2
immediate: 2
immersion: 2
imperatives: 2
imperfect: 2
imply: 2
imposing: 2
impractical: 2
impulse: 2
incorporation: 2
indices: 2
indirection: 2
inefficiency: 2
inefficient: 2
infer: 2
influence: 2
influenced: 2
infrastructures: 2
ingrid: 2
ings: 2
inherent: 2
ining: 2
initialized: 2
initiates: 2
injecting: 2
insertion: 2
inspect: 2
install: 2
installed: 2
instantiated: 2
institutions: 2
instruction: 2
instructs: 2
integer: 2
intentionally: 2
interconnecting: 2
interconnection: 2
interconnects: 2
interix: 2
intermediary: 2
interpret: 2
intersection: 2
intervention: 2
intimate: 2
intricacies: 2
invalid: 2
investment: 2
invoke: 2
invokes: 2
ipdps: 2
iptps: 2
irish: 2
iscussion: 2
island: 2
italy: 2
itcoin: 2
ith: 2
ity: 2
izs: 2
james: 2
javabeans: 2
jimenez: 2
joglekar: 2
jonsson: 2
jsp: 2
juels: 2
justify: 2
kandemir: 2
kansas: 2
kapritsos: 2
karlsson: 2
katabi: 2
kazar: 2
kemme: 2
keycurr: 2
kharif: 2
kiawah: 2
kilper: 2
kim: 2
kimsas: 2
kjkj: 2
knob: 2
knobs: 2
kojo: 2
kroll: 2
krzys: 2
kurose: 2
labelled: 2
labs: 2
lagged: 2
lagging: 2
lake: 2
lambdarail: 2
lambdas: 2
landing: 2
landolsi: 2
laptop: 2
lastly: 2
lastop: 2
launching: 2
laying: 2
le: 2
lease: 2
legitimate: 2
leigh: 2
lepreau: 2
leskovec: 2
leslie: 2
leverages: 2
levy: 2
lightly: 2
lightwave: 2
likewise: 2
lin: 2
liskov: 2
literally: 2
literature: 2
lm: 2
locate: 2
lockstep: 2
longest: 2
longhaul: 2
loops: 2
loosely: 2
louise: 2
lowering: 2
lowers: 2
lows: 2
ltd: 2
luck: 2
lundqvist: 2
lynch: 2
lyon: 2
madden: 2
madhow: 2
magharei: 2
mance: 2
mandatory: 2
mangling: 2
manifested: 2
manipulate: 2
manually: 2
march: 2
marshaling: 2
martinez: 2
matrices: 2
matthews: 2
mature: 2
maximal: 2
maximized: 2
maya: 2
md: 2
mdcc: 2
meant: 2
megabits: 2
memoryless: 2
menees: 2
metacdn: 2
micro: 2
microsystems: 2
migrating: 2
milestone: 2
mined: 2
minimising: 2
minimizes: 2
minus: 2
mirroring: 2
miscalculate: 2
mismatched: 2
mistakenly: 2
mit: 2
mitigated: 2
mitigation: 2
mlml: 2
modem: 2
moderately: 2
modest: 2
modulo: 2
mohr: 2
montenegro: 2
monterey: 2
moshe: 2
mrc: 2
mst: 2
multigrep: 2
multiples: 2
multiplied: 2
multithreading: 2
muri: 2
muthitacharoen: 2
myriad: 2
nakamoto: 2
named: 2
names: 2
naming: 2
nandi: 2
narayanan: 2
naughton: 2
navathe: 2
ncsa: 2
ne: 2
nec: 2
needham: 2
negation: 2
neil: 2
nejdl: 2
newbold: 2
newer: 2
newly: 2
ngan: 2
nic: 2
nichols: 2
nishtala: 2
nity: 2
nlanr: 2
nonequilibrium: 2
nonnenmacher: 2
nontransactional: 2
normalization: 2
normalize: 2
normalizing: 2
normed: 2
notably: 2
notes: 2
notifies: 2
notifying: 2
noting: 2
nutshell: 2
nytimes: 2
obsolete: 2
obviously: 2
occasion: 2
occupies: 2
odd: 2
offices: 2
ofwork: 2
ole: 2
olympics: 2
omi: 2
omits: 2
ool: 2
ooled: 2
op: 2
opacity: 2
opening: 2
operated: 2
opportunities: 2
opt: 2
opted: 2
ordinarily: 2
organizational: 2
organizing: 2
originate: 2
orities: 2
oscillates: 2
ostar: 2
ourselves: 2
outages: 2
outs: 2
outsource: 2
outsources: 2
overcast: 2
overflow: 2
overlays: 2
overqos: 2
pairings: 2
pam: 2
panacea: 2
par: 2
paradigms: 2
parameshwaran: 2
parameterizations: 2
parametrized: 2
parity: 2
park: 2
parno: 2
pass: 2
pathway: 2
patterson: 2
payloads: 2
paypal: 2
pcb: 2
pdcs: 2
pdfs: 2
penalised: 2
pentium: 2
peration: 2
perfor: 2
peris: 2
permits: 2
permitted: 2
perpetrators: 2
perron: 2
petersen: 2
ph: 2
phanishayee: 2
phases: 2
physically: 2
picture: 2
piggybacked: 2
piling: 2
pipeline: 2
pipelines: 2
pitfalls: 2
plague: 2
plays: 2
plication: 2
plugged: 2
plugging: 2
poolattacks: 2
popper: 2
port: 2
porto: 2
ports: 2
poses: 2
position: 2
powersaving: 2
pplive: 2
practically: 2
preceding: 2
precise: 2
precludes: 2
predecessor: 2
predefined: 2
predetermined: 2
predictive: 2
predicts: 2
preferable: 2
prefers: 2
preiss: 2
preliminary: 2
premise: 2
presenting: 2
preservation: 2
preserve: 2
preserving: 2
prevail: 2
prevention: 2
primitive: 2
prioritising: 2
prioritization: 2
prioritize: 2
prioritizing: 2
privately: 2
probabilistically: 2
probe: 2
problematic: 2
processors: 2
produces: 2
professor: 2
profile: 2
profiler: 2
profit: 2
projection: 2
promote: 2
proper: 2
proposals: 2
pros: 2
proving: 2
pseudo: 2
pullbased: 2
pulling: 2
pulse: 2
purchase: 2
purchasing: 2
pure: 2
pursue: 2
pushes: 2
pvldb: 2
qhuang: 2
qin: 2
qmi: 2
qos: 2
quasistatic: 2
quicksilver: 2
quote: 2
race: 2
racticalities: 2
radc: 2
radical: 2
radio: 2
raised: 2
ramakrishnan: 2
ramamritham: 2
randomness: 2
ranges: 2
rank: 2
rateless: 2
rational: 2
ratios: 2
reacts: 2
readily: 2
ready: 2
realizes: 2
rears: 2
reasonably: 2
reception: 2
reciprocation: 2
recognition: 2
recompute: 2
reconciliation: 2
recycling: 2
redesigned: 2
redesigning: 2
reductions: 2
referred: 2
refraining: 2
refreshed: 2
regard: 2
registration: 2
reimplemented: 2
reissue: 2
reissued: 2
rejaie: 2
rejected: 2
rejecting: 2
rejects: 2
relaxed: 2
relay: 2
relevance: 2
relied: 2
relies: 2
reliminaries: 2
relying: 2
remarks: 2
remotely: 2
removes: 2
rendering: 2
rep: 2
repaired: 2
repeatable: 2
repetitions: 2
reporting: 2
repurposing: 2
reputation: 2
requisite: 2
resending: 2
resends: 2
reserves: 2
resident: 2
resolutions: 2
respecting: 2
responsive: 2
restarted: 2
retaliate: 2
retried: 2
retries: 2
reverse: 2
reviewers: 2
revisiting: 2
rewarded: 2
rewritten: 2
reykjavik: 2
reynolds: 2
ricci: 2
rightful: 2
rigid: 2
rigorous: 2
rigorously: 2
rimon: 2
rising: 2
rivalry: 2
roberts: 2
rohrs: 2
rome: 2
roots: 2
rose: 2
rosenblum: 2
ross: 2
rounding: 2
routinely: 2
row: 2
rp: 2
rsized: 2
rt: 2
rtts: 2
ruling: 2
runners: 2
rvr: 2
sabul: 2
safe: 2
saha: 2
said: 2
sake: 2
sales: 2
satellite: 2
saxena: 2
scans: 2
scatter: 2
scattered: 2
scheduler: 2
schedules: 2
sci: 2
scientist: 2
scratch: 2
scsi: 2
seamless: 2
secondgeneration: 2
seda: 2
seeking: 2
seemingly: 2
seldom: 2
seltzer: 2
seminar: 2
senior: 2
sensible: 2
sept: 2
serial: 2
serialize: 2
serially: 2
serious: 2
serverlets: 2
serverpull: 2
settle: 2
shape: 2
shapley: 2
sharp: 2
sheds: 2
shelby: 2
shell: 2
shi: 2
shieh: 2
shifts: 2
shokrollahi: 2
shortcut: 2
shortly: 2
sidebotham: 2
sigact: 2
signs: 2
sigops: 2
sigurbjornsson: 2
silicon: 2
silverlight: 2
simplification: 2
simplified: 2
simulating: 2
singh: 2
sinks: 2
sister: 2
sivakumar: 2
slashdot: 2
slashes: 2
slows: 2
slush: 2
smooth: 2
soar: 2
soars: 2
soas: 2
societies: 2
society: 2
solaris: 2
solely: 2
solheim: 2
solid: 2
solved: 2
something: 2
son: 2
sonic: 2
sons: 2
soper: 2
sourceforge: 2
south: 2
sovran: 2
specialists: 2
speedups: 2
spend: 2
spending: 2
splits: 2
spreads: 2
spreitzer: 2
srs: 2
st: 2
stabilizes: 2
staggering: 2
standalone: 2
stands: 2
stat: 2
statement: 2
station: 2
statqwest: 2
stats: 2
steal: 2
stefan: 2
stephen: 2
stocks: 2
stoller: 2
stops: 2
stories: 2
storms: 2
story: 2
stripe: 2
striping: 2
sturgis: 2
styles: 2
su: 2
subgroup: 2
submits: 2
submitted: 2
submitting: 2
subscribed: 2
subversive: 2
subverted: 2
succession: 2
successively: 2
sudden: 2
suffice: 2
suggest: 2
suggestions: 2
suited: 2
summation: 2
sundr: 2
supergame: 2
supergames: 2
supervisors: 2
supply: 2
suppose: 2
sure: 2
surpass: 2
surprise: 2
survey: 2
susceptibility: 2
suspect: 2
sustain: 2
swallow: 2
swanson: 2
swapping: 2
swift: 2
swinehart: 2
swiss: 2
sybil: 2
synchronize: 2
synthesis: 2
systematic: 2
systemic: 2
tablets: 2
tagged: 2
tailer: 2
tandard: 2
tango: 2
tardos: 2
tation: 2
tauber: 2
tc: 2
technically: 2
tempted: 2
tend: 2
termed: 2
testbed: 2
tgperf: 2
theimer: 2
thick: 2
thing: 2
thirtieth: 2
thumb: 2
tiered: 2
ties: 2
tional: 2
tions: 2
tirumala: 2
toappliance: 2
tock: 2
tods: 2
tolerates: 2
tolerating: 2
topeer: 2
topologically: 2
totally: 2
touch: 2
touches: 2
toueg: 2
tough: 2
toy: 2
tp: 2
tracing: 2
tracked: 2
trades: 2
tragedy: 2
tranmission: 2
transact: 2
transcoded: 2
transforming: 2
trapezoids: 2
treatment: 2
tremel: 2
triangular: 2
tricky: 2
tries: 2
trivially: 2
trol: 2
trsu: 2
trustworthy: 2
tuft: 2
tuned: 2
tv: 2
twentieth: 2
twofold: 2
ugly: 2
umich: 2
un: 2
unaltered: 2
unattacked: 2
unattractive: 2
uncommitable: 2
uncommitted: 2
unexplored: 2
unfavorable: 2
uninvolved: 2
uniquely: 2
united: 2
unlucky: 2
unnecessarily: 2
unnecessary: 2
unreachable: 2
unresponsive: 2
uploading: 2
urgent: 2
userspace: 2
validating: 2
vancouver: 2
vandermeer: 2
vandermonde: 2
vasek: 2
vcurr: 2
vein: 2
venkataramani: 2
ver: 2
verby: 2
versioned: 2
vicinity: 2
viewers: 2
violations: 2
virtualized: 2
visibility: 2
visited: 2
vko: 2
volumes: 2
vpn: 2
wakeup: 2
walks: 2
wallace: 2
war: 2
warehouse: 2
warship: 2
watching: 2
wattenhofer: 2
weakens: 2
weaker: 2
weaknesses: 2
websphere: 2
welch: 2
wesley: 2
west: 2
whereby: 2
whom: 2
wicker: 2
wider: 2
width: 2
wiley: 2
williams: 2
willing: 2
willner: 2
winter: 2
withholds: 2
witnessed: 2
wizkid: 2
wlog: 2
wo: 2
wolfgang: 2
wong: 2
words: 2
workflow: 2
worsening: 2
wrapping: 2
wrongdoing: 2
wvwv: 2
xie: 2
xored: 2
xp: 2
xth: 2
yang: 2
ymir: 2
yxxy: 2
zoom: 2
aaron: 1
abbreviations: 1
abilalso: 1
absorbs: 1
abstracts: 1
abu: 1
accompanied: 1
accomplish: 1
accomplishing: 1
accounted: 1
accumulate: 1
aceves: 1
acheive: 1
acheived: 1
acls: 1
acmula: 1
acomplish: 1
acquires: 1
acquiring: 1
acthe: 1
activated: 1
actuators: 1
acwe: 1
adamic: 1
adaptable: 1
adapted: 1
adaptively: 1
adaptivity: 1
addi: 1
addiserver: 1
additive: 1
addressable: 1
adelaide: 1
adhere: 1
adjacent: 1
administers: 1
admit: 1
admits: 1
adoption: 1
ads: 1
advertise: 1
advertised: 1
adya: 1
aelstrom: 1
aerospace: 1
af: 1
affirmative: 1
afford: 1
afforded: 1
afraid: 1
afterward: 1
agenda: 1
agent: 1
ager: 1
aggregat: 1
aggregrate: 1
aggressively: 1
aggressiveness: 1
agreements: 1
ahnn: 1
aid: 1
aims: 1
airplane: 1
ak: 1
akkus: 1
alarms: 1
albatross: 1
albrecht: 1
alegre: 1
alexander: 1
alfetching: 1
allavena: 1
allegedly: 1
alleviated: 1
alleviates: 1
allo: 1
alloc: 1
allocations: 1
allthingsdistributed: 1
alof: 1
alpha: 1
altogether: 1
altrustic: 1
am: 1
amar: 1
ambitious: 1
america: 1
amortized: 1
ample: 1
amplify: 1
amsden: 1
analogy: 1
analyse: 1
analyst: 1
analytics: 1
ance: 1
anceaume: 1
anddrop: 1
andersen: 1
andre: 1
andreas: 1
ann: 1
anne: 1
annie: 1
annotated: 1
announce: 1
announcement: 1
announces: 1
annoyingly: 1
annually: 1
anonymous: 1
answered: 1
answers: 1
anticipated: 1
antipolis: 1
antonio: 1
anytime: 1
anyway: 1
anywhere: 1
ap: 1
apa: 1
appeal: 1
appendix: 1
applaud: 1
appleton: 1
appli: 1
applicationdropped: 1
appliit: 1
applior: 1
applithe: 1
approaching: 1
approximates: 1
apps: 1
apthe: 1
arbor: 1
architects: 1
archival: 1
archives: 1
argus: 1
arisen: 1
armies: 1
arranging: 1
arrivals: 1
artifact: 1
artificial: 1
ase: 1
aside: 1
ask: 1
asking: 1
assembling: 1
assist: 1
assisted: 1
associates: 1
associating: 1
astrolabe: 1
aswhen: 1
asynbandwidth: 1
asynchrony: 1
asynmicrobenchmarks: 1
asynmobile: 1
asynqueue: 1
ata: 1
atomically: 1
atr: 1
att: 1
attaches: 1
attaching: 1
attar: 1
attention: 1
attr: 1
attracted: 1
attributable: 1
attributed: 1
atypical: 1
audit: 1
audits: 1
australia: 1
authoritative: 1
authorized: 1
autodesk: 1
automation: 1
autotion: 1
autowriteback: 1
autumn: 1
ava: 1
availto: 1
avatar: 1
awaiting: 1
awareness: 1
axes: 1
azim: 1
backgound: 1
backgrounds: 1
backlog: 1
backlogs: 1
backnt: 1
backups: 1
bakalova: 1
balancers: 1
ballance: 1
ballot: 1
banaei: 1
bandcontain: 1
bandhowever: 1
bandwhile: 1
bandwidthdelay: 1
bandwidthsensitive: 1
banff: 1
barcelona: 1
bare: 1
barracuda: 1
barriers: 1
baseline: 1
bastion: 1
batched: 1
batches: 1
batching: 1
batkin: 1
battle: 1
battlefield: 1
battleground: 1
bayeux: 1
bcc: 1
bcq: 1
became: 1
befriended: 1
behren: 1
beijing: 1
belief: 1
believed: 1
beloved: 1
benchmarking: 1
benchmarks: 1
benenational: 1
benoit: 1
bered: 1
berkeleydb: 1
bernd: 1
bershad: 1
bership: 1
bert: 1
bertier: 1
bhattacharjee: 1
biggest: 1
bile: 1
bill: 1
billed: 1
billing: 1
bills: 1
bindel: 1
binds: 1
bio: 1
bitcoinmines: 1
bk: 1
blades: 1
blame: 1
ble: 1
bleeding: 1
blending: 1
blogs: 1
boa: 1
board: 1
body: 1
bold: 1
bologna: 1
bond: 1
bonding: 1
bonn: 1
book: 1
boosting: 1
boot: 1
borisov: 1
bortnikov: 1
boss: 1
bostic: 1
bother: 1
bottlenecks: 1
bought: 1
boundary: 1
bounds: 1
boys: 1
bq: 1
br: 1
brahms: 1
brazil: 1
breakthrough: 1
bregni: 1
breslau: 1
brian: 1
bridging: 1
bright: 1
british: 1
broad: 1
broberg: 1
brokers: 1
brought: 1
bruno: 1
budget: 1
budgets: 1
buffercould: 1
bug: 1
buggy: 1
bugs: 1
builders: 1
burdens: 1
bureau: 1
burgess: 1
buried: 1
burrows: 1
busnel: 1
button: 1
buyer: 1
buying: 1
buys: 1
cabrera: 1
cacheable: 1
cacheserializability: 1
caise: 1
cal: 1
calability: 1
camargos: 1
cameras: 1
cancelled: 1
candidate: 1
cannes: 1
cantwell: 1
capability: 1
cappuccino: 1
captured: 1
caratti: 1
carded: 1
cardinality: 1
cardoso: 1
career: 1
careers: 1
careful: 1
caribbean: 1
carl: 1
carried: 1
carrier: 1
carrying: 1
cart: 1
carzaniga: 1
cas: 1
cascades: 1
cast: 1
castor: 1
catalog: 1
catastrophe: 1
catastrophic: 1
cated: 1
categorized: 1
cations: 1
causal: 1
cbb: 1
cbbc: 1
cbqpcb: 1
ccb: 1
ccdf: 1
cdf: 1
cdrom: 1
ceives: 1
cell: 1
centered: 1
ceremony: 1
certify: 1
certifying: 1
cess: 1
chained: 1
chainlink: 1
chair: 1
chakka: 1
chakravorty: 1
challenger: 1
chang: 1
changtao: 1
chapman: 1
characterised: 1
chawathe: 1
cheat: 1
checkouts: 1
chenchu: 1
cheslack: 1
chicken: 1
chiefly: 1
chien: 1
chinese: 1
ching: 1
chockler: 1
choke: 1
chose: 1
chow: 1
christened: 1
christmas: 1
chronously: 1
chrony: 1
chu: 1
chuck: 1
chunk: 1
chunks: 1
cincilla: 1
circuitous: 1
circulation: 1
circumvented: 1
circumvents: 1
citation: 1
cites: 1
cities: 1
clara: 1
clarity: 1
cleaned: 1
cleanly: 1
clearer: 1
clements: 1
clientserver: 1
clocks: 1
clone: 1
closest: 1
cloudifying: 1
clutter: 1
cmu: 1
codaniques: 1
coded: 1
coding: 1
coexistence: 1
coexists: 1
coherency: 1
coincide: 1
collaborate: 1
collaborating: 1
collapsing: 1
collateral: 1
collects: 1
collusions: 1
columbia: 1
comings: 1
comitting: 1
comm: 1
commatic: 1
commence: 1
commences: 1
commentary: 1
commenting: 1
commercially: 1
commonplace: 1
communal: 1
communi: 1
commutative: 1
comp: 1
compact: 1
comparably: 1
comparaour: 1
comparative: 1
comparisons: 1
compelling: 1
compensating: 1
competitors: 1
compiler: 1
complementary: 1
complementing: 1
complexities: 1
complimentary: 1
comply: 1
compositional: 1
compressed: 1
compresses: 1
comprising: 1
compromises: 1
compromising: 1
computationally: 1
computfits: 1
comsium: 1
concentrates: 1
concentration: 1
conception: 1
conceptually: 1
concludes: 1
concrete: 1
concurby: 1
concuruses: 1
conditioned: 1
conext: 1
configure: 1
conform: 1
conios: 1
conitbased: 1
conjecture: 1
connec: 1
connectionless: 1
conner: 1
consequent: 1
conserving: 1
consisted: 1
consisupdate: 1
consortium: 1
constantly: 1
constituent: 1
constrain: 1
constructs: 1
consulting: 1
consumer: 1
consumers: 1
contacting: 1
contally: 1
contemplate: 1
contemplated: 1
contemplating: 1
contending: 1
conthe: 1
contingencies: 1
contolerate: 1
contractors: 1
contravention: 1
contributes: 1
controller: 1
controversy: 1
convenience: 1
convention: 1
converged: 1
converging: 1
conversely: 1
converts: 1
conveyed: 1
convoys: 1
cooperating: 1
coordinated: 1
coordinating: 1
coordinators: 1
copied: 1
coping: 1
cops: 1
cornelldeveloped: 1
corr: 1
corrected: 1
corrections: 1
correspondingly: 1
corroborated: 1
corrupted: 1
cotton: 1
counters: 1
counting: 1
couple: 1
crashing: 1
crawl: 1
credit: 1
credo: 1
crete: 1
crippling: 1
criteria: 1
critically: 1
crossroads: 1
crowcroft: 1
csd: 1
cstr: 1
culled: 1
cumulatively: 1
customised: 1
customizability: 1
customizable: 1
customization: 1
customizing: 1
customuserserviceapp: 1
cutler: 1
cuts: 1
cybercaf: 1
cyrus: 1
czerwinski: 1
dallas: 1
danielsson: 1
danilov: 1
dantzig: 1
dat: 1
datagrams: 1
dataset: 1
datastores: 1
daunting: 1
dave: 1
davoli: 1
dazzling: 1
dc: 1
dead: 1
deadlock: 1
deadly: 1
deadtially: 1
dean: 1
debatable: 1
debate: 1
debated: 1
debilitating: 1
debris: 1
debugger: 1
declare: 1
declaring: 1
declines: 1
decode: 1
decoder: 1
decoding: 1
decoupled: 1
decouples: 1
decreased: 1
defend: 1
deferplications: 1
deferrable: 1
defers: 1
defgh: 1
defining: 1
definitions: 1
degrees: 1
deit: 1
delegation: 1
delete: 1
deleted: 1
delivers: 1
demanded: 1
demise: 1
demonstration: 1
denning: 1
dennis: 1
denoting: 1
dep: 1
depart: 1
departments: 1
dependalso: 1
dependenrate: 1
depsa: 1
depth: 1
dequeued: 1
der: 1
dered: 1
deregistered: 1
derivative: 1
derivatives: 1
derives: 1
deriving: 1
des: 1
descending: 1
deserver: 1
deshow: 1
designated: 1
designating: 1
designer: 1
desirability: 1
desirable: 1
desktops: 1
destabilize: 1
destinations: 1
detailing: 1
deterioration: 1
determinants: 1
detrimental: 1
dev: 1
developerhours: 1
deviations: 1
devised: 1
devlin: 1
devoted: 1
devoting: 1
dewitt: 1
dexa: 1
dhs: 1
dht: 1
diamond: 1
dictionaries: 1
diego: 1
dies: 1
differany: 1
differential: 1
differentiates: 1
differentiating: 1
differenwith: 1
differing: 1
diffs: 1
dimensions: 1
dimov: 1
ding: 1
directing: 1
directs: 1
disable: 1
disables: 1
disappearance: 1
disappeared: 1
disastrous: 1
disbut: 1
discard: 1
disconnections: 1
disconnects: 1
discontinuing: 1
discotheque: 1
discounts: 1
discovered: 1
discusses: 1
discussing: 1
disguise: 1
disinclined: 1
disjoing: 1
dislike: 1
dismiss: 1
dispatch: 1
dispatcher: 1
dispatching: 1
displayed: 1
displaying: 1
displays: 1
dispools: 1
disregarded: 1
dissatisfied: 1
disseminating: 1
distill: 1
distorted: 1
diverges: 1
diversion: 1
diversity: 1
dll: 1
dlls: 1
documented: 1
dol: 1
domains: 1
dominating: 1
donet: 1
door: 1
dou: 1
doubled: 1
douceur: 1
doug: 1
downgraded: 1
downtime: 1
dozen: 1
dr: 1
drain: 1
drained: 1
drawbacks: 1
drawing: 1
draws: 1
drift: 1
drifting: 1
drive: 1
drivers: 1
drone: 1
duals: 1
ducing: 1
dummynet: 1
dundant: 1
dunn: 1
duplicates: 1
dur: 1
durably: 1
durations: 1
dwarf: 1
dx: 1
dynamics: 1
ear: 1
eastham: 1
economies: 1
ecution: 1
edd: 1
edges: 1
edit: 1
editors: 1
edits: 1
eds: 1
eduardo: 1
educational: 1
edutella: 1
eed: 1
efficacies: 1
eg: 1
egemen: 1
egg: 1
ekin: 1
elasticity: 1
elect: 1
electric: 1
electricity: 1
electronics: 1
eleventh: 1
eliability: 1
elicit: 1
eliciting: 1
elkin: 1
embark: 1
embody: 1
embrace: 1
embraces: 1
emerged: 1
emerges: 1
emitting: 1
emmanuelle: 1
empted: 1
emto: 1
emulating: 1
encapsulates: 1
encod: 1
encode: 1
encompass: 1
encourages: 1
encrypt: 1
encrypts: 1
endeavor: 1
endowment: 1
endpoints: 1
endtransaction: 1
endtransport: 1
enemy: 1
enforced: 1
engine: 1
engineers: 1
enlarge: 1
enlarges: 1
enlarging: 1
enputing: 1
entail: 1
entering: 1
entitled: 1
entropy: 1
enumerate: 1
episodes: 1
epositories: 1
epstein: 1
equeation: 1
equipped: 1
erally: 1
erates: 1
erent: 1
ering: 1
erodes: 1
erred: 1
errorprone: 1
ery: 1
eschewing: 1
esprit: 1
establish: 1
establishes: 1
etup: 1
eugster: 1
evalappended: 1
eventoriented: 1
everyday: 1
everywhere: 1
evocative: 1
evolves: 1
evolving: 1
exacerbating: 1
exaggerated: 1
examined: 1
excellently: 1
excess: 1
exchanging: 1
excitement: 1
exclusively: 1
exec: 1
execusystem: 1
executable: 1
exemplifies: 1
exercise: 1
exhibitthe: 1
existed: 1
exited: 1
exiting: 1
expects: 1
expedited: 1
expense: 1
experiencing: 1
expert: 1
expire: 1
explanation: 1
explanatory: 1
exploits: 1
exponentiated: 1
exporting: 1
expose: 1
exposition: 1
expunged: 1
expurge: 1
exsmart: 1
exspecified: 1
extending: 1
extensible: 1
extensively: 1
extracting: 1
extracts: 1
facilitates: 1
facilitating: 1
facing: 1
factory: 1
failing: 1
failuredetectio: 1
failwhen: 1
faithful: 1
faloutsos: 1
falsely: 1
faltered: 1
famous: 1
farber: 1
farewell: 1
farm: 1
farnoush: 1
farther: 1
fascination: 1
fashioned: 1
fastest: 1
featured: 1
federal: 1
federica: 1
feel: 1
feels: 1
feet: 1
feldman: 1
fell: 1
fellow: 1
fellowship: 1
felt: 1
ferred: 1
ferris: 1
ffs: 1
fic: 1
fidelity: 1
fifteen: 1
figured: 1
fikes: 1
filing: 1
filled: 1
films: 1
filtered: 1
filters: 1
finance: 1
findings: 1
finegrained: 1
finergrained: 1
finish: 1
fiorano: 1
firewall: 1
firms: 1
fisher: 1
fitted: 1
fitting: 1
fixes: 1
flavors: 1
flaws: 1
flickr: 1
flood: 1
flooding: 1
fluctuating: 1
fluke: 1
flushing: 1
fly: 1
focs: 1
football: 1
forcibly: 1
forecast: 1
foregoing: 1
foremost: 1
foresee: 1
forgoing: 1
fork: 1
forked: 1
formal: 1
formally: 1
formed: 1
formerly: 1
fort: 1
fortune: 1
forwards: 1
founder: 1
fractions: 1
franke: 1
frans: 1
freed: 1
freenix: 1
freeze: 1
freshness: 1
fricano: 1
friends: 1
friendship: 1
frightening: 1
frontend: 1
frost: 1
ftcs: 1
fugal: 1
fulfilling: 1
fulfillment: 1
functional: 1
fund: 1
funding: 1
furniture: 1
furthest: 1
gabit: 1
gabriel: 1
gallager: 1
garbinato: 1
garcia: 1
gates: 1
gathering: 1
gauge: 1
gauthier: 1
gave: 1
gb: 1
gbit: 1
gcheap: 1
geambasu: 1
generalized: 1
genercache: 1
generous: 1
geneva: 1
genit: 1
genuinely: 1
geodistributed: 1
geoff: 1
geoffrey: 1
gershinsky: 1
gestion: 1
getting: 1
ghemawat: 1
gi: 1
gian: 1
giardullo: 1
gifford: 1
gilbert: 1
ginting: 1
ginza: 1
gis: 1
gist: 1
giving: 1
glade: 1
glance: 1
glitches: 1
globalized: 1
globecom: 1
goel: 1
gold: 1
goldberg: 1
googles: 1
gov: 1
governed: 1
governmental: 1
grade: 1
gradual: 1
grande: 1
granting: 1
granularity: 1
graphical: 1
grc: 1
gree: 1
greece: 1
grepwe: 1
griffioen: 1
grimm: 1
grips: 1
grochowski: 1
grounds: 1
groundwork: 1
grove: 1
gruber: 1
grunwald: 1
guadelope: 1
gubarev: 1
guha: 1
guis: 1
gunnar: 1
gunnars: 1
gurevich: 1
gurus: 1
guy: 1
guyadec: 1
hacked: 1
hacking: 1
hadoop: 1
haifa: 1
halem: 1
halt: 1
halts: 1
halves: 1
hampering: 1
hanan: 1
handing: 1
handled: 1
handler: 1
handoff: 1
handurukande: 1
hang: 1
hansell: 1
happened: 1
haridasan: 1
haridasana: 1
harmful: 1
harnessing: 1
harpaz: 1
hartman: 1
harwood: 1
hasn: 1
hawaii: 1
hazard: 1
hazards: 1
headquarters: 1
heard: 1
heart: 1
heartbeatmonitor: 1
heat: 1
heavyweight: 1
hegde: 1
hegedu: 1
heidemann: 1
heiser: 1
helen: 1
hellerstein: 1
helped: 1
henceforth: 1
her: 1
herein: 1
hersonissos: 1
hesitate: 1
heterogeneity: 1
heuristic: 1
heuristics: 1
hiding: 1
highassurance: 1
highbandwidth: 1
highbut: 1
highlights: 1
highlyavailable: 1
highpower: 1
highquality: 1
hik: 1
hill: 1
him: 1
himself: 1
hisgen: 1
hjelm: 1
hochschild: 1
holbrook: 1
holder: 1
holding: 1
holte: 1
homes: 1
homomorphic: 1
honolulu: 1
honored: 1
hoon: 1
hopcroft: 1
hoping: 1
horizontal: 1
horn: 1
horrible: 1
hospital: 1
hotice: 1
hotly: 1
hotnets: 1
hotzone: 1
hours: 1
howa: 1
hpca: 1
hreshold: 1
hrs: 1
hsieh: 1
htm: 1
hu: 1
huazhong: 1
huberman: 1
hungary: 1
hurricane: 1
hurting: 1
hyder: 1
hyper: 1
ically: 1
icccn: 1
iceland: 1
icomp: 1
icons: 1
icpads: 1
icsoc: 1
idempotence: 1
iden: 1
idenhigh: 1
identically: 1
idigest: 1
ied: 1
igniting: 1
ignorance: 1
ihkj: 1
iis: 1
ilability: 1
illegal: 1
illusion: 1
imaginable: 1
imation: 1
imc: 1
imlocal: 1
immature: 1
immersive: 1
impacts: 1
implememted: 1
implemenfrom: 1
implemenshared: 1
implementapackages: 1
implosion: 1
implying: 1
import: 1
imported: 1
imporwriteback: 1
imposition: 1
impossibility: 1
imprecise: 1
impressive: 1
improv: 1
inadequacy: 1
inadequate: 1
inadequately: 1
inapplicable: 1
inappropriate: 1
inbound: 1
incentivize: 1
inception: 1
inclusive: 1
incompatible: 1
incomplete: 1
incon: 1
inconsisto: 1
incorpoas: 1
increasess: 1
incredibly: 1
incrementing: 1
indefinitely: 1
independence: 1
indexing: 1
indicators: 1
indictment: 1
indirect: 1
indirectly: 1
indispensable: 1
individinterference: 1
individuals: 1
indranil: 1
induced: 1
industrystandard: 1
inefficiencies: 1
inevitable: 1
inexpennet: 1
inf: 1
infect: 1
infected: 1
infection: 1
infectious: 1
inference: 1
inferred: 1
inflate: 1
inflexibility: 1
inflight: 1
informa: 1
informatics: 1
informing: 1
informs: 1
infrequent: 1
infused: 1
inherited: 1
inhibit: 1
inhibiting: 1
inicontention: 1
initialised: 1
initialize: 1
initiating: 1
initiation: 1
inject: 1
injects: 1
inner: 1
innetwork: 1
innotice: 1
innovate: 1
inprocess: 1
inputs: 1
insecure: 1
insensitive: 1
inseparable: 1
inserted: 1
inserts: 1
inspection: 1
inspired: 1
instruct: 1
instructed: 1
instructing: 1
instructions: 1
instrument: 1
instrumented: 1
instrumenting: 1
int: 1
integers: 1
integrity: 1
intellection: 1
intellectual: 1
intelligence: 1
intem: 1
intense: 1
intensity: 1
intention: 1
intentions: 1
interadditional: 1
intercluster: 1
interdependence: 1
interests: 1
interfere: 1
interferes: 1
interject: 1
interlinked: 1
intermittent: 1
intermittently: 1
internally: 1
internships: 1
interoriginally: 1
interpreted: 1
interpreting: 1
interprocess: 1
interrogates: 1
interrupt: 1
interrupts: 1
interspersed: 1
intervenallows: 1
intra: 1
intractable: 1
intrapartition: 1
intrusion: 1
intrusions: 1
intuitively: 1
invaluable: 1
invariant: 1
invest: 1
investigations: 1
invisible: 1
invocation: 1
invocations: 1
involve: 1
involvement: 1
involving: 1
iperfthe: 1
ipto: 1
irections: 1
irregularity: 1
irregularly: 1
irrelevant: 1
irrespectively: 1
isca: 1
isola: 1
isolate: 1
isolated: 1
isolating: 1
israel: 1
istemi: 1
istva: 1
itcc: 1
items: 1
iterators: 1
ities: 1
itors: 1
iyengar: 1
jacobson: 1
jade: 1
jain: 1
janne: 1
jannotti: 1
jansch: 1
jared: 1
jari: 1
je: 1
jerian: 1
jesi: 1
jian: 1
jiang: 1
jin: 1
jini: 1
jit: 1
jiun: 1
jk: 1
jmc: 1
jms: 1
job: 1
jobs: 1
joined: 1
jones: 1
jong: 1
jorge: 1
jostling: 1
jr: 1
judicious: 1
julkunen: 1
jump: 1
jumpy: 1
juni: 1
junqueira: 1
justice: 1
justification: 1
kallman: 1
kalogeras: 1
kamilmani: 1
kaminsky: 1
kamra: 1
kanthak: 1
karamanolis: 1
karels: 1
karp: 1
kashani: 1
katti: 1
kay: 1
kde: 1
keidl: 1
keith: 1
keller: 1
kempe: 1
kent: 1
kerberos: 1
kernels: 1
kernilized: 1
kevin: 1
keyboard: 1
khan: 1
khorlin: 1
kib: 1
kick: 1
kicking: 1
kicks: 1
kid: 1
kilobyte: 1
kilobytes: 1
kirk: 1
kistler: 1
kit: 1
kk: 1
kleiman: 1
kliot: 1
kloc: 1
knights: 1
knowledgments: 1
kodali: 1
kogan: 1
korhonen: 1
koskela: 1
kostic: 1
kouznetsov: 1
kr: 1
kramer: 1
kraska: 1
krishnakumar: 1
krishnamurthy: 1
kristjan: 1
kristjanvj: 1
krohn: 1
kubiatowicz: 1
kulkarni: 1
kumar: 1
kupfer: 1
kwiatkowski: 1
la: 1
laboratories: 1
laboratory: 1
lacked: 1
ladis: 1
lafayette: 1
lag: 1
lags: 1
laid: 1
laing: 1
lamb: 1
land: 1
landlord: 1
lands: 1
landscapes: 1
lapping: 1
larry: 1
lasting: 1
lauderdale: 1
launch: 1
law: 1
lay: 1
layed: 1
layering: 1
lazy: 1
leaks: 1
learned: 1
learners: 1
leasing: 1
lecture: 1
led: 1
lee: 1
leff: 1
legends: 1
lenient: 1
lenz: 1
lesser: 1
lets: 1
lever: 1
levin: 1
libdeh: 1
liberal: 1
licensing: 1
lie: 1
lied: 1
lieu: 1
lighter: 1
likelihood: 1
limitation: 1
linden: 1
lindsay: 1
linearizable: 1
linger: 1
linkages: 1
lion: 1
listen: 1
listening: 1
littered: 1
liveness: 1
lives: 1
livestreaming: 1
livny: 1
lkjj: 1
ln: 1
lo: 1
localized: 1
localizes: 1
lockfree: 1
logarithmic: 1
logarithmically: 1
logics: 1
login: 1
logstructured: 1
lombard: 1
longput: 1
longrunning: 1
lookup: 1
loose: 1
loses: 1
loudifying: 1
louisiana: 1
lowand: 1
lowbandwidth: 1
lowerfile: 1
lowmfs: 1
lowney: 1
lowpower: 1
lpdc: 1
lr: 1
lugano: 1
luna: 1
luo: 1
lying: 1
lyles: 1
maarten: 1
mach: 1
macrobenchmarks: 1
maffeis: 1
magazine: 1
maglaris: 1
magnetic: 1
magnified: 1
magninetwork: 1
mahajan: 1
maheshwari: 1
mailing: 1
mailoth: 1
mainly: 1
mainteconsequently: 1
mak: 1
maki: 1
malloth: 1
man: 1
mandated: 1
mandreoli: 1
manipulates: 1
manm: 1
mann: 1
mao: 1
marandi: 1
marchukov: 1
marcon: 1
margo: 1
marie: 1
marin: 1
mario: 1
markoff: 1
markus: 1
marrying: 1
marshal: 1
martignon: 1
maryland: 1
marzullo: 1
mash: 1
mashing: 1
masking: 1
mass: 1
massachussetts: 1
matches: 1
materials: 1
matically: 1
matskin: 1
matt: 1
maxcontiguous: 1
maxim: 1
maximizing: 1
maymounkov: 1
mazieres: 1
mazon: 1
mbit: 1
mcauliffe: 1
mcelroy: 1
mckenney: 1
mea: 1
meaning: 1
meaningfully: 1
meantime: 1
mechacies: 1
medians: 1
mediarich: 1
mediately: 1
medical: 1
meet: 1
meetings: 1
megabytes: 1
megastore: 1
meirong: 1
melnik: 1
mem: 1
memcache: 1
memcopy: 1
memoryrelated: 1
men: 1
mendel: 1
menus: 1
mer: 1
merchant: 1
merging: 1
meta: 1
metaphor: 1
miami: 1
miao: 1
mib: 1
migrate: 1
mika: 1
mike: 1
mikhail: 1
mile: 1
milestones: 1
millions: 1
mimic: 1
mindset: 1
minh: 1
minimise: 1
minimised: 1
minimized: 1
minitransactions: 1
minjun: 1
minneapolis: 1
minnesota: 1
minobrowser: 1
mirrored: 1
mirrors: 1
misbehavior: 1
misfinally: 1
miskin: 1
mislove: 1
misra: 1
mistakes: 1
mitigates: 1
mitigating: 1
mitzenmacher: 1
mixes: 1
mmcn: 1
moderate: 1
modewell: 1
modularity: 1
mofavouring: 1
mohan: 1
moll: 1
moments: 1
monetary: 1
monin: 1
monnet: 1
mono: 1
monolithic: 1
monotonically: 1
moon: 1
morning: 1
morris: 1
mostlyreads: 1
motes: 1
motivating: 1
motivations: 1
mounted: 1
mouse: 1
movement: 1
mpi: 1
mplementation: 1
mscorwks: 1
msgs: 1
msiegen: 1
msn: 1
mts: 1
mulsequence: 1
multiframed: 1
multigigabit: 1
multiin: 1
multimedia: 1
multiplexing: 1
multispeed: 1
multitier: 1
multitude: 1
multiversioning: 1
multiwas: 1
multo: 1
mummert: 1
murderous: 1
music: 1
mutexes: 1
mvs: 1
mwaura: 1
na: 1
naaman: 1
nagle: 1
nahrstedt: 1
naively: 1
naks: 1
namespace: 1
nance: 1
napper: 1
narada: 1
nary: 1
nate: 1
nats: 1
naval: 1
navigate: 1
navy: 1
nawab: 1
nca: 1
ndi: 1
neatly: 1
necessity: 1
needing: 1
needless: 1
needlessly: 1
negative: 1
negatively: 1
negligibly: 1
negotiate: 1
nei: 1
neighboring: 1
nelson: 1
ness: 1
netecon: 1
neting: 1
neufeld: 1
newarr: 1
newscasts: 1
nextgeneration: 1
nfs: 1
ngas: 1
nicely: 1
niche: 1
nick: 1
night: 1
nikolov: 1
nimble: 1
ninth: 1
nishimura: 1
nishita: 1
nism: 1
nization: 1
noisy: 1
nomad: 1
nonblockingtransport: 1
noncongestion: 1
nondeterministic: 1
nonempty: 1
nossdav: 1
noteworthy: 1
notified: 1
notoriously: 1
nowadays: 1
np: 1
npapers: 1
nsfc: 1
ntserver: 1
num: 1
numb: 1
numeric: 1
nutanong: 1
nygren: 1
obeyed: 1
obeys: 1
obfuscates: 1
objective: 1
objectivity: 1
objectoriented: 1
obligation: 1
obliging: 1
observable: 1
observes: 1
obsessively: 1
obsoleted: 1
obstacle: 1
obstructs: 1
occurrence: 1
ofc: 1
offenders: 1
offerings: 1
officially: 1
offline: 1
offset: 1
oforder: 1
ogy: 1
oltp: 1
omitting: 1
oneanother: 1
ongoing: 1
ontology: 1
onwards: 1
opearting: 1
openafs: 1
opennt: 1
opens: 1
opensketch: 1
operafrom: 1
operamfs: 1
operat: 1
operatencies: 1
opposing: 1
opposition: 1
optimality: 1
optimally: 1
optimisation: 1
optimisations: 1
optimise: 1
optimised: 1
optimistically: 1
optional: 1
orchestrating: 1
orderings: 1
organised: 1
origin: 1
originated: 1
originating: 1
originator: 1
ority: 1
orks: 1
orleans: 1
orma: 1
ormance: 1
ortributed: 1
orts: 1
oscillate: 1
oscillating: 1
ost: 1
otivation: 1
ource: 1
ous: 1
outcontent: 1
outlook: 1
outof: 1
outperform: 1
outperformed: 1
outright: 1
outweighs: 1
overcomes: 1
overhaul: 1
overlaid: 1
overlayed: 1
overloading: 1
overpredict: 1
overprediction: 1
overreach: 1
overrequest: 1
overrequesting: 1
oversight: 1
oversold: 1
overweigh: 1
overwritten: 1
owing: 1
owned: 1
ozalp: 1
ozsu: 1
pa: 1
pack: 1
package: 1
packparently: 1
packs: 1
pain: 1
pairing: 1
paleczny: 1
pallickara: 1
palossless: 1
pan: 1
panel: 1
pang: 1
panning: 1
pans: 1
paolo: 1
papazoglou: 1
parallelising: 1
parallelism: 1
parallelized: 1
parallelizing: 1
parameterizing: 1
parent: 1
parents: 1
paritybased: 1
parliament: 1
parsa: 1
partitionable: 1
partners: 1
party: 1
passes: 1
pastry: 1
pat: 1
paterson: 1
patin: 1
patino: 1
pavlo: 1
pdc: 1
peculiar: 1
peek: 1
peep: 1
peking: 1
penalized: 1
pennsylvania: 1
penzo: 1
perceive: 1
perceiving: 1
percentiles: 1
perception: 1
perdichizzi: 1
perf: 1
performances: 1
perience: 1
periments: 1
permission: 1
permute: 1
permutes: 1
permuting: 1
perobject: 1
persisted: 1
persistence: 1
persisting: 1
personalize: 1
personalized: 1
personally: 1
pertaining: 1
perturbances: 1
perturbation: 1
perturbations: 1
perv: 1
pervasively: 1
pervasiveness: 1
petko: 1
petrov: 1
pfhsn: 1
phani: 1
philadelphia: 1
philosophical: 1
phones: 1
phpmyadmin: 1
physician: 1
pianese: 1
picconi: 1
picking: 1
picks: 1
piece: 1
pieces: 1
piles: 1
pirahesh: 1
pittsburgh: 1
pivotal: 1
plain: 1
planes: 1
planned: 1
planning: 1
plans: 1
plants: 1
plasma: 1
plat: 1
plausible: 1
please: 1
plentiful: 1
plotted: 1
pluggable: 1
plugins: 1
pn: 1
podcasts: 1
pointer: 1
pointers: 1
poirier: 1
police: 1
political: 1
portability: 1
portal: 1
porting: 1
portob: 1
portray: 1
posix: 1
post: 1
postava: 1
posted: 1
posters: 1
postponed: 1
postponing: 1
potencan: 1
potholes: 1
powell: 1
powerhouse: 1
powering: 1
powers: 1
powersavings: 1
ppendix: 1
practices: 1
pratt: 1
pray: 1
preallocating: 1
precede: 1
precious: 1
precision: 1
preclude: 1
predetermining: 1
predictability: 1
predicting: 1
predictions: 1
predominant: 1
predominantly: 1
preempted: 1
preexisting: 1
preferences: 1
prefetchthe: 1
preguica: 1
preparation: 1
prepare: 1
prepared: 1
prepares: 1
preprocessing: 1
pressing: 1
presume: 1
pretend: 1
pretending: 1
pretends: 1
prevailing: 1
prevalent: 1
previewer: 1
previwhen: 1
prices: 1
prifetched: 1
priin: 1
primaldual: 1
princehouse: 1
priorispeedup: 1
prioritized: 1
priortwo: 1
prito: 1
priviledges: 1
privileged: 1
pro: 1
probed: 1
probes: 1
procedures: 1
proceedin: 1
professional: 1
profiled: 1
profiles: 1
profiling: 1
programmed: 1
progressed: 1
prohibited: 1
prohibitive: 1
prohibitively: 1
prohibits: 1
projected: 1
proliferating: 1
prometheus: 1
prominently: 1
promised: 1
promotional: 1
promptly: 1
pronounced: 1
propagates: 1
propagating: 1
propel: 1
propgated: 1
proportionally: 1
proposal: 1
proposes: 1
prothe: 1
prototypes: 1
protruding: 1
proverbial: 1
provers: 1
provisions: 1
provoke: 1
proximity: 1
prudently: 1
pruned: 1
ptions: 1
publications: 1
publishsubscribe: 1
pubsub: 1
punishing: 1
purchased: 1
purdue: 1
putation: 1
puter: 1
puts: 1
puzar: 1
pvalues: 1
pvm: 1
pvt: 1
qnx: 1
qppq: 1
qu: 1
quadrant: 1
quadrants: 1
qualities: 1
quantified: 1
quantity: 1
quarterman: 1
quarters: 1
quasi: 1
quema: 1
questionable: 1
quinlan: 1
quired: 1
quorum: 1
quotes: 1
raab: 1
races: 1
rachid: 1
racing: 1
radar: 1
radi: 1
rago: 1
raid: 1
rails: 1
raincloud: 1
raisepriority: 1
raising: 1
rameter: 1
ramifications: 1
randomised: 1
ranks: 1
ratnasamy: 1
ratner: 1
rayfield: 1
rbudp: 1
rchitecture: 1
reaction: 1
reactive: 1
readiness: 1
readwrite: 1
realistically: 1
realities: 1
realization: 1
realtime: 1
reardon: 1
reboot: 1
rebuilt: 1
recast: 1
rechecks: 1
recipients: 1
recite: 1
reclamation: 1
recode: 1
recommendation: 1
recommended: 1
recommends: 1
reconfigurable: 1
reconfiguration: 1
reconfigure: 1
reconfiguring: 1
reconnect: 1
reconstruction: 1
recorded: 1
recov: 1
recovrequests: 1
recovthroughput: 1
recurrence: 1
recursive: 1
recursively: 1
redesign: 1
redirect: 1
redirected: 1
redirecting: 1
redisplaying: 1
reedsolomon: 1
referenced: 1
referring: 1
refers: 1
refines: 1
reflectsan: 1
refuse: 1
reg: 1
regenerate: 1
registering: 1
registry: 1
regularity: 1
reid: 1
reiher: 1
reimplementing: 1
relational: 1
relationship: 1
relationships: 1
relayed: 1
religion: 1
relinked: 1
remained: 1
removal: 1
ren: 1
rename: 1
rency: 1
render: 1
renderers: 1
renders: 1
rendezvous: 1
renessea: 1
renewed: 1
rently: 1
reordering: 1
replacements: 1
replicates: 1
reportedly: 1
repre: 1
reprefetch: 1
representa: 1
reproduced: 1
rescuer: 1
researcher: 1
resembles: 1
resend: 1
resetting: 1
reside: 1
resides: 1
resiliency: 1
resolves: 1
resolving: 1
resorting: 1
respected: 1
restarts: 1
restrict: 1
restructured: 1
resumed: 1
retained: 1
retaining: 1
retains: 1
rethese: 1
rethink: 1
retriev: 1
retrieving: 1
reusability: 1
reusable: 1
reuse: 1
reused: 1
revalidate: 1
revealed: 1
revealing: 1
reverts: 1
revisited: 1
revived: 1
revoked: 1
revolution: 1
rewind: 1
rexford: 1
rhee: 1
ricardo: 1
ride: 1
righteous: 1
rio: 1
rive: 1
rlogin: 1
ro: 1
roads: 1
rockell: 1
rocky: 1
rodrigues: 1
rodriguez: 1
rolig: 1
roll: 1
rollback: 1
rolled: 1
rollout: 1
room: 1
rooted: 1
roselli: 1
rotating: 1
rotations: 1
rough: 1
roundrobin: 1
roussel: 1
roy: 1
rss: 1
ru: 1
rubenstein: 1
ruichuan: 1
rush: 1
rushed: 1
rx: 1
saab: 1
sacrificing: 1
saikat: 1
saito: 1
sakoda: 1
salt: 1
sambamurthy: 1
samet: 1
sandber: 1
sankaran: 1
santa: 1
sarana: 1
sarcasm: 1
saroiu: 1
sata: 1
satpep: 1
saturated: 1
saturates: 1
saturating: 1
saturation: 1
savage: 1
saying: 1
says: 1
scaleable: 1
scarce: 1
scenarmobile: 1
scenes: 1
schedule: 1
schematic: 1
schiper: 1
schizophrenic: 1
schlosser: 1
schmidt: 1
schroeder: 1
schuh: 1
schultz: 1
sciascia: 1
scott: 1
screen: 1
screenshots: 1
scripting: 1
scripts: 1
scrutiny: 1
sdns: 1
seagate: 1
searchers: 1
searching: 1
searing: 1
sears: 1
secretly: 1
seeing: 1
seely: 1
seemed: 1
selec: 1
selection: 1
selectively: 1
selfinterested: 1
selforganizing: 1
semanticweb: 1
senses: 1
sensitivfigure: 1
sentative: 1
separating: 1
sequencing: 1
ser: 1
serialised: 1
sericola: 1
serverless: 1
servicing: 1
serving: 1
setceiver: 1
setups: 1
seven: 1
severely: 1
shacham: 1
shaded: 1
shah: 1
shahabi: 1
shalunov: 1
shao: 1
shaped: 1
shapers: 1
shapiro: 1
sharding: 1
shayee: 1
shed: 1
shelf: 1
shenghua: 1
shielding: 1
shim: 1
shipping: 1
shirriff: 1
shop: 1
shopping: 1
shoring: 1
shortcomings: 1
shorter: 1
shouldn: 1
shraer: 1
shrideep: 1
shtml: 1
shupp: 1
shutdown: 1
si: 1
sidebar: 1
siegenthaler: 1
siena: 1
sig: 1
sigkdd: 1
sigmetrics: 1
signature: 1
signed: 1
signers: 1
significance: 1
signing: 1
silberstein: 1
silently: 1
similarities: 1
similarity: 1
simon: 1
simulaneous: 1
simulates: 1
singhai: 1
sintek: 1
sishim: 1
sistencies: 1
sitaraman: 1
sits: 1
sivasubramaniam: 1
sive: 1
sjsu: 1
skepticism: 1
sky: 1
skyrocketing: 1
slash: 1
slay: 1
sleeps: 1
slide: 1
slip: 1
slowdowns: 1
sluggish: 1
smartphone: 1
smith: 1
smoothly: 1
snapshots: 1
snooping: 1
soa: 1
socc: 1
sock: 1
softway: 1
solicited: 1
solves: 1
somefound: 1
sonicmq: 1
sonicsoftware: 1
sooner: 1
sophia: 1
sorted: 1
sought: 1
spain: 1
spanningtree: 1
spans: 1
spared: 1
spawned: 1
speaking: 1
speaks: 1
speci: 1
specializes: 1
specificity: 1
specifies: 1
specifying: 1
spectrum: 1
speech: 1
spends: 1
spielman: 1
spiked: 1
spinning: 1
spirits: 1
spix: 1
splay: 1
splitx: 1
sponse: 1
sporting: 1
sports: 1
sprays: 1
spring: 1
squash: 1
squirrelmail: 1
sridharan: 1
srrs: 1
srsr: 1
ssh: 1
stabilizing: 1
stadrops: 1
stafford: 1
stand: 1
standardizing: 1
stanford: 1
stanislav: 1
stanton: 1
startup: 1
starved: 1
starving: 1
statemachine: 1
statems: 1
stationary: 1
statistic: 1
stead: 1
steen: 1
steep: 1
steer: 1
steere: 1
stepping: 1
stipulating: 1
sto: 1
stochastic: 1
stocking: 1
stodolsky: 1
stoica: 1
stor: 1
stordifferent: 1
straight: 1
street: 1
strengths: 1
stretagy: 1
strike: 1
strikes: 1
strikingly: 1
strings: 1
stripped: 1
strongest: 1
stronglytraces: 1
structuring: 1
studying: 1
stumbled: 1
stylistic: 1
suba: 1
subing: 1
subintervals: 1
subj: 1
subkilobyte: 1
submission: 1
subnetworks: 1
subordinate: 1
subramanian: 1
subscribes: 1
subscription: 1
subscriptions: 1
subsections: 1
subsequence: 1
subservicecontrol: 1
subserviceprocess: 1
substandard: 1
substitute: 1
substreams: 1
subtitles: 1
subtransactions: 1
succeeds: 1
successor: 1
sue: 1
suffix: 1
suggestive: 1
sul: 1
summarise: 1
summarised: 1
summarizes: 1
summarizing: 1
summer: 1
sunos: 1
sup: 1
superbowl: 1
superceded: 1
superfluous: 1
superimpose: 1
superior: 1
superlinearly: 1
supersede: 1
superseded: 1
supervisory: 1
supplementing: 1
supposed: 1
suppressing: 1
surely: 1
surements: 1
surge: 1
surplus: 1
surrounding: 1
surtani: 1
survivors: 1
suryanarayana: 1
suspended: 1
sussman: 1
sw: 1
swart: 1
swivel: 1
swws: 1
sympo: 1
syn: 1
synchro: 1
synchronise: 1
synchronizing: 1
systraditional: 1
szeged: 1
szymaniak: 1
tablet: 1
tag: 1
tags: 1
tailor: 1
tains: 1
talking: 1
talks: 1
tam: 1
tamma: 1
tan: 1
tance: 1
tanin: 1
tao: 1
tapped: 1
tapping: 1
tari: 1
taught: 1
tdi: 1
te: 1
technetwork: 1
technicalsessions: 1
technion: 1
technologists: 1
telecommunications: 1
telemetry: 1
templates: 1
tempt: 1
tems: 1
tency: 1
tended: 1
tension: 1
tent: 1
tentative: 1
tention: 1
terleaving: 1
terlinked: 1
terminal: 1
terminate: 1
terminated: 1
testimony: 1
textures: 1
thanks: 1
thefly: 1
ther: 1
thereafter: 1
thereby: 1
thorsten: 1
thrashing: 1
threading: 1
threetier: 1
throughputs: 1
throughxors: 1
tial: 1
tiate: 1
tib: 1
ticast: 1
ticipant: 1
ticker: 1
ticular: 1
tied: 1
tightrope: 1
timecritical: 1
timeframe: 1
timeline: 1
timers: 1
timescales: 1
timesharing: 1
timo: 1
tination: 1
tings: 1
tiple: 1
titles: 1
tity: 1
tively: 1
tivity: 1
todd: 1
todisincentivize: 1
toend: 1
toknow: 1
tokyo: 1
tolercations: 1
tom: 1
tone: 1
tons: 1
toplas: 1
topoltifiers: 1
tortures: 1
touted: 1
traceroute: 1
traf: 1
trafficshaping: 1
trailing: 1
tranasctions: 1
transactionally: 1
transactypes: 1
transcoding: 1
transformed: 1
transis: 1
transit: 1
transitional: 1
translated: 1
translates: 1
translation: 1
translators: 1
translucence: 1
transportation: 1
transporting: 1
travels: 1
treatments: 1
tri: 1
trials: 1
tricks: 1
tried: 1
trillion: 1
trim: 1
trips: 1
truncate: 1
truncated: 1
truong: 1
tsatalos: 1
ttls: 1
tude: 1
tudy: 1
tunable: 1
tung: 1
tuples: 1
turing: 1
tus: 1
tweb: 1
twelth: 1
twin: 1
twitter: 1
twotier: 1
tx: 1
txcache: 1
txn: 1
typed: 1
typwrite: 1
ual: 1
ubicomm: 1
ubiquitously: 1
ublcs: 1
uc: 1
ucb: 1
ufrgs: 1
ular: 1
ulate: 1
ultrareliable: 1
unacceptably: 1
unavoidable: 1
unbe: 1
uncertain: 1
unclustered: 1
unconstrained: 1
uncontrolled: 1
uncorrelated: 1
underdog: 1
undergo: 1
underlies: 1
underneath: 1
underperform: 1
understandable: 1
understanddevices: 1
understands: 1
understood: 1
undertake: 1
undertaken: 1
underutilisation: 1
underway: 1
undesired: 1
undisturbed: 1
unencrypted: 1
unflattering: 1
unfortunate: 1
unidirectional: 1
unifies: 1
uniformally: 1
unilaterally: 1
unintended: 1
uninterference: 1
unites: 1
univ: 1
univerisity: 1
universal: 1
universe: 1
universita: 1
unjustified: 1
unlink: 1
unlinking: 1
unmodified: 1
unnoticed: 1
unparalleled: 1
unrealistic: 1
unreasonable: 1
unrecoverable: 1
unreserved: 1
unresilient: 1
unresolved: 1
unresponsiveness: 1
unrpcs: 1
unspecified: 1
unsuitable: 1
untouched: 1
unusually: 1
unwilling: 1
upare: 1
upcalls: 1
upcan: 1
upcations: 1
upcoming: 1
upgrade: 1
upgrades: 1
upisting: 1
uploads: 1
upreader: 1
upson: 1
upstudies: 1
upthe: 1
upwidth: 1
ures: 1
urgently: 1
url: 1
urls: 1
usages: 1
usdoj: 1
usefully: 1
usermakes: 1
uservisible: 1
utilising: 1
utilized: 1
utilizes: 1
utilizing: 1
utrsut: 1
utt: 1
uture: 1
uut: 1
uutt: 1
validations: 1
vanilla: 1
vanishes: 1
var: 1
variances: 1
vasilatos: 1
vb: 1
vectored: 1
vehicles: 1
veitch: 1
velenis: 1
venkataraman: 1
vercurr: 1
verification: 1
versa: 1
vertical: 1
victims: 1
videos: 1
vidhyashankar: 1
viding: 1
viewer: 1
viewsynchronous: 1
violated: 1
violates: 1
viral: 1
vironment: 1
virtually: 1
virtue: 1
vishnumurthy: 1
visibly: 1
vision: 1
visit: 1
visiting: 1
vista: 1
visualize: 1
visualizing: 1
vital: 1
vivek: 1
vlo: 1
vmm: 1
vms: 1
voelker: 1
vogel: 1
voip: 1
vollset: 1
voluntary: 1
vrable: 1
wa: 1
waived: 1
wallach: 1
wans: 1
warp: 1
wasn: 1
wasteful: 1
wastes: 1
wasting: 1
watches: 1
wave: 1
wcnc: 1
weaken: 1
weakness: 1
webfs: 1
weblogs: 1
webtier: 1
weeks: 1
weighed: 1
welldefined: 1
weng: 1
wes: 1
westerlund: 1
wg: 1
whatsnew: 1
whatsoever: 1
wheeler: 1
whereupon: 1
whiteboard: 1
whitepaper: 1
whithout: 1
wholefile: 1
wicom: 1
widens: 1
wieloch: 1
wilma: 1
windowsnt: 1
winnie: 1
wires: 1
withuated: 1
witnesses: 1
wolf: 1
wonder: 1
woo: 1
woodford: 1
worker: 1
worries: 1
worrisome: 1
worthwhile: 1
wouldn: 1
wrapped: 1
wraps: 1
writclassification: 1
writeaccesses: 1
writeinvalidations: 1
writequirement: 1
writeserver: 1
writetive: 1
writewrite: 1
wrote: 1
wscompatible: 1
wsdl: 1
wspds: 1
wstransactions: 1
wu: 1
xaxis: 1
xcp: 1
xiao: 1
xisting: 1
xperimental: 1
xu: 1
xyx: 1
yaghmazadeh: 1
yann: 1
yaxes: 1
yee: 1
yielded: 1
yin: 1
ylianttila: 1
youtube: 1
yuanchao: 1
yuanyuan: 1
yum: 1
yushprakh: 1
zahorjan: 1
zdonik: 1
zeal: 1
zealous: 1
zelenka: 1
zephyr: 1
zettabyte: 1
zhen: 1
zhenqi: 1
zhou: 1
zhuang: 1
zoomed: 1
zooming: 1
zooms: 1
zou: 1
zuck: 1
zwilling: 1
