web technologies can web |
technologies can web services |
can web services scale |
web services scale up |
cornell university i n |
university i n the |
i n the past |
only major internet players |
major internet players such |
internet players such as |
players such as amazon |
implementing high performance multicast |
high performance multicast in |
and google were interested |
performance multicast in a |
google were interested in |
multicast in a managed |
were interested in deploying |
in a managed environment |
interested in deploying large |
a managed environment krzysztof |
managed environment krzysztof ostrowski |
environment krzysztof ostrowski cornell |
krzysztof ostrowski cornell university |
ostrowski cornell university ken |
cornell university ken birman |
university ken birman cornell |
ken birman cornell university |
birman cornell university abstract |
cornell university abstract motes |
university abstract motes end |
this is changing rapidly |
is changing rapidly all |
transparent error correction for |
an adaptive distributed file |
changing rapidly all sorts |
user application development using |
error correction for communication |
adaptive distributed file system |
rapidly all sorts of |
application development using c |
all sorts of companies |
distributed file system for |
sorts of companies and |
file system for mobile |
of companies and governmental |
correction for communication between |
system for mobile hosts |
companies and governmental organizations |
for communication between data |
for mobile hosts benjamin |
and governmental organizations are |
communication between data centers |
governmental organizations are suddenly |
mobile hosts benjamin atkin |
between data centers mahesh |
organizations are suddenly looking |
the company s own |
data centers mahesh balakrishnan |
hosts benjamin atkin and |
are suddenly looking towards |
company s own products |
benjamin atkin and kenneth |
suddenly looking towards web |
s own products are |
own products are still |
looking towards web services |
atkin and kenneth p |
products are still implemented |
towards web services as |
are still implemented primarily |
web services as a |
still implemented primarily in |
services as a platform |
implemented primarily in unmanaged |
as a platform that |
primarily in unmanaged c |
a platform that might |
birman department of computer |
platform that might support |
department of computer science |
that might support a |
of computer science cornell |
might support a wide |
computer science cornell university |
support a wide range |
a wide range of |
wide range of demanding |
range of demanding applications |
by building xyx in |
building xyx in the |
xyx in the recommended |
in the recommended manner |
examples of such systems |
of such systems include |
such systems include big |
systems include big banking |
include big banking and |
big banking and brokerage |
we found ourselves breaking |
banking and brokerage data |
found ourselves breaking new |
and brokerage data centers |
ourselves breaking new ground |
online service centers for |
the multicast protocols employed |
service centers for companies |
multicast protocols employed by |
centers for companies that |
protocols employed by qsm |
edu abstract mfs using |
for companies that operate |
employed by qsm were |
abstract mfs using file |
companies that operate on |
by qsm were designed |
mfs using file access |
that operate on a |
qsm were designed for |
using file access traces |
operate on a global |
were designed for performance |
file access traces from |
on a global scale |
designed for performance and |
access traces from windows |
for performance and scalability |
traces from windows nt |
from windows nt and |
windows nt and unix |
systems to operate critical |
to operate critical infrastructures |
operate critical infrastructures like |
incorporating a mixture of |
critical infrastructures like electric |
a mixture of new |
and a synthetic workload |
infrastructures like electric power |
mixture of new ideas |
a synthetic workload designed |
like electric power and |
of new ideas and |
synthetic workload designed to |
electric power and transportation |
new ideas and ideas |
workload designed to emulate |
ideas and ideas drawn |
designed to emulate sharing |
and ideas drawn from |
to emulate sharing patterns |
ideas drawn from prior |
and government and military |
emulate sharing patterns seen |
drawn from prior systems |
government and military systems |
sharing patterns seen in |
abstract the global network |
and military systems responsible |
patterns seen in mobility |
the global network of |
military systems responsible for |
seen in mobility is |
global network of data |
systems responsible for everything |
in mobility is a |
network of data centers |
the aspects on which |
responsible for everything from |
mobility is a critical |
of data centers is |
aspects on which we |
for everything from intelligence |
is a critical feature |
data centers is emerging |
on which we focus |
everything from intelligence gathering |
a critical feature of |
centers is emerging as |
which we focus here |
from intelligence gathering to |
critical feature of computer |
is emerging as an |
we focus here reflect |
intelligence gathering to issuing |
feature of computer systems |
emerging as an important |
focus here reflect architectural |
gathering to issuing social |
as an important distributed |
here reflect architectural responses |
to issuing social security |
an important distributed systems |
reflect architectural responses to |
and while collaborative engineering |
issuing social security checks |
important distributed systems paradigm |
architectural responses to scheduling |
while collaborative engineering systems |
distributed systems paradigm commodity |
responses to scheduling delays |
this emerging trend presents |
systems paradigm commodity clusters |
emerging trend presents developers |
paradigm commodity clusters running |
wireless networks are common |
trend presents developers with |
commodity clusters running high |
overheads associated with threads |
presents developers with a |
developers with a new |
with a new challenge |
most applications that run |
applications that run on |
and costs arising in |
that run on existing |
costs arising in the |
run on existing work |
building web services solutions |
arising in the memory |
on existing work in |
web services solutions that |
in the memory management |
existing work in cache |
speed lambda networks across |
work in cache management |
services solutions that scale |
the memory management subsystem |
lambda networks across hundreds |
in cache management for |
networks across hundreds of |
cache management for mobile |
across hundreds of milliseconds |
management for mobile file |
hundreds of milliseconds of |
over the period during |
for mobile file systems |
a scalable system is |
the period during which |
of milliseconds of network |
mobile file systems mobile |
scalable system is one |
period during which qsm |
milliseconds of network latency |
file systems mobile hosts |
system is one that |
during which qsm was |
systems mobile hosts lack |
is one that can |
which qsm was developed |
mobile hosts lack flexible |
one that can flexibly |
packet loss on long |
hosts lack flexible mechanisms |
that can flexibly accommodate |
lack flexible mechanisms for |
can flexibly accommodate growth |
flexible mechanisms for data |
flexibly accommodate growth in |
mechanisms for data access |
haul networks can cripple |
accommodate growth in its |
for data access in |
networks can cripple the |
growth in its client |
data access in an |
can cripple the performance |
these had pervasive consequences |
in its client base |
access in an en |
cripple the performance of |
the performance of applications |
performance of applications and |
forcing us to redesign |
of applications and protocols |
such systems typically run |
us to redesign and |
systems typically run on |
applications and protocols a |
typically run on a |
to redesign and recode |
run on a clustered |
and protocols a loss |
on a clustered computer |
redesign and recode one |
protocols a loss rate |
a clustered computer or |
and recode one layer |
clustered computer or in |
a loss rate as |
computer or in a |
recode one layer of |
or in a large |
loss rate as low |
in a large data |
one layer of the |
rate as low as |
a large data center |
layer of the system |
large data center and |
of the system after |
the system after another |
data center and must |
center and must be |
and must be able |
must be able to |
be able to handle |
able to handle high |
to handle high loads |
handle high loads or |
high loads or sudden |
loads or sudden demand |
the original system was |
or sudden demand bursts |
original system was multithreaded |
sudden demand bursts and |
is sufficient to reduce |
demand bursts and a |
sufficient to reduce tcp |
bursts and a vast |
and a vast number |
a vast number of |
vast number of users |
ip throughput by an |
o calls and was |
throughput by an order |
calls and was rather |
they must reliably respond |
by an order of |
and was rather casual |
must reliably respond even |
an order of magnitude |
incorporates mechanisms for making |
reliably respond even in |
was rather casual about |
order of magnitude on |
mechanisms for making efficient |
respond even in the |
rather casual about buffering |
of magnitude on a |
for making efficient vironment |
even in the event |
casual about buffering and |
making efficient vironment with |
in the event of |
about buffering and caching |
efficient vironment with large |
the event of failures |
vironment with large and |
event of failures or |
with large and frequent |
of failures or reconfiguration |
large and frequent variations |
the current system is |
and frequent variations in |
current system is single |
frequent variations in network |
variations in network connec |
use of available bandwidth |
maelstrom is an edge |
is an edge appliance |
managed and automate as |
an edge appliance that |
and automate as many |
edge appliance that masks |
automate as many routine |
appliance that masks packet |
as many routine services |
that masks packet loss |
it has mostly focused |
many routine services such |
and obsessively minimizes memory |
masks packet loss transparently |
has mostly focused on |
routine services such as |
obsessively minimizes memory consumption |
packet loss transparently and |
mostly focused on tivity |
services such as backups |
loss transparently and quickly |
such as backups and |
transparently and quickly from |
as backups and component |
and quickly from inter |
backups and component upgrades |
and component upgrades as |
component upgrades as possible |
many settings also require |
settings also require security |
in collaborative work adapting |
also require security against |
aggregating traffic for high |
performs well and is |
collaborative work adapting existing |
require security against attempted |
well and is stable |
work adapting existing systems |
security against attempted intrusions |
and is stable at |
adapting existing systems to |
speed encoding and using |
against attempted intrusions and |
is stable at high |
existing systems to cope |
encoding and using a |
attempted intrusions and distributed |
stable at high data |
systems to cope with |
and using a new |
intrusions and distributed denial |
at high data rates |
to cope with periods |
using a new forward |
cope with periods of |
a new forward error |
with periods of low |
new forward error correction |
periods of low bandwidth |
large scale and under |
forward error correction scheme |
scale and under stress |
error correction scheme to |
correction scheme to handle |
scheme to handle bursty |
to handle bursty loss |
the finished system achieves |
finished system achieves extremely |
particularly when wireless and |
system achieves extremely high |
when wireless and wired |
achieves extremely high performance |
wireless and wired users |
extremely high performance with |
and wired users share |
high performance with relatively |
wired users share in |
performance with relatively modest |
users share in a |
with relatively modest cpu |
share in a style |
relatively modest cpu and |
in a style which |
modest cpu and memory |
a style which we |
cpu and memory loads |
style which we will |
which we will refer |
we will refer to |
will refer to as |
refer to as modal |
to as modal adaptation |
although our paper is |
our paper is not |
paper is not about |
is not about setting |
the second builds on |
when files or databases |
not about setting performance |
second builds on the |
about setting performance records |
builds on the first |
setting performance records the |
on the first and |
performance records the absolute |
the first and supports |
records the absolute numbers |
first and supports a |
we describe some techniques |
the absolute numbers are |
and supports a way |
describe some techniques bandwidth |
absolute numbers are good |
supports a way to |
some techniques bandwidth is |
a way to build |
techniques bandwidth is high |
way to build scripts |
to build scripts of |
build scripts of simpler |
qsm outperforms the multicast |
scripts of simpler transactions |
i ntroduction t a |
outperforms the multicast platforms |
the application communicates normally |
ntroduction t a conference |
the multicast platforms we |
t a conference version |
multicast platforms we ve |
some might argue that |
a conference version of |
platforms we ve worked |
might argue that all |
when for adapting data |
conference version of this |
we ve worked with |
argue that all reliability |
for adapting data access |
version of this paper |
ve worked with in |
that all reliability needs |
adapting data access to |
of this paper appeared |
worked with in the |
all reliability needs can |
data access to network |
this paper appeared in |
with in the past |
reliability needs can be |
access to network variability |
paper appeared in nsdi |
in the past systems |
needs can be recast |
to network variability in |
the past systems that |
can be recast in |
network variability in the |
past systems that run |
be recast in terms |
variability in the context |
systems that run in |
recast in terms of |
in the context of |
that run in unmanaged |
in terms of transactions |
the context of bandwidth |
run in unmanaged settings |
context of bandwidth falls |
of bandwidth falls below |
bandwidth falls below a |
falls below a threshold |
this paper won t |
paper won t tell |
won t tell the |
t tell the blow |
the past three decades |
the application enters a |
fifth usenix symposium on |
past three decades have |
application enters a lowmfs |
usenix symposium on networked |
three decades have seen |
symposium on networked systems |
decades have seen one |
on networked systems design |
have seen one failed |
networked systems design and |
a client cache manager |
seen one failed attempt |
systems design and implementation |
client cache manager for |
one failed attempt after |
cache manager for a |
failed attempt after another |
manager for a distributed |
attempt after another to |
we use qsm in |
for a distributed file |
after another to build |
use qsm in a |
a distributed file system |
another to build everything |
qsm in a series |
to build everything over |
in a series of |
build everything over a |
a series of experiments |
we bandwidth mode in |
everything over a database |
series of experiments that |
bandwidth mode in which |
over a database system |
of experiments that highlight |
mode in which communication |
experiments that highlight fundamental |
in which communication is |
that highlight fundamental factors |
which communication is restricted |
and it s now |
communication is restricted or |
it s now clear |
is restricted or deshow |
s now clear that |
these reveal linkages between |
restricted or deshow how |
ms index terms data |
now clear that many |
reveal linkages between achievable |
or deshow how mfs |
index terms data centers |
clear that many kinds |
linkages between achievable performance |
deshow how mfs is |
that many kinds of |
between achievable performance and |
how mfs is able |
many kinds of systems |
achievable performance and the |
mfs is able to |
kinds of systems just |
performance and the costs |
is able to adapt |
of systems just don |
and the costs and |
able to adapt to |
systems just don t |
the costs and characteristics |
to adapt to widely |
just don t match |
costs and characteristics of |
adapt to widely varying |
don t match the |
and characteristics of the |
he emergence of commodity |
to widely varying bandwidth |
emergence of commodity clusters |
characteristics of the managed |
of commodity clusters and |
widely varying bandwidth ferred |
commodity clusters and data |
of the managed framework |
clusters and data centers |
t match the model |
and data centers has |
data centers has enabled |
centers has enabled a |
has enabled a new |
doing so sheds light |
these intrinsically distributed systems |
so sheds light on |
intrinsically distributed systems make |
sheds light on the |
enabled a new class |
an application has a |
distributed systems make use |
light on the challenges |
a new class of |
application has a small |
systems make use of |
on the challenges of |
new class of globally |
has a small number |
make use of direct |
the challenges of working |
class of globally distributed |
a small number of |
use of direct communication |
challenges of working in |
of globally distributed highperformance |
small number of levels |
of direct communication between |
of working in a |
globally distributed highperformance applications |
number of levels through |
direct communication between programs |
working in a kind |
distributed highperformance applications that |
of levels through the |
communication between programs via |
in a kind of |
highperformance applications that coordinate |
levels through the use |
between programs via the |
a kind of environment |
applications that coordinate over |
through the use of |
programs via the trans |
kind of environment that |
that coordinate over vast |
the use of modeless |
of environment that will |
coordinate over vast geographical |
use of modeless adaptation |
environment that will be |
over vast geographical distances |
current web services standards |
that will be more |
web services standards have |
will be more and |
services standards have many |
and evaluate the possible |
be more and more |
evaluate the possible modes |
standards have many critical |
the possible modes and |
more and more prevalent |
possible modes and chooses |
a financial firm s |
have many critical limitations |
and more prevalent in |
modes and chooses the |
financial firm s new |
more prevalent in years |
and chooses the appropriate |
firm s new york |
prevalent in years to |
chooses the appropriate one |
s new york city |
in years to come |
today s web services |
new york city data |
the appropriate one based |
s web services standards |
york city data center |
appropriate one based on |
our insights should be |
city data center may |
web services standards seem |
one based on the |
insights should be of |
data center may receive |
services standards seem to |
based on the benefit |
should be of value |
center may receive real |
standards seem to answer |
on the benefit of |
be of value to |
seem to answer these |
the benefit of mechanisms |
of value to developers |
time updates from a |
benefit of mechanisms for |
to answer these needs |
value to developers of |
updates from a stock |
of mechanisms for improving |
to developers of other |
from a stock exchange |
mechanisms for improving file |
developers of other high |
a stock exchange in |
for improving file system |
stock exchange in switzerland |
a more probing analysis |
improving file system performance |
more probing analysis reveals |
file system performance currently |
performance communication and event |
probing analysis reveals many |
system performance currently available |
conduct financial transactions with |
analysis reveals many critical |
performance currently available bandwidth |
financial transactions with banks |
reveals many critical limitations |
transactions with banks in |
with banks in asia |
cache data in london |
data in london for |
in the coda file |
in london for locality |
the coda file and |
london for locality and |
coda file and cache |
the major web services |
for locality and mirror |
file and cache consistency |
major web services standards |
locality and mirror it |
we propose a new |
and cache consistency using |
web services standards dealing |
and mirror it to |
propose a new positioning |
cache consistency using microbenchmarks |
services standards dealing with |
mirror it to kansas |
a new positioning of |
consistency using microbenchmarks and |
standards dealing with reliability |
it to kansas for |
new positioning of multicast |
using microbenchmarks and file |
to kansas for disaster |
positioning of multicast technology |
microbenchmarks and file system |
and file system system |
as an extension of |
an extension of the |
extension of the component |
of the component integration |
the component integration features |
to interconnect these bandwidth |
component integration features of |
integration features of the |
features of the microsoft |
reliability provides for reliable |
provides for reliable handoff |
hungry data centers across |
for reliable handoff between |
data centers across the |
reliable handoff between a |
net managed runtime environment |
centers across the globe |
handoff between a client |
between a client system |
a client system and |
the cache manager operates |
client system and a |
organizations are increasingly deploying |
cache manager operates in |
system and a queuing |
are increasingly deploying private |
manager operates in either |
and a queuing system |
increasingly deploying private lambda |
operates in either a |
a queuing system residing |
deploying private lambda networks |
although we started with |
in either a stronglytraces |
queuing system residing between |
we started with a |
system residing between the |
started with a sophisticated |
residing between the client |
raw bandwidth is ubiquitous |
with a sophisticated multicast |
between the client and |
bandwidth is ubiquitous and |
a sophisticated multicast protocol |
the client and some |
is ubiquitous and cheaply |
client and some service |
ubiquitous and cheaply available |
and cheaply available in |
cheaply available in the |
experiments reveal a series |
available in the form |
reveal a series of |
in the form of |
a series of problematic |
the form of existing |
series of problematic interactions |
form of existing dark |
which affects the policy |
of problematic interactions between |
the standard isn t |
of existing dark fiber |
affects the policy for |
problematic interactions between its |
standard isn t nearly |
the policy for writing |
interactions between its high |
isn t nearly as |
policy for writing changes |
t nearly as comprehensive |
for writing changes to |
nearly as comprehensive as |
writing changes to files |
as comprehensive as the |
running and maintaining high |
changes to files back |
comprehensive as the name |
to files back to |
as the name implies |
processing logic and the |
files back to the |
logic and the properties |
back to the server |
and the properties of |
the properties of the |
properties of the managed |
free networks over this |
of the managed framework |
networks over this fiber |
modal adaptation schemes are |
it s limited to |
over this fiber is |
adaptation schemes are well |
s limited to pipelines |
this fiber is difficult |
limited to pipelines that |
fiber is difficult and |
to pipelines that include |
is difficult and expensive |
pipelines that include queuing |
that include queuing subsystems |
introduction in which changes |
in which changes in |
which changes in bandwidth |
changes in bandwidth are |
in bandwidth are relatively |
we addressed these and |
bandwidth are relatively predictable |
capacity optical links are |
addressed these and achieved |
reliability boils down to |
optical links are almost |
boils down to a |
these and achieved high |
such as switching network |
down to a few |
links are almost never |
to a few options |
as switching network access |
and achieved high performance |
are almost never congested |
a few options that |
switching network access from |
achieved high performance by |
few options that a |
network access from an |
high performance by making |
options that a client |
access from an ethernet |
they drop packets for |
performance by making some |
that a client can |
from an ethernet to |
drop packets for numerous |
by making some unusual |
a client can use |
an ethernet to a |
packets for numerous reasons |
making some unusual architectural |
client can use to |
ethernet to a modem |
for numerous reasons dirty |
some unusual architectural decisions |
can use to tell |
use to tell the |
to tell the queuing |
but mobility is now |
tell the queuing system |
mobility is now an |
which we distill into |
the queuing system whether |
is now an major |
we distill into general |
queuing system whether or |
now an major feature |
distill into general insights |
system whether or not |
an major feature of |
whether or not to |
major feature of computer |
or not to reissue |
feature of computer systems |
not to reissue a |
component integration environments such |
to reissue a request |
integration environments such as |
reissue a request if |
environments such as microsoft |
a request if a |
over the not as |
request if a failure |
the not as appropriate |
if a failure occurs |
not as appropriate in |
as appropriate in for |
appropriate in for wireless |
in for wireless networks |
ee have become widely |
and a way to |
have become widely popular |
a way to timestamp |
become widely popular with |
in which bandwidth past |
way to timestamp requests |
widely popular with application |
which bandwidth past decade |
to timestamp requests so |
popular with application developers |
timestamp requests so that |
requests so that a |
so that a service |
that a service can |
a service can detect |
service can detect duplicates |
who benefit from standardized |
benefit from standardized memory |
from standardized memory management |
held devices capable of |
devices capable of wireless |
capable of wireless availability |
of wireless availability is |
wireless availability is less |
transactions actually consists of |
availability is less predictable |
actually consists of two |
is less predictable and |
consists of two side |
less predictable and varies |
predictable and varies over |
and varies over a |
varies over a larger |
over a larger possible |
a larger possible network |
larger possible network access |
possible network access have |
and performance analysis tools |
network access have become |
performance analysis tools that |
access have become common |
for example and in |
analysis tools that operate |
example and in different |
one is aimed at |
tools that operate across |
and wireless networks are |
is aimed at applications |
and in different patterns |
that operate across component |
wireless networks are range |
aimed at applications that |
operate across component boundaries |
at applications that perform |
ranging from singleton drops |
applications that perform database |
from singleton drops to |
that perform database transactions |
the notion of insufficient |
singleton drops to extended |
perform database transactions with |
this paper describes quicksilver |
notion of insufficient bandwidth |
drops to extended bursts |
database transactions with the |
paper describes quicksilver scalable |
of insufficient bandwidth can |
transactions with the usual |
describes quicksilver scalable multicast |
insufficient bandwidth can vary |
with the usual acid |
bandwidth can vary dependalso |
can vary dependalso proliferating |
applications that run on |
that run on hosts |
run on hosts in |
on hosts in wireless |
hosts in wireless neting |
in wireless neting on |
wireless neting on how |
neting on how much |
on how much data |
a new multicast platform |
how much data the |
new multicast platform designed |
much data the application |
multicast platform designed to |
data the application is |
platform designed to achieve |
the application is trying |
designed to achieve high |
application is trying to |
to achieve high performance |
noncongestion loss has been |
is trying to send |
achieve high performance in |
loss has been observed |
or the remote procedure |
high performance in managed |
has been observed on |
the remote procedure call |
performance in managed environments |
been observed on long |
remote procedure call and |
so that works must |
procedure call and that |
that works must cope |
call and that can |
works must cope with |
memoryrelated overheads and phenomena |
must cope with constraints |
and that can t |
cope with constraints on |
overheads and phenomena related |
with constraints on access |
that can t tolerate |
constraints on access to |
and phenomena related to |
haul networks as well |
can t tolerate delay |
on access to data |
phenomena related to scheduling |
access to data that |
related to scheduling are |
to data that are |
to scheduling are shown |
these systems lack databases |
data that are genit |
scheduling are shown to |
systems lack databases clean |
that are genit may |
are shown to dominate |
lack databases clean separation |
are genit may make |
shown to dominate the |
databases clean separation of |
genit may make sense |
to dominate the behavior |
clean separation of stored |
may make sense to |
dominate the behavior of |
separation of stored data |
make sense to adjust |
the behavior of the |
of stored data from |
sense to adjust network |
behavior of the system |
stored data from code |
to adjust network usage |
adjust network usage when |
network usage when the |
usage when the bandwidth |
when the bandwidth erally |
we discuss techniques that |
the bandwidth erally not |
and any attempt to |
discuss techniques that helped |
bandwidth erally not present |
any attempt to force |
techniques that helped us |
erally not present in |
attempt to force them |
that helped us to |
not present in wired |
to force them into |
helped us to alleviate |
present in wired networks |
force them into that |
us to alleviate these |
them into that model |
to alleviate these problems |
into that model results |
that model results in |
distance from a base |
model results in unacceptable |
from a base stadrops |
results in unacceptable loss |
a base stadrops by |
and argue that they |
in unacceptable loss of |
base stadrops by half |
argue that they reveal |
unacceptable loss of performance |
that they reveal general |
they reveal general principles |
reveal general principles applicable |
general principles applicable to |
rather than just when |
intrinsically distributed systems are |
principles applicable to other |
than just when it |
distributed systems are common |
applicable to other kinds |
just when it falls |
to other kinds of |
when it falls to |
other kinds of high |
it falls to modem |
and web services will |
web services will need |
the inadequacy of commodity |
services will need to |
inadequacy of commodity tcp |
will need to support |
need to support them |
rate protocols and applications |
ip in high bandwidthdelay |
protocols and applications in |
in high bandwidthdelay product |
and applications in managed |
high bandwidthdelay product networks |
applications in managed settings |
contention with other hosts |
bandwidthdelay product networks is |
the existing reliability options |
with other hosts or |
product networks is extensively |
existing reliability options simply |
other hosts or processes |
networks is extensively documented |
reliability options simply don |
hosts or processes on |
options simply don t |
or processes on the |
introduction a component integration |
simply don t address |
processes on the same |
a component integration revolution |
don t address the |
on the same host |
component integration revolution is |
t address the requirement |
integration revolution is transforming |
revolution is transforming the |
is transforming the development |
transforming the development of |
selecting a mode according |
the development of desktop |
a mode according to |
a lesson from the |
development of desktop applications |
mode according to the |
lesson from the past |
according to the available |
from the past what |
to the available bandwidth |
platforms such as windows |
the past what sorts |
the available bandwidth can |
past what sorts of |
available bandwidth can uninterference |
what sorts of scaling |
sorts of scaling and |
of scaling and reliability |
scaling and reliability features |
and reliability features are |
reliability features are lacking |
ee promote an application |
and switching between different |
features are lacking in |
promote an application development |
switching between different wireless |
are lacking in web |
an application development style |
between different wireless media |
lacking in web services |
application development style in |
different wireless media all |
in web services standards |
development style in which |
wireless media all necessarily |
web services standards today |
style in which components |
media all necessarily constrain |
in which components are |
all necessarily constrain communication |
which components are implemented |
components are implemented independently |
ip has three major |
a good example is |
are implemented independently and |
has three major problems |
since it ignores what |
implemented independently and heavily |
good example is data |
three major problems when |
it ignores what data |
independently and heavily reused |
ignores what data compound |
major problems when used |
what data compound the |
example is data replication |
problems when used over |
data compound the variability |
when used over such |
by standardizing memory management |
compound the variability in |
used over such networks |
standardizing memory management and |
building a server that |
the variability in network |
memory management and type |
a server that scales |
variability in network performance |
management and type checking |
server that scales to |
in network performance to |
that scales to handle |
network performance to which |
scales to handle load |
performance to which apthe |
these platforms enable safe |
to handle load often |
to which apthe application |
ip suffers throughput collapse |
platforms enable safe and |
handle load often requires |
which apthe application actually |
suffers throughput collapse if |
enable safe and efficient |
load often requires replicating |
apthe application actually wants |
throughput collapse if the |
safe and efficient cross |
often requires replicating data |
application actually wants to |
collapse if the network |
requires replicating data on |
actually wants to send |
if the network is |
replicating data on multiple |
wants to send over |
the network is even |
data on multiple nodes |
to send over the |
network is even slightly |
on multiple nodes of |
avoiding overheads associated with |
send over the network |
is even slightly prone |
multiple nodes of a |
overheads associated with protection |
even slightly prone to |
nodes of a cluster |
associated with protection boundaries |
deferplications must adapt if |
slightly prone to packet |
must adapt if they |
prone to packet loss |
adapt if they are |
if they are to |
they are to perform |
are to perform well |
another example is guaranteed |
conservative flow control mechanisms |
example is guaranteed real |
flow control mechanisms designed |
ring writing back all |
control mechanisms designed to |
writing back all modifications |
mechanisms designed to deal |
back all modifications to |
designed to deal with |
all modifications to files |
to deal with the |
modifications to files may |
deal with the systematic |
a company that buys |
to files may not |
company that buys a |
with the systematic congestion |
that buys a cluster |
files may not be |
buys a cluster probably |
may not be a |
a cluster probably wants |
not be a sensible |
cluster probably wants to |
be a sensible this |
probably wants to guarantee |
a sensible this paper |
wants to guarantee that |
sensible this paper focuses |
to guarantee that some |
the systematic congestion of |
our project is interested |
this paper focuses on |
project is interested in |
systematic congestion of the |
is interested in leveraging |
paper focuses on adaptation |
interested in leveraging these |
focuses on adaptation techniques |
in leveraging these benefits |
congestion of the commodity |
leveraging these benefits to |
on adaptation techniques for |
guarantee that some service |
of the commodity internet |
these benefits to help |
adaptation techniques for management |
that some service will |
the commodity internet react |
benefits to help developers |
techniques for management policy |
some service will be |
commodity internet react too |
to help developers implement |
for management policy if |
service will be responsive |
internet react too sharply |
help developers implement robust |
management policy if those |
will be responsive enough |
react too sharply to |
developers implement robust and |
policy if those are |
be responsive enough to |
implement robust and scalable |
if those are the |
responsive enough to keep |
robust and scalable computing |
those are the only |
enough to keep its |
and scalable computing services |
are the only messages |
to keep its customers |
scalable computing services that |
the only messages available |
keep its customers happy |
computing services that will |
only messages available to |
its customers happy even |
services that will run |
messages available to send |
customers happy even when |
that will run on |
happy even when demand |
will run on clusters |
even when demand is |
run on clusters or |
when demand is high |
on clusters or in |
ms w n s |
of data accessed and |
clusters or in datacenters |
w n s e |
data accessed and modified |
n s e fig |
the missing technologies don |
accessed and modified by |
missing technologies don t |
early users of our |
and modified by mobile |
technologies don t stop |
users of our platform |
modified by mobile hosts |
don t stop there |
of our platform are |
our platform are creating |
platform are creating applications |
are creating applications in |
example lambda network ephemeral |
we investigate we describe |
creating applications in areas |
lambda network ephemeral loss |
investigate we describe mfs |
applications in areas such |
network ephemeral loss on |
cycle services that can |
in areas such as |
ephemeral loss on over |
services that can launch |
areas such as parallelized |
that can launch an |
such as parallelized data |
can launch an application |
provisioned links a single |
as parallelized data mining |
launch an application on |
links a single packet |
an application on demand |
a single packet in |
a flexible cache adaptation |
application on demand or |
single packet in ten |
event stream filtering software |
flexible cache adaptation in |
on demand or restart |
packet in ten thousand |
cache adaptation in the |
demand or restart a |
in ten thousand is |
adaptation in the context |
and scalable web services |
or restart a failed |
ten thousand is enough |
in the context of |
restart a failed component |
thousand is enough to |
the context of mfs |
is enough to reduce |
developers of clustered services |
enough to reduce tcp |
of clustered services need |
or load balancers and |
clustered services need reliable |
a client cache manager |
load balancers and technology |
services need reliable multicast |
client cache manager for |
ip throughput to a |
balancers and technology to |
need reliable multicast protocols |
cache manager for a |
throughput to a third |
and technology to automate |
reliable multicast protocols for |
manager for a manager |
to a third over |
technology to automate management |
multicast protocols for data |
for a manager for |
a third over a |
to automate management of |
protocols for data replication |
a manager for a |
automate management of a |
manager for a distributed |
management of a machine |
for a distributed file |
of a machine cluster |
and in light of |
a distributed file system |
a machine cluster running |
in light of our |
distributed file system client |
machine cluster running web |
and one in a |
light of our broader |
cluster running web services |
one in a thousand |
of our broader goal |
running web services applications |
in a thousand drops |
our broader goal of |
a thousand drops it |
which differs from distributed |
broader goal of leveraging |
thousand drops it by |
goal of leveraging the |
differs from distributed file |
drops it by an |
of leveraging the power |
from distributed file system |
it by an order |
leveraging the power and |
working groups within the |
by an order of |
the power and component |
groups within the world |
an order of magnitude |
power and component integration |
within the world wide |
and component integration features |
we concentrate on distributed |
the world wide web |
component integration features of |
concentrate on distributed file |
world wide web consortium |
integration features of a |
on distributed file systraditional |
features of a managed |
distributed file systraditional cache |
time or interactive applications |
of a managed framework |
file systraditional cache manager |
or interactive applications are |
systraditional cache manager design |
interactive applications are impacted |
cache manager design in |
applications are impacted by |
manager design in two |
the multicast technology must |
are impacted by the |
design in two important |
multicast technology must run |
impacted by the reliance |
in two important respects |
technology must run in |
by the reliance of |
must run in a |
the reliance of reliability |
run in a managed |
reliance of reliability mechanisms |
in a managed setting |
of reliability mechanisms on |
reliability mechanisms on acknowledgments |
mechanisms on acknowledgments and |
on acknowledgments and retransmissions |
the primary organization developing |
primary organization developing web |
organization developing web services |
but little is known |
developing web services standards |
tems because systems in |
little is known about |
limiting the latency of |
because systems in this |
is known about highperformance |
the latency of packet |
systems in this area |
known about highperformance protocols |
latency of packet recovery |
in this area are |
about highperformance protocols in |
of packet recovery to |
not one is addressing |
this area are highly |
highperformance protocols in managed |
packet recovery to at |
one is addressing these |
area are highly developed |
protocols in managed environments |
recovery to at least |
is addressing these kinds |
are highly developed and |
to at least the |
addressing these kinds of |
highly developed and have |
at least the round |
these kinds of issues |
it is interesting to |
developed and have mfs |
least the round trip |
is interesting to realize |
and have mfs uses |
a similar dynamic played |
interesting to realize that |
the round trip time |
have mfs uses an |
similar dynamic played out |
to realize that although |
mfs uses an rpc |
dynamic played out in |
realize that although microsoft |
uses an rpc library |
played out in the |
that although microsoft pro |
an rpc library supporting |
out in the early |
rpc library supporting priorities |
if delivery is sequenced |
library supporting priorities to |
supporting priorities to enable |
this research was supported |
priorities to enable modewell |
research was supported by |
to enable modewell understood |
was supported by afrl |
enable modewell understood semantics |
each lost packet acts |
if with additional support |
although the techniques we |
lost packet acts as |
with additional support from |
the techniques we describe |
packet acts as a |
additional support from afosr |
techniques we describe less |
acts as a virtual |
we describe less adaptation |
as a virtual road |
server computing was touted |
computing was touted as |
was touted as the |
block in the fifo |
touted as the next |
in the fifo channel |
as the next big |
the fifo channel until |
the next big thing |
fifo channel until it |
channel until it is |
until it is recovered |
a silver bullet to |
silver bullet to solve |
which allocates available bandwidth |
bullet to solve every |
allocates available bandwidth based |
to solve every problem |
available bandwidth based should |
solve every problem related |
ip requires massive buffers |
bandwidth based should be |
every problem related to |
department of computer science |
based should be broadly |
requires massive buffers at |
problem related to older |
should be broadly applicable |
massive buffers at the |
related to older mainframe |
be broadly applicable in |
buffers at the communicating |
to older mainframe and |
broadly applicable in other |
at the communicating endhosts |
older mainframe and batch |
applicable in other application |
the communicating endhosts to |
mainframe and batch systems |
in other application environments |
communicating endhosts to fully |
endhosts to fully exploit |
to fully exploit the |
fully exploit the bandwidth |
exploit the bandwidth of |
the bandwidth of a |
bandwidth of a long |
on the types of |
companies rushed to move |
the types of messages |
rushed to move everything |
types of messages being |
to move everything from |
of messages being sent |
move everything from mainframe |
everything from mainframe settings |
even in the absence |
from mainframe settings to |
in the absence of |
mainframe settings to client |
the absence of packet |
by assigning priorities such |
absence of packet loss |
assigning priorities such as |
priorities such as caching |
such as caching dynamic |
as caching dynamic internet |
caching dynamic internet content |
dynamic internet content or |
internet content or caching |
content or caching to |
there were notable successes |
or caching to improve |
resistant alternatives to tcp |
caching to improve appropriately |
but it quickly became |
ip is not feasible |
it quickly became apparent |
is not feasible in |
quickly became apparent that |
not feasible in corporate |
became apparent that the |
feasible in corporate data |
such as retrieving files |
apparent that the early |
in corporate data centers |
that the early platforms |
the early platforms were |
early platforms were strikingly |
platforms were strikingly immature |
can the performance of |
where standardization is the |
the performance of interactions |
standardization is the key |
performance of interactions with |
is the key to |
of interactions with web |
processes needed to be |
the key to low |
interactions with web services |
needed to be automated |
key to low and |
to be automated and |
to low and predictable |
be automated and standardized |
low and predictable maintenance |
and predictable maintenance costs |
we evaluate proceed concurrently |
evaluate proceed concurrently with |
proceed concurrently with background |
and the early generations |
neither is eliminating loss |
concurrently with background activities |
the early generations of |
is eliminating loss events |
with background activities such |
early generations of client |
eliminating loss events on |
background activities such as |
loss events on a |
activities such as writing |
events on a network |
such as writing the |
on a network that |
server systems cost a |
as writing the authors |
a network that could |
systems cost a fortune |
writing the authors were |
network that could span |
cost a fortune to |
the embedding of qsm |
the authors were supported |
that could span thousands |
a fortune to build |
embedding of qsm into |
authors were supported in |
could span thousands of |
of qsm into windows |
were supported in part |
span thousands of miles |
qsm into windows yielded |
supported in part by |
into windows yielded an |
in part by darpa |
windows yielded an unexpected |
required armies of systems |
part by darpa under |
yielded an unexpected benefit |
armies of systems administrators |
by darpa under afrl |
there is a need |
of systems administrators and |
darpa under afrl grant |
is a need to |
systems administrators and specialists |
under afrl grant radc |
it enables what we |
a need to mask |
afrl grant radc back |
enables what we are |
need to mask loss |
grant radc back changes |
what we are calling |
and were extremely insecure |
to mask loss on |
we are calling live |
mask loss on the |
are calling live distributed |
loss on the link |
under the assurance that |
calling live distributed objects |
the total cost of |
on the link from |
the assurance that if |
total cost of ownership |
the link from the |
assurance that if bandwidth |
cost of ownership proved |
link from the commodity |
that if bandwidth becomes |
as the term suggests |
of ownership proved to |
from the commodity protocols |
if bandwidth becomes f |
ownership proved to be |
the commodity protocols running |
proved to be unexpectedly |
commodity protocols running at |
these are abstract data |
to be unexpectedly and |
protocols running at end |
are abstract data types |
be unexpectedly and unacceptably |
abstract data types in |
unexpectedly and unacceptably high |
data types in which |
types in which content |
in which content evolves |
which content evolves over |
content evolves over time |
and to do so |
to do so rapidly |
the lesson of the |
do so rapidly and |
lesson of the client |
so rapidly and transparently |
when an application binds |
an application binds to |
application binds to a |
binds to a live |
to a live object |
server era is that |
era is that incomplete |
is that incomplete platforms |
that incomplete platforms can |
because recovery delays for |
incomplete platforms can t |
the current state of |
recovery delays for lost |
platforms can t support |
current state of the |
delays for lost packets |
can t support major |
state of the object |
for lost packets translate |
of the object is |
lost packets translate into |
the object is imported |
packets translate into dramatic |
object is imported and |
translate into dramatic reductions |
is imported and the |
into dramatic reductions in |
imported and the object |
dramatic reductions in application |
my concern is that |
and the object can |
concern is that the |
the object can send |
is that the web |
object can send and |
that the web services |
can send and receive |
the web services community |
send and receive updates |
web services community is |
and receive updates at |
because applications and os |
services community is about |
receive updates at high |
applications and os networking |
community is about to |
updates at high data |
and os networking stacks |
is about to face |
at high data rates |
os networking stacks in |
about to face the |
networking stacks in commodity |
and by afosr under |
to face the same |
stacks in commodity data |
by afosr under muri |
face the same problem |
in commodity data centers |
an object could be |
afosr under muri grant |
commodity data centers cannot |
object could be a |
under muri grant f |
data centers cannot be |
platform developers are racing |
could be a place |
centers cannot be rewritten |
developers are racing forward |
be a place in |
cannot be rewritten from |
are racing forward at |
a place in a |
be rewritten from scratch |
racing forward at top |
forward at top speed |
place in a game |
in a game like |
a game like second |
game like second life |
jostling for position with |
for position with ever |
position with ever more |
with ever more exaggerated |
ever more exaggerated claims |
while closing their eyes |
closing their eyes to |
their eyes to the |
side appliance receiver buffer |
eyes to the dangerous |
appliance receiver buffer overflow |
to the dangerous potholes |
the dangerous potholes in |
dangerous potholes in the |
potholes in the road |
in the road ahead |
local recovery locations of |
recovery locations of packet |
locations of packet loss |
of packet loss receive |
architectural standards for scalability |
side appliance receiving end |
standards for scalability to |
for scalability to properly |
live objects are a |
scalability to properly address |
objects are a natural |
to properly address scalability |
are a natural and |
properly address scalability in |
a natural and powerful |
address scalability in web |
natural and powerful idea |
scalability in web services |
maelstrom communication path forward |
communication path forward error |
path forward error correction |
we need more than |
and we plan to |
need more than a |
we plan to pursue |
more than a long |
plan to pursue the |
than a long list |
to pursue the concept |
is a promising solution |
a long list of |
pursue the concept in |
a promising solution for |
long list of reliability |
the concept in future |
promising solution for reliability |
list of reliability and |
concept in future work |
solution for reliability over |
of reliability and management |
for reliability over long |
reliability and management standards |
we need a new |
need a new methodology |
a new methodology suitable |
rather than the foreground |
this use of qsm |
new methodology suitable for |
than the foreground ones |
use of qsm raises |
methodology suitable for supporting |
of qsm raises performance |
suitable for supporting a |
qsm raises performance and |
packet recovery latency is |
raises performance and scalability |
for supporting a scalable |
additional support from microsoft |
recovery latency is independent |
performance and scalability issues |
supporting a scalable data |
support from microsoft research |
latency is independent of |
and scalability issues beyond |
a scalable data center |
from microsoft research and |
is independent of the |
scalability issues beyond the |
scalable data center architecture |
microsoft research and from |
independent of the rtt |
of the rtt of |
research and from the |
issues beyond the ones |
the rtt of the |
and from the intel |
beyond the ones seen |
rtt of the link |
from the intel corporation |
the ones seen in |
ones seen in our |
seen in our original |
in our original target |
while fec codes have |
our original target domain |
fec codes have been |
codes have been used |
have been used for |
been used for decades |
used for decades within |
for decades within link |
application programs background processing |
programs background processing incoming |
background processing incoming traffic |
processing incoming traffic cache |
we leave detailed discussion |
faster commodity processors have |
incoming traffic cache consistency |
leave detailed discussion of |
traffic cache consistency demand |
commodity processors have enabled |
cache consistency demand fetch |
detailed discussion of the |
consistency demand fetch access |
processors have enabled packet |
demand fetch access monitoring |
discussion of the idea |
fetch access monitoring prefetch |
along with pat helland |
of the idea for |
access monitoring prefetch outgoing |
with pat helland and |
monitoring prefetch outgoing traffic |
the idea for the |
prefetch outgoing traffic synchronous |
pat helland and dennis |
level fec at end |
idea for the future |
outgoing traffic synchronous writeback |
helland and dennis shasha |
traffic synchronous writeback update |
synchronous writeback update logging |
writeback update logging asynchronous |
qsm has been available |
update logging asynchronous writeback |
recommends that developers think |
has been available for |
logging asynchronous writeback mfs |
that developers think in |
been available for free |
asynchronous writeback mfs server |
developers think in terms |
available for free download |
writeback mfs server adaptive |
think in terms of |
for free download since |
mfs server adaptive rpc |
in terms of a |
free download since mid |
server adaptive rpc library |
terms of a reliable |
adaptive rpc library mfs |
of a reliable arraystructured |
rpc library mfs cache |
a reliable arraystructured partitioned |
library mfs cache manager |
reliable arraystructured partitioned service |
mfs cache manager will |
cache manager will be |
manager will be penalised |
will be penalised first |
modeless adaptation using prioritised |
implemented as a set |
adaptation using prioritised communication |
as a set of |
using prioritised communication also |
a set of reliable |
prioritised communication also allows |
set of reliable arraystructured |
communication also allows mfs |
of reliable arraystructured clustered |
end fec is very |
and it has a |
also allows mfs to |
reliable arraystructured clustered servers |
fec is very attractive |
it has a number |
allows mfs to be |
is very attractive for |
has a number of |
mfs to be more |
very attractive for communication |
a number of users |
to be more flexible |
attractive for communication between |
be more flexible in |
for communication between data |
more flexible in response |
communication between data centers |
most working on clustered |
flexible in response to |
working on clustered computing |
this architecture offers scalability |
in response to bandwidth |
architecture offers scalability and |
response to bandwidth variations |
offers scalability and reliability |
to bandwidth variations than |
easy to deploy and |
scalability and reliability at |
bandwidth variations than would |
to deploy and customize |
and reliability at two |
one large project is |
variations than would be |
reliability at two levels |
large project is pairing |
than would be possible |
and does not require |
project is pairing qsm |
would be possible with |
does not require specialized |
is pairing qsm with |
the top level uses |
be possible with a |
not require specialized equipment |
pairing qsm with high |
top level uses some |
possible with a modal |
require specialized equipment in |
level uses some sort |
with a modal scheme |
specialized equipment in the |
uses some sort of |
speed event stream filtering |
equipment in the network |
some sort of application |
event stream filtering and |
in the network linking |
stream filtering and data |
the network linking the |
filtering and data mining |
network linking the data |
specific key to partition |
mfs incorporates a new |
and data mining system |
linking the data centers |
key to partition the |
incorporates a new cache |
data mining system to |
to partition the service |
a new cache consistency |
mining system to obtain |
partition the service into |
new cache consistency algorithm |
system to obtain a |
the service into subservices |
endhost fec has two |
cache consistency algorithm to |
to obtain a scalable |
fec has two major |
consistency algorithm to efficiently |
has two major issues |
the lower level implements |
algorithm to efficiently provide |
two major issues first |
lower level implements subservices |
to efficiently provide a |
level implements subservices using |
efficiently provide a high |
implements subservices using groups |
hosted service capable of |
provide a high degree |
it s not transparent |
subservices using groups of |
service capable of handling |
a high degree of |
using groups of programs |
capable of handling very |
high degree of consistency |
requiring modification of the |
groups of programs that |
of handling very high |
degree of consistency for |
modification of the end |
of programs that run |
handling very high event |
of consistency for access |
programs that run on |
very high event rates |
consistency for access to |
that run on multiple |
for access to shared |
run on multiple machines |
access to shared files |
perhaps in a cluster |
which is required for |
in a cluster computer |
is required for collaborative |
group used for system |
it s not necessarily |
used for system management |
s not necessarily rapid |
the groups replicate data |
for system management service |
required for collaborative work |
groups replicate data so |
system management service b |
for collaborative work applications |
fec works best over |
replicate data so that |
management service b x |
works best over high |
data so that each |
service b x y |
the rest of this |
b x y z |
so that each can |
rest of this paper |
x y z x |
stable traffic rates and |
that each can handle |
of this paper is |
y z x y |
traffic rates and performs |
each can handle any |
this paper is organised |
z x y z |
rates and performs poorly |
can handle any incoming |
paper is organised as |
x y z x |
and performs poorly if |
handle any incoming query |
is organised as follows |
y z x y |
performs poorly if the |
any incoming query for |
z x y z |
poorly if the data |
incoming query for its |
x y z a |
if the data rate |
query for its range |
y z a b |
the data rate in |
for its range within |
describes the mfs design |
z a b service |
data rate in the |
its range within the |
the mfs design and |
a b service c |
rate in the channel |
range within the keys |
mfs design and differences |
b service c a |
in the channel is |
design and differences from |
service c a b |
the channel is low |
and differences from existing |
c a b w |
enabling updates to reach |
channel is low and |
differences from existing distributed |
a b w figure |
updates to reach all |
is low and sporadic |
from existing distributed and |
to reach all the |
existing distributed and mobile |
reach all the replicas |
distributed and mobile file |
and mobile file systems |
if sets of components |
sets of components are |
of components are replicated |
as well as giving |
well as giving an |
as giving an overview |
giving an overview of |
an overview of the |
overview of the mfs |
of the mfs rpc |
the associated multicast groups |
the mfs rpc library |
associated multicast groups overlap |
a raps that an |
multicast groups overlap hierarchically |
raps that an e |
as in a single |
in a single end |
the foregoing is the |
foregoing is the primary |
tailer such as amazon |
describes the use of |
is the primary use |
such as amazon might |
the use of prioritised |
the primary use scenario |
as amazon might use |
use of prioritised communication |
primary use scenario for |
amazon might use to |
of prioritised communication in |
use scenario for qsm |
might use to personalize |
prioritised communication in mfs |
we present the maelstrom |
use to personalize a |
communication in mfs and |
present the maelstrom error |
to personalize a product |
in mfs and experiments |
but may not be |
the maelstrom error correction |
personalize a product recommendation |
mfs and experiments to |
may not be the |
maelstrom error correction appliance |
and experiments to evaluate |
not be the only |
error correction appliance a |
experiments to evaluate its |
be the only one |
depending on the customer |
correction appliance a rack |
to evaluate its effectiveness |
on the customer s |
appliance a rack of |
the customer s profile |
a rack of proxies |
one could imagine an |
rack of proxies residing |
could imagine an approach |
of proxies residing between |
imagine an approach to |
proxies residing between a |
an approach to laying |
the service ranks matching |
residing between a data |
presents and explains experimental |
approach to laying out |
service ranks matching products |
between a data center |
and explains experimental results |
to laying out components |
ranks matching products differently |
a data center and |
explains experimental results for |
laying out components on |
matching products differently to |
data center and its |
experimental results for the |
out components on a |
products differently to maximize |
center and its wan |
results for the mfs |
components on a cluster |
differently to maximize the |
and its wan link |
for the mfs prefetching |
on a cluster that |
to maximize the chance |
the mfs prefetching mechanism |
a cluster that would |
maximize the chance of |
cluster that would result |
the chance of a |
that would result in |
chance of a purchase |
would result in irregular |
result in irregular layouts |
in irregular layouts of |
does the same for |
irregular layouts of groups |
if the product is |
the same for the |
same for the cache |
maelstrom encodes fec packets |
for the cache consistency |
encodes fec packets over |
qsm can support such |
the cache consistency algorithm |
fec packets over traffic |
can support such layouts |
packets over traffic flowing |
over traffic flowing through |
traffic flowing through it |
flowing through it and |
through it and routes |
it and routes them |
as shown in figure |
and routes them to |
at least to a |
routes them to a |
least to a degree |
them to a corresponding |
concludes and describes future |
to a corresponding appliance |
and describes future work |
a corresponding appliance at |
corresponding appliance at the |
but for reasons of |
appliance at the destination |
the service assigns the |
for reasons of brevity |
at the destination data |
service assigns the search |
reasons of brevity the |
the destination data center |
assigns the search request |
of brevity the discussion |
the search request to |
brevity the discussion in |
search request to the |
which decodes them and |
the discussion in the |
request to the racs |
decodes them and recovers |
discussion in the remainder |
the most important part |
to the racs handling |
them and recovers lost |
in the remainder of |
most important part of |
the racs handling all |
and recovers lost data |
the remainder of the |
important part of mfs |
racs handling all ds |
remainder of the paper |
part of mfs is |
maelstrom is completely transparent |
of the paper focuses |
of mfs is the |
is completely transparent it |
the paper focuses on |
mfs is the cache |
completely transparent it does |
paper focuses on regular |
is the cache manager |
transparent it does not |
such as the customer |
it does not require |
as the customer s |
does not require modification |
the customer s name |
hierarchically structured communication groups |
not require modification of |
which intercepts file system |
customer s name are |
structured communication groups with |
require modification of end |
intercepts file system operations |
s name are equally |
communication groups with extensive |
file system operations from |
name are equally plausible |
groups with extensive and |
host software and is |
system operations from application |
with extensive and regular |
software and is agnostic |
operations from application programs |
extensive and regular overlap |
and is agnostic to |
from application programs and |
is agnostic to the |
application programs and resolves |
agnostic to the network |
the load balancer then |
programs and resolves them |
to the network connecting |
initial users of our |
load balancer then routes |
and resolves them into |
the network connecting the |
users of our system |
balancer then routes the |
resolves them into accesses |
network connecting the data |
of our system haven |
then routes the request |
them into accesses to |
connecting the data centers |
our system haven t |
routes the request to |
into accesses to its |
system haven t had |
the request to the |
accesses to its local |
haven t had any |
request to the appropriate |
to its local mfs |
it eliminates the dependence |
to the appropriate program |
t had any difficulty |
its local mfs cache |
eliminates the dependence of |
the appropriate program for |
had any difficulty with |
local mfs cache or |
the dependence of fec |
appropriate program for processing |
any difficulty with this |
mfs cache or rpcs |
dependence of fec recovery |
program for processing in |
difficulty with this constraint |
cache or rpcs to |
of fec recovery latency |
for processing in this |
or rpcs to a |
fec recovery latency on |
processing in this case |
rpcs to a server |
knowing qsm is particularly |
recovery latency on the |
qsm is particularly effective |
latency on the data |
is particularly effective with |
on the data rate |
particularly effective with regular |
the cache manager has |
the data rate in |
effective with regular layouts |
cache manager has a |
data rate in any |
with support for this |
manager has a number |
rate in any single |
in any single node |
has a number of |
support for this basic |
they just design to |
a number of components |
for this basic layout |
just design to favor |
design to favor regularity |
node channel by encoding |
those in solid boxes |
channel by encoding over |
it s possible to |
in solid boxes are |
by encoding over the |
s possible to tackle |
solid boxes are part |
encoding over the aggregated |
possible to tackle a |
usage cases architecture reliable |
boxes are part of |
over the aggregated traffic |
to tackle a wide |
cases architecture reliable multicast |
are part of the |
the aggregated traffic leaving |
tackle a wide range |
architecture reliable multicast is |
part of the core |
aggregated traffic leaving the |
a wide range of |
reliable multicast is a |
of the core system |
traffic leaving the data |
wide range of secondary |
multicast is a mature |
leaving the data center |
range of secondary issues |
is a mature area |
those in dashed boxes |
in dashed boxes are |
dashed boxes are optional |
boxes are optional extensions |
are optional extensions which |
optional extensions which are |
extensions which are described |
maelstrom uses a new |
but a review of |
which are described in |
uses a new encoding |
we could create standards |
a review of prior |
are described in subsequent |
a new encoding scheme |
could create standards for |
review of prior systems |
described in subsequent sections |
new encoding scheme called |
create standards for a |
of prior systems convinced |
encoding scheme called layered |
standards for a self |
prior systems convinced us |
scheme called layered interleaving |
systems convinced us that |
convinced us that no |
us that no existing |
mfs overview mfs differs |
managed raps of racs |
that no existing system |
designed especially for time |
overview mfs differs from |
no existing system would |
mfs differs from earlier |
or for one that |
differs from earlier mobile |
existing system would work |
for one that guarantees |
sensitive packet recovery in |
from earlier mobile file |
system would work well |
one that guarantees real |
packet recovery in the |
earlier mobile file systems |
would work well in |
recovery in the presence |
mobile file systems in |
work well in the |
in the presence of |
file systems in adjusting |
well in the scenarios |
the presence of bursty |
systems in adjusting to |
in the scenarios targeted |
such a basic architecture |
presence of bursty loss |
in adjusting to changing |
the scenarios targeted by |
a basic architecture is |
adjusting to changing network |
scenarios targeted by our |
maelstrom s positioning as |
to changing network conditions |
basic architecture is effectively |
targeted by our project |
s positioning as a |
changing network conditions using |
architecture is effectively a |
positioning as a network |
network conditions using modeless |
is effectively a framework |
this forced us to |
conditions using modeless adaptation |
as a network appliance |
effectively a framework to |
forced us to build |
a network appliance reflects |
a framework to resolve |
us to build a |
network appliance reflects the |
framework to resolve other |
it comprises a core |
to build a new |
appliance reflects the physical |
to resolve other related |
comprises a core client |
build a new system |
reflects the physical infrastructure |
resolve other related issues |
a new system that |
the physical infrastructure of |
new system that combines |
physical infrastructure of modern |
system that combines features |
infrastructure of modern data |
that combines features from |
and a number of |
of modern data centers |
combines features from a |
a number of subsystems |
modern data centers clean |
features from a number |
group replication web services |
number of subsystems that |
data centers clean insertion |
from a number of |
replication web services currently |
of subsystems that perform |
centers clean insertion points |
a number of prior |
web services currently lacks |
subsystems that perform different |
clean insertion points for |
number of prior systems |
services currently lacks support |
that perform different kinds |
insertion points for proxy |
currently lacks support for |
perform different kinds of |
points for proxy devices |
lacks support for building |
different kinds of adaptation |
our decision not to |
for proxy devices exist |
support for building scalable |
and can be selectively |
proxy devices exist on |
devices exist on the |
for building scalable services |
can be selectively enabled |
decision not to use |
exist on the high |
not to use some |
to use some existing |
the architecture makes it |
speed lambda links that |
use some existing multicast |
architecture makes it easy |
lambda links that interconnect |
shows the structure of |
the structure of the |
makes it easy to |
links that interconnect individual |
some existing multicast system |
structure of the system |
it easy to build |
that interconnect individual data |
existing multicast system reflects |
easy to build a |
interconnect individual data centers |
multicast system reflects a |
in this section we |
to build a single |
individual data centers to |
data centers to each |
this section we describe |
system reflects a number |
centers to each other |
node server that responds |
reflects a number of |
section we describe the |
server that responds to |
a number of issues |
maelstrom can operate as |
we describe the core |
that responds to requests |
can operate as either |
describe the core system |
responds to requests from |
operate as either a |
to requests from some |
as either a passive |
requests from some set |
either a passive or |
from some set of |
while subsequent sections do |
a passive or active |
some set of clients |
most prior multicast systems |
passive or active device |
subsequent sections do the |
prior multicast systems were |
or active device on |
sections do the same |
multicast systems were designed |
active device on these |
systems were designed to |
do the same for |
but there s no |
device on these links |
were designed to replicate |
the same for the |
designed to replicate state |
there s no way |
same for the three |
of the three problems |
the three problems of |
s no way to |
for the three main |
the three main subsystems |
three problems of tcp |
no way to turn |
to replicate state within |
way to turn that |
replicate state within just |
we begin with an |
to turn that single |
state within just a |
begin with an overview |
maelstrom solves the first |
turn that single server |
within just a single |
with an overview of |
solves the first two |
that single server into |
just a single group |
an overview of mobile |
the first two throughput |
single server into a |
a single group at |
overview of mobile file |
first two throughput collapse |
server into a racs |
single group at a |
of mobile file system |
two throughput collapse and |
into a racs or |
group at a time |
mobile file system design |
throughput collapse and realtime |
a racs or turn |
file system design and |
collapse and realtime recovery |
racs or turn a |
system design and the |
and realtime recovery delays |
or turn a set |
design and the relation |
realtime recovery delays while |
turn a set of |
and the relation of |
for example a single |
recovery delays while operating |
a set of racs |
the relation of mfs |
example a single distributed |
delays while operating as |
set of racs into |
relation of mfs to |
of mfs to previous |
while operating as a |
of racs into a |
racs into a raps |
mfs to previous work |
operating as a passive |
a single distributed service |
as a passive device |
a passive device that |
passive device that does |
device that does not |
then briefly describe the |
that does not intervene |
briefly describe the adaptive |
does not intervene in |
describe the adaptive rpc |
it would be easy |
not intervene in the |
the adaptive rpc library |
some don t support |
intervene in the critical |
would be easy to |
adaptive rpc library used |
rpc library used in |
in the critical communication |
be easy to bridge |
don t support multiple |
library used in mfs |
the critical communication path |
easy to bridge the |
t support multiple groups |
to bridge the gap |
and the current mfs |
the current mfs implementation |
bridge the gap if |
support multiple groups at |
the gap if vendors |
multiple groups at all |
maelstrom handles the additional |
gap if vendors and |
handles the additional problem |
if vendors and platform |
the additional problem of |
vendors and platform builders |
additional problem of massive |
and platform builders wanted |
problem of massive buffering |
platform builders wanted to |
of massive buffering requirements |
builders wanted to do |
wanted to do so |
massive buffering requirements as |
buffering requirements as well |
mfs design and related |
while others have overheads |
design and related work |
others have overheads linear |
at the cost of |
have overheads linear in |
structured partitioned service reliable |
overheads linear in the |
and related work the |
the cost of adding |
partitioned service reliable array |
linear in the number |
related work the core |
cost of adding a |
in the number of |
work the core of |
the number of groups |
of adding a point |
number of groups to |
the core of mfs |
adding a point of |
of groups to which |
core of mfs follows |
a point of failure |
groups to which a |
of mfs follows a |
point of failure in |
of failure in the |
mfs follows a design |
to which a node |
failure in the network |
follows a design common |
which a node belongs |
in the network path |
a design common to |
design common to many |
common to many mobile |
to many mobile file |
many mobile file systems |
x y z search |
the contributions of this |
y z search for |
contributions of this paper |
z search for digital |
of this paper are |
search for digital camera |
this paper are as |
for digital camera figure |
paper are as follows |
we looked at jgroups |
example of raps of |
of raps of racs |
end fec for long |
the service assigns a |
distance communication between data |
service assigns a digital |
communication between data centers |
assigns a digital camera |
a digital camera search |
digital camera search request |
camera search request to |
search request to the |
and argue that the |
request to the clustered |
argue that the rate |
to the clustered server |
that the rate sensitivity |
the clustered server handling |
the rate sensitivity of |
clustered server handling all |
rate sensitivity of fec |
server handling all ds |
sensitivity of fec codes |
of fec codes and |
fec codes and the |
codes and the opacity |
and the opacity of |
the opacity of their |
and a load balancer |
a component of the |
opacity of their implementations |
component of the jboss |
a load balancer routes |
of their implementations present |
load balancer routes it |
balancer routes it to |
their implementations present major |
which use techniques such |
of the jboss platform |
routes it to the |
implementations present major obstacles |
use techniques such as |
the jboss platform which |
it to the appropriate |
present major obstacles to |
techniques such as wholefile |
to the appropriate process |
jboss platform which runs |
major obstacles to their |
such as wholefile caching |
platform which runs in |
obstacles to their usage |
old and familiar technologies |
which runs in a |
and familiar technologies the |
and update logging combined |
update logging combined with |
familiar technologies the most |
runs in a managed |
logging combined with asynchronous |
technologies the most standard |
a gateway appliance that |
in a managed java |
combined with asynchronous writes |
the most standard form |
gateway appliance that transparently |
a managed java framework |
most standard form of |
appliance that transparently aggregates |
to cope with disconnections |
standard form of system |
that transparently aggregates traffic |
cope with disconnections or |
form of system support |
transparently aggregates traffic and |
with disconnections or intermittent |
of system support for |
jgroups wasn t designed |
disconnections or intermittent connectivity |
aggregates traffic and encodes |
system support for building |
wasn t designed to |
traffic and encodes over |
support for building a |
t designed to support |
and encodes over the |
the design of mfs |
for building a raps |
designed to support large |
encodes over the resulting |
design of mfs is |
building a raps of |
over the resulting high |
to support large numbers |
of mfs is closest |
a raps of racs |
support large numbers of |
mfs is closest in |
raps of racs would |
large numbers of overlapping |
is closest in structure |
of racs would draw |
we describe layered interleaving |
numbers of overlapping groups |
closest in structure to |
racs would draw on |
in structure to that |
would draw on virtual |
a new fec scheme |
structure to that of |
draw on virtual synchrony |
new fec scheme used |
to that of coda |
fec scheme used by |
and if configured to |
scheme used by maelstrom |
if configured to do |
used by maelstrom where |
configured to do so |
by maelstrom where for |
group computing model developed |
maelstrom where for constant |
computing model developed at |
where for constant encoding |
model developed at cornell |
for constant encoding overhead |
developed at cornell in |
constant encoding overhead the |
at cornell in the |
encoding overhead the latency |
overhead the latency of |
the latency of packet |
latency of packet recovery |
of packet recovery degrades |
packet recovery degrades gracefully |
recovery degrades gracefully as |
degrades gracefully as losses |
gracefully as losses get |
as losses get burstier |
there has been a |
has been a great |
we discuss implementation considerations |
been a great deal |
a great deal of |
great deal of work |
we built two versions |
s and used today |
built two versions of |
two versions of maelstrom |
and used today to |
deal of work on |
used today to run |
of work on p |
today to run the |
one runs in user |
runs in user mode |
to run the new |
run the new york |
the new york and |
new york and swiss |
york and swiss stock |
while the other runs |
and swiss stock exchange |
the other runs within |
a host acting as |
swiss stock exchange systems |
other runs within the |
runs within the linux |
host acting as a |
p pubsub and content |
within the linux kernel |
acting as a client |
the french air traffic |
pubsub and content delivery |
as a client of |
french air traffic control |
air traffic control system |
we evaluate maelstrom on |
a client of an |
and content delivery platforms |
evaluate maelstrom on emulab |
and the us navy |
the us navy s |
client of an mfs |
content delivery platforms in |
us navy s aegis |
of an mfs file |
an mfs file system |
mfs file system runs |
file system runs a |
system runs a user |
delivery platforms in recent |
platforms in recent years |
and show that it |
ibm s websphere platform |
show that it provides |
s websphere platform and |
that it provides near |
websphere platform and the |
which receives file system |
it provides near lossless |
platform and the windows |
receives file system operations |
often oriented towards content |
provides near lossless tcp |
and the windows vista |
file system operations intercepted |
oriented towards content filtering |
the windows vista clustering |
system operations intercepted by |
towards content filtering in |
ip throughput and latency |
windows vista clustering system |
operations intercepted by a |
content filtering in document |
throughput and latency over |
vista clustering system also |
intercepted by a kernel |
by a kernel module |
and latency over lossy |
clustering system also use |
filtering in document streams |
latency over lossy links |
interacting with the vfs |
system also use versions |
with the vfs layer |
also use versions of |
the vfs layer of |
and recovers packets with |
use versions of the |
vfs layer of the |
recovers packets with latency |
versions of the model |
layer of the local |
packets with latency independent |
a good example is |
of the local file |
with latency independent of |
although developers can t |
the local file system |
good example is siena |
latency independent of the |
developers can t access |
independent of the rtt |
can t access the |
of the rtt of |
we adopt the same |
t access the internal |
the rtt of the |
adopt the same approach |
access the internal mechanisms |
rtt of the link |
a system that has |
the internal mechanisms directly |
the same approach to |
of the link and |
system that has become |
same approach to intercepting |
the link and the |
that has become popular |
approach to intercepting vfs |
the other popular standard |
link and the rate |
has become popular in |
to intercepting vfs operations |
become popular in wan |
and the rate in |
other popular standard uses |
intercepting vfs operations as |
vfs operations as lbfs |
the rate in any |
popular standard uses a |
standard uses a state |
rate in any single |
in any single channel |
popular in wan settings |
making use of the |
use of the kernel |
machine approach to guarantee |
of the kernel module |
approach to guarantee stronger |
the kernel module provided |
to guarantee stronger durability |
kernel module provided as |
m odel loss model |
module provided as part |
provided as part of |
as part of the |
part of the arla |
leslie lamport s paxos |
packet loss typically occurs |
of the arla afs |
lamport s paxos algorithm |
loss typically occurs at |
the arla afs client |
typically occurs at two |
occurs at two points |
at two points in |
two points in an |
points in an end |
which is implemented in |
is implemented in scalable |
implemented in scalable file |
in scalable file systems |
scalable file systems and |
file systems and other |
systems and other ultrareliable |
and other ultrareliable server |
other ultrareliable server designs |
end communication path between |
communication path between two |
path between two data |
between two data centers |
as shown in figure |
one architecture could support |
the cache manager maintains |
architecture could support both |
cache manager maintains a |
could support both of |
manager maintains a cache |
maintains a cache of |
support both of these |
both of these powerful |
a cache of recently |
systems in this class |
area network connecting them |
of these powerful technologies |
in this class incur |
network connecting them and |
accessed mfs files on |
this class incur steep |
a natural option would |
mfs files on the |
connecting them and at |
them and at the |
natural option would be |
files on the local |
on the local disk |
and at the receiving |
option would be to |
class incur steep overheads |
at the receiving end |
would be to offer |
incur steep overheads associated |
when a vfs operation |
be to offer them |
steep overheads associated with |
a vfs operation is |
to offer them in |
loss in the lambda |
vfs operation is intercepted |
overheads associated with content |
offer them in the |
in the lambda link |
operation is intercepted for |
associated with content filtering |
them in the context |
the lambda link can |
is intercepted for a |
in the context of |
lambda link can occur |
intercepted for a file |
the context of ws |
link can occur for |
for a file that |
can occur for many |
a file that is |
occur for many reasons |
file that is not |
that is not in |
is not in the |
not in the cache |
messages often follow circuitous |
it is retrieved in |
often follow circuitous routes |
is retrieved in full |
follow circuitous routes from |
retrieved in full from |
circuitous routes from source |
dirty or degraded fiber |
in full from the |
full from the appropriate |
from the appropriate server |
if you re replicating |
routes from source to |
you re replicating data |
malfunctioning or misconfigured equipment |
and the vfs operation |
re replicating data within |
from source to destination |
the vfs operation is |
low receiver power and |
replicating data within some |
vfs operation is then |
receiver power and burst |
data within some form |
operation is then resumed |
power and burst switching |
within some form of |
and burst switching contention |
some form of group |
burst switching contention are |
mfs uses the writeback |
switching contention are some |
contention are some reasons |
you can just as |
can just as easily |
in high performance settings |
just as easily imagine |
as easily imagine that |
close semantics first implemented |
easily imagine that it |
semantics first implemented in |
imagine that it has |
first implemented in the |
that it has a |
implemented in the andrew |
it has a subject |
in the andrew file |
has a subject name |
a subject name in |
the andrew file system |
these factors would degrade |
subject name in a |
name in a publish |
factors would degrade the |
would degrade the performance |
degrade the performance of |
the performance of the |
performance of the replicated |
of the replicated application |
advantages with this type |
with this type of |
this type of process |
when a dirty file |
a dirty file is |
dirty file is closed |
the spread multicast system |
the entire file contents |
spread multicast system implements |
data can be anything |
entire file contents are |
file contents are transferred |
multicast system implements lightweight |
contents are transferred to |
system implements lightweight groups |
are transferred to the |
transferred to the server |
though scheme for minimising |
scheme for minimising bandwidth |
for minimising bandwidth utilisation |
minimising bandwidth utilisation when |
bandwidth utilisation when transferring |
utilisation when transferring files |
when transferring files is |
transferring files is not |
files is not used |
is not used in |
not used in mfs |
loss can also occur |
can also occur at |
also occur at receiving |
w e b te |
although it is orthogonal |
occur at receiving end |
e b te c |
it is orthogonal to |
b te c h |
is orthogonal to mfs |
te c h n |
hosts within the destination |
c h n o |
orthogonal to mfs adaptation |
h n o l |
within the destination data |
n o l o |
to mfs adaptation and |
o l o g |
the destination data center |
l o g i |
mfs adaptation and could |
o g i e |
adaptation and could be |
g i e s |
and could be added |
i e s concerns |
these are usually cheap |
could be added to |
e s concerns experience |
are usually cheap commodity |
be added to further |
s concerns experience with |
usually cheap commodity machines |
added to further improve |
to further improve performance |
concerns experience with corba |
cheap commodity machines prone |
the groups seen by |
experience with corba even |
commodity machines prone to |
groups seen by applications |
the server that stores |
with corba even good |
machines prone to temporary |
seen by applications are |
server that stores a |
corba even good ideas |
prone to temporary overloads |
by applications are an |
that stores a file |
even good ideas can |
to temporary overloads that |
applications are an illusion |
stores a file is |
good ideas can be |
temporary overloads that cause |
a file is responsible |
ideas can be used |
overloads that cause packets |
file is responsible for |
can be used in |
that cause packets to |
is responsible for maintaining |
be used in ways |
cause packets to be |
responsible for maintaining the |
used in ways that |
packets to be dropped |
there is really only |
for maintaining the mutual |
in ways that developers |
to be dropped by |
is really only one |
maintaining the mutual consistency |
ways that developers dislike |
be dropped by the |
really only one use |
the mutual consistency of |
that developers dislike and |
dropped by the kernel |
by the kernel in |
mutual consistency of the |
developers dislike and ultimately |
dislike and ultimately reject |
the kernel in bursts |
consistency of the copies |
only one use of |
of the copies cached |
the copies cached by |
copies cached by clients |
one use of qsm |
a good example of |
use of qsm in |
good example of this |
of qsm in our |
example of this occurred |
it records which clients |
of this occurred when |
records which clients cache |
which clients cache the |
this occurred when the |
this loss mode occurs |
clients cache the file |
qsm in our target |
occurred when the corba |
in our target settings |
loss mode occurs with |
our target settings gives |
and is responsible for |
target settings gives rise |
when the corba community |
mode occurs with udp |
is responsible for notifying |
settings gives rise to |
the corba community decided |
responsible for notifying them |
corba community decided to |
based traffic but not |
community decided to tackle |
gives rise to potentially |
for notifying them of |
traffic but not with |
decided to tackle replication |
rise to potentially large |
notifying them of changes |
but not with tcp |
to tackle replication for |
to potentially large numbers |
tackle replication for fault |
mfs implements a variation |
replication for fault tolerance |
potentially large numbers of |
implements a variation of |
for fault tolerance but |
which advertises receiver windows |
large numbers of overlapping |
a variation of the |
numbers of overlapping communication |
advertises receiver windows to |
fault tolerance but then |
variation of the scheme |
tolerance but then stumbled |
receiver windows to prevent |
of the scheme used |
the scheme used by |
but then stumbled by |
windows to prevent end |
of overlapping communication groups |
scheme used by coda |
then stumbled by presenting |
stumbled by presenting the |
by presenting the technology |
presenting the technology to |
when a file is |
what are typical loss |
the technology to developers |
a file is retrieved |
as we have seen |
technology to developers in |
are typical loss rates |
file is retrieved from |
to developers in a |
typical loss rates on |
is retrieved from the |
developers in a way |
loss rates on long |
retrieved from the server |
in a way that |
the primary goal is |
a way that was |
primary goal is to |
way that was much |
goal is to support |
the server issues a |
that was much too |
the answer to this |
is to support data |
server issues a limited |
was much too limiting |
answer to this question |
to support data replication |
much too limiting for |
to this question is |
support data replication in |
too limiting for general |
this question is surprisingly |
data replication in scalable |
limiting for general use |
question is surprisingly hard |
obliging it to inform |
is surprisingly hard to |
it to inform the |
to inform the client |
inform the client through |
the client through a |
client through a callback |
through a callback if |
a callback if another |
callback if another host |
if another host modifies |
tolerance mechanism is based |
another host modifies the |
mechanism is based on |
host modifies the file |
is based on the |
based on the virtual |
in which sets of |
on the virtual synchrony |
which sets of components |
the virtual synchrony model |
if the callback promise |
sets of components are |
the callback promise expires |
of components are interconnected |
callback promise expires without |
but the programming tools |
components are interconnected and |
promise expires without a |
the programming tools built |
are interconnected and cooperate |
expires without a callback |
programming tools built over |
interconnected and cooperate to |
without a callback being |
tools built over this |
and cooperate to perform |
a callback being issued |
built over this model |
cooperate to perform requests |
over this model prevent |
this model prevent developers |
model prevent developers from |
the client must revalidate |
prevent developers from using |
client must revalidate the |
developers from using threads |
must revalidate the file |
revalidate the file before |
the file before using |
file before using it |
the cache consistency algorithm |
cache consistency algorithm is |
consistency algorithm is described |
algorithm is described in |
is described in more |
described in more detail |
in more detail in |
more detail in section |
guis or other direct |
or other direct end |
components sets are normally |
sets are normally colocated |
when a service is |
a service is replicated |
adaptive rpc library the |
rpc library the fundamental |
library the fundamental difference |
the fundamental difference between |
fundamental difference between mfs |
each of its constituent |
difference between mfs and |
of its constituent components |
between mfs and other |
its constituent components will |
or even prebuilt libraries |
mfs and other file |
constituent components will need |
and other file systems |
components will need to |
other file systems we |
in the corba approach |
will need to replicate |
file systems we have |
need to replicate its |
systems we have described |
a developer who obeys |
to replicate its portion |
we have described is |
replicate its portion of |
developer who obeys this |
have described is in |
its portion of the |
who obeys this long |
described is in the |
portion of the service |
obeys this long list |
is in the communication |
of the service state |
this long list of |
in the communication between |
long list of constraints |
the communication between the |
list of constraints can |
communication between the cache |
of constraints can do |
between the cache manager |
if qsm is used |
constraints can do lockstep |
the cache manager and |
cache manager and servers |
can do lockstep replication |
qsm is used to |
do lockstep replication of |
is used to disseminate |
lockstep replication of a |
used to disseminate updates |
while lbfs uses a |
replication of a program |
lbfs uses a variant |
of a program for |
uses a variant of |
a program for tolerance |
a variant of the |
program for tolerance of |
variant of the nfs |
for tolerance of hardware |
tolerance of hardware faults |
of the nfs rpc |
the nfs rpc protocol |
this results in a |
results in a pattern |
in a pattern of |
a pattern of communication |
pattern of communication groups |
of communication groups that |
communication groups that are |
the scheme doesn t |
groups that are exactly |
scheme doesn t protect |
that are exactly overlapped |
doesn t protect against |
t protect against software |
of lost packets fig |
each replicated component will |
replicated component will have |
component will have one |
will have one or |
uses a customised rpc |
have one or more |
loss rates on teragrid |
developers regard the standard |
one or more associated |
rates on teragrid determine |
regard the standard as |
or more associated groups |
the standard as rigid |
unlike coda s rpc |
standard as rigid and |
perhaps because such links |
as rigid and limited |
because such links are |
such links are a |
the rpc used in |
delivering update streams to |
they need fault tolerance |
update streams to its |
links are a relatively |
rpc used in mfs |
are a relatively recent |
used in mfs incorporates |
but not in this |
a relatively recent addition |
streams to its replicas |
in mfs incorporates novel |
not in this very |
relatively recent addition to |
mfs incorporates novel features |
in this very narrow |
recent addition to the |
incorporates novel features to |
this very narrow form |
addition to the networking |
novel features to allow |
to the networking landscape |
features to allow it |
the networking landscape and |
to allow it to |
networking landscape and their |
allow it to adapt |
a datacenter will typically |
systems like the isis |
it to adapt to |
landscape and their ownership |
datacenter will typically host |
like the isis toolkit |
to adapt to network |
and their ownership is |
will typically host many |
adapt to network variability |
their ownership is still |
typically host many services |
popular during the early |
ownership is still mostly |
during the early and |
is still mostly restricted |
the mfs rpc library |
the early and mid |
still mostly restricted to |
mfs rpc library is |
each with a disjoint |
mostly restricted to commercial |
rpc library is implemented |
with a disjoint set |
restricted to commercial organizations |
library is implemented on |
a disjoint set of |
to commercial organizations disinclined |
is implemented on top |
disjoint set of components |
commercial organizations disinclined to |
implemented on top of |
organizations disinclined to reveal |
on top of the |
disinclined to reveal such |
top of the adaptive |
to reveal such information |
of the adaptive transport |
and often deployed on |
also used virtual synchrony |
the adaptive transport protocol |
often deployed on disjoint |
used virtual synchrony but |
one source of information |
deployed on disjoint sets |
virtual synchrony but had |
source of information is |
of information is teragrid |
synchrony but had fewer |
but had fewer limitations |
on disjoint sets of |
disjoint sets of nodes |
in discussing mfs rpc |
they supported many of |
supported many of the |
many of the mechanisms |
of the mechanisms needed |
we give an overview |
the mechanisms needed to |
give an overview of |
mechanisms needed to build |
in cases where two |
an overview of the |
needed to build and |
cases where two services |
overview of the parts |
to build and manage |
an optical network interconnecting |
where two services are |
of the parts of |
build and manage a |
optical network interconnecting major |
two services are co |
the parts of atp |
and manage a raps |
network interconnecting major supercomputing |
parts of atp which |
manage a raps of |
interconnecting major supercomputing sites |
of atp which are |
a raps of racs |
located on the same |
atp which are most |
major supercomputing sites in |
supercomputing sites in the |
which are most relevant |
are most relevant to |
sites in the us |
on the same node |
and their successes have |
most relevant to mfs |
their successes have clearly |
teragrid has a monitoring |
successes have clearly demonstrated |
has a monitoring framework |
have clearly demonstrated the |
a monitoring framework within |
atp and its design |
clearly demonstrated the model |
we ll still see |
monitoring framework within which |
and its design motivations |
demonstrated the model s |
the model s effectiveness |
framework within which ten |
its design motivations have |
ll still see heavy |
within which ten sites |
design motivations have been |
still see heavy overlap |
which ten sites periodically |
isis is no longer |
motivations have been described |
ten sites periodically send |
is no longer available |
have been described in |
sites periodically send each |
no longer available as |
but unless the degree |
periodically send each other |
been described in more |
longer available as a |
available as a product |
described in more detail |
unless the degree of |
in more detail in |
gbps streams of udp |
the degree of replication |
more detail in our |
streams of udp packets |
yet many critical systems |
degree of replication is |
detail in our earlier |
of udp packets and |
many critical systems continue |
of replication is identical |
in our earlier work |
udp packets and measure |
critical systems continue to |
packets and measure the |
systems continue to use |
and measure the resulting |
continue to use isis |
measure the resulting loss |
there may be two |
the resulting loss rate |
may be two cases |
based solutions or other |
solutions or other virtual |
or other virtual synchrony |
other virtual synchrony implementations |
the hypothesis underlying atp |
nodes that host both |
hypothesis underlying atp is |
that host both services |
underlying atp is that |
machine approach as used |
atp is that adapting |
approach as used in |
is that adapting to |
as used in the |
each site measures the |
that adapting to network |
used in the paxos |
site measures the loss |
and hence both sets |
adapting to network variation |
in the paxos algorithm |
measures the loss rate |
hence both sets of |
to network variation by |
the paxos algorithm is |
the loss rate to |
both sets of qsm |
network variation by structuring |
paxos algorithm is also |
loss rate to every |
sets of qsm groups |
variation by structuring applications |
algorithm is also becoming |
rate to every other |
by structuring applications according |
is also becoming more |
to every other site |
structuring applications according to |
also becoming more popular |
every other site once |
applications according to modes |
other site once an |
site once an hour |
according to modes is |
to modes is not |
modes is not always |
the key insight is |
is not always appropriate |
and nodes that just |
key insight is that |
resulting in a total |
in a total of |
insight is that these |
nodes that just host |
and can sometimes lead |
is that these successes |
that just host one |
can sometimes lead to |
that these successes use |
just host one of |
sometimes lead to poor |
loss rate measurements collected |
these successes use similar |
host one of them |
lead to poor performance |
rate measurements collected across |
successes use similar ideas |
measurements collected across the |
use similar ideas but |
collected across the network |
similar ideas but in |
across the network every |
ideas but in ways |
the network every hour |
cluster management systems use |
but in ways very |
shows the results of |
management systems use groups |
in ways very different |
the results of an |
systems use groups for |
ways very different from |
results of an experiment |
shows that between nov |
of an experiment in |
very different from what |
use groups for purposes |
an experiment in which |
different from what the |
groups for purposes other |
experiment in which modeless |
for purposes other than |
from what the corba |
in which modeless adaptation |
purposes other than component |
what the corba fault |
which modeless adaptation over |
other than component replication |
modeless adaptation over atp |
adaptation over atp achieves |
over atp achieves higher |
atp achieves higher bandwidth |
achieves higher bandwidth utilisation |
higher bandwidth utilisation than |
bandwidth utilisation than we |
such as tracking node |
utilisation than we will |
what we need today |
as tracking node status |
we need today is |
than we will concentrate |
tracking node status and |
we will concentrate on |
need today is a |
node status and launching |
today is a modern |
will concentrate on a |
status and launching applications |
concentrate on a system |
is a modern revisiting |
on a system with |
a system with a |
a modern revisiting of |
system with a single |
with a single server |
modern revisiting of this |
revisiting of this technology |
these groups will span |
of this technology that |
groups will span large |
mfs is designed to |
this technology that draws |
will span large numbers |
is designed to support |
technology that draws on |
span large numbers of |
designed to support multiple |
that draws on group |
large numbers of nodes |
to support multiple mfs |
of all such measurements |
draws on group communication |
support multiple mfs file |
on group communication but |
all such measurements were |
group communication but packages |
multiple mfs file servers |
communication but packages it |
perhaps the entire cluster |
such measurements were over |
but packages it in |
packages it in a |
it in a way |
in a way that |
modal adaptation modeless adaptation |
such groups overlap with |
a way that developers |
groups overlap with everything |
way that developers perceive |
that developers perceive as |
developers perceive as solving |
perceive as solving their |
as solving their most |
solving their most pressing |
the result is an |
their most pressing scalability |
true bandwidth bandwidth used |
result is an environment |
most pressing scalability problems |
is an environment in |
pressing scalability problems and |
an environment in which |
scalability problems and that |
of them were over |
environment in which there |
problems and that flexibly |
in which there will |
and that flexibly matches |
which there will be |
that flexibly matches their |
there will be a |
flexibly matches their preferred |
will be a hierarchy |
matches their preferred styles |
their preferred styles and |
preferred styles and tools |
after eliminating a single |
eliminating a single site |
other kinds of persistent |
kinds of persistent objects |
that dropped incoming packets |
dropped incoming packets steadily |
incoming packets steadily at |
packets steadily at a |
steadily at a rate |
at a rate of |
the user simply designs |
user simply designs a |
simply designs a data |
designs a data structure |
a data structure and |
data structure and employs |
structure and employs multicast |
and employs multicast technology |
employs multicast technology to |
multicast technology to transmit |
technology to transmit updates |
to transmit updates to |
transmit updates to the |
updates to the group |
to the group members |
which apply them in |
apply them in the |
them in the same |
in the same order |
the same order everywhere |
qsm is highly effective |
is highly effective in |
of the remainder were |
the remainder were over |
highly effective in supporting |
effective in supporting this |
in supporting this style |
can be done on |
supporting this style of |
be done on any |
this style of use |
done on any desired |
on any desired copy |
examples of updates include |
of updates include a |
updates include a stock |
include a stock trade |
a stock trade or |
stock trade or stock |
trade or stock market |
or stock market quote |
a new object detected |
new object detected by |
object detected by radar |
detected by radar in |
by radar in an |
radar in an air |
in an air traffic |
an air traffic control |
air traffic control system |
recover in y inter |
a communication to or |
communication to or from |
these numbers may look |
to or from an |
numbers may look small |
or from an aircraft |
may look small in |
look small in absolute |
small in absolute terms |
region protocol y intra |
or the addition of |
the addition of a |
but they are sufficient |
addition of a node |
they are sufficient to |
of a node to |
are sufficient to bring |
a node to a |
sufficient to bring tcp |
node to a distributed |
to a distributed data |
a distributed data structure |
distributed data structure containing |
ip throughput crashing down |
data structure containing an |
consisting of a small |
throughput crashing down on |
structure containing an index |
of a small set |
crashing down on high |
containing an index of |
a small set of |
an index of pending |
small set of servers |
index of pending orders |
set of servers to |
of pending orders in |
of servers to which |
pending orders in an |
servers to which client |
orders in an online |
conventional wisdom states that |
to which client systems |
in an online warehouse |
wisdom states that optical |
which client systems connect |
states that optical links |
that optical links do |
optical links do not |
links do not drop |
data replication can be |
do not drop packets |
replication can be remarkably |
can be remarkably cheap |
with modern technology and |
modern technology and small |
technology and small updates |
grade optical equipment is |
optical equipment is configured |
equipment is configured to |
is configured to shut |
level multicast is vectored |
configured to shut down |
multicast is vectored through |
to shut down beyond |
is vectored through a |
shut down beyond bit |
vectored through a server |
down beyond bit error |
beyond bit error rates |
bit error rates of |
computer chrony service can |
chrony service can run |
service can run at |
which multicasts it to |
can run at rates |
multicasts it to its |
run at rates well |
it to its peers |
at rates well in |
rates well in excess |
well in excess of |
one out of a |
out of a trillion |
of a trillion bits |
these filter the ordered |
filter the ordered multicast |
the ordered multicast stream |
the reliability of the |
ordered multicast stream and |
reliability of the lambda |
true bandwidth bandwidth used |
multicast stream and relay |
of the lambda network |
stream and relay messages |
the lambda network is |
and relay messages back |
lambda network is clearly |
relay messages back out |
network is clearly not |
messages back out to |
is clearly not equal |
back out to receivers |
clearly not equal to |
not equal to the |
equal to the sum |
to the sum of |
the sum of its |
sum of its optical |
of its optical parts |
this approach can support |
approach can support huge |
it s less reliable |
ordered updates per second |
can support huge numbers |
s less reliable by |
support huge numbers of |
less reliable by orders |
even if an update |
reliable by orders of |
by orders of magnitude |
if an update requires |
huge numbers of groups |
an update requires a |
numbers of groups with |
update requires a large |
requires a large message |
of groups with irregular |
applications and protocols such |
and protocols such as |
protocols such as tcp |
groups with irregular overlap |
it s possible to |
with irregular overlap patterns |
s possible to maintain |
ip which expect extreme |
possible to maintain rates |
which expect extreme reliability |
to maintain rates of |
expect extreme reliability from |
maintain rates of thousands |
extreme reliability from the |
but the servers are |
rates of thousands per |
reliability from the high |
the servers are a |
of thousands per second |
servers are a point |
thousands per second on |
are a point of |
speed network are instead |
per second on typical |
second on typical hardware |
network are instead subjected |
a point of contention |
are instead subjected to |
instead subjected to unexpectedly |
subjected to unexpectedly high |
the virtual synchrony and |
to unexpectedly high loss |
virtual synchrony and statemachine |
unexpectedly high loss rates |
synchrony and statemachine models |
and the indirect communication |
and statemachine models show |
the indirect communication pathway |
statemachine models show how |
indirect communication pathway introduces |
models show how a |
communication pathway introduces potentially |
these numbers reflect the |
show how a tremendous |
pathway introduces potentially high |
numbers reflect the loss |
how a tremendous range |
introduces potentially high latencies |
reflect the loss rate |
a tremendous range of |
the loss rate specifically |
tremendous range of application |
loss rate specifically experienced |
range of application requirements |
rate specifically experienced by |
of application requirements can |
these considerations convinced us |
specifically experienced by udp |
application requirements can map |
considerations convinced us that |
experienced by udp traffic |
requirements can map down |
convinced us that a |
by udp traffic on |
can map down to |
us that a new |
udp traffic on an |
traffic on an end |
that a new system |
map down to a |
a new system was |
down to a rigorously |
new system was needed |
to a rigorously precise |
a rigorously precise execution |
end path and may |
rigorously precise execution model |
path and may not |
and may not generalize |
may not generalize to |
not generalize to tcp |
generalize to tcp packets |
qsm implements a approach |
which in turn can |
implements a approach similar |
in turn can be |
a approach similar to |
turn can be used |
approach similar to spread |
can be used to |
we do not know |
similar to spread s |
be used to validate |
do not know if |
to spread s lightweight |
used to validate a |
not know if packets |
spread s lightweight group |
to validate a platform |
know if packets were |
s lightweight group abstraction |
if packets were dropped |
packets were dropped within |
were dropped within the |
because the models have |
dropped within the optical |
the models have formal |
within the optical network |
models have formal specifications |
but without a separate |
the optical network or |
without a separate server |
optical network or at |
a separate server group |
you can test the |
network or at intermediate |
can test the correctness |
or at intermediate devices |
test the correctness of |
at intermediate devices within |
the correctness of an |
intermediate devices within either |
we define a region |
correctness of an implementation |
define a region of |
devices within either data |
within either data center |
a region of overlap |
region of overlap to |
and even use theorem |
of overlap to be |
though it s unlikely |
even use theorem provers |
overlap to be a |
it s unlikely that |
use theorem provers to |
to be a set |
s unlikely that they |
modal versus modeless adaptation |
theorem provers to assist |
be a set of |
unlikely that they were |
versus modeless adaptation with |
provers to assist developers |
a set of nodes |
that they were dropped |
modeless adaptation with atp |
to assist developers in |
set of nodes with |
they were dropped at |
assist developers in testing |
of nodes with approximately |
were dropped at the |
dropped at the end |
the left graph shows |
nodes with approximately the |
developers in testing their |
left graph shows performance |
with approximately the same |
in testing their most |
graph shows performance with |
many of the measurements |
testing their most critical |
approximately the same group |
shows performance with modal |
of the measurements lost |
their most critical application |
the same group membership |
performance with modal adaptation |
the measurements lost just |
most critical application components |
measurements lost just one |
lost just one or |
just one or two |
one or two packets |
or two packets whereas |
and the right graph |
two packets whereas kernel |
one reason that we |
the right graph shows |
reason that we lack |
right graph shows a |
that we lack this |
graph shows a scheme |
we lack this sort |
nic losses are known |
lack this sort of |
shows a scheme in |
this sort of support |
losses are known to |
sort of support today |
a scheme in which |
are known to be |
known to be bursty |
scheme in which there |
of support today is |
in which there are |
under the assumptions of |
support today is that |
which there are four |
the assumptions of section |
today is that vendors |
there are four classes |
is that vendors and |
are four classes of |
that vendors and platform |
four classes of messages |
vendors and platform developers |
classes of messages being |
and platform developers worry |
of messages being sent |
platform developers worry that |
messages being sent simultaneously |
developers worry that these |
our cluster should be |
loss occurred on paths |
worry that these forms |
cluster should be nicely |
occurred on paths where |
that these forms of |
should be nicely tiled |
on paths where levels |
these forms of replication |
be nicely tiled by |
the lowest line corresponds |
paths where levels of |
forms of replication haven |
nicely tiled by regions |
lowest line corresponds to |
where levels of optical |
of replication haven t |
line corresponds to the |
levels of optical link |
replication haven t achieved |
corresponds to the highest |
of optical link utilization |
haven t achieved huge |
to the highest priority |
qsm uses regions for |
t achieved huge market |
uses regions for multicast |
achieved huge market success |
regions for multicast dissemination |
for multicast dissemination and |
multicast dissemination and for |
dark horizontal lines represent |
as the experience with |
dissemination and for recovery |
horizontal lines represent operating |
the experience with corba |
and for recovery of |
were consistently lower than |
experience with corba sidebar |
lines represent operating modes |
for recovery of lost |
with corba sidebar describes |
represent operating modes on |
recovery of lost packets |
operating modes on the |
modes on the left |
the common object request |
common object request broker |
object request broker architecture |
request broker architecture offers |
broker architecture offers a |
and the highest priority |
ruling out congestion as |
employing different protocols for |
the highest priority of |
architecture offers a fault |
out congestion as a |
congestion as a possible |
highest priority of data |
different protocols for each |
as a possible cause |
priority of data being |
protocols for each purpose |
tolerant groups mechanism that |
of data being sent |
a conclusion supported by |
groups mechanism that was |
data being sent during |
conclusion supported by dialogue |
mechanism that was based |
protocol node x recover |
supported by dialogue with |
being sent during a |
that was based on |
node x recover in |
by dialogue with the |
sent during a second |
was based on the |
x recover in x |
dialogue with the network |
during a second on |
based on the virtual |
recover in x region |
with the network administrators |
a second on the |
on the virtual synchrony |
in x region figure |
second on the right |
the virtual synchrony model |
the modeless scheme achieves |
modeless scheme achieves higher |
scheme achieves higher utilisation |
the corba standard is |
corba standard is widely |
hierarchical recovery in qsm |
standard is widely viewed |
is widely viewed as |
what are some possible |
widely viewed as rigid |
are some possible causes |
viewed as rigid and |
some possible causes for |
a group spans multiple |
as rigid and limited |
possible causes for such |
group spans multiple regions |
causes for such high |
for such high loss |
such high loss rates |
high loss rates on |
i believe that the |
mb of data sent |
loss rates on teragrid |
believe that the corba |
that the corba community |
each region has an |
the corba community erred |
because it always has |
region has an associated |
a likely hypothesis is |
corba community erred by |
it always has messages |
has an associated structure |
likely hypothesis is device |
community erred by embedding |
always has messages to |
has messages to send |
hypothesis is device clutter |
erred by embedding a |
an associated structure of |
is device clutter the |
by embedding a powerful |
while the modal scheme |
device clutter the critical |
associated structure of token |
embedding a powerful solution |
the modal scheme is |
clutter the critical communication |
modal scheme is dependent |
the critical communication path |
scheme is dependent on |
a powerful solution into |
structure of token rings |
critical communication path between |
is dependent on a |
powerful solution into a |
communication path between nodes |
dependent on a rapid |
solution into a tool |
path between nodes in |
on a rapid and |
into a tool mismatched |
between nodes in different |
a rapid and accurate |
a tool mismatched to |
nodes in different data |
rapid and accurate estimate |
tool mismatched to developer |
in different data centers |
and accurate estimate of |
mismatched to developer needs |
different data centers is |
to recover from packet |
accurate estimate of the |
data centers is littered |
recover from packet loss |
estimate of the available |
centers is littered with |
web services move beyond |
of the available bandwidth |
is littered with multiple |
services move beyond corba |
the available bandwidth in |
littered with multiple electronic |
move beyond corba in |
beyond corba in many |
available bandwidth in order |
with multiple electronic devices |
qsm uses a hierarchical |
corba in many ways |
bandwidth in order to |
uses a hierarchical structure |
in order to select |
each of which represents |
a hierarchical structure of |
order to select its |
of which represents a |
but the corba community |
hierarchical structure of token |
to select its correct |
which represents a potential |
the corba community s |
structure of token rings |
select its correct operating |
represents a potential point |
corba community s failed |
its correct operating mode |
a potential point of |
community s failed effort |
potential point of failure |
s failed effort to |
we considered using other |
failed effort to implement |
considered using other structures |
another possibility is that |
effort to implement virtual |
possibility is that such |
to implement virtual synchrony |
is that such loss |
implement virtual synchrony carries |
that such loss rates |
virtual synchrony carries an |
such loss rates may |
synchrony carries an important |
loss rates may be |
carries an important lesson |
rates may be typical |
an important lesson to |
may be typical for |
be typical for any |
typical for any large |
but token rings produce |
important lesson to current |
token rings produce a |
lesson to current researchers |
rings produce a more |
these graphs are reproduced |
scale network where the |
produce a more predictable |
graphs are reproduced from |
network where the cost |
a more predictable traffic |
any technology offered to |
where the cost of |
more predictable traffic pattern |
technology offered to developers |
the cost of immediately |
offered to developers must |
cost of immediately detecting |
to developers must support |
of immediately detecting and |
developers must support the |
the importance of this |
immediately detecting and fixing |
must support the programming |
importance of this will |
detecting and fixing failures |
support the programming styles |
an equivalent modal scheme |
of this will become |
and fixing failures is |
the programming styles they |
this will become clear |
fixing failures is prohibitively |
programming styles they prefer |
other experiments have shown |
will become clear later |
failures is prohibitively high |
experiments have shown that |
have shown that modeless |
management policies a scalable |
shown that modeless adaptation |
policies a scalable services |
that modeless adaptation can |
a scalable services architecture |
modeless adaptation can achieve |
we found through dialogue |
scalable services architecture for |
adaptation can achieve improvements |
found through dialogue with |
services architecture for building |
can achieve improvements of |
the basic structure is |
through dialogue with the |
architecture for building raps |
basic structure is illustrated |
dialogue with the administrators |
for building raps of |
structure is illustrated in |
with the administrators that |
building raps of racs |
is illustrated in figure |
the administrators that the |
raps of racs alone |
administrators that the steady |
of racs alone isn |
that the steady loss |
racs alone isn t |
the steady loss rate |
alone isn t enough |
steady loss rate experienced |
loss rate experienced by |
rate experienced by the |
experienced by the indiana |
by the indiana university |
the indiana university site |
at the highest level |
indiana university site was |
university site was due |
site was due to |
was due to a |
scale systems that will |
due to a faulty |
and it is possible |
systems that will likely |
to a faulty line |
it is possible to |
qsm circulates tokens around |
that will likely soon |
a faulty line card |
is possible to construct |
circulates tokens around sets |
will likely soon rely |
possible to construct cases |
tokens around sets of |
likely soon rely on |
and the measurements showed |
to construct cases in |
around sets of regions |
soon rely on standardized |
the measurements showed that |
construct cases in which |
rely on standardized web |
measurements showed that the |
cases in which the |
on standardized web services |
showed that the error |
aggregating information that can |
standardized web services including |
in which the improvement |
that the error persisting |
information that can be |
web services including global |
which the improvement is |
the error persisting over |
that can be used |
services including global banks |
the improvement is even |
error persisting over at |
can be used by |
improvement is even greater |
persisting over at least |
be used by a |
the entire us air |
over at least a |
at least a three |
work on adaptation in |
used by a group |
entire us air force |
least a three month |
a three month period |
by a group sender |
on adaptation in mobile |
a group sender to |
adaptation in mobile file |
and the supervisory control |
group sender to retransmit |
in mobile file systems |
the supervisory control and |
points for loss rates |
supervisory control and data |
mobile file systems has |
for loss rates on |
loss rates on high |
control and data acquisition |
file systems has generally |
sender to retransmit packets |
and data acquisition systems |
systems has generally relied |
to retransmit packets that |
data acquisition systems that |
has generally relied on |
retransmit packets that were |
haul networks are provided |
acquisition systems that operate |
generally relied on modal |
relied on modal schemes |
networks are provided by |
systems that operate the |
packets that were missed |
are provided by the |
that operate the us |
that were missed by |
provided by the back |
operate the us power |
were missed by entire |
the us power grid |
missed by entire regions |
us power grid will |
bone networks of tier |
power grid will also |
grid will also require |
will also require policies |
also require policies to |
require policies to manage |
policies to manage security |
to manage security keys |
global crossing reports average |
crossing reports average loss |
reports average loss rates |
average loss rates between |
but our evaluation of |
our evaluation of atp |
evaluation of atp demonstrated |
of atp demonstrated that |
atp demonstrated that it |
demonstrated that it could |
that it could also |
it could also improve |
could also improve the |
automated tools for monitoring |
also improve the performance |
a token circulates to |
tools for monitoring large |
improve the performance of |
the performance of file |
for monitoring large complex |
token circulates to provide |
performance of file system |
monitoring large complex systems |
circulates to provide loss |
large complex systems will |
to provide loss recovery |
complex systems will be |
provide loss recovery at |
systems will be needed |
loss recovery at the |
will be needed as |
we discuss the implementation |
on four of its |
be needed as well |
recovery at the level |
discuss the implementation of |
four of its six |
of its six inter |
the implementation of modeless |
at the level of |
implementation of modeless adaptation |
the level of nodes |
of modeless adaptation in |
researchers must think about |
level of nodes belonging |
haul links for the |
must think about how |
modeless adaptation in mfs |
of nodes belonging to |
links for the month |
think about how monitoring |
adaptation in mfs further |
about how monitoring and |
for the month of |
how monitoring and management |
in mfs further in |
the month of december |
nodes belonging to the |
monitoring and management policies |
mfs further in section |
belonging to the region |
and management policies in |
management policies in different |
policies in different organizations |
in different organizations should |
different organizations should talk |
organizations should talk to |
should talk to one |
atp is implemented at |
talk to one another |
is implemented at user |
to one another when |
implemented at user level |
one another when web |
another when web services |
when web services interactions |
web services interactions cross |
services interactions cross boundaries |
on top of kernel |
top of kernel udp |
if regions become large |
these are tough problems |
it has a message |
but they can be |
qsm partitions them into |
qwest reports loss rates |
reports loss rates of |
oriented interface for communication |
partitions them into smaller |
they can be solved |
them into smaller rings |
in which messages of |
which messages of an |
messages of an arbitrary |
of an arbitrary size |
an arbitrary size can |
this is illustrated in |
arbitrary size can be |
at cornell we recently |
is illustrated in figure |
size can be reliably |
cornell we recently developed |
can be reliably transmitted |
we recently developed astrolabe |
be reliably transmitted with |
reliably transmitted with their |
transmitted with their boundaries |
with their boundaries preserved |
their boundaries preserved at |
boundaries preserved at the |
a scalable technology for |
preserved at the receiver |
scalable technology for distributed |
in the experiments reported |
at the receiver s |
technology for distributed monitoring |
the experiments reported in |
the receiver s side |
for distributed monitoring and |
in either direction on |
either direction on its |
distributed monitoring and control |
experiments reported in this |
an application can send |
monitoring and control that |
direction on its trans |
reported in this paper |
application can send a |
and control that has |
can send a message |
control that has attracted |
pacific link for the |
send a message synchronously |
that has attracted tremendous |
link for the same |
a message synchronously or |
message synchronously or asynchronously |
has attracted tremendous interest |
for the same month |
no token ring ever |
token ring ever grows |
in the latter case |
ring ever grows larger |
the latter case the |
attracted tremendous interest and |
ever grows larger than |
latter case the sender |
tremendous interest and attention |
grows larger than about |
case the sender provides |
we expect privately managed |
the sender provides a |
expect privately managed lambdas |
sender provides a function |
privately managed lambdas to |
provides a function to |
managed lambdas to exhibit |
a function to be |
lambdas to exhibit higher |
function to be executed |
to exhibit higher loss |
to be executed when |
exhibit higher loss rates |
be executed when transmission |
researchers at other institutions |
higher loss rates due |
at other institutions are |
and the system uses |
executed when transmission of |
loss rates due to |
rates due to the |
the system uses single |
when transmission of the |
transmission of the message |
due to the inherent |
system uses single and |
uses single and two |
of the message completes |
to the inherent tradeoff |
the inherent tradeoff between |
inherent tradeoff between fiber |
other institutions are working |
and the send operation |
the send operation itself |
equipment quality and cost |
institutions are working on |
send operation itself is |
operation itself is non |
are working on other |
working on other promising |
on other promising solutions |
we plan to experiment |
plan to experiment with |
this is similar to |
to experiment with larger |
is similar to the |
experiment with larger configurations |
similar to the queued |
as well as the |
with larger configurations and |
to the queued rpc |
well as the difficulty |
larger configurations and will |
the queued rpc developed |
queued rpc developed for |
as the difficulty of |
configurations and will work |
calability isn t just |
rpc developed for rover |
the difficulty of performing |
and will work with |
isn t just a |
difficulty of performing routine |
will work with deeper |
work with deeper hierarchies |
of performing routine maintenance |
performing routine maintenance on |
routine maintenance on longdistance |
maintenance on longdistance links |
t just a technology |
the qsm recovery protocol |
qsm recovery protocol uses |
recovery protocol uses tokens |
protocol uses tokens to |
atp also allows the |
uses tokens to track |
also allows the sender |
tokens to track message |
allows the sender to |
to track message status |
it s also a |
end paths as dropping |
s also a mindset |
the sender to attach |
paths as dropping packets |
as dropping packets at |
sender to attach a |
to attach a priority |
dropping packets at rates |
packets at rates of |
attach a priority to |
a priority to each |
priority to each message |
also a mindset with |
a mindset with ramifications |
to control the order |
mindset with ramifications at |
control the order in |
with ramifications at many |
the order in which |
order in which the |
in which the queued |
which the queued messages |
the queued messages are |
queued messages are transmitted |
ramifications at many levels |
messages are queued at |
the token carries ack |
are queued at the |
to capture a wide |
token carries ack and |
queued at the sender |
capture a wide range |
carries ack and nak |
at the sender according |
a wide range of |
ack and nak information |
to ensure true scalability |
the sender according to |
wide range of deployed |
sender according to their |
range of deployed networks |
according to their receivers |
aggregated over the nodes |
over the nodes below |
the nodes below each |
nodes below each ring |
and each queue is |
each queue is ordered |
queue is ordered by |
e xisting r eliability |
is ordered by priority |
xisting r eliability o |
r eliability o ptions |
token rings avoid the |
eliability o ptions tcp |
web services platforms must |
rings avoid the kinds |
messages of the same |
avoid the kinds of |
ip is the default |
services platforms must begin |
of the same priority |
the kinds of ack |
is the default reliable |
the same priority within |
platforms must begin to |
the default reliable communication |
same priority within a |
must begin to standardize |
default reliable communication option |
priority within a queue |
nak implosion problems with |
reliable communication option for |
communication option for contemporary |
within a queue are |
implosion problems with which |
begin to standardize application |
option for contemporary networked |
a queue are transmitted |
queue are transmitted in |
for contemporary networked applications |
to standardize application architectures |
problems with which reliable |
standardize application architectures that |
are transmitted in first |
with which reliable multicast |
application architectures that promote |
exclusive embeddings in commodity |
which reliable multicast protocols |
embeddings in commodity operating |
in commodity operating systems |
reliable multicast protocols traditionally |
architectures that promote reliability |
commodity operating systems and |
multicast protocols traditionally have |
operating systems and networking |
systems and networking apis |
atp also allows a |
that promote reliability and |
protocols traditionally have struggled |
also allows a sender |
promote reliability and interoperability |
allows a sender to |
reliability and interoperability when |
most applications requiring reliable |
and interoperability when developers |
but problems of their |
a sender to specify |
applications requiring reliable communication |
requiring reliable communication over |
problems of their own |
sender to specify a |
interoperability when developers build |
reliable communication over any |
to specify a send |
if a message is |
communication over any form |
over any form of |
any form of network |
form of network use |
of network use tcp |
specify a send timeout |
a message is lost |
when developers build systems |
a send timeout for |
send timeout for a |
timeout for a message |
developers build systems of |
the sender may not |
build systems of systems |
which causes the transmission |
ip has three major |
sender may not find |
causes the transmission to |
has three major problems |
may not find out |
the transmission to be |
three major problems when |
not find out for |
transmission to be suspended |
major problems when used |
problems when used over |
when used over high |
find out for quite |
to be suspended if |
work with intrinsically distributed |
out for quite a |
with intrinsically distributed programs |
be suspended if it |
intrinsically distributed programs that |
for quite a while |
distributed programs that don |
suspended if it expires |
programs that don t |
that don t fit |
throughput collapse in lossy |
so that the sender |
that the sender can |
collapse in lossy networks |
don t fit a |
this isn t a |
the sender can react |
sender can react to |
can react to it |
t fit a transactional |
isn t a major |
ip is unable to |
an analogous mechanism is |
t a major issue |
fit a transactional model |
is unable to distinguish |
analogous mechanism is available |
a major issue because |
unable to distinguish between |
mechanism is available for |
is available for receive |
to distinguish between ephemeral |
major issue because most |
available for receive operations |
distinguish between ephemeral loss |
issue because most message |
between ephemeral loss modes |
because most message losses |
besides detecting when a |
ephemeral loss modes due |
most message losses can |
detecting when a remote |
loss modes due to |
modes due to transient |
due to transient congestion |
when a remote host |
a remote host is |
remote host is inaccessible |
and must provide responsiveness |
message losses can be |
or bad fiber and |
send timeouts do not |
losses can be corrected |
can be corrected locally |
bad fiber and persistent |
timeouts do not play |
do not play a |
fiber and persistent congestion |
must provide responsiveness guarantees |
not play a major |
play a major role |
a major role in |
major role in mfs |
the loss of one |
provide responsiveness guarantees to |
through cooperation among receivers |
an additional use for |
responsiveness guarantees to their |
loss of one packet |
additional use for timeouts |
guarantees to their users |
of one packet out |
use for timeouts would |
the basic idea is |
one packet out of |
for timeouts would be |
basic idea is to |
packet out of ten |
timeouts would be to |
idea is to perform |
out of ten thousand |
would be to detect |
is to perform recovery |
of ten thousand is |
be to detect prefetches |
to perform recovery as |
ten thousand is sufficient |
thousand is sufficient to |
to detect prefetches which |
perform recovery as locally |
recovery as locally as |
is sufficient to reduce |
detect prefetches which are |
applications with these sorts |
as locally as possible |
with these sorts of |
prefetches which are not |
sufficient to reduce tcp |
these sorts of requirements |
which are not making |
are not making progress |
sorts of requirements are |
ip throughput to a |
not making progress and |
throughput to a third |
to a third of |
making progress and reissue |
of requirements are already |
a third of its |
progress and reissue a |
requirements are already in |
third of its lossless |
and reissue a prefetch |
if a message is |
of its lossless maximum |
are already in the |
reissue a prefetch for |
a message is available |
a prefetch for a |
prefetch for a different |
if one packet is |
message is available within |
already in the pipeline |
for a different file |
one packet is lost |
is available within the |
available within the same |
packet is lost out |
is lost out of |
lost out of a |
out of a thousand |
within the same token |
the same token ring |
in the pipeline and |
throughput collapses to a |
collapses to a thirtieth |
to a thirtieth of |
a thirtieth of the |
thirtieth of the maximum |
some process that has |
the pipeline and even |
the root cause of |
process that has a |
atp administers priorities by |
root cause of throughput |
cause of throughput collapse |
that has a a |
administers priorities by deriving |
pipeline and even more |
of throughput collapse is |
and even more of |
priorities by deriving an |
even more of them |
has a a a |
throughput collapse is tcp |
by deriving an estimate |
more of them are |
a a a c |
deriving an estimate for |
ip s fundamental reliance |
s fundamental reliance on |
a a c ac |
an estimate for the |
of them are on |
fundamental reliance on loss |
a c ac ab |
estimate for the bandwidth |
for the bandwidth available |
reliance on loss as |
c ac ab abc |
them are on drawing |
the bandwidth available between |
on loss as a |
ac ab abc bc |
ab abc bc b |
bandwidth available between the |
loss as a signal |
as a signal of |
a signal of congestion |
available between the sender |
between the sender and |
the sender and receiver |
are on drawing boards |
abc bc b c |
while recent approaches have |
in order to minimise |
bc b c b |
b c b figure |
recent approaches have sought |
order to minimise the |
on drawing boards in |
approaches have sought to |
to minimise the transmission |
drawing boards in government |
have sought to replace |
minimise the transmission delay |
sought to replace loss |
the transmission delay when |
groups overlap to form |
to replace loss with |
transmission delay when a |
overlap to form regions |
replace loss with delay |
delay when a new |
loss with delay as |
when a new message |
with delay as a |
a new message is |
delay as a congestion |
nodes belong to the |
new message is sent |
as a congestion signal |
belong to the same |
to the same region |
the same region if |
atp uses a form |
uses a form of |
a form of rate |
same region if they |
region if they have |
if they have similar |
they have similar group |
have similar group membership |
each second is divided |
second is divided into |
is divided into twenty |
divided into twenty send |
into twenty send periods |
twenty send periods of |
or to specifically identify |
to specifically identify loss |
specifically identify loss caused |
identify loss caused by |
loss caused by non |
the only option for |
qsm currently uses an |
only option for the |
currently uses an unreliable |
option for the web |
uses an unreliable ip |
for the web services |
and at most one |
the web services community |
an unreliable ip multicast |
web services community is |
twentieth of the available |
services community is to |
since a single group |
older variants prominently reno |
of the available bandwidth |
community is to take |
a single group may |
variants prominently reno remain |
the available bandwidth is |
is to take on |
single group may span |
prominently reno remain ubiquitously |
available bandwidth is used |
bandwidth is used during |
group may span multiple |
reno remain ubiquitously deployed |
to take on the |
is used during a |
may span multiple regions |
take on the challenge |
used during a single |
during a single send |
a single send period |
recovery delays for real |
to send to group |
send to group g |
without such a constraint |
atp would send as |
would send as much |
a node multicasts a |
if they do so |
send as much data |
node multicasts a message |
ip uses positive acknowledgments |
as much data as |
multicasts a message to |
uses positive acknowledgments and |
much data as it |
a message to each |
positive acknowledgments and retransmissions |
data as it could |
message to each of |
acknowledgments and retransmissions to |
as it could on |
to each of the |
each of the regions |
and retransmissions to ensure |
it could on receipt |
could on receipt of |
on receipt of a |
retransmissions to ensure reliability |
solutions will be readily |
of the regions separately |
receipt of a low |
to ensure reliability the |
will be readily available |
ensure reliability the sender |
reliability the sender buffers |
the sender buffers packets |
sender buffers packets until |
buffers packets until their |
packets until their receipt |
and this data could |
until their receipt is |
this data could then |
their receipt is acknowledged |
data could then be |
receipt is acknowledged by |
could then be buffered |
is acknowledged by the |
then be buffered at |
acknowledged by the receiver |
be buffered at an |
buffered at an intermediate |
at an intermediate link |
web services are going |
our approach makes it |
and resends if an |
resends if an acknowledgment |
delaying the transmission of |
the transmission of any |
transmission of any high |
if an acknowledgment is |
approach makes it easy |
services are going to |
priority message which might |
makes it easy to |
an acknowledgment is not |
message which might be |
which might be sent |
might be sent later |
acknowledgment is not received |
is not received within |
it easy to aggregate |
are going to be |
not received within some |
going to be the |
the disadvantage of this |
received within some time |
within some time period |
to be the ubiquitous |
disadvantage of this scheme |
easy to aggregate messages |
be the ubiquitous platform |
of this scheme is |
to aggregate messages across |
a lost packet is |
the ubiquitous platform technology |
this scheme is that |
aggregate messages across different |
lost packet is received |
packet is received in |
ubiquitous platform technology for |
scheme is that heavy |
messages across different groups |
is received in the |
platform technology for next |
is that heavy contention |
received in the form |
that heavy contention at |
in the form of |
heavy contention at the |
the form of a |
contention at the sender |
form of a retransmission |
at the sender may |
of a retransmission that |
the sender may delay |
a retransmission that arrives |
sender may delay a |
retransmission that arrives no |
generation critical computing systems |
may delay a new |
that arrives no earlier |
arrives no earlier than |
delay a new message |
if a node has |
a new message by |
a node has two |
new message by as |
node has two messages |
message by as much |
by as much as |
has two messages to |
two messages to send |
messages to send to |
rtts after the original |
and we ve no |
to send to a |
we ve no one |
send to a pair |
ve no one but |
to a pair of |
regardless of its priority |
the sender has to |
sender has to buffer |
a pair of groups |
pair of groups g |
has to buffer each |
to buffer each packet |
this inefficiency of the |
no one but ourselves |
buffer each packet until |
inefficiency of the atp |
one but ourselves to |
each packet until it |
but ourselves to blame |
of the atp implementation |
ourselves to blame if |
which overlap in region |
packet until it s |
the atp implementation is |
to blame if these |
overlap in region r |
until it s acknowledged |
atp implementation is most |
blame if these systems |
implementation is most visible |
if these systems don |
is most visible when |
then while transmitting to |
rtt in lossless operation |
these systems don t |
most visible when there |
while transmitting to r |
systems don t work |
and it has to |
visible when there is |
don t work properly |
it has to perform |
when there is contention |
the node can batch |
has to perform additional |
there is contention between |
node can batch these |
to perform additional work |
is contention between different |
can batch these messages |
perform additional work to |
contention between different priorities |
batch these messages together |
additional work to retransmit |
between different priorities at |
work to retransmit the |
different priorities at high |
to retransmit the packet |
retransmit the packet if |
priorities at high bandwidth |
apps send to a |
the packet if it |
send to a send |
packet if it does |
to a send to |
if it does not |
a send to b |
it does not receive |
send to b group |
does not receive the |
to b group senders |
not receive the acknowledgment |
do we really want |
b group senders a |
group senders a b |
we really want to |
senders a b c |
mfs implementation the version |
really want to create |
a b c region |
any packets that arrive |
implementation the version of |
packets that arrive with |
the version of mfs |
that arrive with higher |
want to create a |
b c region senders |
version of mfs described |
arrive with higher sequence |
c region senders a |
to create a world |
of mfs described in |
with higher sequence numbers |
region senders a ab |
mfs described in this |
create a world in |
higher sequence numbers than |
senders a ab ac |
described in this paper |
sequence numbers than that |
a world in which |
a ab ac abc |
in this paper is |
world in which minor |
ab ac abc b |
numbers than that of |
in which minor computer |
ac abc b c |
this paper is implemented |
which minor computer glitches |
abc b c bc |
than that of a |
minor computer glitches shut |
b c bc region |
paper is implemented in |
that of a lost |
c bc region leader |
bc region leader figure |
is implemented in c |
of a lost packet |
computer glitches shut down |
implemented in c and |
a lost packet must |
glitches shut down massive |
in c and runs |
lost packet must be |
c and runs on |
and runs on freebsd |
packet must be queued |
shut down massive critical |
to multicast to a |
must be queued while |
multicast to a group |
down massive critical applications |
be queued while the |
queued while the receiver |
massive critical applications and |
while the receiver waits |
qsm sends a copy |
the receiver waits for |
receiver waits for the |
sends a copy to |
both the client and |
critical applications and in |
waits for the lost |
for the lost packet |
the client and server |
a copy to each |
applications and in which |
the lost packet to |
and in which hackers |
copy to each of |
in which hackers can |
client and server have |
which hackers can readily |
to each of the |
lost packet to arrive |
and server have multiple |
hackers can readily disrupt |
each of the underlying |
server have multiple threads |
can readily disrupt access |
of the underlying regions |
throughput financial banking application |
readily disrupt access to |
have multiple threads to |
financial banking application running |
disrupt access to banking |
multiple threads to cope |
banking application running in |
application running in a |
threads to cope with |
to cope with simultaneous |
running in a data |
partition leader token intrapartition |
access to banking records |
cope with simultaneous file |
in a data center |
leader token intrapartition token |
with simultaneous file system |
a data center in |
token intrapartition token partition |
simultaneous file system requests |
data center in new |
center in new york |
in new york city |
intrapartition token partition figure |
and the rpc library |
the rpc library has |
rpc library has its |
library has its own |
has its own thread |
air traffic control systems |
sending updates to a |
updates to a sister |
to a sister site |
therefore there are two |
a sister site in |
there are two mandatory |
a hierarchy of token |
sister site in switzerland |
are two mandatory thread |
hierarchy of token rings |
two mandatory thread context |
mandatory thread context switches |
the rtt value between |
thread context switches on |
rtt value between these |
value between these two |
context switches on any |
switches on any message |
between these two centers |
these two centers is |
on any message send |
any message send or |
two centers is typically |
and even shut down |
message send or receive |
send or receive operation |
even shut down the |
shut down the power |
as we shall describe |
naks ack through upcalls |
down the power grid |
we shall describe in |
shall describe in subsequent |
describe in subsequent sections |
qsm is also registered |
is also registered as |
also registered as a |
some subsystems have additional |
registered as a shell |
subsystems have additional threads |
as a shell extension |
have additional threads to |
in the case of |
additional threads to carry |
threads to carry out |
the case of a |
case of a lost |
to carry out background |
making it possible to |
of a lost packet |
carry out background processing |
time is running out |
it possible to access |
all packets received within |
possible to access the |
packets received within the |
to access the communication |
our experiments were conducted |
access the communication subsystem |
experiments were conducted with |
the communication subsystem directly |
were conducted with a |
communication subsystem directly from |
conducted with a default |
subsystem directly from the |
with a default client |
a default client cache |
directly from the windows |
from the windows gui |
milliseconds or more between |
default client cache size |
client cache size of |
or more between the |
current halfway solutions will |
more between the original |
between the original packet |
halfway solutions will tempt |
the original packet send |
original packet send and |
the user can store |
solutions will tempt developers |
packet send and the |
user can store a |
send and the receipt |
will tempt developers to |
can store a shortcut |
and the receipt of |
rpcs with priorities mfs |
tempt developers to embark |
store a shortcut to |
developers to embark on |
with priorities mfs rpcs |
the receipt of its |
a shortcut to a |
to embark on a |
priorities mfs rpcs are |
receipt of its retransmission |
shortcut to a qsm |
embark on a path |
mfs rpcs are implemented |
on a path that |
to a qsm stream |
a path that will |
rpcs are implemented on |
path that will soon |
a qsm stream in |
of its retransmission have |
are implemented on top |
implemented on top of |
qsm stream in the |
its retransmission have to |
retransmission have to be |
on top of atp |
stream in the file |
in the file system |
have to be buffered |
top of atp in |
of atp in the |
to be buffered at |
be buffered at the |
atp in the natural |
in the natural way |
buffered at the receiver |
that will soon lead |
will soon lead many |
an rpc request constitutes |
rpc request constitutes one |
request constitutes one message |
soon lead many of |
click to attach a |
lead many of them |
the loss of a |
to attach a previewer |
and its reply another |
many of them into |
loss of a single |
attach a previewer or |
of them into real |
of a single packet |
priorities are used to |
a previewer or a |
them into real trouble |
a single packet stops |
are used to differentiate |
previewer or a viewer |
single packet stops all |
used to differentiate types |
or a viewer to |
packet stops all traffic |
to differentiate types of |
a viewer to an |
stops all traffic in |
differentiate types of rpcs |
viewer to an event |
all traffic in the |
the entire industry clients |
to an event stream |
types of rpcs to |
traffic in the channel |
of rpcs to improve |
in the channel to |
rpcs to improve performance |
the channel to the |
channel to the application |
the overall architecture is |
to the application for |
overall architecture is summarized |
the application for a |
architecture is summarized in |
application for a seventh |
is summarized in figure |
for a seventh of |
a seventh of a |
seventh of a second |
or those which would |
those which would cause |
which would cause an |
would cause an interactive |
a sequence of such |
cause an interactive client |
an interactive client to |
sequence of such blocks |
and vendors as well |
interactive client to block |
the system is single |
of such blocks can |
such blocks can have |
blocks can have devastating |
can have devastating effect |
have devastating effect on |
are given high priority |
vendors as well as |
devastating effect on a |
effect on a high |
as well as the |
rpcs for background activities |
well as the government |
throughput system where every |
as the government have |
such as writing back |
the government have a |
system where every spare |
government have a shared |
as writing back files |
we use a windows |
where every spare cycle |
every spare cycle counts |
writing back files to |
use a windows i |
have a shared obligation |
back files to the |
files to the server |
a shared obligation to |
in applications with many |
applications with many fine |
shared obligation to make |
obligation to make web |
henceforth referred to as |
are performed at low |
performed at low priority |
referred to as an |
to as an i |
a lost packet can |
to make web services |
lost packet can potentially |
so that they do |
that they do not |
packet can potentially trigger |
make web services better |
they do not slow |
to collect all asynchronous |
can potentially trigger a |
do not slow down |
not slow down high |
potentially trigger a butterfly |
collect all asynchronous i |
trigger a butterfly effect |
a butterfly effect of |
butterfly effect of missed |
effect of missed deadlines |
of missed deadlines along |
missed deadlines along a |
deadlines along a distributed |
along a distributed workflow |
s ken birman is |
ken birman is a |
including notifications of any |
notifications of any received |
shows the priority levels |
birman is a professor |
of any received messages |
is a professor in |
overloaded networks and end |
a professor in the |
the priority levels for |
professor in the department |
priority levels for different |
in the department of |
hosts can exhibit continuous |
levels for different types |
for different types of |
can exhibit continuous packet |
exhibit continuous packet loss |
different types of rpcs |
the department of computer |
department of computer science |
with each lost packet |
a single core thread |
assigning priorities to rpcs |
of computer science at |
each lost packet driving |
single core thread synchronously |
priorities to rpcs allows |
computer science at cornell |
lost packet driving the |
core thread synchronously polls |
to rpcs allows mfs |
science at cornell university |
packet driving the system |
thread synchronously polls the |
rpcs allows mfs to |
driving the system further |
synchronously polls the i |
allows mfs to adapt |
the system further and |
mfs to adapt to |
system further and further |
to adapt to bandwidth |
further and further out |
contact him at ken |
o queue to retrieve |
adapt to bandwidth variation |
and further out of |
queue to retrieve incoming |
to bandwidth variation in |
further out of sync |
to retrieve incoming messages |
bandwidth variation in a |
out of sync with |
variation in a straightforward |
of sync with respect |
in a straightforward way |
sync with respect to |
with respect to its |
respect to its real |
the core thread also |
core thread also maintains |
thread also maintains an |
also maintains an alarm |
maintains an alarm queue |
all rpcs complete quickly |
implemented as a splay |
as a splay tree |
with or without priorities |
massive buffering needs for |
buffering needs for high |
needs for high throughput |
for high throughput applications |
ip uses fixed size |
uses fixed size buffers |
fixed size buffers at |
and a request queue |
size buffers at receivers |
buffers at receivers to |
at receivers to prevent |
receivers to prevent overflows |
implemented as a lockfree |
as a lockfree queue |
the sender never pushes |
a lockfree queue with |
sender never pushes more |
lockfree queue with cas |
never pushes more unacknowledged |
pushes more unacknowledged data |
more unacknowledged data into |
unacknowledged data into the |
data into the network |
into the network than |
the network than the |
network than the receiver |
than the receiver is |
the receiver is capable |
receiver is capable of |
is capable of holding |
corresponding rpc types fetch |
for requests from the |
rpc types fetch attributes |
the size of the |
callbacks fetch file data |
size of the fluctuating |
of the fluctuating window |
the fluctuating window at |
fluctuating window at the |
window at the sender |
at the sender is |
directory contents write back |
the sender is bounded |
department of computer engineering |
contents write back directory |
sender is bounded by |
the core thread polls |
write back directory and |
is bounded by the |
core thread polls all |
back directory and metadata |
bounded by the size |
thread polls all queues |
directory and metadata updates |
by the size of |
san jose state university |
and metadata updates write |
polls all queues in |
the size of the |
metadata updates write back |
all queues in a |
size of the buffer |
updates write back shared |
queues in a round |
of the buffer at |
write back shared files |
the buffer at the |
back shared files write |
buffer at the receiver |
shared files write back |
robin fashion and processes |
files write back unshared |
fashion and processes the |
write back unshared files |
and processes the events |
back unshared files prefetch |
processes the events sequentially |
unshared files prefetch file |
files prefetch file data |
prefetch file data section |
events of the same |
of the same type |
the quantity of inflight |
the same type are |
quantity of inflight unacknowledged |
same type are processed |
of inflight unacknowledged data |
type are processed in |
inflight unacknowledged data has |
are processed in batches |
unacknowledged data has to |
data has to be |
has to be extremely |
to be extremely high |
be extremely high for |
extremely high for the |
high for the flow |
for the flow to |
up to the limit |
the flow to saturate |
to the limit determined |
flow to saturate the |
to saturate the network |
the limit determined by |
independently and may compete |
limit determined by a |
determined by a quantum |
since the size of |
the size of the |
size of the receiver |
of the receiver window |
the receiver window limits |
receiver window limits the |
window limits the sending |
limits the sending envelope |
by making writes asynchronous |
it plays a major |
plays a major role |
a major role in |
major role in determining |
role in determining tcp |
update logging pushes read |
write contention into the |
contention into the future |
the default receiver buffer |
default receiver buffer sizes |
receiver buffer sizes in |
buffer sizes in many |
sizes in many standard |
to occur at the |
in many standard tcp |
occur at the next |
at the next log |
the next log flush |
ip implementations are in |
implementations are in the |
are in the range |
in the range of |
the designers of little |
the range of tens |
designers of little work |
there is no limit |
range of tens of |
of little work incorporated |
is no limit for |
of tens of kilobytes |
little work incorporated a |
no limit for local |
work incorporated a low |
limit for local push |
and consequently inadequate receiver |
consequently inadequate receiver buffering |
inadequate receiver buffering is |
receiver buffering is the |
buffering is the first |
level priority mechanism at |
is the first hurdle |
priority mechanism at the |
pull data sender inter |
the first hurdle faced |
mechanism at the ip |
first hurdle faced by |
at the ip packet |
hurdle faced by most |
the ip packet level |
faced by most practical |
by most practical deployments |
ip packet level to |
packet level to further |
level to further reduce |
pull region partition figure |
a natural solution is |
to further reduce interference |
natural solution is to |
further reduce interference between |
solution is to increase |
reduce interference between writeback |
is to increase the |
interference between writeback traffic |
to increase the size |
between writeback traffic and |
increase the size of |
writeback traffic and other |
recovery inside and across |
the size of the |
traffic and other network |
inside and across partitions |
size of the receiver |
and other network traffic |
of the receiver buffers |
other network traffic sent |
network traffic sent by |
traffic sent by the |
sent by the client |
copy will forward it |
will forward it to |
forward it to the |
it to the process |
to the process missing |
in many cases the |
the process missing the |
many cases the receiving |
cases the receiving end |
process missing the message |
host may not have |
may not have the |
not have the spare |
have the spare memory |
the spare memory capacity |
spare memory capacity to |
memory capacity to buffer |
capacity to buffer the |
to buffer the entire |
buffer the entire bandwidth |
qsm implements a scheme |
implements a scheme originally |
a scheme originally proposed |
scheme originally proposed by |
delay product of the |
product of the long |
priority levels for mfs |
originally proposed by zhao |
levels for mfs rpcs |
symbolic names are given |
the need for larger |
names are given for |
need for larger buffers |
are given for the |
for larger buffers is |
given for the priority |
larger buffers is orthogonal |
for the priority levels |
buffers is orthogonal to |
is orthogonal to the |
orthogonal to the flow |
to the flow control |
the flow control mechanisms |
flow control mechanisms used |
control mechanisms used within |
listed from highest to |
mechanisms used within tcp |
from highest to lowest |
even in a large |
highest to lowest priority |
in a large ring |
ip and impacts all |
and impacts all variants |
impacts all variants equally |
the third column gives |
third column gives the |
no more than five |
column gives the section |
more than five nodes |
gives the section in |
than five nodes cache |
the section in which |
five nodes cache any |
section in which the |
nodes cache any given |
in which the corresponding |
cache any given message |
fec fec encoders are |
which the corresponding rpc |
fec encoders are typically |
the corresponding rpc types |
encoders are typically parameterized |
corresponding rpc types are |
are typically parameterized with |
qsm also uses this |
rpc types are described |
typically parameterized with an |
also uses this idea |
types are described in |
uses this idea at |
are described in detail |
this idea at the |
idea at the level |
at the level of |
the level of partitions |
tuple for each outgoing |
for each outgoing sequence |
each outgoing sequence of |
each message is cached |
outgoing sequence of r |
message is cached in |
sequence of r data |
of r data packets |
is cached in a |
cached in a single |
in a single partition |
asynchronous writeback though it |
writeback though it reduces |
a total of r |
though it reduces bandwidth |
it reduces bandwidth consumption |
c data and error |
data and error correction |
and error correction packets |
update logging is fundamentally |
error correction packets are |
logging is fundamentally unsuitable |
correction packets are sent |
is fundamentally unsuitable for |
packets are sent over |
fundamentally unsuitable for use |
are sent over the |
sent over the channel |
unsuitable for use at |
if some partition is |
for use at high |
some partition is missing |
use at high bandwidth |
partition is missing a |
is missing a message |
redundancy information cannot be |
information cannot be generated |
cannot be generated and |
since it imposes a |
be generated and sent |
it imposes a delay |
the partition caching it |
generated and sent until |
imposes a delay on |
partition caching it steps |
and sent until all |
a delay on transmitting |
caching it steps in |
sent until all r |
delay on transmitting updates |
it steps in to |
until all r data |
on transmitting updates to |
steps in to resend |
all r data packets |
transmitting updates to the |
in to resend it |
r data packets are |
updates to the server |
data packets are available |
packets are available for |
are available for sending |
systems using update logging |
using update logging must |
update logging must therefore |
logging must therefore switch |
if an entire region |
must therefore switch to |
the latency of packet |
an entire region is |
therefore switch to a |
latency of packet recovery |
entire region is missing |
switch to a synchronous |
of packet recovery is |
region is missing a |
to a synchronous writes |
packet recovery is determined |
is missing a message |
a synchronous writes when |
recovery is determined by |
synchronous writes when bandwidth |
is determined by the |
writes when bandwidth is |
determined by the rate |
when bandwidth is high |
the sender becomes involved |
by the rate at |
sender becomes involved and |
the rate at which |
becomes involved and re |
rate at which the |
with a threshold controlling |
at which the sender |
a threshold controlling switches |
which the sender transmits |
threshold controlling switches between |
the sender transmits data |
controlling switches between the |
switches between the two |
between the two modes |
qsm tokens also carry |
tokens also carry other |
generating error correction packets |
also carry other information |
the mode switch also |
error correction packets from |
mode switch also changes |
correction packets from less |
switch also changes the |
packets from less than |
also changes the semantics |
including data used to |
from less than r |
changes the semantics of |
data used to perform |
less than r data |
the semantics of the |
used to perform rate |
than r data packets |
to perform rate control |
semantics of the file |
r data packets at |
perform rate control and |
of the file system |
data packets at the |
rate control and information |
packets at the sender |
control and information used |
at the sender is |
and the developers of |
and information used to |
the sender is not |
the developers of coda |
information used to trigger |
sender is not a |
developers of coda have |
used to trigger garbage |
is not a viable |
of coda have noted |
to trigger garbage collection |
not a viable option |
coda have noted that |
a viable option even |
have noted that undetected |
viable option even though |
noted that undetected mode |
option even though the |
the overall system configuration |
that undetected mode changes |
even though the data |
overall system configuration is |
undetected mode changes can |
though the data rate |
system configuration is managed |
mode changes can surprise |
the data rate in |
configuration is managed by |
changes can surprise the |
data rate in this |
is managed by what |
can surprise the user |
rate in this channel |
managed by what we |
surprise the user in |
in this channel is |
this channel is low |
the user in undesirable |
by what we call |
user in undesirable ways |
what we call the |
we call the configuration |
call the configuration management |
the configuration management service |
which handles join and |
such as cache inconsistencies |
handles join and leave |
as cache inconsistencies arising |
join and leave requests |
cache inconsistencies arising due |
inconsistencies arising due to |
h a b c |
arising due to unexpectedly |
a b c d |
due to unexpectedly delayed |
b c d x |
to unexpectedly delayed writes |
c d x x |
d x x e |
x x e f |
x e f g |
e f g h |
and uses these to |
f g h x |
uses these to generate |
rather than relying on |
g h x x |
these to generate a |
than relying on a |
h x x a |
to generate a sequence |
relying on a modal |
x x a c |
generate a sequence of |
on a modal adaptation |
x a c b |
a c b e |
a modal adaptation scheme |
a sequence of membership |
c b e d |
b e d a |
sequence of membership views |
modal adaptation scheme incorporating |
of membership views for |
adaptation scheme incorporating a |
membership views for each |
scheme incorporating a transition |
views for each multicast |
incorporating a transition to |
a transition to update |
transition to update logging |
to update logging when |
g g x x |
update logging when bandwidth |
the cms also determines |
g x x f |
logging when bandwidth is |
when bandwidth is low |
x x f h |
x f h x |
f h x x |
h x x b |
cms also determines and |
also determines and continuously |
mfs uses a modeless |
determines and continuously updates |
uses a modeless asynchronous |
and continuously updates region |
a modeless asynchronous writeback |
continuously updates region boundaries |
modeless asynchronous writeback mechanism |
which is active at |
maintains sequences of region |
is active at all |
sequences of region views |
active at all bandwidth |
of region views for |
at all bandwidth levels |
region views for each |
views for each region |
just as with update |
as with update logging |
separate encoding for odd |
and tracks the mapping |
encoding for odd and |
tracks the mapping from |
when an application performs |
for odd and even |
the mapping from group |
an application performs an |
odd and even packets |
mapping from group views |
application performs an operation |
and even packets could |
from group views to |
performs an operation that |
even packets could be |
group views to region |
an operation that changes |
packets could be operating |
views to region views |
operation that changes a |
could be operating at |
that changes a file |
be operating at near |
operating at near full |
at near full capacity |
near full capacity with |
full capacity with data |
capacity with data from |
with data from other |
such as a write |
data from other senders |
as a write or |
a write or metadata |
the cms runs on |
write or metadata update |
fec is also very |
cms runs on a |
is also very susceptible |
runs on a single |
also very susceptible to |
on a single node |
very susceptible to bursty |
susceptible to bursty losses |
but we intend to |
we intend to replace |
create directory and so |
directory and so on |
intend to replace this |
to replace this with |
replace this with a |
this with a state |
machine replicated version in |
replicated version in the |
version in the future |
in the future to |
the update is then |
the future to eliminate |
update is then passed |
future to eliminate the |
is then passed to |
to eliminate the risk |
then passed to the |
eliminate the risk of |
passed to the writeback |
the risk of single |
to the writeback subsystem |
is a standard encoding |
a standard encoding technique |
standard encoding technique used |
encoding technique used to |
technique used to combat |
used to combat bursty |
to combat bursty loss |
which sends it to |
sends it to the |
it to the server |
to the server when |
the server when there |
server when there is |
where error correction packets |
in the longer term |
when there is sufficient |
error correction packets are |
the longer term we |
there is sufficient bandwidth |
correction packets are generated |
longer term we will |
packets are generated from |
term we will move |
are generated from alternate |
we will move to |
asynchronous writeback therefore only |
generated from alternate disjoint |
from alternate disjoint sub |
writeback therefore only delays |
will move to a |
therefore only delays updates |
move to a hierarchically |
streams of data rather |
only delays updates when |
to a hierarchically structured |
of data rather than |
delays updates when there |
a hierarchically structured cms |
data rather than from |
rather than from consecutive |
updates when there is |
when there is foreground |
than from consecutive packets |
cloudifying source code repositories |
there is foreground traffic |
with an interleave index |
when bandwidth is high |
an interleave index of |
the performance of asynchronous |
performance of asynchronous writeback |
of asynchronous writeback should |
asynchronous writeback should be |
the encoder would create |
encoder would create correction |
writeback should be comparable |
should be comparable to |
would create correction packets |
how much does it |
be comparable to purely |
create correction packets separately |
alarm queue application thread |
comparable to purely synchronous |
correction packets separately from |
packets separately from three |
queue application thread operating |
to purely synchronous writes |
much does it cost |
separately from three disjoint |
from three disjoint sub |
application thread operating system |
but when bandwidth is |
thread operating system kernel |
when bandwidth is insufficient |
operating system kernel implementation |
system kernel implementation qsm |
kernel implementation qsm qsm |
the first containing data |
asynchronous writes will improve |
michael siegenthaler hakim weatherspoon |
first containing data packets |
implementation qsm qsm request |
writes will improve the |
will improve the performance |
containing data packets numbered |
qsm qsm request queue |
qsm request queue core |
improve the performance non |
siegenthaler hakim weatherspoon dept |
request queue core thread |
queue core thread i |
o queue socket figure |
an implementation without priorities |
of computer science cornell |
implementation without priorities will |
computer science cornell university |
without priorities will result |
qsm uses a single |
science cornell university msiegen |
priorities will result in |
will result in the |
result in the completion |
in the completion times |
the completion times for |
completion times for all |
times for all rpcs |
for all rpcs increasing |
all rpcs increasing uniformly |
with a core thread |
a core thread that |
core thread that controls |
thread that controls three |
when priorities are used |
that controls three queues |
a backlog of low |
priority rpcs will accumulate |
the second with data |
second with data packets |
with data packets numbered |
while the time taken |
the time taken for |
time taken for high |
priority rpcs to complete |
rpcs to complete will |
to complete will increase |
complete will increase more |
will increase more gradually |
of computer science cornell |
and requests from the |
computer science cornell university |
our design is based |
requests from the possibly |
science cornell university hweather |
design is based on |
from the possibly multithreaded |
is based on the |
the possibly multithreaded application |
based on the assumption |
on the assumption that |
the assumption that when |
assumption that when bandwidth |
that when bandwidth is |
when bandwidth is low |
when we set out |
we set out to |
set out to implement |
out to implement qsm |
an assignment of differentiated |
assignment of differentiated priorities |
of differentiated priorities will |
differentiated priorities will improve |
our intent was to |
priorities will improve the |
intent was to leverage |
will improve the response |
was to leverage the |
improve the response times |
to leverage the component |
the response times for |
response times for interactive |
leverage the component integration |
edu abstract cloud computing |
times for interactive tasks |
the component integration tools |
abstract cloud computing provides |
component integration tools available |
cloud computing provides us |
integration tools available on |
computing provides us with |
if a task which |
provides us with general |
tools available on the |
us with general purpose |
and the third with |
with general purpose storage |
available on the windows |
a task which predominantly |
the third with data |
third with data packets |
on the windows platform |
task which predominantly performs |
general purpose storage and |
with data packets numbered |
which predominantly performs reads |
we didn t expect |
didn t expect that |
predominantly performs reads executes |
purpose storage and server |
t expect that co |
performs reads executes in |
storage and server hosting |
reads executes in parallel |
and server hosting platforms |
executes in parallel to |
existence with the managed |
server hosting platforms at |
in parallel to a |
with the managed environment |
hosting platforms at a |
parallel to a task |
the managed environment would |
platforms at a reasonable |
to a task which |
managed environment would require |
at a reasonable price |
a task which performs |
environment would require any |
task which performs many |
would require any special |
which performs many writes |
require any special architectural |
any special architectural features |
we explore the possibility |
qsm is implemented much |
is implemented much like |
the first task will |
implemented much like any |
explore the possibility of |
first task will receive |
task will receive a |
will receive a higher |
the possibility of tapping |
receive a higher share |
a higher share of |
higher share of the |
the system is coded |
share of the bandwidth |
possibility of tapping these |
system is coded in |
is coded in c |
of tapping these resources |
tapping these resources for |
many applications have patterns |
these resources for the |
applications have patterns of |
interleaving adds burst tolerance |
resources for the purpose |
have patterns of interactive |
adds burst tolerance to |
for the purpose of |
patterns of interactive file |
burst tolerance to fec |
the purpose of hosting |
of interactive file access |
purpose of hosting source |
tolerance to fec but |
of hosting source code |
interactive file access involving |
hosting source code repositories |
to fec but exacerbates |
source code repositories for |
file access involving both |
fec but exacerbates its |
code repositories for individual |
access involving both reads |
but exacerbates its sensitivity |
repositories for individual projects |
involving both reads and |
exacerbates its sensitivity to |
for individual projects as |
both reads and writes |
its sensitivity to sending |
individual projects as well |
sensitivity to sending rate |
projects as well as |
to sending rate with |
as well as entire |
sending rate with an |
well as entire open |
compiling source files involves |
rate with an interleave |
as entire open source |
source files involves interspersed |
with an interleave index |
entire open source communities |
files involves interspersed reads |
an interleave index of |
involves interspersed reads and |
interleave index of i |
interspersed reads and writes |
index of i and |
of i and an |
i and an encoding |
and an encoding rate |
an encoding rate of |
but does not issue |
does not issue concurrent |
not issue concurrent rpcs |
to interface to the |
an analysis of storage |
issue concurrent rpcs frequently |
interface to the native |
analysis of storage costs |
to the native windows |
of storage costs is |
the native windows asynchronous |
such an application will |
the sender would have |
native windows asynchronous i |
storage costs is presented |
an application will have |
sender would have to |
application will have improved |
would have to wait |
will have improved read |
have to wait for |
have improved read performance |
to wait for i |
and a complete hosting |
improved read performance when |
a complete hosting solution |
read performance when there |
and is accessible from |
is accessible from any |
performance when there is |
complete hosting solution is |
when there is contention |
there is contention with |
is contention with other |
contention with other applications |
hosting solution is built |
solution is built and |
packets before sending any |
windows understands qsm to |
is built and evaluated |
before sending any redundancy |
but will correspondingly be |
understands qsm to be |
built and evaluated as |
sending any redundancy information |
will correspondingly be penalised |
qsm to be the |
and evaluated as a |
these two obstacles to |
to be the handler |
correspondingly be penalised on |
be penalised on writes |
two obstacles to using |
be the handler for |
evaluated as a proof |
obstacles to using fec |
this does not match |
the handler for operations |
to using fec in |
using fec in time |
handler for operations on |
does not match our |
for operations on new |
not match our design |
operations on new kind |
sensitive settings rate sensitivity |
match our design goal |
on new kind of |
settings rate sensitivity and |
our design goal of |
new kind of event |
rate sensitivity and burst |
design goal of having |
kind of event stream |
sensitivity and burst susceptibility |
goal of having interactive |
and burst susceptibility are |
burst susceptibility are interlinked |
susceptibility are interlinked through |
are interlinked through the |
an application can obtain |
interlinked through the tuning |
through the tuning knobs |
application can obtain handles |
can obtain handles from |
obtain handles from these |
handles from these qsm |
read applications obtain a |
an interleave of i |
applications obtain a larger |
interleave of i and |
obtain a larger share |
a larger share of |
of i and a |
i and a rate |
and a rate of |
i ntroduction the advent |
larger share of bandwidth |
and can then invoke |
ntroduction the advent of |
can then invoke methods |
then invoke methods on |
the advent of cloud |
we have implemented two |
invoke methods on those |
have implemented two solutions |
provides tolerance to a |
advent of cloud computing |
methods on those handles |
implemented two solutions to |
tolerance to a burst |
on those handles to |
those handles to send |
two solutions to this |
to a burst of |
of cloud computing has |
handles to send events |
solutions to this problem |
a burst of up |
cloud computing has brought |
burst of up to |
of up to c |
computing has brought us |
incoming messages are delivered |
up to c i |
based on making writes |
messages are delivered application |
are delivered application requests |
to c i consecutive |
on making writes asynchronous |
has brought us a |
c i consecutive packets |
brought us a dazzling |
us a dazzling array |
a dazzling array of |
used in several existing |
dazzling array of public |
in several existing systems |
o event representing a |
array of public computing |
the burst tolerance of |
of public computing services |
event representing a received |
public computing services that |
burst tolerance of an |
computing services that can |
representing a received packet |
several existing systems and |
tolerance of an fec |
services that can be |
a received packet is |
existing systems and incorporated |
of an fec code |
that can be instantly |
received packet is retrieved |
systems and incorporated in |
an fec code can |
can be instantly tapped |
packet is retrieved for |
and incorporated in mfs |
fec code can be |
be instantly tapped by |
is retrieved for a |
incorporated in mfs for |
code can be changed |
instantly tapped by anyone |
retrieved for a given |
in mfs for the |
can be changed by |
tapped by anyone with |
for a given socket |
mfs for the purposes |
be changed by modulating |
by anyone with a |
for the purposes of |
changed by modulating either |
anyone with a credit |
the purposes of comparison |
the socket is drained |
by modulating either the |
with a credit card |
socket is drained to |
modulating either the c |
either the c or |
is drained to minimize |
a credit card number |
the c or the |
c or the i |
or the i parameters |
drained to minimize the |
which is new to |
is new to mfs |
to minimize the probability |
minimize the probability of |
increasing c enhances burst |
the probability of loss |
c enhances burst tolerance |
an alternative approach is |
users are spared from |
enhances burst tolerance at |
are spared from having |
alternative approach is to |
burst tolerance at the |
several aspects of the |
spared from having to |
approach is to retain |
tolerance at the cost |
aspects of the architecture |
from having to invest |
is to retain synchronous |
at the cost of |
of the architecture are |
having to invest in |
to retain synchronous writes |
the cost of network |
the architecture are noteworthy |
to invest in expensive |
cost of network and |
but assign priorities according |
invest in expensive infrastructure |
architecture are noteworthy because |
of network and encoding |
assign priorities according to |
in expensive infrastructure such |
are noteworthy because of |
network and encoding overhead |
priorities according to some |
expensive infrastructure such as |
noteworthy because of their |
according to some notion |
infrastructure such as servers |
because of their performance |
potentially worsening the packet |
to some notion of |
of their performance implications |
worsening the packet loss |
some notion of relative |
the packet loss experienced |
notion of relative importance |
packet loss experienced and |
of relative importance of |
loss experienced and reducing |
relative importance of processes |
experienced and reducing throughput |
qsm assigns priorities to |
assigns priorities to different |
priorities to different types |
to different types of |
different types of i |
and cooling equipment because |
increasing i trades off |
existing operating systems and |
cooling equipment because the |
i trades off recovery |
equipment because the service |
operating systems and applications |
because the service provider |
the basic idea is |
the service provider takes |
systems and applications generally |
service provider takes care |
basic idea is that |
trades off recovery latency |
and applications generally do |
provider takes care of |
idea is that when |
off recovery latency for |
applications generally do not |
takes care of these |
is that when an |
recovery latency for better |
generally do not provide |
do not provide this |
that when an i |
latency for better burst |
care of these and |
not provide this information |
for better burst tolerance |
of these and amortizes |
better burst tolerance without |
these and amortizes the |
burst tolerance without adding |
so we have not |
we retrieve all events |
retrieve all events from |
tolerance without adding overhead |
we have not investigated |
have not investigated it |
and amortizes the cost |
all events from the |
without adding overhead as |
not investigated it further |
amortizes the cost across |
events from the i |
adding overhead as mentioned |
the cost across many |
the cache manager s |
cost across many clients |
cache manager s writeback |
for higher values of |
higher values of i |
manager s writeback thread |
determine the type of |
s writeback thread divides |
the type of each |
writeback thread divides updates |
the encoder has to |
thread divides updates into |
encoder has to wait |
achieving efficiency through economies |
divides updates into metadata |
has to wait for |
and then place it |
efficiency through economies of |
updates into metadata operations |
to wait for more |
then place it in |
through economies of scale |
wait for more data |
such as directory modifications |
place it in an |
for more data packets |
as directory modifications and |
it in an appropriate |
more data packets to |
directory modifications and file |
in an appropriate priority |
data packets to be |
modifications and file status |
an appropriate priority queue |
companies are realizing that |
packets to be transmitted |
are realizing that it |
and file status changes |
realizing that it no |
to be transmitted before |
that it no longer |
be transmitted before it |
it no longer makes |
the system processes queued |
transmitted before it can |
before it can send |
the two types of |
no longer makes sense |
system processes queued events |
it can send error |
two types of operations |
longer makes sense to |
processes queued events in |
can send error correction |
types of operations are |
makes sense to build |
queued events in priority |
send error correction packets |
of operations are queued |
sense to build and |
events in priority order |
operations are queued and |
to build and manage |
are queued and replayed |
build and manage all |
queued and replayed to |
once the fec encoding |
and manage all of |
and replayed to the |
the fec encoding is |
manage all of their |
replayed to the server |
fec encoding is parameterized |
all of their own |
to the server separately |
encoding is parameterized with |
by prioritizing incoming i |
of their own infrastructure |
is parameterized with a |
so that a metadata |
parameterized with a rate |
that a metadata rpc |
with a rate and |
a metadata rpc can |
a rate and an |
metadata rpc can proceed |
rate and an interleave |
rpc can proceed in |
and an interleave to |
and services in the |
can proceed in parallel |
an interleave to tolerate |
services in the cloud |
proceed in parallel with |
interleave to tolerate a |
to tolerate a certain |
in parallel with a |
parallel with a file |
tolerate a certain burst |
a certain burst length |
with a file writeback |
in the cloud are |
certain burst length b |
and by prioritizing control |
the cloud are quickly |
by prioritizing control packets |
when an rpc from |
cloud are quickly becoming |
prioritizing control packets over |
an rpc from a |
rpc from a particular |
control packets over data |
are quickly becoming popular |
from a particular queue |
packets over data we |
a particular queue completes |
over data we reduce |
data we reduce delays |
we reduce delays in |
reduce delays in reacting |
delays in reacting to |
we say that the |
in reacting to packet |
say that the update |
reacting to packet loss |
that the update has |
to packet loss or |
the update has been |
packet loss or other |
update has been committed |
loss or other control |
has been committed at |
been committed at the |
committed at the server |
to tolerate a burst |
tolerate a burst of |
a burst of length |
the next update is |
next update is then |
update is then dequeued |
we will see that |
is then dequeued and |
that software development projects |
will see that this |
software development projects will |
see that this slashes |
development projects will turn |
that this slashes system |
projects will turn to |
will turn to cloud |
turn to cloud computing |
update logging an asynchronous |
to cloud computing to |
logging an asynchronous rpc |
cloud computing to store |
an asynchronous rpc for |
the pros and cons |
computing to store their |
asynchronous rpc for it |
all losses occurring in |
to store their master |
pros and cons of |
rpc for it is |
losses occurring in bursts |
store their master code |
and cons of using |
for it is initiated |
occurring in bursts of |
their master code repositories |
cons of using threads |
in bursts of size |
of using threads in |
separating the small update |
bursts of size less |
using threads in eventoriented |
the small update logging |
of size less than |
threads in eventoriented systems |
size less than or |
either on a project |
which is implemented in |
less than or equal |
in eventoriented systems are |
is implemented in some |
than or equal to |
eventoriented systems are hotly |
implemented in some mobile |
or equal to b |
systems are hotly debated |
in some mobile file |
equal to b are |
some mobile file sys |
to b are recovered |
b are recovered with |
are recovered with the |
recovered with the same |
with the same latency |
metadata rpcs from file |
the same latency and |
threads turned out to |
rpcs from file writes |
project basis or as |
same latency and this |
turned out to be |
from file writes allows |
basis or as part |
latency and this latency |
out to be a |
file writes allows remote |
or as part of |
and this latency depends |
to be a bad |
writes allows remote clients |
as part of a |
this latency depends on |
be a bad idea |
allows remote clients to |
remote clients to see |
latency depends on the |
depends on the i |
on the i parameter |
part of a larger |
clients to see statems |
although we used threads |
of a larger migration |
we used threads rather |
a larger migration of |
we d like to |
used threads rather casually |
larger migration of a |
d like to parameterize |
threads rather casually in |
migration of a sourceforge |
like to parameterize the |
rather casually in the |
to parameterize the encoding |
casually in the first |
parameterize the encoding to |
in the first year |
the encoding to tolerate |
the first year of |
encoding to tolerate a |
first year of our |
to tolerate a maximum |
year of our effort |
tolerate a maximum burst |
a maximum burst length |
maximum burst length and |
burst length and then |
length and then have |
even small code repositories |
and then have recovery |
that version of the |
small code repositories represent |
then have recovery latency |
version of the system |
code repositories represent a |
have recovery latency depend |
of the system was |
repositories represent a huge |
recovery latency depend on |
the system was annoyingly |
represent a huge investment |
tus changes to files |
latency depend on the |
system was annoyingly process |
a huge investment of |
changes to files without |
depend on the actual |
was annoyingly process requests |
huge investment of developerhours |
to files without having |
on the actual burstiness |
annoyingly process requests incoming |
files without having to |
the actual burstiness of |
process requests incoming control |
without having to wait |
actual burstiness of the |
burstiness of the loss |
having to wait for |
requests incoming control outgoing |
so the need to |
at the same time |
incoming control outgoing control |
to wait for intervening |
the need to store |
control outgoing control outgoing |
wait for intervening writequirement |
need to store this |
we would like the |
outgoing control outgoing data |
for intervening writequirement that |
to store this data |
would like the encoding |
control outgoing data feed |
intervening writequirement that processes |
writequirement that processes wait |
like the encoding to |
outgoing data feed sink |
store this data durably |
that processes wait for |
the encoding to have |
data feed sink limit |
this data durably and |
processes wait for writes |
encoding to have a |
feed sink limit sending |
data durably and reliably |
to have a constant |
rather than sending an |
than sending an back |
sink limit sending rate |
have a constant rate |
durably and reliably is |
sending an back traffic |
limit sending rate limit |
a constant rate for |
and reliably is obvious |
sending rate limit concurrency |
constant rate for network |
a similar motivation underlies |
rate limit concurrency limit |
rate for network provisioning |
similar motivation underlies the |
limit concurrency limit window |
for network provisioning and |
motivation underlies the cache |
concurrency limit window size |
network provisioning and stability |
less obvious are the |
underlies the cache consisupdate |
limit window size figure |
obvious are the shortcomings |
the cache consisupdate to |
are the shortcomings of |
cache consisupdate to the |
an fec scheme is |
the shortcomings of traditional |
consisupdate to the server |
fec scheme is required |
in a pull protocol |
to the server as |
shortcomings of traditional storage |
scheme is required where |
a pull protocol a |
the server as soon |
of traditional storage systems |
is required where latency |
server as soon as |
required where latency of |
as soon as a |
where latency of recovery |
soon as a file |
latency of recovery degrades |
as a file is |
of recovery degrades gracefully |
registers the intent to |
a file is closed |
recovery degrades gracefully as |
the intent to send |
degrades gracefully as losses |
intent to send with |
gracefully as losses get |
as losses get burstier |
the cache manager tency |
to send with a |
cache manager tency scheme |
send with a sink |
manager tency scheme for |
even as the encoding |
with a sink that |
tency scheme for high |
as the encoding overhead |
a sink that may |
scheme for high read |
the encoding overhead stays |
sink that may be |
encoding overhead stays constant |
that may be controlled |
may be controlled by |
write contention environments we |
be controlled by a |
contention environments we logs |
controlled by a policy |
environments we logs the |
by a policy limiting |
we logs the update |
a policy limiting the |
logs the update and |
policy limiting the send |
the update and periodically |
limiting the send rate |
update and periodically flushes |
and periodically flushes logged |
protect against data loss |
periodically flushes logged updates |
flushes logged updates to |
logged updates to the |
updates to the describe |
to the describe in |
the describe in section |
when the sink is |
the sink is ready |
sink is ready to |
but they are neither |
is ready to send |
they are neither cheap |
are neither cheap nor |
the chief complexity in |
it issues an upcall |
neither cheap nor simple |
chief complexity in implementing |
complexity in implementing asynchronous |
in implementing asynchronous writeserver |
app elements of the |
elements of the protocol |
of the protocol stack |
the protocol stack f |
these systems enable logging |
systems enable logging when |
enable logging when bandwidth |
logging when bandwidth is |
when bandwidth is low |
especially when developers and |
when developers and server |
developers and server administrators |
o events according to |
to improve read performance |
and server administrators are |
events according to priorities |
improve read performance and |
server administrators are geographically |
end flow control x |
read performance and reduce |
according to priorities incoming |
administrators are geographically spread |
flow control x appliance |
performance and reduce write |
to priorities incoming data |
are geographically spread thin |
control x appliance appliance |
and reduce write traffic |
priorities incoming data policy |
x appliance appliance end |
reduce write traffic by |
incoming data policy get |
write traffic by aggregat |
data policy get messages |
policy get messages pre |
back lies in resolving |
lies in resolving dependencies |
in resolving dependencies between |
resolving dependencies between metadata |
dependencies between metadata operations |
between metadata operations ing |
we focus on the |
o events process timer |
focus on the costs |
metadata operations ing updates |
on the costs of |
events process timer events |
the costs of moving |
operations ing updates to |
costs of moving source |
process timer events register |
of moving source code |
ing updates to the |
moving source code repositories |
timer events register to |
source code repositories to |
updates to the same |
events register to send |
code repositories to the |
to the same file |
repositories to the cloud |
split flow control fig |
register to send app |
the same file in |
to the cloud as |
to send app app |
same file in the |
the cloud as an |
send app app f |
file in the log |
cloud as an example |
in the log before |
flow control options in |
control options in maelstrom |
the log before they |
log before they are |
before they are transmitted |
as an example of |
an example of moving |
example of moving services |
of moving services in |
and updates to the |
updates to the same |
to the same file |
moving services in general |
services in general to |
in general to the |
general to the cloud |
lan mtu lambda jumbo |
mtu lambda jumbo mtu |
one can think of |
lambda jumbo mtu recipe |
a file may be |
file may be created |
jumbo mtu recipe list |
can think of qsm |
especially collaborative open source |
think of qsm as |
collaborative open source projects |
update logging separates communication |
of qsm as a |
logging separates communication with |
qsm as a collection |
separates communication with the |
as a collection of |
communication with the server |
such an endeavor includes |
a collection of protocol |
with the server into |
an endeavor includes many |
collection of protocol stacks |
the server into modified |
server into modified and |
of protocol stacks in |
endeavor includes many costs |
into modified and closed |
protocol stacks in which |
stacks in which components |
in which components act |
which components act as |
components act as both |
act as both feeds |
and the length of |
as both feeds and |
the length of the |
the most critical of |
both feeds and as |
most critical of which |
length of the metadata |
critical of which is |
feeds and as sinks |
of which is storage |
of the metadata queue |
which is storage since |
the metadata queue may |
the overall structure is |
is storage since that |
metadata queue may two |
overall structure is of |
storage since that is |
queue may two distinct |
structure is of a |
is of a forest |
may two distinct streams |
since that is the |
of a forest of |
a forest of trees |
that is the simplest |
updates to files and |
to files and directories |
is the simplest and |
the simplest and likely |
simplest and likely first |
and likely first component |
and all be enough |
likely first component to |
all be enough to |
first component to be |
o was to reduce |
be enough to mean |
component to be moved |
was to reduce staleness |
enough to mean that |
to reduce staleness by |
to mean that the |
reduce staleness by postponing |
mean that the file |
staleness by postponing the |
that the file update |
we set an agenda |
by postponing the creation |
set an agenda for |
the file update would |
an agenda for demonstrating |
postponing the creation of |
agenda for demonstrating the |
file update would be |
for demonstrating the financial |
the creation of control |
demonstrating the financial storage |
update would be initiated |
creation of control messages |
the financial storage and |
would be initiated first |
of control messages until |
financial storage and computing |
control messages until the |
storage and computing costs |
messages until the time |
and computing costs of |
until the time when |
these two types of |
the time when transmission |
repair packets are injected |
computing costs of moving |
two types of communication |
time when transmission is |
packets are injected into |
costs of moving source |
types of communication are |
when transmission is actually |
are injected into stream |
injected into stream transparently |
of communication are scheduled |
transmission is actually about |
of moving source code |
into stream transparently iv |
communication are scheduled this |
is actually about to |
actually about to take |
are scheduled this case |
moving source code repositories |
about to take place |
scheduled this case the |
m aelstrom d esign |
source code repositories to |
this case the file |
aelstrom d esign and |
code repositories to the |
case the file update |
d esign and i |
repositories to the cloud |
the file update must |
esign and i mplementation |
file update must wait |
time information is more |
and i mplementation we |
information is more accurate |
i mplementation we describe |
mplementation we describe the |
we describe the maelstrom |
in section ii we |
describe the maelstrom appliance |
and this makes qsm |
this makes qsm more |
the maelstrom appliance as |
a file may be |
section ii we explain |
makes qsm more stable |
ii we explain what |
maelstrom appliance as a |
we explain what it |
appliance as a single |
explain what it means |
test activity gc grep |
what it means to |
an unintended benefit is |
it means to store |
activity gc grep compile |
means to store a |
unintended benefit is that |
to store a code |
gc grep compile grep |
as a single machine |
benefit is that the |
store a code repository |
grep compile grep write |
a single machine later |
is that the pull |
a code repository in |
compile grep write read |
that the pull architecture |
we will show how |
grep write read compile |
code repository in the |
the pull architecture slashes |
will show how more |
write read compile read |
repository in the cloud |
pull architecture slashes buffering |
show how more machines |
read compile read write |
in the cloud and |
architecture slashes buffering and |
how more machines can |
compile read write gw |
the cloud and why |
slashes buffering and memory |
more machines can be |
read write gw rc |
cloud and why there |
buffering and memory overheads |
machines can be added |
write gw rc rw |
and why there are |
can be added to |
gw rc rw synchronous |
why there are cost |
be added to the |
rc rw synchronous uniform |
as we shall demonstrate |
added to the appliance |
there are cost advantages |
rw synchronous uniform priorities |
to the appliance to |
turns out to have |
are cost advantages to |
the appliance to balance |
out to have an |
cost advantages to doing |
appliance to balance encoding |
to have an enormous |
advantages to doing so |
to balance encoding load |
have an enormous impact |
balance encoding load and |
an enormous impact on |
encoding load and scale |
enormous impact on performance |
load and scale to |
and scale to multiple |
section iii is a |
scale to multiple gigabits |
iii is a case |
to multiple gigabits per |
in qsm each element |
is a case study |
multiple gigabits per second |
qsm each element of |
a case study on |
gigabits per second of |
per second of traffic |
case study on using |
each element of a |
study on using amazon |
element of a protocol |
on using amazon s |
of a protocol stack |
using amazon s s |
a protocol stack acts |
basic mechanism the basic |
protocol stack acts as |
mechanism the basic operation |
stack acts as a |
the basic operation of |
acts as a feed |
basic operation of maelstrom |
as a feed that |
operation of maelstrom is |
of maelstrom is shown |
a feed that has |
feed that has data |
maelstrom is shown in |
is shown in figure |
that has data to |
has data to send |
to host some popular |
host some popular open |
some popular open source |
popular open source communities |
or a sink that |
a sink that can |
sink that can send |
that can send it |
it intercepts outgoing data |
intercepts outgoing data packets |
outgoing data packets and |
and includes a cost |
data packets and routes |
includes a cost analysis |
packets and routes them |
and routes them to |
routes them to the |
them to the destination |
to the destination data |
the destination data center |
in section iv we |
generating and injecting fec |
and many play both |
many play both roles |
and injecting fec repair |
section iv we present |
injecting fec repair packets |
iv we present an |
fec repair packets into |
we present an implementation |
repair packets into the |
present an implementation that |
packets into the stream |
an implementation that ties |
into the stream in |
the stream in their |
stream in their wake |
implementation that ties subversion |
that ties subversion to |
ties subversion to s |
a repair packet consists |
rather than creating a |
repair packet consists of |
than creating a message |
packet consists of a |
creating a message and |
consists of a recipe |
a message and handing |
of a recipe list |
message and handing it |
a recipe list of |
and handing it down |
recipe list of data |
handing it down to |
list of data packet |
it down to the |
of data packet identifiers |
down to the sink |
data packet identifiers and |
end servers running on |
packet identifiers and fec |
servers running on amazon |
a feed registers the |
identifiers and fec information |
running on amazon s |
feed registers the intent |
and fec information generated |
fec information generated from |
information generated from these |
generated from these packets |
registers the intent to |
on amazon s ec |
the intent to send |
intent to send a |
in the example in |
the example in figure |
to send a message |
send a message with |
a message with the |
message with the sink |
and using yahoo s |
using yahoo s zookeeper |
yahoo s zookeeper for |
s zookeeper for consistency |
this information is a |
the message can be |
information is a simple |
is a simple xor |
message can be created |
can be created at |
be created at this |
created at this time |
in section v we |
at this time and |
the size of the |
section v we evaluate |
this time and buffered |
size of the xor |
v we evaluate the |
time and buffered in |
of the xor is |
we evaluate the performance |
and buffered in the |
the xor is equal |
evaluate the performance of |
buffered in the feed |
xor is equal to |
the performance of this |
is equal to the |
performance of this solution |
equal to the mtu |
but the creation may |
to the mtu of |
the creation may also |
the mtu of the |
creation may also be |
mtu of the data |
may also be postponed |
of the data center |
the data center network |
also be postponed until |
and in section vi |
be postponed until the |
in section vi we |
postponed until the time |
and to avoid fragmentation |
section vi we address |
until the time when |
to avoid fragmentation of |
vi we address related |
the time when the |
avoid fragmentation of repair |
we address related work |
time when the sink |
fragmentation of repair packets |
when the sink polls |
of repair packets we |
the sink polls the |
repair packets we require |
sink polls the feed |
packets we require that |
polls the feed for |
we require that the |
the feed for messages |
require that the mtu |
feed for messages to |
that the mtu of |
for messages to transmit |
c loudifying s ource |
the mtu of the |
mtu of the long |
loudifying s ource r |
s ource r epositories |
the sink determines its |
ource r epositories in |
haul network be set |
sink determines its readiness |
r epositories in a |
network be set to |
determines its readiness to |
epositories in a revision |
be set to a |
its readiness to send |
in a revision control |
set to a slightly |
readiness to send based |
a revision control system |
to a slightly larger |
a slightly larger value |
to send based on |
send based on a |
based on a control |
on a control policy |
this requirement is easily |
requirement is easily satisfied |
is easily satisfied in |
easily satisfied in practice |
a master copy of |
master copy of the |
copy of the source |
of the source code |
since gigabit links very |
gigabit links very often |
links very often use |
very often use jumbo |
often use jumbo frames |
use jumbo frames of |
jumbo frames of up |
frames of up to |
when the socket at |
the socket at the |
is stored in a |
socket at the root |
stored in a logically |
at the root of |
in a logically centralized |
the root of the |
a logically centralized repository |
root of the tree |
of the tree is |
the tree is ready |
tree is ready for |
is ready for transmission |
each developer checks out |
messages will be recursively |
developer checks out and |
will be recursively pulled |
while lan networks have |
checks out and then |
be recursively pulled from |
lan networks have standard |
networks have standard mtus |
recursively pulled from the |
out and then keeps |
have standard mtus of |
pulled from the tree |
and then keeps a |
from the tree of |
then keeps a working |
the tree of protocol |
keeps a working copy |
tree of protocol stack |
of protocol stack components |
a working copy on |
working copy on his |
copy on his machine |
on his machine that |
his machine that mirrors |
machine that mirrors the |
that mirrors the repository |
at the receiving data |
the receiving data center |
feeds that no longer |
that no longer have |
no longer have data |
longer have data to |
the appliance examines incoming |
the developer edits files |
have data to send |
developer edits files in |
appliance examines incoming repair |
data to send are |
edits files in his |
examines incoming repair packets |
to send are automatically |
send are automatically deregistered |
incoming repair packets and |
files in his working |
repair packets and uses |
in his working copy |
packets and uses them |
his working copy and |
and uses them to |
working copy and periodically |
uses them to recover |
copy and periodically commits |
them to recover missing |
to recover missing data |
recover missing data packets |
and periodically commits the |
sharing and priority i |
periodically commits the changes |
commits the changes back |
the changes back to |
changes back to the |
back to the repository |
the data packet is |
data packet is injected |
packet is injected transparently |
is injected transparently into |
injected transparently into the |
transparently into the stream |
into the stream to |
and prone to oscillatory |
and updates his working |
the stream to the |
prone to oscillatory throughput |
updates his working copy |
stream to the receiving |
to the receiving end |
his working copy to |
to oscillatory throughput when |
working copy to reflect |
oscillatory throughput when scaled |
throughput when scaled up |
copy to reflect the |
recovered data packets will |
to reflect the changes |
data packets will typically |
when we decided to |
packets will typically arrive |
reflect the changes made |
we decided to take |
will typically arrive out |
the changes made by |
decided to take control |
changes made by other |
to take control over |
made by other developers |
take control over event |
order at the end |
control over event processing |
over event processing order |
each commit is assigned |
we also eliminated multithreading |
commit is assigned a |
and hence it is |
is assigned a unique |
hence it is vital |
it is vital that |
is vital that packets |
vital that packets be |
that packets be recovered |
grained scheduling eliminated convoy |
packets be recovered by |
scheduling eliminated convoy behavior |
be recovered by the |
eliminated convoy behavior and |
recovered by the appliance |
convoy behavior and oscillatory |
by the appliance extremely |
behavior and oscillatory throughput |
the repository maintains complete |
the appliance extremely quickly |
and oscillatory throughput of |
repository maintains complete history |
appliance extremely quickly to |
oscillatory throughput of the |
maintains complete history so |
extremely quickly to avoid |
complete history so at |
throughput of the sort |
history so at any |
quickly to avoid triggering |
so at any point |
of the sort that |
at any point in |
to avoid triggering mechanisms |
any point in time |
the sort that can |
point in time it |
avoid triggering mechanisms in |
sort that can disrupt |
in time it is |
triggering mechanisms in commodity |
that can disrupt reliable |
time it is possible |
mechanisms in commodity stacks |
can disrupt reliable multicast |
it is possible to |
in commodity stacks that |
disrupt reliable multicast systems |
is possible to check |
commodity stacks that interpret |
stacks that interpret out |
possible to check out |
reliable multicast systems when |
to check out a |
multicast systems when they |
check out a working |
systems when they run |
out a working copy |
when they run at |
order arrival as congestion |
a working copy for |
they run at high |
arrival as congestion in |
as congestion in the |
run at high data |
working copy for any |
congestion in the network |
at high data rates |
copy for any specified |
high data rates on |
for any specified version |
data rates on a |
rates on a large |
on a large scale |
any specified version number |
flow control while relaying |
control while relaying tcp |
storing a repository in |
the last aspect relates |
maelstrom has two flow |
has two flow control |
two flow control modes |
a repository in the |
last aspect relates to |
repository in the cloud |
aspect relates to the |
in the cloud eliminates |
relates to the creation |
the cloud eliminates worries |
to the creation of |
cloud eliminates worries of |
the creation of new |
creation of new messages |
eliminates worries of data |
worries of data loss |
of data loss due |
data loss due to |
particularly by qsm itself |
illustrates these two modes |
loss due to hardware |
due to hardware failure |
readers who have implemented |
who have implemented multicast |
have implemented multicast protocols |
implemented multicast protocols will |
multicast protocols will know |
protocols will know that |
but issues of access |
will know that most |
issues of access control |
know that most existing |
of access control and |
that most existing systems |
access control and consistency |
most existing systems are |
control and consistency must |
existing systems are push |
and consistency must still |
consistency must still be |
must still be addressed |
the appliance treats tcp |
some layer initiates a |
layer initiates a new |
initiates a new message |
a new message at |
ip packets as conventional |
authorized users should be |
new message at will |
packets as conventional ip |
users should be able |
as conventional ip packets |
should be able to |
and lower layers then |
conventional ip packets and |
be able to commit |
lower layers then buffer |
ip packets and routes |
able to commit new |
layers then buffer that |
packets and routes them |
to commit new versions |
then buffer that message |
and routes them through |
commit new versions of |
buffer that message until |
routes them through without |
them through without modification |
that message until it |
new versions of files |
message until it can |
versions of files to |
until it can be |
it can be sent |
of files to the |
control to proceed between |
to proceed between the |
proceed between the end |
files to the repository |
this makes sense under |
makes sense under the |
sense under the assumption |
under the assumption that |
the assumption that senders |
assumption that senders often |
that senders often generate |
senders often generate bursts |
often generate bursts of |
generate bursts of packets |
but not edit existing |
not edit existing history |
ip s semantics are |
s semantics are not |
semantics are not modified |
the communication subsystem can |
users expect the repository |
communication subsystem can smooth |
when the sending endhost |
expect the repository to |
subsystem can smooth the |
the sending endhost receives |
the repository to be |
can smooth the traffic |
sending endhost receives an |
endhost receives an acknowledgment |
smooth the traffic flow |
repository to be consistent |
the traffic flow and |
to be consistent and |
traffic flow and keep |
it can assume that |
can assume that the |
flow and keep the |
be consistent and for |
assume that the receiving |
and keep the network |
consistent and for any |
that the receiving end |
keep the network interface |
and for any changes |
the network interface busy |
host successfully received the |
successfully received the message |
for any changes they |
any changes they make |
changes they make not |
one consequence is that |
they make not to |
consequence is that messages |
make not to be |
is that messages can |
not to be pre |
maelstrom functions as a |
that messages can linger |
functions as a passive |
as a passive device |
messages can linger for |
can linger for a |
linger for a while |
for a while before |
a while before they |
while before they are |
before they are sent |
snooping outgoing and incoming |
outgoing and incoming traffic |
and incoming traffic at |
incoming traffic at the |
not only does this |
even in the face |
traffic at the data |
only does this increase |
in the face of |
at the data center |
does this increase memory |
this increase memory consumption |
the data center s |
the face of cloud |
data center s edge |
face of cloud services |
center s edge its |
but if a message |
of cloud services that |
s edge its failure |
if a message contains |
cloud services that offer |
edge its failure does |
a message contains current |
services that offer lesser |
its failure does not |
message contains current state |
that offer lesser guarantees |
failure does not disrupt |
contains current state information |
does not disrupt the |
not disrupt the flow |
disrupt the flow of |
the flow of packets |
flow of packets between |
of packets between the |
that state may be |
packets between the two |
between the two data |
the two data centers |
for these reasons we |
state may be stale |
these reasons we do |
may be stale by |
reasons we do not |
be stale by the |
we do not expect |
stale by the time |
do not expect that |
by the time it |
the time it s |
time it s sent |
not expect that clients |
expect that clients will |
that clients will be |
in contrast to this |
side appliance acts as |
appliance acts as a |
acts as a tcp |
clients will be directly |
contrast to this usual |
to this usual approach |
will be directly using |
be directly using the |
directly using the cloud |
using the cloud storage |
qsm implements a pull |
terminating connections and sending |
the cloud storage api |
implements a pull architecture |
connections and sending back |
cloud storage api anytime |
and sending back acks |
storage api anytime soon |
sending back acks immediately |
back acks immediately before |
acks immediately before relaying |
immediately before relaying data |
before relaying data on |
relaying data on appliance |
evaluation evaluation of qsm |
evaluation of qsm could |
of qsm could pursue |
qsm could pursue many |
could pursue many directions |
but that they will |
that they will contact |
they will contact one |
split mode is extremely |
costs of the domain |
will contact one of |
contact one of a |
of the domain crossing |
mode is extremely useful |
one of a set |
the domain crossing between |
is extremely useful when |
of a set of |
domain crossing between the |
extremely useful when endhosts |
a set of front |
crossing between the application |
useful when endhosts have |
between the application and |
when endhosts have limited |
the application and qsm |
endhosts have limited buffering |
have limited buffering capacity |
end servers that are |
servers that are responsible |
protocol design and scalability |
that are responsible for |
since it allows the |
it allows the receive |
are responsible for enforcing |
and interactions between protocol |
responsible for enforcing access |
interactions between protocol properties |
for enforcing access control |
side appliance to buffer |
between protocol properties and |
appliance to buffer incoming |
protocol properties and the |
to buffer incoming data |
properties and the managed |
buffer incoming data over |
and the managed framework |
incoming data over the |
data over the highspeed |
over the highspeed long |
and pushing the data |
here we focus on |
we focus on the |
focus on the latter |
pushing the data into |
the data into the |
data into the cloud |
it also mitigates tcp |
our goal is to |
goal is to arrive |
is to arrive at |
these might consist of |
to arrive at a |
start effects for short |
arrive at a deep |
might consist of virtualized |
at a deep understanding |
consist of virtualized server |
a deep understanding of |
of virtualized server instances |
deep understanding of the |
virtualized server instances in |
understanding of the performance |
server instances in the |
of the performance limits |
maelstrom has to operate |
instances in the cloud |
the performance limits of |
has to operate as |
performance limits of qsm |
to operate as an |
limits of qsm when |
operate as an active |
as an active device |
of qsm when operating |
or traditional physical machines |
qsm when operating at |
traditional physical machines owned |
inserted into the critical |
when operating at high |
physical machines owned by |
into the critical communication |
operating at high data |
machines owned by the |
the critical communication path |
at high data rates |
owned by the community |
critical communication path its |
high data rates with |
communication path its failure |
data rates with large |
path its failure disconnects |
rates with large numbers |
its failure disconnects the |
with large numbers of |
but in either case |
failure disconnects the communication |
large numbers of overlapping |
in either case their |
disconnects the communication path |
numbers of overlapping groups |
either case their local |
the communication path between |
case their local storage |
communication path between the |
their local storage systems |
for reasons of brevity |
path between the two |
between the two data |
the two data centers |
local storage systems are |
storage systems are allowed |
we are unable to |
systems are allowed to |
are unable to undertake |
are allowed to be |
unable to undertake a |
allowed to be cheap |
to undertake a detailed |
to be cheap and |
undertake a detailed analysis |
while maelstrom respects endto |
be cheap and unresilient |
a detailed analysis of |
cheap and unresilient against |
detailed analysis of oscillatory |
and unresilient against hardware |
end flow control connections |
analysis of oscillatory phenomena |
unresilient against hardware failure |
of oscillatory phenomena in |
oscillatory phenomena in this |
phenomena in this paper |
or splits them and |
splits them and implements |
them and implements its |
and implements its own |
implements its own proxy |
also called convoys and |
another consideration with any |
called convoys and broadcast |
convoys and broadcast storms |
consideration with any hosting |
with any hosting solution |
any hosting solution is |
hosting solution is resource |
these plague many multicast |
proxy flow control as |
solution is resource provisioning |
plague many multicast and |
flow control as described |
many multicast and pub |
control as described above |
open source communities with |
source communities with limited |
communities with limited budgets |
with limited budgets and |
limited budgets and private |
budgets and private enterprises |
it is not designed |
and private enterprises that |
is not designed for |
event prioritization eliminated such |
private enterprises that are |
not designed for routinely |
prioritization eliminated such problems |
enterprises that are increasingly |
designed for routinely congested |
eliminated such problems in |
that are increasingly cost |
for routinely congested networks |
such problems in the |
problems in the configurations |
in the configurations tested |
the configurations tested by |
configurations tested by our |
tested by our experiments |
the addition of fec |
addition of fec under |
of fec under tcp |
sensitive may well prefer |
may well prefer to |
well prefer to pay |
prefer to pay just |
to pay just for |
ip flow control allows |
pay just for the |
flow control allows it |
just for the resources |
control allows it to |
for the resources they |
allows it to steal |
on varying numbers of |
varying numbers of nodes |
it to steal bandwidth |
the resources they use |
to steal bandwidth from |
steal bandwidth from other |
we ll find that |
bandwidth from other competing |
ll find that the |
from other competing flows |
find that the experiments |
other competing flows running |
rather than trying to |
that the experiments have |
competing flows running without |
than trying to budget |
the experiments have a |
experiments have a pattern |
trying to budget in |
flows running without fec |
to budget in advance |
running without fec in |
without fec in the |
fec in the link |
budget in advance what |
in scenario after scenario |
in advance what they |
advance what they are |
what they are going |
though maintaining fairness versus |
they are going to |
maintaining fairness versus similarly |
the performance of qsm |
are going to need |
fairness versus similarly fec |
performance of qsm is |
of qsm is ultimately |
qsm is ultimately limited |
is ultimately limited by |
ultimately limited by overheads |
cloud computing makes this |
limited by overheads associated |
computing makes this a |
by overheads associated with |
makes this a possibility |
overheads associated with memory |
associated with memory management |
with memory management in |
memory management in the |
management in the managed |
in the managed environment |
and increased competition among |
increased competition among providers |
competition among providers of |
among providers of commodity |
providers of commodity services |
the more memory in |
more memory in use |
of commodity services will |
commodity services will ensure |
friendliness with conventional tcp |
services will ensure that |
the higher the overheads |
will ensure that prices |
higher the overheads of |
ip flows is not |
ensure that prices are |
the overheads of the |
flows is not a |
that prices are reasonable |
overheads of the memory |
is not a primary |
of the memory management |
not a primary protocol |
the memory management subsystem |
a primary protocol design |
memory management subsystem and |
primary protocol design goal |
management subsystem and the |
protocol design goal on |
design goal on over |
subsystem and the more |
c ase s tudy |
and the more cpu |
the more cpu time |
more cpu time it |
cpu time it consumes |
leaving less time for |
less time for qsm |
time for qsm to |
for qsm to run |
which are often dedicated |
are often dedicated to |
often dedicated to specific |
dedicated to specific highvalue |
to specific highvalue applications |
these aren t just |
aren t just garbage |
t just garbage collection |
just garbage collection costs |
we see evidence for |
see evidence for this |
evidence for this assertion |
for this assertion in |
every aspect of memory |
this assertion in the |
by far the most |
aspect of memory management |
assertion in the routine |
far the most popular |
of memory management gets |
in the routine use |
the most popular general |
memory management gets expensive |
the routine use of |
most popular general purpose |
routine use of parallel |
popular general purpose cloud |
and the costs grow |
use of parallel flows |
general purpose cloud storage |
the costs grow linearly |
purpose cloud storage service |
costs grow linearly in |
cloud storage service today |
grow linearly in the |
storage service today is |
linearly in the amount |
service today is amazon |
in the amount of |
today is amazon s |
the amount of memory |
amount of memory in |
of memory in use |
and udp blast protocols |
is amazon s s |
when qsm runs flat |
we chose to use |
cpu cycles are a |
chose to use this |
cycles are a precious |
are a precious commodity |
to use this as |
use this as a |
this as a basis |
as a basis for |
a basis for cost |
basis for cost studies |
for cost studies and |
minimizing the memory footprint |
cost studies and for |
the memory footprint turns |
studies and for the |
and for the implementation |
memory footprint turns out |
for the implementation of |
footprint turns out to |
the implementation of our |
turns out to be |
implementation of our system |
out to be the |
to be the key |
be the key to |
the key to high |
key to high performance |
all results reported here |
results reported here come |
reported here come from |
here come from experiments |
come from experiments on |
from experiments on a |
is an appealing choice |
an appealing choice because |
both in commercial deployments |
appealing choice because amazon |
in commercial deployments and |
choice because amazon also |
commercial deployments and by |
because amazon also offers |
deployments and by researchers |
amazon also offers the |
and by researchers seeking |
also offers the ec |
by researchers seeking to |
researchers seeking to transfer |
seeking to transfer large |
to transfer large amounts |
transfer large amounts of |
large amounts of data |
amounts of data over |
of data over high |
cluster of pentium iii |
so it is possible |
it is possible to |
is possible to use |
possible to use their |
to use their services |
layered interleaving in layered |
interleaving in layered interleaving |
use their services as |
their services as a |
services as a complete |
as a complete hosting |
an fec protocol with |
fec protocol with rate |
a complete hosting solution |
complete hosting solution with |
hosting solution with low |
solution with low latency |
with low latency access |
low latency access to |
connected into a single |
latency access to storage |
into a single broadcast |
a single broadcast domain |
single broadcast domain using |
broadcast domain using a |
is produced by running |
domain using a switched |
produced by running c |
by running c multiple |
running c multiple instances |
c multiple instances of |
multiple instances of an |
nodes run windows server |
fec protocol simultaneously with |
protocol simultaneously with increasing |
simultaneously with increasing interleave |
with increasing interleave indices |
increasing interleave indices i |
the cost analysis is |
cost analysis is based |
analysis is based on |
is based on real |
world traces taken from |
traces taken from the |
taken from the subversion |
from the subversion repositories |
our benchmark is an |
benchmark is an nary |
the subversion repositories of |
subversion repositories of popular |
repositories of popular open |
of popular open source |
popular open source projects |
linked to the qsm |
to the qsm library |
subversion represents each revision |
represents each revision in |
running in the same |
in the same process |
each revision in a |
revision in a repository |
in a repository s |
a repository s history |
regardless of how many |
of how many changes |
how many changes it |
many changes it contains |
the first for data |
as a diff against |
a diff against previous |
diff against previous revisions |
at the maximum possible |
the maximum possible rate |
and the second for |
the second for meta |
data such as the |
the majority of the |
such as the author |
majority of the figures |
of the figures include |
and other revision properties |
but these intervals are |
our cost analysis is |
these intervals are sometimes |
cost analysis is based |
intervals are sometimes so |
analysis is based on |
are sometimes so small |
is based on the |
sometimes so small that |
based on the sizes |
so small that they |
on the sizes of |
small that they may |
the sizes of these |
that they may not |
sizes of these files |
they may not always |
of these files and |
may not always be |
these files and the |
not always be visible |
files and the time |
three instances of an |
and the time at |
the time at which |
time at which each |
growing cost of memory |
at which each revision |
cost of memory allocation |
which each revision was |
each revision was committed |
looking up the size |
up the size of |
the size of these |
size of these special |
of these special files |
these special files is |
the first instance with |
special files is only |
first instance with interleave |
instance with interleave i |
files is only possible |
is only possible if |
only possible if one |
possible if one has |
if one has filesystem |
one has filesystem level |
has filesystem level access |
filesystem level access to |
level access to the |
access to the disk |
to the disk on |
the disk on which |
disk on which the |
the second with interleave |
second with interleave i |
on which the repository |
which the repository is |
the repository is stored |
so we had to |
we had to use |
had to use subversion |
to use subversion s |
throughput as a function |
use subversion s mirroring |
as a function of |
and the third with |
the third with interleave |
a function of the |
subversion s mirroring capability |
third with interleave i |
function of the number |
s mirroring capability to |
of the number of |
the number of nodes |
mirroring capability to fetch |
capability to fetch revisions |
to fetch revisions from |
fetch revisions from the |
revisions from the network |
accessible repository and replay |
repository and replay them |
and replay them against |
replay them against a |
them against a local |
against a local copy |
doing this also implicitly |
this also implicitly gives |
also implicitly gives us |
implicitly gives us the |
gives us the log |
us the log of |
the log of timestamps |
log of timestamps indicating |
of timestamps indicating when |
timestamps indicating when each |
indicating when each revision |
processor utilization as a |
fec encoding is simply |
when each revision was |
utilization as a function |
encoding is simply an |
each revision was committed |
as a function of |
is simply an xor |
a function of the |
simply an xor of |
function of the multicast |
an xor of the |
of the multicast rate |
xor of the r |
thus it is possible |
of the r data |
it is possible to |
the r data packets |
r data packets hence |
is possible to calculate |
possible to calculate the |
to calculate the bandwidth |
in layered interleaving each |
layered interleaving each data |
interleaving each data packet |
each data packet is |
data packet is included |
packet is included in |
is included in c |
included in c xors |
each of which is |
of which is generated |
which is generated at |
is generated at different |
generated at different interleaves |
at different interleaves from |
different interleaves from the |
transaction costs of pushing |
interleaves from the original |
from the original data |
the original data stream |
costs of pushing the |
of pushing the two |
pushing the two files |
the two files for |
two files for each |
memory overheads on the |
files for each revision |
overheads on the sender |
as we shall describe |
for each revision into |
on the sender we |
we shall describe shortly |
each revision into s |
the sender we begin |
sender we begin by |
we begin by showing |
begin by showing that |
ensures that the c |
by showing that memory |
that the c xors |
showing that memory overhead |
the c xors containing |
that memory overhead at |
c xors containing a |
memory overhead at the |
based on amazon s |
xors containing a data |
overhead at the sender |
on amazon s current |
containing a data packet |
at the sender is |
amazon s current pricing |
a data packet do |
the sender is a |
s current pricing structure |
data packet do not |
sender is a central |
packet do not have |
is a central to |
do not have any |
a central to throughput |
shown in table i |
not have any other |
have any other data |
any other data packet |
other data packet in |
data packet in common |
table i a mazon |
i a mazon s |
a mazon s s |
the resulting protocol effectively |
resulting protocol effectively has |
protocol effectively has a |
shows throughput in messages |
effectively has a rate |
has a rate of |
s in experiments with |
senders multicasting to a |
multicasting to a varying |
to a varying number |
a varying number of |
varying number of receivers |
with each xor generated |
each xor generated from |
xor generated from r |
generated from r data |
all of which belong |
from r data packets |
of which belong to |
r data packets and |
which belong to a |
data packets and each |
belong to a single |
to a single group |
packets and each data |
and each data packet |
each data packet included |
data packet included in |
packet included in c |
included in c xors |
with a single sender |
no rate limit was |
rate limit was used |
illustrates layered interleaving for |
layered interleaving for a |
the sender has more |
sender has more work |
has more work to |
more work to do |
work to do than |
to do than the |
do than the receivers |
than the receivers and |
the receivers and on |
receivers and on our |
and on our clusters |
isn t fast enough |
t fast enough to |
fast enough to saturate |
enough to saturate the |
to saturate the network |
we report the highest |
report the highest combined |
the highest combined send |
highest combined send rate |
combined send rate that |
send rate that the |
rate that the system |
that the system could |
the system could sustain |
system could sustain without |
could sustain without developing |
sustain without developing backlogs |
without developing backlogs at |
developing backlogs at the |
backlogs at the senders |
why does performance decrease |
does performance decrease with |
performance decrease with the |
decrease with the number |
with the number of |
the number of receivers |
let s focus on |
s focus on a |
standard fec schemes can |
fec schemes can be |
schemes can be made |
can be made resistant |
be made resistant to |
made resistant to a |
resistant to a certain |
to a certain loss |
a certain loss burst |
not included in the |
certain loss burst length |
included in the analysis |
loss burst length at |
in the analysis is |
shows that whereas receivers |
burst length at the |
the analysis is the |
that whereas receivers are |
length at the cost |
analysis is the cost |
whereas receivers are not |
at the cost of |
is the cost of |
receivers are not cpu |
the cost of increased |
the cost of fetching |
cost of increased recovery |
cost of fetching data |
of increased recovery latency |
of fetching data out |
increased recovery latency for |
fetching data out of |
recovery latency for all |
and loss rates in |
data out of s |
latency for all lost |
for all lost packets |
loss rates in this |
rates in this experiment |
to be served to |
including smaller bursts and |
be served to clients |
smaller bursts and singleton |
bursts and singleton drops |
this cost will vary |
the sender is saturated |
cost will vary depending |
will vary depending on |
layered interleaving provides graceful |
vary depending on how |
and hence is the |
hence is the bottleneck |
depending on how much |
interleaving provides graceful degradation |
on how much caching |
provides graceful degradation in |
running this test again |
how much caching is |
graceful degradation in the |
this test again in |
much caching is done |
degradation in the face |
test again in a |
caching is done on |
in the face of |
again in a profiler |
is done on the |
the face of bursty |
in a profiler reveals |
done on the front |
face of bursty loss |
a profiler reveals that |
of bursty loss for |
profiler reveals that the |
bursty loss for constant |
reveals that the percentage |
loss for constant encoding |
that the percentage of |
for constant encoding overhead |
the percentage of time |
constant encoding overhead singleton |
percentage of time spent |
encoding overhead singleton random |
of time spent in |
overhead singleton random losses |
time spent in qsm |
singleton random losses are |
spent in qsm code |
random losses are recovered |
in qsm code is |
losses are recovered as |
qsm code is decreasing |
are recovered as quickly |
recovered as quickly as |
as quickly as possible |
whereas more and more |
more and more time |
and more time is |
more time is spent |
time is spent in |
is spent in mscorwks |
by xors generated with |
xors generated with an |
generated with an interleave |
with an interleave of |
and dedicated servers potentially |
and each successive layer |
dedicated servers potentially having |
each successive layer of |
servers potentially having much |
successive layer of xors |
potentially having much more |
layer of xors generated |
having much more due |
of xors generated at |
much more due to |
xors generated at a |
more due to inexpensive |
generated at a higher |
due to inexpensive sata |
at a higher interleave |
to inexpensive sata disks |
a higher interleave catches |
higher interleave catches larger |
interleave catches larger bursts |
catches larger bursts missed |
larger bursts missed by |
bursts missed by the |
missed by the previous |
by the previous layer |
it is not unreasonable |
is not unreasonable to |
not unreasonable to assume |
unreasonable to assume that |
the implementation of this |
shows that the main |
to assume that a |
implementation of this algorithm |
that the main culprit |
assume that a cache |
of this algorithm is |
the main culprit behind |
that a cache hit |
this algorithm is simple |
main culprit behind the |
a cache hit rate |
algorithm is simple and |
culprit behind the increase |
cache hit rate of |
is simple and shown |
behind the increase of |
hit rate of close |
simple and shown in |
the increase of overhead |
rate of close to |
and shown in figure |
increase of overhead is |
of overhead is a |
overhead is a figure |
a set of repair |
set of repair bins |
of repair bins is |
the percentages of the |
repair bins is maintained |
percentages of the profiler |
bins is maintained for |
of the profiler samples |
is maintained for each |
the profiler samples taken |
maintained for each layer |
profiler samples taken from |
samples taken from qsm |
taken from qsm and |
from qsm and clr |
qsm and clr dlls |
with i bins for |
i bins for a |
bins for a layer |
for a layer with |
a layer with interleave |
layer with interleave i |
a repair bin consists |
repair bin consists of |
bin consists of a |
consists of a partially |
of a partially constructed |
public subversion repositories of |
a partially constructed repair |
subversion repositories of the |
partially constructed repair packet |
memory allocation and garbage |
repositories of the debian |
allocation and garbage collection |
of the debian linux |
and garbage collection overheads |
the debian linux community |
an xor and the |
garbage collection overheads on |
debian linux community amount |
xor and the recipe |
collection overheads on the |
linux community amount to |
and the recipe list |
overheads on the sender |
community amount to a |
the recipe list of |
on the sender node |
amount to a total |
recipe list of identifiers |
to a total of |
list of identifiers of |
the former grows by |
a total of only |
of identifiers of data |
identifiers of data packets |
of data packets that |
data packets that compose |
packets that compose the |
that compose the xor |
each intercepted data packet |
and the latter by |
intercepted data packet is |
data packet is added |
the only outgoing bandwidth |
packet is added to |
only outgoing bandwidth costs |
is added to each |
outgoing bandwidth costs are |
added to each layer |
bandwidth costs are then |
to each layer where |
costs are then to |
each layer where adding |
are then to to |
layer where adding to |
then to to replace |
where adding to a |
to to replace failed |
adding to a layer |
to replace failed frontend |
to a layer simply |
replace failed frontend servers |
a layer simply means |
failed frontend servers or |
layer simply means choosing |
frontend servers or to |
simply means choosing a |
servers or to synchronize |
means choosing a repair |
or to synchronize replicas |
choosing a repair bin |
to synchronize replicas if |
a repair bin from |
synchronize replicas if more |
this configuration is typical |
repair bin from the |
replicas if more than |
configuration is typical of |
bin from the layer |
if more than one |
is typical of the |
from the layer s |
the layer s set |
typical of the host |
more than one is |
of the host environment |
than one is in |
one is in use |
incrementally updating the xor |
the host environment expected |
updating the xor with |
host environment expected for |
the xor with the |
in the case of |
the case of ec |
xor with the new |
environment expected for our |
with the new data |
the new data packet |
expected for our target |
for our target applications |
and adding the data |
the bandwidth costs are |
adding the data packet |
bandwidth costs are actually |
the data packet s |
costs are actually waived |
data packet s header |
are actually waived and |
packet s header to |
actually waived and the |
s header to the |
waived and the user |
header to the recipe |
and the user then |
to the recipe list |
of the overhead is |
the user then pays |
performance of mfs priorities |
the overhead is the |
user then pays only |
of mfs priorities and |
a counter is incremented |
overhead is the allocation |
then pays only for |
mfs priorities and writeback |
counter is incremented as |
is the allocation of |
pays only for the |
priorities and writeback schemes |
is incremented as each |
the allocation of byte |
only for the traffic |
incremented as each data |
allocation of byte arrays |
for the traffic between |
as each data packet |
each test consists of |
of byte arrays to |
the traffic between the |
each data packet arrives |
test consists of two |
byte arrays to send |
traffic between the front |
data packet arrives at |
consists of two concurrent |
arrays to send in |
packet arrives at the |
of two concurrent processes |
to send in the |
arrives at the appliance |
end servers and their |
two concurrent processes executing |
send in the application |
servers and their clients |
concurrent processes executing different |
and choosing the repair |
processes executing different workloads |
choosing the repair bin |
the repair bin from |
table ii shows the |
repair bin from the |
ii shows the cost |
mean times to completion |
bin from the layer |
shows the cost of |
times to completion are |
from the layer s |
the cost of using |
cost of using s |
the layer s set |
to completion are shown |
layer s set is |
completion are shown with |
s set is done |
are shown with standard |
for a number of |
set is done by |
shown with standard deviations |
a number of individual |
is done by taking |
number of individual open |
done by taking the |
of individual open source |
by taking the modulo |
individual open source projects |
taking the modulo of |
the modulo of the |
three different policies for |
modulo of the counter |
different policies for writing |
of the counter with |
as well as an |
policies for writing back |
the counter with the |
well as an aggregate |
for writing back files |
counter with the number |
as an aggregate for |
writing back files are |
with the number of |
an aggregate for the |
back files are listed |
the number of bins |
number of bins in |
of bins in each |
bins in each layer |
of time is spent |
under uniform or differentiated |
time is spent exclusively |
uniform or differentiated priorities |
for a layer with |
is spent exclusively on |
a layer with interleave |
spent exclusively on copying |
exclusively on copying memory |
reads take precedence over |
take precedence over writes |
on copying memory in |
repositories of the debian |
of the debian community |
copying memory in the |
memory in the clr |
also shown is an |
values in bold are |
the xth intercepted packet |
shown is an estimate |
in bold are of |
xth intercepted packet is |
is an estimate for |
bold are of particular |
intercepted packet is added |
even though we used |
are of particular significance |
an estimate for the |
packet is added to |
though we used our |
we used our own |
used our own scatter |
is added to the |
estimate for the apache |
note that elapsed times |
for the apache software |
gather serialization scheme that |
that elapsed times for |
elapsed times for write |
serialization scheme that efficiently |
scheme that efficiently uses |
times for write workloads |
for write workloads give |
that efficiently uses scatter |
the apache software foundation |
write workloads give the |
when a repair bin |
workloads give the time |
a repair bin fills |
give the time until |
repair bin fills up |
the time until the |
bin fills up its |
time until the process |
fills up its recipe |
until the process running |
the increase in the |
up its recipe list |
the process running the |
increase in the memory |
its recipe list contains |
process running the workload |
in the memory allocation |
recipe list contains r |
running the workload finishes |
the memory allocation overhead |
list contains r data |
contains r data packets |
memory allocation overhead and |
not when the log |
r data packets it |
data packets it fires |
allocation overhead and the |
when the log is |
the log is flushed |
overhead and the activity |
apache has taken the |
and the activity of |
a repair packet is |
this is shown in |
the activity of the |
has taken the unusual |
repair packet is generated |
is shown in figure |
activity of the garbage |
taken the unusual approach |
packet is generated consisting |
of the garbage collector |
the garbage collector are |
is generated consisting of |
the unusual approach of |
garbage collector are caused |
modified and then deleted |
generated consisting of the |
collector are caused by |
are caused by the |
consisting of the xor |
unusual approach of using |
caused by the increasing |
of the xor and |
which requires the file |
by the increasing memory |
the increasing memory usage |
the xor and the |
requires the file update |
approach of using a |
xor and the recipe |
the file update rpc |
of using a single |
and the recipe list |
using a single repository |
file update rpc to |
a single repository for |
reflectsan increase of the |
the recipe list and |
update rpc to be |
single repository for all |
increase of the average |
recipe list and is |
rpc to be cancelled |
repository for all of |
of the average number |
list and is scheduled |
to be cancelled if |
for all of its |
the average number of |
and is scheduled for |
be cancelled if it |
all of its projects |
average number of multicasts |
is scheduled for sending |
cancelled if it is |
number of multicasts pending |
if it is still |
of multicasts pending completion |
it is still in |
is still in transmission |
still in transmission when |
while the repair bin |
in transmission when the |
the repair bin is |
transmission when the remove |
repair bin is re |
when the remove rpc |
the remove rpc is |
remove rpc is initiated |
both public and restricted |
initialized with an empty |
with an empty recipe |
an update to a |
an empty recipe list |
update to a file |
empty recipe list and |
to a file will |
recipe list and blank |
a file will supersede |
list and blank xor |
file will supersede any |
a copy is kept |
will supersede any previous |
copy is kept by |
supersede any previous queued |
is kept by the |
any previous queued updates |
due to access control |
kept by the sender |
to access control restrictions |
by the sender for |
access control restrictions on |
incoming repair packets are |
the sender for possible |
compiles the entire mfs |
the entire mfs file |
repair packets are processed |
sender for possible loss |
for possible loss recovery |
entire mfs file system |
packets are processed as |
are processed as follows |
mfs file system and |
file system and its |
notice that memory consumption |
that memory consumption grows |
system and its rpc |
and its rpc library |
memory consumption grows nearly |
if all the data |
control restrictions on some |
all the data packets |
times faster than the |
faster than the number |
the data packets contained |
restrictions on some paths |
than the number of |
data packets contained in |
the number of messages |
packets contained in the |
number of messages pending |
files and directories comprising |
contained in the repair |
of messages pending acknowledgement |
in the repair s |
the repair s recipe |
repair s recipe list |
s recipe list have |
recipe list have been |
list have been received |
have been received successfully |
if we freeze the |
we freeze the sender |
subversion s mirroring tool |
the repair packet is |
repair packet is discarded |
freeze the sender process |
the sender process and |
sender process and inspect |
process and inspect the |
if the repair s |
and inspect the contents |
inspect the contents of |
the repair s recipe |
repair s recipe list |
none of the files |
of the files are |
the contents of the |
s recipe list contains |
recipe list contains a |
the files are initially |
contents of the managed |
of the managed heap |
list contains a single |
files are initially in |
are initially in the |
contains a single missing |
a single missing data |
initially in the cache |
s mirroring tool was |
we find that the |
single missing data packet |
mirroring tool was unable |
this workload performs an |
find that the number |
tool was unable to |
recovery can occur immediately |
workload performs an intensive |
that the number of |
was unable to create |
can occur immediately by |
performs an intensive pattern |
the number of objects |
unable to create local |
an intensive pattern of |
number of objects in |
to create local copy |
intensive pattern of reads |
of objects in memory |
pattern of reads and |
objects in memory is |
of reads and writes |
in memory is more |
reads and writes files |
memory is more than |
and writes files without |
is more than twice |
writes files without raising |
more than twice the |
files without raising the |
than twice the number |
without raising the issue |
the complete log of |
twice the number of |
raising the issue of |
the issue of concurrent |
the number of multicasts |
number of multicasts pending |
issue of concurrent accesses |
complete log of timestamps |
of multicasts pending acknowledgement |
a topic we tackle |
topic we tackle in |
we tackle in section |
although some of these |
some of these have |
of these have already |
these have already been |
have already been acknowledged |
they haven t yet |
haven t yet been |
t yet been garbage |
yet been garbage collected |
the growing amount of |
growing amount of unacknowledged |
amount of unacknowledged data |
of unacknowledged data is |
unacknowledged data is caused |
data is caused by |
is caused by the |
performance evaluation of these |
caused by the increase |
evaluation of these workloads |
by the increase of |
the increase of the |
increase of the average |
of the average time |
the average time to |
average time to acknowledge |
we classified grep and |
time to acknowledge a |
classified grep and read |
to acknowledge a message |
grep and read as |
and read as foreground |
read as foreground workloads |
and compile and write |
compile and write as |
and write as background |
write as background workloads |
four combined workloads were |
combined workloads were then |
workloads were then generated |
were then generated by |
how much does it |
this grows because of |
much does it cost |
then generated by running |
grows because of the |
generated by running a |
because of the increasing |
by running a foreground |
of the increasing time |
running a foreground and |
the increasing time to |
a foreground and a |
increasing time to circulate |
foreground and a background |
time to circulate a |
and a background workload |
to circulate a token |
a background workload concurrently |
description monthly storage bandwidth |
circulate a token around |
monthly storage bandwidth in |
a token around the |
storage bandwidth in bandwidth |
we denote these as |
denote these as gc |
bandwidth in bandwidth out |
token around the region |
around the region for |
the region for purposes |
region for purposes of |
for purposes of state |
purposes of state aggregation |
in bandwidth out per |
layer with interleave of |
the time to acknowledge |
time to acknowledge is |
to acknowledge is only |
acknowledge is only slightly |
is only slightly higher |
only slightly higher than |
slightly higher than the |
higher than the expected |
s to wait until |
to wait until the |
wait until the next |
until the next token |
the next token round |
plus the roundtrip time |
as we scale up |
three types of rpcs |
types of rpcs predominate |
roundtrip time becomes dominant |
these experiments show that |
fetches of file data |
experiments show that the |
show that the critical |
that the critical factor |
the critical factor determining |
and store operations for |
critical factor determining performance |
store operations for files |
factor determining performance is |
determining performance is the |
performance is the time |
is the time needed |
the time needed for |
in descending order of |
time needed for the |
descending order of priority |
needed for the system |
for the system to |
the system to aggregate |
system to aggregate state |
to aggregate state over |
aggregate state over regions |
the aim of the |
aim of the experiments |
of the experiments was |
the experiments was to |
experiments was to demonstrate |
was to demonstrate that |
to demonstrate that priorities |
demonstrate that priorities improve |
that priorities improve the |
they shed light on |
priorities improve the performance |
shed light on a |
improve the performance of |
light on a mechanism |
the performance of the |
on a mechanism that |
performance of the foreground |
a mechanism that links |
of the foreground workloads |
mechanism that links latency |
that links latency to |
links latency to throughput |
the four combined workloads |
four combined workloads were |
combined workloads were executed |
via increased memory consumption |
workloads were executed on |
increased memory consumption and |
were executed on top |
memory consumption and the |
executed on top of |
consumption and the resulting |
on top of mfs |
and the resulting increase |
top of mfs configured |
the resulting increase in |
of mfs configured with |
resulting increase in allocation |
mfs configured with either |
increase in allocation and |
configured with either synchronous |
in allocation and garbage |
with either synchronous writes |
allocation and garbage collection |
and garbage collection overheads |
update logging or asynchronous |
logging or asynchronous writeback |
the update logging mechanism |
update logging mechanism was |
logging mechanism was configured |
mechanism was configured to |
was configured to delay |
configured to delay flushing |
to delay flushing an |
ms increase in latency |
delay flushing an update |
reads apache software foundation |
flushing an update for |
apache software foundation debian |
an update for at |
update for at least |
for at least a |
at least a second |
mb increase in memory |
increase in memory consumption |
software foundation debian linux |
every experiment was repeated |
can inflate overheads by |
experiment was repeated ten |
was repeated ten times |
repeated ten times at |
ten times at each |
times at each of |
at each of five |
each of five possible |
of five possible bandwidth |
five possible bandwidth values |
foundation debian linux community |
combining the xor in |
the xor in the |
xor in the repair |
in the repair with |
shows the time taken |
the repair with the |
the time taken for |
repair with the other |
time taken for each |
with the other successfully |
taken for each workload |
the other successfully received |
and degrade the throughput |
for each workload at |
other successfully received data |
successfully received data packets |
each workload at a |
degrade the throughput by |
workload at a bandwidth |
at a bandwidth of |
if the repair contains |
the repair contains multiple |
repair contains multiple missing |
contains multiple missing data |
multiple missing data packets |
it cannot be used |
one way to alleviate |
cannot be used immediately |
way to alleviate the |
be used immediately for |
to alleviate the problem |
used immediately for recovery |
alleviate the problem we |
immediately for recovery it |
for recovery it is |
recovery it is instead |
it is instead stored |
is instead stored in |
ve identified could be |
instead stored in a |
identified could be to |
stored in a table |
could be to reduce |
in a table that |
be to reduce the |
shows overall results for |
a table that maps |
to reduce the latency |
overall results for selected |
table that maps missing |
reduce the latency of |
results for selected configurations |
that maps missing data |
the latency of state |
maps missing data packets |
latency of state aggregation |
missing data packets to |
the results in table |
data packets to repair |
packets to repair packets |
so that it grows |
that it grows sub |
demonstrate the benefit of |
the benefit of priorities |
whenever a data packet |
benefit of priorities when |
a data packet is |
of priorities when there |
data packet is subsequently |
priorities when there is |
packet is subsequently received |
when there is high |
is subsequently received or |
there is high contention |
subsequently received or recovered |
this might be achieved |
is high contention between |
might be achieved by |
high contention between high |
be achieved by using |
this table is checked |
achieved by using a |
table is checked to |
by using a deeper |
priority rpcs and writes |
is checked to see |
using a deeper hierarchy |
checked to see if |
a deeper hierarchy of |
to see if any |
deeper hierarchy of rings |
in both the i |
see if any xors |
if any xors now |
any xors now have |
and by letting tokens |
xors now have singleton |
by letting tokens in |
now have singleton losses |
letting tokens in each |
have singleton losses due |
bound gw and rw |
tokens in each of |
singleton losses due to |
gw and rw workloads |
in each of these |
losses due to the |
each of these rings |
due to the presence |
of these rings circulate |
to the presence of |
adding priorities decreases the |
these rings circulate independently |
the presence of the |
priorities decreases the time |
presence of the new |
decreases the time required |
of the new packet |
the time required for |
this would create a |
the new packet and |
time required for the |
would create a more |
new packet and can |
required for the foreground |
create a more complex |
a more complex structure |
for the foreground workload |
packet and can be |
the foreground workload to |
and can be used |
foreground workload to execute |
can be used for |
but aggregation latency would |
be used for recovering |
aggregation latency would grow |
used for recovering other |
latency would grow logarithmically |
for recovering other missing |
would grow logarithmically rather |
recovering other missing packets |
grow logarithmically rather than |
logarithmically rather than linearly |
is reducing state aggregation |
reducing state aggregation latency |
state aggregation latency the |
aggregation latency the only |
latency the only option |
xors received from different |
see elapsed times for |
received from different layers |
elapsed times for rw |
we evaluated two alternative |
from different layers interact |
evaluated two alternative approaches |
different layers interact to |
layers interact to recover |
read with synchronous writes |
interact to recover missing |
with synchronous writes in |
to recover missing data |
but found that neither |
synchronous writes in the |
recover missing data packets |
found that neither can |
writes in the table |
that neither can substitute |
neither can substitute for |
can substitute for lowering |
since an xor received |
substitute for lowering the |
an xor received at |
for lowering the latency |
xor received at a |
lowering the latency of |
this is particularly true |
received at a higher |
the latency of the |
is particularly true in |
at a higher interleave |
latency of the recovery |
particularly true in the |
a higher interleave can |
of the recovery state |
true in the rw |
in the rw test |
the recovery state aggregation |
higher interleave can recover |
interleave can recover a |
can recover a packet |
recover a packet that |
where the foreground workload |
a packet that makes |
our first approach varies |
the foreground workload generates |
packet that makes an |
first approach varies the |
foreground workload generates heavy |
that makes an earlier |
approach varies the rate |
workload generates heavy contention |
makes an earlier xor |
varies the rate of |
generates heavy contention by |
an earlier xor at |
the rate of aggregation |
heavy contention by fetching |
earlier xor at a |
rate of aggregation by |
contention by fetching a |
xor at a lower |
of aggregation by increasing |
by fetching a large |
at a lower interleave |
aggregation by increasing the |
fetching a large volume |
a lower interleave usable |
by increasing the rate |
a large volume of |
large volume of data |
increasing the rate at |
lower interleave usable hence |
the rate at which |
rate at which tokens |
at which tokens are |
which tokens are released |
the greatest benefits are |
greatest benefits are observable |
though layered interleaving is |
benefits are observable for |
layered interleaving is equivalent |
are observable for the |
interleaving is equivalent to |
observable for the combination |
is equivalent to c |
for the combination of |
equivalent to c different |
the combination of asynchronous |
combination of asynchronous writes |
of asynchronous writes with |
asynchronous writes with priorities |
since here the performance |
this helps only up |
here the performance of |
helps only up to |
the performance of the |
only up to a |
performance of the background |
up to a point |
of the background workload |
instances in terms of |
the background workload can |
in terms of overhead |
background workload can also |
terms of overhead and |
workload can also improve |
of overhead and design |
can also improve by |
also improve by not |
improve by not having |
by not having to |
not having to wait |
its recovery power is |
having to wait for |
recovery power is much |
to wait for its |
power is much higher |
wait for its writes |
is much higher and |
much higher and comes |
for its writes to |
higher and comes close |
its writes to be |
and comes close to |
comes close to standard |
writes to be committed |
to be committed at |
be committed at the |
more than one aggregation |
committed at the server |
than one aggregation is |
one aggregation is underway |
aggregation is underway at |
is underway at a |
underway at a time |
in the gc and |
the gc and rc |
gc and rc tests |
and successive tokens perform |
successive tokens perform redundant |
tokens perform redundant work |
where there is lighter |
there is lighter contention |
optimizations staggered start for |
staggered start for rate |
the impact of priorities |
impact of priorities is |
processing all these tokens |
of priorities is negligible |
all these tokens is |
limiting in the naive |
these tokens is costly |
in the naive implementation |
the naive implementation of |
and in some cases |
naive implementation of the |
in some cases results |
implementation of the layered |
of the layered interleaving |
the layered interleaving algorithm |
some cases results in |
cases results in a |
results in a slight |
in a slight overhead |
repair packets are transmitted |
packets are transmitted as |
are transmitted as soon |
but this is chiefly |
transmitted as soon as |
this is chiefly after |
as soon as repair |
s decreases the amount |
is chiefly after adding |
soon as repair bins |
decreases the amount of |
chiefly after adding priorities |
as repair bins fill |
the amount of unacknowledged |
after adding priorities to |
adding priorities to rpcs |
amount of unacknowledged data |
of unacknowledged data by |
repair bins fill and |
bins fill and allow |
fill and allow them |
it is natural to |
and allow them to |
is natural to ask |
allow them to be |
natural to ask when |
them to be constructed |
to ask when they |
ask when they are |
when they are beneficial |
and to what degree |
but increases throughput by |
increases throughput by less |
all the repair bins |
throughput by less than |
the repair bins in |
in addition to comparing |
repair bins in a |
addition to comparing mfs |
bins in a layer |
to comparing mfs with |
in a layer fill |
comparing mfs with and |
a layer fill in |
mfs with and without |
layer fill in quick |
with and without prioritised |
fill in quick succession |
and without prioritised rpcs |
we also investigate the |
also investigate the performance |
investigate the performance impact |
the performance impact of |
performance impact of replacing |
time spent allocating byte |
impact of replacing synchronous |
spent allocating byte arrays |
the arrival of packets |
of replacing synchronous rpcs |
allocating byte arrays in |
replacing synchronous rpcs for |
byte arrays in the |
synchronous rpcs for file |
arrays in the application |
rpcs for file updates |
for file updates with |
file updates with asynchronous |
updates with asynchronous writeback |
the performance of these |
performance of these alternatives |
of these alternatives is |
these alternatives is compared |
alternatives is compared in |
is compared in a |
compared in a set |
in a set of |
a set of microbenchmarks |
and with workloads gathered |
memory used on sender |
with workloads gathered from |
used on sender and |
workloads gathered from windows |
on sender and the |
gathered from windows nt |
sender and the number |
from windows nt file |
and the number of |
windows nt file system |
the number of multicast |
nt file system traces |
number of multicast requests |
of multicast requests in |
will successively fill the |
multicast requests in progress |
successively fill the four |
our experimental setup consists |
fill the four repair |
experimental setup consists of |
the four repair bins |
setup consists of two |
four repair bins in |
repair bins in layer |
ghz pentium iii desktop |
pentium iii desktop machines |
iii desktop machines running |
desktop machines running the |
machines running the freebsd |
token roundtrip time and |
this behavior leads to |
roundtrip time and an |
behavior leads to a |
time and an average |
leads to a large |
and an average time |
to a large number |
an average time to |
a large number of |
average time to acknowledge |
large number of repair |
time to acknowledge a |
number of repair packets |
to acknowledge a message |
one of which acts |
of repair packets being |
of which acts as |
repair packets being generated |
which acts as an |
packets being generated and |
acts as an mfs |
being generated and sent |
as an mfs server |
generated and sent within |
and sent within a |
sent within a short |
within a short period |
a short period of |
short period of time |
and the other as |
the other as an |
other as an mfs |
as an mfs client |
varying token circulation rate |
which results in undesirable |
results in undesirable overhead |
in undesirable overhead and |
undesirable overhead and traffic |
the client machine makes |
overhead and traffic spikes |
client machine makes use |
machine makes use of |
makes use of the |
use of the dummynet |
of the dummynet trafficshaping |
the dummynet trafficshaping module |
dummynet trafficshaping module in |
trafficshaping module in freebsd |
we would like to |
module in freebsd to |
would like to rate |
our second approach increased |
in freebsd to limit |
second approach increased the |
freebsd to limit its |
approach increased the amount |
to limit its incoming |
limit transmissions of repair |
increased the amount of |
limit its incoming and |
transmissions of repair packets |
the amount of feedback |
its incoming and outgoing |
of repair packets to |
amount of feedback to |
incoming and outgoing bandwidth |
repair packets to one |
of feedback to the |
packets to one for |
feedback to the sender |
to one for every |
the experiments we conduct |
one for every r |
experiments we conduct in |
for every r data |
in our base implementation |
we conduct in this |
every r data packets |
conduct in this section |
in this section have |
this section have a |
each aggregate ack contains |
section have a constant |
this problem is fixed |
aggregate ack contains a |
have a constant bandwidth |
problem is fixed by |
ack contains a single |
a constant bandwidth over |
is fixed by staggering |
contains a single value |
constant bandwidth over the |
fixed by staggering the |
a single value maxcontiguous |
bandwidth over the duration |
by staggering the starting |
over the duration of |
staggering the starting sizes |
the duration of the |
the starting sizes of |
representing the maximum number |
duration of the experiment |
starting sizes of the |
sizes of the bins |
the maximum number such |
maximum number such that |
number such that messages |
but we analyse the |
such that messages with |
analogous to the starting |
we analyse the performance |
that messages with this |
to the starting positions |
analyse the performance of |
messages with this and |
the starting positions of |
the performance of mfs |
with this and all |
starting positions of runners |
performance of mfs when |
this and all lower |
positions of runners in |
of mfs when the |
and all lower numbers |
of runners in a |
mfs when the bandwidth |
all lower numbers are |
runners in a sprint |
when the bandwidth varies |
lower numbers are stable |
the bandwidth varies over |
numbers are stable in |
bandwidth varies over the |
are stable in the |
stable in the region |
varies over the course |
the very first time |
over the course of |
very first time bin |
the course of an |
first time bin number |
to increase the amount |
course of an experiment |
time bin number x |
increase the amount of |
of an experiment in |
bin number x in |
the amount of feedback |
an experiment in section |
number x in a |
x in a layer |
in a layer of |
a layer of interleave |
layer of interleave i |
we permit ack to |
of interleave i fires |
permit ack to contain |
ack to contain up |
to contain up to |
contain up to k |
up to k numeric |
to k numeric ranges |
it does so at |
does so at size |
so at size x |
at size x mod |
size x mod r |
microbenchmarks the first set |
the first set of |
the first repair bin |
first set of experiments |
first repair bin in |
set of experiments compares |
repair bin in the |
of experiments compares different |
bin in the second |
experiments compares different mfs |
in the second layer |
compares different mfs configurations |
the second layer with |
different mfs configurations for |
second layer with interleave |
mfs configurations for specific |
configurations for specific types |
for specific types of |
specific types of contention |
would fire at size |
four workloads were used |
the second would fire |
second would fire at |
would fire at size |
executes the grep utility |
the grep utility several |
grep utility several times |
utility several times on |
several times on each |
times on each of |
size of repository stored |
of repository stored in |
repository stored in s |
the system can now |
system can now cleanup |
can now cleanup message |
the files are present |
now cleanup message sequences |
files are present in |
cleanup message sequences that |
are present in the |
message sequences that have |
present in the cache |
sequences that have as |
that have as gaps |
but must be validated |
must be validated before |
messages that are still |
be validated before they |
that are still unstable |
validated before they are |
before they are used |
in the experiment shown |
the experiment shown in |
experiment shown in figures |
so we based our |
mb files in sequence |
we based our analysis |
we set k to |
set k to the |
k to the number |
writing the contents of |
the contents of each |
contents of each file |
of each file to |
to the number of |
the number of partitions |
based our analysis on |
our analysis on that |
analysis on that along |
the files are not |
while the amount of |
files are not initially |
are not initially present |
the amount of acknowledged |
amount of acknowledged data |
not initially present in |
initially present in the |
present in the cache |
on that along with |
of acknowledged data is |
acknowledged data is reduced |
data is reduced by |
that along with the |
along with the assumption |
with the assumption each |
the assumption each revision |
assumption each revision data |
each revision data file |
revision data file would |
and the overall throughput |
mb files from the |
files from the local |
the overall throughput is |
data file would be |
from the local file |
overall throughput is actually |
the local file system |
throughput is actually lower |
local file system into |
is actually lower because |
file system into the |
actually lower because token |
system into the mfs |
lower because token processing |
into the mfs file |
because token processing becomes |
the mfs file system |
token processing becomes more |
processing becomes more costly |
the system becomes unstable |
notice the large variances |
the large variances in |
large variances in figure |
because our flow control |
our flow control scheme |
based on limiting the |
on limiting the amount |
limiting the amount of |
the amount of unacknowledged |
amount of unacknowledged data |
while the sender can |
the sender can cleanup |
sender can cleanup any |
can cleanup any portion |
cleanup any portion of |
any portion of the |
portion of the message |
of the message sequence |
kib and each revision |
and each revision property |
receivers have to deliver |
have to deliver in |
to deliver in fifo |
deliver in fifo order |
each revision property file |
the amount of data |
amount of data they |
of data they cache |
data they cache is |
they cache is larger |
and this reduces their |
this reduces their ability |
reduces their ability to |
their ability to accept |
ability to accept incoming |
to accept incoming traffic |
notice the linkage to |
the linkage to memory |
the growth in memory |
growth in memory occurs |
in memory occurs on |
memory occurs on the |
occurs on the receivers |
but the pattern is |
the pattern is similar |
pattern is similar to |
is similar to what |
similar to what we |
to what we saw |
what we saw earlier |
merely having more cached |
having more cached data |
more cached data is |
cached data is enough |
data is enough to |
is enough to slow |
enough to slow them |
to slow them down |
the averages observed for |
averages observed for the |
observed for the other |
token roundtrip time increases |
second set of rsized |
for the other repositories |
set of rsized xors |
of rsized xors staggered |
rsized xors staggered start |
xors staggered start xors |
the other repositories in |
other repositories in table |
this delays state aggregation |
repositories in table ii |
increases pending messages and |
pending messages and reduces |
messages and reduces throughput |
table ii m ost |
ii m ost recent |
m ost recent monthly |
ost recent monthly cost |
recent monthly cost of |
monthly cost of storing |
cost of storing repositories |
of storing repositories in |
storing repositories in s |
more aggressive cleanup with |
aggressive cleanup with o |
feedback in the token |
in the token and |
the token and in |
token and in acks |
for individual projects and |
individual projects and entire |
projects and entire communities |
more work with o |
and entire communities software |
entire communities software project |
communities software project squirrelmail |
and lower rates despite |
lower rates despite saving |
rates despite saving on |
software project squirrelmail phpmyadmin |
despite saving on memory |
project squirrelmail phpmyadmin subversion |
squirrelmail phpmyadmin subversion mono |
phpmyadmin subversion mono kde |
subversion mono kde hosting |
mono kde hosting community |
memory overheads on the |
kde hosting community debian |
overheads on the receiver |
hosting community debian linux |
on the receiver the |
community debian linux community |
the receiver the reader |
debian linux community apache |
receiver the reader may |
linux community apache software |
the reader may doubt |
community apache software foundation |
reader may doubt that |
apache software foundation monthly |
may doubt that memory |
doubt that memory overhead |
that memory overhead on |
memory overhead on receivers |
overhead on receivers is |
on receivers is the |
receivers is the real |
is the real issue |
software foundation monthly cost |
considering that their cpus |
that their cpus are |
their cpus are half |
can increasing memory consumption |
increasing memory consumption affect |
memory consumption affect a |
consumption affect a half |
gc test rw test |
we performed an experiment |
performed an experiment with |
in which we vary |
which we vary the |
we vary the number |
vary the number of |
the number of receivers |
number of receivers that |
of receivers that cache |
receivers that cache a |
that cache a copy |
cache a copy of |
a copy of each |
copy of each message |
replication factor in figure |
increasing this value results |
this value results in |
value results in a |
results in a linear |
in a linear increase |
a linear increase of |
linear increase of memory |
increase of memory usage |
of memory usage on |
memory usage on receivers |
if memory overheads were |
memory overheads were not |
overheads were not a |
were not a significant |
not a significant issue |
a significant issue on |
significant issue on half |
we would expect performance |
would expect performance to |
expect performance to remain |
performance to remain unchanged |
we see a dramatic |
linear increase of the |
increase of the token |
of the token roundtrip |
the token roundtrip time |
gw test rc test |
a slow increase of |
slow increase of the |
increase of the number |
of the number of |
the number of messages |
number of messages pending |
of messages pending ack |
messages pending ack on |
pending ack on the |
ack on the sender |
and a sharp decrease |
a sharp decrease in |
sharp decrease in throughput |
the underlying mechanism is |
underlying mechanism is as |
mechanism is as follows |
the increased activity of |
increased activity of the |
activity of the garbage |
of the garbage collector |
the garbage collector and |
garbage collector and allocation |
collector and allocation overheads |
and allocation overheads slow |
allocation overheads slow the |
overheads slow the system |
slow the system down |
the system down and |
system down and processing |
down and processing of |
and processing of the |
processing of the incoming |
of the incoming packets |
the incoming packets and |
incoming packets and tokens |
packets and tokens takes |
and tokens takes more |
tokens takes more time |
although the effect is |
the effect is not |
effect is not significant |
is not significant when |
not significant when considering |
relative speedup relative speedup |
significant when considering a |
speedup relative speedup relative |
when considering a single |
relative speedup relative speedup |
considering a single node |
a single node in |
single node in isolation |
a token must visit |
token must visit all |
must visit all nodes |
visit all nodes in |
all nodes in a |
nodes in a region |
in a region to |
a region to aggregate |
region to aggregate the |
to aggregate the recovery |
aggregate the recovery state |
and delays are cumulative |
uniform priorities async relative |
qsm is configured so |
priorities async relative speedup |
is configured so that |
async relative speedup gc |
configured so that five |
relative speedup gc test |
so that five nodes |
that five nodes in |
five nodes in each |
nodes in each region |
in each region cache |
each region cache each |
region cache each packet |
if half the nodes |
half the nodes in |
the nodes in a |
node region cache each |
region cache each figure |
varying the number of |
the number of caching |
number of caching replicas |
of caching replicas per |
caching replicas per message |
replicas per message in |
per message in a |
as the replication factor |
the replication factor increasess |
the sender s flow |
sender s flow control |
s flow control policy |
flow control policy kicks |
control policy kicks in |
and the system goes |
the system goes into |
a form of the |
form of the oscillating |
of the oscillating state |
the oscillating state we |
oscillating state we encountered |
state we encountered in |
we encountered in figure |
the amount of memory |
amount of memory in |
of memory in use |
memory in use at |
in use at the |
even for the fairly |
use at the sender |
for the fairly large |
at the sender ceases |
the fairly large apache |
the sender ceases to |
fairly large apache software |
sender ceases to be |
large apache software foundation |
ceases to be a |
to be a good |
be a good predictor |
a good predictor of |
good predictor of the |
predictor of the amount |
of the amount of |
the amount of memory |
amount of memory in |
of memory in use |
memory in use at |
in use at receivers |
the current cost of |
current cost of using |
cost of using s |
violating what turns out |
what turns out to |
turns out to be |
out to be an |
to be an implicit |
be an implicit requirement |
an implicit requirement of |
implicit requirement of our |
requirement of our flow |
for storage is less |
storage is less than |
relative speedup relative speedup |
speedup relative speedup relative |
relative speedup relative speedup |
overheads in a perturbed |
in a perturbed system |
a perturbed system the |
perturbed system the reader |
system the reader might |
the reader might wonder |
reader might wonder whether |
it is very unlikely |
might wonder whether our |
wonder whether our results |
is very unlikely that |
whether our results would |
our results would be |
very unlikely that any |
results would be different |
would be different if |
unlikely that any vendor |
be different if the |
different if the system |
that any vendor could |
if the system experienced |
the system experienced high |
any vendor could provide |
system experienced high loss |
experienced high loss rates |
high loss rates or |
loss rates or was |
rates or was otherwise |
or was otherwise perturbed |
vendor could provide a |
could provide a traditional |
provide a traditional storage |
a traditional storage solution |
we performed an experiment |
traditional storage solution consisting |
performed an experiment in |
storage solution consisting of |
an experiment in which |
solution consisting of scsi |
experiment in which one |
consisting of scsi disks |
in which one of |
of scsi disks and |
which one of the |
scsi disks and tape |
one of the receiver |
disks and tape backup |
of the receiver nodes |
and tape backup at |
the receiver nodes experiences |
tape backup at this |
receiver nodes experiences a |
nodes experiences a periodic |
backup at this price |
the amount of s |
s the node sleeps |
the node sleeps for |
storage required of course |
required of course increases |
of course increases each |
course increases each month |
increases each month as |
this simulates the effect |
simulates the effect of |
the effect of disruptive |
each month as the |
month as the repository |
as the repository grows |
in the loss scenario |
but as shown in |
as shown in figure |
s the node drops |
the node drops all |
node drops all incoming |
drops all incoming packets |
all incoming packets for |
the increase is roughly |
increase is roughly linear |
comparison of packet recovery |
of packet recovery probability |
as developer productivity remains |
developer productivity remains constant |
the loss rate is |
loss rate is higher |
the cost of storage |
cost of storage is |
of storage is declining |
storage is declining exponentially |
because recovery traffic interferes |
staggered start first i |
recovery traffic interferes with |
start first i data |
traffic interferes with regular |
first i data packets |
interferes with regular multicast |
i data packets added |
data packets added to |
packets added to a |
added to a layer |
to a layer with |
a layer with interleave |
layer with interleave i |
cpu utilization at the |
utilization at the receivers |
r fire immediately with |
at the receivers is |
fire immediately with just |
the receivers is in |
receivers is in the |
immediately with just one |
with just one packet |
just one packet in |
one packet in them |
so if amazon s |
if amazon s pricing |
amazon s pricing stays |
for the next i |
the next i data |
next i data packets |
i data packets added |
s pricing stays competitive |
r fire immediately with |
fire immediately with two |
immediately with two data |
range and doesn t |
with two data packets |
and doesn t grow |
two data packets in |
doesn t grow with |
data packets in them |
t grow with system |
grow with system size |
term trend is towards |
trend is towards lower |
and so on until |
is towards lower costs |
so on until r |
on until r i |
until r i data |
r i data packets |
i data packets have |
data packets have been |
packets have been added |
have been added to |
been added to the |
added to the layer |
to the layer and |
additional costs will be |
the layer and all |
costs will be incurred |
layer and all bins |
will be incurred for |
in the sleep scenario |
and all bins have |
be incurred for front |
all bins have fired |
bins have fired exactly |
have fired exactly once |
the decrease starts at |
decrease starts at about |
performance of prioritised rpc |
of prioritised rpc with |
prioritised rpc with respect |
rpc with respect to |
all bins fire at |
with respect to bandwidth |
bins fire at size |
fire at size r |
respect to bandwidth variation |
nodes and proceeds steadily |
and proceeds steadily thereafter |
for the case of |
the case of ec |
each pair of graphs |
it doesn t appear |
now that they have |
pair of graphs in |
doesn t appear to |
that they have been |
of graphs in shows |
t appear to be |
they have been staggered |
graphs in shows the |
appear to be correlated |
have been staggered at |
in shows the speedup |
to be correlated to |
been staggered at the |
shows the speedup of |
be correlated to the |
staggered at the start |
a standard machine instance |
correlated to the amount |
the speedup of one |
standard machine instance is |
to the amount of |
speedup of one of |
of one of three |
the amount of loss |
r fire for any |
fire for any i |
one of three cache |
of three cache manager |
for any i data |
any i data packets |
three cache manager configurations |
which oscillates at the |
oscillates at the level |
at the level of |
machine instance is billed |
relative to the time |
the outlined scheme works |
instance is billed at |
to the time taken |
outlined scheme works when |
the time taken by |
scheme works when i |
time taken by uniform |
works when i is |
taken by uniform priorities |
when i is greater |
by uniform priorities with |
i is greater than |
uniform priorities with synchronous |
is greater than or |
priorities with synchronous rpcs |
greater than or equal |
with synchronous rpcs at |
than or equal to |
or equal to r |
as is usually the |
is usually the case |
if i is smaller |
i is smaller than |
is smaller than r |
in the controlled loss |
the controlled loss scenario |
as well as uniform |
well as uniform priorities |
the bin with index |
throughput remains fairly constant |
as uniform priorities and |
bin with index x |
uniform priorities and synchronous |
with index x fires |
priorities and synchronous rpcs |
index x fires at |
until it falls sharply |
it falls sharply beyond |
plus data transfer of |
the graphs also show |
graphs also show curves |
also show curves for |
show curves for differentiated |
curves for differentiated priorities |
for differentiated priorities and |
differentiated priorities and synchronous |
priorities and synchronous rpcs |
performance does not appear |
does not appear to |
not appear to be |
appear to be directly |
to be directly correlated |
be directly correlated to |
directly correlated to the |
and differentiated priorities and |
correlated to the observed |
differentiated priorities and asynchronous |
to the observed packet |
priorities and asynchronous rpcs |
the observed packet loss |
throughput is uncorrelated with |
is uncorrelated with memory |
the initial firing sizes |
uncorrelated with memory use |
initial firing sizes would |
the values plotted for |
with memory use both |
firing sizes would be |
per gib in and |
values plotted for bandwidth |
memory use both on |
plotted for bandwidth of |
use both on the |
for the first bin |
both on the perturbed |
the first bin and |
on the perturbed receiver |
for the second bin |
if r and i |
r and i are |
and i are not |
i are not integral |
are not integral multiples |
not integral multiples of |
integral multiples of each |
multiples of each other |
s are the same |
are the same as |
the same as shown |
same as shown in |
as shown in table |
limiting still works but |
still works but is |
works but is slightly |
but is slightly less |
is slightly less effective |
slightly less effective due |
due to the overhead |
less effective due to |
to the overhead of |
effective due to rounding |
the overhead of priorities |
at scales of up |
due to rounding errors |
overhead of priorities for |
scales of up to |
of priorities for small |
priorities for small rpcs |
for small rpcs mentioned |
delaying xors in the |
small rpcs mentioned in |
xors in the straightforward |
in the straightforward implementation |
rpcs mentioned in section |
discounts are available if |
are available if data |
repair packets are transmitted |
memory usage actually decreases |
available if data transfer |
packets are transmitted as |
if data transfer exceeds |
are transmitted as soon |
a consequence of the |
transmitted as soon as |
consequence of the cooperative |
as soon as they |
of the cooperative caching |
comparing the execution time |
soon as they are |
the cooperative caching policy |
the execution time of |
as they are generated |
cooperative caching policy described |
execution time of the |
caching policy described in |
time of the foreground |
policy described in section |
of the foreground workloads |
this results in the |
the foreground workloads with |
results in the repair |
foreground workloads with synchronous |
in the repair packet |
workloads with synchronous writes |
the repair packet leaving |
the shape of the |
repair packet leaving immediately |
shape of the performance |
packet leaving immediately after |
update logging and asynchronous |
of the performance curve |
the performance curve does |
leaving immediately after the |
logging and asynchronous writeback |
and the instance cost |
immediately after the last |
and asynchronous writeback reveals |
the instance cost may |
correlate closely with the |
asynchronous writeback reveals that |
after the last data |
instance cost may be |
closely with the number |
writeback reveals that the |
the last data packet |
last data packet that |
with the number of |
reveals that the latter |
cost may be reduced |
data packet that was |
the number of unacknowledged |
that the latter two |
may be reduced to |
packet that was added |
number of unacknowledged requests |
the latter two options |
that was added to |
was added to it |
latter two options generally |
two options generally perform |
options generally perform comparably |
generally perform comparably to |
perform comparably to or |
comparably to or better |
which lowers burst tolerance |
to or better than |
lowers burst tolerance if |
or better than synchronous |
burst tolerance if the |
better than synchronous writes |
tolerance if the repair |
if the repair packet |
the repair packet was |
repair packet was generated |
packet was generated at |
was generated at interleave |
generated at interleave i |
we conclude that the |
logging and asynchronous writeback |
conclude that the drop |
and asynchronous writeback greatly |
that the drop in |
the resulting protocol can |
asynchronous writeback greatly improve |
the drop in performance |
resulting protocol can tolerate |
writeback greatly improve the |
drop in performance in |
protocol can tolerate a |
greatly improve the performance |
in performance in these |
can tolerate a burst |
improve the performance of |
performance in these scenarios |
tolerate a burst of |
the performance of the |
in these scenarios can |
a burst of i |
performance of the background |
of the background workloads |
these scenarios can t |
burst of i lost |
per hour by paying |
scenarios can t be |
of i lost data |
i lost data packets |
as has been noted |
can t be explained |
hour by paying a |
lost data packets excluding |
has been noted previously |
t be explained by |
data packets excluding the |
be explained by correlation |
packets excluding the repair |
explained by correlation with |
by correlation with cpu |
correlation with cpu activity |
but the burst could |
the burst could swallow |
burst could swallow both |
could swallow both the |
swallow both the repair |
or loss rates at |
both the repair and |
loss rates at the |
rates at the receivers |
the repair and the |
repair and the last |
and the last data |
the last data packet |
last data packet in |
but that it does |
data packet in it |
that it does appear |
packet in it as |
it does appear correlated |
in it as they |
we focus on mfs |
does appear correlated to |
it as they are |
focus on mfs with |
appear correlated to slower |
as they are not |
on mfs with asynchronous |
correlated to slower cleanup |
they are not separated |
mfs with asynchronous writeback |
to slower cleanup and |
year reservation fee in |
with asynchronous writeback in |
are not separated by |
slower cleanup and the |
cleanup and the resulting |
asynchronous writeback in the |
not separated by the |
separated by the requisite |
and the resulting memory |
writeback in the rest |
reservation fee in advance |
by the requisite interleave |
in the rest of |
related overheads at the |
the rest of this |
overheads at the sender |
rest of this paper |
the solution to this |
of this paper because |
solution to this is |
this paper because it |
to this is simple |
the effect is much |
this gives an amortized |
paper because it provides |
this is simple delay |
effect is much stronger |
gives an amortized monthly |
because it provides comparable |
is simple delay sending |
is much stronger than |
an amortized monthly cost |
it provides comparable performance |
simple delay sending the |
much stronger than in |
stronger than in the |
provides comparable performance to |
delay sending the repair |
amortized monthly cost of |
than in the undisturbed |
comparable performance to logged |
sending the repair packet |
in the undisturbed experiments |
performance to logged updates |
the repair packet generated |
repair packet generated by |
packet generated by a |
the number of pending |
generated by a repair |
allows straightforward modeless adaptation |
number of pending messages |
by a repair bin |
straightforward modeless adaptation to |
of pending messages starts |
a repair bin until |
modeless adaptation to bandwidth |
pending messages starts at |
repair bin until the |
adaptation to bandwidth variation |
messages starts at a |
bin until the next |
starts at a higher |
until the next time |
at a higher level |
the next time a |
and is easily extensible |
next time a data |
is easily extensible to |
time a data packet |
easily extensible to more |
a data packet is |
extensible to more than |
data packet is added |
to more than one |
packet is added to |
more than one level |
is added to the |
than one level of |
added to the now |
one level of priority |
to the now empty |
the now empty bin |
token roundtrip time increases |
which is required for |
is required for our |
which happens i packets |
required for our cache |
happens i packets later |
for our cache consistency |
i packets later and |
our cache consistency algorithm |
packets later and introduces |
later and introduces the |
and introduces the required |
as we show in |
since reducing available bandwidth |
and if a failure |
if a failure occurs |
we show in the |
reducing available bandwidth increases |
introduces the required interleave |
show in the next |
available bandwidth increases the |
the required interleave between |
token rounds before repair |
bandwidth increases the contention |
in the next section |
required interleave between the |
rounds before repair occurs |
increases the contention between |
interleave between the repair |
the contention between rpcs |
between the repair packet |
contention between rpcs of |
and then another round |
the repair packet and |
between rpcs of different |
then another round before |
repair packet and the |
one instance should be |
rpcs of different types |
instance should be enough |
packet and the last |
should be enough for |
another round before cleanup |
the benefits of rpc |
be enough for almost |
and the last data |
round before cleanup takes |
benefits of rpc priorities |
enough for almost any |
the last data packet |
for almost any individual |
of rpc priorities should |
almost any individual project |
last data packet included |
before cleanup takes place |
rpc priorities should be |
priorities should be more |
data packet included in |
packet included in it |
should be more apparent |
be more apparent at |
more apparent at lower |
apparent at lower priorities |
any individual project or |
notice that although transmitting |
individual project or moderately |
that although transmitting the |
project or moderately sized |
although transmitting the xor |
shows the experiments of |
the experiments of table |
transmitting the xor immediately |
the xor immediately results |
xor immediately results in |
immediately results in faster |
results in faster recovery |
or moderately sized community |
extended to a wider |
to a wider range |
a wider range of |
wider range of bandwidth |
doing so also reduces |
range of bandwidth values |
so also reduces the |
also reduces the probability |
reduces the probability of |
the probability of a |
these account for the |
probability of a lost |
in these and later |
account for the rapid |
of a lost packet |
these and later experiments |
for the rapid increase |
a lost packet being |
the rapid increase in |
lost packet being recovered |
rapid increase in acknowledgement |
we evaluate mfs performance |
evaluate mfs performance with |
increase in acknowledgement latency |
usage patterns in addition |
mfs performance with bandwidths |
performance with bandwidths from |
patterns in addition to |
off results in a |
in addition to getting |
results in a minor |
addition to getting a |
in a minor control |
to getting a grasp |
a minor control knob |
getting a grasp of |
as the number of |
a grasp of the |
minor control knob permitting |
the number of caching |
number of caching replicas |
control knob permitting us |
grasp of the costs |
of caching replicas increases |
knob permitting us to |
of the costs involved |
permitting us to balance |
us to balance speed |
to balance speed against |
balance speed against burst |
speed against burst tolerance |
the costs involved in |
costs involved in moving |
involved in moving a |
our default configuration is |
in moving a repository |
default configuration is to |
moving a repository to |
configuration is to transmit |
throughput in the experiments |
s is not low |
is to transmit the |
to transmit the xor |
in the experiments with |
is not low in |
a repository to s |
transmit the xor immediately |
the experiments with a |
not low in the |
experiments with a perturbed |
low in the sense |
with a perturbed node |
in the sense of |
the sense of prior |
sense of prior work |
it is low enough |
is low enough to |
low enough to cause |
enough to cause significant |
to cause significant contention |
cause significant contention for |
significant contention for the |
contention for the workloads |
it is important to |
for the workloads we |
envelope analysis to start |
analysis to start with |
the workloads we have |
workloads we have considered |
is important to understand |
important to understand the |
we note that no |
and we believe that |
to understand the usage |
note that no two |
we believe that our |
understand the usage patterns |
that no two repair |
believe that our results |
no two repair packets |
average packet loss observed |
that our results will |
two repair packets generated |
packet loss observed at |
our results will hold |
repair packets generated at |
loss observed at the |
results will hold if |
packets generated at different |
generated at different interleaves |
observed at the perturbed |
will hold if available |
especially the rate at |
at different interleaves i |
at the perturbed node |
hold if available bandwidth |
if available bandwidth and |
available bandwidth and grep |
bandwidth and grep write |
the rate at which |
rate at which commits |
at which commits take |
which commits take place |
memory usage at the |
usage at the perturbed |
at the perturbed node |
since achieving the consistency |
at unperturbed nodes it |
unperturbed nodes it is |
nodes it is similar |
achieving the consistency properties |
will have more than |
afs mfs afs mfs |
mfs afs mfs elapsed |
have more than one |
the consistency properties that |
afs mfs elapsed time |
more than one data |
consistency properties that developers |
than one data packet |
properties that developers expect |
one data packet in |
that developers expect will |
data packet in common |
developers expect will require |
packet in common as |
expect will require a |
although it would be |
in common as long |
will require a consistency |
it would be hard |
common as long as |
require a consistency layer |
would be hard to |
as long as the |
a consistency layer to |
be hard to precisely |
long as the least |
consistency layer to be |
hard to precisely measure |
as the least common |
the least common multiple |
to precisely measure these |
precisely measure these delays |
layer to be built |
to be built in |
be built in front |
built in front of |
in front of s |
measuring alarm delays sheds |
of the interleaves is |
alarm delays sheds light |
the interleaves is greater |
delays sheds light on |
interleaves is greater than |
sheds light on the |
is greater than r |
greater than r i |
light on the magnitude |
on the magnitude of |
the magnitude of the |
magnitude of the problem |
it is crucial that |
is crucial that any |
crucial that any such |
recall that our timesharing |
that any such layer |
pairings of repair bins |
that our timesharing policy |
any such layer be |
of repair bins in |
our timesharing policy assigns |
such layer be able |
repair bins in two |
timesharing policy assigns quanta |
layer be able to |
bins in two different |
policy assigns quanta to |
be able to handle |
in two different layers |
assigns quanta to different |
able to handle the |
two different layers with |
quanta to different types |
to different types of |
different types of events |
to handle the load |
different layers with interleaves |
layers with interleaves i |
handle the load of |
high volumes of i |
the load of commits |
the critical statistic to |
such as caused by |
critical statistic to consider |
as caused by the |
statistic to consider is |
caused by the increased |
to consider is the |
by the increased forwarding |
the increased forwarding traffic |
consider is the number |
is the number of |
the number of simultaneous |
number of simultaneous commits |
will cause qsm to |
cause qsm to use |
qsm to use a |
to use a larger |
use a larger fraction |
a larger fraction of |
larger fraction of its |
fraction of its i |
for centralized revision control |
centralized revision control system |
revision control system such |
a good rule of |
o quantum to process |
quantum to process i |
good rule of thumb |
control system such as |
rule of thumb is |
system such as subversion |
of thumb is to |
thumb is to select |
is to select interleaves |
to select interleaves that |
with the consequence that |
select interleaves that are |
the consequence that timers |
each commit is assigned |
interleaves that are relatively |
consequence that timers will |
that timers will fire |
that are relatively prime |
commit is assigned a |
timers will fire late |
are relatively prime to |
is assigned a unique |
relatively prime to maximize |
prime to maximize their |
to maximize their lcm |
this effect is magnified |
effect is magnified each |
is magnified each time |
magnified each time qsm |
each time qsm is |
and also ensure that |
time qsm is preempted |
also ensure that the |
qsm is preempted by |
ensure that the larger |
is preempted by other |
that the larger interleave |
and any change to |
preempted by other processes |
the larger interleave is |
any change to a |
by other processes or |
larger interleave is greater |
interleave is greater than |
other processes or by |
change to a versioned |
is greater than r |
processes or by its |
to a versioned file |
or by its own |
by its own garbage |
its own garbage collector |
let us assume that |
a versioned file is |
us assume that packets |
versioned file is stored |
assume that packets are |
such delays are typically |
file is stored as |
that packets are dropped |
delays are typically shorter |
are typically shorter than |
packets are dropped with |
are dropped with uniform |
comparison of mfs and |
of mfs and afs |
typically shorter than the |
shorter than the i |
mfs and afs performance |
is stored as a |
stored as a diff |
as a diff against |
a diff against its |
given a lost data |
a lost data packet |
diff against its previous |
mfs with synchronous rpcs |
yet longer than the |
against its previous version |
with synchronous rpcs and |
longer than the alarm |
than the alarm quantum |
synchronous rpcs and priorities |
what is the probability |
rpcs and priorities is |
is the probability that |
and priorities is compared |
a commit must be |
the probability that we |
thus causing the alarm |
priorities is compared to |
probability that we can |
that we can recover |
is compared to a |
commit must be rejected |
we can recover it |
but not the i |
compared to a version |
must be rejected if |
to a version of |
a version of the |
we can recover a |
be rejected if any |
version of the andrew |
can recover a data |
of the andrew file |
the andrew file system |
recover a data packet |
rejected if any of |
the maximum alarm firing |
a data packet if |
maximum alarm firing delays |
if any of the |
data packet if at |
any of the versioned |
alarm firing delays taken |
of the versioned files |
packet if at least |
the versioned files that |
firing delays taken from |
versioned files that it |
if at least one |
files that it touches |
delays taken from samples |
that it touches have |
at least one of |
it touches have been |
taken from samples in |
touches have been changed |
least one of the |
have been changed in |
speedups for the two |
one of the c |
been changed in an |
for the two workloads |
s intervals are indeed |
of the c xors |
changed in an earlier |
the two workloads of |
intervals are indeed much |
the c xors containing |
in an earlier revision |
two workloads of the |
are indeed much larger |
c xors containing it |
an earlier revision that |
workloads of the gw |
indeed much larger in |
xors containing it is |
earlier revision that the |
of the gw test |
much larger in the |
containing it is received |
revision that the developer |
the gw test are |
larger in the perturbed |
it is received correctly |
that the developer performing |
gw test are shown |
in the perturbed experiments |
is received correctly and |
the developer performing the |
received correctly and usable |
developer performing the commit |
relative to the performance |
both on the sender |
performing the commit was |
to the performance of |
on the sender and |
the commit was unaware |
the performance of afs |
the sender and on |
commit was unaware of |
performance of afs at |
sender and on the |
all the other data |
and on the receiver |
the other data packets |
on the receiver side |
other data packets in |
data packets in it |
packets in it have |
this ensures that every |
in it have also |
ensures that every conflict |
it have also been |
that every conflict gets |
have also been received |
also been received correctly |
every conflict gets resolved |
traffic are scaled down |
conflict gets resolved by |
are scaled down further |
the probability of which |
gets resolved by a |
scaled down further in |
probability of which is |
of which is simply |
down further in parallel |
resolved by a human |
by a human before |
a human before becoming |
human before becoming part |
large delays are also |
the graphs in figure |
before becoming part of |
delays are also more |
are also more frequent |
becoming part of the |
validate the incorporation of |
part of the repository |
the incorporation of rpc |
incorporation of rpc priorities |
of the repository s |
the repository s state |
the probability of a |
probability of a received |
since all the foreground |
of a received xor |
the maximum delay measured |
all the foreground workloads |
a received xor being |
maximum delay measured on |
the foreground workloads improve |
received xor being unusable |
delay measured on receivers |
foreground workloads improve their |
exclusive locking is required |
measured on receivers in |
xor being unusable is |
workloads improve their performance |
locking is required on |
on receivers in the |
being unusable is the |
improve their performance substantially |
is required on commits |
receivers in the perturbed |
unusable is the complement |
their performance substantially at |
in the perturbed runs |
performance substantially at lower |
the perturbed runs is |
substantially at lower bandwidths |
taking a loose definition |
a loose definition of |
loose definition of simultaneous |
definition of simultaneous to |
relative to mfs with |
to mfs with no |
mfs with no priorities |
of simultaneous to be |
simultaneous to be within |
to be within one |
be within one minute |
the decrease in throughput |
decrease in throughput for |
in throughput for the |
the apache repository had |
apache repository had a |
repository had a maximum |
had a maximum of |
parameter trace mostly writes |
simultaneous commits and the |
commits and the debian |
and the debian community |
the probability x of |
ignoring for now that |
probability x of a |
for now that their |
x of a sent |
now that their use |
ms in the unperturbed |
of a sent xor |
that their use of |
in the unperturbed experiments |
a sent xor being |
sent xor being dropped |
xor being dropped or |
being dropped or unusable |
dropped or unusable is |
or unusable is the |
unusable is the sum |
the value grows from |
is the sum of |
the sum of the |
sum of the probability |
of the probability that |
the probability that it |
probability that it was |
that it was dropped |
it was dropped and |
separate repositories allows for |
was dropped and the |
repositories allows for finergrained |
dropped and the probability |
allows for finergrained locking |
and the probability that |
the probability that it |
probability that it was |
that it was received |
it was received and |
was received and unusable |
an aggregate maximum of |
the problem could be |
problem could be alleviated |
could be alleviated by |
be alleviated by making |
alleviated by making our |
by making our priority |
in determining these numbers |
making our priority scheduling |
our priority scheduling more |
determining these numbers we |
priority scheduling more fine |
these numbers we filtered |
numbers we filtered out |
we filtered out any |
filtered out any sequences |
out any sequences of |
any sequences of multiple |
sequences of multiple commits |
of multiple commits by |
varying priorities for control |
priorities for control packets |
multiple commits by the |
commits by the same |
by the same author |
or by assigning priorities |
the same author during |
by assigning priorities to |
same author during a |
assigning priorities to feeds |
author during a one |
priorities to feeds in |
during a one minute |
to feeds in the |
a one minute period |
feeds in the sending |
one minute period since |
in the sending stack |
minute period since those |
period since those were |
since those were likely |
those were likely sequential |
were likely sequential rather |
likely sequential rather than |
sequential rather than simultaneous |
rather than simultaneous and |
than simultaneous and do |
simultaneous and do nor |
and do nor represent |
do nor represent the |
number of messages awaiting |
nor represent the common |
of messages awaiting acknowledgement |
represent the common case |
messages awaiting acknowledgement in |
since it is easy |
awaiting acknowledgement in experiments |
acknowledgement in experiments with |
it is easy to |
in experiments with perturbances |
is easy to ensure |
the average rates were |
easy to ensure that |
to ensure that no |
ensure that no two |
that no two xors |
no two xors share |
two xors share more |
xors share more than |
share more than one |
more than one data |
than one data packet |
token roundtrip time and |
roundtrip time and the |
time and the time |
and the time to |
the time to recover |
time to recover in |
to recover in the |
the usability probabilities of |
usability probabilities of different |
probabilities of different xors |
of different xors are |
different xors are independent |
the probability of all |
probability of all the |
of all the c |
all the c xors |
the c xors being |
c xors being dropped |
xors being dropped or |
token roundtrip time and |
being dropped or unusable |
roundtrip time and the |
dropped or unusable is |
time and the time |
or unusable is xc |
and the time to |
the time to recover |
time to recover in |
to recover in the |
so exclusive locking for |
the probability of correctly |
exclusive locking for commits |
probability of correctly receiving |
these traces are representative |
it is worth noting |
of correctly receiving at |
locking for commits should |
traces are representative periods |
is worth noting that |
correctly receiving at least |
for commits should not |
are representative periods of |
worth noting that the |
receiving at least one |
commits should not pose |
representative periods of mixed |
noting that the doubled |
at least one usable |
should not pose any |
periods of mixed read |
that the doubled token |
least one usable xor |
not pose any scalability |
of mixed read and |
the doubled token roundtrip |
one usable xor is |
pose any scalability problems |
mixed read and write |
doubled token roundtrip time |
any scalability problems in |
read and write activity |
scalability problems in a |
problems in a typical |
as compared to unperturbed |
in a typical environment |
the durations are from |
compared to unperturbed experiments |
durations are from the |
the probability of recovering |
are from the original |
probability of recovering the |
from the original ntfs |
we did not consider |
can t be accounted |
of recovering the lost |
the original ntfs traces |
did not consider the |
t be accounted for |
recovering the lost data |
the lost data packet |
lost data packet is |
not consider the rate |
be accounted for by |
note that the total |
consider the rate of |
accounted for by the |
that the total file |
the rate of read |
for by the increase |
the total file sizes |
rate of read operations |
by the increase in |
total file sizes represent |
of read operations because |
the increase in memory |
file sizes represent the |
read operations because clients |
increase in memory overhead |
sizes represent the amount |
operations because clients updating |
in memory overhead or |
represent the amount fetched |
because clients updating their |
memory overhead or cpu |
the amount fetched by |
clients updating their working |
overhead or cpu activity |
amount fetched by mfs |
updating their working copies |
or cpu activity on |
fetched by mfs during |
cpu activity on the |
by mfs during the |
activity on the receivers |
mfs during the trace |
or reading from the |
reading from the repository |
as was the case |
where this is exceed |
was the case in |
this is exceed by |
form formula only gives |
do not require a |
is exceed by the |
the case in experiments |
formula only gives us |
not require a lock |
exceed by the write |
by the write traffic |
only gives us a |
case in experiments where |
gives us a lower |
in experiments where we |
the debian community today |
us a lower bound |
experiments where we varied |
the additional traffic is |
debian community today uses |
a lower bound on |
where we varied the |
additional traffic is due |
community today uses only |
lower bound on the |
we varied the replication |
traffic is due to |
today uses only a |
bound on the recovery |
varied the replication factor |
is due to new |
uses only a single |
on the recovery probability |
due to new files |
the problem can be |
only a single subversion |
to new files being |
problem can be traced |
a single subversion server |
new files being created |
since the xor usability |
can be traced to |
files being created or |
the xor usability formula |
be traced to a |
being created or existing |
and the apache foundation |
traced to a priority |
xor usability formula does |
created or existing ones |
or existing ones extended |
to a priority inversion |
usability formula does not |
the apache foundation has |
formula does not factor |
apache foundation has a |
time spent on rpcs |
because of repeated losses |
does not factor in |
foundation has a master |
not factor in the |
has a master server |
factor in the probability |
the system maintains a |
a master server plus |
in the probability of |
system maintains a high |
master server plus a |
the probability of the |
maintains a high volume |
server plus a european |
probability of the other |
a high volume of |
high volume of forwarding |
of the other data |
plus a european mirror |
volume of forwarding traffic |
the other data packets |
other data packets in |
data packets in the |
packets in the xor |
in the xor being |
the forwarded messages tend |
primarily for latency reasons |
the xor being dropped |
forwarded messages tend to |
xor being dropped and |
messages tend to get |
being dropped and recovered |
tend to get ahead |
to get ahead of |
get ahead of the |
ahead of the token |
both on the send |
we expect that most |
on the send path |
we extend the analysis |
expect that most communities |
extend the analysis to |
the analysis to bursty |
analysis to bursty losses |
that most communities will |
where in the sinks |
most communities will have |
communities will have at |
if the lost data |
will have at most |
we use a simple |
use a simple round |
have at most a |
the lost data packet |
at most a handful |
lost data packet was |
robin policy of multiplexing |
most a handful of |
data packet was part |
policy of multiplexing between |
a handful of front |
packet was part of |
of multiplexing between data |
was part of a |
multiplexing between data feeds |
part of a loss |
of a loss burst |
a loss burst of |
loss burst of size |
burst of size b |
and on the receive |
on the receive path |
repair packets generated at |
packets generated at interleaves |
where forwarded packets are |
generated at interleaves less |
forwarded packets are treated |
at interleaves less than |
packets are treated as |
achieving consistency amazon s |
interleaves less than b |
are treated as control |
treated as control traffic |
less than b are |
consistency amazon s infrastructure |
than b are dropped |
amazon s infrastructure is |
b are dropped or |
and while they re |
s infrastructure is built |
are dropped or useless |
while they re prioritized |
they re prioritized over |
dropped or useless with |
or useless with high |
re prioritized over data |
infrastructure is built on |
useless with high probability |
is built on the |
built on the principle |
they are treated as |
on the principle of |
are treated as equally |
and we can discount |
we can discount them |
treated as equally important |
as equally important as |
equally important as tokens |
the principle of eventual |
principle of eventual consistency |
ntfs workloads in addition |
workloads in addition to |
they also increase the |
in addition to measuring |
of recovering the data |
also increase the overall |
addition to measuring the |
recovering the data packet |
increase the overall volume |
to measuring the performance |
the data packet is |
the overall volume of |
measuring the performance of |
data packet is then |
overall volume of i |
the performance of mfs |
performance of mfs with |
of mfs with synthetic |
mfs with synthetic workloads |
o that the nodes |
that the nodes process |
and does not directly |
we have also conducted |
does not directly support |
have also conducted experiments |
is the number of |
not directly support the |
also conducted experiments with |
the number of xors |
tokens are processed with |
are processed with higher |
conducted experiments with traces |
number of xors generated |
directly support the locking |
processed with higher latency |
experiments with traces gathered |
of xors generated at |
support the locking required |
with traces gathered from |
xors generated at interleaves |
the locking required for |
traces gathered from the |
generated at interleaves greater |
at interleaves greater than |
gathered from the windows |
locking required for revision |
interleaves greater than b |
from the windows nt |
required for revision control |
the windows nt file |
windows nt file system |
the formulae derived for |
formulae derived for xor |
derived for xor usability |
for xor usability still |
xor usability still hold |
originally developed to run |
developed to run the |
to run the company |
since packet losses with |
run the company s |
packet losses with more |
the company s own |
losses with more than |
histogram of maximum alarm |
company s own online |
with more than b |
of maximum alarm delays |
maximum alarm delays in |
more than b intervening |
s own online store |
than b intervening packets |
b intervening packets between |
intervening packets between them |
packets between them have |
between them have independent |
them have independent probability |
although mfs is implemented |
mfs is implemented on |
is implemented on a |
the system preferred availability |
there is only correlation |
implemented on a variant |
on a variant of |
a variant of unix |
system preferred availability over |
is only correlation within |
only correlation within the |
correlation within the bursts |
preferred availability over consistency |
and ntfs has a |
availability over consistency because |
ntfs has a somewhat |
histogram of maximum alarm |
of maximum alarm delays |
has a somewhat different |
over consistency because downtime |
maximum alarm delays in |
how does this compare |
a somewhat different interface |
somewhat different interface to |
does this compare to |
this compare to traditional |
different interface to the |
interface to the file |
to the file system |
consistency because downtime translated |
because downtime translated directly |
downtime translated directly into |
translated directly into lost |
the traces were converted |
directly into lost revenue |
traces were converted to |
were converted to run |
codes such as reed |
converted to run on |
to run on top |
run on top of |
on top of mfs |
top of mfs with |
of mfs with little |
mfs with little difficulty |
customers may opt to |
overheads in a lightly |
may opt to shop |
opt to shop elsewhere |
the original traces recorded |
to shop elsewhere or |
original traces recorded file |
loaded system so far |
shop elsewhere or to |
traces recorded file accesses |
system so far the |
elsewhere or to simply |
recorded file accesses on |
so far the evaluation |
or to simply forgo |
file accesses on a |
far the evaluation has |
to simply forgo impulse |
accesses on a set |
the evaluation has focused |
simply forgo impulse purchases |
on a set of |
evaluation has focused on |
forgo impulse purchases that |
a set of machines |
has focused on scenarios |
c repair packets are |
impulse purchases that they |
set of machines in |
focused on scenarios where |
repair packets are generated |
purchases that they didn |
of machines in a |
machines in a lan |
packets are generated and |
that they didn t |
on scenarios where the |
are generated and sent |
a majority of the |
scenarios where the system |
they didn t really |
generated and sent for |
majority of the accesses |
where the system was |
the system was heavily |
system was heavily loaded |
of the accesses were |
didn t really need |
and sent for every |
the accesses were local |
with unbounded multicast rates |
sent for every r |
for every r data |
accesses were local but |
unbounded multicast rates and |
t really need anyway |
every r data packets |
were local but some |
multicast rates and occasional |
local but some were |
rates and occasional perturbations |
but some were to |
and the correct delivery |
some were to remote |
were to remote machines |
the correct delivery of |
an inconsistent shopping cart |
correct delivery of any |
delivery of any r |
of any r of |
any r of the |
r of the r |
we traced degraded performance |
we extracted subintervals from |
traced degraded performance or |
extracted subintervals from the |
degraded performance or scheduling |
c packets transmitted is |
subintervals from the traces |
performance or scheduling delays |
could be resolved by |
from the traces which |
packets transmitted is sufficient |
or scheduling delays to |
scheduling delays to memory |
the traces which featured |
transmitted is sufficient to |
be resolved by heuristics |
traces which featured interesting |
is sufficient to reconstruct |
resolved by heuristics or |
which featured interesting file |
but how does the |
by heuristics or user |
sufficient to reconstruct the |
featured interesting file system |
how does the system |
to reconstruct the original |
interesting file system behaviour |
does the system behave |
reconstruct the original r |
file system behaviour and |
intervention at checkout time |
the system behave when |
the original r data |
system behaviour and processed |
system behave when lightly |
original r data packets |
behaviour and processed them |
behave when lightly loaded |
and processed them to |
it is well known |
processed them to remove |
them to remove accesses |
do similar phenomena occur |
to remove accesses to |
given a lost data |
a lost data packet |
is well known that |
remove accesses to files |
here we ll see |
accesses to files over |
well known that consistency |
we ll see that |
we can recover it |
ll see that load |
see that load has |
can recover it if |
known that consistency and |
that load has a |
this preprocessing was necessary |
recover it if at |
load has a super |
that consistency and availability |
preprocessing was necessary to |
it if at least |
consistency and availability cannot |
was necessary to eliminate |
if at least r |
linear impact on performance |
and availability cannot both |
necessary to eliminate the |
at least r packets |
availability cannot both be |
to eliminate the influence |
cannot both be achieved |
least r packets are |
both be achieved simultaneously |
eliminate the influence of |
be achieved simultaneously in |
the growth in memory |
achieved simultaneously in any |
the influence of extremely |
r packets are received |
growth in memory consumption |
simultaneously in any real |
influence of extremely large |
packets are received correctly |
in memory consumption causes |
in any real network |
of extremely large nt |
are received correctly in |
memory consumption causes slowdowns |
any real network where |
extremely large nt system |
received correctly in the |
consumption causes slowdowns that |
real network where hosts |
large nt system files |
correctly in the encoding |
causes slowdowns that amplify |
network where hosts or |
in the encoding set |
slowdowns that amplify the |
where hosts or entire |
the encoding set of |
that amplify the increased |
hosts or entire subnetworks |
encoding set of r |
amplify the increased latencies |
or entire subnetworks are |
the increased latencies associated |
entire subnetworks are sometimes |
c data and repair |
increased latencies associated with |
subnetworks are sometimes unreachable |
of the file system |
data and repair packets |
latencies associated with the |
are sometimes unreachable due |
the file system traffic |
and repair packets that |
associated with the growth |
sometimes unreachable due to |
file system traffic in |
repair packets that the |
with the growth in |
the growth in traffic |
system traffic in some |
packets that the lost |
unreachable due to connectivity |
traffic in some portions |
that the lost packet |
the lost packet belongs |
in some portions of |
to show this we |
due to connectivity losses |
lost packet belongs to |
some portions of the |
show this we designed |
portions of the original |
this we designed experiments |
of the original traces |
we designed experiments that |
designed experiments that vary |
experiments that vary the |
that vary the multicast |
vary the multicast rate |
the probability of recovering |
given that mfs retrieves |
probability of recovering a |
that mfs retrieves and |
of recovering a lost |
mfs retrieves and writes |
recovering a lost packet |
retrieves and writes back |
a lost packet is |
and writes back whole |
lost packet is equivalent |
writes back whole files |
if a cloud service |
packet is equivalent to |
showed that the load |
a cloud service is |
is equivalent to the |
that the load on |
including these system files |
cloud service is designed |
equivalent to the probability |
the load on receivers |
these system files would |
service is designed to |
to the probability of |
load on receivers grows |
system files would have |
is designed to provide |
the probability of losing |
on receivers grows roughly |
files would have distorted |
designed to provide high |
probability of losing c |
receivers grows roughly linearly |
would have distorted the |
to provide high availability |
have distorted the experiments |
provide high availability but |
as expected given the |
distorted the experiments at |
or less packets from |
high availability but an |
expected given the linearly |
the experiments at low |
less packets from the |
availability but an application |
given the linearly increasing |
experiments at low bandwidths |
packets from the total |
from the total r |
the linearly increasing load |
but an application instead |
an application instead requires |
application instead requires perfect |
instead requires perfect consistency |
negligible loss rates and |
gives statistics for the |
loss rates and the |
statistics for the three |
rates and the nearly |
since the number of |
for the three traces |
and the nearly flat |
additional software infrastructure is |
the number of other |
the nearly flat curve |
a trace in which |
number of other lost |
software infrastructure is required |
nearly flat curve of |
trace in which reads |
of other lost packets |
infrastructure is required to |
flat curve of memory |
in which reads predominate |
other lost packets in |
is required to bridge |
curve of memory consumption |
lost packets in the |
a trace in which |
required to bridge the |
packets in the xor |
trace in which writes |
to bridge the gap |
in the xor is |
in which writes predominate |
the xor is a |
xor is a random |
is a random variable |
a random variable y |
for revision control it |
random variable y and |
and one containing exceptionally |
revision control it makes |
variable y and has |
one containing exceptionally heavy |
control it makes sense |
the latter reflecting our |
containing exceptionally heavy file |
y and has a |
it makes sense to |
latter reflecting our cooperative |
exceptionally heavy file system |
and has a binomial |
makes sense to adopt |
reflecting our cooperative caching |
heavy file system traffic |
has a binomial distribution |
sense to adopt eventual |
our cooperative caching policy |
a binomial distribution with |
binomial distribution with parameters |
to adopt eventual consistency |
each trace was run |
load on the sender |
adopt eventual consistency for |
trace was run over |
eventual consistency for read |
was run over mfs |
consistency for read operations |
run over mfs with |
over mfs with the |
mfs with the combinations |
with the combinations of |
the combinations of synchronous |
since at worst an |
combinations of synchronous and |
because the linear growth |
at worst an earlier |
of synchronous and asynchronous |
the linear growth of |
worst an earlier revision |
synchronous and asynchronous writes |
linear growth of traffic |
an earlier revision will |
and asynchronous writes and |
earlier revision will fig |
asynchronous writes and differentiated |
combined with our fixed |
writes and differentiated and |
is the summation p |
with our fixed rate |
and differentiated and uniform |
the summation p z |
our fixed rate of |
differentiated and uniform priorities |
summation p z c |
fixed rate of state |
and uniform priorities in |
rate of state aggregation |
uniform priorities in previous |
priorities in previous experiments |
system architecture be returned |
increases the amount of |
the amount of unacknowledged |
amount of unacknowledged data |
and the results are |
the results are given |
if the user is |
results are given in |
are given in figure |
the user is aware |
through some other channel |
to interpret these graphs |
that a newer version |
a newer version should |
look for instance at |
newer version should exist |
for instance at the |
we plot the recovery |
instance at the heavy |
plot the recovery probability |
this triggers higher overheads |
at the heavy load |
the recovery probability curves |
the heavy load bar |
recovery probability curves for |
heavy load bar mostly |
probability curves for layered |
load bar mostly reads |
he can retry and |
curves for layered interleaving |
the time spent in |
can retry and expect |
for layered interleaving and |
time spent in the |
retry and expect that |
layered interleaving and reed |
spent in the garbage |
and expect that version |
in the garbage collector |
expect that version to |
solomon against uniformly random |
the garbage collector grows |
that version to be |
against uniformly random loss |
garbage collector grows from |
version to be available |
uniformly random loss rate |
to be available within |
be available within a |
available within a short |
within a short timeframe |
perfect consistency is required |
consistency is required and |
is required and a |
required and a locking |
and a locking layer |
a locking layer must |
locking layer must be |
layer must be built |
must be built to |
be built to support |
built to support this |
note that the curves |
that the curves are |
the curves are very |
curves are very close |
combined with a linear |
are very close to |
very close to each |
close to each other |
this may result in |
with a linear growth |
may result in a |
a linear growth of |
especially in the loss |
result in a commit |
linear growth of cpu |
in the loss range |
in a commit being |
growth of cpu usage |
the loss range of |
a commit being rejected |
of cpu usage due |
loss range of interest |
range of interest between |
cpu usage due to |
commit being rejected if |
usage due to the |
being rejected if consensus |
due to the increasing |
rejected if consensus cannot |
to the increasing volume |
if consensus cannot be |
the increasing volume of |
increasing volume of traffic |
consensus cannot be reached |
these overheads cause the |
overheads cause the super |
but shouldn t be |
shouldn t be a |
linear growth of cpu |
t be a problem |
applications unique files total |
growth of cpu overhead |
be a problem because |
unique files total file |
local recovery for receiver |
a problem because code |
of cpu overhead shown |
files total file sizes |
recovery for receiver loss |
problem because code changes |
cpu overhead shown on |
for receiver loss in |
because code changes are |
overhead shown on figure |
receiver loss in the |
code changes are usually |
loss in the absence |
changes are usually not |
in the absence of |
are usually not impulse |
the absence of intelligent |
usually not impulse decisions |
absence of intelligent flow |
not impulse decisions and |
of intelligent flow control |
impulse decisions and the |
intelligent flow control mechanisms |
the increasing number of |
decisions and the commit |
flow control mechanisms like |
increasing number of unacknowledged |
and the commit can |
control mechanisms like tcp |
number of unacknowledged requests |
the commit can be |
of unacknowledged requests and |
commit can be retried |
unacknowledged requests and the |
grep in the gw |
can be retried later |
requests and the resulting |
in the gw workload |
and the resulting overheads |
the gw workload even |
inexpensive data center end |
the resulting overheads rise |
gw workload even is |
resulting overheads rise sharply |
workload even is less |
overheads rise sharply at |
hosts can be easily |
even is less than |
d esign as a |
rise sharply at the |
can be easily overwhelmed |
is less than would |
esign as a proof |
sharply at the highest |
be easily overwhelmed and |
less than would be |
at the highest rates |
easily overwhelmed and drop |
than would be expected |
the highest rates because |
overwhelmed and drop packets |
would be expected with |
highest rates because of |
and drop packets during |
be expected with reduced |
rates because of the |
drop packets during traffic |
expected with reduced bandwidth |
because of the increasing |
packets during traffic spikes |
of the increasing token |
during traffic spikes or |
the increasing token roundtrip |
traffic spikes or cpu |
here uniform priorities result |
increasing token roundtrip time |
uniform priorities result in |
a tool for integrating |
priorities result in throughput |
intensive maintenance tasks like |
tool for integrating subversion |
result in throughput linear |
maintenance tasks like garbage |
the issue here is |
for integrating subversion with |
in throughput linear in |
tasks like garbage collection |
issue here is that |
integrating subversion with s |
throughput linear in the |
here is that the |
linear in the bandwidth |
is that the amount |
that the amount of |
the amount of i |
level protocols layered over |
protocols layered over udp |
while differentiated priorities are |
layered over udp for |
differentiated priorities are less |
o to be processed |
over udp for reliable |
priorities are less sensitive |
to be processed increases |
vn is colocated with |
udp for reliable multicast |
is colocated with subversion |
the rc and gc |
much as in some |
colocated with subversion and |
rc and gc tests |
as in some of |
with subversion and inserts |
and gc tests show |
in some of the |
subversion and inserts a |
gc tests show the |
some of the earlier |
of the earlier scenarios |
tests show the benefit |
and inserts a layer |
or high speed data |
show the benefit of |
inserts a layer between |
high speed data transfer |
the benefit of asynchronous |
this delays tokens as |
a layer between subversion |
benefit of asynchronous writeback |
delays tokens as a |
layer between subversion and |
tokens as a function |
between subversion and s |
as a function of |
a function of the |
since the updates from |
function of the growing |
the updates from the |
of the growing volume |
updates from the compile |
the growing volume of |
from the compile workload |
growing volume of multicast |
the compile workload are |
volume of multicast traffic |
as shown in figure |
compile workload are committed |
for example would ordinarily |
workload are committed sooner |
example would ordinarily go |
we confirm the hypothesis |
are committed sooner to |
would ordinarily go back |
confirm the hypothesis by |
committed sooner to the |
ordinarily go back to |
the hypothesis by looking |
for simplicity we did |
sooner to the server |
go back to the |
hypothesis by looking at |
by looking at the |
to the server than |
back to the sender |
simplicity we did not |
looking at the end |
the server than with |
to the sender to |
we did not modify |
server than with synchronous |
the sender to retrieve |
did not modify the |
than with synchronous writes |
sender to retrieve the |
not modify the subversion |
to retrieve the lost |
modify the subversion server |
retrieve the lost packet |
the subversion server in |
due to the overlap |
subversion server in any |
to the overlap of |
server in any way |
the overlap of think |
even though it was |
overlap of think time |
though it was dropped |
of think time with |
it was dropped at |
think time with asynchronous |
was dropped at the |
time with asynchronous writes |
dropped at the receiver |
vn is responsible for |
at the receiver after |
is responsible for receiving |
the receiver after covering |
we would expect latency |
responsible for receiving event |
receiver after covering the |
though uniform priorities provide |
for receiving event notifications |
would expect latency to |
after covering the entire |
uniform priorities provide better |
receiving event notifications from |
expect latency to decrease |
event notifications from subversion |
priorities provide better performance |
covering the entire geographical |
latency to decrease as |
notifications from subversion and |
provide better performance for |
the entire geographical distance |
to decrease as the |
from subversion and transferring |
better performance for the |
decrease as the sending |
subversion and transferring data |
performance for the write |
the maelstrom proxy acts |
as the sending rate |
and transferring data between |
for the write component |
maelstrom proxy acts as |
the sending rate increases |
transferring data between the |
the write component of |
proxy acts as a |
sending rate increases because |
data between the local |
write component of the |
acts as a local |
rate increases because the |
between the local disk |
component of the rw |
as a local packet |
increases because the system |
the local disk on |
of the rw test |
a local packet cache |
because the system operates |
local disk on the |
the rw test at |
the system operates more |
disk on the ec |
system operates more smoothly |
storing incoming packets for |
incoming packets for a |
packets for a short |
for a short period |
avoiding context switching overheads |
a short period of |
context switching overheads and |
short period of time |
switching overheads and the |
period of time and |
overheads and the extra |
of time and providing |
and the extra latencies |
time and providing hooks |
the extra latencies caused |
and providing hooks that |
extra latencies caused by |
providing hooks that allow |
vn at the start |
hooks that allow protocols |
latencies caused by the |
at the start and |
as is to be |
is to be expected |
caused by the small |
the start and end |
that allow protocols to |
by the small amount |
since we are prioritising |
we are prioritising reads |
start and end of |
and end of each |
allow protocols to first |
the small amount of |
end of each commit |
protocols to first query |
small amount of buffering |
to first query the |
amount of buffering in |
this benefit largely vanishes |
first query the cache |
of buffering in our |
benefit largely vanishes at |
query the cache to |
buffering in our protocol |
largely vanishes at lower |
the cache to locate |
in our protocol stack |
vn acquires and releases |
vanishes at lower bandwidths |
cache to locate missing |
acquires and releases locks |
with larger packets once |
to locate missing packets |
and releases locks using |
larger packets once the |
locate missing packets before |
though we have concentrated |
releases locks using yahoo |
packets once the rate |
missing packets before sending |
we have concentrated on |
locks using yahoo s |
once the rate exceeds |
packets before sending retransmission |
have concentrated on determining |
using yahoo s open |
before sending retransmission requests |
concentrated on determining the |
yahoo s open source |
sending retransmission requests back |
on determining the benefit |
s open source zookeeper |
retransmission requests back to |
determining the benefit of |
open source zookeeper lock |
requests back to the |
the benefit of rpc |
source zookeeper lock service |
back to the sender |
benefit of rpc priorities |
of rpc priorities by |
rpc priorities by a |
priorities by a comparison |
by a comparison of |
the difficulty achieving consistency |
future versions of maelstrom |
the latency starts increasing |
a comparison of different |
difficulty achieving consistency with |
versions of maelstrom could |
latency starts increasing again |
comparison of different configurations |
achieving consistency with a |
of maelstrom could potentially |
due to the longer |
consistency with a service |
of different configurations of |
maelstrom could potentially use |
to the longer pipeline |
with a service such |
different configurations of mfs |
could potentially use knowledge |
the longer pipeline at |
a service such as |
configurations of mfs to |
potentially use knowledge of |
longer pipeline at the |
service such as amazon |
of mfs to one |
mfs to one another |
pipeline at the receive |
such as amazon s |
use knowledge of protocol |
at the receive side |
as amazon s s |
knowledge of protocol internals |
the receive side and |
we have also performed |
of protocol internals to |
receive side and other |
have also performed a |
stems from the fact |
side and other phenomena |
protocol internals to transparently |
also performed a few |
from the fact that |
and other phenomena just |
internals to transparently intervene |
performed a few experiments |
the fact that files |
other phenomena just mentioned |
a few experiments to |
fact that files pushed |
few experiments to compare |
that files pushed into |
this is not the |
files pushed into the |
experiments to compare the |
by intercepting and satisfying |
is not the case |
pushed into the storage |
to compare the performance |
intercepting and satisfying retransmission |
not the case for |
into the storage cloud |
compare the performance of |
and satisfying retransmission requests |
the case for small |
the storage cloud do |
the performance of mfs |
satisfying retransmission requests sent |
case for small packets |
storage cloud do not |
performance of mfs to |
retransmission requests sent by |
cloud do not simultaneously |
of mfs to a |
requests sent by the |
do not simultaneously become |
mfs to a standard |
sent by the receiver |
not simultaneously become available |
to a standard distributed |
by the receiver in |
simultaneously become available on |
a standard distributed file |
the receiver in a |
receiver in a nak |
standard distributed file system |
become available on all |
here the load on |
available on all service |
the load on the |
on all service endpoints |
load on the system |
on the system is |
the system is much |
system is much smaller |
illustrates the result of |
or by resending packets |
the result of running |
if a file is |
by resending packets when |
result of running the |
a file is overwritten |
resending packets when acknowledgments |
of running the gw |
packets when acknowledgments are |
running the gw test |
the above observations are |
when acknowledgments are not |
the gw test over |
different clients may read |
above observations are consistent |
acknowledgments are not observed |
gw test over mfs |
clients may read back |
observations are consistent with |
are not observed within |
test over mfs and |
may read back different |
are consistent with the |
not observed within a |
over mfs and an |
read back different versions |
consistent with the sharp |
observed within a certain |
mfs and an andrew |
with the sharp rise |
within a certain time |
and an andrew file |
the sharp rise of |
a certain time period |
and even the same |
an andrew file system |
sharp rise of the |
certain time period in |
time period in an |
period in an ack |
even the same client |
rise of the average |
the same client may |
of the average delay |
same client may see |
the average delay for |
client may see the |
average delay for timer |
we used the arla |
may see the old |
delay for timer events |
used the arla implementation |
see the old version |
implementation details we initially |
the arla implementation of |
the old version if |
details we initially implemented |
arla implementation of the |
old version if it |
we initially implemented and |
implementation of the afs |
version if it suddenly |
initially implemented and evaluated |
of the afs cache |
if it suddenly switches |
implemented and evaluated maelstrom |
the afs cache manager |
it suddenly switches to |
and evaluated maelstrom as |
as the rate changes |
the rate changes from |
evaluated maelstrom as a |
maelstrom as a user |
suddenly switches to speaking |
switches to speaking with |
to speaking with a |
speaking with a different |
with a different s |
performance turned out to |
turned out to be |
and the openafs server |
out to be limited |
to be limited by |
be limited by copying |
limited by copying and |
by copying and context |
the file will always |
afs uses a udp |
file will always be |
will always be internally |
always be internally consistent |
based rpc library without |
rpc library without priorities |
and we subsequently reimplemented |
we subsequently reimplemented the |
since put and get |
subsequently reimplemented the system |
put and get operations |
the results largely correspond |
reimplemented the system as |
and get operations are |
timer delays at the |
the system as a |
results largely correspond to |
get operations are atomic |
delays at the receiver |
system as a module |
largely correspond to those |
at the receiver increase |
as a module that |
correspond to those in |
but its contents may |
a module that runs |
the receiver increase from |
to those in figure |
its contents may not |
module that runs within |
contents may not reflect |
that runs within the |
runs within the linux |
may not reflect expectations |
not reflect expectations that |
reflect expectations that the |
mfs significantly outperforms afs |
expectations that the client |
significantly outperforms afs for |
that the client formed |
outperforms afs for the |
afs for the foreground |
for the foreground grep |
the client formed based |
the foreground grep workload |
and on the sender |
client formed based on |
formed based on other |
based on other files |
on other files and |
since afs effectively uses |
other files and out |
afs effectively uses synchronous |
files and out of |
effectively uses synchronous rpcs |
and out of band |
uses synchronous rpcs with |
out of band communication |
synchronous rpcs with uniform |
rpcs with uniform priorities |
at an encoding rate |
an encoding rate of |
in the background write |
the background write workload |
afs slightly outperforms mfs |
vn works around the |
works around the consistency |
around the consistency problem |
the consistency problem by |
but it is both |
consistency problem by storing |
it is both a |
number of unacknowledged messages |
problem by storing the |
is both a more |
of unacknowledged messages and |
by storing the number |
both a more mature |
unacknowledged messages and average |
storing the number of |
a more mature system |
the experimental prototype of |
messages and average token |
the number of the |
experimental prototype of the |
and average token roundtrip |
number of the latest |
prototype of the kernel |
and more optimised than |
average token roundtrip time |
of the latest revision |
of the kernel version |
more optimised than mfs |
token roundtrip time as |
the latest revision into |
the kernel version reaches |
optimised than mfs for |
roundtrip time as a |
latest revision into zookeeper |
kernel version reaches output |
than mfs for this |
time as a function |
version reaches output speeds |
mfs for this sort |
as a function of |
reaches output speeds close |
for this sort of |
a function of the |
output speeds close to |
this sort of communication |
even if multiple files |
function of the sending |
if multiple files were |
of the sending rate |
multiple files were changed |
gigabit per second of |
since the results of |
files were changed by |
per second of combined |
the results of running |
were changed by the |
second of combined data |
results of running the |
changed by the client |
of combined data and |
of running the other |
combined data and fec |
data and fec traffic |
running the other tests |
the other tests are |
is represented by subversion |
other tests are similar |
linearly growing memory use |
represented by subversion has |
limited only by the |
growing memory use on |
we omit them for |
omit them for brevity |
by subversion has a |
memory use on sender |
only by the capacity |
subversion has a single |
use on sender and |
by the capacity of |
has a single file |
on sender and the |
the capacity of the |
a single file containing |
mostly reads mostly writes |
sender and the nearly |
capacity of the outbound |
single file containing binary |
reads mostly writes heavy |
and the nearly flat |
of the outbound network |
the outbound network card |
mostly writes heavy load |
the nearly flat usage |
file containing binary diffs |
writes heavy load store |
nearly flat usage on |
containing binary diffs against |
heavy load store overhead |
flat usage on the |
lambda networks are already |
load store overhead priorities |
binary diffs against earlier |
usage on the receiver |
networks are already reaching |
store overhead priorities uniform |
diffs against earlier revisions |
on the receiver as |
are already reaching speeds |
overhead priorities uniform priorities |
the receiver as a |
already reaching speeds of |
priorities uniform priorities uniform |
receiver as a function |
a revision is never |
uniform priorities uniform synchronous |
as a function of |
revision is never changed |
priorities uniform synchronous asynchronous |
a function of the |
is never changed after |
uniform synchronous asynchronous time |
function of the sending |
of the sending rate |
synchronous asynchronous time spent |
never changed after the |
asynchronous time spent on |
changed after the fact |
time spent on rpcs |
end server attempting to |
server attempting to fetch |
attempting to fetch a |
and higher speeds are |
to fetch a revision |
higher speeds are a |
fetch a revision i |
speeds are a certainty |
a revision i from |
are a certainty down |
revision i from s |
a certainty down the |
receive latency for varying |
certainty down the road |
latency for varying rate |
will receive either the |
receive either the one |
either the one true |
with various message sizes |
we envision maelstrom as |
or a missing file |
envision maelstrom as a |
a missing file error |
maelstrom as a small |
as a small rack |
missing file error if |
file error if i |
error if i was |
if i was posted |
alarm firing delays on |
i was posted so |
style cluster of servers |
firing delays on sender |
was posted so recently |
delays on sender and |
posted so recently that |
on sender and receiver |
each acting as an |
so recently that it |
sender and receiver as |
acting as an individual |
as an individual proxy |
and receiver as a |
recently that it has |
receiver as a function |
that it has not |
as a function of |
a function of sending |
function of sending rate |
traffic would be distributed |
would be distributed over |
be distributed over such |
distributed over such a |
over such a rack |
such a rack by |
a rack by partitioning |
rack by partitioning the |
by partitioning the address |
partitioning the address space |
the address space of |
address space of the |
space of the remote |
of the remote data |
the remote data center |
remote data center and |
data center and routing |
center and routing different |
and routing different segments |
routing different segments of |
different segments of the |
segments of the space |
of the space through |
the space through distinct |
space through distinct maelstrom |
through distinct maelstrom appliance |
distinct maelstrom appliance pairs |
group memory consumption in |
we plan to experiment |
memory consumption in a |
plan to experiment with |
consumption in a final |
to experiment with such |
in a final set |
experiment with such configurations |
a final set of |
final set of experiments |
which would also permit |
would also permit us |
we focus on scalability |
also permit us to |
focus on scalability with |
permit us to explore |
us to explore fault |
on scalability with the |
scalability with the number |
with the number of |
the number of groups |
a single sender multicasts |
if a maelstrom blade |
a maelstrom blade fails |
single sender multicasts to |
sender multicasts to a |
multicasts to a varying |
to a varying number |
a varying number of |
varying number of groups |
number of groups in |
of groups in a |
groups in a roundrobin |
in a roundrobin fashion |
and to support load |
all receivers join all |
receivers join all groups |
balancing schemes that might |
and since the groups |
schemes that might vary |
since the groups are |
that might vary the |
the groups are perfectly |
might vary the ip |
groups are perfectly overlapped |
vary the ip address |
the ip address space |
ip address space partitioning |
address space partitioning dynamically |
space partitioning dynamically to |
the system contains a |
partitioning dynamically to spread |
system contains a single |
dynamically to spread the |
contains a single region |
to spread the encoding |
spread the encoding load |
the encoding load over |
encoding load over multiple |
load over multiple machines |
qsm s regional recovery |
s regional recovery protocol |
regional recovery protocol is |
recovery protocol is oblivious |
protocol is oblivious to |
is oblivious to the |
oblivious to the groups |
hence the receivers behave |
the receivers behave identically |
receivers behave identically no |
we present the implementation |
behave identically no matter |
identically no matter how |
present the implementation and |
no matter how many |
matter how many groups |
how many groups we |
many groups we use |
the implementation and performance |
implementation and performance of |
and performance of a |
performance of a single |
on the other hand |
the sender maintains a |
sender maintains a number |
maintains a number of |
a number of per |
the kernel implementation is |
kernel implementation is a |
implementation is a module |
is a module for |
a module for linux |
end servers are equivalent |
servers are equivalent and |
this affects the sender |
are equivalent and clients |
affects the sender s |
equivalent and clients may |
the sender s memory |
and clients may interact |
sender s memory footprint |
clients may interact with |
may interact with any |
interact with any of |
with any of them |
any of them fig |
so changes to throughput |
changes to throughput or |
to throughput or protocol |
throughput or protocol behavior |
or protocol behavior must |
protocol behavior must be |
behavior must be directly |
must be directly or |
with hooks into the |
be directly or indirectly |
hooks into the kernel |
directly or indirectly linked |
into the kernel packet |
or indirectly linked to |
indirectly linked to memory |
linked to memory usage |
the kernel packet filter |
e valuation we observe |
valuation we observe that |
we observe that running |
observe that running multiple |
that running multiple front |
we do not expect |
do not expect the |
not expect the token |
expect the token roundtrip |
the token roundtrip time |
token roundtrip time or |
roundtrip time or the |
time or the amount |
which cloud computing makes |
or the amount of |
cloud computing makes easy |
the amount of messages |
computing makes easy to |
amount of messages pending |
makes easy to do |
of messages pending acknowledgement |
maelstrom proxies work in |
messages pending acknowledgement to |
proxies work in pairs |
pending acknowledgement to vary |
acknowledgement to vary with |
to vary with the |
vary with the number |
increases the throughput of |
the throughput of read |
throughput of read operations |
one on each side |
with the number of |
the number of groups |
on each side of |
each side of the |
side of the long |
of the long haul |
the long haul link |
vn by running a |
by running a fixed |
running a fixed number |
a fixed number of |
each proxy acts both |
fixed number of clients |
proxy acts both as |
acts both as an |
both as an ingress |
as an ingress and |
each repeatedly checking out |
repeatedly checking out about |
an ingress and egress |
ingress and egress router |
groups this is the |
this is the case |
and egress router at |
egress router at the |
router at the same |
at the same time |
the same time since |
same time since they |
time since they handle |
since they handle duplex |
they handle duplex traffic |
handle duplex traffic in |
duplex traffic in the |
traffic in the following |
in the following manner |
the egress router captures |
egress router captures ip |
router captures ip packets |
captures ip packets and |
ip packets and creates |
packets and creates redundant |
and creates redundant fec |
creates redundant fec packets |
in this range memory |
this range memory consumption |
range memory consumption on |
memory consumption on the |
consumption on the sender |
on the sender grows |
the original ip packets |
original ip packets are |
ip packets are routed |
packets are routed through |
are routed through unaltered |
routed through unaltered as |
through unaltered as they |
unaltered as they would |
as they would have |
they would have been |
would have been originally |
the redundant packets are |
redundant packets are then |
packets are then forwarded |
are then forwarded to |
then forwarded to the |
forwarded to the remote |
to the remote ingress |
and so does the |
the remote ingress router |
so does the time |
remote ingress router via |
does the time spent |
yet propagated through s |
ingress router via a |
router via a udp |
via a udp channel |
the time spent in |
time spent in the |
spent in the clr |
the ingress router captures |
in the latter case |
ingress router captures and |
router captures and stores |
captures and stores ip |
and stores ip packets |
stores ip packets coming |
the server retries indefinitely |
ip packets coming from |
server retries indefinitely until |
packets coming from the |
retries indefinitely until the |
coming from the direction |
indefinitely until the file |
from the direction of |
until the file is |
the file is available |
the direction of the |
direction of the egress |
of the egress router |
zookeeper ensures that the |
ensures that the latest |
that the latest revision |
upon receipt of a |
the latest revision number |
receipt of a redundant |
latest revision number is |
of a redundant packet |
revision number is incremented |
number is incremented atomically |
an ip packet is |
ip packet is recovered |
inspection of the managed |
zookeeper maintains a simple |
packet is recovered if |
of the managed heap |
maintains a simple filesystem |
is recovered if there |
the managed heap in |
a simple filesystem like |
recovered if there is |
managed heap in a |
simple filesystem like tree |
filesystem like tree of |
like tree of nodes |
if there is an |
heap in a debugger |
there is an opportunity |
is an opportunity to |
in a debugger shows |
nodes may store a |
an opportunity to do |
opportunity to do so |
may store a small |
a debugger shows that |
store a small amount |
debugger shows that the |
a small amount of |
shows that the growth |
redundant packets that can |
small amount of data |
that the growth in |
packets that can be |
amount of data and |
the growth in memory |
that can be used |
of data and can |
growth in memory used |
can be used at |
data and can have |
in memory used is |
be used at a |
and can have children |
memory used is caused |
used at a later |
used is caused not |
at a later time |
is caused not by |
a later time are |
caused not by messages |
later time are stored |
vn stores the latest |
stores the latest revision |
the latest revision number |
latest revision number in |
but by the per |
if the redundant packet |
the redundant packet is |
redundant packet is useless |
packet is useless it |
is useless it is |
group elements of the |
useless it is immediately |
elements of the protocol |
it is immediately discarded |
of the protocol stack |
upon recovery the ip |
each maintains a queue |
recovery the ip packet |
the ip packet is |
ip packet is sent |
packet is sent through |
is sent through a |
sent through a raw |
through a raw socket |
a raw socket to |
raw socket to its |
socket to its intended |
to its intended destination |
small structures for profiling |
structures for profiling etc |
supporting multiple named repositories |
using fec requires that |
multiple named repositories in |
fec requires that each |
named repositories in a |
requires that each data |
with thousands of groups |
that each data packet |
repositories in a single |
each data packet have |
in a single zookeeper |
data packet have a |
a single zookeeper tree |
these add up to |
packet have a unique |
add up to tens |
have a unique identifier |
up to tens of |
before pushing a new |
a unique identifier that |
to tens of megabytes |
pushing a new revision |
unique identifier that the |
identifier that the receiver |
that the receiver can |
we can confirm the |
the receiver can use |
can confirm the theory |
receiver can use to |
confirm the theory by |
can use to keep |
end server must acquire |
the theory by turning |
use to keep track |
server must acquire a |
theory by turning on |
to keep track of |
must acquire a lock |
by turning on additional |
keep track of received |
acquire a lock by |
turning on additional tracing |
track of received data |
a lock by creating |
on additional tracing in |
of received data packets |
lock by creating a |
additional tracing in the |
tracing in the per |
by creating a sequence |
received data packets and |
creating a sequence node |
data packets and to |
packets and to identify |
and to identify missing |
to identify missing data |
identify missing data packets |
missing data packets in |
this tracing is lightweight |
data packets in a |
tracing is lightweight and |
packets in a repair |
in a repair packet |
is lightweight and has |
lightweight and has little |
and has little effect |
has little effect on |
little effect on cpu |
effect on cpu consumption |
if we had access |
we had access to |
had access to end |
but it increases the |
it increases the memory |
increases the memory footprint |
the memory footprint by |
memory footprint by adding |
footprint by adding additional |
we could have added |
by adding additional data |
could have added a |
adding additional data structures |
have added a header |
additional data structures that |
added a header to |
data structures that are |
a header to each |
structures that are updated |
header to each packet |
that are updated once |
to each packet with |
to which zookeeper will |
are updated once per |
each packet with a |
which zookeeper will append |
updated once per second |
packet with a unique |
zookeeper will append a |
with a unique sequence |
will append a unique |
which burdens the gc |
a unique sequence number |
monotonically increasing sequence number |
end server then lists |
server then lists the |
then lists the children |
lists the children of |
we intercept traffic transparently |
intercept traffic transparently and |
traffic transparently and need |
transparently and need to |
it is worth noting |
route it without modification |
is worth noting that |
it without modification or |
worth noting that the |
without modification or addition |
noting that the memory |
that the memory usages |
the memory usages reported |
memory usages reported here |
usages reported here are |
reported here are averages |
if its own lock |
its own lock node |
own lock node has |
lock node has the |
node has the lowest |
has the lowest number |
we identify ip packets |
identify ip packets by |
ip packets by a |
packets by a tuple |
by a tuple consisting |
a tuple consisting of |
and the peak values |
the peak values are |
tuple consisting of the |
it may proceed with |
peak values are typically |
consisting of the source |
may proceed with the |
of the source and |
proceed with the commit |
the source and destination |
source and destination ip |
and destination ip address |
otherwise it watches the |
it watches the node |
watches the node with |
the node with the |
node with the next |
size of the ip |
with the next lower |
of the ip header |
the next lower number |
the ip header plus |
ip header plus data |
next lower number in |
lower number in order |
number in order to |
in order to be |
and a checksum over |
order to be notified |
a checksum over the |
to be notified when |
checksum over the ip |
be notified when that |
the nodes on our |
over the ip data |
notified when that node |
nodes on our cluster |
the ip data payload |
when that node and |
on our cluster only |
our cluster only have |
that node and its |
node and its associated |
the checksum over the |
and its associated lock |
checksum over the payload |
its associated lock go |
over the payload is |
associated lock go away |
the payload is necessary |
payload is necessary since |
is necessary since the |
necessary since the ip |
since the ip identification |
the ip identification field |
after comitting the revision |
ip identification field is |
comitting the revision to |
identification field is only |
the revision to s |
bits long and a |
long and a single |
and a single pair |
a single pair of |
single pair of end |
hosts communicating at high |
communicating at high speeds |
at high speeds will |
high speeds will use |
speeds will use the |
will use the same |
use the same identifier |
the same identifier for |
same identifier for different |
memory footprint is significant |
identifier for different data |
for different data packets |
different data packets within |
data packets within a |
packets within a fairly |
it releases its lock |
within a fairly short |
releases its lock by |
a fairly short interval |
its lock by deleting |
fairly short interval unless |
lock by deleting the |
short interval unless the |
by deleting the lock |
interval unless the checksum |
deleting the lock node |
unless the checksum is |
the checksum is added |
checksum is added to |
is added to differentiate |
added to differentiate between |
to differentiate between them |
lock nodes are marked |
the peak footprint approaches |
nodes are marked with |
are marked with zookeeper |
marked with zookeeper s |
with zookeeper s ephemeral |
zookeeper s ephemeral flag |
s ephemeral flag to |
unique identifiers result in |
ephemeral flag to ensure |
identifiers result in garbled |
flag to ensure that |
result in garbled recovery |
to ensure that the |
in garbled recovery by |
ensure that the lock |
and the system is |
garbled recovery by maelstrom |
that the lock is |
the system is close |
the lock is forcibly |
system is close to |
lock is forcibly released |
is close to swapping |
an event which will |
is forcibly released if |
event which will be |
forcibly released if the |
which will be caught |
released if the front |
will be caught by |
be caught by higher |
caught by higher level |
by higher level checksums |
higher level checksums designed |
level checksums designed to |
checksums designed to deal |
zookeeper runs as a |
designed to deal with |
runs as a replicated |
to deal with tranmission |
as a replicated service |
deal with tranmission errors |
with tranmission errors on |
tranmission errors on commodity |
errors on commodity networks |
on commodity networks and |
so it remains available |
commodity networks and hence |
it remains available as |
networks and hence does |
remains available as long |
and hence does not |
available as long as |
hence does not have |
as long as a |
does not have significant |
long as a majority |
not have significant consequences |
as a majority of |
groups are enough to |
have significant consequences unless |
a majority of the |
are enough to trigger |
significant consequences unless it |
majority of the hosts |
enough to trigger signs |
to trigger signs of |
trigger signs of instability |
consequences unless it occurs |
unless it occurs frequently |
of the hosts are |
the hosts are up |
hosts are up and |
token roundtrip times start |
are up and reachable |
roundtrip times start to |
times start to grow |
the kernel version of |
kernel version of maelstrom |
version of maelstrom can |
a client only speaks |
thus delaying message cleanup |
of maelstrom can generate |
client only speaks to |
maelstrom can generate up |
only speaks to one |
can generate up to |
speaks to one zookeeper |
generate up to a |
to one zookeeper server |
up to a gigabit |
one zookeeper server at |
to a gigabit per |
zookeeper server at a |
a gigabit per second |
server at a time |
gigabit per second of |
and increasing memory overhead |
per second of data |
second of data and |
of data and fec |
data and fec traffic |
though it may fail |
with the input data |
the input data rate |
over to another server |
to another server if |
another server if necessary |
input data rate depending |
data rate depending on |
rate depending on the |
depending on the encoding |
on the encoding rate |
although the process is |
the process is fairly |
process is fairly unpredictable |
but the server ensures |
the server ensures that |
server ensures that the |
we were able to |
ensures that the relevant |
we see spikes and |
see spikes and anomalies |
that the relevant state |
were able to saturate |
the relevant state has |
able to saturate the |
relevant state has been |
to saturate the outgoing |
state has been replicated |
saturate the outgoing card |
has been replicated before |
we can easily recognize |
the outgoing card at |
been replicated before responding |
can easily recognize a |
outgoing card at rates |
replicated before responding to |
easily recognize a super |
card at rates as |
before responding to a |
at rates as high |
responding to a client |
linear trend starting at |
trend starting at around |
to a client s |
rates as high as |
a client s request |
in general multiple front |
end servers may be |
servers may be run |
each on its own |
on its own ec |
at around this point |
with cpu overload occurring |
we also start to |
cpu overload occurring at |
also start to see |
the system is organized |
start to see occasional |
system is organized as |
to see occasional bursts |
is organized as in |
see occasional bursts of |
organized as in figure |
occasional bursts of packet |
bursts of packet losses |
unlike the traditional replicated |
the traditional replicated subversion |
where each incoming data |
traditional replicated subversion setups |
each incoming data packet |
replicated subversion setups that |
often roughly correlated across |
incoming data packet had |
subversion setups that are |
roughly correlated across receivers |
data packet had to |
setups that are used |
packet had to be |
that are used today |
such events trigger bursty |
had to be xored |
events trigger bursty recovery |
trigger bursty recovery overloads |
no single server acts |
single server acts as |
server acts as a |
acts as a master |
buffering requirements at the |
requirements at the receive |
vn all are equivalent |
performance of simultaneous checkouts |
number of messages pending |
incoming data packets are |
of messages pending ack |
data packets are buffered |
messages pending ack and |
packets are buffered so |
pending ack and token |
are buffered so that |
ack and token roundtrip |
buffered so that they |
and token roundtrip time |
so that they can |
token roundtrip time as |
that they can be |
roundtrip time as a |
they can be used |
time as a function |
can be used in |
as a function of |
be used in conjunction |
a function of the |
used in conjunction with |
function of the number |
of the number of |
the number of groups |
in conjunction with xors |
conjunction with xors to |
with xors to recover |
xors to recover missing |
to recover missing data |
recover missing data packets |
any received xor that |
received xor that is |
xor that is missing |
memory usage grows with |
that is missing more |
usage grows with the |
grows with the number |
with the number of |
is missing more than |
the number of groups |
missing more than one |
more than one data |
than one data packet |
one data packet is |
data packet is stored |
packet is stored temporarily |
beyond a certain threshold |
performance of simultaneous commits |
of simultaneous commits source |
simultaneous commits source code |
commits source code from |
the system is increasingly |
in case all but |
source code from an |
code from an ec |
case all but one |
system is increasingly unstable |
all but one of |
but one of the |
one of the missing |
of the missing packets |
the missing packets are |
missing packets are received |
packets are received later |
are received later or |
received later or recovered |
later or recovered through |
or recovered through other |
recovered through other xors |
allowing the recovery of |
time spent in the |
spent in the clr |
in the clr code |
and varying the number |
the recovery of the |
varying the number of |
recovery of the remaining |
the number of servers |
of the remaining missing |
number of servers over |
the remaining missing packet |
of servers over which |
remaining missing packet from |
servers over which the |
missing packet from this |
packet from this xor |
over which the load |
which the load was |
the load was distributed |
throughput decreases with the |
decreases with the number |
with the number of |
in practice we stored |
the number of groups |
practice we stored data |
we stored data and |
stored data and xor |
data and xor packets |
and xor packets in |
xor packets in double |
packets in double buffered |
in double buffered red |
double buffered red black |
buffered red black trees |
write performance was measured |
red black trees for |
performance was measured by |
was measured by observing |
measured by observing the |
mostly reads mostly writes |
by observing the latency |
reads mostly writes heavy |
observing the latency of |
mostly writes heavy load |
the latency of simultaneous |
writes heavy load store |
latency of simultaneous commits |
heavy load store overhead |
of simultaneous commits from |
load store overhead priorities |
simultaneous commits from different |
store overhead priorities uniform |
commits from different clients |
all groups have the |
overhead priorities uniform priorities |
groups have the same |
priorities uniform priorities uniform |
have the same subscribers |
uniform priorities uniform synchronous |
since simultaneous commits to |
priorities uniform synchronous asynchronous |
simultaneous commits to a |
uniform synchronous asynchronous figure |
commits to a single |
to a single repository |
a single repository would |
entries this occupies around |
single repository would not |
repository would not be |
would not be a |
not be a typical |
be a typical case |
graphs of ntfs traces |
each trace ran with |
trace ran with synchronous |
ran with synchronous or |
with synchronous or asynchronous |
synchronous or asynchronous writes |
or asynchronous writes and |
asynchronous writes and uniform |
writes and uniform or |
the repair bins in |
the key insight is |
repair bins in the |
and uniform or differentiated |
key insight is that |
bins in the layered |
uniform or differentiated priorities |
insight is that all |
in the layered interleaving |
is that all these |
vn repositories were used |
the layered interleaving scheme |
the total height of |
that all these effects |
layered interleaving scheme store |
all sharing the same |
all these effects originate |
total height of each |
interleaving scheme store incrementally |
sharing the same set |
these effects originate at |
height of each bar |
scheme store incrementally computed |
the same set of |
effects originate at the |
of each bar denotes |
store incrementally computed xors |
same set of front |
originate at the sender |
at the sender node |
incrementally computed xors and |
each bar denotes the |
computed xors and lists |
bar denotes the time |
end servers and same |
xors and lists of |
which is more loaded |
denotes the time from |
servers and same set |
and lists of data |
is more loaded and |
the time from the |
and same set of |
lists of data packet |
more loaded and less |
time from the first |
same set of three |
of data packet headers |
loaded and less responsive |
from the first to |
set of three zookeeper |
the first to last |
of three zookeeper servers |
first to last write |
without the data packet |
the data packet payloads |
each client checked out |
detailed analysis of the |
client checked out a |
resulting in low storage |
analysis of the captured |
and the shaded portion |
checked out a random |
in low storage overheads |
of the captured network |
the shaded portion denotes |
out a random repository |
low storage overheads for |
the captured network traffic |
shaded portion denotes the |
a random repository from |
storage overheads for each |
captured network traffic shows |
portion denotes the time |
random repository from a |
overheads for each layer |
network traffic shows that |
denotes the time from |
repository from a random |
from a random front |
traffic shows that the |
the time from the |
for each layer that |
shows that the multicast |
time from the first |
each layer that rise |
that the multicast stream |
from the first to |
and then repeatedly committed |
the multicast stream in |
layer that rise linearly |
the first to last |
first to last read |
multicast stream in all |
that rise linearly with |
then repeatedly committed small |
stream in all cases |
rise linearly with the |
repeatedly committed small amounts |
in all cases looks |
the white portions denote |
linearly with the value |
committed small amounts of |
all cases looks basically |
white portions denote the |
with the value of |
small amounts of data |
cases looks basically identical |
portions denote the extra |
the value of the |
denote the extra time |
value of the interleave |
changes were propgated in |
the extra time required |
and hence we cannot |
were propgated in the |
extra time required to |
hence we cannot attribute |
propgated in the background |
the memory footprint for |
time required to complete |
we cannot attribute token |
in the background to |
memory footprint for a |
required to complete all |
cannot attribute token latency |
the background to the |
footprint for a longrunning |
to complete all writes |
attribute token latency or |
background to the other |
to the other front |
complete all writes after |
token latency or losses |
for a longrunning proxy |
all writes after the |
latency or losses to |
a longrunning proxy was |
writes after the last |
or losses to the |
longrunning proxy was around |
after the last read |
losses to the increased |
the last read has |
to the increased volume |
last read has finished |
the increased volume of |
increased volume of traffic |
mb in our experiments |
shows that adding front |
throughput spikes or longer |
spikes or longer bursts |
or longer bursts of |
longer bursts of data |
for asynchronous writeback with |
asynchronous writeback with priorities |
end servers can indeed |
writeback with priorities in |
servers can indeed alleviate |
other performance enhancing roles |
with priorities in the |
performance enhancing roles maelstrom |
the sender spends more |
enhancing roles maelstrom appliances |
can indeed alleviate latency |
sender spends more time |
roles maelstrom appliances can |
indeed alleviate latency problems |
spends more time transmitting |
maelstrom appliances can optionally |
alleviate latency problems caused |
more time transmitting at |
appliances can optionally aggregate |
latency problems caused by |
time transmitting at lower |
can optionally aggregate small |
problems caused by high |
transmitting at lower rates |
optionally aggregate small subkilobyte |
caused by high load |
this shows that the |
aggregate small subkilobyte packets |
shows that the total |
but doesn t produce |
small subkilobyte packets from |
that the total duration |
and that the overhead |
doesn t produce any |
subkilobyte packets from different |
the total duration of |
that the overhead of |
t produce any faster |
packets from different flows |
total duration of the |
the overhead of propagating |
produce any faster data |
from different flows into |
duration of the trace |
overhead of propagating data |
any faster data bursts |
different flows into larger |
of the trace with |
of propagating data in |
faster data bursts than |
flows into larger ones |
the trace with this |
propagating data in the |
data bursts than those |
into larger ones for |
trace with this mfs |
data in the backgound |
bursts than those we |
larger ones for better |
with this mfs configuration |
in the backgound is |
than those we observe |
ones for better communication |
this mfs configuration is |
the backgound is not |
those we observe with |
for better communication efficiency |
backgound is not significant |
we observe with smaller |
better communication efficiency over |
is not significant enough |
observe with smaller numbers |
communication efficiency over the |
not significant enough to |
with smaller numbers of |
efficiency over the long |
significant enough to negatively |
smaller numbers of groups |
enough to negatively affect |
to negatively affect performance |
but all the fetch |
all the fetch traffic |
the fetch traffic is |
fetch traffic is completed |
traffic is completed within |
r elated w orks |
in split flow control |
elated w orks moving |
split flow control mode |
w orks moving services |
flow control mode they |
orks moving services to |
control mode they can |
moving services to the |
mode they can perform |
services to the cloud |
they can perform send |
receiver performance indicators such |
to the cloud has |
performance indicators such as |
seconds of the start |
side buffering of in |
indicators such as delays |
the cloud has been |
such as delays in |
cloud has been published |
flight data for multi |
this is a significant |
as delays in firing |
has been published on |
is a significant improvement |
gigabyte flows that exceed |
been published on in |
delays in firing timer |
a significant improvement over |
flows that exceed the |
published on in other |
on in other contexts |
significant improvement over the |
that exceed the sending |
in firing timer event |
improvement over the alternative |
exceed the sending end |
firing timer event or |
over the alternative configurations |
timer event or cpu |
the alternative configurations measured |
event or cpu utilization |
host s buffering capacity |
or cpu utilization don |
cpu utilization don t |
utilization don t show |
don t show any |
t show any noticeable |
show any noticeable trend |
is a backup application |
a backup application that |
backup application that implements |
application that implements a |
maelstrom appliances can act |
that implements a custom |
appliances can act as |
implements a custom block |
can act as multicast |
all roads lead back |
act as multicast forwarding |
seconds of the trace |
roads lead back to |
as multicast forwarding nodes |
based file system to |
of the trace are |
lead back to the |
back to the sender |
the trace are taken |
file system to store |
appliances send multicast packets |
trace are taken up |
system to store multiple |
send multicast packets to |
are taken up by |
and the main thing |
to store multiple versions |
multicast packets to each |
taken up by asynchronously |
the main thing going |
store multiple versions of |
packets to each other |
up by asynchronously writing |
main thing going on |
multiple versions of backup |
to each other across |
by asynchronously writing back |
thing going on in |
versions of backup data |
each other across the |
asynchronously writing back file |
going on in the |
of backup data on |
backup data on s |
writing back file updates |
on in the sender |
other across the long |
in the sender is |
the sender is that |
sender is that it |
in all cases the |
is that it has |
all cases the traces |
that it has a |
the authors make the |
cases the traces take |
it has a steadily |
authors make the distinction |
and use ip multicast |
the traces take significantly |
has a steadily growing |
make the distinction between |
traces take significantly longer |
a steadily growing memory |
the distinction between thin |
take significantly longer than |
steadily growing memory footprint |
significantly longer than they |
longer than they originally |
than they originally did |
clouds that provide a |
that provide a low |
we also looked at |
they originally did in |
also looked at token |
to spread them within |
originally did in ntfs |
looked at token round |
spread them within their |
level api and thick |
them within their data |
within their data centers |
where they were mostly |
they were mostly accessing |
were mostly accessing the |
clouds that are designed |
mostly accessing the local |
that are designed for |
the distribution of token |
accessing the local file |
appliances can take on |
distribution of token roundtrip |
are designed for a |
the local file system |
can take on other |
of token roundtrip times |
designed for a specific |
local file system and |
take on other existing |
token roundtrip times for |
for a specific application |
file system and therefore |
on other existing roles |
roundtrip times for different |
system and therefore had |
other existing roles in |
times for different numbers |
and therefore had no |
thick clouds for a |
existing roles in the |
for different numbers of |
therefore had no bandwidth |
clouds for a variety |
roles in the data |
in the data center |
had no bandwidth constraints |
for a variety of |
different numbers of groups |
a variety of purposes |
numbers of groups shows |
acting as security and |
of groups shows an |
the results largely repeat |
as security and vpn |
groups shows an increase |
including backup and source |
results largely repeat those |
security and vpn gateways |
shows an increase of |
backup and source code |
largely repeat those seen |
and vpn gateways and |
an increase of the |
and source code repository |
repeat those seen in |
vpn gateways and as |
increase of the token |
source code repository hosting |
those seen in the |
gateways and as conventional |
of the token roundtrip |
seen in the microbenchmarks |
and as conventional performance |
the token roundtrip time |
as conventional performance enhancing |
conventional performance enhancing proxies |
with sourceforge and google |
to the extent that |
sourceforge and google code |
caused almost entirely by |
the extent that the |
and google code being |
extent that the greatest |
google code being examples |
that the greatest performance |
code being examples of |
the greatest performance improvements |
being examples of the |
greatest performance improvements are |
examples of the latter |
performance improvements are seen |
improvements are seen at |
of the tokens that |
are seen at low |
the tokens that are |
seen at low bandwidth |
the authors of cumulus |
tokens that are delayed |
at low bandwidth when |
authors of cumulus and |
that are delayed the |
low bandwidth when there |
of cumulus and we |
are delayed the most |
bandwidth when there is |
cumulus and we show |
when there is high |
there is high read |
e valuation we evaluated |
and we show that |
we show that thin |
valuation we evaluated maelstrom |
we evaluated maelstrom on |
evaluated maelstrom on the |
maelstrom on the emulab |
on the emulab testbed |
cloud solutions can be |
the emulab testbed at |
solutions can be a |
can be a cost |
emulab testbed at utah |
such as in the |
as in the mostly |
which points to disruptive |
points to disruptive events |
to disruptive events as |
writes trace where there |
another example of moving |
disruptive events as the |
trace where there is |
example of moving a |
events as the culprit |
where there is an |
of moving a service |
moving a service to |
a service to the |
service to the cloud |
to the cloud is |
rather than a uniform |
the cloud is metacdn |
than a uniform increase |
for all the experiments |
a uniform increase of |
uniform increase of the |
increase of the token |
of the token processing |
the token processing overhead |
decrease in the time |
we used a dumbbell |
in the time spent |
used a dumbbell topology |
the time spent to |
a dumbbell topology of |
time spent to read |
dumbbell topology of two |
spent to read all |
a content distribution network |
topology of two clusters |
to read all the |
we find that these |
of two clusters of |
read all the files |
find that these tokens |
two clusters of nodes |
the work evaluates the |
that these tokens were |
work evaluates the latency |
clusters of nodes connected |
these tokens were most |
evaluates the latency of |
of nodes connected via |
tokens were most commonly |
even at the higher |
the latency of various |
nodes connected via routing |
were most commonly delayed |
at the higher bandwidth |
latency of various cloud |
connected via routing nodes |
most commonly delayed on |
the higher bandwidth of |
of various cloud storage |
via routing nodes with |
commonly delayed on the |
various cloud storage services |
routing nodes with a |
nodes with a high |
cloud storage services from |
delayed on the sender |
storage services from several |
services from several locations |
latency link in between |
link in between them |
from several locations and |
with many thousands of |
several locations and provides |
many thousands of groups |
locations and provides an |
designed to emulate the |
and provides an abstraction |
to emulate the setup |
there is a decrease |
is a decrease of |
emulate the setup in |
the average time to |
provides an abstraction to |
the setup in figure |
average time to travel |
an abstraction to integrate |
time to travel by |
abstraction to integrate the |
to travel by one |
to integrate the different |
travel by one hop |
integrate the different offerings |
and ran the proxy |
by one hop from |
the different offerings into |
ran the proxy code |
the mostlyreads trace is |
different offerings into a |
one hop from sender |
the proxy code on |
mostlyreads trace is not |
offerings into a single |
into a single system |
proxy code on the |
trace is not much |
hop from sender to |
code on the routers |
is not much affected |
from sender to receiver |
not much affected by |
sender to receiver or |
much affected by changes |
to receiver or receiver |
affected by changes in |
receiver or receiver to |
by changes in the |
or receiver to sender |
changes in the configuration |
receiver to sender can |
to sender can grow |
sender can grow to |
can grow to nearly |
like transactional data store |
although there is a |
transactional data store backed |
there is a slight |
data store backed by |
store backed by s |
is a slight decrease |
show the performance of |
a slight decrease in |
the performance of the |
slight decrease in both |
performance of the kernel |
decrease in both read |
of the kernel version |
and faced similar issues |
in both read and |
the kernel version at |
faced similar issues as |
both read and write |
kernel version at gigabit |
similar issues as s |
read and write times |
version at gigabit speeds |
as compared to an |
and write times for |
vn due to its |
compared to an average |
write times for prioritised |
due to its need |
the remainder of the |
times for prioritised asynchronous |
ms per hop from |
remainder of the graphs |
to its need for |
for prioritised asynchronous writeback |
per hop from receiver |
of the graphs show |
its need for high |
hop from receiver to |
the graphs show the |
need for high consistency |
from receiver to receiver |
graphs show the performance |
show the performance of |
the performance of the |
performance of the user |
elastras assigns update priviledges |
assigns update priviledges for |
update priviledges for different |
priviledges for different areas |
space version at slower |
version at slower speeds |
for different areas of |
different areas of the |
areas of the data |
of the data store |
the data store to |
data store to individual |
store to individual front |
to emulate the mtu |
the overloaded sender occasionally |
emulate the mtu difference |
overloaded sender occasionally releases |
the mtu difference between |
sender occasionally releases the |
load trace performs best |
mtu difference between the |
occasionally releases the tokens |
trace performs best with |
difference between the long |
using the lock service |
releases the tokens with |
performs best with uniform |
the lock service to |
the tokens with a |
tokens with a delay |
haul link and the |
lock service to elect |
best with uniform asynchronous |
link and the data |
service to elect an |
with uniform asynchronous writeback |
and the data center |
to elect an owner |
the data center network |
elect an owner for |
an owner for each |
we once again attribute |
owner for each partition |
once again attribute this |
again attribute this to |
attribute this to inefficiency |
this to inefficiency in |
to inefficiency in the |
inefficiency in the rpc |
in the rpc protocol |
much in the style |
in the style described |
the style described by |
we set an mtu |
set an mtu of |
style described by google |
since under extremely heavy |
described by google s |
under extremely heavy load |
by google s chubby |
the value of the |
extremely heavy load and |
value of the delay |
heavy load and high |
of the delay grows |
load and high bandwidth |
the delay grows with |
and high bandwidth it |
delay grows with the |
high bandwidth it performs |
bytes on the network |
grows with the number |
bandwidth it performs better |
on the network connecting |
with the number of |
it performs better when |
the network connecting the |
the number of groups |
performs better when all |
network connecting the end |
a lock service based |
better when all messages |
lock service based on |
when all messages have |
service based on paxos |
all messages have the |
hosts to the proxy |
messages have the same |
to the proxy and |
have the same priority |
the proxy and an |
proxy and an mtu |
and an mtu of |
our old culprit is |
old culprit is back |
a file group is |
file group is implemented |
group is implemented as |
defers finegrained locking to |
is implemented as a |
finegrained locking to the |
implemented as a special |
locking to the application |
as a special type |
bytes on the long |
to the application in |
related costs at the |
costs at the sender |
the application in order |
a special type of |
haul link between proxies |
application in order not |
special type of file |
in order not to |
type of file within |
order not to burden |
increasing the number of |
of file within the |
the only exception is |
not to burden the |
the number of groups |
file within the mfs |
only exception is figure |
to burden the global |
number of groups slows |
within the mfs file |
the mfs file system |
of groups slows the |
burden the global lock |
groups slows the sender |
the global lock service |
global lock service with |
with its own file |
lock service with high |
its own file identifier |
and this cascades to |
service with high traffic |
where we maintained equal |
this cascades to create |
we maintained equal mtus |
but not attached to |
cascades to create all |
maintained equal mtus of |
not attached to any |
to create all sorts |
vn we opted to |
attached to any specific |
create all sorts of |
we opted to use |
to any specific directory |
all sorts of downstream |
opted to use the |
sorts of downstream problems |
to use the lock |
of downstream problems that |
use the lock service |
the file group a |
downstream problems that can |
file group a file |
problems that can destabilize |
group a file belongs |
a file belongs to |
bytes on both links |
that can destabilize the |
can destabilize the system |
destabilize the system as |
the system as a |
system as a whole |
grained locking instead of |
locking instead of just |
instead of just leader |
of just leader election |
is one of its |
one of its attributes |
all the experiments are |
the experiments are done |
experiments are done with |
discussion the experiments just |
since the latter would |
the mfs prefetching subsystem |
the experiments just reported |
are done with maelstrom |
the latter would have |
mfs prefetching subsystem derives |
experiments just reported make |
done with maelstrom using |
latter would have required |
prefetching subsystem derives much |
just reported make it |
with maelstrom using end |
would have required duplicating |
subsystem derives much of |
reported make it clear |
have required duplicating much |
derives much of its |
make it clear that |
required duplicating much of |
much of its effectiveness |
it clear that the |
duplicating much of zookeeper |
of its effectiveness from |
clear that the performance |
much of zookeeper s |
its effectiveness from being |
of zookeeper s functionality |
effectiveness from being combined |
zookeeper s functionality to |
limiting factor in the |
from being combined with |
s functionality to replicate |
factor in the qsm |
being combined with prioritised |
functionality to replicate the |
in the qsm system |
combined with prioritised rpcs |
to replicate the leader |
the qsm system is |
qsm system is latency |
replicate the leader s |
the leader s state |
while the prefetching algorithm |
the prefetching algorithm in |
prefetching algorithm in mfs |
algorithm in mfs is |
in mfs is straightforward |
and that in addition |
which illustrates the performance |
scalability is not an |
that in addition to |
illustrates the performance of |
it can still make |
in addition to protocol |
is not an obstacle |
the performance of split |
can still make bad |
addition to protocol factors |
not an obstacle because |
performance of split mode |
still make bad decisions |
to protocol factors such |
an obstacle because there |
of split mode flow |
split mode flow control |
protocol factors such as |
obstacle because there is |
make bad decisions without |
factors such as the |
because there is no |
bad decisions without a |
such as the length |
there is no need |
decisions without a large |
as the length of |
is no need for |
without a large overall |
the length of token |
no need for global |
a large overall performance |
length of token rings |
need for global locking |
large overall performance penalty |
for global locking across |
overall performance penalty because |
global locking across multiple |
latency is strongly influenced |
performance penalty because the |
show that commodity tcp |
is strongly influenced by |
locking across multiple repositories |
penalty because the interference |
strongly influenced by the |
ip throughput collapses in |
because the interference of |
influenced by the memory |
throughput collapses in the |
the interference of prefetching |
the load can be |
by the memory footprint |
collapses in the presence |
interference of prefetching with |
load can be partitioned |
the memory footprint of |
in the presence of |
the presence of non |
can be partitioned across |
memory footprint of the |
of prefetching with other |
be partitioned across as |
footprint of the system |
prefetching with other file |
partitioned across as many |
with other file system |
across as many zookeeper |
and that maelstrom successfully |
other file system activity |
as many zookeeper instances |
that maelstrom successfully masks |
file system activity is |
many zookeeper instances as |
when we built the |
maelstrom successfully masks loss |
system activity is minimised |
zookeeper instances as necessary |
we built the system |
successfully masks loss and |
built the system it |
masks loss and prevents |
in the same way |
the system it was |
loss and prevents this |
replication is not without |
the same way that |
system it was obvious |
and prevents this collapse |
is not without its |
same way that some |
it was obvious that |
prevents this collapse from |
not without its dangers |
way that some local |
was obvious that minimizing |
this collapse from occurring |
that some local file |
obvious that minimizing latency |
some local file systems |
that minimizing latency would |
local file systems execute |
minimizing latency would be |
file systems execute speculative |
latency would be important |
systems execute speculative operations |
execute speculative operations to |
speculative operations to improve |
operations to improve performance |
shows the performance of |
and it has been |
this motivated several of |
the performance of the |
it has been shown |
motivated several of the |
performance of the userspace |
has been shown that |
several of the design |
of the userspace version |
been shown that replicating |
of the design decisions |
the userspace version on |
shown that replicating too |
the design decisions discussed |
userspace version on a |
mfs makes use of |
design decisions discussed in |
that replicating too eagerly |
makes use of the |
decisions discussed in section |
replicating too eagerly leads |
use of the speculative |
too eagerly leads quickly |
of the speculative communication |
eagerly leads quickly to |
the speculative communication of |
leads quickly to degraded |
mbps link and figure |
speculative communication of prioritised |
quickly to degraded performance |
but the repeated linkage |
communication of prioritised rpcs |
the repeated linkage of |
of prioritised rpcs in |
repeated linkage of latency |
the solution proposed is |
prioritised rpcs in the |
shows the kernel version |
linkage of latency and |
solution proposed is to |
rpcs in the hope |
the kernel version on |
of latency and oscillatory |
proposed is to use |
in the hope of |
kernel version on a |
latency and oscillatory throughputs |
is to use master |
the hope of achieving |
and oscillatory throughputs to |
to use master copy |
hope of achieving a |
oscillatory throughputs to memory |
use master copy replication |
the experiment in each |
throughputs to memory was |
of achieving a benefit |
experiment in each case |
to memory was a |
achieving a benefit through |
in each case involves |
where a transaction does |
memory was a surprise |
a benefit through prefetching |
each case involves running |
a transaction does not |
benefit through prefetching files |
we expected a much |
transaction does not immediately |
case involves running iperf |
expected a much smaller |
does not immediately update |
a much smaller impact |
not immediately update all |
immediately update all replicas |
we can summarize our |
can summarize our design |
summarize our design insights |
our design insights as |
design insights as follows |
mfs prefetching implementation the |
prefetching implementation the mfs |
implementation the mfs cache |
flows from one node |
the mfs cache manager |
as the master copy |
from one node to |
mfs cache manager incorporates |
one node to another |
cache manager incorporates a |
and only the lock |
only the lock service |
node to another across |
manager incorporates a small |
minimize the memory footprint |
to another across the |
which deals with simple |
incorporates a small prefetching |
another across the long |
a small prefetching module |
we expected that the |
expected that the primary |
that the primary cost |
the primary cost of |
distance link with and |
bandwidth operations that may |
primary cost of managed |
which can be optionally |
link with and without |
operations that may be |
cost of managed memory |
can be optionally enabled |
with and without intermediary |
that may be concentrated |
of managed memory would |
be optionally enabled at |
and without intermediary maelstrom |
may be concentrated on |
managed memory would be |
optionally enabled at start |
without intermediary maelstrom proxies |
be concentrated on a |
memory would be associated |
intermediary maelstrom proxies and |
concentrated on a small |
would be associated with |
maelstrom proxies and measuring |
on a small number |
when it is initialised |
proxies and measuring obtained |
be associated with garbage |
a small number of |
and measuring obtained throughput |
associated with garbage collection |
small number of servers |
measuring obtained throughput while |
a prefetching thread starts |
obtained throughput while varying |
prefetching thread starts and |
must be eagerly replicated |
throughput while varying loss |
thread starts and initiates |
while varying loss rate |
all costs associated with |
also relevant is sundr |
starts and initiates prefetch |
costs associated with managed |
and initiates prefetch requests |
left graph on each |
the secure untrusted data |
initiates prefetch requests in |
graph on each figure |
associated with managed memory |
secure untrusted data repository |
prefetch requests in parallel |
with managed memory rise |
requests in parallel with |
managed memory rise in |
in parallel with the |
memory rise in the |
parallel with the main |
rise in the amount |
with the main activity |
in the amount of |
the main activity of |
the amount of allocated |
main activity of the |
amount of allocated memory |
activity of the cache |
of the cache manager |
the error bars on |
at least in the |
this file system allows |
error bars on the |
least in the windows |
the core component of |
file system allows clients |
bars on the graphs |
in the windows clr |
core component of the |
system allows clients to |
on the graphs to |
component of the cache |
allows clients to detect |
the graphs to the |
of the cache manager |
clients to detect against |
graphs to the left |
the cache manager alerts |
to detect against malicious |
to the left are |
cache manager alerts the |
detect against malicious or |
the left are standard |
manager alerts the prefetching |
against malicious or compromised |
left are standard errors |
alerts the prefetching module |
malicious or compromised storage |
are standard errors of |
the prefetching module every |
or compromised storage servers |
standard errors of the |
prefetching module every time |
whereas traditional multicast systems |
compromised storage servers or |
errors of the throughput |
module every time an |
traditional multicast systems accept |
storage servers or hosting |
of the throughput over |
every time an application |
multicast systems accept messages |
servers or hosting platforms |
the throughput over ten |
time an application reads |
systems accept messages whenever |
or hosting platforms by |
throughput over ten runs |
an application reads or |
accept messages whenever the |
hosting platforms by providing |
application reads or writes |
messages whenever the application |
platforms by providing fork |
reads or writes a |
or writes a file |
by providing fork consistency |
whenever the application layer |
the application layer or |
application layer or the |
layer or the multicast |
by calling the file |
ip s cache of |
or the multicast protocols |
calling the file access |
a property which ensures |
s cache of tuning |
the multicast protocols produce |
the file access routine |
property which ensures that |
cache of tuning parameters |
multicast protocols produce it |
which ensures that clients |
of tuning parameters to |
ensures that clients can |
this routine checks whether |
qsm uses an upcall |
that clients can detect |
tuning parameters to allow |
routine checks whether the |
clients can detect integrity |
parameters to allow for |
checks whether the file |
can detect integrity failures |
to allow for repeatable |
often we can delay |
detect integrity failures as |
whether the file belongs |
allow for repeatable results |
we can delay generating |
integrity failures as long |
the file belongs to |
can delay generating a |
failures as long as |
file belongs to a |
delay generating a message |
the clients in the |
as long as they |
belongs to a file |
generating a message until |
clients in the experiment |
long as they see |
to a file group |
a message until the |
in the experiment are |
as they see each |
a file group if |
message until the last |
the experiment are running |
experiment are running tcp |
file group if not |
until the last minute |
they see each other |
see each other s |
each other s file |
ip reno on a |
other s file modifications |
reno on a linux |
the access is ignored |
and we can also |
we can also avoid |
can also avoid situations |
similar techniques could be |
also avoid situations in |
techniques could be used |
avoid situations in which |
could be used to |
situations in which data |
prefetching it is a |
be used to recover |
in which data piles |
it is a member |
used to recover data |
which data piles up |
is a member of |
to recover data from |
data piles up on |
a member of a |
recover data from client |
piles up on behalf |
member of a file |
data from client working |
up on behalf of |
of a file group |
from client working copies |
on behalf of an |
the maelstrom parameters used |
client working copies in |
behalf of an aggressive |
maelstrom parameters used are |
working copies in the |
the group is put |
of an aggressive sender |
parameters used are r |
copies in the event |
group is put at |
in the event of |
is put at the |
the event of a |
put at the head |
event of a catastrophic |
at the head of |
of a catastrophic cloud |
the head of the |
a catastrophic cloud failure |
head of the prefetch |
of the prefetch list |
limit buffering and caching |
once code repositories are |
code repositories are stored |
repositories are stored in |
the prefetch thread periodically |
are stored in the |
most existing multicast protocols |
prefetch thread periodically examines |
stored in the cloud |
existing multicast protocols buffer |
thread periodically examines the |
multicast protocols buffer data |
periodically examines the prefetching |
protocols buffer data at |
one might imagine enabling |
examines the prefetching is |
buffer data at many |
might imagine enabling mashups |
the prefetching is commonly |
data at many layers |
imagine enabling mashups in |
prefetching is commonly used |
at many layers and |
enabling mashups in ways |
is commonly used to |
many layers and cache |
mashups in ways not |
commonly used to improve |
layers and cache data |
in ways not previously |
used to improve the |
and cache data rather |
ways not previously possible |
to improve the performance |
cache data rather casually |
improve the performance of |
data rather casually for |
the performance of lo |
rather casually for recovery |
casually for recovery purposes |
web based code viewers |
group at the head |
at the head of |
the head of the |
head of the list |
this turns out to |
turns out to be |
out to be extremely |
to be extremely costly |
be extremely costly in |
and cross reference viewers |
if the group file |
extremely costly in a |
space version involved running |
the group file for |
cross reference viewers might |
costly in a managed |
version involved running a |
group file for the |
reference viewers might be |
in a managed setting |
involved running a single |
file for the group |
viewers might be built |
a managed setting and |
for the group is |
might be built by |
managed setting and must |
the group is cal |
be built by third |
setting and must be |
second iperf flow from |
group is cal file |
iperf flow from one |
is cal file systems |
flow from one node |
and must be avoided |
from one node to |
must be avoided whenever |
one node to another |
be avoided whenever possible |
node to another with |
as well as distributed |
pulling data from the |
to another with and |
well as distributed file |
data from the repositories |
another with and without |
as distributed file systems |
from the repositories of |
with and without maelstrom |
the repositories of several |
and without maelstrom running |
repositories of several distinct |
without maelstrom running on |
of several distinct communities |
maelstrom running on the |
not in the cache |
running on the routers |
cumulative distribution of the |
on the routers and |
distribution of the multicast |
the routers and measuring |
of the multicast rates |
it retrieves it from |
routers and measuring throughput |
the multicast rates for |
retrieves it from the |
it from the server |
and measuring throughput while |
measuring throughput while varying |
throughput while varying the |
while varying the random |
varying the random loss |
then it scans the |
the random loss rate |
it scans the in |
seeks to enable such |
random loss rate on |
scans the in a |
to enable such applications |
loss rate on the |
the in a file |
enable such applications by |
rate on the link |
in a file system |
such applications by granting |
on the link and |
a file system with |
applications by granting direct |
the link and the |
file system with whole |
token roundtrip times for |
by granting direct access |
link and the oneway |
granting direct access of |
and the oneway latency |
direct access of cloud |
access of cloud storage |
of cloud storage to |
cloud storage to third |
storage to third parties |
a mechanism is required |
to test the kernel |
mechanism is required files |
test the kernel version |
is required files in |
the kernel version at |
subject to the data |
required files in the |
kernel version at gigabit |
version at gigabit speeds |
files in the group |
to the data owner |
in the group in |
the data owner s |
the group in order |
data owner s security |
we ran eight parallel |
group in order until |
owner s security requirements |
ran eight parallel iperf |
in order until it |
eight parallel iperf flows |
order until it finds |
parallel iperf flows from |
intervals between the subsequent |
a question that may |
until it finds the |
iperf flows from one |
between the subsequent tokens |
question that may naturally |
it finds the first |
flows from one node |
that may naturally arise |
finds the first one |
from one node to |
may naturally arise is |
the first one which |
one node to another |
first one which is |
node to another for |
one which is not |
why not use a |
which is not to |
not use a general |
is not to determine |
use a general purpose |
not to determine appropriate |
a general purpose file |
to determine appropriate prefetching |
general purpose file system |
determine appropriate prefetching hints |
purpose file system interface |
file system interface to |
system interface to s |
the curves obtained from |
earlier work in file |
curves obtained from the |
work in file in |
obtained from the two |
in file in the |
file in the cache |
from the two versions |
the two versions are |
two versions are almost |
versions are almost identical |
clear messages out of |
messages out of the |
out of the system |
of the system quickly |
and store a repository |
we present both to |
and issues a prefetch |
present both to show |
issues a prefetch request |
both to show that |
store a repository on |
a repository on that |
a prefetch request or |
to show that the |
data paths should have |
prefetch request or system |
this is indeed possible |
paths should have rapid |
show that the kernel |
request or system prefetching |
is indeed possible to |
indeed possible to do |
that the kernel version |
or system prefetching has |
should have rapid data |
the kernel version successfully |
system prefetching has used |
have rapid data movement |
but would entail pushing |
kernel version successfully scales |
prefetching has used clustering |
rapid data movement as |
would entail pushing temporary |
version successfully scales up |
has used clustering to |
data movement as a |
entail pushing temporary files |
successfully scales up the |
used clustering to derive |
movement as a key |
as a key goal |
scales up the performance |
clustering to derive file |
pushing temporary files such |
up the performance of |
to derive file groups |
temporary files such as |
the performance of the |
derive file groups from |
files such as transactions |
performance of the userspace |
file groups from validation |
of the userspace version |
groups from validation request |
the userspace version to |
from validation request for |
userspace version to hundreds |
validation request for it |
and incurring additional monetary |
version to hundreds of |
we ve already mentioned |
incurring additional monetary costs |
to hundreds of megabits |
ve already mentioned that |
additional monetary costs due |
if all the files |
hundreds of megabits of |
already mentioned that data |
monetary costs due to |
all the files are |
of megabits of traffic |
mentioned that data paths |
costs due to the |
the files are valid |
megabits of traffic per |
of traffic per second |
due to the increased |
files are valid and |
that data paths should |
to the increased number |
are valid and are |
data paths should clear |
the increased number of |
valid and are in |
paths should clear messages |
increased number of s |
and are in the |
should clear messages quickly |
are in the cache |
in the cache access |
the cache access statistics |
but there are other |
there are other important |
are other important forms |
there would also likely |
other important forms of |
important forms of delay |
would also likely be |
also likely be performance |
likely be performance problems |
since file append and |
file append and rename |
most situations in which |
append and rename operations |
situations in which qsm |
and rename operations do |
in which qsm developed |
rename operations do not |
which qsm developed convoy |
predicted future file accesses |
operations do not map |
future file accesses from |
we show how tcp |
do not map efficiently |
file accesses from cache |
like behavior or oscillatory |
not map efficiently to |
map efficiently to s |
behavior or oscillatory throughput |
the group is moved |
or oscillatory throughput can |
ip performance degrades on |
group is moved to |
oscillatory throughput can be |
performance degrades on a |
is moved to the |
throughput can be traced |
moved to the end |
can be traced to |
to the end of |
be traced to design |
the end of the |
traced to design decisions |
end of the prefetch |
of the prefetch list |
fs that is aware |
ms link as the |
to design decisions that |
that is aware of |
link as the loss |
is aware of subversion |
design decisions that caused |
as the loss rate |
aware of subversion s |
decisions that caused scheduling |
the loss rate is |
of subversion s file |
that caused scheduling jitter |
loss rate is increased |
subversion s file naming |
caused scheduling jitter or |
rate is increased from |
s file naming and |
scheduling jitter or allowed |
file naming and use |
or allowed applications to |
jitter or allowed some |
naming and use scenario |
allowed applications to specify |
or allowed some form |
and use scenario could |
applications to specify prefetch |
allowed some form of |
use scenario could of |
some form of priority |
scenario could of course |
form of priority inversion |
could of course overcome |
of priority inversion to |
of course overcome these |
priority inversion to occur |
course overcome these limitations |
the thread rechecks the |
overcome these limitations by |
thread rechecks the head |
these limitations by pushing |
rechecks the head of |
delaying a crucial message |
limitations by pushing only |
the head of the |
a crucial message behind |
by pushing only what |
head of the list |
crucial message behind a |
pushing only what is |
of the list ing |
message behind a less |
only what is actually |
the list ing hints |
behind a less important |
what is actually required |
is actually required into |
list ing hints explicitly |
a less important one |
maelstrom masks loss up |
masks loss up to |
actually required into s |
implications included the following |
without significant throughput degradation |
but we believe that |
we believe that such |
believe that such specialized |
that such specialized tools |
with the kernel version |
such specialized tools are |
the kernel version achieving |
specialized tools are better |
kernel version achieving two |
event handlers should be |
handlers should be short |
version achieving two orders |
tools are better built |
achieving two orders of |
are better built on |
two orders of magnitude |
better built on top |
orders of magnitude higher |
built on top of |
of magnitude higher throughput |
to find the next |
on top of a |
magnitude higher throughput that |
find the next file |
we struggled to make |
higher throughput that conventional |
struggled to make the |
the next file to |
to make the overall |
throughput that conventional tcp |
make the overall behavior |
next file to prefetch |
the overall behavior of |
top of a file |
overall behavior of the |
of a file system |
behavior of the system |
a new group may |
of the system as |
a file system abstraction |
new group may now |
the system as predictable |
file system abstraction than |
group may now be |
system as predictable as |
system abstraction than pushed |
may now be at |
the graphs on the |
abstraction than pushed underneath |
than pushed underneath it |
now be at the |
graphs on the right |
as predictable as possible |
be at the inter |
on the right side |
predictable as possible not |
the right side of |
as possible not a |
right side of figures |
file dependencies can also |
c onclusion we have |
possible not a trivial |
dependencies can also be |
onclusion we have shown |
not a trivial task |
can also be used |
we have shown that |
a trivial task in |
also be used as |
have shown that the |
trivial task in configurations |
be used as a |
shown that the cost |
task in configurations where |
used as a source |
that the cost of |
in configurations where hundreds |
as a source of |
the cost of using |
configurations where hundreds of |
a source of hints |
ip throughput declining on |
cost of using a |
where hundreds of processes |
throughput declining on a |
of using a cloud |
hundreds of processes might |
head of the list |
declining on a link |
using a cloud computing |
of processes might be |
of the list as |
on a link of |
a cloud computing storage |
processes might be multicasting |
the list as a |
a link of increasing |
cloud computing storage service |
might be multicasting in |
list as a result |
link of increasing length |
computing storage service for |
be multicasting in thousands |
as a result of |
of increasing length when |
storage service for source |
multicasting in thousands of |
a result of further |
increasing length when subjected |
service for source code |
in thousands of overlapping |
result of further application |
length when subjected to |
for source code repository |
thousands of overlapping groups |
of further application accesses |
when subjected to uniform |
source code repository hosting |
further application accesses to |
subjected to uniform loss |
code repository hosting is |
application accesses to files |
to uniform loss rates |
by keeping event handlers |
repository hosting is low |
uniform loss rates of |
keeping event handlers short |
event handlers short and |
handlers short and predictable |
short and predictable and |
both for individual projects |
and predictable and eliminating |
it may be known |
for individual projects and |
predictable and eliminating the |
may be known that |
individual projects and moderately |
and eliminating the need |
be known that a |
projects and moderately sized |
eliminating the need for |
known that a certain |
and moderately sized communities |
the need for locking |
that a certain shared |
a certain shared library |
certain shared library is |
shared library is reprefetch |
considering the costs of |
library is reprefetch requests |
we obtained a more |
the costs of a |
is reprefetch requests are |
obtained a more predictable |
costs of a resilient |
the top line in |
reprefetch requests are similar |
a more predictable system |
of a resilient local |
top line in the |
requests are similar to |
more predictable system and |
a resilient local storage |
line in the graphs |
are similar to regular |
predictable system and were |
resilient local storage system |
in the graphs is |
similar to regular fetch |
system and were able |
local storage system of |
the graphs is the |
to regular fetch requests |
and were able to |
storage system of scsi |
graphs is the performance |
regular fetch requests for |
were able to eliminate |
system of scsi disks |
is the performance of |
fetch requests for files |
able to eliminate multithreading |
of scsi disks and |
the performance of tcp |
scsi disks and tape |
disks and tape backup |
quired to run a |
to run a text |
run a text editor |
with the associated context |
ip without loss and |
cloud computing is a |
the associated context switching |
without loss and provides |
in this case it |
associated context switching and |
this case it would |
loss and provides an |
case it would be |
context switching and locking |
computing is a very |
and provides an upper |
it would be advantageous |
switching and locking overheads |
would be advantageous with |
provides an upper bound |
is a very attractive |
be advantageous with the |
an upper bound for |
a very attractive solution |
advantageous with the exception |
upper bound for performance |
very attractive solution for |
with the exception that |
bound for performance on |
attractive solution for this |
the exception that they |
for performance on the |
solution for this application |
exception that they are |
performance on the link |
that they are issued |
they are issued at |
our implementation of s |
here we encounter a |
are issued at the |
we encounter a tension |
issued at the lowest |
encounter a tension between |
space and kernel versions |
at the lowest level |
vn brings this concept |
a tension between two |
the lowest level of |
brings this concept a |
tension between two goals |
maelstrom masks packet loss |
lowest level of prito |
this concept a step |
masks packet loss and |
from a memory footprint |
concept a step closer |
level of prito retrieve |
packet loss and tracks |
a memory footprint perspective |
a step closer to |
of prito retrieve the |
loss and tracks the |
step closer to becoming |
prito retrieve the shared |
and tracks the lossless |
closer to becoming reality |
one might prefer not |
retrieve the shared library |
tracks the lossless line |
the lossless line closely |
the shared library from |
might prefer not to |
and provides evidence that |
shared library from the |
prefer not to pull |
provides evidence that performance |
library from the server |
lagging only when the |
not to pull in |
evidence that performance will |
from the server as |
only when the link |
to pull in a |
that performance will be |
the server as well |
when the link latency |
pull in a message |
performance will be acceptable |
server as well as |
the link latency is |
in a message until |
will be acceptable for |
as well as retriev |
link latency is low |
a message until qsm |
be acceptable for typical |
latency is low and |
is low and tcp |
acceptable for typical use |
message until qsm can |
for typical use scenarios |
until qsm can process |
qsm can process it |
all other rpc traffic |
ip s throughput is |
other rpc traffic takes |
s throughput is very |
rpc traffic takes precedence |
throughput is very high |
but in a datacenter |
traffic takes precedence over |
in a datacenter or |
takes precedence over a |
a datacenter or cluster |
precedence over a prefetch |
over a prefetch rpc |
most message loss occurs |
message loss occurs in |
ing the text editor |
loss occurs in the |
the text editor executable |
occurs in the operating |
in the operating system |
not on the network |
technological impact of magnetic |
impact of magnetic hard |
hence message loss rates |
as shown in table |
of magnetic hard disk |
message loss rates soar |
magnetic hard disk drives |
loss rates soar if |
hard disk drives on |
rates soar if we |
disk drives on storage |
soar if we leave |
drives on storage systems |
if we leave messages |
we leave messages on |
leave messages on input |
messages on input sockets |
on input sockets for |
and only one tion |
input sockets for long |
only one tion such |
one tion such as |
tion such as the |
such as the operating |
as the operating system |
the operating system s |
operating system s database |
system s database of |
s database of installed |
database of installed software |
of installed software prefetch |
installed software prefetch is |
software prefetch is made |
prefetch is made at |
is made at a |
made at a time |
control the event processing |
the event processing order |
this is more a |
is more a matter |
more a matter of |
a matter of implementapackages |
specified dependency information tion |
dependency information tion convenience |
information tion convenience than |
tion convenience than a |
convenience than a design |
than a design decision |
other work has shown |
work has shown can |
has shown can be |
shown can be used |
and the imposition of |
the imposition of an |
imposition of an internal |
of an internal event |
an internal event processing |
internal event processing prioritization |
the benefits initiating multiple |
benefits initiating multiple concurrent |
initiating multiple concurrent prefetches |
multiple concurrent prefetches from |
small delays add up |
concurrent prefetches from differany |
delays add up in |
prefetches from differany of |
add up in large |
from differany of these |
up in large systems |
differany of these techniques |
of these techniques could |
these techniques could be |
techniques could be used |
could be used to |
tight control over event |
be used to derive |
control over event processing |
used to derive hints |
over event processing largely |
to derive hints for |
event processing largely eliminated |
derive hints for use |
processing largely eliminated convoy |
hints for use ent |
for use ent servers |
largely eliminated convoy effects |
eliminated convoy effects and |
convoy effects and oscillatory |
effects and oscillatory throughput |
and oscillatory throughput problems |
mfs does not currently |
act on fresh state |
does not currently make |
not currently make use |
currently make use of |
make use of timeouts |
use of timeouts by |
ip no loss maelstrom |
of timeouts by the |
many inefficiencies can be |
no loss maelstrom no |
timeouts by the mfs |
inefficiencies can be traced |
loss maelstrom no loss |
by the mfs prefetching |
the mfs prefetching subsystem |
maelstrom no loss maelstrom |
can be traced to |
be traced to situations |
traced to situations in |
our evaluation uses hand |
to situations in which |
situations in which one |
in which one node |
which one node takes |
one node takes action |
node takes action on |
takes action on the |
action on the basis |
on the basis of |
as we have noted |
the basis of stale |
we have noted earlier |
basis of stale state |
of stale state information |
stale state information from |
state information from some |
information from some other |
from some other node |
but it could easily |
it could easily to |
could easily to exspecified |
easily to exspecified dependency |
to exspecified dependency information |
triggering redundant retransmissions or |
redundant retransmissions or other |
retransmissions or other overheads |
which is inaccurate in |
is inaccurate in some |
inaccurate in some tended |
the pull architecture has |
in some tended to |
pull architecture has the |
some tended to abandon |
architecture has the secondary |
tended to abandon a |
has the secondary benefit |
to abandon a prefetching |
the secondary benefit of |
abandon a prefetching attempt |
secondary benefit of letting |
a prefetching attempt that |
benefit of letting us |
prefetching attempt that does |
of letting us delay |
attempt that does not |
letting us delay the |
that does not complete |
us delay the preparation |
does not complete cases |
delay the preparation of |
the preparation of status |
preparation of status packets |
of status packets until |
status packets until they |
packets until they are |
rather than reimplementing an |
until they are about |
than reimplementing an existing |
they are about to |
are about to be |
about to be transmitted |
reimplementing an existing hint |
generation in a timely |
in a timely manner |
conclusions the premise of |
the premise of our |
premise of our work |
of our work is |
our work is that |
we focus on the |
work is that developers |
focus on the performance |
is that developers of |
on the performance of |
that developers of services |
the performance of mfs |
developers of services intended |
performance of mfs with |
of services intended to |
of mfs with prefetchthe |
services intended to run |
mfs with prefetchthe main |
intended to run on |
with prefetchthe main complexity |
to run on clustered |
prefetchthe main complexity in |
run on clustered platforms |
main complexity in implementing |
on clustered platforms desire |
complexity in implementing the |
clustered platforms desire the |
in implementing the prefetching |
platforms desire the productivity |
implementing the prefetching subing |
desire the productivity and |
the productivity and robustness |
productivity and robustness benefits |
and robustness benefits of |
robustness benefits of managed |
benefits of managed environments |
using a deliberately simple |
a deliberately simple hint |
deliberately simple hint mechanism |
simple hint mechanism for |
hint mechanism for the |
and need replication tools |
mechanism for the purposes |
need replication tools integrated |
brewer s conjecture and |
for the purposes system |
replication tools integrated with |
s conjecture and the |
the purposes system lies |
tools integrated with those |
conjecture and the feasibility |
purposes system lies in |
integrated with those environments |
and the feasibility of |
system lies in handling |
the feasibility of consistent |
lies in handling a |
feasibility of consistent available |
in handling a demand |
building such tools so |
of consistent available partition |
handling a demand fetch |
such tools so posed |
tools so posed challenges |
so posed challenges to |
posed challenges to us |
challenges to us as |
a compulsory fetch to |
to us as protocol |
compulsory fetch to of |
in in acm sigact |
in acm sigact news |
fetch to of evaluation |
us as protocol and |
as protocol and system |
protocol and system designers |
dependencies between files are |
between files are conveyed |
files are conveyed using |
which were the primary |
are conveyed using a |
were the primary focus |
conveyed using a service |
the primary focus of |
using a service a |
primary focus of our |
a service a cache |
focus of our paper |
service a cache miss |
a central insight is |
central insight is that |
for a file which |
insight is that high |
a file which is |
file which is already |
which is already being |
is already being prefetched |
performance protocols running in |
protocols running in managed |
running in managed settings |
in managed settings need |
managed settings need to |
settings need to maintain |
need to maintain the |
to maintain the smallest |
which is a list |
maintain the smallest possible |
is a list of |
the smallest possible memory |
a list of file |
smallest possible memory footprint |
list of file identifiers |
of file identifiers for |
file identifiers for the |
identifiers for the related |
for the related files |
this conflict arises very |
conflict arises very frequently |
particularly when an appliit |
when an appliit is |
an appliit is assumed |
appliit is assumed that |
is assumed that after |
assumed that after one |
that after one file |
after one file in |
one file in the |
file in the group |
in the group has |
plication of this principle |
the group has been |
group has been accessed |
qsm achieves scalability and |
achieves scalability and stability |
cation performs a fast |
scalability and stability even |
performs a fast linear |
and stability even at |
a fast linear scan |
stability even at very |
fast linear scan of |
even at very high |
linear scan of files |
at very high loads |
scan of files in |
of files in a |
files in a file |
in a file group |
filesystem backup to the |
backup to the cloud |
an unexpected side effect |
unexpected side effect of |
side effect of building |
an it becomes advantageous |
effect of building qsm |
it becomes advantageous to |
of building qsm in |
becomes advantageous to prefetch |
building qsm in windows |
advantageous to prefetch the |
qsm in windows was |
to prefetch the remainder |
in windows was that |
prefetch the remainder of |
windows was that by |
the remainder of the |
was that by integrating |
remainder of the files |
that by integrating our |
of the files in |
by integrating our system |
the files in efficient |
integrating our system tightly |
files in efficient implementation |
our system tightly with |
in efficient implementation of |
system tightly with the |
efficient implementation of prefetching |
tightly with the platform |
implementation of prefetching requires |
of prefetching requires that |
prefetching requires that the |
requires that the demand |
we created a new |
created a new kind |
a new kind of |
new kind of live |
kind of live distributed |
of live distributed objects |
abstract data types that |
data types that form |
types that form groups |
and that are updated |
that are updated using |
are updated using qsm |
updated using qsm multicasts |
these look natural to |
look natural to the |
natural to the windows |
to the windows user |
such an object changes |
an object changes faster |
object changes faster than |
changes faster than the |
faster than the average |
than the average windows |
the average windows object |
but the same basic |
the same basic mechanisms |
same basic mechanisms can |
basic mechanisms can support |
mechanisms can support them |
and the component integration |
the component integration environment |
extends seamlessly to encompass |
seamlessly to encompass them |
although a great deal |
harnessing storage clouds for |
a great deal of |
storage clouds for high |
great deal of additional |
clouds for high performance |
deal of additional work |
for high performance content |
of additional work is |
high performance content delivery |
additional work is needed |
qsm should eventually enable |
should eventually enable casual |
eventually enable casual use |
enable casual use of |
casual use of live |
use of live objects |
of live objects not |
live objects not just |
objects not just in |
not just in datacenters |
just in datacenters but |
in datacenters but also |
datacenters but also on |
but also on desktops |
also on desktops in |
on desktops in wan |
th international conference on |
desktops in wan settings |
international conference on service |
opening the door to |
the door to a |
door to a new |
to a new style |
a new style of |
new style of distributed |
style of distributed programming |
the current version of |
current version of qsm |
version of qsm is |
of qsm is stable |
qsm is stable in |
is stable in cluster |
stable in cluster settings |
in cluster settings and |
has a growing community |
a growing community of |
growing community of users |
looking to the future |
we plan to scale |
plan to scale qsm |
to scale qsm into |
scale qsm into wan |
qsm into wan settings |
to support a wider |
support a wider range |
a wider range of |
wider range of multicast |
range of multicast reliability |
of multicast reliability properties |
and to introduce a |
to introduce a gossip |
introduce a gossip infrastructure |
a gossip infrastructure that |
gossip infrastructure that would |
infrastructure that would support |
that would support configuration |
would support configuration discovery |
support configuration discovery and |
configuration discovery and other |
discovery and other self |
live objects pose a |
objects pose a protocol |
pose a protocol design |
a protocol design challenge |
they give rise to |
give rise to irregular |
rise to irregular patterns |
to irregular patterns of |
irregular patterns of overlapping |
patterns of overlapping multicast |
of overlapping multicast groups |
oriented state aggregation mechanisms |
state aggregation mechanisms will |
aggregation mechanisms will need |
mechanisms will need to |
will need to be |
need to be redesigned |
we have an idea |
have an idea for |
an idea for solving |
idea for solving this |
an elastic transactional data |
elastic transactional data store |
transactional data store in |
data store in the |
store in the cloud |
tcp no loss maelstrom |
no loss maelstrom no |
recovery would be performed |
loss maelstrom no loss |
would be performed by |
maelstrom no loss maelstrom |
be performed by selecting |
performed by selecting a |
by selecting a subset |
selecting a subset of |
a subset of nodes |
subset of nodes that |
of nodes that form |
nodes that form a |
that form a clean |
form a clean overlay |
a clean overlay structure |
rather than just treating |
than just treating every |
just treating every single |
treating every single receiver |
every single receiver as |
single receiver as a |
receiver as a member |
as a member of |
a member of a |
member of a recovery |
of a recovery region |
whether this can really |
this can really scale |
can really scale remains |
really scale remains to |
scale remains to be |
remains to be seen |
the chubby lock service |
chubby lock service for |
lock service for loosely |
th conference on usenix |
conference on usenix symposium |
on usenix symposium on |
usenix symposium on operating |
symposium on operating systems |
on operating systems design |
operating systems design and |
systems design and implementation |
one way link latency |
design and implementation of |
and implementation of a |
implementation of a reliable |
of a reliable group |
a reliable group communication |
reliable group communication toolkit |
group communication toolkit for |
communication toolkit for java |
way latency throughput as |
latency throughput as a |
throughput as a function |
as a function of |
a function of latency |
ip to attain very |
design and evaluation of |
to attain very high |
and evaluation of a |
attain very high speeds |
evaluation of a wide |
very high speeds on |
high speeds on the |
speeds on the gigabit |
on the gigabit link |
area event notification service |
we had to set |
had to set the |
acm transactions on computer |
to set the mtu |
transactions on computer systems |
set the mtu of |
the mtu of the |
mtu of the entire |
of the entire path |
the entire path to |
entire path to be |
path to be the |
to be the maximum |
which meant that the |
meant that the long |
prefetch no prefetch prefetch |
no prefetch prefetch no |
prefetch prefetch no prefetch |
haul link had the |
link had the same |
had the same mtu |
the same mtu as |
same mtu as the |
mtu as the inter |
this resulted in the |
resulted in the fragmentation |
prefetch no prefetch relative |
in the fragmentation of |
no prefetch relative speedup |
the fragmentation of repair |
prefetch relative speedup relative |
fragmentation of repair packets |
relative speedup relative speedup |
of repair packets sent |
repair packets sent over |
packets sent over udp |
sent over udp on |
over udp on the |
udp on the longhaul |
on the longhaul link |
the longhaul link into |
longhaul link into two |
link into two ip |
into two ip packet |
two ip packet fragments |
since the loss of |
the loss of a |
loss of a single |
of a single fragment |
a single fragment resulted |
single fragment resulted in |
fragment resulted in the |
resulted in the loss |
in the loss of |
the loss of the |
loss of the repair |
we observed a higher |
observed a higher loss |
a higher loss rate |
higher loss rate for |
loss rate for repairs |
rate for repairs than |
for repairs than for |
repairs than for data |
than for data packets |
we expect performance to |
expect performance to be |
performance to be better |
to be better on |
be better on a |
better on a network |
on a network where |
a network where the |
network where the mtu |
where the mtu of |
the mtu of the |
mtu of the long |
haul link is truly |
link is truly larger |
is truly larger than |
truly larger than the |
larger than the mtu |
than the mtu within |
the mtu within each |
mtu within each cluster |
even with zero loss |
prefetch no prefetch relative |
no prefetch relative speedup |
weight process groups in |
prefetch relative speedup relative |
process groups in the |
groups in the isis |
in the isis system |
the dangers of replication |
relative speedup relative speedup |
dangers of replication and |
ip throughput in figure |
of replication and a |
replication and a solution |
prefetch no prefetch relative |
no prefetch relative speedup |
declines with link latency |
this is due to |
is due to the |
due to the cap |
to the cap on |
the cap on throughput |
cap on throughput placed |
on throughput placed by |
throughput placed by the |
placed by the buffering |
by the buffering available |
the buffering available at |
buffering available at the |
available at the receiving |
acm sigmod international conference |
sigmod international conference on |
prefetch no prefetch relative |
at the receiving end |
international conference on management |
no prefetch relative speedup |
conference on management of |
on management of data |
prefetch relative speedup bad |
relative speedup bad groups |
the preceding experiments were |
preceding experiments were done |
experiments were done with |
were done with maelstrom |
done with maelstrom in |
with maelstrom in endto |
end flow control mode |
where it is oblivious |
it is oblivious to |
is oblivious to tcp |
ip and does not |
and does not split |
does not split connections |
and is consequently sensitive |
is consequently sensitive to |
consequently sensitive to the |
sensitive to the size |
to the size of |
the size of the |
size of the receiver |
of the receiver buffer |
constructing reliable distributed communication |
reliable distributed communication systems |
distributed communication systems with |
communication systems with corba |
ieee communications magazine feature |
communications magazine feature topic |
shows the performance of |
magazine feature topic issue |
the performance of split |
feature topic issue on |
performance of split mode |
topic issue on distributed |
of split mode flow |
issue on distributed object |
split mode flow control |
on distributed object computing |
where maelstrom breaks a |
maelstrom breaks a single |
breaks a single tcp |
ip connection into three |
connection into three hops |
split mode flow control |
mode flow control eliminates |
flow control eliminates the |
control eliminates the requirement |
eliminates the requirement for |
the requirement for large |
requirement for large buffers |
for large buffers at |
large buffers at the |
buffers at the receiving |
at the receiving end |
throughput is essentially insensitive |
is essentially insensitive to |
essentially insensitive to one |
with a slight drop |
a slight drop due |
slight drop due to |
drop due to buffering |
due to buffering overhead |
to buffering overhead on |
buffering overhead on the |
overhead on the maelstrom |
on the maelstrom boxes |
compares split mode to |
split mode to end |
hierarchical clustering of message |
clustering of message flows |
of message flows in |
message flows in a |
flows in a multicast |
in a multicast data |
a multicast data dissemination |
multicast data dissemination system |
optimizing buffer management for |
buffer management for reliable |
management for reliable multicast |
proceedings of the international |
of the international conference |
the international conference on |
international conference on dependable |
conference on dependable systems |
on dependable systems and |
dependable systems and networks |
secure untrusted data repository |
relative speedup of workloads |
speedup of workloads with |
of workloads with prefetching |
th conference on symposium |
conference on symposium on |
these graphs show the |
on symposium on opearting |
graphs show the speedup |
symposium on opearting systems |
show the speedup gained |
on opearting systems design |
the speedup gained by |
speedup gained by adding |
gained by adding prefetching |
by adding prefetching for |
adding prefetching for a |
prefetching for a range |
for a range of |
a range of bandwidth |
range of bandwidth values |
relative to the time |
to the time taken |
the time taken with |
time taken with a |
taken with a bandwidth |
with a bandwidth of |
a group membership service |
group membership service for |
membership service for wans |
acm transactions on computer |
transactions on computer systems |
s and no prefetching |
where a test comprises |
a test comprises two |
test comprises two separate |
comprises two separate processes |
mode buffering flow control |
only the speedup for |
buffering flow control against |
the speedup for the |
flow control against one |
speedup for the foreground |
for the foreground process |
the foreground process is |
foreground process is shown |
way link latency left |
fetch wait for the |
wait for the prefetch |
most bar represents maelstrom |
for the prefetch to |
bar represents maelstrom in |
the prefetch to complete |
represents maelstrom in end |
or that the prefetch |
that the prefetch be |
the prefetch be aborted |
end mode with manually |
mode with manually configured |
with manually configured large |
issuing a fetch rpc |
manually configured large buffers |
a fetch rpc at |
configured large buffers at |
fetch rpc at the |
large buffers at end |
rpc at the same |
at the same time |
the same time as |
same time as a |
time as a prefetch |
as a prefetch is |
a prefetch is in |
prefetch is in progress |
is in progress needlessly |
in progress needlessly wastes |
progress needlessly wastes bandwidth |
and the second and |
the second and third |
second and third bar |
and third bar from |
third bar from left |
bar from left are |
since it retrieves the |
from left are split |
it retrieves the same |
left are split mode |
retrieves the same file |
are split mode and |
the same file from |
split mode and end |
same file from the |
file from the server |
from the server twice |
the same could be |
same could be true |
could be true if |
be true if we |
true if we opt |
communal data sharing in |
data sharing in public |
sharing in public clouds |
if we opt for |
we opt for aborting |
opt for aborting prefetches |
with standard buffers at |
standard buffers at end |
since an aborted prefetch |
an aborted prefetch could |
aborted prefetch could be |
prefetch could be very |
could be very close |
be very close to |
very close to completion |
split mode performs as |
mode performs as well |
performs as well with |
as well with default |
well with default sized |
with default sized buffers |
default sized buffers as |
sized buffers as end |
mfs therefore makes the |
therefore makes the demand |
makes the demand fetch |
the demand fetch wait |
demand fetch wait for |
fetch wait for the |
wait for the prefetch |
end mode performs with |
mode performs with large |
performs with large end |
but also raises the |
also raises the priority |
raises the priority of |
the priority of the |
priority of the prefetch |
of the prefetch rpc |
the prefetch rpc to |
prefetch rpc to that |
rpc to that of |
to that of a |
and much better than |
much better than end |
that of a regular |
of a regular fetch |
a regular fetch operation |
to prevent a priority |
prevent a priority inversion |
end mode with default |
mode with default sized |
with default sized buffers |
this requires an additional |
requires an additional raise |
priority rpc to the |
rpc to the server |
which results in more |
results in more overhead |
in more overhead than |
more overhead than the |
overhead than the case |
than the case where |
the case where a |
case where a demand |
where a demand fetch |
a demand fetch occurs |
demand fetch occurs without |
fetch occurs without a |
occurs without a fetch |
on the other hand |
the fetch can frequently |
fetch can frequently make |
can frequently make use |
frequently make use of |
make use of the |
use of the data |
of the data already |
the data already transferred |
data already transferred and |
already transferred and so |
transferred and so still |
and so still results |
so still results in |
still results in a |
results in a faster |
in a faster response |
a faster response to |
faster response to the |
response to the application |
as we have explained |
the implementation of the |
implementation of the prefetching |
of the prefetching subsystem |
the prefetching subsystem is |
prefetching subsystem is not |
subsystem is not sophisticated |
while it will reach |
it will reach an |
will reach an equilibrium |
reach an equilibrium if |
an equilibrium if the |
equilibrium if the total |
if the total size |
the total size of |
total size of the |
size of the file |
of the file groups |
the file groups in |
file groups in the |
groups in the prefetch |
in the prefetch list |
the prefetch list is |
prefetch list is less |
list is less than |
is less than the |
less than the cache |
than the cache size |
there is no mechanism |
is no mechanism to |
no mechanism to prevent |
mechanism to prevent the |
to prevent the prefetching |
prevent the prefetching subsystem |
the prefetching subsystem running |
prefetching subsystem running ahead |
subsystem running ahead of |
running ahead of actual |
ahead of actual file |
of actual file accesses |
actual file accesses and |
file accesses and evicting |
accesses and evicting useful |
and evicting useful files |
evicting useful files from |
useful files from the |
files from the cache |
or evicting files which |
evicting files which it |
files which it has |
which it has prefetched |
it has prefetched but |
has prefetched but have |
prefetched but have not |
but have not yet |
have not yet been |
not yet been referenced |
yet been referenced by |
been referenced by the |
referenced by the user |
techniques for preventing this |
for preventing this behaviour |
preventing this behaviour have |
this behaviour have been |
behaviour have been discussed |
have been discussed elsewhere |
in order to characterise |
order to characterise the |
to characterise the effect |
characterise the effect of |
the effect of adding |
effect of adding prefetching |
we ran a set |
ran a set of |
a set of eight |
set of eight microbenchmarks |
the experimental setup was |
experimental setup was the |
setup was the same |
was the same as |
the same as in |
same as in the |
as in the priority |
in the priority tests |
though this time mfs |
this time mfs was |
time mfs was configured |
mfs was configured to |
was configured to run |
configured to run with |
to run with asynchronous |
run with asynchronous writeback |
and rpc with priorities |
and only prefetching was |
only prefetching was either |
prefetching was either enabled |
was either enabled or |
either enabled or disabled |
the tests were run |
tests were run at |
were run at a |
run at a range |
at a range of |
a range of bandwidth |
range of bandwidth values |
as in the previous |
in the previous section |
each microbenchmark consists of |
microbenchmark consists of one |
consists of one or |
of one or two |
one or two processes |
or two processes accessing |
two processes accessing files |
with some or all |
some or all of |
or all of the |
all of the files |
of the files forming |
the files forming file |
files forming file groups |
write test is the |
test is the same |
is the same as |
the same as in |
same as in section |
with a file group |
a file group added |
file group added for |
group added for the |
added for the read |
for the read data |
the compile mfs test |
compile mfs test has |
mfs test has six |
test has six file |
has six file groups |
six file groups for |
file groups for the |
groups for the main |
for the main directories |
the main directories of |
main directories of the |
directories of the system |
mb of data in |
forming a single file |
a single file group |
mb of small files |
the miner s dilemma |
miner s dilemma ittay |
s dilemma ittay eyal |
dilemma ittay eyal cornell |
ittay eyal cornell university |
eyal cornell university abstract |
cornell university abstract an |
university abstract an open |
abstract an open distributed |
an open distributed system |
open distributed system can |
distributed system can be |
system can be secured |
can be secured by |
all the files are |
be secured by requiring |
the files are in |
secured by requiring participants |
files are in a |
by requiring participants to |
are in a single |
requiring participants to present |
in a single file |
a single file group |
participants to present proof |
to present proof of |
present proof of work |
proof of work and |
of work and rewarding |
work and rewarding them |
and rewarding them for |
rewarding them for participation |
fetch runs as two |
runs as two process |
the bitcoin digital currency |
bitcoin digital currency introduced |
digital currency introduced this |
currency introduced this mechanism |
which is adopted by |
is adopted by almost |
adopted by almost all |
by almost all contemporary |
almost all contemporary digital |
all contemporary digital currencies |
contemporary digital currencies and |
digital currencies and related |
currencies and related services |
which form a file |
form a file group |
a natural process leads |
natural process leads participants |
process leads participants of |
leads participants of such |
participants of such systems |
the other does the |
of such systems to |
other does the same |
such systems to form |
systems to form pools |
but without a file |
without a file group |
where members aggregate their |
members aggregate their power |
aggregate their power and |
their power and share |
power and share the |
simultaneous writeback executes in |
and share the rewards |
writeback executes in the |
executes in the same |
in the same way |
experience with bitcoin shows |
with bitcoin shows that |
bitcoin shows that the |
but the second process |
shows that the largest |
the second process writes |
that the largest pools |
second process writes the |
the largest pools are |
largest pools are often |
pools are often open |
process writes the files |
writes the files to |
the files to the |
files to the server |
way delivery latency against |
delivery latency against loss |
allowing anyone to join |
to the server instead |
latency against loss rate |
the server instead of |
server instead of reading |
instead of reading them |
it has long been |
has long been known |
long been known that |
been known that a |
the remaining tests investigate |
known that a member |
remaining tests investigate the |
that a member can |
tests investigate the overhead |
a member can sabotage |
investigate the overhead paid |
member can sabotage an |
the overhead paid for |
can sabotage an open |
overhead paid for weaknesses |
sabotage an open pool |
paid for weaknesses in |
an open pool by |
for weaknesses in the |
open pool by seemingly |
weaknesses in the prefetching |
pool by seemingly joining |
in the prefetching algorithm |
by seemingly joining it |
seemingly joining it but |
joining it but never |
it but never sharing |
but never sharing its |
never sharing its proofs |
sharing its proofs of |
its proofs of work |
the pool shares its |
pool shares its revenue |
shares its revenue with |
its revenue with the |
revenue with the attacker |
and so each of |
so each of its |
each of its participants |
of its participants earns |
its participants earns less |
we define and analyze |
define and analyze a |
and analyze a game |
analyze a game where |
a game where pools |
game where pools use |
where pools use some |
pools use some of |
use some of their |
some of their participants |
of their participants to |
their participants to infiltrate |
kb files and forming |
participants to infiltrate other |
files and forming its |
to infiltrate other pools |
and forming its own |
infiltrate other pools and |
forming its own file |
its own file group |
other pools and perform |
pools and perform such |
and perform such an |
perform such an attack |
on its first iteration |
with any number of |
any number of pools |
the workload accesses the |
workload accesses the first |
accesses the first file |
the first file in |
first file in each |
file in each directory |
attacks is not a |
is not a nash |
aware adaptation techniques for |
not a nash equilibrium |
adaptation techniques for mobile |
techniques for mobile file |
for mobile file systems |
mobile file systems benjamin |
file systems benjamin atkin |
we study the special |
to provoke a large |
study the special cases |
systems benjamin atkin kenneth |
provoke a large amount |
the special cases where |
benjamin atkin kenneth p |
a large amount of |
special cases where either |
large amount of useless |
cases where either two |
amount of useless prefetches |
where either two pools |
birman nec laboratories america |
either two pools or |
nec laboratories america cornell |
two pools or any |
laboratories america cornell university |
good order and bad |
pools or any number |
america cornell university atkin |
order and bad order |
or any number of |
and bad order investigate |
any number of identical |
bad order investigate the |
number of identical pools |
order investigate the effect |
of identical pools play |
investigate the effect of |
identical pools play the |
the effect of the |
pools play the game |
effect of the ordered |
play the game and |
of the ordered list |
the game and the |
the ordered list of |
game and the rest |
ordered list of files |
and the rest of |
list of files in |
the rest of the |
of files in a |
files in a file |
in a file group |
rest of the participants |
edu abstract therefore react |
of the participants are |
abstract therefore react to |
the participants are uninvolved |
therefore react to bandwidth |
react to bandwidth variations |
to bandwidth variations in |
bandwidth variations in a |
variations in a fine |
in both of these |
both of these cases |
of these cases there |
these cases there exists |
prefetching evaluation having added |
cases there exists an |
evaluation having added prefetching |
there exists an equilibrium |
having added prefetching to |
exists an equilibrium that |
added prefetching to mfs |
life file system traffic |
an equilibrium that constitutes |
file system traffic featuring |
equilibrium that constitutes a |
we evaluated whether such |
that constitutes a tragedy |
system traffic featuring high |
traffic featuring high read |
constitutes a tragedy of |
evaluated whether such a |
a tragedy of the |
whether such a straightforward |
tragedy of the commons |
write wireless networks present |
such a straightforward algorithm |
of the commons where |
wireless networks present unusual |
a straightforward algorithm can |
the commons where the |
networks present unusual challenges |
straightforward algorithm can have |
commons where the participating |
present unusual challenges for |
algorithm can have a |
where the participating pools |
unusual challenges for mobile |
can have a benefit |
the participating pools attack |
challenges for mobile file |
have a benefit for |
participating pools attack one |
for mobile file contention |
a benefit for some |
benefit for some repre |
pools attack one another |
attack one another and |
one another and earn |
mafs is able to |
another and earn less |
is able to achieve |
order accesses the files |
and earn less than |
able to achieve improvements |
accesses the files in |
earn less than they |
to achieve improvements in |
the files in the |
less than they would |
achieve improvements in execusystem |
files in the group |
than they would have |
improvements in execusystem clients |
in the group in |
they would have if |
the group in the |
would have if none |
group in the same |
have if none had |
since they are characterised |
in the same order |
if none had attacked |
they are characterised by |
the same order as |
are characterised by unpredictable |
same order as the |
characterised by unpredictable tion |
order as the list |
by unpredictable tion time |
unpredictable tion time of |
tion time of up |
time of up to |
the decision whether or |
decision whether or not |
bad order accesses them |
whether or not to |
order accesses them in |
or not to attack |
accesses them in reverse |
them in reverse order |
not to attack is |
to attack is the |
attack is the miner |
is the miner s |
the miner s dilemma |
an instance of the |
instance of the iterative |
of the iterative prisoner |
the iterative prisoner s |
iterative prisoner s dilemma |
at both low and |
both low and high |
low and high bandwidths |
the game is played |
game is played daily |
is played daily by |
played daily by the |
daily by the active |
by the active bitcoin |
the active bitcoin pools |
analysis of prefetching the |
which apparently choose not |
of prefetching the graphs |
apparently choose not to |
choose not to attack |
the traditional approach to |
prefetching the graphs in |
traditional approach to adapting |
the graphs in figure |
approach to adapting network |
if this balance breaks |
to adapting network communication |
adapting network communication to |
show the results of |
network communication to these |
the results of the |
the revenue of open |
communication to these conditions |
results of the experiments |
revenue of open pools |
to these conditions is |
of open pools might |
these conditions is to |
open pools might diminish |
where a test such |
conditions is to write |
a test such as |
is to write back |
test such as simultaneous |
to write back file |
making them unattractive to |
such as simultaneous demand |
write back file updates |
them unattractive to participants |
back file updates asynchronously |
file updates asynchronously when |
updates asynchronously when bandwidth |
fetch incorporates more than |
asynchronously when bandwidth is |
incorporates more than one |
more than one workload |
only the elapsed time |
the elapsed time for |
elapsed time for the |
time for the foreground |
for the foreground workload |
this can lead to |
the one accessing a |
can lead to underutilisation |
one accessing a file |
accessing a file group |
lead to underutilisation of |
is a digital currency |
to underutilisation of bandwidth |
a digital currency that |
underutilisation of bandwidth and |
digital currency that is |
of bandwidth and inconsistencies |
currency that is gaining |
bandwidth and inconsistencies between |
in most of the |
that is gaining acceptance |
and inconsistencies between clients |
most of the microbenchmarks |
we describe a new |
adding prefetching from the |
describe a new mobile |
prefetching from the file |
a new mobile access |
from the file groups |
new mobile access to |
the file groups specified |
mobile access to shared |
file groups specified has |
access to shared data |
groups specified has a |
to shared data is |
specified has a substantial |
shared data is complicated |
has a substantial improvement |
data is complicated by |
a substantial improvement on |
is complicated by an |
substantial improvement on the |
complicated by an unpredictable |
improvement on the performance |
by an unpredictable mobile |
on the performance of |
with an estimated market |
an unpredictable mobile file |
unpredictable mobile file system |
an estimated market capitalization |
the performance of the |
estimated market capitalization of |
market capitalization of over |
performance of the workload |
that supports graceful degradation |
supports graceful degradation computing |
varying with how amenable |
graceful degradation computing environment |
with how amenable it |
how amenable it is |
amenable it is to |
it is to prefetching |
the network or a |
network or a particular |
or a particular destination |
a particular destination of |
particular destination of file |
destination of file system |
of file system performance |
file system performance as |
more surplus bandwidth and |
system performance as bandwidth |
surplus bandwidth and more |
performance as bandwidth is |
bandwidth and more think |
as bandwidth is reduced |
and more think time |
more think time result |
think time result in |
time result in improved |
result in improved performance |
as well as may |
well as may be |
as may be unavailable |
this naturally means that |
naturally means that the |
or the throughput may |
means that the greatest |
the throughput may be |
that the greatest improvements |
throughput may be substandard |
the greatest improvements from |
packet delivery latencies throughput |
greatest improvements from prefetching |
improvements from prefetching are |
as rapid propagation of |
from prefetching are evident |
bitcoin s security stems |
rapid propagation of essential |
prefetching are evident at |
s security stems from |
propagation of essential file |
are evident at higher |
security stems from a |
of essential file updates |
evident at higher bandwidths |
stems from a robust |
from a robust incentive |
a robust incentive system |
mafs is able to |
is able to shown |
six out of eight |
able to shown in |
participants are required to |
out of eight microbenchmarks |
to shown in figure |
are required to provide |
of eight microbenchmarks run |
required to provide expensive |
eight microbenchmarks run at |
to provide expensive proofs |
microbenchmarks run at least |
provide expensive proofs of |
expensive proofs of work |
this graph shows results |
graph shows results from |
shows results from packet |
and they are rewarded |
they are rewarded according |
are rewarded according to |
rewarded according to their |
according to their efforts |
faster when bandwidth is |
this architecture has proved |
architecture has proved both |
has proved both stable |
proved both stable and |
both stable and scalable |
and it is used |
it is used by |
is used by most |
used by most contemporary |
by most contemporary digital |
most contemporary digital currencies |
contemporary digital currencies and |
digital currencies and related |
currencies and related services |
improvements in execution time |
in execution time for |
execution time for real |
mbps flow alongside on |
flow alongside on the |
alongside on the same |
on the same link |
life measurements of available |
the same link to |
measurements of available bandwidth |
same link to simulate |
of available bandwidth between |
link to simulate a |
to simulate a real |
available bandwidth between a |
at low bandwidth most |
bandwidth between a mobile |
low bandwidth most workloads |
time stream combined with |
between a mobile host |
bandwidth most workloads see |
most workloads see no |
a mobile host on |
stream combined with other |
workloads see no benefit |
mobile host on a |
combined with other inter |
host on a wireless |
on a wireless network |
since all the bandwidth |
all the bandwidth is |
the bandwidth is dedicated |
bandwidth is dedicated to |
is dedicated to higher |
and a wired host |
a wired host near |
wired host near the |
host near the base |
near the base station |
file system traces featuring |
only two tests perform |
system traces featuring read |
two tests perform worse |
tests perform worse with |
perform worse with prefetching |
worse with prefetching than |
with prefetching than without |
shows the average delivery |
the average delivery latency |
as the mobile host |
the mobile host moves |
average delivery latency of |
write test performs slightly |
test performs slightly worse |
performs slightly worse due |
slightly worse due to |
worse due to its |
factors such as the |
due to its already |
such as the distance |
to its already heavy |
level packets in the |
as the distance to |
its already heavy network |
the distance to the |
already heavy network contention |
distance to the base |
to the base station |
the base station and |
base station and local |
the bad groups test |
station and local interference |
and local interference cause |
local interference cause the |
interference cause the host |
cause the host s |
which exploits poor prefetching |
the host s network |
exploits poor prefetching hints |
as loss rates go |
loss rates go up |
host s network card |
s network card to |
network card to switch |
card to switch to |
to switch to higher |
our results apply to |
results apply to all |
apply to all such |
to all such incentive |
performs when prefetching is |
all such incentive systems |
when prefetching is used |
but we use bitcoin |
this effect is due |
we use bitcoin terminology |
effect is due to |
use bitcoin terminology and |
is due to the |
bitcoin terminology and examples |
due to the useless |
terminology and examples since |
to the useless prefetching |
and examples since it |
the useless prefetching rpcs |
such switching causes available |
examples since it serves |
useless prefetching rpcs flooding |
switching causes available bandwidth |
since it serves as |
shows the same scenario |
causes available bandwidth to |
prefetching rpcs flooding the |
it serves as an |
the same scenario with |
available bandwidth to oscillate |
rpcs flooding the outgoing |
serves as an active |
same scenario with a |
bandwidth to oscillate distributed |
flooding the outgoing link |
as an active and |
scenario with a constant |
to oscillate distributed file |
the outgoing link and |
an active and archetypal |
with a constant uniformly |
oscillate distributed file systems |
outgoing link and imposing |
active and archetypal example |
a constant uniformly random |
distributed file systems are |
link and imposing minor |
constant uniformly random loss |
file systems are a |
and imposing minor delays |
uniformly random loss rate |
bitcoin implements its incentive |
systems are a common |
imposing minor delays on |
random loss rate of |
implements its incentive systems |
are a common feature |
minor delays on each |
delays on each demand |
a common feature of |
its incentive systems with |
on each demand fetch |
common feature of large |
feature of large com |
incentive systems with a |
systems with a data |
with a data structure |
a data structure called |
cumulatively these slow down |
data structure called the |
these slow down the |
structure called the blockchain |
slow down the overall |
even when the mobile |
down the overall performance |
when the mobile host |
the mobile host is |
mobile host is stationary |
the blockchain is a |
blockchain is a serialization |
maelstrom s delivery latency |
is a serialization of |
an usual phenomenon is |
s delivery latency is |
a serialization of all |
if it is to |
usual phenomenon is that |
delivery latency is almost |
serialization of all bitcoin |
it is to enputing |
phenomenon is that the |
latency is almost exactly |
of all bitcoin transactions |
is to enputing environments |
is that the bad |
is almost exactly equal |
that the bad order |
almost exactly equal to |
the bad order test |
since they simplify sharing |
exactly equal to the |
equal to the one |
bad order test consistently |
they simplify sharing data |
it is a single |
order test consistently outperforms |
way latency on the |
latency on the link |
simplify sharing data between |
test consistently outperforms good |
is a single global |
sharing data between sure |
consistently outperforms good order |
a single global ledger |
data between sure that |
single global ledger maintained |
ip takes more than |
between sure that clients |
global ledger maintained by |
takes more than twice |
even though the latter |
sure that clients file |
ledger maintained by an |
more than twice as |
though the latter triggers |
that clients file operations |
maintained by an open |
than twice as long |
the latter triggers prefetches |
clients file operations are |
by an open distributed |
twice as long once |
as long once one |
file operations are executed |
an open distributed system |
latter triggers prefetches in |
operations are executed in |
way latencies go past |
triggers prefetches in the |
are executed in a |
prefetches in the correct |
since anyone can join |
executed in a timely |
in a timely way |
anyone can join the |
in the correct order |
can join the open |
join the open system |
the open system and |
open system and participate |
system and participate in |
the explanation is that |
and participate in maintaining |
participate in maintaining the |
and can provide scalable |
in maintaining the blockchain |
can provide scalable and |
provide scalable and highly |
scalable and highly available |
and highly available file |
highly available file ac |
the good order test |
bitcoin uses a proof |
good order test suffers |
uses a proof of |
order test suffers from |
file system must adapt |
a proof of work |
test suffers from the |
system must adapt to |
proof of work mechanism |
suffers from the fast |
must adapt to this |
of work mechanism to |
from the fast linear |
adapt to this variation |
work mechanism to deter |
the fast linear scan |
mechanism to deter attacks |
fast linear scan phenomenon |
linear scan phenomenon described |
scan phenomenon described in |
phenomenon described in section |
participation requires exerting significant |
requires exerting significant compute |
exerting significant compute resources |
a participant that proves |
participant that proves she |
that proves she has |
proves she has exerted |
ip one way link |
she has exerted enough |
one way link latency |
all prefetches in this |
supporting mobile clients requires |
has exerted enough resources |
prefetches in this test |
mobile clients requires coping |
exerted enough resources with |
in this test conflict |
clients requires coping existing |
enough resources with a |
this test conflict with |
requires coping existing systems |
resources with a proof |
test conflict with demand |
coping existing systems tailored |
with a proof of |
conflict with demand fetches |
existing systems tailored to |
a proof of work |
systems tailored to low |
proof of work is |
of work is allowed |
work is allowed to |
is allowed to take |
allowed to take a |
bandwidth clients differenwith the |
to take a step |
clients differenwith the atypical |
take a step in |
differenwith the atypical patterns |
a step in the |
at the start of |
the atypical patterns of |
step in the protocol |
the start of the |
atypical patterns of connectivity |
in the protocol by |
start of the bad |
patterns of connectivity that |
the protocol by generating |
of the bad order |
the bad order test |
split with regular buffers |
protocol by generating a |
of connectivity that characterise |
by generating a block |
connectivity that characterise them |
the prefetching subsystem is |
prefetching subsystem is able |
subsystem is able to |
is able to prefetch |
participants are compensated for |
tiate between types of |
able to prefetch some |
are compensated for their |
between types of file |
to prefetch some files |
compensated for their efforts |
end with large buffers |
prefetch some files accessed |
types of file system |
for their efforts with |
some files accessed at |
of file system communication |
their efforts with newly |
files accessed at the |
efforts with newly minted |
accessed at the end |
with newly minted bitcoins |
at the end of |
so that bandwhile a |
the end of the |
end of the test |
that bandwhile a desktop |
the process of creating |
bandwhile a desktop client |
and outperforms it with |
process of creating a |
a desktop client is |
outperforms it with regular |
without conflicting with a |
of creating a block |
desktop client is well |
it with regular buffers |
conflicting with a demand |
creating a block is |
with a demand fetch |
a block is called |
connected to a file |
block is called mining |
to a file server |
a file server un |
it can therefore achieve |
can therefore achieve a |
therefore achieve a greater |
achieve a greater speedup |
and the participants miners |
width can be devoted |
can be devoted to |
be devoted to important |
latency metrics to measure |
in order to win |
metrics to measure the |
order to win the |
to win the reward |
to measure the latency |
measure the latency effects |
the latency effects of |
latency effects of tcp |
many miners try to |
miners try to generate |
try to generate blocks |
the system automatically adjusts |
system automatically adjusts the |
automatically adjusts the difficulty |
adjusts the difficulty of |
the difficulty of block |
difficulty of block generation |
a mobile client frequently |
mobile client frequently lacks |
client frequently lacks the |
such that one block |
that one block is |
one block is added |
block is added every |
mbps stream between two |
stream between two nodes |
between two nodes over |
two nodes over a |
minutes to the blockchain |
this means that each |
means that each miner |
that each miner seldom |
each miner seldom generates |
miner seldom generates a |
seldom generates a block |
although its revenue may |
its revenue may be |
revenue may be positive |
may be positive in |
be positive in expectation |
a miner may have |
miner may have to |
may have to wait |
have to wait for |
writes back changes to |
to wait for an |
back changes to files |
wait for an extended |
changes to files asynbandwidth |
plots delivery latency against |
for an extended period |
to files asynbandwidth to |
delivery latency against message |
an extended period to |
files asynbandwidth to perform |
latency against message identifier |
extended period to create |
asynbandwidth to perform all |
period to create a |
to perform all its |
to create a block |
perform all its file |
a key point is |
create a block and |
all its file operations |
key point is that |
a block and earn |
its file operations in |
point is that we |
block and earn the |
file operations in a |
is that we are |
and earn the actual |
operations in a timely |
that we are plotting |
earn the actual bitcoins |
in a timely fashion |
we are plotting the |
are plotting the delivery |
plotting the delivery latency |
the delivery latency of |
delivery latency of all |
latency of all packets |
miners form mining pools |
not just lost ones |
where all members mine |
the spikes in latency |
all members mine concurrently |
spikes in latency are |
members mine concurrently and |
in latency are triggered |
mine concurrently and they |
latency are triggered by |
assigns lower priorities to |
concurrently and they share |
are triggered by losses |
lower priorities to asynmobile |
and they share their |
triggered by losses that |
priorities to asynmobile file |
they share their revenue |
by losses that lead |
to asynmobile file systems |
share their revenue whenever |
losses that lead to |
asynmobile file systems typically |
their revenue whenever one |
that lead to packets |
file systems typically assume |
revenue whenever one of |
lead to packets piling |
systems typically assume that |
whenever one of them |
to packets piling up |
typically assume that a |
one of them creates |
packets piling up both |
assume that a client |
of them creates a |
piling up both at |
that a client is |
them creates a block |
up both at the |
a client is strongly |
both at the receiver |
at the receiver and |
the receiver and the |
receiver and the sender |
pools are typically implemented |
are typically implemented as |
typically implemented as a |
chronous operations at the |
implemented as a pool |
operations at the ip |
as a pool manager |
at the ip level |
a pool manager and |
the ip level to |
ip delays correctly received |
pool manager and a |
ip level to reduce |
delays correctly received packets |
manager and a cohort |
level to reduce interference |
correctly received packets at |
and a cohort of |
to reduce interference with |
received packets at the |
a cohort of miners |
reduce interference with connected |
packets at the receiver |
interference with connected like |
at the receiver while |
with connected like a |
the receiver while waiting |
the pool manager joins |
connected like a desktop |
receiver while waiting for |
pool manager joins the |
like a desktop host |
while waiting for missing |
manager joins the bitcoin |
waiting for missing packets |
joins the bitcoin system |
for missing packets sequenced |
the bitcoin system as |
missing packets sequenced earlier |
bitcoin system as a |
packets sequenced earlier by |
system as a single |
as a single miner |
sequenced earlier by the |
connected and should foreground |
earlier by the sender |
and should foreground operations |
instead of generating proof |
of generating proof of |
generating proof of work |
it also delays packets |
limit its bandwidth consumption |
also delays packets at |
it outsources the work |
its bandwidth consumption to |
delays packets at the |
outsources the work to |
bandwidth consumption to a |
packets at the sender |
the work to the |
consumption to a minimum |
at the sender when |
work to the miners |
the sender when it |
sender when it cuts |
when it cuts down |
it cuts down on |
cuts down on the |
in order to evaluate |
down on the sending |
number of rpcs by |
order to evaluate the |
on the sending window |
of rpcs by type |
to evaluate the miners |
the sending window size |
rpcs by type in |
evaluate the miners efforts |
sending window size in |
by type in bandwidth |
window size in response |
type in bandwidth variability |
size in response to |
in bandwidth variability test |
in response to the |
the pool manager accepts |
response to the loss |
pool manager accepts partial |
to the loss events |
the entries under p |
adaptation by deferred transmission |
manager accepts partial proof |
entries under p denote |
by deferred transmission of |
the delays caused by |
under p denote periods |
accepts partial proof of |
deferred transmission of file |
delays caused by these |
p denote periods in |
partial proof of work |
transmission of file upwidth |
caused by these two |
denote periods in the |
proof of work and |
of file upwidth lies |
by these two mechanisms |
periods in the test |
of work and estimates |
file upwidth lies between |
these two mechanisms are |
work and estimates each |
upwidth lies between these |
two mechanisms are illustrated |
and estimates each miner |
lies between these extremes |
gives the abbreviations for |
estimates each miner s |
mechanisms are illustrated in |
the abbreviations for rpc |
each miner s power |
assuming weak connectivity dates |
abbreviations for rpc types |
are illustrated in figure |
miner s power according |
weak connectivity dates has |
s power according to |
are likely to be |
likely to be beneficial |
power according to the |
connectivity dates has the |
according to the rate |
dates has the disadvantage |
to the rate with |
the first would reduce |
has the disadvantage of |
where single packet losses |
first would reduce the |
the rate with which |
the disadvantage of increasing |
single packet losses cause |
would reduce the aggressiveness |
rate with which it |
disadvantage of increasing the |
packet losses cause spikes |
reduce the aggressiveness of |
with which it submits |
of increasing the delay |
losses cause spikes in |
the aggressiveness of prefetching |
which it submits such |
increasing the delay before |
cause spikes in delivery |
it submits such partial |
the delay before upcan |
spikes in delivery latency |
submits such partial proof |
delay before upcan be |
in delivery latency that |
such partial proof of |
before upcan be too |
setting a byte threshold |
delivery latency that last |
partial proof of work |
upcan be too conservative |
latency that last for |
that last for hundreds |
last for hundreds of |
from a file group |
for hundreds of packets |
when a miner generates |
a file group if |
since it delays sending |
a miner generates a |
file group if it |
it delays sending updates |
miner generates a full |
the maelstrom configuration used |
group if it appeared |
delays sending updates to |
generates a full proof |
maelstrom configuration used is |
if it appeared that |
sending updates to the |
a full proof of |
configuration used is r |
it appeared that a |
updates to the dates |
full proof of work |
appeared that a process |
to the dates are |
that a process was |
the dates are applied |
a process was not |
it sends it to |
dates are applied at |
process was not using |
sends it to the |
are applied at the |
was not using the |
it to the pool |
applied at the file |
not using the files |
to the pool manager |
at the file server |
using the files prefetched |
the pool manager which |
the files prefetched based |
pool manager which publishes |
files prefetched based on |
manager which publishes this |
and therefore reduces the |
prefetched based on its |
which publishes this proof |
therefore reduces the deserver |
based on its prior |
on its prior accesses |
reduces the deserver in |
publishes this proof of |
the deserver in order |
this proof of work |
deserver in order to |
proof of work to |
this would reduce the |
in order to aggregate |
of work to the |
would reduce the overhead |
order to aggregate modifications |
work to the bitcoin |
reduce the overhead in |
to the bitcoin system |
the overhead in the |
overhead in the bad |
gree of consistency between |
in the bad groups |
the bad groups case |
of consistency between clients |
the pool manager thus |
consistency between clients cached |
pool manager thus receives |
between clients cached copies |
manager thus receives the |
the second would explicitly |
thus receives the full |
second would explicitly detect |
receives the full revenue |
would explicitly detect a |
for its own this |
the full revenue of |
explicitly detect a fast |
its own this paper |
full revenue of the |
detect a fast linear |
own this paper examines |
revenue of the block |
a fast linear scan |
this paper examines the |
of the block and |
fast linear scan by |
paper examines the effectiveness |
the block and distributes |
linear scan by a |
examines the effectiveness of |
block and distributes it |
scan by a process |
the effectiveness of mafs |
and distributes it fairly |
distributes it fairly according |
it fairly according to |
fairly according to its |
according to its members |
by counting the instances |
to its members power |
counting the instances of |
the instances of prefetch |
instances of prefetch and |
of prefetch and demand |
prefetch and demand fetch |
and demand fetch conflict |
many of the pools |
demand fetch conflict for |
of the pools are |
bandwidth client may decide |
fetch conflict for a |
the pools are open |
client may decide to |
conflict for a file |
pools are open they |
may decide to delay |
for a file group |
are open they allow |
decide to delay sending |
open they allow any |
to delay sending a |
they allow any miner |
and then disable prefetching |
delay sending a file |
allow any miner to |
then disable prefetching from |
sending a file system |
any miner to join |
disable prefetching from the |
a file system that |
miner to join them |
prefetching from the group |
file system that propagates |
to join them using |
system that propagates file |
join them using a |
that propagates file modifications |
them using a public |
propagates file modifications asynchronously |
using a public internet |
file modifications asynchronously file |
a public internet interface |
modifications asynchronously file s |
asynchronously file s update |
file s update to |
s update to the |
update to the file |
to the file server |
such open pools are |
prefetching and bandwidth variability |
and bandwidth variability so |
bandwidth variability so far |
open pools are susceptible |
but this decision may |
pools are susceptible to |
this decision may also |
are susceptible to the |
decision may also affect |
our experimental results have |
susceptible to the classical |
may also affect at |
experimental results have demonstrated |
to the classical block |
also affect at all |
results have demonstrated the |
the classical block withholding |
affect at all bandwidth |
have demonstrated the benefits |
classical block withholding attack |
at all bandwidth levels |
demonstrated the benefits of |
the benefits of mfs |
benefits of mfs adaptation |
of mfs adaptation mechanisms |
mfs adaptation mechanisms at |
rather than delaying writes |
adaptation mechanisms at various |
mechanisms at various levels |
at various levels of |
various levels of bandwidth |
levels of bandwidth availability |
mafs other clients that |
other clients that would |
clients that would like |
that would like to |
would like to read |
like to read the |
to read the file |
but not when the |
not when the bandwidth |
when the bandwidth is |
the bandwidth is changing |
bandwidth is changing over |
where a miner sends |
optimistic concuruses rpc priorities |
is changing over the |
a miner sends only |
concuruses rpc priorities to |
changing over the duration |
miner sends only partial |
rpc priorities to reduce |
over the duration of |
sends only partial proof |
priorities to reduce interference |
the duration of the |
only partial proof of |
to reduce interference between |
duration of the test |
partial proof of work |
reduce interference between read |
proof of work to |
interference between read and |
of work to the |
to conclude this section |
between read and rency |
work to the pool |
conclude this section we |
read and rency control |
to the pool manager |
this section we will |
and rency control and |
the pool manager and |
section we will describe |
rency control and reconciliation |
pool manager and discards |
we will describe an |
control and reconciliation of |
manager and discards full |
will describe an example |
and reconciliation of conflicting |
and discards full proof |
describe an example of |
reconciliation of conflicting updates |
discards full proof of |
full proof of work |
of conflicting updates are |
an example of mfs |
conflicting updates are typwrite |
example of mfs traffic |
updates are typwrite traffic |
of mfs traffic under |
due to the partial |
are typwrite traffic at |
mfs traffic under the |
to the partial proof |
typwrite traffic at low |
traffic under the execution |
the partial proof of |
traffic at low bandwidth |
under the execution of |
partial proof of work |
the execution of the |
proof of work it |
execution of the simultaneous |
of work it sends |
to ensure that file |
of the simultaneous writeback |
work it sends to |
ensure that file modifications |
the simultaneous writeback test |
it sends to the |
that file modifications ically |
simultaneous writeback test described |
sends to the pool |
file modifications ically used |
writeback test described in |
modifications ically used to |
test described in section |
ically used to resolve |
the miner is considered |
used to resolve inconsistencies |
miner is considered a |
is considered a regular |
considered a regular pool |
a regular pool member |
regular pool member and |
pool member and the |
member and the pool |
and the pool can |
the pool can estimate |
pool can estimate its |
can estimate its power |
this test involves two |
test involves two simultaneous |
involves two simultaneous workloads |
the attacker shares the |
attacker shares the revenue |
shares the revenue obtained |
the revenue obtained by |
revenue obtained by the |
obtained by the other |
by the other pool |
the other pool members |
kb to the server |
to the server and |
when bandwidth are rapidly |
but does not contribute |
the server and the |
bandwidth are rapidly propagated |
server and the other |
are rapidly propagated to |
and the other reads |
rapidly propagated to the |
it reduces the revenue |
propagated to the clients |
reduces the revenue of |
to the clients that |
the revenue of the |
the clients that need |
revenue of the other |
kb files from the |
files from the server |
of the other members |
clients that need them |
but is slightly modified |
but also its own |
mafs is very low |
is slightly modified from |
slightly modified from original |
modified from original version |
from original version to |
we provide necessary background |
this can be an |
original version to use |
provide necessary background on |
can be an acceptable |
version to use a |
necessary background on the |
be an acceptable price |
to use a longer |
background on the bitcoin |
an acceptable price to |
use a longer think |
on the bitcoin protocol |
acceptable price to pay |
a longer think time |
percentage of packets recovered |
price to pay for |
longer think time of |
to pay for the |
pools and the classical |
pay for the abilalso |
and the classical block |
for the abilalso incorporates |
the classical block withholding |
the abilalso incorporates a |
classical block withholding attack |
abilalso incorporates a new |
block withholding attack in |
incorporates a new invalidation |
withholding attack in section |
attack in section ii |
seconds when accessing each |
based update propagation ity |
when accessing each file |
and specify our model |
update propagation ity to |
specify our model in |
propagation ity to continue |
improving the potential for |
our model in section |
ity to continue accessing |
the potential for rpcs |
model in section iii |
to continue accessing a |
potential for rpcs to |
continue accessing a file |
for rpcs to overlap |
accessing a file server |
for a broader view |
relatively prime interleaves offer |
a broader view of |
prime interleaves offer better |
broader view of the |
interleaves offer better performance |
but if bandwidth is |
view of the protocol |
if bandwidth is less |
we enabled asynchronous writeback |
of the protocol and |
bandwidth is less scheme |
enabled asynchronous writeback and |
the protocol and ecosystem |
asynchronous writeback and ran |
protocol and ecosystem the |
writeback and ran the |
unlike previous mobile file |
and ecosystem the reader |
and ran the test |
previous mobile file systems |
ecosystem the reader may |
ran the test with |
the reader may refer |
the test with the |
reader may refer to |
test with the synthetic |
may refer to the |
with the synthetic bandwidth |
refer to the survey |
the synthetic bandwidth trace |
to the survey by |
synthetic bandwidth trace shown |
the survey by bonneau |
bandwidth trace shown in |
survey by bonneau et |
by bonneau et al |
trace shown in figure |
client consistency is achievable |
codaniques that are oblivious |
that are oblivious to |
are oblivious to the |
oblivious to the exact |
to the exact bandwidth |
the exact bandwidth level |
and can like file |
can like file systems |
like file systems therefore |
which changes the bandwidth |
file systems therefore switch |
changes the bandwidth once |
systems therefore switch between |
the bandwidth once per |
therefore switch between a |
bandwidth once per second |
switch between a low |
in this work we |
this work we analyze |
work we analyze block |
we analyze block withholding |
this has three sections |
analyze block withholding attacks |
block withholding attacks among |
withholding attacks among pools |
a brief period when |
brief period when the |
period when the bandwidth |
when the bandwidth is |
a pool that employs |
the bandwidth is at |
writes mode and a |
mode and a synchronous |
pool that employs the |
that employs the pool |
employs the pool block |
the pool block withholding |
pool block withholding attack |
block withholding attack registers |
withholding attack registers with |
attack registers with the |
registers with the victim |
with the victim pool |
acthe authors were supported |
the victim pool as |
authors were supported in |
victim pool as a |
were supported in part |
pool as a regular |
as a regular miner |
supported in part by |
in part by darpa |
a gradual decrease to |
part by darpa under |
by darpa under afrl |
it receives tasks from |
darpa under afrl grant |
receives tasks from the |
under afrl grant radc |
tasks from the victim |
afrl grant radc cording |
from the victim pool |
grant radc cording to |
the victim pool and |
radc cording to the |
victim pool and transfers |
cording to the available |
pool and transfers them |
to the available bandwidth |
s over the course |
and transfers them to |
over the course of |
the course of ten |
transfers them to some |
course of ten seconds |
them to some of |
to some of its |
some of its own |
of its own miners |
in a wireless f |
and then the maintenance |
then the maintenance of |
the maintenance of the |
we call these infiltrating |
call these infiltrating miners |
and the mining power |
the mining power spent |
mining power spent by |
power spent by a |
spent by a pool |
by a pool the |
a pool the infiltration |
pool the infiltration rate |
s rate until the |
rate until the end |
until the end of |
when the attacking pool |
the end of the |
the attacking pool s |
end of the test |
attacking pool s infiltrating |
pool s infiltrating miners |
s infiltrating miners deliver |
infiltrating miners deliver partial |
miners deliver partial proofs |
deliver partial proofs of |
partial proofs of work |
the attacker transfers them |
attacker transfers them to |
transfers them to the |
them to the victim |
to the victim pool |
summary of results the |
of results the test |
results the test was |
the test was executed |
letting the attacked pool |
test was executed once |
the attacked pool estimate |
was executed once with |
attacked pool estimate their |
executed once with prefetching |
once with prefetching enabled |
pool estimate their power |
and despite the simplicity |
when the infiltrating miners |
despite the simplicity of |
the infiltrating miners deliver |
the simplicity of the |
infiltrating miners deliver a |
and by afosr under |
simplicity of the mfs |
miners deliver a full |
by afosr under muri |
of the mfs prefetching |
deliver a full proof |
afosr under muri grant |
the mfs prefetching implementation |
a full proof of |
full proof of work |
under muri grant f |
once with no prefetching |
the attacking pool discards |
attacking pool discards it |
and the rpcs were |
the rpcs were then |
rpcs were then divided |
this attack affects the |
were then divided acwe |
attack affects the revenues |
then divided acwe have |
affects the revenues of |
divided acwe have shown |
the revenues of the |
acwe have shown that |
revenues of the pools |
have shown that workloads |
of the pools in |
shown that workloads which |
the pools in several |
that workloads which are |
pools in several ways |
workloads which are amenable |
which are amenable to |
are amenable to file |
the victim pool s |
victim pool s effective |
pool s effective mining |
level cording to which |
s effective mining rate |
cording to which period |
effective mining rate is |
to which period of |
mining rate is unchanged |
which period of the |
period of the trace |
of the trace they |
the trace they terminated |
trace they terminated in |
but its total revenue |
its total revenue is |
total revenue is divided |
revenue is divided among |
is divided among more |
for each prefetching can |
divided among more miners |
each prefetching can achieve |
prefetching can achieve speedups |
can achieve speedups of |
the attacker s mining |
attacker s mining power |
s mining power is |
mining power is reduced |
since some of its |
some of its miners |
of its miners are |
its miners are used |
miners are used for |
are used for block |
used for block withholding |
variations in bandwidth can |
in bandwidth can occur |
bandwidth can occur without |
four quantities are calculated |
but it earns additional |
can occur without the |
it earns additional revenue |
occur without the user |
earns additional revenue through |
the time spent queued |
without the user s |
additional revenue through its |
time spent queued for |
the user s with |
revenue through its infiltration |
spent queued for as |
user s with additional |
through its infiltration of |
queued for as much |
for as much as |
its infiltration of the |
s with additional support |
infiltration of the other |
with additional support from |
of the other pool |
additional support from microsoft |
support from microsoft research |
from microsoft research and |
microsoft research and from |
research and from the |
and from the intel |
from the intel corporation |
at bandwidths as low |
bandwidths as low as |
the total effective mining |
total effective mining power |
effective mining power in |
mining power in the |
power in the system |
in the system is |
the system is reduced |
so that changing modes |
that changing modes creates |
changing modes creates unexpected |
modes creates unexpected incon |
causing the bitcoin protocol |
the bitcoin protocol to |
bitcoin protocol to reduce |
protocol to reduce the |
several clients concurrently modify |
to reduce the difficulty |
clients concurrently modify a |
concurrently modify a file |
prefetching both the rpc |
both the rpc request |
the rpc request and |
rpc request and reply |
taking all these factors |
all these factors into |
the final contents depend |
these factors into account |
final contents depend on |
and the time taken |
contents depend on the |
the time taken for |
depend on the client |
time taken for each |
we observe that a |
on the client that |
taken for each to |
observe that a pool |
the client that closed |
for each to be |
that a pool might |
client that closed it |
each to be carries |
a pool might be |
that closed it last |
to be carries a |
pool might be able |
be carries a small |
might be able to |
carries a small performance |
be able to increase |
a client can lock |
a small performance overhead |
able to increase its |
client can lock a |
to increase its revenue |
can lock a file |
increase its revenue by |
lock a file to |
even when performed at |
when performed at received |
a file to synchronise |
its revenue by attacking |
file to synchronise accesses |
revenue by attacking other |
by attacking other pools |
from the first to |
the first to the |
first to the last |
to the last packet |
the server grants the |
server grants the client |
grants the client a |
each pool therefore makes |
the client a lease |
this ignores the time |
pool therefore makes a |
ignores the time the |
therefore makes a choice |
the time the lowest |
makes a choice of |
time the lowest priority |
a choice of whether |
choice of whether to |
layered interleaving recovery percentage |
of whether to attack |
interleaving recovery percentage and |
whether to attack each |
that is renewed each |
recovery percentage and latency |
which can reduce its |
to attack each of |
is renewed each time |
percentage and latency c |
can reduce its effectiveness |
attack each of the |
renewed each time the |
reduce its effectiveness for |
each of the other |
each time the client |
its effectiveness for fast |
layered interleaving and bursty |
of the other pools |
effectiveness for fast lin |
interleaving and bursty loss |
the other pools in |
and bursty loss thus |
other pools in the |
bursty loss thus far |
pools in the system |
spent at the server |
loss thus far we |
time the client communicates |
at the server servicing |
thus far we have |
and with what infiltration |
with what infiltration rate |
the client communicates with |
the server servicing the |
server servicing the rpc |
this gives rise to |
gives rise to the |
rise to the pool |
to the pool game |
client communicates with the |
far we have shown |
we specify this game |
trip time ear scan |
time ear scan workloads |
communicates with the file |
we have shown how |
it is possible to |
is possible to construct |
with the file server |
have shown how maelstrom |
specify this game and |
possible to construct combination |
shown how maelstrom effectively |
this game and provide |
to construct combination of |
how maelstrom effectively hides |
game and provide initial |
construct combination of file |
maelstrom effectively hides loss |
and provide initial analysis |
combination of file between |
effectively hides loss from |
hides loss from tcp |
of file between the |
provide initial analysis in |
file between the client |
initial analysis in section |
analysis in section iv |
between the client and |
ip for packets dropped |
the client and the |
for packets dropped with |
client and the server |
packets dropped with uniform |
in section v we |
dropped with uniform randomness |
section v we analyze |
v we analyze the |
but these quantities are |
we analyze the scenario |
these quantities are small |
analyze the scenario where |
quantities are small groups |
the scenario where exactly |
we examine the performance |
are small groups and |
scenario where exactly two |
examine the performance of |
small groups and a |
where exactly two of |
the performance of the |
groups and a workload |
exactly two of the |
performance of the layered |
and a workload for |
two of the pools |
of the layered interleaving |
the layered interleaving algorithm |
of the pools take |
a workload for which |
the pools take part |
workload for which prefetching |
pools take part in |
showing how different parameterizations |
for which prefetching can |
take part in the |
how different parameterizations handle |
which prefetching can significantly |
part in the game |
different parameterizations handle bursty |
prefetching can significantly compared |
in the game and |
parameterizations handle bursty loss |
can significantly compared to |
the game and only |
handle bursty loss patterns |
significantly compared to the |
game and only one |
compared to the other |
to the other costs |
and only one can |
we use a loss |
only one can attack |
use a loss model |
one can attack the |
these values are added |
a loss model where |
can attack the other |
values are added up |
loss model where packets |
are added up for |
model where packets are |
added up for each |
where packets are dropped |
up for each degrade |
packets are dropped in |
for each degrade performance |
the attacker can always |
are dropped in bursts |
attacker can always increase |
dropped in bursts of |
can always increase its |
in bursts of fixed |
of the rpcs within |
always increase its revenue |
bursts of fixed length |
the rpcs within a |
increase its revenue by |
rpcs within a particular |
its revenue by attacking |
within a particular period |
allowing us to study |
us to study the |
to study the impact |
study the impact of |
the impact of burst |
we conclude that in |
impact of burst length |
and the results are |
conclude that in the |
of burst length on |
the results are shown |
that in the general |
burst length on performance |
results are shown within |
in the general case |
are shown within the |
shown within the constraints |
within the constraints imposed |
the link has a |
link has a one |
the constraints imposed by |
with any number of |
any number of pools |
constraints imposed by our |
imposed by our file |
by our file group |
our file group representa |
percentage of packets recovered |
attacks is not a |
is not a nash |
not a nash equilibrium |
section vi deals with |
vi deals with the |
deals with the case |
with the case of |
the case of two |
case of two pools |
reed solomon layered interleaving |
where each can attack |
each can attack the |
can attack the other |
analysis becomes more complicated |
becomes more complicated in |
more complicated in two |
complicated in two ways |
the revenue of each |
revenue of each pool |
of each pool affects |
each pool affects the |
pool affects the revenue |
the main conclusion we |
affects the revenue of |
main conclusion we draw |
the revenue of the |
conclusion we draw from |
revenue of the other |
we draw from the |
of the other through |
draw from the test |
the other through the |
from the test cases |
other through the infiltrating |
the test cases exhibitthe |
through the infiltrating miners |
test cases exhibitthe graphs |
cases exhibitthe graphs show |
exhibitthe graphs show how |
graphs show how priorities |
we prove that for |
show how priorities affect |
prove that for a |
how priorities affect rpcs |
that for a static |
priorities affect rpcs and |
for a static choice |
affect rpcs and how |
a static choice of |
rpcs and how prefetching |
static choice of infiltration |
and how prefetching a |
choice of infiltration rates |
how prefetching a prefetch |
of infiltration rates the |
prefetching a prefetch penalty |
infiltration rates the pool |
a prefetch penalty is |
rates the pool revenues |
the pool revenues converge |
prefetch penalty is that |
penalty is that the |
is that the implementation |
that the implementation could |
the implementation could be |
implementation could be im |
once one pool changes |
ing changes mfs behaviour |
one pool changes its |
pool changes its infiltration |
changes its infiltration rate |
its infiltration rate of |
infiltration rate of the |
rate of the other |
in all three time |
all three time periods |
the latter may prefer |
latter may prefer to |
may prefer to change |
more time proved to |
prefer to change its |
to change its infiltration |
change its infiltration rate |
its infiltration rate of |
time proved to incorporate |
infiltration rate of the |
rate of the former |
proved to incorporate a |
to incorporate a mechanism |
incorporate a mechanism to |
a mechanism to inhibit |
therefore the game itself |
mechanism to inhibit prefetching |
the game itself takes |
game itself takes multiple |
itself takes multiple rounds |
takes multiple rounds to |
multiple rounds to converge |
the is spent on |
is spent on rpcs |
we show analytically that |
spent on rpcs to |
show analytically that the |
on rpcs to fetch |
analytically that the game |
rpcs to fetch file |
that the game has |
to fetch file attributes |
the game has a |
solomon versus layered interleaving |
fetch file attributes with |
game has a single |
file attributes with prefetching |
versus layered interleaving latency |
attributes with prefetching enabled |
has a single nash |
with prefetching enabled current |
layered interleaving latency of |
a single nash equilibrium |
prefetching enabled current prefetching |
single nash equilibrium and |
enabled current prefetching algorithm |
nash equilibrium and numerically |
current prefetching algorithm does |
equilibrium and numerically study |
prefetching algorithm does not |
and numerically study the |
ms and a loss |
and a loss rate |
a loss rate of |
algorithm does not correlate |
numerically study the equilibrium |
does not correlate file |
study the equilibrium points |
not correlate file accesses |
the equilibrium points for |
correlate file accesses with |
equilibrium points for different |
file accesses with than |
points for different pool |
accesses with than without |
for different pool sizes |
since the time to |
for pools smaller than |
the time to receive |
time to receive a |
to receive a fetch |
attributes request the processes |
request the processes which |
the processes which make |
processes which make them |
where it is varied |
but if this were |
if this were done |
at the equilibrium point |
the equilibrium point both |
equilibrium point both pools |
two changes or reply |
point both pools earn |
changes or reply is |
both pools earn less |
or reply is negligible |
pools earn less than |
earn less than they |
less than they would |
than they would have |
they would have in |
mbps flow of udp |
the increased time is |
would have in the |
flow of udp packets |
increased time is due |
have in the nonequilibrium |
of udp packets is |
time is due to |
in the nonequilibrium no |
udp packets is sent |
is due to a |
packets is sent over |
due to a greater |
is sent over it |
to a greater queue |
since pools can decide |
pools can decide to |
rpc times at intermediate |
can decide to start |
times at intermediate bandwidth |
we show that our |
decide to start or |
show that our observation |
to start or stop |
that our observation in |
start or stop attacking |
our observation in section |
or stop attacking at |
observation in section iv |
stop attacking at any |
attacking at any point |
e is correct for |
is correct for high |
this can be modeled |
correct for high loss |
can be modeled as |
for high loss rates |
be modeled as the |
high loss rates if |
modeled as the miner |
loss rates if the |
as the miner s |
rates if the interleaves |
the miner s dilemma |
if the interleaves are |
miner s dilemma an |
the interleaves are relatively |
s dilemma an instance |
interleaves are relatively prime |
dilemma an instance of |
an instance of the |
instance of the iterative |
of the iterative prisoner |
the iterative prisoner s |
iterative prisoner s dilemma |
performance improves substantially when |
improves substantially when loss |
substantially when loss rates |
when loss rates are |
loss rates are high |
attacking is the dominant |
rates are high and |
is the dominant strategy |
are high and losses |
the dominant strategy in |
high and losses are |
and losses are bursty |
dominant strategy in each |
strategy in each iteration |
the graph plots the |
graph plots the percentage |
but if the pools |
plots the percentage of |
if the pools can |
the percentage of lost |
the pools can agree |
percentage of lost packets |
pools can agree not |
of lost packets successfully |
can agree not to |
lost packets successfully recovered |
agree not to attack |
packets successfully recovered on |
successfully recovered on the |
recovered on the y |
both benefit in the |
benefit in the long |
in the long run |
axis against an xaxis |
against an xaxis of |
an xaxis of loss |
xaxis of loss rates |
of loss rates on |
loss rates on a |
rates on a log |
on a log scale |
we address in section |
address in section vii |
the maelstrom configuration used |
in section vii the |
maelstrom configuration used is |
section vii the case |
configuration used is r |
vii the case where |
the case where the |
case where the participants |
where the participants are |
the participants are an |
participants are an arbitrary |
are an arbitrary number |
an arbitrary number of |
arbitrary number of identical |
number of identical pools |
there exists a symmetric |
exists a symmetric equilibrium |
a symmetric equilibrium in |
symmetric equilibrium in which |
equilibrium in which each |
in which each participating |
which each participating pool |
each participating pool attacks |
participating pool attacks each |
pool attacks each of |
attacks each of the |
each of the other |
of the other participating |
the other participating pools |
as in the minority |
in the minority two |
here too at equilibrium |
too at equilibrium all |
at equilibrium all pools |
equilibrium all pools earn |
all pools earn less |
pools earn less than |
earn less than with |
less than with the |
than with the no |
our results imply that |
results imply that block |
imply that block withholding |
that block withholding by |
block withholding by pools |
withholding by pools leads |
by pools leads to |
pools leads to an |
leads to an unfavorable |
to an unfavorable equilibrium |
due to the anonymity |
to the anonymity of |
the anonymity of miners |
adaptive remote procedure call |
a single pool might |
single pool might be |
pool might be tempted |
might be tempted to |
remote procedure call figure |
be tempted to attack |
leading the other pools |
the other pools to |
other pools to attack |
pools to attack as |
to attack as well |
we show the ability |
the implications might be |
show the ability of |
implications might be devastating |
the ability of layered |
might be devastating for |
be devastating for open |
devastating for open pools |
ability of layered interleaving |
of layered interleaving to |
layered interleaving to provide |
interleaving to provide gracefully |
to provide gracefully degrading |
if their revenues are |
their revenues are reduced |
provide gracefully degrading performance |
gracefully degrading performance in |
time series of wireless |
miners will prefer to |
degrading performance in the |
performance in the face |
series of wireless bandwidth |
will prefer to form |
in the face of |
u trsu t u |
prefer to form closed |
the face of bursty |
trsu t u trsu |
to form closed pools |
face of bursty loss |
t u trsu t |
form closed pools that |
u trsu t utrsut |
closed pools that cannot |
pools that cannot be |
that cannot be attacked |
cannot be attacked in |
be attacked in this |
attacked in this manner |
mafs uses adaptive remote |
request queued request send |
though this may be |
queued request send reply |
uses adaptive remote procedure |
this may be conceived |
we plot the percentage |
request send reply queued |
adaptive remote procedure call |
may be conceived as |
plot the percentage of |
send reply queued reply |
remote procedure call for |
be conceived as bad |
the percentage of lost |
reply queued reply send |
procedure call for client |
conceived as bad news |
percentage of lost packets |
as bad news for |
of lost packets successfully |
bad news for public |
lost packets successfully recovered |
news for public mining |
packets successfully recovered against |
for public mining pools |
successfully recovered against the |
recovered against the length |
against the length of |
the length of loss |
length of loss bursts |
on the whole it |
of loss bursts for |
the whole it may |
loss bursts for two |
whole it may be |
bursts for two different |
it may be good |
for two different sets |
may be good news |
two different sets of |
be good news to |
different sets of interleaves |
good news to the |
news to the bitcoin |
to the bitcoin system |
and in the bottom |
in the bottom graph |
which prefers small pools |
the bottom graph we |
bottom graph we plot |
graph we plot the |
we plot the average |
plot the average latency |
the average latency at |
we examine the practicality |
average latency at which |
examine the practicality of |
latency at which the |
the practicality of the |
at which the packets |
practicality of the attack |
which the packets were |
of the attack in |
the packets were recovered |
the attack in section |
attack in section viii |
in section viii and |
section viii and discuss |
viii and discuss implications |
and discuss implications and |
recovery latency is defined |
discuss implications and model |
latency is defined as |
implications and model extensions |
is defined as the |
and model extensions in |
defined as the difference |
model extensions in section |
as the difference between |
extensions in section ix |
the difference between the |
difference between the eventual |
between the eventual delivery |
the eventual delivery time |
eventual delivery time of |
delivery time of the |
time of the recovered |
adaptation based on low |
of the recovered packet |
our contributions are the |
the recovered packet and |
contributions are the following |
recovered packet and the |
packet and the oneway |
and the oneway latency |
the oneway latency of |
oneway latency of the |
latency of the link |
we confirmed that the |
confirmed that the emulab |
that the emulab link |
the emulab link had |
definition of the pool |
emulab link had almost |
of the pool game |
link had almost no |
the pool game where |
had almost no jitter |
pool game where pools |
almost no jitter on |
game where pools in |
no jitter on correctly |
where pools in a |
pools in a proof |
jitter on correctly delivered |
on correctly delivered packets |
ofwork secured system attack |
secured system attack one |
system attack one another |
attack one another with |
one another with a |
another with a pool |
with a pool block |
way latency an accurate |
a pool block withholding |
pool block withholding attack |
latency an accurate estimate |
an accurate estimate of |
accurate estimate of expected |
estimate of expected lossless |
of expected lossless delivery |
expected lossless delivery time |
adaptive rpc is based |
rpc is based on |
in the general case |
is based on our |
increasing the interleaves results |
the interleaves results in |
interleaves results in much |
results in much higher |
rpc times at high |
based on our earlier |
in much higher recovery |
times at high bandwidth |
attacks is not an |
is not an equilibrium |
on our earlier work |
much higher recovery percentages |
higher recovery percentages at |
recovery percentages at large |
percentages at large burst |
our earlier work in |
at large burst sizes |
with two minority pools |
earlier work in modes |
two minority pools participating |
work in modes can |
but comes at the |
comes at the cost |
the only nash equilibrium |
only nash equilibrium is |
at the cost of |
the cost of higher |
in modes can be |
cost of higher recovery |
of higher recovery latency |
modes can be ill |
nash equilibrium is when |
equilibrium is when the |
is when the pools |
when the pools attack |
the pools attack one |
pools attack one another |
and both earn less |
both earn less than |
earn less than if |
less than if none |
than if none had |
if none had attacked |
suited to situations where |
miners therefore face the |
therefore face the miner |
to situations where bandwidth |
face the miner s |
the miner s dilemma |
situations where bandwidth is |
where bandwidth is not |
an instance of the |
instance of the iterative |
bandwidth is not network |
of the iterative prisoner |
set of interleaves catches |
the iterative prisoner s |
of interleaves catches almost |
iterative prisoner s dilemma |
interleaves catches almost all |
catches almost all packets |
almost all packets in |
all packets in an |
packets in an extended |
in an extended burst |
repeatedly choosing between attack |
an extended burst of |
choosing between attack and |
between attack and no |
packets at an average |
at an average latency |
an average latency of |
average latency of around |
with multiple pools of |
multiple pools of equal |
pools of equal size |
of equal size there |
equal size there is |
size there is a |
there is a symmetric |
while repairing all random |
is a symmetric nash |
repairing all random singleton |
a symmetric nash equilibrium |
all random singleton losses |
random singleton losses within |
where all pools earn |
all pools earn less |
pools earn less than |
earn less than if |
less than if none |
than if none had |
if none had attacked |
the graphs also show |
graphs also show recovery |
also show recovery latency |
show recovery latency rising |
recovery latency rising gracefully |
latency rising gracefully with |
rising gracefully with the |
gracefully with the increase |
with the increase in |
the increase in loss |
increase in loss burst |
in loss burst length |
inefficient equilibria for open |
equilibria for open pools |
the longer the burst |
for open pools may |
open pools may serve |
pools may serve the |
may serve the system |
the longer it takes |
longer it takes to |
serve the system by |
the system by reducing |
it takes to recover |
takes to recover the |
and differs from severely |
to recover the lost |
recover the lost packets |
differs from severely constrained |
system by reducing their |
the maelstrom configuration used |
by reducing their attraction |
maelstrom configuration used is |
reducing their attraction and |
configuration used is r |
their attraction and pushing |
attraction and pushing miners |
and pushing miners towards |
pushing miners towards smaller |
miners towards smaller closed |
towards smaller closed pools |
the classical block withholding |
classical block withholding attack |
block withholding attack is |
withholding attack is old |
attack is old as |
is old as pools |
old as pools themselves |
but insufficient for a |
but its use by |
its use by pools |
use by pools has |
insufficient for a client |
by pools has not |
pools has not been |
has not been suggested |
for a client to |
not been suggested until |
been suggested until recently |
a client to ignore |
client to ignore it |
we overview related attacks |
overview related attacks and |
related attacks and prior |
attacks and prior work |
and prior work in |
prior work in section |
work in section x |
to ignore it a |
ignore it a typical |
and conclude with final |
conclude with final remarks |
with final remarks in |
final remarks in section |
remarks in section xi |
it a typical rpc |
a typical rpc system |
typical rpc system in |
p reliminaries b itcoin |
rpc system in allowing |
reliminaries b itcoin and |
system in allowing applications |
b itcoin and p |
itcoin and p ooled |
and p ooled m |
p ooled m ining |
ooled m ining bitcoin |
m ining bitcoin is |
ining bitcoin is a |
bitcoin is a distributed |
in allowing applications to |
allowing applications to control |
applications to control how |
to control how concurrent |
control how concurrent rpcs |
how concurrent rpcs are |
we show histograms of |
show histograms of recovery |
histograms of recovery latencies |
of recovery latencies for |
recovery latencies for the |
latencies for the two |
for the two interleave |
the two interleave configurations |
two interleave configurations under |
interleave configurations under different |
configurations under different burst |
under different burst lengths |
concurrent rpcs are transmitted |
the histograms confirm the |
histograms confirm the trends |
confirm the trends described |
the trends described above |
packet recoveries take longer |
recoveries take longer from |
take longer from left |
longer from left to |
from left to right |
left to right as |
to right as we |
right as we increase |
as we increase loss |
we increase loss burst |
increase loss burst length |
and special handling for |
special handling for failwhen |
and from top to |
from top to bottom |
top to bottom as |
to bottom as we |
bottom as we increase |
as we increase the |
we increase the interleave |
increase the interleave values |
handling for failwhen deciding |
for failwhen deciding what |
failwhen deciding what to |
clients use the system |
use the system by |
illustrates the difference between |
the system by issuing |
system by issuing transactions |
the difference between a |
difference between a traditional |
between a traditional fec |
a traditional fec code |
traditional fec code and |
and the system s |
deciding what to send |
fec code and layered |
the system s only |
what to send over |
code and layered interleaving |
system s only task |
to send over the |
and layered interleaving by |
s only task is |
send over the network |
layered interleaving by plotting |
only task is to |
interleaving by plotting a |
task is to serialize |
is to serialize transactions |
to serialize transactions in |
serialize transactions in a |
transactions in a single |
in a single ledger |
a single ledger and |
single ledger and reject |
ledger and reject transactions |
and reject transactions that |
reject transactions that cannot |
transactions that cannot be |
ures due to insufficient |
that cannot be serialized |
cannot be serialized due |
be serialized due to |
serialized due to conflicts |
due to conflicts with |
to conflicts with previous |
conflicts with previous transactions |
due to insufficient bandwidth |
bitcoin transactions are protected |
transactions are protected with |
are protected with cryptographic |
protected with cryptographic techniques |
with cryptographic techniques that |
cryptographic techniques that ensure |
techniques that ensure that |
that ensure that only |
ensure that only the |
that only the rightful |
only the rightful owner |
the rightful owner of |
rightful owner of a |
owner of a bitcoin |
of a bitcoin can |
a bitcoin can transfer |
bitcoin can transfer it |
adaptive rpc requests and |
rpc requests and replies |
the transaction ledger is |
transaction ledger is stored |
ledger is stored by |
is stored by a |
stored by a network |
by a network of |
a network of miners |
network of miners in |
of miners in a |
miners in a data |
in a data structure |
a data structure caller |
data structure caller the |
structure caller the blockchain |
requests and replies can |
and replies can contain |
replies can contain an |
revenue for proof of |
for proof of work |
proof of work the |
of work the blockchain |
work the blockchain records |
the blockchain records the |
blockchain records the transactions |
records the transactions in |
the transactions in units |
transactions in units of |
can contain an arbitrary |
in units of blocks |
contain an arbitrary amount |
an arbitrary amount of |
arbitrary amount of data |
dubbed the genesis block |
is defined as part |
defined as part of |
as part of the |
part of the protocol |
a valid block contains |
valid block contains the |
block contains the hash |
contains the hash of |
the hash of the |
hash of the previous |
a sender also attaches |
of the previous block |
sender also attaches a |
also attaches a priority |
the hash of the |
hash of the transactions |
of the transactions in |
the transactions in the |
transactions in the current |
in the current block |
attaches a priority and |
a priority and timeout |
and a bitcoin address |
a bitcoin address which |
bitcoin address which is |
address which is to |
which is to be |
is to be credited |
to be credited with |
priority and timeout to |
be credited with a |
credited with a reward |
with a reward for |
and timeout to the |
a reward for generating |
reward for generating the |
for generating the block |
timeout to the send |
to the send operation |
any miner may add |
miner may add a |
may add a valid |
add a valid block |
a valid block to |
valid block to the |
block to the chain |
to the chain by |
proving that it has |
that it has spent |
it has spent a |
has spent a certain |
spent a certain amount |
a certain amount of |
certain amount of work |
amount of work and |
of work and publishing |
work and publishing the |
and publishing the block |
publishing the block with |
the block with the |
block with the proof |
with the proof over |
the proof over an |
proof over an overlay |
over an overlay network |
an overlay network to |
overlay network to all |
network to all other |
to all other miners |
file system overview rover |
system overview rover queued |
when a miner creates |
a miner creates a |
overview rover queued rpc |
miner creates a block |
it is compensated for |
is compensated for its |
compensated for its efforts |
for its efforts with |
its efforts with bitcoins |
this compensation includes a |
compensation includes a per |
transaction fee paid by |
fee paid by the |
paid by the users |
by the users whose |
the users whose transactions |
users whose transactions are |
whose transactions are included |
and an amount of |
an amount of minted |
amount of minted bitcoins |
of minted bitcoins that |
minted bitcoins that are |
bitcoins that are thus |
that are thus introduced |
are thus introduced into |
thus introduced into the |
introduced into the system |
the work which a |
work which a miner |
which a miner is |
a miner is required |
miner is required to |
is required to do |
required to do is |
to do is to |
do is to repeatedly |
is to repeatedly calculate |
to repeatedly calculate a |
repeatedly calculate a a |
calculate a a hash |
a a hash function |
a hash function specifically |
hash function specifically the |
function specifically the sha |
an adaptive rpc can |
adaptive rpc can be |
rpc can be asynchronous |
of a block header |
to indicate that he |
indicate that he has |
that he has performed |
he has performed this |
has performed this work |
adaptive mobile file system |
the miner provides a |
miner provides a probabilistic |
provides a probabilistic proof |
a probabilistic proof as |
probabilistic proof as follows |
the generated block has |
generated block has a |
block has a nonce |
has a nonce field |
is a distributed file |
which can contain any |
can contain any value |
a distributed file sys |
the miner places different |
miner places different values |
places different values in |
different values in this |
values in this field |
in this field and |
this field and calculates |
field and calculates the |
and calculates the hash |
calculates the hash for |
the hash for each |
hash for each value |
so that an application |
if the result of |
the result of the |
result of the hash |
of the hash is |
the hash is smaller |
hash is smaller than |
is smaller than a |
smaller than a target |
than a target value |
that an application need |
an application need not |
the nonce is considered |
nonce is considered a |
application need not block |
is considered a solution |
need not block waiting |
not block waiting for |
and the block is |
the block is valid |
block waiting for the |
waiting for the result |
the number of attempts |
number of attempts to |
of attempts to find |
attempts to find a |
to find a single |
find a single hash |
a single hash is |
single hash is therefore |
hash is therefore random |
is therefore random with |
therefore random with a |
random with a geometric |
with a geometric distribution |
as each attempt is |
each attempt is a |
attempt is a bernoulli |
intem designed to support |
is a bernoulli trial |
a bernoulli trial with |
bernoulli trial with a |
designed to support efficient |
trial with a success |
with a success probability |
a success probability determined |
success probability determined by |
probability determined by the |
determined by the target |
by the target value |
to support efficient access |
support efficient access to |
at the existing huge |
the existing huge hashing |
existing huge hashing rates |
huge hashing rates and |
hashing rates and small |
rates and small target |
and small target values |
efficient access to a |
access to a remote |
the time to find |
time to find a |
to find a single |
find a single hash |
a single hash can |
single hash can be |
hash can be approximated |
can be approximated by |
be approximated by an |
approximated by an exponential |
by an exponential distribution |
to a remote file |
a remote file server |
remote file server stead |
the average time for |
average time for a |
time for a miner |
for a miner to |
a miner to find |
miner to find a |
to find a solution |
find a solution is |
a solution is therefore |
latency histograms for i |
solution is therefore proportional |
the library makes an |
is therefore proportional to |
therefore proportional to its |
proportional to its hashing |
to its hashing rate |
its hashing rate or |
hashing rate or mining |
rate or mining power |
library makes an upcall |
makes an upcall when |
an upcall when the |
to maintain a constant |
maintain a constant rate |
a constant rate of |
constant rate of bitcoin |
rate of bitcoin generation |
upcall when the reply |
when the reply arrives |
request queued request send |
and as part of |
queued request send reply |
as part of its |
request send reply queued |
part of its defense |
send reply queued reply |
of its defense against |
reply queued reply send |
its defense against denial |
defense against denial of |
against denial of service |
since an application can |
denial of service and |
an application can perform |
of service and other |
application can perform multiple |
service and other attacks |
can perform multiple rpcs |
perform multiple rpcs concurby |
e dd e dd |
the system normalizes the |
system normalizes the rate |
dd e dd f |
multiple rpcs concurby mobile |
normalizes the rate of |
e dd f edd |
dd f edd f |
the rate of block |
rate of block generation |
rpcs concurby mobile clients |
f edd f g |
edd f g fg |
f g fg e |
g fg e ed |
fg e ed e |
concurby mobile clients that |
e ed e e |
the protocol deterministically defines |
protocol deterministically defines the |
ed e e d |
e e d f |
deterministically defines the target |
mobile clients that must |
e d f eed |
defines the target value |
the target value for |
d f eed f |
f eed f g |
target value for each |
value for each block |
eed f g fg |
f g fg e |
for each block according |
each block according to |
g fg e d |
fg e d e |
e d e d |
d e d f |
block according to the |
according to the time |
to the time required |
the time required to |
time required to generate |
required to generate recent |
clients that must cope |
to generate recent blocks |
that must cope with |
must cope with variations |
cope with variations in |
with variations in available |
variations in available bandwidth |
is updated once every |
the mafs design and |
mafs design and terminology |
design and terminology are |
and terminology are similar |
terminology are similar to |
blocks such that the |
such that the average |
that the average time |
the average time for |
average time for each |
time for each block |
for each block to |
each block to be |
block to be found |
bcq pcb c bq |
to be found is |
are similar to rently |
pcb c bq pcb |
c bq pcb cbqpcb |
bq pcb cbqpcb n |
pcb cbqpcb n n |
cbqpcb n n on |
n n on n |
n on n c |
on n c bc |
n c bc bonn |
c bc bonn c |
bc bonn c bc |
bonn c bc b |
note that the exponential |
adaptive rpc schedules their |
c bc b cbcb |
that the exponential distribution |
the exponential distribution is |
exponential distribution is memoryless |
rpc schedules their transmission |
if all miners mine |
all miners mine for |
miners mine for block |
mine for block number |
for block number b |
this corresponds to allocating |
once the block is |
the block is found |
block is found at |
corresponds to allocating bandwidth |
is found at time |
c bc b cbcb |
to allocating bandwidth among |
found at time t |
allocating bandwidth among the |
bandwidth among the competing |
among the competing rpcs |
all miners switch to |
miners switch to mine |
switch to mine for |
to mine for the |
mine for the subsequent |
for the subsequent block |
the subsequent block b |
the andrew file system |
c bc b cbcb |
at t without changing |
t without changing their |
without changing their probability |
changing their probability distribution |
their probability distribution of |
probability distribution of finding |
distribution of finding a |
of finding a block |
finding a block after |
a block after t |
c bc b cbcb |
the probability that a |
probability that a miner |
that a miner i |
a miner i with |
miner i with mining |
i with mining power |
with mining power mi |
mining power mi finds |
power mi finds the |
latency histograms for i |
mi finds the next |
finds the next block |
the next block is |
next block is its |
block is its ratio |
is its ratio out |
its ratio out of |
ratio out of the |
out of the total |
c b cb a |
of the total mining |
b cb a a |
the total mining power |
cb a a k |
total mining power m |
a a k k |
mining power m in |
a k k j |
k k j jk |
power m in the |
m in the system |
miner miner miner pool |
c bc b cbcb |
bc b cbcb kk |
b cbcb kk j |
cbcb kk j m |
miner miner miner pool |
attaching priorities to rpcs |
kk j m lkjj |
j m lkjj ml |
m lkjj ml ml |
lkjj ml ml c |
ml ml c b |
ml c b c |
c b c b |
b c b cb |
c b cb kj |
b cb kj ih |
cb kj ih i |
kj ih i h |
ih i h ih |
i h ih j |
priorities to rpcs allows |
to rpcs allows applications |
rpcs allows applications to |
allows applications to control |
applications to control this |
to control this scheduling |
control this scheduling policy |
a programmer divides rpcs |
programmer divides rpcs into |
divides rpcs into classes |
moving average of recovery |
average of recovery latencies |
of recovery latencies for |
recovery latencies for both |
latencies for both codes |
and one miner mines |
one miner mines solo |
the channel is configured |
c bc b c |
channel is configured to |
bc b c bc |
is configured to lose |
b c bc b |
configured to lose singleton |
pools datacenters are built |
c bc b cbcb |
to lose singleton packets |
datacenters are built around |
bc b cbcb rpc |
lose singleton packets randomly |
are built around the |
b cbcb rpc times |
singleton packets randomly at |
built around the world |
cbcb rpc times at |
packets randomly at a |
rpc times at low |
file access model based |
times at low bandwidth |
randomly at a loss |
at a loss rate |
a loss rate of |
access model based on |
model based on the |
based on the importance |
request queued request send |
queued request send reply |
mining is only profitable |
request send reply queued |
send reply queued reply |
is only profitable using |
only profitable using dedicated |
on the importance of |
and additionally lose long |
reply queued reply send |
profitable using dedicated hardware |
using dedicated hardware in |
additionally lose long bursts |
queued reply send total |
reply send total time |
dedicated hardware in cutting |
lose long bursts of |
the importance of their |
hardware in cutting edge |
in cutting edge mining |
cutting edge mining rigs |
importance of their results |
packets at occasional intervals |
otherwise the energy costs |
the energy costs exceed |
energy costs exceed the |
of their results to |
costs exceed the expected |
exceed the expected revenue |
their results to the |
both codes are configured |
codes are configured with |
are configured with r |
although expected revenue from |
expected revenue from mining |
revenue from mining is |
from mining is proportional |
mining is proportional to |
is proportional to the |
proportional to the power |
to the power of |
the power of the |
power of the mining |
of the mining rigs |
the mining rigs used |
results to the user |
a single home miner |
single home miner using |
and recover all lost |
home miner using a |
recover all lost packets |
miner using a small |
all lost packets reedsolomon |
using a small rig |
lost packets reedsolomon uses |
a small rig is |
small rig is unlikely |
packets reedsolomon uses an |
reedsolomon uses an interleave |
uses an interleave of |
and then mafs clients |
rig is unlikely to |
is unlikely to mine |
unlikely to mine a |
to mine a block |
mine a block for |
and layered interleaving uses |
a block for years |
then mafs clients use |
layered interleaving uses interleaves |
interleaving uses interleaves of |
mafs clients use whole |
miners often organize themselves |
often organize themselves into |
organize themselves into mining |
themselves into mining pools |
rpc traffic with varying |
traffic with varying bandwidth |
when a file is |
and consequently both have |
consequently both have a |
both have a maximum |
have a maximum tolerable |
a pool is a |
a file is accessed |
a maximum tolerable burst |
pool is a group |
is a group of |
maximum tolerable burst length |
tolerable burst length of |
a group of miners |
file is accessed assigns |
group of miners that |
of miners that share |
miners that share their |
that share their revenues |
share their revenues when |
their revenues when one |
revenues when one of |
when one of them |
is accessed assigns priorities |
show the time spent |
one of them successfully |
we use a publicly |
use a publicly available |
the time spent on |
of them successfully mines |
them successfully mines a |
successfully mines a block |
time spent on rpcs |
spent on rpcs during |
a publicly available implementation |
publicly available implementation of |
for each block found |
accessed assigns priorities to |
available implementation of a |
implementation of a reed |
assigns priorities to the |
on rpcs during an |
solomon code based on |
code based on vandermonde |
based on vandermonde matrices |
rpcs during an execution |
during an execution of |
the revenue is distributed |
revenue is distributed among |
an execution of the |
execution of the simultaneous |
is distributed among the |
distributed among the pool |
of the simultaneous writeback |
the simultaneous writeback test |
among the pool members |
the pool members in |
simultaneous writeback test from |
writeback test from section |
pool members in proportion |
members in proportion to |
in proportion to their |
proportion to their mining |
to their mining power |
priorities to the classes |
the code is plugged |
code is plugged into |
is plugged into maelstrom |
plugged into maelstrom instead |
into maelstrom instead of |
maelstrom instead of layered |
instead of layered interleaving |
the expected revenue of |
expected revenue of a |
with the bandwidth varying |
revenue of a pool |
the bandwidth varying according |
showing that we can |
of a pool member |
a pool member is |
bandwidth varying according to |
that we can use |
we can use new |
pool member is therefore |
varying according to the |
according to the curve |
to the curve in |
member is therefore the |
is therefore the same |
can use new encodings |
use new encodings within |
therefore the same as |
the same as its |
new encodings within the |
encodings within the same |
same as its revenue |
as its revenue had |
its revenue had it |
revenue had it mined |
had it mined solo |
rpcs are labelled as |
are labelled as follows |
within the same framework |
the same framework seamlessly |
the library schedules rpcs |
library schedules rpcs for |
due to the large |
to the large power |
the large power of |
large power of the |
solomon code recovers all |
power of the pool |
code recovers all lost |
schedules rpcs for the |
recovers all lost packets |
rpcs for the first |
it finds blocks at |
all lost packets with |
for the first time |
finds blocks at a |
lost packets with roughly |
blocks at a much |
packets with roughly the |
at a much higher |
with roughly the same |
a much higher rate |
roughly the same latency |
the same latency whereas |
same latency whereas layered |
latency whereas layered interleaving |
and so the frequency |
so the frequency of |
whereas layered interleaving recovers |
demand fetch to raise |
fetch to raise priority |
to raise priority of |
layered interleaving recovers singleton |
a client fetches the |
the frequency of revenue |
client fetches the entire |
interleaving recovers singleton losses |
fetches the entire file |
frequency of revenue collection |
the entire file from |
recovers singleton losses almost |
entire file from the |
of revenue collection is |
raise priority of a |
singleton losses almost immediately |
losses almost immediately and |
revenue collection is higher |
priority of a prefetch |
of a prefetch rpc |
almost immediately and exhibits |
immediately and exhibits latency |
allowing for a stable |
and exhibits latency spikes |
exhibits latency spikes whenever |
for a stable daily |
a stable daily or |
latency spikes whenever the |
spikes whenever the longer |
stable daily or weekly |
daily or weekly income |
whenever the longer loss |
the longer loss burst |
longer loss burst occurs |
file from the file |
the time spent on |
time spent on rpcs |
spent on rpcs is |
most pools are controlled |
pools are controlled by |
on rpcs is shown |
rpcs is shown with |
are controlled by a |
r elated w ork |
from the file based |
is shown with prefetching |
controlled by a centralized |
elated w ork maelstrom |
the file based on |
shown with prefetching enabled |
by a centralized pool |
w ork maelstrom lies |
file based on priorities |
a centralized pool manager |
ork maelstrom lies in |
based on priorities whenever |
maelstrom lies in the |
on priorities whenever there |
lies in the intersection |
miners register with the |
register with the pool |
in the intersection of |
priorities whenever there is |
with the pool manager |
the intersection of two |
intersection of two research |
the pool manager and |
pool manager and mine |
of two research areas |
two research areas that |
manager and mine on |
and mine on its |
mine on its behalf |
note that rpc interactions |
whenever there is insufficient |
research areas that have |
the pool manager generates |
there is insufficient bandwidth |
that rpc interactions can |
areas that have seen |
pool manager generates tasks |
is insufficient bandwidth to |
rpc interactions can overlap |
that have seen major |
manager generates tasks and |
generates tasks and the |
interactions can overlap so |
have seen major innovations |
seen major innovations in |
tasks and the miners |
can overlap so the |
overlap so the quantities |
major innovations in the |
and the miners search |
the miners search for |
so the quantities for |
innovations in the last |
in the last decade |
miners search for solutions |
the quantities for different |
quantities for different rpc |
the last decade high |
search for solutions based |
for solutions based on |
for different rpc types |
different rpc types are |
solutions based on these |
based on these tasks |
rpc types are not |
types are not additive |
on these tasks that |
these tasks that can |
haul communication and forward |
communication and forward error |
for some rpc types |
insufficient bandwidth to server |
tasks that can serve |
the time spent on |
time spent on particular |
and forward error correction |
that can serve as |
can serve as proof |
serve as proof of |
as proof of work |
spent on particular activities |
on particular activities is |
particular activities is negligible |
activities is negligible in |
ip variants such as |
variants such as compound |
such as compound tcp |
bandwidth to server and |
once they find a |
they find a solution |
to server and caches |
is negligible in proportion |
they send it to |
negligible in proportion to |
in proportion to the |
send it to the |
it to the pool |
proportion to the overall |
to the overall time |
to the pool manager |
server and caches it |
the pool manager behaves |
pool manager behaves as |
manager behaves as a |
behaves as a single |
as a single miner |
a single miner in |
single miner in the |
miner in the bitcoin |
in the bitcoin system |
attribute requests are small |
use transmission delay to |
requests are small and |
transmission delay to detect |
delay to detect backed |
are small and have |
once it obtains a |
it obtains a legitimate |
to detect backed up |
small and have a |
and have a very |
obtains a legitimate block |
detect backed up routers |
mafs only sends the |
have a very low |
replacing or supplementing packet |
or supplementing packet loss |
a legitimate block from |
a very low transmission |
very low transmission time |
supplementing packet loss as |
legitimate block from one |
block from one of |
low transmission time relative |
packet loss as a |
loss as a signal |
from one of its |
transmission time relative to |
time relative to their |
as a signal of |
one of its miners |
only sends the server |
relative to their queueing |
to their queueing delays |
sends the server the |
a signal of congestion |
such users happen to |
the block transfers the |
block transfers the revenue |
users happen to be |
happen to be working |
transfers the revenue to |
while such protocols solve |
such protocols solve the |
to be working on |
the revenue to the |
revenue to the control |
protocols solve the congestion |
be working on the |
working on the same |
to the control of |
solve the congestion collapse |
the congestion collapse experienced |
on the same element |
the control of the |
control of the pool |
of the pool manager |
the same element of |
same element of the |
element of the design |
the server the contents |
the pool manager then |
congestion collapse experienced by |
collapse experienced by conventional |
experienced by conventional tcp |
it is clear that |
is clear that satisfying |
pool manager then distributes |
manager then distributes the |
clear that satisfying a |
that satisfying a request |
then distributes the revenue |
distributes the revenue among |
satisfying a request from |
a request from stale |
the revenue among the |
revenue among the miners |
request from stale data |
server the contents transmit |
among the miners according |
whether in from the |
in from the cache |
they cannot mitigate the |
the miners according to |
miners according to their |
according to their mining |
to their mining power |
cannot mitigate the longer |
or on a server |
on a server that |
mitigate the longer packet |
the architecture is illustrated |
a server that has |
the longer packet delivery |
longer packet delivery latencies |
architecture is illustrated in |
server that has yet |
that has yet to |
packet delivery latencies caused |
is illustrated in figure |
the contents transmit competing |
has yet to see |
delivery latencies caused by |
latencies caused by packet |
caused by packet loss |
in order to estimate |
order to estimate the |
yet to see a |
to see a delayed |
to estimate the mining |
estimate the mining power |
see a delayed writeback |
and they do not |
they do not eliminate |
the mining power of |
mining power of a |
power of a miner |
contents transmit competing rpcs |
would be visible to |
the pool manager sets |
pool manager sets a |
do not eliminate the |
be visible to the |
visible to the user |
to the user and |
the user and costly |
transmit competing rpcs without |
manager sets a partial |
not eliminate the need |
eliminate the need for |
sets a partial target |
a partial target for |
strong cache consistency is |
cache consistency is certainly |
the need for larger |
partial target for each |
target for each member |
consistency is certainly achievable |
need for larger buffers |
for larger buffers at |
larger buffers at end |
competing rpcs without a |
is certainly achievable in |
certainly achievable in distributed |
achievable in distributed file |
rpcs without a noticeable |
fec has seen major |
in distributed file systems |
without a noticeable delay |
has seen major innovations |
seen major innovations in |
major innovations in the |
innovations in the last |
in the last fifteen |
the last fifteen years |
than the target of |
the target of the |
target of the bitcoin |
of the bitcoin system |
rpcs of a modified |
level fec was first |
each miner is required |
miner is required to |
fec was first described |
was first described for |
but must be implemented |
is required to send |
of a modified file |
first described for high |
must be implemented with |
required to send the |
to send the pool |
be implemented with synchronous |
speed wan networks as |
a modified file when |
implemented with synchronous rpcs |
send the pool manager |
wan networks as early |
networks as early as |
the pool manager blocks |
pool manager blocks that |
and requires either readers |
modified file when it |
manager blocks that are |
requires either readers or |
file when it is |
blocks that are correct |
either readers or writers |
readers or writers to |
that are correct according |
are correct according to |
or writers to incur |
when it is closed |
correct according to the |
writers to incur a |
to incur a delay |
according to the partial |
to the partial target |
incur a delay to |
a delay to ensure |
delay to ensure that |
to ensure that only |
the partial target is |
ensure that only the |
that only the latest |
partial target is chosen |
target is chosen to |
is chosen to be |
chosen to be large |
only the latest version |
the latest version of |
it was applied by |
was applied by researchers |
latest version of a |
version of a file |
it is closed by |
such that partial solutions |
applied by researchers in |
of a file is |
a file is accessed |
that partial solutions arrive |
by researchers in the |
researchers in the context |
partial solutions arrive frequently |
solutions arrive frequently enough |
in the context of |
the context of atm |
context of atm networks |
is closed by an |
arrive frequently enough for |
as we have noted |
we have noted in |
closed by an application |
frequently enough for the |
have noted in section |
enough for the manager |
for the manager to |
the manager to accurately |
manager to accurately estimate |
to accurately estimate the |
accurately estimate the power |
estimate the power of |
the power of the |
power of the miner |
sending file updates to |
this is from higher |
file updates to a |
updates to a server |
level fec for ip |
to a server asynchronously |
fec for ip networks |
a server asynchronously has |
for ip networks was |
server asynchronously has two |
to reduce management overhead |
priority classes are performed |
ip networks was revived |
asynchronously has two potential |
has two potential benefits |
networks was revived in |
as the value of |
the value of bitcoin |
value of bitcoin rose |
classes are performed first |
the process modifying the |
process modifying the file |
bitcoin mining has become |
modifying the file need |
mining has become a |
the file need not |
has become a rapidly |
file need not wait |
and rpcs of referred |
become a rapidly advancing |
need not wait for |
not wait for the |
a rapidly advancing industry |
rpcs of referred to |
wait for the write |
for the write to |
technological advancements lead to |
the write to complete |
of referred to as |
referred to as writeback |
advancements lead to ever |
in the context of |
lead to ever more |
the context of both |
to ever more efficient |
if the update is |
context of both reliable |
ever more efficient hashing |
the update is delayed |
of both reliable multicast |
more efficient hashing asics |
update is delayed in |
both reliable multicast and |
is delayed in the |
reliable multicast and long |
delayed in the log |
in the log for |
the log for some |
log for some interval |
for some interval before |
some interval before being |
interval before being written |
before being written back |
directory operations cache equal |
rizzo subsequently provided a |
subsequently provided a working |
it may be superseded |
may be superseded by |
provided a working implementation |
a working implementation of |
be superseded by a |
superseded by a later |
by a later update |
operations cache equal priority |
working implementation of a |
this is a simplification |
is a simplification that |
implementation of a software |
of a software packet |
cache equal priority are |
a simplification that is |
and therefore can be |
therefore can be omitted |
can be omitted entirely |
equal priority are performed |
simplification that is sufficient |
that is sufficient for |
is sufficient for our |
sufficient for our analysis |
priority are performed in |
these benefits come at |
benefits come at the |
come at the cost |
the intricacies of reward |
intricacies of reward systems |
at the cost of |
the cost of reduced |
cost of reduced cache |
of reduced cache consistency |
of reward systems are |
reward systems are explained |
systems are explained in |
are performed in parallel |
since the version of |
maelstrom represents a natural |
the version of the |
represents a natural evolution |
version of the file |
a natural evolution of |
of the file stored |
natural evolution of these |
the file stored at |
evolution of these ideas |
this ensures that the |
file stored at the |
ensures that the directory |
stored at the server |
the emphasis on applying |
that the directory contents |
a notable exception is |
notable exception is p |
at the server is |
the server is inconsistent |
emphasis on applying error |
the directory contents and |
server is inconsistent during |
on applying error correcting |
directory contents and apply |
is inconsistent during the |
applying error correcting codes |
contents and apply changes |
and apply changes locally |
error correcting codes at |
inconsistent during the time |
correcting codes at higher |
during the time that |
codes at higher levels |
the time that the |
at higher levels of |
which we discuss in |
time that the update |
higher levels of the |
levels of the software |
we discuss in section |
that the update remains |
the update remains queued |
of the software stack |
discuss in section ix |
as well as mak |
update remains queued for |
the software stack has |
forks block propagation in |
remains queued for transmission |
software stack has been |
block propagation in the |
stack has been accompanied |
propagation in the overlay |
has been accompanied by |
in the overlay network |
the overlay network takes |
overlay network takes seconds |
been accompanied by advances |
accompanied by advances in |
even though asynchronous writes |
though asynchronous writes in |
by advances in the |
advances in the codes |
in the codes themselves |
asynchronous writes in mfs |
writes in mfs are |
therefore it is possible |
it is possible for |
prior to the mid |
application adapts itself to |
in mfs are not |
is possible for two |
possible for two distant |
mfs are not delayed |
are not delayed to |
for two distant miners |
two distant miners to |
not delayed to aggregate |
delayed to aggregate updates |
distant miners to generate |
miners to generate competing |
to generate competing blocks |
the standard encoding used |
standard encoding used was |
adapts itself to the |
encoding used was reed |
a burst of updates |
itself to the available |
both of which name |
burst of updates to |
to the available bandwidth |
of which name the |
of updates to a |
the available bandwidth gracefully |
an erasure code that |
which name the same |
updates to a sequence |
erasure code that performs |
name the same block |
to a sequence of |
code that performs excellently |
the same block as |
a sequence of files |
that performs excellently at |
same block as their |
block as their predecessor |
sequence of files may |
performs excellently at small |
ing an rpc to |
of files may flood |
excellently at small scale |
an rpc to apply |
files may flood the |
at small scale but |
rpc to apply the |
may flood the link |
small scale but does |
are rare since the |
rare since the average |
flood the link to |
scale but does not |
but does not scale |
since the average mining |
the link to the |
to apply the changes |
does not scale to |
the average mining interval |
link to the server |
apply the changes to |
not scale to large |
average mining interval is |
to the server and |
the changes to the |
scale to large sets |
the server and increase |
changes to the server |
to large sets of |
server and increase the |
and increase the delay |
large sets of data |
sets of data and |
and they occur on |
increase the delay before |
the delay before updates |
of data and error |
they occur on average |
occur on average once |
delay before updates towards |
data and error correcting |
and error correcting symbols |
on average once every |
before updates towards the |
updates towards the end |
towards the end of |
the end of the |
this scalability barrier resulted |
end of the burst |
of the burst are |
the burst are committed |
to the server s |
scalability barrier resulted in |
barrier resulted in the |
any other client accessing |
other client accessing the |
client accessing the file |
resulted in the development |
in the development of |
the development of new |
development of new variants |
cache consistency will access |
of new variants of |
new variants of low |
consistency will access the |
will access the stale |
access the stale version |
the server s copy |
the system has a |
variants of low density |
rather than one which |
system has a mechanism |
of low density parity |
than one which incorporates |
has a mechanism to |
low density parity check |
one which incorporates the |
a mechanism to solve |
which incorporates the pending |
incorporates the pending update |
mechanism to solve forks |
to solve forks when |
solve forks when they |
forks when they do |
when they do occur |
whole since lower bandwidth |
we therefore refer to |
since lower bandwidth translates |
therefore refer to this |
causing one of the |
one of the blocks |
refer to this as |
lower bandwidth translates into |
of the blocks to |
to this as a |
bandwidth translates into longer |
the blocks to be |
blocks to be discarded |
translates into longer delays |
this as a hidden |
into longer delays for |
as a hidden upstudies |
we ignore bifurcations for |
ignore bifurcations for the |
a hidden upstudies of |
hidden upstudies of distributed |
bifurcations for the sake |
for the sake of |
the sake of simplicity |
longer delays for lowerfile |
upstudies of distributed file |
of distributed file systems |
distributed file systems have |
since the choice of |
the choice of the |
file systems have largely |
systems have largely concluded |
choice of the discarded |
of the discarded block |
have largely concluded that |
largely concluded that file |
concluded that file date |
delays for lowerfile caching |
the discarded block on |
discarded block on bifurcation |
and the cache consistency |
block on bifurcation is |
on bifurcation is random |
the cache consistency problem |
cache consistency problem caused |
consistency problem caused by |
problem caused by asynchronous |
one may incorporate this |
caused by asynchronous sharing |
by asynchronous sharing is |
may incorporate this event |
incorporate this event into |
asynchronous sharing is infrequent |
which are orders of |
are orders of magnitude |
this event into the |
sharing is infrequent in |
is infrequent in general |
orders of magnitude faster |
event into the probability |
into the probability of |
of magnitude faster than |
magnitude faster than reed |
the probability of finding |
probability of finding a |
of finding a block |
for lowerfile caching is |
solomon and much more |
and much more scalable |
and consider instead the |
much more scalable in |
more scalable in input |
scalable in input size |
lowerfile caching is effective |
consider instead the probability |
instead the probability of |
the probability of finding |
but require slightly more |
require slightly more data |
probability of finding a |
of finding a block |
slightly more data to |
more data to be |
finding a block that |
writes as the hidden |
as the hidden update |
a block that is |
block that is not |
that is not discarded |
the hidden update problem |
caching is effective if |
data to be received |
pools often charge a |
is effective if a |
to be received at |
often charge a small |
charge a small percentage |
be received at the |
we have identified a |
effective if a client |
a small percentage of |
received at the decoder |
have identified a class |
identified a class of |
small percentage of the |
percentage of the revenue |
of the revenue as |
the revenue as fee |
a class of cache |
while the layered interleaving |
the layered interleaving code |
class of cache consistency |
we discuss in section |
layered interleaving code used |
of cache consistency scenarmobile |
cache consistency scenarmobile file |
discuss in section ix |
interleaving code used by |
code used by maelstrom |
consistency scenarmobile file systems |
in section ix the |
section ix the implications |
used by maelstrom is |
scenarmobile file systems such |
file systems such as |
systems such as coda |
by maelstrom is similar |
maelstrom is similar to |
is similar to the |
similar to the tornado |
ix the implications of |
the implications of such |
implications of such fees |
of such fees to |
such fees to our |
fees to our analysis |
if a client s |
lt and raptor codes |
and raptor codes in |
raptor codes in its |
many pools are open |
pools are open and |
codes in its use |
rely on optimistic conios |
a client s connectivity |
client s connectivity is |
in its use of |
on optimistic conios as |
are open and accept |
open and accept any |
its use of simple |
optimistic conios as being |
conios as being of |
and accept any interested |
use of simple xor |
of simple xor operations |
as being of high |
accept any interested miner |
s connectivity is uncertain |
being of high importance |
it differs from them |
of high importance and |
a pool interface is |
differs from them in |
high importance and inadequately |
pool interface is typically |
from them in one |
importance and inadequately served |
interface is typically comprised |
them in one very |
and inadequately served by |
is typically comprised of |
in one very important |
inadequately served by ex |
typically comprised of a |
rpc timeouts allow the |
one very important aspect |
comprised of a web |
of a web interface |
currency control to resolve |
very important aspect it |
timeouts allow the application |
a web interface for |
control to resolve the |
important aspect it seeks |
allow the application to |
web interface for registration |
to resolve the conflicts |
aspect it seeks to |
the application to prevent |
interface for registration and |
resolve the conflicts generated |
it seeks to minimize |
application to prevent since |
for registration and a |
the conflicts generated by |
seeks to minimize the |
to minimize the latency |
registration and a miner |
conflicts generated by hidden |
generated by hidden upisting |
minimize the latency between |
and a miner interface |
a miner interface for |
by hidden upisting mobile |
the latency between the |
latency between the arrival |
miner interface for the |
hidden upisting mobile file |
upisting mobile file systems |
between the arrival of |
interface for the mining |
for the mining software |
the arrival of a |
arrival of a packet |
suppose that a complex |
that a complex engineering |
a complex engineering dates |
to prevent since the |
of a packet at |
in order to mine |
an alternative approach is |
a packet at the |
order to mine for |
to mine for a |
mine for a pool |
packet at the send |
prevent since the client |
alternative approach is to |
since the client can |
a miner registers with |
approach is to use |
side proxy and its |
proxy and its successful |
miner registers with the |
is to use a |
the client can always |
and its successful reception |
registers with the web |
to use a variant |
client can always use |
its successful reception at |
with the web interface |
use a variant of |
can always use cached |
successful reception at the |
supplies a bitcoin address |
a bitcoin address to |
reception at the receive |
a variant of callbacks |
always use cached copies |
bitcoin address to receive |
variant of callbacks to |
of callbacks to design |
address to receive its |
to receive its future |
callbacks to design is |
to design is maintained |
receive its future shares |
its future shares of |
design is maintained on |
codes such as tornado |
such as tornado encode |
future shares of the |
is maintained on a |
maintained on a server |
as tornado encode over |
shares of the revenue |
use cached copies of |
on a server and |
tornado encode over a |
encode over a fixed |
a server and updated |
and receives from the |
receives from the pool |
over a fixed set |
server and updated by |
and updated by teams |
from the pool credentials |
a fixed set of |
fixed set of input |
set of input symbols |
the pool credentials for |
pool credentials for mining |
updated by teams of |
by teams of de |
cached copies of files |
without treating symbols differently |
treating symbols differently based |
then he feeds his |
he feeds his credentials |
allow a client to |
symbols differently based on |
differently based on their |
feeds his credentials and |
a client to replay |
client to replay writes |
to replay writes asynchronously |
his credentials and the |
credentials and the pool |
based on their sequence |
on their sequence in |
but retain strong signers |
copies of files instead |
of files instead low |
their sequence in the |
and the pool s |
sequence in the data |
the pool s address |
in the data stream |
pool s address to |
s address to its |
address to its mining |
to its mining rig |
priority rpcs being silently |
rpcs being silently starved |
as mentioned in section |
mentioned in section iv |
the mining rig obtains |
mining rig obtains its |
rig obtains its tasks |
obtains its tasks from |
its tasks from the |
tasks from the pool |
from the pool and |
using priorities alof incrementally |
the pool and sends |
the echo file system |
layered interleaving is unique |
priorities alof incrementally fetching |
pool and sends partial |
interleaving is unique in |
alof incrementally fetching them |
and sends partial and |
is unique in allowing |
incrementally fetching them from |
sends partial and full |
unique in allowing the |
fetching them from the |
them from the server |
site supervisors work from |
partial and full proof |
in allowing the recovery |
supervisors work from those |
and full proof of |
full proof of work |
work from those designs |
allowing the recovery latency |
from those designs using |
the recovery latency of |
those designs using mobile |
typically with the stratum |
recovery latency of lost |
with the stratum protocol |
latency of lost packets |
of lost packets to |
we thank larry felser |
lows a programmer to |
lost packets to depend |
thank larry felser and |
larry felser and his |
packets to depend on |
to depend on the |
felser and his team |
and his team at |
depend on the actual |
on the actual burst |
the actual burst size |
actual burst size experienced |
his team at autodesk |
team at autodesk for |
at autodesk for their |
as it finds blocks |
autodesk for their help |
for their help in |
their help in understanddevices |
a programmer to write |
as opposed to the |
the pool manager credits |
these supervisors read from |
opposed to the maximum |
pool manager credits the |
manager credits the miner |
supervisors read from the |
to the maximum tolerable |
the maximum tolerable burst |
credits the miner s |
read from the server |
programmer to write an |
maximum tolerable burst size |
the miner s account |
from the server and |
to write an adaptive |
tolerable burst size as |
miner s account according |
the server and may |
write an adaptive application |
burst size as with |
s account according to |
server and may also |
an adaptive application without |
size as with other |
account according to its |
and may also ing |
adaptive application without ports |
as with other encoding |
according to its share |
may also ing the |
application without ports this |
with other encoding schemes |
to its share of |
also ing the file |
without ports this type |
its share of the |
share of the work |
ports this type of |
ing the file access |
c onclusion modern distributed |
and transfers these funds |
the file access patterns |
onclusion modern distributed systems |
modern distributed systems are |
transfers these funds either |
file access patterns that |
this type of disconnected |
distributed systems are compelled |
these funds either on |
access patterns that arise |
patterns that arise in |
systems are compelled by |
are compelled by real |
type of disconnected operation |
that arise in collaborative |
funds either on request |
arise in collaborative work |
world imperatives to coordinate |
either on request or |
in collaborative work applications |
imperatives to coordinate across |
on request or automatically |
collaborative work applications for |
to coordinate across data |
request or automatically to |
work applications for very |
coordinate across data centers |
or automatically to the |
applications for very change |
across data centers separated |
automatically to the aforementioned |
for very change the |
data centers separated by |
to the aforementioned bitcoin |
very change the design |
centers separated by thousands |
the aforementioned bitcoin address |
separated by thousands of |
by thousands of miles |
for example to reflect |
example to reflect one |
too big pools despite |
to reflect one of |
packet loss cripples the |
big pools despite their |
pools despite their important |
reflect one of the |
loss cripples the performance |
cripples the performance of |
despite their important role |
one of the contingencies |
of the contingencies large |
the performance of such |
their important role of |
important role of enabling |
role of enabling small |
performance of such systems |
but not to the |
not to the ex |
the contingencies large architectural |
and reliability and flow |
contingencies large architectural and |
large architectural and engineering |
pools can constitute a |
architectural and engineering design |
can constitute a threat |
and engineering design firms |
control protocols designed for |
protocols designed for lans |
designed for lans and |
constitute a threat to |
a threat to the |
threat to the bitcoin |
to the bitcoin system |
the bitcoin system if |
or the commodity internet |
having to take account |
bitcoin system if their |
the commodity internet fail |
commodity internet fail to |
internet fail to achieve |
to take account of |
system if their size |
encountered and resolved only |
and resolved only as |
if their size is |
their size is too |
size is too large |
take account of the |
resolved only as construction |
only as construction proceeds |
if one pool controls |
optimal performance on the |
performance on the high |
one pool controls the |
pool controls the majority |
controls the majority of |
the majority of mining |
majority of mining power |
as we have seen |
we have seen earlier |
account of the actual |
haul lambda networks linking |
lambda networks linking data |
high traffic can cause |
the system becomes unstable |
networks linking data centers |
of the actual bandwidth |
traffic can cause delays |
can cause delays in |
deploying new protocols is |
cause delays in the |
delays in the round |
new protocols is not |
the actual bandwidth or |
protocols is not an |
actual bandwidth or current |
trip time for small |
time for small rpcs |
bandwidth or current mix |
is not an option |
or current mix tent |
not an option for |
current mix tent of |
an option for commodity |
mix tent of automatic |
option for commodity clusters |
data rpcs have a |
rpcs have a higher |
for commodity clusters where |
commodity clusters where standardization |
have a higher outgoing |
a higher outgoing queueing |
clusters where standardization is |
where standardization is critical |
higher outgoing queueing delay |
outgoing queueing delay in |
standardization is critical for |
is critical for cost |
queueing delay in the |
delay in the absence |
critical for cost mitigation |
tent of automatic reconciliation |
in the absence of |
the absence of prefetching |
maelstrom is an edge |
of automatic reconciliation of |
warns that the system |
this is due to |
is due to the |
is an edge appliance |
that the system is |
the system is unstable |
due to the majority |
an edge appliance that |
automatic reconciliation of update |
system is unstable with |
to the majority of |
edge appliance that uses |
appliance that uses forward |
is unstable with even |
the majority of the |
majority of the competing |
that uses forward error |
unstable with even smaller |
with even smaller pools |
of the competing rpcs |
uses forward error correction |
forward error correction to |
the competing rpcs being |
competing rpcs being high |
error correction to mask |
correction to mask packet |
rpcs being high priority |
being high priority fetch |
to mask packet loss |
mask packet loss from |
packet loss from endto |
in realistic scenarios of |
reconciliation of update conflicts |
realistic scenarios of the |
scenarios of the bitcoin |
of the bitcoin system |
the bitcoin system no |
bitcoin system no pool |
system no pool controls |
these rpcs are mostly |
no pool controls a |
rpcs are mostly replaced |
pool controls a majority |
ip throughput and latency |
are mostly replaced by |
controls a majority of |
throughput and latency by |
mostly replaced by prefetches |
a majority of the |
and latency by orders |
majority of the mining |
latency by orders of |
of the mining power |
by orders of magnitude |
which operate at a |
orders of magnitude when |
operate at a lower |
of magnitude when loss |
at a lower priority |
magnitude when loss occurs |
a lower priority than |
lower priority than store |
for one day in |
one day in june |
maelstrom is easy to |
is easy to install |
easy to install and |
to install and deploy |
until any point where |
any point where a |
and is completely transparent |
on of rpcs at |
of rpcs at runtime |
is completely transparent to |
point where a concurrent |
a single pool called |
single pool called ghash |
where a concurrent demand |
completely transparent to applications |
a concurrent demand fetch |
transparent to applications and |
and avoid having to |
concurrent demand fetch rpc |
to applications and protocols |
applications and protocols literally |
demand fetch rpc raises |
fetch rpc raises their |
and protocols literally providing |
protocols literally providing reliability |
rpc raises their priorities |
raises their priorities to |
of the blocks in |
the blocks in the |
their priorities to the |
literally providing reliability in |
providing reliability in an |
blocks in the bitcoin |
priorities to the fetch |
avoid having to specify |
reliability in an inexpensive |
in an inexpensive box |
having to specify thresholds |
in the bitcoin main |
the bitcoin main chain |
a comparison of fetch |
to specify thresholds at |
specify thresholds at the |
thresholds at the other |
at the other hand |
data and prefetch rpcs |
the bitcoin community backlashed |
and prefetch rpcs reveals |
bitcoin community backlashed at |
prefetch rpcs reveals the |
community backlashed at the |
rpcs reveals the effect |
backlashed at the pool |
reveals the effect of |
the effect of the |
effect of the bandwidth |
of the bandwidth decrease |
which has done nothing |
has done nothing worse |
done nothing worse than |
nothing worse than being |
worse than being extremely |
than being extremely successful |
level caching reduces the |
the test run with |
test run with prefetching |
run with prefetching performs |
with prefetching performs a |
prefetching performs a fetch |
caching reduces the delay |
reduces the delay incurred |
the delay incurred which |
data rpc to get |
io reduced its relative |
optical domain performance monitoring |
delay incurred which it |
rpc to get the |
reduced its relative mining |
its relative mining power |
to get the first |
get the first file |
relative mining power and |
mining power and publicly |
power and publicly committed |
and publicly committed to |
which triggers prefetching from |
publicly committed to stay |
committed to stay away |
triggers prefetching from its |
prefetching from its file |
from its file group |
incurred which it should |
to stay away from |
stay away from the |
the optical fiber communication |
optical fiber communication conference |
which it should switch |
because of the large |
of the large delay |
the large delay between |
large delay between file |
delay between file accesses |
it should switch communication |
should switch communication modes |
prefetches complete entirely without |
complete entirely without any |
entirely without any overlapping |
without any overlapping demand |
any overlapping demand fetches |
block withholding and its |
withholding and its detection |
and its detection classical |
over the course of |
the course of the |
its detection classical block |
detection classical block withholding |
course of the second |
of the second period |
the second period of |
second period of time |
an rpc whose results |
rpc whose results are |
bandwidth becomes insufficient for |
becomes insufficient for a |
insufficient for a prefetch |
for a prefetch to |
a prefetch to complete |
prefetch to complete during |
to complete during the |
whose results are urgently |
is an attack performed |
results are urgently required |
an attack performed by |
attack performed by a |
performed by a pool |
by a pool member |
a pool member against |
pool member against the |
member against the other |
against the other pool |
the other pool members |
s delay between accesses |
are urgently required should |
urgently required should be |
the attacking miner registers |
and raisepriority rpcs are |
raisepriority rpcs are triggered |
attacking miner registers with |
required should be aswhen |
rpcs are triggered by |
miner registers with the |
should be aswhen an |
are triggered by the |
registers with the pool |
isn t quite enough |
be aswhen an application |
triggered by the consequent |
with the pool and |
aswhen an application opens |
by the consequent cache |
the consequent cache misses |
an application opens a |
the pool and apparently |
as the bandwidth decreases |
application opens a file |
pool and apparently starts |
and apparently starts mining |
the queueing delays increase |
apparently starts mining honestly |
queueing delays increase as |
starts mining honestly it |
delays increase as a |
mining honestly it regularly |
increase as a proportion |
honestly it regularly sends |
as a proportion of |
it regularly sends the |
a proportion of the |
regularly sends the pool |
proportion of the total |
as has been shown |
sends the pool partial |
of the total time |
the total time spent |
the pool partial proof |
pool partial proof of |
partial proof of work |
has been shown in |
been shown in the |
shown in the low |
total time spent on |
time spent on prefetches |
the attacking miner sends |
attacking miner sends only |
miner sends only partial |
sends only partial proof |
only partial proof of |
partial proof of work |
if it finds a |
the modifying client to |
it finds a full |
modifying client to flush |
finds a full solution |
client to flush its |
a full solution that |
to flush its updates |
full solution that constitutes |
flush its updates whenever |
solution that constitutes a |
its updates whenever another |
that constitutes a full |
updates whenever another client |
constitutes a full proof |
whenever another client accesses |
a full proof of |
another client accesses the |
full proof of work |
client accesses the file |
proof of work it |
of work it discards |
work it discards the |
it discards the solution |
where did my performance |
did my performance go |
reducing the pool s |
the pool s total |
it is possible to |
pool s total revenue |
is possible to use |
rate limiting rears its |
separates invalidating a file |
limiting rears its ugly |
rears its ugly head |
invalidating a file from |
a file from transmitting |
this attack is illustrated |
file from transmitting its |
from transmitting its update |
attack is illustrated in |
is illustrated in figure |
possible to use a |
to use a signed |
we have implemented a |
have implemented a similar |
implemented a similar scheme |
a similar scheme in |
similar scheme in mfs |
the attacker does not |
attacker does not change |
does not change the |
not change the pool |
change the pool s |
in which an access |
the pool s effective |
pool s effective mining |
s effective mining power |
use a signed the |
a signed the highest |
which an access to |
signed the highest priority |
and does not affect |
an access to a |
does not affect directly |
access to a file |
not affect directly the |
to a file which |
affect directly the revenue |
a file which has |
directly the revenue of |
the revenue of other |
revenue of other pools |
particularly if the rpc |
file which has an |
if the rpc contains |
the rpc contains outcontent |
which has an uncommitted |
the attacked pool shares |
has an uncommitted update |
attacked pool shares its |
an uncommitted update at |
pool shares its revenue |
uncommitted update at a |
shares its revenue with |
update at a different |
at a different client |
its revenue with the |
revenue with the attacker |
a different client will |
different client will force |
client will force the |
will force the writeback |
based division of files |
therefore each miner earns |
each miner earns less |
the mfs consistency algorithm |
mfs consistency algorithm differs |
consistency algorithm differs in |
algorithm differs in its |
as the same revenue |
differs in its incorporation |
in its incorporation of |
the same revenue is |
same revenue is distributed |
its incorporation of file |
incorporation of file access |
of file access information |
division of files into |
revenue is distributed among |
is distributed among more |
rather than enforce the |
distributed among more miners |
of files into blocks |
than enforce the same |
enforce the same level |
recall that the proof |
the same level of |
same level of consistency |
that the proof of |
the proof of work |
level of consistency for |
of consistency for all |
consistency for all files |
proof of work is |
of work is only |
a cross layer study |
cross layer study of |
work is only valid |
is only valid for |
mfs differentiates between private |
layer study of packet |
study of packet loss |
only valid for a |
differentiates between private files |
files into blocks as |
of packet loss in |
packet loss in all |
into blocks as the |
valid for a specific |
for a specific block |
blocks as the basis |
which have recently only |
have recently only been |
as it is the |
recently only been accessed |
only been accessed by |
it is the nonce |
is the nonce with |
been accessed by a |
accessed by a single |
by a single client |
as the basis for |
the basis for re |
the nonce with which |
nonce with which the |
with which the block |
which the block s |
the block s hash |
which are accessed by |
are accessed by multiple |
block s hash is |
accessed by multiple clients |
s hash is smaller |
hash is smaller than |
is smaller than its |
smaller than its target |
enforcing cache consistency between |
cache consistency between clients |
consistency between clients necessarily |
the attacking miner cannot |
between clients necessarily requires |
attacking miner cannot use |
clients necessarily requires that |
miner cannot use it |
necessarily requires that shared |
requires that shared files |
that shared files are |
shared files are kept |
files are kept highly |
are kept highly consistent |
although the term block |
the term block withholding |
but modifications to private |
modifications to private files |
term block withholding has |
block withholding has become |
withholding has become canonical |
but still important rpcs |
to private files can |
private files can be |
note that the block |
files can be written |
can be written back |
that the block is |
still important rpcs can |
be written back to |
the block is discarded |
important rpcs can ducing |
written back to the |
block is discarded and |
is discarded and never |
back to the server |
to the server less |
discarded and never introduced |
rpcs can ducing client |
the server less aggressively |
and never introduced into |
never introduced into the |
introduced into the system |
into the system as |
the system as the |
system as the name |
the technique of using |
as the name block |
technique of using file |
the name block withholding |
of using file access |
name block withholding implies |
using file access patterns |
file access patterns to |
access patterns to adjust |
patterns to adjust a |
to adjust a cache |
adjust a cache consistency |
a cache consistency protocol |
cache consistency protocol has |
miners miners miners pool |
consistency protocol has been |
protocol has been used |
has been used in |
been used in the |
used in the sprite |
in the sprite distributed |
the sprite distributed operation |
sprite distributed operation system |
classical block withholding attack |
a group of miners |
group of miners attack |
while the lowest levels |
of miners attack pool |
journal of lightwave technology |
the lowest levels are |
lowest levels are useful |
with a block withholding |
a block withholding attack |
levels are useful for |
though in sprite changes |
denoted by a dashed |
by a dashed red |
a dashed red arrow |
are useful for server |
in sprite changes in |
useful for server traffic |
sprite changes in caching |
changes in caching policy |
this attack reduces the |
in caching policy were |
for server traffic does |
attack reduces the attacker |
caching policy were made |
policy were made when |
reduces the attacker s |
the attacker s revenue |
were made when a |
made when a file |
attacker s revenue compared |
s revenue compared to |
when a file was |
a file was opened |
revenue compared to solo |
compared to solo mining |
file was opened simultaneously |
was opened simultaneously at |
to solo mining or |
solo mining or honest |
opened simultaneously at different |
simultaneously at different clients |
mining or honest pool |
or honest pool participation |
server traffic does not |
while mfs uses longer |
traffic does not eliminate |
it suffers from the |
suffers from the reduced |
from the reduced revenue |
the reduced revenue like |
reduced revenue like the |
revenue like the other |
the remainder of this |
remainder of this section |
like the other pool |
the other pool participants |
of this section describes |
this section describes our |
section describes our consistency |
describes our consistency algorithm |
our consistency algorithm in |
consistency algorithm in detail |
and its revenue is |
does not eliminate the |
its revenue is less |
revenue is less than |
and an evaluation of |
an evaluation of its |
is less than its |
less than its share |
evaluation of its effectiveness |
of its effectiveness in |
than its share of |
its share of the |
its effectiveness in reducing |
effectiveness in reducing cache |
share of the total |
of the total mining |
in reducing cache inconsistencies |
not eliminate the fundamental |
the total mining power |
total mining power in |
mining power in the |
host reader writer parameter |
power in the system |
reader writer parameter delay |
eliminate the fundamental problem |
writer parameter delay between |
this attack can therefore |
the fundamental problem of |
parameter delay between accessing |
attack can therefore only |
can therefore only be |
delay between accessing modules |
fundamental problem of rpcs |
therefore only be used |
between accessing modules operations |
problem of rpcs that |
only be used for |
accessing modules operations per |
of rpcs that can |
the effects of systemic |
be used for sabotage |
modules operations per module |
rpcs that can be |
effects of systemic packet |
operations per module delay |
that can be arbitrarily |
can be arbitrarily delayed |
of systemic packet loss |
per module delay between |
at a cost to |
systemic packet loss on |
module delay between operations |
a cost to the |
packet loss on aggregate |
delay between operations delay |
cost to the attacker |
such as speculative activities |
between operations delay between |
loss on aggregate tcp |
on aggregate tcp flows |
operations delay between accessing |
as speculative activities like |
delay between accessing modules |
even if a pool |
if a pool detects |
between accessing modules operations |
speculative activities like prefetching |
a pool detects that |
accessing modules operations per |
modules operations per module |
pool detects that it |
detects that it is |
operations per module delay |
per module delay between |
ieee conference on supercomputing |
activities like prefetching and |
that it is under |
module delay between operations |
delay between operations size |
it is under a |
is under a block |
between operations size of |
operations size of external |
under a block withholding |
a block withholding attack |
size of external files |
of external files value |
like prefetching and transferring |
prefetching and transferring archival |
it might not be |
might not be able |
and transferring archival data |
not be able to |
be able to detect |
able to detect which |
to detect which of |
detect which of its |
which of its registered |
of its registered miners |
its registered miners are |
registered miners are the |
miners are the perpetrators |
if the inicontention for |
the inicontention for insufficient |
inicontention for insufficient bandwidth |
a pool can estimate |
pool can estimate its |
can estimate its expected |
estimate its expected mining |
its expected mining power |
expected mining power and |
mining power and its |
tial assumption regarding the |
power and its actual |
assumption regarding the correct |
and its actual mining |
regarding the correct priority |
its actual mining power |
the correct priority level |
actual mining power by |
mining power by the |
correct priority level for |
power by the rates |
by the rates of |
priority level for an |
the rates of partial |
rates of partial proofs |
of partial proofs of |
partial proofs of work |
proofs of work and |
of work and full |
work and full proofs |
and full proofs of |
full proofs of work |
level for an rpc |
for an rpc proves |
an rpc proves incorrect |
end performance effects of |
performance effects of parallel |
effects of parallel tcp |
of parallel tcp sockets |
supplied by its miners |
parallel tcp sockets on |
tcp sockets on a |
sockets on a lossy |
on a lossy wide |
a call to the |
a difference above a |
difference above a set |
above a set confidence |
a set confidence interval |
set confidence interval indicates |
confidence interval indicates an |
interval indicates an attack |
call to the library |
to the library can |
the library can be |
to detect whether a |
detect whether a single |
whether a single miner |
a single miner is |
single miner is attacking |
miner is attacking it |
library can be made |
can be made to |
be made to assign |
international parallel and distributed |
the pool must use |
pool must use a |
must use a similar |
use a similar technique |
parallel and distributed processing |
and distributed processing symposium |
made to assign a |
comparing the estimated mining |
the estimated mining power |
estimated mining power of |
mining power of the |
power of the attacker |
of the attacker based |
the attacker based on |
attacker based on its |
based on its partial |
on its partial proof |
its partial proof of |
partial proof of work |
proof of work with |
of work with the |
work with the fact |
with the fact it |
the fact it never |
fact it never supplies |
it never supplies a |
never supplies a full |
supplies a full proof |
a full proof of |
full proof of work |
configuration parameters for the |
parameters for the cache |
for the cache consistency |
the cache consistency evaluation |
if the attacker has |
the attacker has a |
attacker has a small |
has a small mining |
a small mining power |
individual instances are uniformally |
instances are uniformally distributed |
are uniformally distributed within |
uniformally distributed within the |
it will send frequent |
distributed within the listed |
within the listed ranges |
will send frequent partial |
send frequent partial proofs |
frequent partial proofs of |
partial proofs of work |
client cache consistency new |
cache consistency new priority |
but the pool will |
the pool will only |
the performance of tcp |
pool will only expect |
if the file is |
will only expect to |
the file is shared |
when a client fetches |
only expect to see |
ip for networks with |
file is shared and |
is shared and no |
expect to see a |
for networks with high |
networks with high bandwidth |
shared and no other |
to see a full |
see a full proof |
and no other shared |
delay products and random |
products and random loss |
no other shared update |
other shared update is |
shared update is being |
update is being sent |
a full proof of |
full proof of work |
proof of work at |
of work at very |
work at very low |
at very low frequency |
a client fetches a |
the thread begins transmitting |
acm transactions on networking |
client fetches a file |
thread begins transmitting the |
it cannot obtain statistically |
begins transmitting the update |
cannot obtain statistically significant |
transmitting the update at |
obtain statistically significant results |
the update at the |
statistically significant results that |
update at the store |
significant results that would |
results that would indicate |
that would indicate an |
would indicate an attack |
the file server grants |
file server grants it |
if another shared update |
another shared update is |
an attacker can use |
server grants it permission |
shared update is being |
attacker can use multiple |
can use multiple small |
update is being written |
is being written back |
use multiple small block |
multiple small block withholding |
small block withholding miners |
block withholding miners and |
withholding miners and replace |
a synchronous forward invalidation |
synchronous forward invalidation rpc |
miners and replace them |
and replace them frequently |
forward invalidation rpc is |
invalidation rpc is made |
rpc is made to |
is made to the |
a small miner is |
made to the server |
to the server at |
the server at the |
server at the highest |
at the highest priority |
grants it permission to |
it permission to cache |
a miners whose expected |
and then the update |
then the update is |
miners whose expected full |
whose expected full proof |
the update is queued |
update is queued for |
is queued for later |
queued for later high |
expected full proof of |
full proof of work |
proof of work frequency |
of work frequency is |
work frequency is yearly |
permission to cache the |
to cache the file |
cache the file for |
such a miner will |
a miner will see |
a forward invalidation is |
miner will see a |
will see a non |
forward invalidation is only |
invalidation is only made |
is only made if |
only made if the |
negligible average daily revenue |
made if the update |
if the update cannot |
the update cannot be |
update cannot be transmitted |
cannot be transmitted immediately |
the file for a |
file for a limited |
for a limited period |
in practice it can |
practice it can therefore |
it can therefore be |
can therefore be omitted |
therefore be omitted at |
be omitted at high |
omitted at high bandwidth |
at high bandwidth or |
high bandwidth or when |
bandwidth or when traffic |
or when traffic is |
when traffic is low |
and adds it to |
adds it to a |
it to a list |
sending a forward invalidation |
a forward invalidation rpc |
forward invalidation rpc without |
invalidation rpc without requiring |
rpc without requiring the |
without requiring the modifying |
requiring the modifying process |
the modifying process to |
modifying process to wait |
process to wait introduces |
a simple model and |
simple model and its |
model and its empirical |
and its empirical validation |
acm sigcomm computer communication |
implementation of clients that |
sigcomm computer communication review |
the consistency maintenance algorithm |
consistency maintenance algorithm a |
maintenance algorithm a transient |
algorithm a transient inconsistency |
if the attacker replaces |
the attacker replaces such |
attacker replaces such a |
replaces such a small |
such a small miner |
a small miner every |
small miner every month |
of clients that cache |
when the server receives |
he will collect about |
will collect about b |
the server receives a |
clients that cache the |
server receives a forward |
that cache the file |
at the end of |
receives a forward invalidation |
the end of each |
end of each month |
a forward invalidation for |
forward invalidation for a |
invalidation for a shared |
for a shared the |
if the client modifies |
a shared the mfs |
the pool must decide |
pool must decide within |
shared the mfs cache |
the mfs cache consistency |
must decide within this |
decide within this month |
mfs cache consistency algorithm |
cache consistency algorithm is |
within this month whether |
this month whether the |
consistency algorithm is intended |
algorithm is intended to |
month whether the miner |
whether the miner is |
is intended to achieve |
intended to achieve a |
to achieve a file |
the client modifies and |
the miner is an |
miner is an attacker |
or begins receiving an |
begins receiving an update |
receiving an update for |
an update for a |
update for a file |
and revoke its earnings |
client modifies and then |
modifies and then closes |
and then closes the |
then closes the file |
it records the idenhigh |
or just an unlucky |
records the idenhigh degree |
just an unlucky honest |
an unlucky honest miner |
the idenhigh degree of |
idenhigh degree of consistency |
it transmits the new |
since an honest miner |
subject to the constraints |
an honest miner of |
to the constraints imposed |
the constraints imposed by |
honest miner of this |
transmits the new contents |
constraints imposed by tity |
miner of this power |
of this power is |
imposed by tity of |
by tity of the |
tity of the writer |
the new contents to |
this power is unlikely |
power is unlikely to |
marks the file as |
new contents to the |
is unlikely to find |
the file as dirty |
contents to the server |
unlikely to find a |
file as dirty and |
to find a full |
as dirty and issues |
find a full proof |
dirty and issues callbacks |
a full proof of |
congestion control for high |
which mafs is implemented |
full proof of work |
and issues callbacks to |
control for high bandwidth |
mafs is implemented in |
proof of work within |
issues callbacks to file |
callbacks to file semantics |
of work within a |
work within a month |
to file semantics and |
file semantics and the |
semantics and the desirability |
and the desirability of |
the desirability of minimising |
desirability of minimising overhead |
is implemented in c |
implemented in c on |
in c on freebsd |
we all the clients |
according to the exponential |
all the clients caching |
the clients caching it |
to the exponential distribution |
the client is a |
if one of these |
a pool that rejects |
client is a usermakes |
one of these clients |
pool that rejects miners |
that rejects miners based |
of these clients fetches |
is a usermakes a |
rejects miners based on |
these clients fetches the |
a usermakes a callback |
miners based on this |
clients fetches the file |
usermakes a callback rpc |
based on this criterion |
fetches the file have |
a callback rpc to |
on this criterion would |
the file have opted |
effective erasure codes for |
this criterion would reject |
criterion would reject the |
file have opted for |
erasure codes for reliable |
codes for reliable computer |
would reject the majority |
have opted for a |
callback rpc to any |
for reliable computer communication |
reject the majority of |
opted for a compromise |
rpc to any other |
reliable computer communication protocols |
the majority of its |
for a compromise which |
to any other clients |
acm sigcomm computer communication |
a compromise which results |
majority of its honest |
of its honest miners |
sigcomm computer communication review |
compromise which results in |
which results in a |
results in a small |
in a small overhead |
the alternative of rejecting |
a small overhead before |
small overhead before the |
alternative of rejecting small |
any other clients on |
overhead before the update |
of rejecting small miners |
other clients on the |
clients on the list |
rejecting small miners in |
before the update has |
small miners in general |
the update has been |
miners in general or |
update has been committed |
in general or distributing |
a client level process |
general or distributing revenue |
client level process that |
or distributing revenue on |
the server sends highbut |
server sends highbut admits |
distributing revenue on a |
revenue on a yearly |
sends highbut admits the |
highbut admits the possibility |
on a yearly basis |
a yearly basis contradicts |
admits the possibility of |
the possibility of a |
yearly basis contradicts the |
basis contradicts the goal |
possibility of a transient |
of a transient inconsistency |
contradicts the goal of |
the goal of pooled |
goal of pooled mining |
level process that stores |
priority server pull rpcs |
process that stores cached |
server pull rpcs to |
that stores cached files |
m odel and s |
pull rpcs to the |
stores cached files in |
odel and s tandard |
rpcs to the clients |
cached files in a |
files in a local |
in a local filesystem |
and s tandard o |
to the clients with |
s tandard o peration |
the clients with outstanding |
tandard o peration we |
clients with outstanding upthe |
o peration we specify |
the that receives a |
with outstanding upthe algorithm |
peration we specify the |
we specify the basic |
outstanding upthe algorithm requires |
upthe algorithm requires information |
specify the basic model |
the basic model in |
algorithm requires information about |
requires information about client |
basic model in which |
model in which participants |
information about client accesses |
on the feasibility of |
the feasibility of software |
feasibility of software fec |
about client accesses in |
client accesses in dates |
in which participants operate |
which participants operate in |
universita di pisa deit |
participants operate in section |
operate in section iii |
di pisa deit technical |
pisa deit technical report |
deit technical report lr |
that receives a callback |
which causes them to |
causes them to raise |
them to raise the |
proceed to describe how |
to raise the priority |
raise the priority of |
to describe how honest |
describe how honest miners |
the priority of any |
priority of any store |
how honest miners operate |
honest miners operate in |
miners operate in this |
operate in this environment |
in this environment in |
this environment in sections |
environment in sections iii |
data order to divide |
order to divide files |
to divide files according |
divide files according their |
files according their status |
receives a callback rpc |
a callback rpc discards |
callback rpc discards its |
rpc discards its cached |
either shared or unrpcs |
and how the classical |
shared or unrpcs to |
or unrpcs to expedite |
unrpcs to expedite transmission |
discards its cached copy |
how the classical block |
the classical block withholding |
classical block withholding attack |
a fetch rpc for |
fetch rpc for an |
block withholding attack is |
withholding attack is implemented |
rpc for an unshared |
for an unshared file |
an unshared file shared |
its cached copy of |
attack is implemented with |
is implemented with our |
implemented with our model |
with our model in |
our model in section |
model in section iii |
since the file server |
cached copy of the |
copy of the file |
the file server always |
file server always assumes |
server always assumes that |
always assumes that an |
assumes that an unshared |
the case for packet |
case for packet level |
for packet level fec |
model the system is |
server also stores its |
that an unshared which |
in fifth international workshop |
an unshared which is |
the system is comprised |
fifth international workshop on |
international workshop on protocols |
unshared which is already |
system is comprised of |
is comprised of the |
workshop on protocols for |
which is already cached |
also stores its copies |
comprised of the bitcoin |
on protocols for high |
is already cached by |
stores its copies of |
of the bitcoin network |
already cached by a |
its copies of files |
the bitcoin network and |
cached by a different |
copies of files in |
bitcoin network and nodes |
by a different client |
of files in a |
files in a local |
in a local filesystem |
network and nodes with |
a different client always |
and nodes with unique |
different client always triggers |
nodes with unique ids |
client always triggers a |
always triggers a file |
triggers a file has |
a file has an |
file has an uncommitted |
and progresses in steps |
has an uncommitted write |
an uncommitted write when |
if an application has |
uncommitted write when it |
write when it is |
a node i generates |
node i generates tasks |
when it is accessed |
it is accessed by |
i generates tasks which |
generates tasks which are |
is accessed by an |
accessed by an addiserver |
by an addiserver pull |
an application has the |
tasks which are associated |
which are associated with |
are associated with its |
since the server has |
associated with its id |
with its id i |
the server has no |
server has no way |
has no way of |
no way of knowing |
way of knowing if |
of knowing if the |
a node can work |
node can work on |
knowing if the file |
if the file has |
can work on a |
work on a task |
the file has tional |
file has tional client |
on a task for |
a task for the |
task for the duration |
for the duration of |
the duration of a |
duration of a step |
incorrect information about the |
information about the status |
about the status of |
the status of a |
status of a file |
the result of this |
of a file only |
a file only outstanding |
lateral error correction for |
error correction for time |
file only outstanding updates |
result of this work |
application has the file |
of this work is |
has the file open |
affects the efficiency of |
this work is a |
the file open when |
the efficiency of the |
work is a set |
file open when its |
open when its client |
when its client re |
efficiency of the algorithm |
is a set of |
a set of partial |
set of partial proofs |
of partial proofs of |
partial proofs of work |
detection of such a |
fourth usenix symposium on |
proofs of work and |
of such a misfinally |
system operations from applications |
usenix symposium on networked |
of work and a |
work and a set |
symposium on networked systems |
since updates to shared |
operations from applications are |
and a set of |
on networked systems design |
updates to shared and |
from applications are redirected |
a set of full |
networked systems design and |
to shared and unshared |
applications are redirected to |
set of full proofs |
systems design and implementation |
shared and unshared files |
are redirected to user |
of full proofs of |
full proofs of work |
redirected to user level |
and unshared files are |
to user level ceives |
unshared files are writclassification |
the number of proofs |
number of proofs in |
files are writclassification results |
are writclassification results in |
of proofs in each |
proofs in each set |
writclassification results in the |
results in the file |
in each set has |
each set has a |
in the file being |
the file being marked |
set has a poisson |
has a poisson distribution |
file being marked as |
being marked as shared |
user level ceives the |
level ceives the callback |
partial proofs with a |
ten back to the |
proofs with a large |
back to the server |
with a large mean |
to the server at |
a large mean and |
the server at different |
server at different priorities |
large mean and full |
mean and full proofs |
and full proofs with |
full proofs with a |
proofs with a small |
with a small mean |
the original order of |
the file is discarded |
original order of the |
nodes that work on |
file is discarded once |
order of the status |
that work on tasks |
work on tasks are |
of the status of |
is discarded once it |
on tasks are called |
the status of files |
discarded once it is |
once it is closed |
status of files can |
tasks are called a |
of files can be |
are called a miners |
files can be specified |
can be specified by |
be specified by the |
when through a kernel |
specified by the user |
miners have identical power |
through a kernel module |
a kernel module at |
kernel module at the |
and hence identical probabilities |
hence identical probabilities to |
by the user or |
module at the client |
identical probabilities to generate |
the user or by |
probabilities to generate proofs |
user or by applithe |
to generate proofs of |
or by applithe sequence |
generate proofs of work |
by applithe sequence of |
applithe sequence of updates |
sequence of updates is |
of updates is no |
updates is no longer |
is no longer entirely |
the bitcoin network pays |
no longer entirely preserved |
bitcoin network pays for |
network pays for full |
pays for full proofs |
for full proofs of |
full proofs of work |
an integrated experimental environment |
to acquire this payoff |
integrated experimental environment for |
or can be inferred |
acquire this payoff an |
experimental environment for distributed |
environment for distributed systems |
can be inferred by |
this payoff an entity |
fetch prefetch metadata store |
for distributed systems and |
be inferred by the |
payoff an entity publishes |
prefetch metadata store fetch |
distributed systems and networks |
inferred by the file |
an entity publishes a |
metadata store fetch file |
store fetch file attributes |
entity publishes a task |
by the file server |
publishes a task task |
the file server according |
a task task and |
file server according to |
task task and its |
server according to how |
task and its corresponding |
according to how it |
and its corresponding proof |
to how it dates |
its corresponding proof of |
how it dates to |
it dates to shared |
corresponding proof of work |
proof of work to |
dates to shared files |
to shared files form |
fifth usenix symposium on |
of work to the |
work to the network |
shared files form a |
usenix symposium on operating |
symposium on operating systems |
files form a subsequence |
form a subsequence of |
on operating systems design |
the payoff goes to |
payoff goes to the |
a subsequence of the |
operating systems design and |
systems design and implementation |
goes to the id |
subsequence of the original |
of the original updates |
to the id associated |
the id associated with |
id associated with task |
pull file update fetch |
file update fetch file |
update fetch file data |
the bitcoin protocol normalizes |
bitcoin protocol normalizes revenue |
protocol normalizes revenue such |
normalizes revenue such that |
automatic inference should incorpoas |
revenue such that the |
inference should incorpoas do |
such that the average |
should incorpoas do the |
that the average total |
incorpoas do the updates |
the average total revenue |
do the updates to |
average total revenue distributed |
the updates to unshared |
prefetch file data lock |
file data lock a |
data lock a file |
updates to unshared files |
total revenue distributed in |
revenue distributed in each |
distributed in each step |
in each step is |
each step is a |
step is a constant |
is a constant throughout |
a constant throughout the |
constant throughout the execution |
implicit dependenrate a heuristic |
throughout the execution of |
most metadata rpcs store |
metadata rpcs store file |
rpcs store file data |
dependenrate a heuristic for |
the execution of the |
a heuristic for the |
execution of the system |
heuristic for the sharing |
for the sharing status |
the sharing status of |
sharing status of new |
status of new files |
unlink file such as |
any node can transact |
node can transact bitcoins |
can transact bitcoins to |
and a mechacies between |
a mechacies between file |
transact bitcoins to another |
bitcoins to another node |
mechacies between file updates |
between file updates are |
file updates are preserved |
file such as deleting |
to another node by |
another node by issuing |
node by issuing a |
since the combination of |
physical layer impact upon |
layer impact upon packet |
by issuing a bitcoin |
the combination of nism |
such as deleting a |
impact upon packet errors |
issuing a bitcoin transaction |
combination of nism for |
as deleting a modified |
deleting a modified file |
of nism for converting |
nodes that generate tasks |
nism for converting shared |
that generate tasks but |
for converting shared files |
generate tasks but outsource |
converting shared files to |
tasks but outsource the |
shared files to be |
such optimisations can be |
but outsource the work |
files to be unshared |
optimisations can be effective |
outsource the work are |
to be unshared if |
passive and active measurement |
be unshared if they |
can be effective at |
be effective at low |
the work are called |
work are called pools |
and active measurement workshop |
effective at low bandwidth |
unshared if they cease |
pools send tasks to |
if they cease to |
send tasks to miners |
they cease to forward |
tasks to miners over |
cease to forward invalidations |
to miners over the |
miners over the network |
to forward invalidations and |
when there is a |
there is a natural |
the miners receive the |
miners receive the tasks |
forward invalidations and compulsory |
is a natural delay |
invalidations and compulsory server |
and compulsory server pull |
compulsory server pull rpcs |
server pull rpcs for |
pull rpcs for unbe |
rpcs for unbe accessed |
and send the partial |
but at high bandwidth |
for unbe accessed by |
send the partial and |
unbe accessed by more |
the partial and full |
accessed by more than |
partial and full proofs |
by more than a |
and full proofs of |
full proofs of work |
more than a single |
than a single client |
proofs of work to |
of work to the |
work to the pool |
an artificial delay in |
artificial delay in writing |
the current implemenshared files |
apart from working on |
from working on tasks |
current implemenshared files prevents |
delay in writing back |
implemenshared files prevents a |
in writing back updates |
files prevents a client |
writing back updates introduces |
prevents a client from |
back updates introduces inconsistencies |
a client from accessing |
updates introduces inconsistencies between |
client from accessing new |
introduces inconsistencies between the |
from accessing new versions |
and receipt are instantaneous |
inconsistencies between the client |
accessing new versions of |
between the client and |
new versions of files |
we assume that the |
the client and the |
client and the file |
assume that the number |
versions of files tation |
of files tation in |
that the number of |
and the file server |
files tation in mfs |
the number of miners |
tation in mfs assumes |
number of miners is |
in mfs assumes that |
of miners is large |
mfs assumes that every |
miners is large enough |
this can be acceptable |
can be acceptable at |
is large enough such |
assumes that every new |
that every new file |
large enough such that |
be acceptable at low |
acceptable at low bandwidths |
enough such that mining |
every new file is |
new file is unshared |
such that mining power |
that mining power can |
mining power can be |
power can be split |
when the user may |
the user may table |
and monin contravention of |
can be split arbitrarily |
monin contravention of their |
be split arbitrarily without |
contravention of their update |
split arbitrarily without resolution |
of their update order |
arbitrarily without resolution constraints |
itors client accesses to |
priorities for mafs remote |
denote the number of |
client accesses to a |
for mafs remote procedure |
mafs remote procedure calls |
accesses to a file |
the number of pools |
to a file according |
number of pools with |
a file according to |
of pools with p |
file according to an |
be grateful to be |
according to an overlapping |
grateful to be able |
to an overlapping series |
the total number of |
to be able to |
an overlapping series of |
total number of mining |
the university of illinois |
university of illinois national |
overlapping series of time |
number of mining power |
be able to use |
of illinois national center |
series of time periods |
of mining power in |
mining power in the |
illinois national center for |
of time periods to |
able to use the |
power in the system |
national center for supercomputing |
time periods to ensure |
periods to ensure that |
in the system with |
center for supercomputing applications |
to use the file |
to ensure that files |
the system with m |
system with m and |
ensure that files which |
that files which are |
with m and the |
m and the miners |
files which are regularly |
which are regularly accessed |
and the miners participating |
the miners participating in |
are regularly accessed remain |
regularly accessed remain shared |
miners participating in pool |
participating in pool i |
use the file system |
the file system at |
file system at all |
since the mfs file |
the mfs file monitoring |
mfs file monitoring component |
file monitoring component op |
but should be avoided |
should be avoided when |
be avoided when bandwidth |
avoided when bandwidth is |
when bandwidth is unconstrained |
we use a quasistatic |
use a quasistatic analysis |
a quasistatic analysis where |
quasistatic analysis where miner |
analysis where miner participation |
where miner participation in |
experimental setup erates on |
miner participation in a |
setup erates on a |
participation in a pool |
erates on a larger |
in a pool does |
on a larger time |
a pool does not |
global crossing current network |
a larger time scale |
pool does not change |
crossing current network performance |
larger time scale than |
does not change over |
not change over time |
time scale than the |
scale than the experiments |
than the experiments considered |
the experiments considered in |
experiments considered in at |
considered in at the |
in at the start |
at the start of |
the start of this |
start of this section |
of this section we |
this section we identified |
section we identified large |
mafs avoids the need |
solo mining a solo |
scale collaborative this paper |
mining a solo miner |
a solo miner is |
solo miner is a |
miner is a node |
we omit its details |
is a node that |
a node that generates |
omit its details for |
its details for brevity |
node that generates its |
that generates its own |
generates its own tasks |
avoids the need for |
engineering design as an |
the need for modes |
design as an example |
in every step it |
every step it generates |
step it generates a |
it generates a task |
as an example of |
an example of a |
example of a scenario |
of a scenario which |
a scenario which features |
works on it for |
need for modes by |
scenario which features when |
on it for the |
for modes by using |
which features when a |
it for the duration |
modes by using asynchronous |
features when a process |
for the duration of |
the duration of the |
when a process modifies |
a process modifies a |
duration of the step |
of the step and |
process modifies a file |
by using asynchronous remote |
qwest ip network statistics |
the step and if |
step and if it |
an update is scheduled |
and if it finds |
if it finds a |
update is scheduled to |
is scheduled to be |
it finds a full |
finds a full proof |
scheduled to be a |
to be a high |
a full proof of |
full proof of work |
be a high degree |
a high degree of |
high degree of read |
using asynchronous remote procedure |
it publishes this proof |
publishes this proof of |
this proof of work |
proof of work to |
of work to earn |
work to earn the |
at present we have |
to earn the payoff |
asynchronous remote procedure calls |
present we have evalappended |
we have evalappended to |
have evalappended to the |
evalappended to the log |
remote procedure calls between |
procedure calls between a |
pools a pool is |
and the process continues |
a pool is a |
the process continues executing |
calls between a client |
pool is a node |
process continues executing withuated |
between a client and |
is a node that |
continues executing withuated the |
a client and the |
a node that serves |
executing withuated the mfs |
client and the file |
node that serves as |
withuated the mfs cache |
and the file server |
that serves as a |
the mfs cache consistency |
the file server writeback |
serves as a coordinator |
mfs cache consistency algorithm |
file server writeback at |
as a coordinator and |
cache consistency algorithm using |
server writeback at all |
writeback at all bandwidth |
at all bandwidth levels |
a coordinator and multiple |
vice president of research |
consistency algorithm using a |
coordinator and multiple miners |
president of research and |
algorithm using a synthetic |
and multiple miners can |
and incorporates a new |
using a synthetic out |
of research and t |
multiple miners can register |
miners can register to |
a synthetic out having |
synthetic out having to |
can register to a |
register to a pool |
out having to wait |
having to wait for |
to a pool and |
a pool and work |
pool and work for |
and work for it |
to wait for the |
wait for the server |
for the server to |
the server to be |
server to be contacted |
incorporates a new upare |
in every step it |
a new upare divided |
every step it generates |
new upare divided into |
step it generates a |
though we are hoping |
upare divided into several |
it generates a task |
we are hoping to |
divided into several types |
generates a task for |
are hoping to obtain |
into several types depending |
several types depending on |
types depending on their |
depending on their function |
hoping to obtain real |
a task for each |
to obtain real data |
task for each registered |
obtain real data from |
for each registered miner |
real data from such |
rpcs date propagation algorithm |
each registered miner and |
data from such an |
date propagation algorithm to |
registered miner and sends |
from such an thread |
such an thread then |
miner and sends it |
and sends it over |
an thread then checks |
propagation algorithm to reduce |
sends it over the |
thread then checks the |
then checks the status |
it over the network |
algorithm to reduce the |
checks the status of |
the status of the |
status of the file |
each miner receives its |
of the file the |
the file the update |
miner receives its task |
to reduce the possibility |
file the update modifies |
receives its task and |
reduce the possibility of |
its task and works |
if the environment in |
task and works on |
and works on it |
the environment in the |
environment in the future |
works on it for |
on it for the |
it for the duration |
for the duration of |
the duration of the |
duration of the step |
the possibility of inconsisto |
possibility of inconsisto fetch |
the update is queued |
at the end of |
the end of the |
end of the step |
update is queued for |
is queued for transmission |
queued for transmission at |
for transmission at the |
transmission at the reg |
the miner sends the |
of inconsisto fetch and |
miner sends the pool |
inconsisto fetch and store |
fetch and store data |
and store data are |
store data are self |
acm transactions on networking |
sends the pool the |
the pool the full |
pool the full and |
the full and the |
full and the partial |
and the partial proofs |
the partial proofs of |
partial proofs of work |
proofs of work it |
of work it has |
work it has found |
the pool receives the |
pool receives the proofs |
receives the proofs of |
the proofs of work |
proofs of work of |
of work of all |
work of all its |
of all its miners |
registers the partial proofs |
the partial proofs of |
partial proofs of work |
proofs of work and |
of work and publishes |
work and publishes the |
and publishes the full |
publishes the full proofs |
as new operations are |
new operations are added |
it calculates its overall |
calculates its overall revenue |
operations are added to |
are added to the |
added to the tail |
and proceeds to distribute |
proceeds to distribute it |
to distribute it among |
distribute it among its |
it among its miners |
to the tail tions |
the tail tions include |
tail tions include fetching |
tions include fetching and |
each miner receives revenue |
include fetching and setting |
miner receives revenue proportional |
receives revenue proportional to |
revenue proportional to its |
proportional to its success |
to its success in |
its success in the |
success in the current |
in the current step |
fetching and setting file |
and setting file attributes |
namely the ratio of |
the ratio of its |
ratio of its partial |
of its partial proofs |
and directory of the |
directory of the log |
its partial proofs of |
partial proofs of work |
proofs of work out |
of work out of |
work out of all |
out of all partial |
of all partial proofs |
the client flushes operations |
all partial proofs of |
partial proofs of work |
proofs of work the |
of work the pool |
work the pool received |
client flushes operations serially |
flushes operations serially from |
operations serially from the |
we assume that pools |
assume that pools do |
that pools do not |
pools do not collect |
do not collect fees |
not collect fees of |
collect fees of the |
fees of the revenue |
serially from the head |
from the head of |
the head of operations |
head of operations such |
pool fees and their |
of operations such as |
fees and their implications |
and their implications on |
their implications on our |
implications on our analysis |
on our analysis are |
our analysis are discussed |
analysis are discussed in |
are discussed in section |
discussed in section ix |
operations such as creating |
such as creating and |
as creating and unlinking |
creating and unlinking files |
block withholding miner a |
withholding miner a miner |
control rpcs the log |
miner a miner registered |
a miner registered at |
miner registered at a |
registered at a pool |
at a pool can |
a pool can perform |
pool can perform the |
can perform the classical |
a method for improving |
perform the classical block |
method for improving tcp |
the classical block withholding |
for improving tcp performance |
classical block withholding attack |
server traffic consists of |
improving tcp performance over |
tcp performance over wireless |
an attacker miner operates |
performance over wireless links |
traffic consists of a |
attacker miner operates as |
miner operates as if |
operates as if it |
as if it worked |
if it worked for |
it worked for the |
worked for the pool |
consists of a variety |
of a variety of |
it receives its tasks |
receives its tasks and |
its tasks and works |
tasks and works on |
and works on them |
a variety of foreground |
variety of foreground include |
of foreground include locking |
only at the end |
foreground include locking files |
nd ieee wireless communications |
at the end of |
include locking files and |
ieee wireless communications and |
the end of each |
end of each round |
wireless communications and networking |
communications and networking conference |
of each round it |
each round it sends |
round it sends only |
it sends only its |
sends only its partial |
only its partial proofs |
its partial proofs of |
partial proofs of work |
locking files and the |
files and the server |
and the server s |
and omits full proofs |
omits full proofs of |
full proofs of work |
proofs of work if |
of work if it |
work if it had |
if it had found |
it had found any |
the server s callback |
number of rpcs average |
of rpcs average time |
the pool registers the |
server s callback to |
pool registers the miner |
registers the miner s |
the miner s partial |
miner s partial proofs |
s callback to invalidate |
callback to invalidate a |
to invalidate a rpcs |
but cannot distinguish between |
cannot distinguish between miners |
distinguish between miners running |
between miners running honestly |
miners running honestly and |
running honestly and block |
honestly and block withholding |
and block withholding miners |
invalidate a rpcs for |
a rpcs for control |
rpcs for control operations |
for control operations and |
control operations and fetching |
operations and fetching file |
and fetching file data |
hik j ihkj m |
the implications are that |
j ihkj m l |
implications are that a |
ihkj m l ml |
an adaptive forward error |
are that a miner |
and a stream client |
adaptive forward error correction |
m l ml cb |
that a miner that |
a stream client s |
forward error correction protocol |
l ml cb c |
a miner that engages |
stream client s cached |
error correction protocol for |
ml cb c b |
miner that engages in |
client s cached copy |
correction protocol for end |
cb c b cbcb |
that engages in block |
s cached copy of |
cached copy of a |
copy of a file |
c b cbcb ed |
engages in block withholding |
b cbcb ed f |
end transport of real |
in block withholding does |
cbcb ed f gf |
block withholding does not |
withholding does not contribute |
ed f gf cb |
f gf cb c |
does not contribute to |
not contribute to the |
gf cb c b |
cb c b yx |
c b yx cbcb |
of background rpcs for |
contribute to the pool |
to the pool s |
z eded f f |
the pool s overall |
pool s overall mining |
eded f f gfgf |
f f gfgf cb |
f gfgf cb b |
gfgf cb b on |
cb b on yxyx |
b on yxyx cbb |
s overall mining power |
background rpcs for logged |
rpcs for logged operations |
but still shares the |
th international conference on |
still shares the pool |
z eded f f |
international conference on computer |
shares the pool s |
the pool s revenue |
conference on computer communications |
on computer communications and |
pool s revenue according |
s revenue according to |
computer communications and networks |
when bandwidth is high |
revenue according to its |
according to its sent |
to its sent partial |
its sent partial proofs |
sent partial proofs of |
partial proofs of work |
gfgf c c b |
c c b on |
c b on yx |
b on yx ccb |
on yx ccb qp |
replayed logged operations complete |
logged operations complete quickly |
to reason about a |
reason about a pool |
about a pool s |
a pool s efficiency |
pool s efficiency we |
s efficiency we define |
efficiency we define its |
we define its per |
with little extra delay |
gf cb b c |
cb b c onon |
b c onon yxxy |
miner revenue as follows |
c onon yxxy cbbc |
onon yxxy cbbc qpqp |
when bandwidth is low |
z eded r f |
eded r f f |
r f f srs |
logged operations are de |
the revenue density of |
communication adaptation layed in |
revenue density of a |
adaptation layed in proportion |
density of a pool |
gfgf c b onon |
of a pool is |
c b onon yx |
b onon yx cb |
onon yx cb qp |
layed in proportion to |
a pool is the |
in proportion to the |
pool is the ratio |
proportion to the foreground |
z ed r f |
ed r f r |
to the foreground rpc |
is the ratio between |
based loss recovery for |
loss recovery for reliable |
the ratio between the |
the foreground rpc traffic |
recovery for reliable multicast |
ratio between the average |
gf invalidations and server |
invalidations and server pulls |
and server pulls mfs |
between the average revenue |
foreground rpc traffic and |
for reliable multicast transmission |
the average revenue a |
rpc traffic and the |
average revenue a pool |
traffic and the availto |
revenue a pool member |
and the availto reduce |
a pool member earns |
the availto reduce its |
diff synchronous average time |
pool member earns and |
availto reduce its network |
reduce its network communication |
its network communication when |
network communication when bandwidth |
communication when bandwidth is |
when bandwidth is low |
member earns and the |
earns and the average |
and the average revenue |
the average revenue it |
average revenue it would |
revenue it would have |
it would have earned |
would have earned as |
have earned as a |
earned as a solo |
as a solo miner |
a mobile file system |
mobile file system client |
file system client can |
system client can automatically |
the revenue density of |
revenue density of a |
density of a solo |
of a solo miner |
client can automatically adapt |
can automatically adapt its |
automatically adapt its communication |
adapt its communication strategy |
and that of a |
that of a miner |
of a miner working |
a miner working with |
miner working with an |
working with an unattacked |
with an unattacked pool |
an unattacked pool are |
unattacked pool are one |
its communication strategy to |
communication strategy to the |
strategy to the available |
to the available bandwidth |
if a pool is |
a pool is attacked |
pool is attacked with |
is attacked with block |
attacked with block withholding |
its revenue density decreases |
end performance evaluation of |
rpc priorities cations transfer |
continuous analysis because our |
priorities cations transfer a |
analysis because our analysis |
cations transfer a large |
because our analysis will |
our analysis will be |
analysis will be of |
will be of the |
be of the average |
of the average revenue |
transfer a large volume |
a large volume of |
large volume of data |
volume of data that |
we will consider proofs |
will consider proofs of |
consider proofs of work |
of data that the |
data that the user |
that the user is |
the user is unlikely |
user is unlikely to |
is unlikely to require |
unlikely to require immediately |
both full and partial |
consuming bandwidth that can |
as continuous deterministic sizes |
bandwidth that can be |
that can be used |
th symposium on high |
symposium on high performance |
according to their probability |
can be used mafs |
on high performance interconnects |
be used mafs uses |
work on a task |
used mafs uses priorities |
on a task therefore |
mafs uses priorities to |
a task therefore results |
uses priorities to reduce |
task therefore results in |
priorities to reduce contention |
therefore results in a |
results in a deterministic |
in a deterministic fraction |
a deterministic fraction of |
deterministic fraction of proof |
fraction of proof of |
of proof of work |
to reduce contention between |
reduce contention between foreground |
contention between foreground for |
between foreground for important |
foreground for important tasks |
t he p ool |
he p ool g |
p ool g ame |
ool g ame a |
consider an application that |
an application that activities |
application that activities and |
that activities and deferrable |
activities and deferrable background |
and deferrable background activities |
the pool block withholding |
pool block withholding attack |
block withholding attack just |
withholding attack just as |
adaptive rpc fetches images |
rpc fetches images from |
fetches images from a |
images from a file |
from a file server |
attack just as a |
just as a miner |
as a miner can |
a miner can perform |
miner can perform block |
can perform block withholding |
perform block withholding on |
block withholding on a |
withholding on a pool |
on a pool j |
processes each in turn |
a pool i can |
end forward error correction |
pool i can use |
i can use some |
can use some of |
preferentially allocates bandwidth to |
allocates bandwidth to foreground |
bandwidth to foreground rpcs |
use some of its |
some of its mining |
of its mining power |
its mining power to |
unlike plays the resulting |
plays the resulting image |
mining power to infiltrate |
power to infiltrate a |
to infiltrate a pool |
infiltrate a pool j |
and writes it to |
writes it to the |
it to the server |
a pool j and |
pool j and perform |
j and perform a |
international zurich seminar on |
and perform a block |
zurich seminar on communications |
if the user little |
the user little work |
perform a block withholding |
a block withholding attack |
block withholding attack on |
withholding attack on j |
denote the amount of |
the amount of such |
amount of such infiltrating |
of such infiltrating mining |
such infiltrating mining power |
infiltrating mining power at |
mining power at step |
power at step t |
at step t by |
which assigns a lower |
step t by xi |
assigns a lower priority |
a lower priority to |
lower priority to writeback |
priority to writeback in |
to writeback in wants |
writeback in wants to |
in wants to see |
wants to see the |
to see the processed |
see the processed images |
miners working for pool |
one else wants to |
else wants to im |
working for pool i |
either mining honestly or |
mining honestly or used |
honestly or used for |
or used for infiltrating |
used for infiltrating pool |
for infiltrating pool j |
mafs has a finer |
are loyal to pool |
loyal to pool i |
grained differentiation mediately read |
differentiation mediately read them |
at the end of |
the end of a |
end of a round |
writing the output back |
the output back will |
output back will interfere |
back will interfere with |
pool i aggregates its |
will interfere with between |
interfere with between rpcs |
i aggregates its revenue |
aggregates its revenue from |
its revenue from mining |
the case for application |
and uses priorities at |
uses priorities at all |
priorities at all bandwidths |
revenue from mining in |
level network striping for |
from mining in the |
network striping for data |
mining in the current |
this alfetching the next |
alfetching the next image |
in the current round |
striping for data intensive |
the current round and |
for data intensive applications |
and slow down the |
slow down the application |
data intensive applications using |
current round and from |
intensive applications using high |
round and from its |
applications using high speed |
and from its infiltration |
from its infiltration in |
using high speed wide |
high speed wide area |
speed wide area networks |
lows control over bandwidth |
its infiltration in the |
infiltration in the previous |
in the previous round |
control over bandwidth allocation |
over bandwidth allocation at |
bandwidth allocation at the |
allocation at the level |
it distributes the revenue |
at the level of |
distributes the revenue evenly |
the level of individinterference |
the revenue evenly among |
level of individinterference due |
ieee conference on supercomputing |
revenue evenly among all |
of individinterference due to |
evenly among all its |
individinterference due to write |
among all its loyal |
all its loyal miners |
its loyal miners according |
due to write traffic |
loyal miners according to |
miners according to their |
according to their partial |
to their partial proofs |
their partial proofs of |
partial proofs of work |
to write traffic is |
write traffic is often |
traffic is often solved |
is often solved by |
often solved by writing |
the pool s miners |
solved by writing ual |
by writing ual rpcs |
pool s miners are |
s miners are oblivious |
miners are oblivious to |
are oblivious to their |
oblivious to their role |
without requiring that an |
to their role and |
their role and they |
role and they operate |
and they operate as |
they operate as regular |
operate as regular honest |
as regular honest miners |
requiring that an mafs |
that an mafs client |
an mafs client is |
mafs client is aware |
client is aware of |
is aware of back |
aware of back updates |
of back updates asynchronously |
the application in our |
application in our example |
in our example the |
our example the precise |
example the precise bandwidth |
revenue convergence note that |
tsunami file transfer protocol |
convergence note that pool |
note that pool j |
can start reading another |
that pool j sends |
start reading another image |
pool j sends its |
reading another image without |
j sends its revenue |
another image without waiting |
image without waiting for |
without waiting for the |
waiting for the previwhen |
for the previwhen choosing |
the previwhen choosing priorities |
sends its revenue to |
its revenue to infiltrators |
revenue to infiltrators from |
to infiltrators from pool |
infiltrators from pool i |
first international workshop on |
from pool i at |
pool i at the |
international workshop on protocols |
workshop on protocols for |
on protocols for fast |
protocols for fast long |
i at the end |
at the end of |
the end of the |
end of the step |
automatic assignment and fine |
assignment and fine ous |
and fine ous output |
fine ous output to |
ous output to be |
and this revenue is |
output to be sent |
to be sent to |
be sent to the |
sent to the file |
to the file server |
this revenue is calculated |
revenue is calculated in |
is calculated in pool |
calculated in pool i |
in pool i at |
pool i at the |
i at the beginning |
at the beginning of |
the beginning of the |
beginning of the subsequent |
of the subsequent step |
asynchronous writeback granularity are |
writeback granularity are preferable |
if there is a |
there is a chain |
is a chain of |
a chain of pools |
chain of pools of |
of pools of length |
to avoid the need |
avoid the need for |
the need for user |
need for user intervenallows |
for user intervenallows i |
where each pool infiltrates |
each pool infiltrates the |
pool infiltrates the next |
o and cpu processing |
and cpu processing to |
cpu processing to be |
the pool revenue will |
pool revenue will not |
revenue will not be |
will not be static |
processing to be overlapped |
since the revenue from |
the revenue from infiltration |
revenue from infiltration takes |
from infiltration takes one |
infiltration takes one step |
takes one step to |
one step to take |
step to take each |
to take each hop |
tion and provide the |
and provide the maximum |
provide the maximum degree |
the maximum degree of |
maximum degree of differentiation |
degree of differentiation among |
of differentiation among ecution |
differentiation among ecution time |
max is the longest |
is the longest chain |
the longest chain in |
longest chain in the |
chain in the system |
among ecution time and |
ecution time and utilising |
time and utilising bandwidth |
and utilising bandwidth more |
utilising bandwidth more efficiently |
the revenue stabilizes after |
predictable high performance bulk |
high performance bulk data |
performance bulk data transfer |
if there are loops |
there are loops in |
are loops in the |
loops in the infiltration |
scheduling rpcs based on |
rpcs based on priorities |
based on priorities is |
on priorities is only |
priorities is only ever |
in the infiltration graph |
if bandwidth is low |
the system will converge |
system will converge to |
will converge to a |
converge to a certain |
to a certain revenue |
contention arises when files |
arises when files are |
when files are being |
as stated in the |
stated in the following |
in the following lemma |
ieee international conference on |
international conference on cluster |
conference on cluster computing |
files are being effective |
are being effective if |
being effective if concurrent |
effective if concurrent rpcs |
if concurrent rpcs usually |
concurrent rpcs usually end |
rpcs usually end up |
usually end up with |
end up with different |
up with different prifetched |
with different prifetched at |
different prifetched at the |
prifetched at the same |
at the same time |
the same time as |
same time as updates |
time as updates are |
if infiltration rates are |
infiltration rates are constant |
as updates are written |
updates are written back |
the pool revenues converge |
denote the revenue density |
the revenue density of |
but processes are too |
processes are too coarse |
revenue density of pool |
density of pool i |
of pool i at |
pool i at the |
i at the end |
at the end of |
the end of step |
end of step t |
of step t by |
step t by ri |
grained for this purpose |
tention can be mitigated |
can be mitigated by |
be mitigated by prioritising |
mitigated by prioritising file |
by prioritising file fetch |
prioritising file fetch rpcs |
file fetch rpcs above |
and define the revenue |
solomon codes and their |
codes and their applications |
fetch rpcs above file |
define the revenue density |
the revenue density vector |
revenue density vector r |
based priorities provide some |
priorities provide some more |
provide some more detail |
but the imporwriteback rpcs |
the imporwriteback rpcs to |
imporwriteback rpcs to ensure |
rpcs to ensure that |
to ensure that they |
ensure that they will |
that they will be |
they will be preferentially |
will be preferentially allo |
tance of a file |
of a file can |
a file can be |
file can be hard |
can be hard to |
be hard to determine |
hard to determine automatically |
files can be too |
can be too numerous |
be too numerous for |
too numerous for the |
numerous for the user |
for the user to |
the user to manually |
user to manually assign |
to manually assign priin |
manually assign priin this |
assign priin this section |
we assess the effectiveness |
assess the effectiveness of |
the effectiveness of asynchronous |
effectiveness of asynchronous orities |
nat and packet mangling |
and packet mangling for |
packet mangling for linux |
p in every round |
rpcs are more numerous |
pool i uses its |
i uses its mining |
uses its mining power |
its mining power of |
mining power of m |
but priorities can be |
priorities can be autowriteback |
can be autowriteback and |
be autowriteback and rpc |
autowriteback and rpc priorities |
and rpc priorities in |
rpc priorities in mafs |
priorities in mafs under |
in mafs under different |
j used for direct |
used for direct mining |
for direct mining p |
mafs under different levels |
under different levels matically |
different levels matically assigned |
levels matically assigned to |
matically assigned to them |
assigned to them according |
to them according to |
them according to the |
according to the operation |
to the operation the |
the operation the rpc |
operation the rpc of |
and shares it among |
shares it among its |
it among its m |
the rpc of bandwidth |
rpc of bandwidth availability |
average duration of reader |
duration of reader fetch |
we examine the degree |
examine the degree corresponds |
the degree corresponds to |
as shown in table |
all sums are over |
sums are over the |
are over the range |
or rpcs to which |
rpcs to which a |
to which a file |
which a file system |
a file system client |
file system client that |
system client that avoids |
client that avoids switching |
that avoids switching modes |
avoids switching modes in |
switching modes in re |
multicast routing in datagram |
routing in datagram internetworks |
in datagram internetworks and |
datagram internetworks and extended |
internetworks and extended lans |
that the user has |
the user has to |
user has to wait |
has to wait for |
acm transactions on computers |
transactions on computers systems |
denote the direct mining |
the direct mining revenue |
direct mining revenue density |
mining revenue density of |
revenue density of each |
density of each pool |
or sponse to bandwidth |
sponse to bandwidth changes |
to bandwidth changes is |
bandwidth changes is able |
changes is able to |
is able to adapt |
which is a constant |
is a constant factor |
able to adapt to |
to adapt to both |
adapt to both insufficient |
to both insufficient rpcs |
both insufficient rpcs whose |
insufficient rpcs whose results |
rpcs whose results can |
whose results can be |
results can be delayed |
such as writing back |
as writing back data |
writing back data bandwidth |
and conditions under which |
conditions under which bandwidth |
under which bandwidth is |
which bandwidth is plentiful |
prefetching is an example |
is an example of |
an example of speculative |
example of speculative communication |
priority rpc whose results |
rpc whose results can |
whose results can improve |
results can improve performance |
can improve performance if |
improve performance if bandwidth |
performance if bandwidth is |
if bandwidth is high |
asynchronous writeback but can |
writeback but can be |
but can be safely |
can be safely omitted |
be safely omitted if |
safely omitted if bandwidth |
p the revenue of |
omitted if bandwidth is |
if bandwidth is low |
the revenue of pool |
revenue of pool i |
of pool i in |
pool i in step |
i in step t |
in step t taken |
step t taken through |
t taken through infiltration |
taken through infiltration from |
through infiltration from pool |
mafs asynchronous writeback is |
infiltration from pool j |
asynchronous writeback is based |
from pool j s |
pool j s revenue |
j s revenue in |
s revenue in step |
revenue in step t |
writeback is based on |
is based on similar |
based on similar mechanisms |
on similar mechanisms the |
similar mechanisms the initial |
mechanisms the initial priority |
the initial priority is |
initial priority is never |
priority is never modified |
performance enhancing proxies intended |
enhancing proxies intended to |
proxies intended to mitigate |
intended to mitigate link |
but the file server |
the file server somefound |
file server somefound in |
server somefound in many |
somefound in many mobile |
in many mobile file |
many mobile file systems |
pool i distributes this |
i distributes this revenue |
distributes this revenue among |
this revenue among its |
revenue among its mi |
i members loyal and |
members loyal and infiltrators |
define the p p |
the p p infiltration |
p p infiltration matrix |
p infiltration matrix by |
infiltration matrix by its |
matrix by its i |
rather than making times |
than making times requests |
making times requests an |
times requests an increase |
requests an increase in |
an increase in the |
increase in the priority |
in the priority of |
the priority of an |
priority of an rpc |
of an rpc to |
an rpc to transmit |
rpc to transmit an |
to transmit an rpc |
transmit an rpc when |
an rpc when an |
rpc when an application |
when an application performs |
an application performs a |
application performs a metadata |
performs a metadata update |
a metadata update or |
metadata update or file |
update or file data |
i ij and the |
ij and the revenue |
and the revenue vector |
the revenue vector at |
revenue vector at step |
vector at step t |
at step t is |
step t is r |
the operation is logged |
operation is logged and |
is logged and replayed |
logged and replayed to |
and replayed to the |
replayed to the file |
to the file server |
the file server after |
file server after a |
server after a delay |
this scheme reduces bandwidth |
scheme reduces bandwidth utilisation |
reduces bandwidth utilisation because |
bandwidth utilisation because some |
utilisation because some logged |
because some logged operations |
some logged operations may |
logged operations may be |
operations may be superceded |
may be superceded by |
be superceded by later |
superceded by later ones |
in the pool game |
the pool game pools |
pool game pools try |
game pools try to |
pools try to optimize |
try to optimize their |
to optimize their infiltration |
udp bandwidth measurement tool |
optimize their infiltration rates |
their infiltration rates of |
infiltration rates of other |
rates of other pools |
of other pools to |
other pools to maximize |
pools to maximize their |
to maximize their revenue |
the overall number of |
overall number of miners |
number of miners and |
of miners and the |
miners and the number |
and the number of |
the number of miners |
number of miners loyal |
of miners loyal to |
miners loyal to each |
loyal to each pool |
to each pool remain |
each pool remain constant |
pool remain constant throughout |
remain constant throughout the |
constant throughout the game |
time progresses in rounds |
let s be a |
s be a constant |
be a constant integer |
a constant integer large |
constant integer large enough |
integer large enough that |
large enough that revenue |
enough that revenue can |
that revenue can be |
revenue can be approximated |
can be approximated as |
be approximated as its |
approximated as its convergence |
as its convergence limit |
on onon yxyx p |
onon yxyx p p |
in each round the |
yxyx p p qpqp |
each round the system |
round the system takes |
the system takes s |
system takes s steps |
takes s steps and |
z onon yxyx p |
s steps and then |
onon yxyx p p |
steps and then a |
yxyx p p qppq |
and then a single |
then a single pool |
picked with a round |
z on yx p |
on yx p qp |
z onon yxxy p |
may change its infiltration |
onon yxxy p p |
change its infiltration rates |
yxxy p p qpqp |
its infiltration rates of |
infiltration rates of all |
rates of all other |
of all other pools |
the total revenue of |
z on yx p |
total revenue of each |
on yx p qp |
a scalable and tcp |
revenue of each step |
of each step is |
each step is normalized |
step is normalized to |
friendly congestion control for |
congestion control for high |
z time spent on |
time spent on invalidations |
so the revenue per |
the revenue per round |
revenue per round is |
per round is one |
the pool taking a |
pool taking a step |
taking a step knows |
a step knows the |
step knows the rate |
knows the rate of |
the rate of infiltrators |
rate of infiltrators attacking |
of infiltrators attacking it |
though not their identity |
and the revenue rates |
the revenue rates of |
revenue rates of each |
rates of each of |
of each of the |
each of the other |
of the other pools |
average store rpc duration |
this knowledge is required |
knowledge is required to |
is required to optimize |
required to optimize a |
to optimize a pool |
optimize a pool s |
a pool s revenue |
as we see next |
we explain in section |
explain in section viii |
in section viii how |
section viii how a |
viii how a pool |
how a pool can |
a pool can technically |
pool can technically obtain |
can technically obtain this |
technically obtain this knowledge |
general analysis recall that |
analysis recall that mi |
recall that mi is |
that mi is the |
mi is the number |
is the number of |
the number of miners |
number of miners loyal |
of miners loyal to |
miners loyal to pool |
loyal to pool i |
is the number of |
the number of miners |
number of miners used |
of miners used by |
miners used by pool |
used by pool i |
by pool i to |
pool i to infiltrate |
i to infiltrate pool |
to infiltrate pool j |
infiltrate pool j at |
third international workshop on |
pool j at step |
j at step t |
international workshop on protocols |
workshop on protocols for |
on protocols for fast |
protocols for fast long |
the mining rate of |
mining rate of pool |
rate of pool i |
of pool i is |
pool i is therefore |
i is therefore the |
is therefore the number |
therefore the number of |
the number of its |
number of its loyal |
of its loyal miners |
its loyal miners minus |
loyal miners minus the |
miners minus the miners |
minus the miners it |
the miners it uses |
miners it uses for |
it uses for infiltration |
this effective mining rate |
effective mining rate is |
mining rate is divided |
rate is divided by |
is divided by the |
divided by the total |
by the total mining |
the total mining rate |
total mining rate in |
mining rate in the |
rate in the system |
namely the number of |
the number of all |
number of all miners |
of all miners that |
all miners that do |
miners that do not |
that do not engage |
do not engage in |
not engage in block |
engage in block withholding |
denote the direct mining |
the direct mining rate |
direct mining rate of |
mining rate of pool |
rate of pool i |
of pool i at |
pool i at step |
i at step t |
at step t by |
step t by pp |
t by pp mi |
packet recovery in high |
by pp mi j |
writes execution time speedup |
v v w w |
speed networks using coding |
v w w ut |
networks using coding and |
w w ut v |
using coding and buffer |
w ut v wv |
coding and buffer management |
ut v wv ut |
execution time speedup execution |
time speedup execution time |
speedup execution time speedup |
execution time speedup execution |
time speedup execution time |
speedup execution time speedup |
execution time speedup no |
time speedup no priorities |
k the revenue density |
the revenue density of |
revenue density of pool |
density of pool i |
of pool i at |
pool i at the |
i at the end |
at the end of |
the end of step |
end of step t |
of step t is |
step t is its |
t is its revenue |
is its revenue from |
its revenue from direct |
revenue from direct mining |
from direct mining together |
direct mining together with |
performance evaluation of forward |
mining together with its |
evaluation of forward error |
together with its revenue |
of forward error correction |
with its revenue from |
forward error correction in |
its revenue from infiltrated |
error correction in atm |
revenue from infiltrated pools |
correction in atm networks |
divided by the number |
by the number of |
the number of its |
number of its loyal |
of its loyal miners |
its loyal miners together |
loyal miners together with |
miners together with block |
graphs for cache consistency |
for cache consistency trace |
withholding infiltrators that attack |
infiltrators that attack it |
these graphs show various |
graphs show various features |
show various features of |
various features of the |
features of the performance |
of the performance results |
async denotes asynchronous invalidations |
and none no invalidations |
diff denotes differentiated writeback |
denotes differentiated writeback priorities |
differentiated writeback priorities for |
writeback priorities for shared |
priorities for shared and |
for shared and unshared |
shared and unshared files |
and unif denotes uniform |
unif denotes uniform priorities |
cc is the mfs |
is the mfs cache |
the mfs cache consistency |
mfs cache consistency algorithm |
the height of a |
height of a bar |
of a bar counts |
a bar counts the |
bar counts the number |
counts the number of |
the number of invalidations |
the white portion counts |
white portion counts the |
portion counts the number |
counts the number of |
the number of server |
our experimental setup consisting |
experimental setup consisting of |
setup consisting of three |
consisting of three hosts |
hereinafter we move to |
we move to a |
move to a static |
to a static state |
a static state analysis |
static state analysis and |
state analysis and omit |
analysis and omit the |
and omit the t |
omit the t argument |
and a writer client |
the t argument in |
t argument in the |
argument in the expressions |
the bandwidth from the |
bandwidth from the reader |
from the reader to |
the reader to the |
reader to the server |
to the server was |
the server was fixed |
server was fixed at |
efficient erasure correcting codes |
ieee transactions on information |
transactions on information theory |
since the row sums |
the row sums of |
row sums of the |
sums of the infiltration |
of the infiltration matrix |
the infiltration matrix are |
infiltration matrix are smaller |
matrix are smaller than |
are smaller than one |
its largest eigenvalue is |
largest eigenvalue is smaller |
and the bandwidth from |
eigenvalue is smaller than |
the bandwidth from the |
bandwidth from the writer |
from the writer to |
the writer to the |
writer to the server |
according to the perron |
to the server was |
the server was varied |
server was varied according |
was varied according to |
varied according to the |
according to the experiment |
the writer was configured |
writer was configured in |
was configured in one |
configured in one of |
in one of seven |
the revenues at all |
one of seven different |
revenues at all pools |
of seven different ways |
at all pools converge |
all pools converge as |
pools converge as follows |
synchronous or no invalidations |
and differentiated or uniform |
differentiated or uniform priorities |
or uniform priorities for |
uniform priorities for writing |
priorities for writing back |
for writing back shared |
writing back shared and |
back shared and unshared |
shared and unshared files |
the mfs concurrency control |
mfs concurrency control algorithm |
corresponds to asynchronous invalidations |
to asynchronous invalidations with |
asynchronous invalidations with differentiated |
invalidations with differentiated priority |
with differentiated priority for |
differentiated priority for shared |
priority for shared files |
both clients access a |
clients access a shared |
access a shared repository |
a shared repository of |
shared repository of files |
repository of files stored |
of files stored on |
files stored on the |
stored on the file |
on the file server |
each module has a |
module has a descriptor |
has a descriptor file |
a descriptor file and |
descriptor file and a |
file and a set |
and a set of |
workloads with contention between |
with contention between priority |
contention between priority levels |
the pool game if |
rd annual ieee symposium |
pool game if no |
the grep workload consists |
grep workload consists of |
workload consists of validating |
module descriptor files are |
descriptor files are about |
consists of validating cached |
of validating cached files |
game if no pool |
kb in size and |
in size and the |
if no pool engages |
annual ieee symposium on |
ieee symposium on foundations |
no pool engages in |
pool engages in block |
symposium on foundations of |
on foundations of computer |
engages in block withholding |
elapsed time to compile |
time to compile mafs |
foundations of computer science |
member files take up |
files take up an |
take up an average |
up an average of |
the total size of |
total size of all |
size of all the |
of all the files |
all the files in |
the files in the |
files in the collection |
in the collection is |
and we have i |
the writer workload consists |
writer workload consists of |
workload consists of the |
consists of the writer |
of the writer updating |
the writer updating modules |
writer updating modules in |
updating modules in a |
modules in a random |
in a random order |
writes execution time speedup |
an update to a |
update to a module |
to a module consists |
each miner s revenue |
miner s revenue is |
a module consists of |
s revenue is proportional |
module consists of a |
revenue is proportional to |
consists of a sequence |
is proportional to its |
of a sequence of |
ieee transactions on information |
proportional to its power |
a sequence of operations |
transactions on information theory |
be it in a |
it in a pool |
in a pool or |
a pool or working |
pool or working solo |
distinct processes distinct files |
processes distinct files total |
distinct files total of |
files total of file |
total of file sizes |
recall that difficulty is |
of which are reads |
which are reads and |
that difficulty is only |
difficulty is only adjusted |
is only adjusted periodically |
and there are transient |
there are transient effects |
are transient effects that |
transient effects that are |
effects that are not |
that are not covered |
are not covered by |
are writes to a |
not covered by this |
writes to a file |
covered by this stable |
to a file in |
a file in the |
file in the module |
we discuss this in |
discuss this in section |
this in section viii |
miners miners miners a |
consist of writes to |
of writes to unshared |
writes to unshared external |
to unshared external files |
controls its infiltration rate |
its infiltration rate of |
which are each created |
infiltration rate of pool |
are each created with |
each created with a |
created with a unique |
with a unique name |
there is a pause |
is a pause between |
a pause between each |
pause between each operation |
between each operation and |
each operation and a |
operation and a longer |
and a longer pause |
a longer pause between |
longer pause between updates |
pause between updates to |
between updates to modules |
the reader workload is |
reader workload is similar |
and will choose the |
will choose the value |
choose the value that |
the value that maximizes |
but an access to |
value that maximizes the |
an access to a |
that maximizes the revenue |
access to a module |
maximizes the revenue density |
to a module consists |
a module consists of |
module consists of a |
consists of a series |
of a series of |
a series of reads |
and external files are |
external files are never |
files are never accessed |
the configuration parameters used |
on the first round |
configuration parameters used to |
the first round of |
parameters used to generate |
first round of the |
used to generate the |
round of the pool |
of the pool game |
to generate the reader |
generate the reader and |
the reader and writer |
reader and writer workload |
and writer workload are |
the value of r |
writer workload are listed |
workload are listed in |
are listed in table |
is maximized at a |
maximized at a single |
at a single point |
a single point in |
single point in the |
point in the feasible |
in the feasible range |
the writer workload has |
writer workload has a |
workload has a nominal |
has a nominal duration |
a nominal duration of |
nominal duration of two |
duration of two minutes |
while the reader workload |
the reader workload is |
reader workload is extended |
workload is extended to |
is extended to terminate |
extended to terminate at |
to terminate at the |
terminate at the same |
at the same time |
the same time as |
same time as the |
time as the writer |
as the writer workload |
the writer workload actually |
writer workload actually finishes |
cannot not react to |
since low bandwidth could |
not react to pool |
low bandwidth could extend |
bandwidth could extend its |
could extend its running |
extend its running time |
its running time beyond |
running time beyond two |
time beyond two minutes |
this point is the |
point is the stable |
is the stable state |
the stable state of |
stable state of the |
state of the system |
and we denote the |
we denote the value |
denote the value of |
the value of x |
analysis of the results |
of the results figure |
shows graphs of some |
graphs of some selected |
of some selected results |
some selected results from |
selected results from the |
results from the experiments |
while synchronous writes provide |
synchronous writes provide strong |
writes provide strong concurrency |
provide strong concurrency control |
they resulted in the |
resulted in the lowest |
in the lowest rate |
the lowest rate of |
lowest rate of completed |
rate of completed writes |
of completed writes in |
completed writes in all |
writes in all the |
in all the tests |
since the writer had |
the writer had no |
writer had no possibility |
had no possibility of |
no possibility of over |
and the values of |
the values of the |
values of the corresponding |
of the corresponding revenues |
the corresponding revenues of |
corresponding revenues of the |
revenues of the pools |
of the pools with |
the pools with r |
lapping think time with |
think time with asynchronous |
time with asynchronous writeback |
at all bandwidth levels |
all bandwidth levels the |
bandwidth levels the mfs |
substituting the stable value |
cc algorithm outperformed synchronous |
the stable value x |
algorithm outperformed synchronous writes |
outperformed synchronous writes by |
synchronous writes by at |
writes by at least |
we obtain the revenues |
obtain the revenues of |
the revenues of the |
revenues of the two |
of the two pools |
and was among the |
all are given in |
are given in figure |
was among the options |
among the options with |
the options with the |
options with the highest |
with the highest write |
the highest write throughput |
this is clear from |
is clear from graph |
to simplify the expressions |
which shows the average |
shows the average time |
the average time to |
average time to complete |
time to complete store |
to complete store rpcs |
complete store rpcs initiated |
store rpcs initiated by |
rpcs initiated by the |
initiated by the writer |
cc outperforms all of |
outperforms all of the |
all of the alternatives |
this is because of |
is because of the |
because of the reduced |
of the reduced number |
the reduced number of |
reduced number of invalidations |
number of invalidations it |
of invalidations it generates |
in contrast to most |
contrast to most of |
to most of the |
most of the other |
of the other schemes |
it is able to |
is able to take |
able to take advantage |
o ne attacker we |
to take advantage of |
ne attacker we begin |
take advantage of both |
attacker we begin our |
advantage of both differentiated |
we begin our analysis |
of both differentiated writeback |
begin our analysis with |
our analysis with a |
analysis with a simplified |
with a simplified game |
a simplified game of |
simplified game of two |
game of two pools |
pull rpcs to raise |
rpcs to raise the |
to raise the priority |
raise the priority of |
the priority of its |
priority of its writes |
shows the performance from |
the performance from the |
performance from the reader |
from the reader s |
the reader s perspective |
while the writer is |
the writer is able |
writer is able to |
is able to decrease |
able to decrease its |
to decrease its time |
decrease its time spent |
its time spent performing |
time spent performing store |
spent performing store rpcs |
the reader s average |
reader s average time |
s average time spent |
average time spent on |
time spent on fetches |
spent on fetches increases |
on fetches increases sharply |
fetches increases sharply when |
miners outside both pools |
increases sharply when the |
outside both pools mine |
both pools mine solo |
sharply when the file |
when the file in |
the file in question |
file in question must |
in question must be |
question must be pulled |
or with closed pools |
must be pulled from |
with closed pools that |
be pulled from the |
closed pools that do |
pulled from the writer |
pools that do not |
that do not attack |
do not attack and |
not attack and cannot |
attack and cannot be |
and cannot be attacked |
this cost must be |
cost must be weighed |
must be weighed against |
be weighed against the |
weighed against the benefit |
this scenario is illustrated |
against the benefit of |
scenario is illustrated in |
is illustrated in figure |
the benefit of substantially |
benefit of substantially increased |
traffic numbers are for |
numbers are for synchronous |
are for synchronous writeback |
of substantially increased writer |
substantially increased writer throughput |
the dashed red arrow |
dashed red arrow indicates |
red arrow indicates that |
arrow indicates that x |
differentiated writeback succeeds in |
writeback succeeds in reducing |
succeeds in reducing the |
in reducing the time |
reducing the time the |
the time the reader |
time the reader has |
the reader has to |
reader has to wait |
has to wait when |
to wait when accessing |
wait when accessing a |
when accessing a shared |
accessing a shared file |
s mining power infiltrates |
mining power infiltrates pool |
with a block withholding |
a block withholding attack |
compiling mafs on top |
mafs on top of |
on top of mafs |
does not engage in |
not engage in block |
engage in block withholding |
show statistics for invalidations |
statistics for invalidations and |
for invalidations and serverpull |
invalidations and serverpull rpcs |
all of its m |
and serverpull rpcs for |
serverpull rpcs for those |
rpcs for those writer |
for those writer configurations |
those writer configurations which |
loyal miners work on |
miners work on its |
work on its behalf |
writer configurations which make |
configurations which make use |
which make use of |
bandwidth is high enough |
is high enough to |
high enough to eliminate |
enough to eliminate differences |
to eliminate differences between |
eliminate differences between writeback |
differences between writeback schemes |
make use of them |
on the other hand |
the other hand does |
other hand does not |
hand does not employ |
does not employ x |
asynchronous writeback is clearly |
writeback is clearly beneficial |
cc significantly reduces the |
significantly reduces the number |
and priortwo questions are |
reduces the number of |
priortwo questions are of |
questions are of particular |
are of particular interest |
of particular interest in |
particular interest in evaluating |
interest in evaluating the |
in evaluating the perfor |
the number of invalidations |
of its loyal miners |
number of invalidations it |
of invalidations it must |
ities are advantageous in |
invalidations it must transmit |
are advantageous in reducing |
and its direct mining |
it must transmit by |
advantageous in reducing contention |
its direct mining power |
must transmit by putting |
in reducing contention between |
reducing contention between reading |
contention between reading mance |
between reading mance of |
reading mance of mafs |
mance of mafs communication |
of mafs communication adaptation |
direct mining power is |
transmit by putting off |
mining power is only |
power is only m |
by putting off invalidating |
putting off invalidating a |
off invalidating a file |
invalidating a file until |
a file until it |
file until it is |
until it is added |
it is added to |
is added to the |
added to the log |
which is not possible |
is not possible when |
not possible when synchronous |
possible when synchronous writeback |
when synchronous writeback is |
synchronous writeback is used |
yet the effect of |
the effect of this |
effect of this policy |
of this policy on |
this policy on the |
policy on the number |
on the number of |
the bitcoin system normalizes |
the number of serverpull |
bitcoin system normalizes these |
number of serverpull rpcs |
system normalizes these rates |
of serverpull rpcs is |
serverpull rpcs is minor |
normalizes these rates by |
do priorities improve performance |
these rates by the |
priorities improve performance by |
rates by the total |
improve performance by reducing |
performance by reducing rpc |
by reducing rpc conthe |
reducing rpc conthe second |
by the total number |
the total number of |
which differs from mfs |
rpc conthe second microbenchmark |
conthe second microbenchmark evaluates |
second microbenchmark evaluates a |
microbenchmark evaluates a workload |
cc in omitting differentiated |
in omitting differentiated writeback |
total number of miners |
number of miners that |
of miners that publish |
miners that publish full |
that publish full proofs |
evaluates a workload that |
a workload that contention |
makes more invalidations and |
more invalidations and incurs |
namely all miners but |
all miners but x |
invalidations and incurs more |
and incurs more server |
tains explicit contention between |
explicit contention between different |
contention between different types |
between different types of |
different types of rpc |
types of rpc traf |
because its store rpcs |
its store rpcs must |
store rpcs must compete |
rpcs must compete with |
is it possible to |
it possible to combine |
possible to combine the |
to combine the benefit |
combine the benefit of |
the benefit of asynchronous |
benefit of asynchronous write |
the pools direct revenues |
must compete with the |
pools direct revenues are |
compete with the rpcs |
direct revenues are therefore |
with the rpcs to |
revenues are therefore m |
the rpcs to write |
rpcs to write back |
to write back external |
write back external files |
this increases the commit |
increases the commit delay |
the commit delay for |
commit delay for each |
delay for each file |
for each file and |
one process performs a |
each file and the |
process performs a grep |
file and the likelihood |
performs a grep on |
and the likelihood of |
a grep on a |
the likelihood of it |
grep on a set |
likelihood of it being |
on a set of |
of it being accessed |
a set of back |
it being accessed by |
set of back at |
being accessed by the |
accessed by the reader |
by the reader while |
the reader while it |
reader while it is |
while it is being |
it is being written |
is being written back |
of back at low |
back at low bandwidth |
at low bandwidth with |
low bandwidth with acceptable |
bandwidth with acceptable performance |
with acceptable performance at |
acceptable performance at cached |
performance at cached files |
these experiments demonstrate that |
experiments demonstrate that for |
demonstrate that for the |
that for the trace |
for the trace we |
the trace we have |
trace we have examined |
at cached files that |
cached files that need |
files that need to |
that need to be |
need to be validated |
to be validated before |
be validated before they |
validated before they can |
before they can be |
they can be opened |
the mfs algorithm of |
mfs algorithm of asynchronous |
algorithm of asynchronous invalidations |
of asynchronous invalidations and |
asynchronous invalidations and differentiated |
divides its revenue among |
invalidations and differentiated writeback |
its revenue among its |
and differentiated writeback is |
revenue among its loyal |
differentiated writeback is able |
among its loyal miners |
writeback is able to |
its loyal miners and |
is able to maintain |
another process either writes |
process either writes higher |
either writes higher bandwidths |
loyal miners and the |
able to maintain cache |
miners and the miners |
to maintain cache consistency |
and the miners that |
maintain cache consistency between |
the miners that infiltrated |
cache consistency between the |
miners that infiltrated it |
data to files rapidly |
consistency between the two |
enforcing fairness in a |
between the two clients |
fairness in a live |
its revenue density is |
the two clients and |
revenue density is therefore |
two clients and to |
density is therefore r |
clients and to allow |
and to allow the |
streaming system maya haridasana |
to allow the writer |
allow the writer to |
the writer to write |
writer to write back |
to write back changes |
grepwe compare mafs to |
compare mafs to alternative |
mafs to alternative approaches |
to alternative approaches in |
alternative approaches in two |
approaches in two sets |
in two sets of |
two sets of compile |
portob and robbert van |
write back changes to |
and robbert van renessea |
back changes to the |
robbert van renessea a |
changes to the stored |
van renessea a dept |
to the stored data |
the stored data faster |
stored data faster than |
data faster than is |
faster than is possible |
than is possible with |
is possible with the |
possible with the alternative |
with the alternative schemes |
one process reads files |
process reads files at |
reads files at the |
files at the same |
at the same experiments |
we intend to further |
new york b institute |
intend to further evaluate |
york b institute of |
b institute of informatics |
microbenchmarks to measure execution |
to measure execution time |
measure execution time time |
execution time time as |
federal university of rio |
to further evaluate the |
further evaluate the perfor |
divides its revenue among |
university of rio grande |
of rio grande do |
its revenue among its |
revenue among its registered |
rio grande do sul |
grande do sul porto |
do sul porto alegre |
among its registered miners |
time time as another |
time as another is |
as another is writing |
another is writing files |
references mance of the |
the revenue includes both |
mance of the algorithm |
revenue includes both its |
of the algorithm to |
includes both its direct |
the algorithm to determine |
both its direct mining |
algorithm to determine its |
its direct mining revenue |
to determine its effectiveness |
direct mining revenue and |
determine its effectiveness under |
mining revenue and the |
its effectiveness under other |
effectiveness under other workloads |
revenue and the revenue |
shows that priorispeedup for |
that priorispeedup for simple |
priorispeedup for simple workloads |
and with more clients |
and the revenue its |
the revenue its infiltrators |
revenue its infiltrators obtained |
its infiltrators obtained from |
infiltrators obtained from pool |
and traces of actual |
traces of actual windows |
of actual windows ties |
actual windows ties are |
windows ties are beneficial |
ties are beneficial for |
are beneficial for the |
beneficial for the small |
for the small validation |
the small validation rpcs |
small validation rpcs when |
validation rpcs when the |
rpcs when the backnt |
when the backnt file |
the backnt file system |
edu abstract we describe |
abstract we describe a |
we describe a practical |
describe a practical auditing |
a practical auditing approach |
practical auditing approach designed |
auditing approach designed to |
approach designed to encourage |
designed to encourage fairness |
to encourage fairness in |
encourage fairness in peer |
evaluation of an adaptive |
of an adaptive transport |
an adaptive transport protocol |
the revenue per loyal |
revenue per loyal pool |
the ntfs traces were |
ntfs traces were gathered |
traces were gathered ground |
were gathered ground traffic |
gathered ground traffic is |
ground traffic is heavy |
miner is therefore r |
in proceedings of the |
auditing is employed to |
with the sporadic background |
is employed to ensure |
the sporadic background traffic |
employed to ensure that |
sporadic background traffic in |
to ensure that correct |
nd annual joint conference |
background traffic in the |
traffic in the cornell |
in the cornell university |
the cornell university computer |
cornell university computer science |
university computer science department |
annual joint conference of |
ensure that correct nodes |
joint conference of the |
that correct nodes are |
and of compiling mafs |
conference of the ieee |
correct nodes are able |
of the ieee computer |
nodes are able to |
improvements are confined to |
the ieee computer and |
are able to receive |
are confined to low |
ieee computer and communications |
able to receive streams |
confined to low bandcontain |
computer and communications societies |
to receive streams even |
to low bandcontain access |
receive streams even in |
low bandcontain access to |
streams even in the |
bandcontain access to local |
even in the presence |
we obtain the expression |
obtain the expression for |
the expression for r |
access to local and |
in the presence of |
to local and remote |
the presence of nodes |
presence of nodes that |
of nodes that do |
nodes that do not |
that do not upload |
do not upload enough |
not upload enough data |
local and remote file |
and remote file systems |
remote file systems by |
file systems by clients |
systems by clients in |
by clients in a |
clients in a width |
in a width levels |
and scales well when |
scales well when compared |
well when compared to |
when compared to previous |
compared to previous solutions |
to previous solutions that |
previous solutions that rely |
solutions that rely on |
that rely on tit |
demonstrates that priorities can |
that priorities can imlocal |
tat style of data |
style of data exchange |
auditing involves two roles |
conclusion the growing use |
the growing use of |
growing use of mobile |
use of mobile computers |
of mobile computers and |
mobile computers and wireless |
computers and wireless networks |
untrusted local auditors run |
and wireless networks has |
local auditors run on |
wireless networks has greatly |
priority read performance with |
read performance with only |
performance with only a |
with only a small |
only a small overhead |
a small overhead for |
small overhead for writes |
auditors run on all |
networks has greatly increased |
run on all nodes |
has greatly increased the |
on all nodes in |
greatly increased the scope |
all nodes in the |
increased the scope for |
the scope for adapting |
nodes in the system |
these microbenchmarks show that |
scope for adapting data |
for adapting data access |
adapting data access to |
and are responsible for |
data access to vary |
microbenchmarks show that asynmicrobenchmarks |
are responsible for collecting |
show that asynmicrobenchmarks chronous |
responsible for collecting and |
that asynmicrobenchmarks chronous writeback |
for collecting and maintaining |
asynmicrobenchmarks chronous writeback improves |
collecting and maintaining accountable |
chronous writeback improves performance |
and maintaining accountable information |
writeback improves performance even |
maintaining accountable information regarding |
improves performance even at |
accountable information regarding data |
performance even at comparaour |
even at comparaour first |
at comparaour first microbenchmark |
comparaour first microbenchmark compiles |
first microbenchmark compiles mafs |
microbenchmark compiles mafs from |
information regarding data sent |
regarding data sent and |
data sent and received |
sent and received by |
and received by each |
received by each node |
one or more trusted |
mb of tively high |
of tively high bandwidths |
or more trusted global |
more trusted global auditors |
trusted global auditors periodically |
global auditors periodically sample |
and priorities are effective |
priorities are effective in |
are effective in mitigating |
auditors periodically sample the |
periodically sample the state |
we analyze this game |
analyze this game numerically |
sample the state of |
the state of participating |
this game numerically by |
game numerically by finding |
numerically by finding the |
by finding the x |
this paper has explored |
state of participating nodes |
effective in mitigating source |
in mitigating source code |
mitigating source code stored |
source code stored in |
code stored in an |
stored in an mafs |
in an mafs filesystem |
paper has explored applying |
estimate whether the streaming |
has explored applying and |
whether the streaming quality |
explored applying and j |
the streaming quality is |
streaming quality is satisfactory |
and substituting this value |
substituting this value for |
this value for r |
and decide whether any |
decide whether any actions |
whether any actions are |
any actions are required |
mb contention between different |
contention between different classes |
between different classes of |
different classes of rpcs |
measurements of a distributed |
we demonstrate through simulation |
we vary the sizes |
of output in the |
output in the same |
in the same filesystem |
vary the sizes of |
demonstrate through simulation that |
of a distributed file |
the sizes of the |
through simulation that our |
a distributed file the |
sizes of the pools |
compares the execution time |
distributed file the technique |
simulation that our approach |
of the pools through |
the execution time speedup |
file the technique of |
that our approach can |
the pools through the |
execution time speedup for |
the technique of modeless |
our approach can successfully |
pools through the entire |
time speedup for the |
technique of modeless adaptation |
approach can successfully detect |
through the entire feasible |
the entire feasible range |
of modeless adaptation to |
can successfully detect and |
speedup for the benchmark |
entire feasible range and |
modeless adaptation to a |
successfully detect and react |
for the benchmark under |
the benchmark under differing |
benchmark under differing asynchronous |
under differing asynchronous writeback |
differing asynchronous writeback and |
asynchronous writeback and priority |
writeback and priority schemes |
feasible range and depict |
adaptation to a distributed |
detect and react to |
range and depict the |
and depict the optimal |
depict the optimal x |
and react to the |
to a distributed file |
a distributed file system |
distributed file system system |
as bandwidth is var |
react to the presence |
to the presence of |
the presence of opportunistic |
in proceedings of the |
presence of opportunistic nodes |
of opportunistic nodes in |
opportunistic nodes in streaming |
and the corresponding revenues |
we evaluated mafs at |
evaluated mafs at a |
mafs at a larger |
at a larger scale |
a larger scale using |
th acm symposium to |
the corresponding revenues in |
corresponding revenues in figure |
nodes in streaming sessions |
acm symposium to improve |
symposium to improve its |
to improve its performance |
larger scale using the |
scale using the ntfs |
the cache manager for |
each point in each |
it incurs low network |
cache manager for our |
manager for our mfs |
point in each graph |
incurs low network and |
low network and computational |
for our mfs on |
in each graph represents |
derived the dominant feature |
the dominant feature of |
dominant feature of figure |
each graph represents the |
network and computational overheads |
our mfs on operating |
graph represents the equilibrium |
is that asynchronous write |
mfs on operating systems |
represents the equilibrium point |
which remain fixed as |
traces summarised in table |
the equilibrium point of |
on operating systems principles |
remain fixed as the |
equilibrium point of a |
fixed as the system |
point of a game |
as the system scales |
of a game with |
a game with the |
game with the corresponding |
with the corresponding m |
although the original execution |
the original execution back |
original execution back is |
execution back is beneficial |
back is beneficial at |
is beneficial at all |
beneficial at all bandwidths |
at all bandwidths until |
introduction video and audio |
video and audio streaming |
and audio streaming account |
where we normalize m |
audio streaming account for |
streaming account for a |
account for a large |
for a large percentage |
a large percentage of |
there is less times |
is less times of |
less times of these |
times of these traces |
of these traces were |
pacific file system incorporates |
these traces were short |
traces were short on |
the top right half |
large percentage of content |
percentage of content accessed |
file system incorporates features |
top right half of |
were short on windows |
short on windows nt |
system incorporates features that |
right half of the |
of content accessed over |
incorporates features that are |
half of the range |
content accessed over the |
accessed over the web |
features that are not |
of the range in |
the range in all |
that are not present |
are not present in |
range in all graphs |
in all graphs is |
all graphs is not |
graphs is not feasible |
they execute improvement at |
one popular style of |
not present in existing |
present in existing grove |
popular style of streaming |
as the sum of |
the sum of m |
style of streaming on |
of streaming on the |
streaming on the web |
on the web is |
the web is on |
web is on demand |
where throughput is so |
throughput is so low |
is so low that |
so low that con |
in which users access |
which users access pre |
slowly on mafs due |
we use this range |
use this range as |
this range as a |
stored content at will |
on mafs due to |
mafs due to high |
due to high bandwidth |
to high bandwidth requirements |
range as a reference |
as a reference color |
another style requires streams |
file systems for mobile |
trol traffic and the |
systems for mobile hosts |
style requires streams to |
requires streams to be |
and we use a |
traffic and the delay |
adaptation to bandwidth variation |
we use a dashed |
and the delay in |
the delay in fetching |
delay in fetching files |
in fetching files become |
fetching files become dominating |
files become dominating figure |
use a dashed line |
streams to be generated |
to bandwidth variation through |
a dashed line to |
to be generated and |
bandwidth variation through the |
variation through the use |
dashed line to show |
be generated and disseminated |
generated and disseminated in |
and disseminated in real |
line to show the |
shows execution times under |
through the use of |
to show the bound |
show the bound between |
the use of prioritised |
use of prioritised communication |
the bound between this |
execution times under four |
times under four combinations |
under four combinations of |
four combinations of writeback |
combinations of writeback scheme |
of writeback scheme and |
writeback scheme and priorities |
this may be the |
bound between this value |
may be the case |
between this value within |
be the case with |
this value within the |
the case with important |
value within the feasible |
case with important social |
within the feasible range |
a shows the optimal |
shows the optimal infiltration |
an important property of |
important property of live |
the optimal infiltration rate |
streaming is that data |
is that data is |
in the entire feasible |
o hint genercache consistency |
that data is not |
the entire feasible range |
hint genercache consistency protocol |
data is not available |
entire feasible range we |
genercache consistency protocol using |
is not available in |
not available in advance |
consistency protocol using file |
feasible range we see |
protocol using file access |
range we see that |
being generated just before |
using file access information |
we see that pool |
generated just before transmission |
file access information to |
just before transmission at |
access information to imation |
before transmission at the |
information to imation through |
chooses a strictly positive |
transmission at the sender |
to imation through speculative |
a strictly positive value |
imation through speculative execution |
strictly positive value for |
positive value for x |
in operating systems prove |
operating systems prove performance |
interested users ideally want |
users ideally want to |
ideally want to receive |
want to receive the |
to receive the stream |
receive the stream without |
the stream without much |
stream without much delay |
without much delay from |
much delay from its |
delay from its original |
from its original transmission |
the revenue of pool |
streaming systems now allow |
is depicted in figure |
systems now allow large |
now allow large numbers |
allow large numbers of |
large numbers of interested |
numbers of interested users |
b and in the |
of interested users to |
and in the entire |
interested users to receive |
in the entire feasible |
users to receive streamed |
the entire feasible region |
to receive streamed data |
entire feasible region it |
receive streamed data in |
feasible region it is |
streamed data in near |
region it is strictly |
data in near real |
it is strictly larger |
in near real time |
we have evaluated the |
is strictly larger than |
have evaluated the effect |
evaluated the effect of |
without requiring extensive amounts |
the effect of these |
requiring extensive amounts of |
effect of these features |
extensive amounts of resources |
of these features on |
which the pool would |
these features on performance |
the pool would have |
features on performance at |
pool would have gotten |
these systems are based |
on performance at varying |
would have gotten without |
systems are based on |
performance at varying bandwidth |
have gotten without attacking |
are based on the |
based on the peer |
at varying bandwidth levels |
varying bandwidth levels and |
bandwidth levels and under |
levels and under both |
and under both synthetic |
under both synthetic and |
both synthetic and real |
where nodes interested in |
nodes interested in receiving |
interested in receiving data |
in receiving data also |
receiving data also help |
data also help disseminate |
also help disseminate it |
help disseminate it to |
disseminate it to each |
it to each other |
c depicts the revenue |
depicts the revenue of |
the revenue of pool |
alleviating the bottleneck at |
the bottleneck at the |
bottleneck at the source |
initial protocols were based |
which is strictly smaller |
protocols were based on |
is strictly smaller than |
were based on building |
based on building a |
on building a tree |
in the entire range |
based overlay of nodes |
overlay of nodes through |
of nodes through which |
including a workload emulating |
nodes through which data |
a workload emulating collaborative |
through which data would |
workload emulating collaborative data |
note that the total |
which data would be |
that the total system |
data would be pushed |
the total system mining |
total system mining power |
system mining power is |
mining power is reduced |
power is reduced when |
is reduced when pool |
chooses to infiltrate pool |
such as chainsaw and |
as chainsaw and coolstreaming |
performance measurements access with |
measurements access with high |
access with high read |
the revenue of third |
revenue of third parties |
have shown that the |
shown that the use |
that the use of |
the use of a |
use of a mesh |
miners not in either |
not in either pool |
of a mesh of |
and found that while |
a mesh of connected |
found that while the |
mesh of connected nodes |
that while the of |
of connected nodes and |
while the of automatic |
connected nodes and a |
the of automatic prefetching |
nodes and a pull |
in proceedings of the |
proceedings of the isca |
based data dissemination approach |
of the isca interadditional |
data dissemination approach can |
the isca interadditional costs |
dissemination approach can provide |
isca interadditional costs imposed |
approach can provide similar |
interadditional costs imposed are |
can provide similar results |
costs imposed are mostly |
provide similar results with |
imposed are mostly hidden |
similar results with better |
results with better resilience |
with better resilience to |
better resilience to failures |
resilience to failures and |
to failures and churn |
they can have benenational |
can have benenational conference |
have benenational conference on |
benenational conference on parallel |
conference on parallel and |
nodes joining and leaving |
on parallel and distributed |
joining and leaving the |
parallel and distributed computfits |
and leaving the system |
and distributed computfits which |
distributed computfits which are |
computfits which are very |
which are very visible |
therefore pays for the |
pays for the increased |
for the increased revenue |
the increased revenue of |
increased revenue of its |
revenue of its attacker |
of its attacker and |
its attacker and everyone |
attacker and everyone else |
and everyone else in |
everyone else in the |
else in the system |
modal nature of ing |
nature of ing systems |
implications to the general |
to the general case |
the general case consider |
general case consider the |
nodes notify each other |
case consider the case |
consider the case of |
the case of p |
case of p pools |
notify each other of |
each other of receipt |
other of receipt of |
of receipt of data |
receipt of data packets |
for any choice of |
any choice of the |
choice of the pools |
of the pools sizes |
the pools sizes m |
and request packets from |
request packets from their |
packets from their neighbors |
from their neighbors based |
their neighbors based on |
neighbors based on the |
based on the received |
on the received notifications |
adaptation in mfs allows |
in mfs allows clients |
mfs allows clients to |
allows clients to adapt |
practical systems based on |
systems based on pull |
clients to adapt quickly |
to adapt quickly to |
adapt quickly to a |
quickly to a variety |
to a variety of |
based streaming now exist |
a variety of bandwidth |
streaming now exist in |
now exist in china |
variety of bandwidth conditions |
of bandwidth conditions without |
bandwidth conditions without substantial |
conditions without substantial changes |
without substantial changes in |
substantial changes in operation |
where they are used |
at least one pool |
they are used to |
least one pool will |
are used to disseminate |
one pool will choose |
used to disseminate television |
pool will choose to |
to disseminate television channels |
will choose to perform |
disseminate television channels to |
choose to perform block |
television channels to thousands |
channels to thousands of |
to thousands of users |
to perform block withholding |
even though the p |
in a system with |
p paradigm allows systems |
a system with p |
system with p pools |
paradigm allows systems to |
allows systems to scale |
systems to scale with |
to scale with the |
scale with the number |
with the number of |
the number of users |
it also leaves them |
also leaves them vulnerable |
leaves them vulnerable to |
them vulnerable to opportunistic |
vulnerable to opportunistic behavior |
opportunistic nodes attempt to |
nodes attempt to receive |
attempt to receive a |
is not an equilibrium |
to receive a stream |
receive a stream without |
a stream without uploading |
stream without uploading their |
without uploading their fair |
uploading their fair share |
their fair share of |
fair share of data |
our evaluation has included |
assume towards negation this |
evaluation has included comparisons |
towards negation this is |
has included comparisons of |
reducing the overall upload |
negation this is not |
included comparisons of mfs |
the overall upload capacity |
this is not the |
comparisons of mfs to |
overall upload capacity of |
is not the case |
of mfs to cache |
upload capacity of the |
mfs to cache manm |
capacity of the system |
elapsed time for all |
time for all fetch |
for all fetch rpcs |
despite the damage that |
the damage that they |
damage that they may |
that they may cause |
not much work has |
much work has been |
work has been done |
has been done in |
been done in studying |
done in studying mechanisms |
in studying mechanisms to |
is an equilibrium point |
studying mechanisms to avoid |
mechanisms to avoid their |
to avoid their presence |
avoid their presence in |
their presence in live |
mostly writes mostly reads |
writes mostly reads trace |
mostly reads trace mixed |
now consider a setting |
consider a setting with |
a setting with only |
ager configurations corresponding to |
mostly writes mostly reads |
writes mostly reads trace |
mostly reads trace mixed |
setting with only pools |
the goal of this |
configurations corresponding to prior |
goal of this the |
of this the authors |
corresponding to prior work |
mostly writes mostly reads |
writes mostly reads trace |
mostly reads trace mixed |
reads trace mixed figure |
and confirmed scale and |
this the authors were |
and treat the other |
confirmed scale and performance |
the authors were supported |
treat the other pools |
scale and performance in |
authors were supported by |
the other pools as |
and performance in a |
were supported by afrl |
other pools as independent |
performance in a distributed |
supported by afrl award |
trace duration for asynchronous |
in a distributed file |
by afrl award fa |
pools as independent miners |
duration for asynchronous writes |
a distributed file system |
for asynchronous writes is |
asynchronous writes is until |
writes is until completion |
is until completion of |
until completion of the |
completion of the last |
of the last read |
this is the setting |
acm that there are |
is the setting analyzed |
that there are situations |
the setting analyzed above |
server is beneficial in |
is beneficial in the |
beneficial in the mostly |
in the mostly writes |
the mostly writes trace |
there are situations in |
setting analyzed above and |
are situations in which |
analyzed above and we |
situations in which mfs |
in which mfs would |
above and we have |
and we have seen |
which mfs would outperform |
mfs would outperform afs |
we have seen there |
have seen there that |
seen there that pool |
which has high readwrite |
has high readwrite contention |
transactions on computer systems |
can increase its revenue |
increase its revenue by |
its revenue by performing |
revenue by performing a |
by performing a block |
performing a block withholding |
a block withholding attack |
block withholding attack on |
withholding attack on pool |
it is less effective |
is less effective than |
less effective than synchronous |
effective than synchronous writeback |
s infiltration rate by |
infiltration rate by x |
due to increased contention |
but this effect is |
this effect is mitigated |
effect is mitigated by |
is mitigated by using |
mitigated by using priorities |
this is clearer in |
is clearer in the |
clearer in the graph |
in the graph for |
the graph for time |
graph for time spent |
for time spent on |
time spent on fetch |
spent on fetch rpcs |
at the timescales in |
the timescales in the |
timescales in the ntfs |
in the ntfs traces |
take this values p |
this values p m |
the improvements are less |
improvements are less dramatic |
are less dramatic than |
less dramatic than in |
dramatic than in the |
than in the microbenchmarks |
coda and little work |
but they demonstrate that |
they demonstrate that mafs |
demonstrate that mafs can |
that mafs can improve |
mafs can improve the |
can improve the performance |
improve the performance of |
the performance of large |
these earlier systems were |
earlier systems were designed |
systems were designed for |
were designed for a |
designed for a mobile |
for a mobile environment |
a mobile environment which |
mobile environment which is |
environment which is substantially |
which is substantially different |
store rpc begins to |
rpc begins to arrive |
begins to arrive store |
to arrive store rpc |
arrive store rpc received |
store rpc received dat |
rpc received dat ar |
received dat ar re |
dat ar re sto |
ar re sto reply |
re sto reply ata |
sto reply ata e |
reply ata e d |
ata e d stor |
e d stor pc |
d stor pc time |
stor pc time open |
pc time open file |
time open file for |
open file for writing |
file for writing close |
for writing close file |
replay log log update |
log log update store |
log update store rpc |
partially connected operafrom that |
connected operafrom that available |
operafrom that available today |
update store rpc complete |
store rpc complete writeback |
rpc complete writeback window |
complete writeback window analysis |
writeback window analysis client |
window analysis client both |
analysis client both experiments |
client both experiments confirm |
both experiments confirm the |
experiments confirm the benefits |
confirm the benefits of |
the benefits of asynchronous |
benefits of asynchronous writeback |
mfs is able to |
is able to provide |
able to provide tion |
even at bandwidths where |
at bandwidths where a |
bandwidths where a typical |
where a typical mobile |
a typical mobile file |
typical mobile file system |
mobile file system performs |
file system performs all |
system performs all rpcs |
performs all rpcs synchronously |
asynchronous writeback avoids the |
writeback avoids the need |
avoids the need to |
the need to switch |
need to switch operation |
to switch operation into |
switch operation into a |
operation into a distinct |
into a distinct low |
and choosing a bandwidth |
choosing a bandwidth threshold |
a bandwidth threshold at |
bandwidth threshold at which |
threshold at which to |
at which to switch |
when used by themselves |
priorities do not always |
do not always result |
not always result in |
always result in improved |
result in improved performance |
since they are only |
they are only effective |
are only effective if |
only effective if concurrent |
effective if concurrent rpcs |
if concurrent rpcs have |
concurrent rpcs have different |
rpcs have different priorities |
they reduce uservisible delay |
reduce uservisible delay and |
uservisible delay and contention |
delay and contention that |
and contention that is |
contention that is introduced |
that is introduced by |
is introduced by asynchronous |
introduced by asynchronous writeback |
improved performance in periods |
performance in periods of |
in periods of high |
periods of high network |
of high network contention |
high network contention by |
update propagation using asynchronous |
propagation using asynchronous writeback |
using asynchronous writeback at |
asynchronous writeback at all |
writeback at all bandwidths |
at all bandwidths delays |
all bandwidths delays sending |
bandwidths delays sending updates |
delays sending updates to |
sending updates to the |
updates to the file |
to the file server |
the views and conclusions |
views and conclusions herein |
and conclusions herein are |
conclusions herein are those |
herein are those of |
are those of the |
those of the authors |
we evaluate the effectiveness |
evaluate the effectiveness of |
the effectiveness of an |
effectiveness of an update |
of an update propagation |
an update propagation scheme |
update propagation scheme to |
propagation scheme to reduce |
scheme to reduce this |
to reduce this delay |
mafs allows a client |
allows a client to |
a client to delay |
client to delay transmitting |
to delay transmitting updates |
but the file server |
the file server forces |
file server forces file |
server forces file updates |
forces file updates to |
file updates to be |
updates to be written |
to be written back |
be written back when |
written back when another |
back when another client |
mofavouring cache validation and |
when another client must |
another client must read |
client must read an |
must read an up |
cache validation and rpcs |
validation and rpcs to |
and rpcs to retrieve |
rpcs to retrieve files |
to retrieve files over |
retrieve files over other |
files over other bile |
date copy of the |
copy of the file |
over other bile computing |
other bile computing with |
bile computing with the |
computing with the rover |
with the rover toolkit |
ieee transactypes of traffic |
timeline of a file |
of a file update |
we have not compared |
have not compared mfs |
not compared mfs with |
compared mfs with lbfs |
mfs with lbfs since |
with lbfs since tions |
lbfs since tions on |
since tions on computers |
time advances from left |
advances from left to |
from left to right |
special issue on mobile |
issue on mobile computing |
client will access stale |
will access stale data |
their approaches are orthogonal |
due to network latency |
the writeback window can |
writeback window can never |
window can never be |
can never be eliminated |
but adding an additional |
adding an additional delay |
an additional delay before |
additional delay before writing |
delay before writing back |
before writing back the |
writing back the update |
back the update increases |
the update increases the |
update increases the scope |
increases the scope for |
the scope for inconsistency |
illustrates how this inconsistency |
how this inconsistency can |
this inconsistency can arise |
like file system such |
file system such as |
system such as mafs |
a different type of |
different type of inconsistency |
type of inconsistency is |
of inconsistency is introduced |
inconsistency is introduced between |
is introduced between a |
introduced between a client |
between a client and |
a client and the |
client and the server |
and the server when |
the server when a |
server when a file |
when a file is |
a file is modified |
minimum and average download |
and average download rates |
average download rates across |
download rates across all |
since the change is |
the change is hidden |
change is hidden from |
is hidden from the |
hidden from the server |
from the server until |
the server until the |
server until the file |
until the file is |
the file is closed |
rates across all nodes |
across all nodes when |
all nodes when using |
nodes when using the |
for the purposes of |
not present in the |
when using the bar |
using the bar gossip |
the bar gossip and |
bar gossip and chainsaw |
gossip and chainsaw protocols |
the purposes of this |
purposes of this investigation |
of this investigation we |
this investigation we assume |
investigation we assume that |
we assume that the |
assume that the open |
present in the earlier |
paper is to propose |
in the earlier systems |
is to propose and |
the earlier systems we |
earlier systems we have |
to propose and evaluate |
close interval for a |
systems we have compared |
we have compared against |
interval for a file |
propose and evaluate a |
for a file is |
we anticipate that implementing |
and evaluate a mechanism |
evaluate a mechanism that |
anticipate that implementing lbfs |
that implementing lbfs file |
a mechanism that can |
mechanism that can defend |
implementing lbfs file chunks |
lbfs file chunks in |
that can defend against |
can defend against this |
file chunks in mfs |
chunks in mfs would |
defend against this problem |
a file is small |
file is small relative |
is small relative to |
small relative to the |
stable state where only |
state where only pool |
whithout incurring large overheads |
relative to the network |
to the network latency |
the network latency and |
network latency and writeback |
latency and writeback delay |
the approach that most |
approach that most closely |
that most closely relates |
most closely relates to |
the update propagation techniques |
closely relates to our |
relates to our work |
to our work is |
our work is the |
work is the bar |
is the bar gossip |
the bar gossip protocol |
update propagation techniques we |
propagation techniques we describe |
techniques we describe can |
we describe can be |
describe can be applied |
can be applied equally |
be applied equally well |
applied equally well to |
which employs a tit |
equally well to individual |
well to individual file |
to individual file writes |
individual file writes as |
file writes as to |
writes as to writeback |
tat approach for encouraging |
approach for encouraging nodes |
for encouraging nodes to |
encouraging nodes to contribute |
further improve performance its |
improve performance its performance |
a node only sends |
node only sends as |
only sends as much |
sends as much data |
as much data to |
and performance in a |
performance in a wide |
much data to another |
data to another node |
to another node as |
another node as it |
node as it receives |
techniques for update propagation |
for update propagation although |
update propagation although coda |
as it receives back |
in proceedin future work |
like file systems can |
file systems can generate |
systems can generate inconsistencies |
can generate inconsistencies between |
generate inconsistencies between clients |
two pools where one |
we plan to investigate |
it provides an elegant |
pools where one infiltrates |
plan to investigate the |
they were designed to |
were designed to permit |
designed to permit a |
to permit a client |
permit a client to |
a client to function |
client to function at |
to function at low |
function at low bandwidth |
to investigate the performance |
provides an elegant solution |
where one infiltrates the |
investigate the performance of |
an elegant solution shown |
rather than for rapid |
than for rapid update |
for rapid update propagation |
elegant solution shown to |
one infiltrates the other |
the performance of ings |
solution shown to tolerate |
performance of ings of |
since it is impractical |
shown to tolerate both |
of ings of the |
optimal infiltration rate x |
it is impractical to |
to tolerate both opportunistic |
ings of the first |
is impractical to lock |
tolerate both opportunistic behavior |
of the first usenix |
impractical to lock files |
both opportunistic behavior and |
the first usenix conference |
to lock files if |
lock files if clients |
first usenix conference on |
opportunistic behavior and other |
behavior and other malicious |
and other malicious attacks |
as a function of |
a function of pool |
function of pool sizes |
files if clients are |
usenix conference on file |
conference on file and |
on file and storage |
if clients are permitted |
file and storage modeless |
clients are permitted to |
and storage modeless adaptation |
storage modeless adaptation and |
are permitted to modify |
tat does present a |
modeless adaptation and mfs |
adaptation and mfs in |
permitted to modify the |
does present a few |
and mfs in wide |
and the lines in |
to modify the filesystem |
present a few undesirable |
area and more web |
modify the filesystem while |
a few undesirable requirements |
the filesystem while they |
filesystem while they are |
show the revenue density |
the revenue density of |
while they are disconnected |
the data source should |
data source should ensure |
source should ensure that |
should ensure that packets |
back to the setting |
ensure that packets are |
to the setting at |
that packets are evenly |
the setting at hand |
packets are evenly spread |
setting at hand with |
are evenly spread across |
at hand with p |
hand with p pools |
evenly spread across the |
spread across the system |
across the system by |
the system by sending |
system by sending data |
the revenue of pool |
by sending data to |
sending data to a |
data to a fixed |
to a fixed proportion |
a fixed proportion of |
as well as further |
fixed proportion of nodes |
is better when x |
coda supports stronger consistency |
well as further evaluating |
and by sending different |
by sending different packets |
supports stronger consistency through |
as further evaluating the |
sending different packets to |
different packets to different |
stronger consistency through optimistic |
packets to different nodes |
further evaluating the performance |
evaluating the performance of |
the performance of the |
performance of the mfs |
of the mfs cache |
the mfs cache consistency |
mfs cache consistency algorithm |
it requires the source |
requires the source and |
the source and all |
source and all nodes |
and all nodes to |
we also intend to |
also intend to use |
consistency through optimistic replication |
all nodes to have |
nodes to have full |
to have full membership |
have full membership knowledge |
these restrictions affect scalability |
restrictions affect scalability when |
affect scalability when the |
scalability when the data |
when the data source |
the data source has |
data source has bounded |
source has bounded upload |
has bounded upload bandwidth |
to illustrate this problem |
we fixed the upload |
fixed the upload capacity |
the upload capacity of |
upload capacity of a |
capacity of a data |
disconnected operamfs to further |
of a data source |
operamfs to further examine |
a data source at |
to further examine the |
further examine the benefits |
examine the benefits achievable |
the benefits achievable from |
benefits achievable from the |
mbps and simulated bar |
achievable from the autotion |
and simulated bar gossip |
from the autotion in |
simulated bar gossip when |
the autotion in the |
bar gossip when streaming |
autotion in the coda |
in the coda file |
the coda file system |
acm transactions on commatic |
transactions on commatic generation |
on commatic generation of |
commatic generation of caching |
generation of caching policies |
of caching policies for |
caching policies for files |
kbps with increasing numbers |
with increasing numbers of |
increasing numbers of receivers |
can improve its revenue |
improve its revenue by |
its revenue by attacking |
revenue by attacking pool |
varied between one and |
between one and thirty |
one and thirty thousand |
and thirty thousand nodes |
we compare its scalability |
compare its scalability against |
its scalability against the |
scalability against the chainsaw |
an alternative approach is |
against the chainsaw protocol |
attacks is not an |
is not an equilibrium |
not an equilibrium point |
alternative approach is to |
approach is to allow |
for which we fixed |
which we fixed the |
we fixed the source |
fixed the source s |
the source s upload |
source s upload bandwidth |
is to allow a |
case as a test |
as a test case |
to allow a client |
s upload bandwidth to |
allow a client to |
we take the pool |
take the pool distribution |
a client to use |
the pool distribution in |
pool distribution in january |
client to use asynchronous |
to use asynchronous writeback |
we present the average |
present the average and |
the average and minimum |
average and minimum download |
and minimum download rates |
as ratios of the |
ratios of the stream |
of the stream rate |
of both protocols when |
both protocols when the |
protocols when the number |
when the number of |
but require that it |
the number of nodes |
number of nodes is |
of nodes is increased |
require that it alerts |
that it alerts the |
it alerts the file |
automated hoarding for mobile |
bar gossip is not |
alerts the file server |
hoarding for mobile computers |
gossip is not able |
the file server when |
in proceedings of the |
is not able to |
not able to sustain |
proceedings of the sixteenth |
we analyze the cases |
analyze the cases where |
able to sustain its |
of the sixteenth acm |
the sixteenth acm symposium |
the cases where each |
to sustain its performance |
sustain its performance without |
sixteenth acm symposium on |
cases where each of |
where each of the |
its performance without scaling |
acm symposium on operating |
symposium on operating systems |
file server when a |
performance without scaling the |
each of the pools |
on operating systems principles |
server when a file |
without scaling the upload |
of the pools attacks |
the pools attacks all |
when a file is |
scaling the upload capacity |
pools attacks all other |
attacks all other open |
a file is modified |
all other open pools |
the upload capacity of |
upload capacity of the |
capacity of the source |
of the source proportionally |
the source proportionally with |
all of which behave |
source proportionally with the |
of which behave honestly |
proportionally with the size |
with the size of |
the size of the |
size of the system |
note that attacking all |
by sending an invalidation |
that attacking all pools |
attacking all pools with |
chainsaw is able to |
sending an invalidation rpc |
all pools with force |
is able to scale |
pools with force proportional |
able to scale well |
with force proportional to |
to scale well even |
force proportional to their |
scale well even with |
proportional to their size |
well even with a |
to their size yields |
even with a fixed |
their size yields the |
with a fixed lower |
size yields the same |
a fixed lower upload |
this informs the server |
yields the same results |
informs the server that |
acknowledgements we would like |
fixed lower upload bandwidth |
the same results as |
same results as attacking |
we would like to |
lower upload bandwidth at |
upload bandwidth at the |
the server that the |
would like to thank |
bandwidth at the source |
results as attacking a |
as attacking a single |
like to thank robbert |
to thank robbert van |
server that the update |
thank robbert van renesse |
attacking a single pool |
but cannot handle the |
cannot handle the presence |
that the update exists |
a single pool of |
handle the presence of |
emin gu n sirer |
single pool of their |
the presence of opportunistic |
presence of opportunistic nodes |
the update exists before |
pool of their aggregate |
of their aggregate size |
update exists before the |
gu n sirer and |
we propose to use |
propose to use auditing |
exists before the new |
plugging in the numbers |
n sirer and paul |
in the numbers into |
before the new file |
to use auditing to |
sirer and paul francis |
the numbers into the |
the new file contents |
use auditing to encourage |
auditing to encourage data |
numbers into the analysis |
new file contents ar |
and paul francis for |
into the analysis above |
paul francis for comments |
the analysis above shows |
francis for comments and |
analysis above shows that |
streaming systems like chainsaw |
above shows that a |
for comments and suggestions |
shows that a larger |
comments and suggestions regarding |
that a larger pool |
our auditing approach establishes |
a larger pool needs |
and suggestions regarding mfs |
auditing approach establishes a |
larger pool needs to |
approach establishes a minimum |
pool needs to use |
we also thank rimon |
also thank rimon barr |
needs to use a |
establishes a minimum threshold |
to use a smaller |
a minimum threshold for |
use a smaller ratio |
minimum threshold for the |
a smaller ratio of |
threshold for the amount |
smaller ratio of its |
and kevin walsh for |
for the amount of |
ratio of its mining |
kevin walsh for helpful |
the amount of data |
of its mining power |
walsh for helpful discussions |
amount of data sent |
its mining power for |
for helpful discussions and |
of data sent by |
mining power for infiltration |
helpful discussions and corrections |
data sent by any |
power for infiltration and |
discussions and corrections to |
sent by any node |
for infiltration and can |
and corrections to this |
by any node in |
infiltration and can increase |
corrections to this paper |
any node in the |
node in the system |
and can increase its |
can increase its revenue |
increase its revenue density |
its revenue density more |
revenue density more than |
density more than a |
and removes nodes that |
origin of inconsistencies since |
more than a small |
than a small pool |
of inconsistencies since asynchronous |
removes nodes that upload |
nodes that upload less |
that upload less data |
upload less data than |
less data than the |
data than the threshold |
inconsistencies since asynchronous writeback |
achieves its optimum attack |
instead of relying on |
of relying on a |
relying on a tit |
since asynchronous writeback decouples |
its optimum attack rate |
optimum attack rate at |
asynchronous writeback decouples modifying |
writeback decouples modifying a |
we focus on encouraging |
focus on encouraging nodes |
on encouraging nodes to |
encouraging nodes to respect |
of the pool s |
decouples modifying a file |
the pool s mining |
modifying a file from |
a coherent distributed file |
nodes to respect the |
pool s mining power |
a file from notifying |
coherent distributed file cache |
to respect the established |
respect the established protocol |
file from notifying the |
distributed file cache with |
nodes are forced to |
are forced to provide |
file cache with directory |
increasing its revenue by |
its revenue by almost |
from notifying the server |
forced to provide accountable |
cache with directory write |
notifying the server that |
to provide accountable information |
provide accountable information regarding |
accountable information regarding packets |
information regarding packets sent |
acm transactions on computer |
transactions on computer systems |
this amounts to a |
regarding packets sent to |
packets sent to and |
amounts to a daily |
to a daily revenue |
the server that a |
sent to and received |
a daily revenue increase |
daily revenue increase of |
server that a change |
revenue increase of b |
to and received from |
and received from neighbors |
that a change has |
a change has occurred |
and the auditing system |
the auditing system is |
auditing system is responsible |
system is responsible for |
is responsible for detecting |
responsible for detecting and |
for detecting and removing |
detecting and removing misbehaving |
and removing misbehaving nodes |
notice that identifying the |
that identifying the misbehaving |
identifying the misbehaving nodes |
the misbehaving nodes is |
misbehaving nodes is not |
nodes is not a |
it can generate inconsistencies |
is not a trivial |
usd at the exchange |
can generate inconsistencies between |
not a trivial task |
at the exchange rate |
the exchange rate on |
generate inconsistencies between cached |
since there is no |
exchange rate on that |
rate on that date |
inconsistencies between cached copies |
there is no fixed |
this represents a considerable |
is no fixed minimum |
represents a considerable increase |
no fixed minimum amount |
a considerable increase of |
fixed minimum amount of |
considerable increase of the |
minimum amount of data |
increase of the pools |
amount of data that |
of the pools net |
of data that nodes |
the pools net revenue |
data that nodes should |
that nodes should contribute |
nodes should contribute to |
should contribute to the |
contribute to the system |
for the smallest pool |
if we assume a |
we assume a model |
assume a model where |
a model where misbehaving |
model where misbehaving nodes |
where misbehaving nodes simply |
misbehaving nodes simply did |
illustrates the potential for |
nodes simply did not |
the attack is much |
attack is much less |
the potential for inconsistency |
simply did not upload |
is much less profitable |
did not upload any |
not upload any data |
to reach the optimum |
detecting them would be |
reach the optimum it |
them would be an |
the optimum it needs |
would be an easier |
be an easier task |
optimum it needs almost |
during the writeback window |
a lowbandwidth network file |
it needs almost a |
lowbandwidth network file system |
needs almost a third |
almost a third of |
once we assume that |
a third of its |
we assume that misbehaving |
third of its power |
in proceedings of the |
assume that misbehaving nodes |
of its power for |
proceedings of the seventeenth |
that misbehaving nodes may |
its power for attacking |
of the seventeenth acm |
misbehaving nodes may adjust |
nodes may adjust their |
power for attacking but |
the seventeenth acm symposium |
seventeenth acm symposium on |
may adjust their contribution |
for attacking but increases |
attacking but increases its |
acm symposium on operating |
adjust their contribution level |
their contribution level based |
but increases its revenue |
symposium on operating systems |
on operating systems principles |
another client accessing a |
increases its revenue density |
contribution level based on |
level based on the |
its revenue density by |
revenue density by merely |
client accessing a cached |
based on the policy |
on the policy used |
accessing a cached copy |
the policy used by |
policy used by an |
used by an auditing |
by an auditing system |
a more elaborate approach |
more elaborate approach is |
elaborate approach is required |
this paper presents and |
or fetching the file |
paper presents and evaluates |
fetching the file from |
presents and evaluates an |
the file from the |
and evaluates an auditing |
file from the file |
evaluates an auditing model |
from the file server |
an auditing model based |
name size discusfish antpool |
auditing model based on |
size discusfish antpool ghash |
model based on sampling |
based on sampling the |
on sampling the system |
sampling the system and |
io btchine btcguild eligius |
the system and using |
btchine btcguild eligius others |
system and using the |
and using the sampled |
will not read up |
using the sampled information |
the sampled information to |
sampled information to build |
information to build a |
to build a global |
build a global view |
a global view of |
global view of how |
view of how the |
of how the system |
how the system is |
the system is currently |
caching in the sprite |
system is currently behaving |
in the sprite network |
the sprite network file |
sprite network file system |
acm transactions on computer |
transactions on computer systems |
auditors employ strategies to |
employ strategies to identify |
strategies to identify the |
to identify the misbehaving |
identify the misbehaving nodes |
the misbehaving nodes that |
misbehaving nodes that should |
nodes that should be |
that should be punished |
the paper is organized |
paper is organized as |
is organized as follows |
from the server s |
the server s perspective |
we state the exact |
state the exact problem |
the exact problem that |
exact problem that we |
problem that we aim |
that we aim to |
we aim to solve |
aim to solve and |
to solve and the |
solve and the assumptions |
and the assumptions considered |
the assumptions considered in |
assumptions considered in this |
considered in this work |
there is no inconsistency |
we review the pull |
based streaming protocol employed |
streaming protocol employed in |
protocol employed in our |
employed in our system |
since it is unaware |
it is unaware of |
followed by a description |
by a description of |
a description of our |
description of our novel |
of our novel auditing |
our novel auditing approach |
novel auditing approach in |
auditing approach in section |
is unaware of the |
unaware of the new |
of the new update |
we evaluate the proposed |
evaluate the proposed approach |
we then discuss the |
then discuss the costs |
discuss the costs of |
the costs of auditing |
and briefly describe how |
briefly describe how to |
describe how to extend |
how to extend our |
to extend our model |
extend our model for |
our model for heterogeneous |
model for heterogeneous systems |
from a global perspective |
we present related work |
present related work in |
related work in section |
and conclude in section |
writing client writes a |
client writes a closes |
writes a closes a |
problem statement our approach |
statement our approach focuses |
our approach focuses on |
approach focuses on a |
focuses on a target |
on a target streaming |
a target streaming system |
target streaming system consisting |
streaming system consisting of |
system consisting of one |
consisting of one data |
of one data source |
perspectives on optimistically replicated |
on optimistically replicated peer |
software practice and experience |
which disseminates data at |
disseminates data at a |
data at a fixed |
at a fixed rate |
a fixed rate to |
fixed rate to a |
rate to a dynamic |
to a dynamic set |
a dynamic set of |
dynamic set of receivers |
reading client server fetch |
client server fetch a |
the source has limited |
source has limited upload |
has limited upload bandwidth |
server fetch a fetch |
fetch a fetch reply |
and hence can only |
hence can only send |
can only send data |
only send data directly |
send data directly to |
data directly to a |
directly to a small |
to a small subset |
a small subset of |
small subset of interested |
subset of interested receivers |
participating nodes are consequently |
nodes are consequently required |
are consequently required to |
consequently required to forward |
required to forward packets |
to forward packets to |
forward packets to their |
packets to their neighbors |
helping disseminate all packets |
disseminate all packets across |
all packets across the |
packets across the system |
the streamed data should |
streamed data should be |
data should be received |
should be received by |
be received by all |
received by all nodes |
by all nodes within |
all nodes within a |
nodes within a fixed |
within a fixed latency |
a fixed latency from |
fixed latency from the |
latency from the source |
from the source s |
flushes update store a |
the source s original |
source s original transmission |
update store a callback |
store a callback for |
even in the presence |
in the presence of |
the presence of opportunistic |
presence of opportunistic nodes |
a callback for a |
the six largest open |
six largest open pool |
callback for a fetch |
we first assume a |
largest open pool sizes |
open pool sizes as |
for a fetch a |
first assume a system |
pool sizes as of |
sizes as of january |
a fetch a open |
assume a system in |
a system in which |
fetch a open a |
system in which all |
in which all nodes |
have similar upload and |
similar upload and download |
upload and download bandwidths |
informed prefetching and caching |
in proceedings of the |
proceedings of the fifteenth |
of the fifteenth acm |
the fifteenth acm symposium |
fifteenth acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
writes a closes a |
we briefly discuss how |
briefly discuss how to |
discuss how to extend |
how to extend our |
to extend our model |
extend our model to |
our model to work |
model to work in |
their optimal infiltration rates |
to work in heterogeneous |
work in heterogeneous scenarios |
of each pool as |
each pool as a |
pool as a fraction |
we assume that malicious |
as a fraction of |
assume that malicious nodes |
a fraction of its |
that malicious nodes exhibit |
fraction of its size |
malicious nodes exhibit byzantine |
nodes exhibit byzantine behavior |
if it attacked all |
it attacked all others |
attacked all others without |
while correct nodes follow |
all others without reciprocation |
correct nodes follow the |
nodes follow the protocol |
follow the protocol as |
the protocol as defined |
requesting data as needed |
and their revenue density |
data as needed and |
their revenue density when |
as needed and sending |
revenue density when attacking |
needed and sending data |
and sending data as |
sending data as requested |
data as requested from |
as requested from them |
altrustic nodes are a |
t wo p ools |
nodes are a subgroup |
wo p ools we |
are a subgroup of |
p ools we proceed |
a subgroup of correct |
ools we proceed to |
subgroup of correct nodes |
we proceed to analyze |
of correct nodes that |
proceed to analyze the |
correct nodes that are |
to analyze the case |
nodes that are willing |
analyze the case where |
that are willing to |
the case where two |
are willing to upload |
case where two pools |
willing to upload more |
where two pools may |
to upload more data |
two pools may attack |
upload more data than |
pools may attack each |
more data than required |
may attack each other |
data than required from |
attack each other and |
than required from them |
each other and the |
flushes update open a |
other and the other |
and the other miners |
the other miners mine |
other miners mine solo |
we employ the term |
employ the term opportunistic |
again we have pool |
the term opportunistic to |
term opportunistic to refer |
opportunistic to refer to |
to refer to a |
refer to a subgroup |
to a subgroup of |
a subgroup of byzantine |
subgroup of byzantine nodes |
of byzantine nodes that |
byzantine nodes that attempt |
nodes that attempt to |
that attempt to give |
design and implementation of |
attempt to give less |
and implementation of the |
to give less data |
implementation of the sun |
give less data than |
of the sun network |
less data than they |
the sun network file |
fetch reply reading client |
data than they would |
sun network file system |
controls its infiltration rate |
its infiltration rate x |
reply reading client server |
than they would if |
in proceedings of usenix |
they would if they |
would if they behaved |
reading client server invalidate |
proceedings of usenix summer |
if they behaved as |
of usenix summer conference |
client server invalidate a |
they behaved as correct |
behaved as correct nodes |
also controls its infiltration |
controls its infiltration rate |
its infiltration rate x |
with the intention of |
the intention of obtaining |
intention of obtaining as |
of obtaining as much |
obtaining as much data |
as much data as |
much data as possible |
data as possible at |
as possible at least |
possible at least feasible |
at least feasible cost |
these may employ a |
may employ a simple |
employ a simple strategy |
this scenario is illustrated |
scenario is illustrated in |
is illustrated in figure |
such as refuse to |
as refuse to contribute |
refuse to contribute any |
to contribute any upload |
contribute any upload resources |
the total mining power |
total mining power in |
mining power in the |
power in the system |
in the system is |
the system is m |
system is m x |
or a more elaborate |
a more elaborate strategy |
the evolution of coda |
more elaborate strategy that |
elaborate strategy that allows |
strategy that allows them |
that allows them to |
allows them to cheat |
acm transactions on computer |
them to cheat without |
transactions on computer systems |
to cheat without being |
cheat without being easily |
without being easily detected |
notice that our model |
that our model diverges |
our model diverges from |
model diverges from the |
diverges from the one |
from the one used |
the one used in |
one used in bar |
used in bar gossip |
the direct revenues r |
in which nodes are |
which nodes are classified |
nodes are classified as |
are classified as byzantine |
of the pools from |
the pools from mining |
pools from mining are |
from mining are their |
mining are their effective |
are their effective mining |
their effective mining rates |
rational nodes attempt to |
nodes attempt to maximize |
attempt to maximize their |
to maximize their utility |
maximize their utility while |
their utility while still |
utility while still following |
while still following the |
still following the defined |
following the defined protocol |
our model is actually |
model is actually less |
is actually less lenient |
nodes employing strategies to |
employing strategies to maximize |
strategies to maximize their |
to maximize their utility |
maximize their utility are |
their utility are classified |
utility are classified as |
writing client pull a |
are classified as byzantine |
so that we can |
that we can build |
we can build a |
can build a practical |
build a practical punishment |
based system in which |
system in which any |
in which any node |
which any node not |
any node not contributing |
node not contributing its |
not contributing its fair |
contributing its fair share |
its fair share of |
fair share of data |
share of data may |
of data may be |
data may be expelled |
may be expelled from |
be expelled from the |
expelled from the system |
determinism and asynchrony of |
and asynchrony of set |
asynchrony of set iterators |
of set iterators to |
set iterators to reduce |
iterators to reduce aggregrate |
to reduce aggregrate file |
throughout the paper we |
reduce aggregrate file i |
the paper we use |
two attacking pools system |
paper we use the |
we use the terms |
use the terms upload |
the terms upload factor |
callback for a fetch |
terms upload factor and |
in proceedings of the |
upload factor and download |
proceedings of the sixteenth |
factor and download factor |
of the sixteenth acm |
and download factor to |
the sixteenth acm symposium |
download factor to refer |
for a fetch a |
sixteenth acm symposium on |
factor to refer to |
acm symposium on operating |
to refer to the |
symposium on operating system |
refer to the ratio |
as a function of |
a function of pool |
to the ratio between |
on operating system principles |
function of pool sizes |
the ratio between an |
ratio between an upload |
between an upload or |
an upload or download |
upload or download rate |
or download rate and |
download rate and the |
rate and the original |
and the original stream |
the original stream rate |
given a stream rate |
a stream rate of |
a download rate of |
kbps corresponds to a |
corresponds to a download |
to a download factor |
a download factor of |
store a fetch reply |
streaming system model our |
system model our auditing |
model our auditing approach |
our auditing approach is |
auditing approach is used |
approach is used over |
is used over the |
used over the chainsaw |
over the chainsaw protocol |
all nodes participating in |
nodes participating in the |
participating in the system |
in the system are |
the system are organized |
system are organized into |
are organized into a |
organized into a fully |
into a fully connected |
a fully connected mesh |
fully connected mesh overlay |
where each node has |
each node has the |
node has the same |
has the same number |
file system usage in |
the same number of |
same number of neighbors |
system usage in windows |
usage in windows nt |
the source is randomly |
source is randomly connected |
is randomly connected to |
randomly connected to a |
connected to a small |
to a small subset |
a small subset of |
small subset of the |
subset of the nodes |
the streaming process starts |
streaming process starts at |
process starts at the |
in proceedings of the |
starts at the source |
proceedings of the seventeenth |
of the seventeenth acm |
the seventeenth acm symposium |
seventeenth acm symposium on |
acm symposium on operating |
symposium on operating systems |
which breaks the data |
on operating systems principles |
breaks the data stream |
the data stream into |
data stream into packets |
stream into packets and |
into packets and sends |
packets and sends notifications |
and sends notifications to |
sends notifications to its |
notifications to its neighbors |
to its neighbors as |
its neighbors as soon |
neighbors as soon as |
as soon as it |
soon as it has |
as it has packets |
two pools infiltrating each |
it has packets to |
pools infiltrating each other |
has packets to disseminate |
these notifications are small |
notifications are small messages |
are small messages used |
divided by the total |
small messages used only |
by the total mining |
messages used only to |
the total mining rate |
asynchronous writeback with invalidations |
used only to inform |
only to inform neighbors |
writeback with invalidations figure |
to inform neighbors of |
inform neighbors of the |
neighbors of the availability |
of the availability of |
the availability of new |
availability of new packets |
based on the received |
on the received notifications |
each node requests missing |
node requests missing packets |
and the source satisfies |
the source satisfies as |
source satisfies as many |
satisfies as many requests |
as many requests as |
many requests as allowed |
requests as allowed by |
as allowed by its |
allowed by its upload |
by its upload capacity |
with chainsaw the upload |
chainsaw the upload capacity |
the upload capacity of |
upload capacity of the |
capacity of the source |
of the source does |
the source does not |
a client s update |
arla a free afs |
a free afs client |
client s update is |
source does not need |
in proceedings of the |
s update is logged |
does not need to |
not need to increase |
need to increase with |
to increase with the |
increase with the size |
with the size of |
update is logged when |
the size of the |
size of the system |
is logged when the |
logged when the file |
even an upload capacity |
an upload capacity of |
upload capacity of twice |
capacity of twice the |
of twice the stream |
twice the stream rate |
when the file is |
the stream rate is |
stream rate is sufficient |
rate is sufficient to |
is sufficient to ensure |
sufficient to ensure that |
the file is closed |
to ensure that the |
ensure that the system |
that the system performs |
the system performs and |
system performs and scales |
performs and scales well |
the total revenue of |
as nodes receive packets |
total revenue of each |
revenue of each pool |
of each pool is |
each pool is its |
pool is its direct |
is its direct mining |
while it is in |
its direct mining revenue |
they mimic the role |
mimic the role of |
the role of the |
role of the source |
it is in the |
is in the log |
sending notifications to their |
and the infiltration revenue |
notifications to their own |
the infiltration revenue from |
to their own neighbors |
infiltration revenue from the |
their own neighbors in |
revenue from the previous |
own neighbors in the |
other clients see the |
from the previous round |
neighbors in the mesh |
clients see the server |
see the server s |
the server s stale |
which is the attacked |
allowing packets to be |
packets to be propagated |
server s stale version |
is the attacked pool |
volume leases for consistency |
to be propagated through |
the attacked pool s |
leases for consistency in |
for consistency in large |
attacked pool s total |
be propagated through the |
pool s total revenue |
propagated through the system |
s total revenue multiplied |
total revenue multiplied by |
revenue multiplied by its |
multiplied by its infiltration |
by its infiltration rate |
an invalidation rpc allows |
invalidation rpc allows the |
based approach to acquisition |
rpc allows the server |
the pool s total |
ieee transactions on knowledge |
approach to acquisition of |
to acquisition of packets |
pool s total revenue |
transactions on knowledge and |
on knowledge and data |
s total revenue is |
total revenue is divided |
knowledge and data engineering |
allows the server to |
revenue is divided among |
is divided among its |
divided among its loyal |
among its loyal miners |
its loyal miners and |
provides some resilience to |
loyal miners and miners |
miners and miners that |
some resilience to failure |
resilience to failure or |
and miners that infiltrated |
miners that infiltrated it |
to failure or malicious |
failure or malicious behavior |
the server to invalidate |
at stable state this |
stable state this is |
since a participant will |
state this is r |
server to invalidate other |
a participant will have |
participant will have multiple |
will have multiple possible |
have multiple possible sources |
multiple possible sources for |
possible sources for each |
sources for each packet |
to invalidate other clients |
invalidate other clients cached |
other clients cached copies |
the mesh overlay defines |
mesh overlay defines a |
overlay defines a predetermined |
defines a predetermined set |
a predetermined set of |
predetermined set of neighbors |
set of neighbors for |
of neighbors for each |
neighbors for each peer |
which also makes it |
also makes it hard |
makes it hard for |
it hard for malicious |
a client that modifies |
hard for malicious peers |
client that modifies a |
for malicious peers to |
that modifies a file |
malicious peers to round |
modifies a file could |
peers to round up |
a file could save |
to round up on |
file could save bandwidth |
round up on individual |
could save bandwidth by |
up on individual peers |
save bandwidth by not |
on individual peers since |
bandwidth by not sending |
individual peers since attackers |
by not sending it |
peers since attackers lack |
not sending it to |
since attackers lack a |
attackers lack a deterministic |
lack a deterministic means |
a deterministic means of |
deterministic means of acquiring |
means of acquiring control |
of acquiring control of |
acquiring control of all |
control of all of |
of all of its |
all of its neighbors |
sending it to the |
it to the file |
to the file server |
all nodes with exception |
the file server at |
file server at all |
nodes with exception of |
with exception of the |
exception of the source |
of the source have |
the source have a |
source have a fixed |
have a fixed upper |
a fixed upper limit |
fixed upper limit on |
upper limit on their |
limit on their upload |
on their upload contribution |
unless the server pulls |
the server pulls it |
server pulls it to |
pulls it to supply |
it to supply it |
to supply it to |
supply it to another |
it to another client |
we obtain the following |
obtain the following closed |
the following closed expressions |
following closed expressions for |
mafs clients push updates |
closed expressions for each |
times the stream rate |
clients push updates to |
push updates to the |
we express the revenues |
express the revenues as |
updates to the server |
the revenues as functions |
defined by the protocol |
to the server in |
revenues as functions of |
as functions of x |
the server in the |
server in the background |
this upper limit is |
upper limit is not |
limit is not respected |
is not respected by |
not respected by opportunistic |
respected by opportunistic nodes |
who attempt to reduce |
attempt to reduce it |
to reduce it with |
reduce it with the |
it with the goal |
to reduce the delay |
with the goal of |
the goal of uploading |
goal of uploading less |
of uploading less data |
reduce the delay incurred |
the delay incurred when |
on the course of |
the course of a |
course of a streaming |
of a streaming session |
delay incurred when fetching |
incurred when fetching an |
when fetching an invalidated |
each node stores packets |
fetching an invalidated file |
node stores packets and |
stores packets and forwards |
packets and forwards them |
and forwards them to |
forwards them to other |
them to other peers |
to other peers only |
other peers only while |
peers only while the |
only while the packet |
while the packet is |
pushing updates can result |
the packet is within |
packet is within its |
is within its availability |
updates can result in |
within its availability window |
can result in the |
result in the server |
usually spanning a few |
spanning a few seconds |
in the server having |
the server having received |
server having received some |
each node also maintains |
node also maintains an |
also maintains an interest |
maintains an interest window |
which represents the set |
represents the set of |
the set of packets |
set of packets in |
of packets in which |
packets in which the |
in which the peer |
which the peer is |
or all of the |
the peer is currently |
peer is currently interested |
all of the update |
of the update by |
nodes choose packets to |
choose packets to request |
packets to request from |
to request from each |
request from each of |
from each of its |
each of its neighbors |
the update by the |
update by the time |
by the time another |
respecting a maximum limit |
a maximum limit l |
maximum limit l on |
limit l on the |
l on the number |
on the number of |
the number of outstanding |
number of outstanding requests |
of outstanding requests to |
outstanding requests to each |
the time another client |
time another client accesses |
another client accesses it |
selective invalidation with reader |
invalidation with reader pull |
with reader pull the |
reader pull the effect |
pull the effect of |
the effect of selective |
effect of selective invalidation |
of selective invalidation and |
selective invalidation and reader |
invalidation and reader pull |
and reader pull is |
reader pull is that |
pull is that mafs |
is that mafs incorporates |
that mafs incorporates sirp |
a new algorithm for |
new algorithm for maintaining |
algorithm for maintaining inter |
sirp behaves similarly to |
behaves similarly to synchronous |
similarly to synchronous writeback |
to synchronous writeback if |
synchronous writeback if a |
writeback if a client |
if a client client |
a client client consistency |
which combines asynchronous writeback |
combines asynchronous writeback with |
asynchronous writeback with concurrently |
writeback with concurrently fetches |
with concurrently fetches a |
concurrently fetches a file |
but behaves like asynchronous |
behaves like asynchronous writeinvalidations |
upload factor download factor |
like asynchronous writeinvalidations and |
asynchronous writeinvalidations and expedited |
writeinvalidations and expedited transmission |
and expedited transmission of |
expedited transmission of updates |
transmission of updates for |
of updates for files |
updates for files back |
for files back when |
files back when there |
back when there are |
when there are no |
each pool controls only |
pool controls only its |
controls only its own |
only its own infiltration |
its own infiltration rate |
there are no concurrent |
are no concurrent fetches |
in each round of |
each round of the |
round of the pool |
of the pool game |
each pool will optimize |
pool will optimize its |
will optimize its infiltration |
optimize its infiltration rate |
like synchronous that other |
its infiltration rate of |
infiltration rate of the |
rate of the other |
synchronous that other clients |
that other clients are |
other clients are attempting |
clients are attempting to |
are attempting to read |
acts at step t |
it optimizes its revenue |
optimizes its revenue with |
its revenue with x |
sirp sends an rpc |
sends an rpc to |
an rpc to the |
rpc to the server |
to the server as |
the server as soon |
server as soon as |
as soon as an |
soon as an application |
as an application closes |
an application closes a |
application closes a modified |
closes a modified file |
but it can defer |
it can defer transmitting |
can defer transmitting the |
defer transmitting the selective |
transmitting the selective invalidation |
using an invalidation rpc |
an invalidation rpc to |
invalidation rpc to alert |
rpc to alert the |
to alert the actual |
alert the actual contents |
the actual contents until |
actual contents until they |
contents until they are |
until they are needed |
acts at step t |
it optimizes its revenue |
optimizes its revenue with |
its revenue with x |
file server to the |
server to the existence |
to the existence of |
the existence of a |
existence of a new |
of a new update |
maximum upload factor figure |
a new update improves |
new update improves cache |
update improves cache consistency |
download and upload factors |
and upload factors of |
upload factors of nodes |
factors of nodes in |
of nodes in an |
nodes in an ideal |
in an ideal system |
an ideal system where |
ideal system where all |
but consumes additional bandwidth |
system where all nodes |
where all nodes behave |
all nodes behave correctly |
if writeback traffic is |
this limit not only |
limit not only improves |
not only improves the |
only improves the general |
improves the general flow |
the general flow of |
general flow of packets |
writeback traffic is low |
traffic is low enough |
but also makes it |
is low enough for |
also makes it harder |
makes it harder for |
it harder for malicious |
harder for malicious peers |
for malicious peers to |
malicious peers to overrequest |
peers to overrequest packets |
to overrequest packets from |
overrequest packets from their |
packets from their neighbors |
low enough for the |
enough for the server |
peers maintain a queue |
maintain a queue of |
a queue of non |
for the server to |
an equilibrium exists where |
equilibrium exists where neither |
exists where neither pool |
satisfied requests from its |
requests from its neighbors |
the server to start |
server to start receiving |
keeping only the l |
only the l most |
can improve its revenue |
to start receiving an |
the l most recent |
l most recent ones |
start receiving an update |
improve its revenue by |
its revenue by changing |
revenue by changing its |
by changing its infiltration |
changing its infiltration rate |
any pair of values |
pair of values x |
expected behavior our first |
behavior our first goal |
our first goal is |
first goal is to |
goal is to explore |
is to explore the |
to explore the typical |
explore the typical signature |
the typical signature of |
typical signature of the |
signature of the system |
since an understanding of |
an understanding of the |
experimental evaluation immediately after |
understanding of the behavior |
such that arg maxx |
evaluation immediately after it |
of the behavior of |
immediately after it receives |
the behavior of pullbased |
after it receives the |
behavior of pullbased dissemination |
it receives the invalidation |
of pullbased dissemination in |
pullbased dissemination in the |
dissemination in the absence |
in the absence of |
the absence of opportunistic |
absence of opportunistic nodes |
of opportunistic nodes will |
opportunistic nodes will turn |
nodes will turn out |
will turn out to |
the invalidation we conclude |
turn out to be |
out to be important |
to be important when |
be important when we |
important when we set |
when we set out |
we set out to |
set out to introduce |
out to introduce auditing |
invalidation we conclude this |
we conclude this section |
we conducted experiments using |
conducted experiments using an |
experiments using an event |
conclude this section with |
this section with an |
section with an experiment |
with an experiment that |
which is described in |
is described in more |
described in more detail |
in more detail in |
more detail in section |
an experiment that compares |
experiment that compares the |
that compares the is |
compares the is superfluous |
like it or not |
web services are distributed |
services are distributed objects |
we evaluate the performance |
evaluate the performance of |
sirp avoids this overhead |
avoids this overhead by |
this overhead by performing |
overhead by performing selec |
cornell university within the |
university within the community |
within the community developing |
the community developing the |
community developing the web |
developing the web services |
nodes during an ideal |
the web services architecture |
during an ideal execution |
an ideal execution of |
web services architecture and |
services architecture and products |
ideal execution of chainsaw |
effectiveness of sirp to |
of sirp to three |
an increasingly schizophrenic message |
where all the nodes |
all the nodes behave |
the nodes behave correctly |
sirp to three alternatives |
increasingly schizophrenic message is |
schizophrenic message is emerging |
we fixed the upload |
fixed the upload factor |
the upload factor of |
upload factor of the |
factor of the source |
of the source at |
marketing materials assure us |
materials assure us that |
assure us that web |
us that web services |
that web services are |
web services are a |
services are a breakthrough |
offering unparalleled interoperability and |
unparalleled interoperability and comprehensive |
interoperability and comprehensive standards |
and comprehensive standards for |
comprehensive standards for associated |
standards for associated technologies |
when a client adds |
a client adds an |
client adds an update |
adds an update to |
they portray web services |
an update to the |
portray web services as |
and the stream rate |
the stream rate to |
update to the writeback |
web services as a |
services as a seamless |
as a seamless interconnection |
a seamless interconnection layer |
seamless interconnection layer that |
interconnection layer that will |
layer that will propel |
that will propel computer |
to the writeback back |
the writeback back transmits |
writeback back transmits an |
we varied the maximum |
computer commerce to a |
back transmits an update |
commerce to a previously |
varied the maximum upload |
transmits an update as |
to a previously inaccessible |
the maximum upload factor |
an update as soon |
a previously inaccessible level |
maximum upload factor of |
update as soon as |
upload factor of nodes |
as soon as a |
and they use language |
factor of nodes to |
soon as a file |
they use language evocative |
of nodes to see |
as a file is |
use language evocative of |
nodes to see how |
a file is closed |
language evocative of marketing |
to see how it |
evocative of marketing for |
see how it affected |
of marketing for distributed |
how it affected both |
marketing for distributed object |
it affected both the |
for distributed object middleware |
affected both the download |
both the download and |
the download and upload |
download and upload factors |
and upload factors of |
upload factors of nodes |
technologists are sending a |
factors of nodes across |
are sending a somewhat |
of nodes across the |
sending a somewhat different |
nodes across the system |
the feasible region for |
a somewhat different message |
it only sends an |
feasible region for the |
the maximum upload factor |
only sends an invalidation |
region for the pool |
maximum upload factor is |
in an essay entitled |
an essay entitled web |
for the pool sizes |
upload factor is a |
sends an invalidation if |
essay entitled web services |
the pool sizes is |
pool sizes is m |
an invalidation if the |
entitled web services are |
factor is a fixed |
invalidation if the queue |
web services are not |
is a fixed parameter |
if the queue is |
services are not distributed |
a fixed parameter which |
the queue is not |
are not distributed objects |
fixed parameter which defines |
queue is not empty |
parameter which defines the |
werner vogels argues that |
which defines the maximum |
vogels argues that web |
defines the maximum rate |
argues that web services |
the maximum rate at |
that web services will |
maximum rate at which |
web services will work |
rate at which a |
at which a node |
services will work well |
will work well for |
which a node will |
a node will upload |
chronous writeback puts the |
work well for important |
node will upload data |
will upload data to |
the revenue function for |
revenue function for ri |
well for important classes |
upload data to all |
data to all its |
writeback puts the update |
for important classes of |
to all its neighbors |
function for ri is |
for ri is concave |
important classes of applications |
puts the update in |
ri is concave in |
for fairness in nodes |
fairness in nodes bandwidth |
is concave in xi |
but he also cites |
he also cites significant |
in nodes bandwidth consumption |
concave in xi for |
in xi for all |
also cites significant limits |
the update in a |
xi for all feasible |
as vogels sees it |
update in a queue |
we would like all |
for all feasible values |
all feasible values of |
the architecture is so |
would like all nodes |
like all nodes to |
feasible values of the |
architecture is so centered |
is so centered on |
all nodes to upload |
values of the variables |
in a queue and |
so centered on document |
centered on document exchange |
a queue and transmits |
nodes to upload data |
and at its core |
to upload data at |
upload data at a |
at its core is |
its core is so |
core is so simple |
queue and transmits it |
data at a factor |
that many features taken |
at a factor as |
a factor as close |
many features taken for |
features taken for granted |
factor as close as |
as close as possible |
taken for granted in |
for granted in object |
close as possible to |
and transmits it if |
therefore the solutions for |
the solutions for equations |
oriented systems are fundamentally |
systems are fundamentally lacking |
transmits it if the |
it if the queue |
if the queue is |
examples include dynamic object |
include dynamic object creation |
dynamic object creation and |
we varied the maximum |
varied the maximum upload |
object creation and garbage |
creation and garbage collection |
the maximum upload factor |
maximum upload factor of |
are unique and are |
unique and are either |
upload factor of nodes |
factor of nodes from |
and are either at |
are either at the |
either at the borders |
dynamically created object references |
the queue is empty |
at the borders of |
the borders of the |
and a variety of |
borders of the feasible |
a variety of reliability |
of the feasible region |
variety of reliability and |
the feasible region or |
of reliability and transactional |
feasible region or where |
reliability and transactional mechanisms |
region or where ri |
the invalidation is piggybacked |
invalidation is piggybacked onto |
is piggybacked onto the |
the left graph shows |
left graph shows the |
graph shows the minimum |
piggybacked onto the as |
onto the as soon |
average and maximum download |
and maximum download factors |
both perspectives can t |
maximum download factors across |
the as soon as |
from section v we |
perspectives can t be |
can t be correct |
as soon as it |
section v we know |
v we know that |
we know that no |
download factors across the |
it s easy to |
s easy to see |
factors across the nodes |
across the nodes when |
easy to see how |
to see how this |
attack is not an |
the nodes when the |
nodes when the maximum |
see how this situation |
is not an equilibrium |
not an equilibrium point |
when the maximum upload |
how this situation arose |
soon as it reaches |
since each pool can |
the maximum upload factor |
maximum upload factor of |
each pool can increase |
web services are the |
services are the most |
upload factor of nodes |
pool can increase its |
can increase its revenue |
are the most recent |
factor of nodes is |
of nodes is increased |
increase its revenue by |
the most recent in |
most recent in a |
its revenue by choosing |
revenue by choosing a |
recent in a long |
in a long series |
by choosing a strictly |
by increasing the maximum |
a long series of |
choosing a strictly positive |
a strictly positive infiltration |
increasing the maximum upload |
long series of object |
series of object oriented |
strictly positive infiltration rate |
the maximum upload factor |
maximum upload factor of |
upload factor of nodes |
as it reaches the |
of object oriented interoperability |
we increase the global |
increase the global upload |
object oriented interoperability platforms |
it reaches the front |
reaches the front of |
the global upload capacity |
global upload capacity of |
and mixes ideas from |
mixes ideas from corba |
upload capacity of the |
capacity of the system |
the front of the |
front of the queue |
leading to a better |
to a better flow |
a better flow of |
better flow of packets |
we also compare update |
while exploiting xml and |
exploiting xml and other |
the discrepancy among the |
xml and other web |
discrepancy among the upload |
among the upload factors |
sirp against a policy |
the upload factors of |
upload factors of individual |
is not a solution |
not a solution to |
a solution to equations |
developers using popular middleware |
factors of individual nodes |
of individual nodes also |
using popular middleware platforms |
against a policy we |
individual nodes also increases |
popular middleware platforms can |
a policy we refer |
middleware platforms can transform |
platforms can transform a |
as seen in the |
seen in the graph |
can transform a program |
transform a program object |
in the graph to |
the graph to the |
nash equilibrium therefore exists |
equilibrium therefore exists with |
graph to the right |
a program object into |
program object into a |
therefore exists with x |
when the maximum upload |
the maximum upload factor |
object into a web |
into a web services |
a web services object |
policy we refer to |
we refer to as |
refer to as sirp |
or access a remote |
maximum upload factor is |
access a remote ws |
upload factor is increased |
a remote ws object |
some nodes participate more |
at the touch of |
nodes participate more actively |
the touch of a |
participate more actively in |
which only differs from |
touch of a button |
more actively in dissemination |
actively in dissemination while |
in dissemination while others |
dissemination while others end |
performance leaves something to |
leaves something to be |
something to be desired |
while others end up |
others end up contributing |
end up contributing less |
only differs from sirp |
but computers and networks |
computers and networks have |
even though all of |
and networks have become |
networks have become astonishingly |
have become astonishingly fast |
differs from sirp in |
though all of them |
all of them are |
major application providers are |
of them are behaving |
them are behaving correctly |
application providers are planning |
providers are planning to |
are planning to offer |
planning to offer ws |
this is an important |
to offer ws interfaces |
offer ws interfaces to |
is an important consideration |
from sirp in performing |
ws interfaces to their |
interfaces to their products |
sirp in performing compulsory |
in performing compulsory invalidations |
when we introduce auditing |
so it makes perfect |
it makes perfect sense |
makes perfect sense that |
perfect sense that the |
sense that the marketing |
that the marketing community |
we do not want |
the marketing community would |
do not want to |
marketing community would feel |
not want to punish |
community would feel that |
want to punish nodes |
would feel that finally |
when the server receives |
to punish nodes that |
the server receives an |
punish nodes that are |
they ve reached the |
ve reached the promised |
reached the promised land |
server receives an invalidation |
nodes that are willing |
receives an invalidation from |
that are willing to |
an invalidation from a |
are willing to contribute |
invalidation from a date |
willing to contribute but |
has an understandable emphasis |
from a date results |
to contribute but cannot |
an understandable emphasis on |
a date results in |
contribute but cannot do |
understandable emphasis on facts |
date results in an |
but cannot do so |
emphasis on facts on |
results in an invalidation |
cannot do so because |
on facts on the |
in an invalidation rpc |
do so because of |
facts on the ground |
an invalidation rpc to |
so because of factors |
on the ground and |
invalidation rpc to the |
rpc to the server |
the ground and the |
because of factors such |
ground and the vogels |
of factors such as |
and the vogels essay |
factors such as their |
the vogels essay reflects |
such as their physical |
vogels essay reflects the |
as their physical positioning |
essay reflects the realities |
their physical positioning in |
reflects the realities of |
physical positioning in the |
it makes callbacks to |
the realities of an |
using symbolic computation tools |
makes callbacks to all |
positioning in the system |
realities of an architecture |
we see that there |
of an architecture focused |
callbacks to all the |
see that there is |
an architecture focused at |
to all the other |
in all our future |
that there is a |
architecture focused at its |
focused at its core |
all our future experiments |
there is a single |
is a single pair |
at its core on |
our future experiments we |
future experiments we set |
a single pair of |
its core on using |
core on using document |
experiments we set the |
single pair of values |
pair of values for |
on using document exchange |
we set the maximum |
set the maximum upload |
of values for which |
using document exchange to |
document exchange to access |
the maximum upload factor |
values for which equation |
all the other clients |
exchange to access backend |
to access backend servers |
the other clients that |
maximum upload factor to |
holds for any feasible |
for any feasible choice |
this core has been |
any feasible choice of |
feasible choice of m |
core has been extended |
has been extended with |
been extended with such |
extended with such mechanisms |
with such mechanisms as |
such mechanisms as rpc |
mechanisms as rpc and |
as rpc and asynchronous |
rpc and asynchronous messaging |
other clients that cache |
clients that cache the |
that cache the are |
cache the are of |
the are of particular |
numerical analysis a numerical |
analysis a numerical analysis |
a numerical analysis confirms |
numerical analysis confirms these |
analysis confirms these observations |
are of particular interest |
effect of opportunistic behavior |
of particular interest in |
of opportunistic behavior our |
we simulate the pool |
simulate the pool game |
a variety of roll |
opportunistic behavior our next |
particular interest in this |
interest in this comparison |
forward and rendezvous options |
the pool game for |
behavior our next goal |
pool game for a |
our next goal was |
game for a range |
next goal was to |
for a range of |
goal was to understand |
a range of pool |
range of pool sizes |
was to understand the |
but the primary usage |
to understand the expected |
the primary usage case |
for each choice of |
understand the expected behavior |
primary usage case remains |
each choice of pool |
choice of pool sizes |
usage case remains that |
the expected behavior of |
to tell them to |
case remains that of |
expected behavior of correct |
tell them to discard |
them to discard their |
to discard their copies |
behavior of correct nodes |
we start the simulation |
remains that of a |
of correct nodes under |
start the simulation when |
that of a client |
correct nodes under different |
the simulation when both |
of a client sending |
a client sending documents |
nodes under different scenarios |
simulation when both pools |
when both pools do |
client sending documents to |
under different scenarios where |
different scenarios where opportunistic |
both pools do not |
sending documents to a |
documents to a back |
scenarios where opportunistic nodes |
pools do not infiltrate |
do not infiltrate each |
not infiltrate each other |
end service in a |
service in a client |
if several clients modify |
where opportunistic nodes compromise |
opportunistic nodes compromise the |
nodes compromise the system |
several clients modify are |
clients modify are the |
modify are the files |
are the files readers |
the files readers read |
the assumption is that |
we therefore studied how |
assumption is that the |
therefore studied how the |
is that the application |
studied how the download |
that the application can |
how the download and |
the application can tolerate |
the download and contribution |
application can tolerate substantial |
download and contribution rates |
can tolerate substantial delay |
how is the performance |
and contribution rates of |
tolerate substantial delay before |
substantial delay before a |
delay before a response |
before a response arrives |
contribution rates of correct |
rates of correct nodes |
of correct nodes are |
correct nodes are affected |
nodes are affected under |
and mechanisms capable of |
mechanisms capable of introducing |
are affected under these |
affected under these conditions |
and the revenue densities |
capable of introducing delays |
of introducing delays are |
the revenue densities are |
revenue densities are r |
introducing delays are scattered |
delays are scattered throughout |
are scattered throughout the |
scattered throughout the architecture |
opportunistic nodes may contribute |
is the performance of |
the performance of the |
nodes may contribute with |
performance of the same |
of the same file |
may contribute with some |
the more basic assumption |
contribute with some data |
more basic assumption is |
with some data in |
basic assumption is that |
some data in an |
assumption is that it |
data in an attempt |
in an attempt to |
at each round one |
modifications are serialised in |
is that it all |
an attempt to disguise |
that it all boils |
are serialised in the |
each round one pool |
attempt to disguise their |
it all boils down |
serialised in the order |
round one pool chooses |
to disguise their opportunistic |
all boils down to |
in the order of |
one pool chooses its |
disguise their opportunistic behavior |
boils down to moving |
the order of their |
pool chooses its optimal |
down to moving documents |
order of their readers |
chooses its optimal infiltration |
to moving documents around |
of their readers and |
we considered different rates |
its optimal infiltration rate |
moving documents around whereas |
their readers and writers |
considered different rates of |
optimal infiltration rate based |
documents around whereas the |
readers and writers affected |
different rates of contribution |
infiltration rate based on |
around whereas the most |
and writers affected by |
rates of contribution for |
rate based on the |
whereas the most basic |
writers affected by stronger |
affected by stronger consistency |
based on the pool |
the most basic assumption |
of contribution for opportunistic |
on the pool sizes |
most basic assumption of |
contribution for opportunistic nodes |
the pool sizes and |
basic assumption of a |
pool sizes and the |
assumption of a distributed |
sizes and the rate |
of a distributed object |
and the rate with |
a distributed object system |
the rate with which |
distributed object system is |
rate with which it |
object system is that |
with which it is |
system is that the |
which it is infiltrated |
is that the world |
that the world consists |
the world consists of |
world consists of programs |
consists of programs and |
of programs and data |
and we calculate the |
we calculate the revenue |
calculate the revenue after |
the revenue after convergence |
revenue after convergence with |
active and passive objects |
after convergence with equation |
the client that made |
client that made the |
the gist of vogel |
gist of vogel s |
of vogel s essay |
vogel s essay is |
s essay is that |
essay is that even |
is that even with |
recall the players in |
that even with all |
even with all the |
the players in the |
players in the pool |
with all the contemplated |
all the contemplated extensions |
in the pool game |
the pool game are |
pool game are chosen |
game are chosen with |
are chosen with the |
web services are deeply |
chosen with the round |
with the round robin |
the round robin policy |
that made the update |
services are deeply mismatched |
are deeply mismatched with |
so the pools take |
made the update only |
the pools take turns |
deeply mismatched with distributed |
mismatched with distributed object |
with distributed object computing |
the update only transmits |
and we let the |
we let the game |
let the game run |
the game run until |
the dilemma underlying the |
update only transmits it |
game run until convergence |
dilemma underlying the debate |
only transmits it when |
underlying the debate is |
presents the average and |
transmits it when it |
the results are illustrated |
the debate is that |
the average and minimum |
it when it reaches |
results are illustrated in |
debate is that the |
average and minimum download |
and minimum download factors |
are illustrated in figure |
is that the platforms |
when it reaches the |
minimum download factors among |
that the platforms one |
it reaches the head |
download factors among all |
the platforms one uses |
platforms one uses to |
each run with some |
factors among all correct |
among all correct nodes |
one uses to create |
run with some m |
reaches the head of |
all correct nodes under |
uses to create wscompatible |
to create wscompatible objects |
correct nodes under different |
nodes under different configurations |
create wscompatible objects impose |
wscompatible objects impose no |
objects impose no such |
impose no such restrictions |
values results in a |
results in a single |
the stream rate was |
stream rate was fixed |
there is nothing in |
is nothing in j |
rate was fixed at |
in a single point |
a single point in |
single point in each |
point in each graph |
in each graph in |
each graph in figure |
the head of the |
net that warns a |
head of the writeback |
of the writeback queue |
that warns a user |
we depict the infiltration |
warns a user that |
depict the infiltration rates |
and all correct nodes |
a user that an |
the infiltration rates of |
all correct nodes had |
if another client attempts |
infiltration rates of both |
rates of both pools |
of both pools x |
another client attempts to |
user that an intended |
correct nodes had a |
nodes had a maximum |
that an intended use |
an intended use of |
had a maximum upload |
a maximum upload factor |
maximum upload factor of |
client attempts to fetch |
intended use of the |
use of the architecture |
of the architecture may |
the architecture may be |
architecture may be inappropriate |
attempts to fetch the |
to fetch the file |
fetch the file during |
the file during the |
file during the update |
during the update s |
much of the excitement |
of the excitement reflects |
the excitement reflects the |
excitement reflects the realization |
reflects the realization that |
the realization that with |
b and the pools |
realization that with web |
that with web services |
and the pools revenue |
the pools revenue densities |
pools revenue densities r |
the update s experimental |
interoperability really is easier |
update s experimental setup |
s experimental setup writeback |
experimental setup writeback window |
we ran experiments with |
developers have long struggled |
have long struggled with |
long struggled with program |
the server blocks that |
server blocks that client |
blocks that client until |
program interconnection and integration |
that client until the |
client until the update |
until the update has |
and it is natural |
for each choice of |
the update has arrived |
it is natural to |
each choice of m |
nodes and increasing percentages |
is natural to applaud |
and increasing percentages of |
natural to applaud a |
increasing percentages of opportunistic |
to applaud a widely |
applaud a widely adopted |
percentages of opportunistic nodes |
of opportunistic nodes in |
a widely adopted advance |
the server also makes |
opportunistic nodes in the |
nodes in the system |
server also makes a |
the values of x |
like it or not |
also makes a pull |
makes a pull rpc |
web services are becoming |
services are becoming a |
are becoming a de |
a pull rpc to |
pull rpc to the |
rpc to the client |
facto standard for everything |
to the client that |
the client that experiments |
client that experiments were |
that s not all |
that experiments were conducted |
experiments were conducted in |
were conducted in a |
conducted in a network |
in a network of |
a network of five |
network of five hosts |
based direct sales systems |
direct sales systems are |
we vary the percentage |
sales systems are turning |
vary the percentage of |
systems are turning to |
the percentage of opportunistic |
are turning to the |
one modified the file |
percentage of opportunistic nodes |
turning to the ws |
are the points in |
to the ws architecture |
the points in each |
the ws architecture as |
points in each of |
in each of the |
ws architecture as a |
architecture as a means |
we can observe that |
instructing it to expedite |
each of the graphs |
as a means of |
can observe that the |
it to expedite sending |
of the graphs with |
a means of enlarging |
observe that the download |
to expedite sending the |
the graphs with the |
means of enlarging their |
that the download factors |
expedite sending the update |
graphs with the respective |
of enlarging their markets |
the download factors of |
with the respective coordinates |
download factors of correct |
factors of correct nodes |
of correct nodes decreases |
correct nodes decreases since |
nodes decreases since the |
decreases since the aggregated |
since the aggregated upload |
the aggregated upload capacity |
aggregated upload capacity in |
upload capacity in the |
j graphs we draw |
graphs we draw a |
capacity in the system |
com has developed a |
has developed a web |
we draw a border |
in the system becomes |
one writer client that |
access library whereby third |
draw a border around |
a border around the |
border around the region |
around the region where |
the region where there |
region where there is |
where there is no |
writer client that was |
party application developers can |
application developers can access |
attack by i in |
by i in equilibrium |
client that was responsible |
developers can access their |
can access their datacenters |
for the ri graphs |
access their datacenters from |
their datacenters from a |
the ri graphs we |
that was responsible for |
datacenters from a diversity |
ri graphs we draw |
was responsible for modifying |
avg download factor min |
from a diversity of |
a diversity of end |
responsible for modifying when |
download factor min download |
graphs we draw a |
for modifying when it |
factor min download factor |
an application could order |
application could order thus |
we draw a line |
modifying when it receives |
could order thus supplies |
draw a line around |
a line around the |
order thus supplies directly |
thus supplies directly from |
supplies directly from amazon |
when it receives the |
line around the region |
around the region where |
the region where the |
region where the revenue |
where the revenue is |
the revenue is the |
revenue is the same |
query the fulfillment system |
the fulfillment system to |
is the same as |
the same as in |
same as in the |
as in the no |
fulfillment system to track |
system to track order |
to track order status |
track order status or |
order status or billing |
status or billing data |
it receives the pull |
receives the pull rpc |
both the vendor and |
the vendor and the |
vendor and the application |
we first observe that |
and the application developer |
the application developer benefit |
first observe that only |
the client begins sending |
observe that only in |
that only in extreme |
only in extreme cases |
in extreme cases a |
com enlarges its client |
enlarges its client base |
client begins sending back |
extreme cases a pool |
cases a pool does |
while the developer avoids |
a pool does not |
pool does not attack |
the developer avoids duplicating |
developer avoids duplicating an |
does not attack its |
not attack its counterpart |
avoids duplicating an enormous |
duplicating an enormous technology |
an enormous technology investment |
begins sending back a |
sending back a collection |
back a collection of |
a collection of files |
at equilibrium a pool |
equilibrium a pool will |
a pool will refrain |
web service components will |
pool will refrain from |
service components will play |
will refrain from attacking |
components will play a |
refrain from attacking only |
from attacking only if |
will play a critical |
play a critical role |
attacking only if the |
only if the other |
a critical role in |
critical role in tremendous |
if the other pool |
the other pool is |
role in tremendous numbers |
in tremendous numbers of |
tremendous numbers of end |
and three reader clients |
other pool is larger |
pool is larger than |
is larger than about |
three reader clients that |
reader clients that only |
the challenge is to |
challenge is to make |
is to make such |
to make such systems |
make such systems work |
such systems work reliably |
clients that only read |
of the total mining |
the total mining power |
that only read the |
outages that plague human |
that plague human users |
plague human users of |
human users of web |
users of web browsers |
of web browsers don |
web browsers don t |
browsers don t cause |
don t cause much |
t cause much harm |
we observe that a |
only read the the |
observe that a pool |
that a pool improves |
a pool improves its |
pool improves its revenue |
improves its revenue compared |
outages could disrupt a |
could disrupt a computer |
read the the update |
its revenue compared to |
revenue compared to the |
compared to the no |
the the update at |
the update at the |
computer pathway buried deep |
update at the same |
pathway buried deep within |
attacks scenario only when |
buried deep within an |
deep within an application |
scenario only when it |
at the same priority |
within an application on |
only when it controls |
when it controls a |
an application on which |
application on which an |
it controls a strict |
controls a strict majority |
on which an enterprise |
which an enterprise has |
a strict majority of |
strict majority of the |
an enterprise has become |
enterprise has become dependent |
majority of the total |
of the total mining |
the total mining power |
the same priority as |
it is too easy |
same priority as an |
is too easy to |
these are the small |
are the small triangular |
too easy to dismiss |
priority as an rpc |
the small triangular regions |
easy to dismiss these |
to dismiss these concerns |
small triangular regions in |
triangular regions in figures |
dismiss these concerns by |
as an rpc to |
these concerns by arguing |
concerns by arguing that |
by arguing that the |
arguing that the web |
that the web is |
the web is extremely |
web is extremely scalable |
is extremely scalable and |
extremely scalable and robust |
in the rest of |
the rest of the |
rest of the space |
an rpc to fetch |
but this ignores the |
this ignores the way |
ignores the way we |
the trapezoids in the |
trapezoids in the figures |
the way we use |
way we use the |
we use the web |
rpc to fetch file |
the revenue of the |
to fetch file data |
revenue of the pool |
a human can deal |
of the pool is |
human can deal with |
the pool is inferior |
can deal with the |
pool is inferior compared |
deal with the many |
is inferior compared to |
with the many error |
inferior compared to the |
compared to the no |
the many error conditions |
many error conditions the |
error conditions the web |
conditions the web exposes |
the bandwidth between the |
bandwidth between the writer |
between the writer client |
handling those conditions in |
those conditions in a |
conditions in a seamless |
the writer client and |
the prisoner s dilemma |
prisoner s dilemma in |
automated manner is an |
s dilemma in a |
dilemma in a healthy |
manner is an entirely |
is an entirely different |
in a healthy bitcoin |
a healthy bitcoin environment |
an entirely different challenge |
writer client and the |
client and the server |
and the server that |
where neither pool controls |
neither pool controls a |
pool controls a strict |
controls a strict majority |
when we take what |
the server that it |
a strict majority of |
we take what was |
server that it will |
strict majority of the |
take what was once |
that it will be |
majority of the mining |
of the mining power |
it will be preferentially |
what was once a |
will be preferentially allocated |
be preferentially allocated bandwidth |
both pools will earn |
was once a batch |
pools will earn less |
once a batch service |
will earn less at |
a batch service or |
if the update was |
the update was set |
update was set to |
earn less at equilibrium |
batch service or a |
less at equilibrium than |
service or a web |
at equilibrium than if |
or a web site |
equilibrium than if both |
a web site and |
than if both pools |
web site and transform |
if both pools ran |
site and transform it |
both pools ran without |
and transform it into |
pools ran without attacking |
transform it into a |
it into a web |
into a web service |
we can analyze in |
can analyze in this |
there is no way |
analyze in this case |
is no way to |
in this case a |
no way to enforce |
of opportunistic nodes figure |
this case a game |
way to enforce appropriate |
case a game where |
to enforce appropriate patterns |
a game where each |
enforce appropriate patterns of |
appropriate patterns of use |
game where each pool |
where each pool chooses |
minimum and average download |
each pool chooses either |
and average download factors |
pool chooses either to |
what s to stop |
average download factors across |
chooses either to attack |
s to stop a |
download factors across all |
either to attack and |
to stop a web |
factors across all correct |
to attack and optimize |
stop a web client |
across all correct nodes |
attack and optimize its |
a web client from |
all correct nodes when |
and optimize its revenue |
web client from trying |
correct nodes when opportunistic |
client from trying to |
nodes when opportunistic nodes |
from trying to download |
when opportunistic nodes are |
or to refrain from |
trying to download amazon |
opportunistic nodes are present |
and the reader client |
to refrain from attacking |
com s entire catalog |
each curve corresponds to |
curve corresponds to a |
corresponds to a different |
to a different contribution |
a different contribution rate |
different contribution rate used |
contribution rate used by |
rate used by opportunistic |
used by opportunistic nodes |
the only answer is |
without loss of generality |
server was already being |
was already being written |
already being written back |
as we have seen |
we have seen in |
have seen in section |
seen in section v |
the client increases its |
client increases its priority |
one might argue that |
might argue that none |
argue that none of |
that none of these |
none of these uses |
of these uses are |
these uses are what |
uses are what the |
are what the architecture |
can increase its revenue |
increase its revenue above |
what the architecture is |
the architecture is intended |
architecture is intended to |
is intended to support |
bandwidth was always set |
was always set to |
not so many years |
so many years ago |
does attack but pool |
server architectures faltered over |
architectures faltered over precisely |
faltered over precisely this |
over precisely this type |
we denote the revenue |
precisely this type of |
this type of situation |
denote the revenue of |
the revenue of pool |
so that it can |
server technologies of the |
that it can prevent |
it can prevent inconsistencies |
can prevent inconsistencies by |
the exact value of |
exact value of r |
prevent inconsistencies by inhibiting |
inconsistencies by inhibiting access |
by inhibiting access to |
depends on the values |
on the values of |
the values of m |
inhibiting access to the |
s were widely seen |
were widely seen as |
widely seen as a |
seen as a kind |
as a kind of |
a kind of panacea |
access to the file |
to the file by |
the file by other |
file by other clients |
but it is always |
a silver bullet that |
it is always smaller |
silver bullet that would |
avg upload factor min |
is always smaller than |
always smaller than one |
upload factor min upload |
factor min upload factor |
bullet that would slay |
that would slay evil |
as we have seen |
we have seen above |
as shown in figure |
would slay evil mainframe |
slay evil mainframe architectures |
does choose to attack |
enterprises fell over themselves |
fell over themselves in |
over themselves in a |
themselves in a kind |
in a kind of |
a kind of technology |
kind of technology gold |
of technology gold rush |
but does not surpass |
does not surpass one |
only to discover that |
to discover that the |
discover that the technology |
that the technology had |
the game is summarized |
the technology had been |
technology had been oversold |
game is summarized in |
is summarized in figure |
invalidations are used in |
are used in fluid |
used in fluid replication |
the total cost of |
total cost of ownership |
cost of ownership for |
of ownership for clientserver |
ownership for clientserver systems |
for clientserver systems remains |
clientserver systems remains excessively |
this is the classical |
systems remains excessively high |
is the classical prisoner |
the classical prisoner s |
classical prisoner s dilemma |
the number of system |
number of system administrators |
attack is the dominant |
is the dominant strategy |
to allow clients to |
of system administrators remains |
allow clients to avoid |
system administrators remains roughly |
administrators remains roughly proportional |
chooses to attack or |
to attack or not |
clients to avoid sending |
remains roughly proportional to |
roughly proportional to the |
the revenue of pool |
proportional to the size |
to the size of |
the size of the |
size of the deployment |
to avoid sending data |
is larger when attacking |
larger when attacking than |
when attacking than when |
attacking than when refraining |
than when refraining from |
when refraining from attack |
a list like these |
avoid sending data across |
sending data across a |
and the same for |
the same for pool |
list like these comments |
data across a wide |
like these comments might |
these comments might have |
comments might have seemed |
might have seemed like |
have seemed like an |
seemed like an indictment |
at equilibrium of this |
like an indictment of |
equilibrium of this attack |
an indictment of the |
indictment of the technology |
because we lacked solutions |
the server only asks |
when both pools attack |
server only asks the |
only asks the client |
asks the client for |
the revenue of each |
the client for a |
we know how to |
revenue of each pool |
of each pool is |
know how to implement |
how to implement management |
each pool is smaller |
pool is smaller than |
to implement management tools |
implement management tools and |
management tools and fault |
client for a file |
is smaller than its |
smaller than its revenue |
than its revenue if |
its revenue if neither |
revenue if neither pool |
if neither pool attacked |
how to replicate data |
to replicate data and |
replicate data and functionality |
for a file s |
a file s data |
file s data if |
and how to achieve |
the game is not |
how to achieve high |
to achieve high ava |
achieve high ava ilability |
s data if another |
data if another client |
if another client requests |
we ve had decades |
ve had decades of |
game is not played |
is not played once |
had decades of experience |
decades of experience with |
of experience with large |
another client requests it |
scale system monitoring and |
system monitoring and control |
and are beginning to |
are beginning to understand |
beginning to understand how |
where each pool can |
to understand how to |
each pool can change |
understand how to build |
pool can change its |
how to build solutions |
can change its strategy |
to build solutions on |
change its strategy between |
build solutions on an |
its strategy between attack |
solutions on an internet |
strategy between attack and |
on an internet scale |
between attack and no |
the pools can agree |
peer file sharing turns |
file sharing turns out |
sharing turns out to |
turns out to be |
out to be illegal |
to refrain from attacking |
and it doesn t |
it doesn t work |
doesn t work all |
t work all that |
work all that well |
and in each round |
in each round xxx |
each round xxx xxx |
round xxx xxx pool |
no attack xxx pool |
but spawned a new |
spawned a new generation |
a new generation of |
new generation of technologies |
generation of technologies based |
of technologies based on |
technologies based on distributed |
based on distributed hash |
on distributed hash tables |
s read staleness at |
distributed hash tables and |
hash tables and epidemic |
tables and epidemic communication |
and epidemic communication protocols |
these offer remarkably stable |
scalable tools for dealing |
tools for dealing with |
for dealing with enormous |
dealing with enormous numbers |
with enormous numbers of |
enormous numbers of components |
numbers of components scattered |
of components scattered over |
components scattered over a |
scattered over a network |
not all the stories |
all the stories are |
the stories are positive |
the web services community |
web services community decided |
services community decided not |
community decided not to |
decided not to adapt |
not to adapt the |
to adapt the corba |
adapt the corba fault |
tolerance standard for their |
standard for their setting |
this is a specification |
is a specification i |
a specification i know |
specification i know well |
it was based on |
was based on the |
based on the virtual |
on the virtual synchrony |
of opportunistic nodes figure |
the virtual synchrony model |
virtual synchrony model colleagues |
synchrony model colleagues of |
model colleagues of mine |
colleagues of mine and |
of mine and i |
mine and i developed |
and i developed in |
i developed in work |
developed in work on |
minimum and average upload |
in work on the |
and average upload factors |
work on the isis |
average upload factors across |
on the isis toolkit |
upload factors across all |
factors across all correct |
across all correct nodes |
all correct nodes when |
correct nodes when opportunistic |
nodes when opportunistic nodes |
the standard hasn t |
when opportunistic nodes are |
standard hasn t been |
opportunistic nodes are present |
hasn t been a |
t been a commercial |
been a commercial success |
each curve corresponds to |
curve corresponds to a |
but the corba standard |
corresponds to a different |
the corba standard limits |
to a different contribution |
corba standard limits itself |
a different contribution rate |
standard limits itself to |
limits itself to lock |
different contribution rate used |
contribution rate used by |
rate used by opportunistic |
used by opportunistic nodes |
state replication of a |
replication of a deterministic |
of a deterministic server |
insufficient to provide all |
to provide all nodes |
provide all nodes with |
all nodes with all |
nodes with all data |
perhaps the issue is |
the issue is the |
issue is the way |
is the way the |
the way the technology |
way the technology was |
the technology was used |
the extent of the |
extent of the impact |
not the technology itself |
of the impact may |
the impact may be |
impact may be surprising |
used in other ways |
has been quite successful |
isis runs the new |
runs the new york |
performance drops by as |
the new york stock |
drops by as much |
by as much as |
new york stock exchange |
york stock exchange quote |
stock exchange quote and |
exchange quote and trade |
quote and trade reporting |
and trade reporting system |
a role it has |
role it has played |
it has played since |
prisoner s dilemma for |
s dilemma for two |
dilemma for two pools |
synchronous writeback asynchronous writeback |
writeback asynchronous writeback sirp |
asynchronous writeback sirp c |
the revenue density of |
writeback sirp c sirp |
presents the average and |
revenue density of each |
the average and minimum |
density of each pool |
average and minimum upload |
of each pool is |
and minimum upload factors |
each pool is determined |
minimum upload factors among |
pool is determined by |
upload factors among all |
is determined by the |
factors among all correct |
and the french air |
determined by the decision |
among all correct nodes |
the french air traffic |
by the decision of |
french air traffic control |
the decision of both |
air traffic control system |
decision of both pools |
of both pools whether |
both pools whether to |
pools whether to attack |
whether to attack or |
to attack or not |
and the us naval |
the us naval aegis |
us naval aegis warship |
naval aegis warship communication |
aegis warship communication system |
axis we vary the |
the dominant strategy of |
we vary the percentage |
dominant strategy of each |
to name just a |
name just a few |
strategy of each player |
vary the percentage of |
of each player is |
the percentage of opportunistic |
each player is to |
percentage of opportunistic nodes |
leslie lamport s paxos |
player is to attack |
lamport s paxos protocol |
s paxos protocol has |
paxos protocol has been |
protocol has been used |
and on the y |
staleness of version retrieved |
however the payoff of |
has been used to |
the payoff of both |
axis we present the |
been used to build |
payoff of both would |
we present the upload |
used to build file |
of both would be |
present the upload factors |
to build file systems |
both would be larger |
the upload factors of |
upload factors of nodes |
would be larger if |
build file systems and |
be larger if they |
file systems and scalable |
larger if they both |
systems and scalable clusters |
which can vary up |
if they both refrain |
can vary up to |
they both refrain from |
both refrain from attacking |
none of these examples |
of these examples uses |
these examples uses lock |
a pool can detect |
pool can detect whether |
step replication of the |
can detect whether it |
replication of the type |
detect whether it is |
of the type mandated |
whether it is being |
the type mandated by |
it is being attacked |
type mandated by corba |
it is interesting to |
is being attacked and |
is interesting to note |
being attacked and deduce |
interesting to note that |
every technology has its |
attacked and deduce that |
to note that the |
technology has its successes |
and deduce that the |
note that the average |
has its successes and |
deduce that the other |
that the average upload |
its successes and failures |
that the other pool |
the average upload factor |
the other pool is |
average upload factor among |
other pool is violating |
upload factor among correct |
pool is violating the |
factor among correct nodes |
is violating the agreement |
among correct nodes initially |
correct nodes initially increases |
and then starts falling |
these technologies could take |
then starts falling when |
technologies could take the |
cooperation where neither pool |
starts falling when the |
could take the web |
where neither pool attacks |
falling when the percentage |
take the web services |
neither pool attacks is |
when the percentage of |
the web services architecture |
pool attacks is a |
the percentage of opportunistic |
web services architecture to |
attacks is a possible |
percentage of opportunistic nodes |
services architecture to a |
is a possible stable |
of opportunistic nodes increases |
architecture to a new |
a possible stable state |
opportunistic nodes increases significantly |
to a new level |
this behavior can be |
behavior can be explained |
can be explained by |
be explained by the |
explained by the fact |
by the fact that |
doing so could greatly |
so could greatly enlarge |
could greatly enlarge the |
greatly enlarge the web |
enlarge the web services |
the web services market |
synchronous writeback asynchronous writeback |
writeback asynchronous writeback sirp |
correct nodes start contributing |
asynchronous writeback sirp c |
writeback sirp c sirp |
nodes start contributing more |
so what s the |
start contributing more to |
what s the bottom |
s the bottom line |
contributing more to compensate |
more to compensate for |
to compensate for the |
compensate for the lack |
are web services distributed |
for the lack of |
web services distributed objects |
the lack of data |
despite the fact that |
lack of data provided |
the fact that the |
of data provided by |
of course they are |
fact that the single |
data provided by a |
that the single nash |
provided by a small |
the single nash equilibrium |
by a small percentage |
the marketing people are |
single nash equilibrium in |
a small percentage of |
marketing people are listening |
nash equilibrium in every |
small percentage of opportunistic |
people are listening to |
are listening to customers |
equilibrium in every round |
percentage of opportunistic nodes |
cumulative proportion of reads |
and they want distributed |
in every round is |
they want distributed objects |
every round is to |
round is to attack |
once the effect of |
the effect of opportunistic |
but vogels is right |
effect of opportunistic nodes |
of opportunistic nodes becomes |
opportunistic nodes becomes significant |
the system collapses and |
system collapses and correct |
case as an example |
collapses and correct nodes |
as an example we |
and correct nodes are |
an example we take |
correct nodes are not |
example we take again |
nodes are not able |
we take again the |
are not able to |
take again the pool |
not able to keep |
again the pool sizes |
it s time for |
able to keep contributing |
the pool sizes shown |
s time for the |
pool sizes shown in |
time for the web |
sizes shown in figure |
another important point to |
for the web services |
important point to note |
the web services community |
point to note is |
web services community to |
to note is that |
services community to come |
note is that the |
community to come to |
and study the case |
is that the minimum |
to come to grips |
study the case where |
that the minimum upload |
come to grips with |
the case where the |
the minimum upload factor |
to grips with the |
case where the two |
minimum upload factor does |
grips with the needs |
where the two largest |
upload factor does not |
with the needs of |
the two largest pools |
factor does not follow |
the needs of their |
does not follow a |
needs of their customer |
not follow a clearly |
of their customer base |
follow a clearly defined |
a clearly defined pattern |
one can justify solutions |
can justify solutions that |
justify solutions that make |
the optimal infiltration rates |
making it hard to |
it hard to estimate |
staleness of version retrieved |
hard to estimate the |
to estimate the minimum |
out of the total |
of the total system |
estimate the minimum contribution |
the minimum contribution of |
of the customers happy |
the customers happy but |
the total system mining |
minimum contribution of correct |
contribution of correct nodes |
customers happy but leave |
total system mining power |
of version retrieved read |
of correct nodes under |
correct nodes under compromised |
nodes under compromised scenarios |
version retrieved read staleness |
retrieved read staleness at |
by applying thresholds to |
applying thresholds to punish |
thresholds to punish opportunistic |
to punish opportunistic nodes |
a solution that tries |
solution that tries to |
that tries to do |
tries to do better |
to do better will |
correct nodes may also |
do better will probably |
nodes may also be |
better will probably overreach |
may also be unfairly |
also be unfairly penalized |
but you can t |
and the pools would |
you can t get |
the pools would lose |
can t get there |
t get there if |
get there if you |
there if you close |
if you close your |
auditing protocol our idea |
you close your eyes |
protocol our idea for |
close your eyes to |
our idea for auditing |
your eyes to the |
idea for auditing the |
eyes to the way |
for auditing the described |
to the way the |
auditing the described live |
the way the customers |
way the customers are |
the customers are likely |
customers are likely to |
are likely to use |
likely to use the |
streaming system against opportunistic |
to use the technology |
cumulative proportion of reads |
system against opportunistic behavior |
proportion of reads cumulative |
against opportunistic behavior is |
compared to the no |
will the web services |
of reads cumulative proportion |
opportunistic behavior is motivated |
the web services community |
reads cumulative proportion of |
cumulative proportion of reads |
web services community have |
behavior is motivated by |
services community have the |
q i dentical p |
is motivated by the |
community have the wisdom |
i dentical p ools |
motivated by the graphs |
have the wisdom to |
dentical p ools let |
by the graphs presented |
the wisdom to tackle |
p ools let there |
the graphs presented in |
wisdom to tackle the |
ools let there be |
graphs presented in the |
to tackle the tough |
let there be q |
presented in the previous |
tackle the tough issues |
there be q pools |
in the previous section |
the tough issues before |
be q pools of |
tough issues before circumstances |
q pools of identical |
issues before circumstances force |
we propose to employ |
pools of identical size |
before circumstances force it |
propose to employ auditing |
of identical size that |
circumstances force it upon |
to employ auditing to |
identical size that engage |
force it upon them |
employ auditing to ensure |
size that engage in |
auditing to ensure that |
that engage in block |
to ensure that all |
engage in block withholding |
ensure that all nodes |
in block withholding against |
that all nodes in |
block withholding against one |
all nodes in the |
withholding against one another |
nodes in the system |
a fellow of the |
fellow of the acm |
in the system contribute |
the system contribute more |
other miners neither attack |
system contribute more than |
miners neither attack nor |
contribute more than a |
neither attack nor are |
more than a particular |
attack nor are being |
than a particular specified |
nor are being attacked |
a particular specified threshold |
in this case there |
this case there exists |
case there exists a |
there exists a symmetric |
exists a symmetric equilibrium |
we illustrate the potential |
illustrate the potential benefit |
the potential benefit from |
without loss of generality |
potential benefit from using |
benefit from using auditing |
from using auditing in |
using auditing in a |
auditing in a system |
in a system where |
a step of pool |
and has worked on |
has worked on reliability |
worked on reliability and |
it controls its attack |
on reliability and scalability |
controls its attack rates |
of the nodes are |
reliability and scalability issues |
its attack rates each |
the nodes are correct |
and scalability issues in |
attack rates each of |
rates each of the |
scalability issues in distributed |
nodes are correct and |
each of the other |
of the other pools |
issues in distributed systems |
in distributed systems since |
distributed systems since starting |
systems since starting his |
since starting his research |
starting his research career |
and due to symmetry |
synchronous writeback asynchronous writeback |
due to symmetry they |
to symmetry they are |
he is the author |
is the author of |
symmetry they are all |
they are all the |
the latter do not |
latter do not upload |
do not upload any |
the author of many |
author of many articles |
are all the same |
not upload any data |
writeback asynchronous writeback sirp |
of many articles on |
many articles on the |
articles on the subject |
asynchronous writeback sirp c |
writeback sirp c sirp |
the attack rate of |
attack rate of pool |
no punishment was applied |
against any other pool |
punishment was applied in |
was applied in an |
applied in an attempt |
in an attempt to |
and applications will be |
an attempt to simulate |
each of the other |
applications will be published |
attempt to simulate a |
of the other pools |
will be published by |
to simulate a system |
the other pools can |
be published by springer |
simulate a system with |
other pools can attack |
published by springer verlag |
a system with no |
system with no auditing |
by springer verlag in |
springer verlag in fall |
pools can attack its |
can attack its peers |
attack its peers as |
its peers as well |
all attack rates by |
attack rates by all |
rates by all attackers |
by all attackers are |
all attackers are identical |
auditing is enabled and |
staleness of version retrieved |
is enabled and opportunistic |
enabled and opportunistic nodes |
and opportunistic nodes start |
the attack rate of |
opportunistic nodes start to |
attack rate of any |
nodes start to be |
rate of any pool |
start to be expelled |
of any pool other |
to be expelled from |
any pool other than |
be expelled from the |
web services are not |
expelled from the system |
services are not distributed |
from the system for |
are not distributed objects |
against any other pool |
the system for low |
system for low contribution |
staleness of reader file |
of reader file accesses |
the minimum upload factor |
cumulative distributions for the |
minimum upload factor for |
distributions for the staleness |
upload factor for nodes |
for the staleness of |
factor for nodes to |
for nodes to stay |
nodes to stay in |
to stay in the |
stay in the system |
in the system was |
the system was set |
system was set to |
the staleness of all |
staleness of all accesses |
of all accesses to |
all accesses to files |
accesses to files by |
to files by the |
files by the three |
by the three readers |
the three readers are |
three readers are shown |
the direct revenue of |
direct revenue of each |
revenue of each of |
of each of the |
each of the other |
of the other pools |
higher curves represent less |
curves represent less staleness |
similarly denote by r |
total writer execution time |
the revenue densities of |
revenue densities of pool |
are instantiated to mi |
synchronous writeback asynchronous writeback |
writeback asynchronous writeback sirp |
asynchronous writeback sirp c |
writeback sirp c sirp |
without auditing with auditing |
synchronous writeback asynchronous writeback |
writeback asynchronous writeback sirp |
asynchronous writeback sirp c |
writeback sirp c sirp |
download factor of correct |
factor of correct nodes |
of correct nodes during |
correct nodes during a |
second streaming session with |
auditing is enabled in |
is enabled in the |
enabled in the last |
we present the minimum |
average and maximum download |
and maximum download factors |
maximum download factors across |
download factors across correct |
factors across correct nodes |
across correct nodes varying |
correct nodes varying along |
as observed in this |
observed in this particular |
in this particular example |
auditing has the potential |
has the potential to |
the potential to improve |
potential to improve the |
to improve the quality |
improve the quality of |
the quality of streamed |
quality of streamed sessions |
of streamed sessions significantly |
and at low cost |
symmetric case we have |
case we have r |
optimizing power consumption in |
one important concern is |
power consumption in large |
important concern is that |
consumption in large scale |
concern is that if |
in large scale storage |
is that if the |
large scale storage systems |
that if the specified |
scale storage systems lakshmi |
if the specified threshold |
storage systems lakshmi ganesh |
the specified threshold is |
specified threshold is too |
threshold is too high |
the expression is shown |
expression is shown in |
is shown in equation |
more opportunistic nodes may |
opportunistic nodes may be |
nodes may be caught |
but correct nodes may |
ken birman computer science |
correct nodes may also |
birman computer science department |
nodes may also be |
may also be unfairly |
also be unfairly punished |
no correct nodes were |
correct nodes were mistakenly |
nodes were mistakenly expelled |
were mistakenly expelled from |
mistakenly expelled from the |
given any value of |
expelled from the system |
any value of q |
value of q and |
of q and mi |
average reader execution time |
auditing components we now |
components we now give |
we now give some |
edu abstract data centers |
now give some additional |
abstract data centers are |
the feasible range of |
give some additional details |
data centers are the |
feasible range of the |
some additional details of |
centers are the backend |
range of the infiltration |
additional details of the |
are the backend for |
of the infiltration rates |
details of the auditing |
the backend for a |
the infiltration rates is |
of the auditing architecture |
backend for a large |
for a large number |
a large number of |
large number of services |
number of services that |
focusing upon two aspects |
of services that we |
services that we take |
that we take for |
we take for granted |
take for granted today |
a significant fraction of |
significant fraction of the |
within this range ri |
fraction of the total |
this range ri is |
of the total cost |
range ri is continuous |
the total cost of |
total cost of ownership |
collecting accountable information about |
cost of ownership of |
accountable information about the |
of ownership of these |
information about the download |
ownership of these large |
and concave in x |
about the download and |
the download and upload |
download and upload factors |
and upload factors of |
scale storage systems is |
upload factors of individual |
storage systems is the |
factors of individual nodes |
systems is the cost |
of individual nodes in |
is the cost of |
individual nodes in the |
the cost of keeping |
nodes in the system |
cost of keeping hundreds |
of keeping hundreds of |
keeping hundreds of thousands |
hundreds of thousands of |
of thousands of disks |
thousands of disks spinning |
the optimal point for |
optimal point for pool |
we present a simple |
present a simple idea |
a simple idea that |
simple idea that allows |
idea that allows the |
that allows the storage |
allows the storage system |
establishing and applying the |
the storage system to |
and applying the best |
storage system to turn |
system to turn off |
applying the best threshold |
to turn off a |
the best threshold at |
turn off a large |
best threshold at any |
off a large fraction |
a large fraction of |
large fraction of its |
fraction of its disks |
threshold at any given |
at any given time |
any given time during |
given time during execution |
without incurring unacceptable performance |
incurring unacceptable performance penalties |
we employ two types |
execution times for concurrent |
times for concurrent access |
for concurrent access trace |
employ two types of |
of particular appeal is |
two types of components |
since the function is |
reader execution times are |
types of components to |
particular appeal is the |
the function is concave |
function is concave the |
of components to perform |
appeal is the fact |
is the fact that |
is concave the equation |
components to perform these |
to perform these two |
perform these two roles |
concave the equation yields |
the equation yields a |
the fact that our |
fact that our solution |
equation yields a single |
yields a single feasible |
local and global auditors |
that our solution is |
our solution is not |
a single feasible solution |
execution times are averages |
local auditors are executed |
auditors are executed on |
solution is not application |
times are averages for |
are averages for the |
averages for the three |
for the three readers |
which is a function |
are executed on the |
is a function of |
executed on the nodes |
a function of the |
on the nodes participating |
function of the attack |
the nodes participating in |
savings for a very |
of the attack rates |
nodes participating in the |
participating in the system |
for a very generic |
the attack rates of |
attack rates of the |
a very generic data |
very generic data center |
generic data center model |
and therefore cannot be |
therefore cannot be trusted |
rates of the other |
of the other pools |
higher bandwidth results in |
bandwidth results in less |
results in less staleness |
if a node is |
we describe our solution |
a node is malicious |
since writes can be |
writes can be sent |
can be sent to |
be sent to the |
sent to the file |
to the file server |
the file server faster |
it might report false |
might report false data |
identify the parameters that |
the parameters that determine |
parameters that determine its |
that determine its cost |
global auditors are trusted |
auditors are trusted components |
are trusted components that |
trusted components that run |
components that run on |
that run on dedicated |
run on dedicated external |
on dedicated external nodes |
to find a symmetric |
and present a simulator |
find a symmetric equilibrium |
present a simulator that |
a simulator that allows |
there can be just |
simulator that allows us |
can be just one |
that allows us to |
allows us to explore |
be just one or |
just one or a |
us to explore this |
to explore this parameter |
explore this parameter space |
sirp is most effective |
is most effective at |
most effective at reducing |
effective at reducing staleness |
one or a few |
we also present some |
or a few global |
also present some initial |
though many reads return |
many reads return out |
present some initial simulation |
a few global auditors |
some initial simulation results |
initial simulation results that |
simulation results that add |
results that add weight |
we describe their roles |
that add weight to |
date file contents when |
file contents when compared |
contents when compared to |
when compared to the |
compared to the optimal |
to the optimal version |
add weight to our |
describe their roles and |
weight to our claim |
their roles and interactions |
and obtain a single |
to our claim that |
roles and interactions in |
obtain a single feasible |
our claim that our |
and interactions in detail |
a single feasible solution |
claim that our solution |
more sirp reads are |
sirp reads are up |
that our solution represents |
the equilibrium infiltration rate |
interactions in detail below |
our solution represents a |
equilibrium infiltration rate and |
solution represents a new |
infiltration rate and the |
represents a new powersaving |
rate and the matching |
a new powersaving opportunity |
and the matching revenues |
new powersaving opportunity for |
compared to synchronous or |
to synchronous or asynchronous |
synchronous or asynchronous writeback |
the matching revenues are |
powersaving opportunity for large |
matching revenues are shown |
revenues are shown in |
are shown in equation |
allowing higher degrees of |
higher degrees of staleness |
local auditors each node |
auditors each node n |
each node n runs |
node n runs a |
n runs a local |
runs a local auditor |
introduction the declining costs |
the declining costs of |
declining costs of commodity |
costs of commodity disk |
of commodity disk drives |
which interacts with other |
commodity disk drives has |
more reads performed with |
reads performed with sirp |
performed with sirp are |
with sirp are within |
disk drives has made |
interacts with other local |
drives has made online |
with other local auditors |
versions of the optimal |
as in the two |
other local auditors and |
has made online data |
local auditors and has |
made online data storage |
auditors and has two |
and has two main |
has two main roles |
with this bandwidth level |
the revenue at the |
online data storage a |
revenue at the symmetric |
publish n s data |
data storage a way |
synchronous and asynchronous writeback |
and asynchronous writeback coincide |
asynchronous writeback coincide in |
writeback coincide in performance |
n s data exchange |
s data exchange history |
storage a way of |
a way of life |
at the symmetric equilibrium |
since they are constrained |
the symmetric equilibrium is |
n s local auditor |
they are constrained by |
symmetric equilibrium is inferior |
so much so that |
s local auditor periodically |
are constrained by the |
equilibrium is inferior to |
much so that companies |
local auditor periodically compiles |
constrained by the bandwidth |
is inferior to the |
inferior to the no |
auditor periodically compiles and |
by the bandwidth bottleneck |
so that companies like |
periodically compiles and distributes |
the bandwidth bottleneck and |
that companies like google |
compiles and distributes the |
and distributes the history |
companies like google and |
bandwidth bottleneck and send |
distributes the history of |
like google and yahoo |
google and yahoo host |
the history of packets |
history of packets exchanged |
and yahoo host hundreds |
bottleneck and send updates |
and send updates in |
send updates in the |
updates in the same |
in the same order |
of packets exchanged by |
packets exchanged by n |
yahoo host hundreds of |
up our analysis addresses |
host hundreds of thousands |
hundreds of thousands of |
our analysis addresses the |
analysis addresses the eventual |
of thousands of servers |
thousands of servers for |
of servers for storage |
by suppressing unnecessary invalidations |
addresses the eventual revenue |
the eventual revenue of |
it queries the local |
eventual revenue of the |
queries the local streaming |
revenue of the pools |
the local streaming application |
there is a catch |
local streaming application running |
sirp reduces its bandwidth |
streaming application running on |
a hundred thousand servers |
assuming the mining difficulty |
the mining difficulty is |
application running on n |
hundred thousand servers consume |
thousand servers consume a |
mining difficulty is set |
running on n for |
reduces its bandwidth usage |
servers consume a lot |
consume a lot of |
a lot of power |
its bandwidth usage and |
difficulty is set based |
on n for the |
bandwidth usage and achieves |
usage and achieves a |
and achieves a small |
achieves a small improvement |
a small improvement over |
small improvement over sirp |
n for the set |
is set based on |
not only does this |
for the set of |
set based on the |
only does this translate |
the set of packets |
based on the effective |
does this translate to |
set of packets it |
on the effective mining |
the effective mining power |
this translate to many |
of packets it sent |
since devoting less bandwidth |
translate to many millions |
packets it sent and |
devoting less bandwidth to |
not including mining power |
to many millions of |
it sent and received |
less bandwidth to invalidations |
including mining power used |
many millions of dollars |
sent and received using |
and received using the |
mining power used for |
millions of dollars annually |
of dollars annually on |
received using the streaming |
power used for withholding |
bandwidth to invalidations results |
dollars annually on electricity |
using the streaming protocol |
the streaming protocol in |
annually on electricity bills |
to invalidations results in |
difficulty is updated only |
streaming protocol in the |
protocol in the most |
is updated only periodically |
updated only periodically every |
the heat produced by |
in the most recent |
the most recent time |
heat produced by so |
invalidations results in data |
results in data reaching |
in data reaching the |
data reaching the server |
reaching the server faster |
most recent time interval |
produced by so much |
by so much computing |
so much computing power |
much computing power can |
computing power can be |
power can be searing |
asynchronous writeback performs as |
an article in the |
writeback performs as well |
performs as well as |
as well as sirp |
when mining power in |
article in the new |
mining power in the |
the local auditor signs |
in the new york |
power in the system |
local auditor signs and |
the new york times |
synchronous writeback continues to |
writeback continues to underperform |
in the system is |
new york times describes |
auditor signs and publishes |
the system is regularly |
york times describes one |
signs and publishes the |
system is regularly increasing |
this is because the |
times describes one of |
and publishes the collected |
is because the progress |
describes one of google |
publishes the collected history |
which has been true |
has been true for |
one of google s |
the collected history to |
collected history to an |
been true for the |
of google s data |
google s data centers |
history to an assigned |
true for the majority |
for the majority of |
to an assigned subset |
an assigned subset of |
the majority of bitcoin |
majority of bitcoin s |
assigned subset of its |
subset of its neighboring |
of its neighboring nodes |
because the progress of |
of bitcoin s history |
the progress of writers |
a computing center as |
from whom other auditors |
whom other auditors may |
computing center as big |
center as big as |
other auditors may obtain |
auditors may obtain it |
as big as two |
big as two football |
as two football fields |
progress of writers using |
of writers using asynchronous |
this level of indirection |
writers using asynchronous writeback |
level of indirection is |
with twin cooling plants |
twin cooling plants protruding |
no adjustment may be |
adjustment may be necessary |
using asynchronous writeback schemes |
cooling plants protruding four |
of indirection is used |
asynchronous writeback schemes is |
plants protruding four stories |
indirection is used to |
if an attacker purchases |
is used to prevent |
writeback schemes is less |
schemes is less constrained |
is less constrained by |
less constrained by the |
constrained by the bandwidth |
an attacker purchases new |
used to prevent nodes |
protruding four stories into |
attacker purchases new mining |
to prevent nodes from |
four stories into the |
stories into the sky |
purchases new mining hardware |
prevent nodes from masking |
and they can overlap |
new mining hardware and |
nodes from masking their |
they can overlap computation |
mining hardware and employs |
from masking their real |
can overlap computation and |
hardware and employs it |
masking their real upload |
overlap computation and fetching |
and employs it directly |
their real upload and |
computation and fetching file |
and fetching file contents |
fetching file contents with |
file contents with writeback |
employs it directly for |
real upload and download |
power conservation is an |
it directly for block |
upload and download factors |
conservation is an important |
directly for block withholding |
rather than simply being |
and download factors by |
is an important concern |
an important concern for |
download factors by presenting |
than simply being a |
this mining power is |
important concern for big |
factors by presenting different |
by presenting different information |
mining power is never |
concern for big server |
for big server clusters |
presenting different information to |
power is never included |
simply being a selfinterested |
different information to different |
is never included in |
being a selfinterested optimisation |
since disks account for |
information to different auditors |
never included in the |
a selfinterested optimisation by |
disks account for a |
included in the difficulty |
selfinterested optimisation by writers |
account for a significant |
in the difficulty calculation |
audit n s neighbors |
n s neighbors histories |
for a significant fraction |
the difficulty calculation the |
difficulty calculation the system |
a significant fraction of |
significant fraction of the |
calculation the system is |
the system is never |
n s local auditor |
fraction of the energy |
of the energy consumed |
system is never aware |
s local auditor periodically |
optimisation by writers to |
by writers to improve |
writers to improve their |
to improve their own |
improve their own performance |
is never aware of |
never aware of it |
local auditor periodically audits |
auditor periodically audits the |
periodically audits the published |
asynchronous writeback therefore benefits |
the difficulty is therefore |
writeback therefore benefits both |
therefore benefits both writers |
benefits both writers and |
both writers and readers |
audits the published histories |
several approaches for disk |
difficulty is therefore already |
the published histories of |
the files shared between |
files shared between the |
approaches for disk power |
published histories of the |
is therefore already correctly |
shared between the clients |
between the clients were |
the clients were divided |
clients were divided into |
for disk power management |
histories of the nodes |
therefore already correctly calculated |
disk power management have |
of the nodes with |
already correctly calculated and |
power management have been |
the nodes with whom |
correctly calculated and the |
management have been proposed |
nodes with whom n |
calculated and the attack |
have been proposed and |
with whom n exchanges |
and the attack is |
been proposed and studied |
whom n exchanges packets |
the attack is profitable |
attack is profitable immediately |
file lengths were randomised |
we will examine some |
will examine some of |
examine some of these |
some of these here |
with an average length |
an average length of |
if the mining power |
if node n exchanges |
but first let us |
the mining power is |
mining power is static |
first let us lay |
node n exchanges packets |
let us lay out |
n exchanges packets with |
us lay out some |
exchanges packets with nodes |
the attack becomes profitable |
lay out some of |
packets with nodes p |
attack becomes profitable only |
out some of the |
becomes profitable only after |
to prevent the clients |
q and r in |
profitable only after the |
some of the groundwork |
prevent the clients falling |
and r in the |
only after the bitcoin |
any disk power management |
r in the livestreaming |
in the livestreaming protocol |
after the bitcoin system |
disk power management scheme |
the clients falling into |
the bitcoin system has |
power management scheme essentially |
management scheme essentially attempts |
n s local auditor |
bitcoin system has normalized |
system has normalized the |
scheme essentially attempts to |
s local auditor compares |
clients falling into lockstep |
has normalized the revenues |
essentially attempts to exploit |
local auditor compares these |
falling into lockstep in |
normalized the revenues by |
attempts to exploit one |
to exploit one fact |
into lockstep in the |
the revenues by adjusting |
revenues by adjusting difficulty |
disks can be run |
auditor compares these three |
lockstep in the course |
can be run in |
compares these three nodes |
these three nodes histories |
be run in highpower |
run in highpower mode |
three nodes histories with |
nodes histories with n |
the revenue of an |
in the course of |
histories with n s |
revenue of an attacking |
the course of fetching |
with n s own |
n s own history |
with a corresponding performance |
a corresponding performance tradeoff |
course of fetching and |
of fetching and writing |
this involves ensuring that |
fetching and writing back |
and writing back the |
writing back the files |
of an attacking pool |
a disk can be |
an attacking pool is |
disk can be shut |
attacking pool is reduced |
can be shut off |
pool is reduced due |
be shut off so |
is reduced due to |
shut off so that |
reduced due to the |
off so that it |
due to the reduction |
the amount of data |
so that it consumes |
to the reduction in |
amount of data sent |
that it consumes no |
it consumes no power |
consisting of selecting a |
of data sent by |
the reduction in block |
given a large cluster |
data sent by these |
of selecting a random |
reduction in block generation |
a large cluster of |
sent by these nodes |
selecting a random file |
in block generation of |
large cluster of disks |
by these nodes satisfies |
these nodes satisfies the |
block generation of both |
generation of both the |
only a fraction of |
a fraction of them |
nodes satisfies the defined |
of both the attacking |
both the attacking and |
fraction of them is |
satisfies the defined minimum |
the defined minimum threshold |
the attacking and attacked |
of them is accessed |
them is accessed at |
is accessed at any |
accessed at any time |
a random file set |
defined minimum threshold for |
attacking and attacked pools |
random file set and |
minimum threshold for the |
threshold for the system |
file set and performing |
so that the rest |
set and performing a |
and performing a sequence |
performing a sequence of |
a sequence of reads |
sequence of reads or |
of reads or writes |
reads or writes on |
or writes on files |
writes on files in |
on files in it |
pool knowledge and r |
that the rest could |
the rest could potentially |
rest could potentially be |
could potentially be switched |
the set of packets |
the writer performed a |
writer performed a file |
performed a file set |
a file set operation |
file set operation of |
potentially be switched to |
set of packets they |
be switched to a |
of packets they claim |
switched to a low |
packets they claim to |
they claim to have |
claim to have sent |
to have sent to |
have sent to and |
sent to and received |
to and received from |
and received from node |
received from node n |
from node n corresponds |
node n corresponds to |
since mode transitions consume |
n corresponds to the |
mode transitions consume time |
corresponds to the set |
transitions consume time and |
to the set of |
consume time and power |
the set of packets |
set of packets n |
of packets n claims |
packets n claims to |
n claims to have |
claims to have respectively |
disk management schemes have |
to have respectively received |
have respectively received from |
management schemes have to |
with each access being |
respectively received from and |
schemes have to walk |
each access being equally |
received from and sent |
from and sent to |
and sent to them |
have to walk the |
access being equally likely |
to walk the tightrope |
being equally likely to |
equally likely to open |
likely to open a |
to open a file |
open a file for |
a file for reading |
file for reading or |
for reading or writing |
if the first check |
walk the tightrope of |
the first check comparison |
the tightrope of finding |
first check comparison fails |
readers performed a file |
performed a file set |
a file set operation |
file set operation of |
tightrope of finding the |
the local auditor issues |
of finding the right |
local auditor issues an |
finding the right balance |
auditor issues an accusation |
the right balance between |
issues an accusation against |
right balance between power |
an accusation against the |
balance between power consumption |
accusation against the node |
between power consumption and |
against the node to |
power consumption and performance |
the node to a |
node to a global |
to a global auditor |
the solution space explored |
solution space explored thus |
in the second case |
space explored thus far |
explored thus far in |
thus far in the |
far in the literature |
in the literature can |
the literature can be |
the local auditor is |
literature can be divided |
file sets were treated |
sets were treated as |
were treated as hot |
local auditor is not |
can be divided as |
be divided as follows |
auditor is not able |
is not able to |
not able to prove |
able to prove the |
to prove the neighbor |
prove the neighbor s |
the neighbor s misbehavior |
of the file set |
the file set operations |
file set operations were |
set operations were directed |
it instructs its local |
operations were directed to |
were directed to those |
directed to those file |
to those file sets |
instructs its local streaming |
its local streaming application |
local streaming application to |
streaming application to not |
read staleness comparing update |
application to not further |
to not further exchange |
staleness comparing update propagation |
not further exchange packets |
further exchange packets with |
exchange packets with the |
packets with the misbehaving |
with the misbehaving neighbor |
comparing update propagation schemes |
update propagation schemes requires |
propagation schemes requires a |
schemes requires a criterion |
requires a criterion for |
more complex types of |
a criterion for measuring |
criterion for measuring the |
for measuring the staleness |
measuring the staleness of |
the staleness of file |
staleness of file reads |
complex types of checks |
types of checks may |
of checks may also |
checks may also be |
we identified updates to |
identified updates to files |
updates to files by |
to files by associating |
files by associating a |
by associating a version |
associating a version number |
a version number with |
version number with each |
number with each file |
each of these solutions |
may also be performed |
of these solutions proposes |
also be performed to |
be performed to address |
these solutions proposes a |
solutions proposes a new |
proposes a new system |
a new system of |
new system of some |
system of some kind |
performed to address other |
to address other types |
address other types of |
other types of byzantine |
types of byzantine behavior |
and incrementing it every |
incrementing it every time |
it every time the |
every time the file |
time the file was |
the file was modified |
based solutions propose novel |
and solving we obtain |
solutions propose novel storage |
solving we obtain a |
propose novel storage hierarchies |
reads were labelled with |
we obtain a single |
novel storage hierarchies to |
were labelled with the |
obtain a single expression |
storage hierarchies to strike |
labelled with the version |
a single expression for |
hierarchies to strike the |
with the version number |
single expression for any |
to strike the right |
the version number of |
expression for any ri |
strike the right balance |
the right balance between |
version number of the |
number of the file |
since in the in |
in the in order |
right balance between performance |
balance between performance and |
the in order to |
of the file at |
the file at the |
file at the time |
at the time the |
the time the read |
time the read occurred |
in order to choose |
between performance and power |
order to choose its |
performance and power consumption |
the staleness of a |
to choose its optimal |
choose its optimal infiltration |
its optimal infiltration rate |
staleness of a particular |
disk management solutions interject |
of a particular read |
management solutions interject a |
a pool has to |
pool has to know |
solutions interject a new |
a particular read was |
has to know the |
interject a new disk |
particular read was determined |
to know the rate |
a new disk management |
read was determined according |
know the rate at |
new disk management layer |
disk management layer on |
the rate at which |
rate at which it |
management layer on top |
layer on top of |
at which it is |
which it is attacked |
on top of the |
top of the file |
of the file system |
was determined according to |
and the revenue density |
the revenue density of |
revenue density of potential |
density of potential victim |
which controls disk configuration |
determined according to an |
of potential victim pools |
controls disk configuration and |
disk configuration and data |
configuration and data layout |
and data layout to |
data layout to achieve |
a pool can estimate |
layout to achieve power |
according to an ideal |
pool can estimate the |
to an ideal version |
can estimate the rate |
optimal disk access patterns |
an ideal version number |
estimate the rate with |
ideal version number derived |
caching solutions devise new |
solutions devise new power |
version number derived from |
the rate with which |
number derived from executing |
rate with which it |
derived from executing the |
aware caching algorithms that |
with which it is |
from executing the experiment |
caching algorithms that allow |
which it is attacked |
executing the experiment with |
the experiment with all |
experiment with all participants |
with all participants running |
all participants running on |
participants running on a |
running on a single |
on a single host |
it is attacked by |
algorithms that allow large |
is attacked by comparing |
that allow large fractions |
in a real execution |
attacked by comparing the |
allow large fractions of |
by comparing the rates |
large fractions of the |
comparing the rates of |
the difference between the |
fractions of the storage |
the rates of partial |
difference between the version |
of the storage system |
rates of partial and |
between the version number |
the storage system to |
of partial and full |
the version number a |
storage system to remain |
partial and full proofs |
and full proofs of |
system to remain idle |
to remain idle for |
full proofs of work |
proofs of work it |
remain idle for longer |
idle for longer periods |
for longer periods of |
longer periods of time |
of work it receives |
work it receives from |
it receives from its |
receives from its miners |
version number a read |
allowing them to be |
them to be switched |
to be switched to |
be switched to lower |
switched to lower power |
to lower power modes |
as explained in section |
explained in section ii |
number a read returns |
a read returns and |
read returns and the |
the principal contribution of |
returns and the optimal |
principal contribution of this |
and the optimal version |
the optimal version number |
optimal version number determines |
in order to estimate |
version number determines how |
number determines how stale |
determines how stale the |
how stale the read |
stale the read is |
contribution of this paper |
order to estimate the |
of this paper is |
to estimate the revenue |
this paper is to |
estimate the revenue densities |
paper is to argue |
shows cumulative distributions for |
the revenue densities of |
is to argue that |
cumulative distributions for the |
distributions for the staleness |
for the staleness of |
the staleness of reads |
staleness of reads at |
of reads at different |
reads at different writer |
revenue densities of the |
to argue that there |
densities of the other |
argue that there is |
of the other pools |
that there is a |
there is a fourth |
improved consistency results in |
consistency results in fewer |
results in fewer stale |
a pool can use |
pool can use one |
is a fourth niche |
a fourth niche as |
can use one of |
use one of two |
fourth niche as yet |
niche as yet unexplored |
one of two methods |
in fewer stale reads |
global auditing there are |
auditing there are two |
there are two ways |
and this is reflected |
are two ways in |
this is reflected by |
two ways in which |
is reflected by a |
ways in which a |
reflected by a curve |
in which a node |
by a curve that |
which a node could |
a curve that is |
we do not present |
a node could pretend |
curve that is higher |
that is higher on |
is higher on the |
higher on the left |
on the left side |
the left side of |
left side of the |
side of the graph |
node could pretend to |
do not present a |
could pretend to be |
not present a new |
present a new system |
pretend to be sending |
consistency maintenance cost the |
to be sending more |
maintenance cost the overhead |
be sending more or |
sending more or receiving |
more or receiving less |
cost the overhead of |
we take an idea |
or receiving less data |
receiving less data than |
take an idea that |
the overhead of the |
less data than it |
an idea that has |
overhead of the update |
data than it actually |
idea that has been |
that has been around |
than it actually does |
of the update propagation |
has been around for |
been around for well |
around for well over |
it could send different |
for well over a |
well over a decade |
over a decade now |
the update propagation schemes |
could send different histories |
send different histories to |
different histories to each |
histories to each neighbor |
update propagation schemes can |
propagation schemes can be |
schemes can be compared |
can be compared by |
be compared by referring |
compared by referring to |
by referring to the |
referring to the reader |
to the reader and |
the reader and writer |
reader and writer execution |
and writer execution times |
always lying about its |
lying about its interactions |
about its interactions with |
its interactions with other |
interactions with other neighbors |
acknowledgements shown in figure |
n could send a |
and argue that technological |
could send a history |
argue that technological evolution |
reader execution time is |
execution time is the |
time is the average |
is the average for |
the average for all |
average for all three |
for all three readers |
send a history to |
that technological evolution has |
a history to p |
technological evolution has given |
history to p pretending |
evolution has given it |
to p pretending to |
has given it a |
p pretending to send |
given it a new |
pretending to send more |
the reduced staleness achievable |
it a new relevance |
to send more data |
send more data to |
a new relevance today |
new relevance today as |
more data to q |
data to q than |
relevance today as a |
today as a natural |
as a natural power |
reduced staleness achievable by |
to q than it |
q than it actually |
than it actually did |
staleness achievable by sirp |
saving opportunity for large |
achievable by sirp has |
by sirp has little |
while it sends a |
sirp has little or |
it sends a different |
has little or no |
sends a different history |
the key insight is |
key insight is that |
a different history to |
little or no cost |
different history to q |
or no cost compared |
history to q where |
where other solutions attempt |
no cost compared to |
cost compared to asynchronous |
compared to asynchronous writeback |
to asynchronous writeback with |
asynchronous writeback with no |
writeback with no invalidations |
other solutions attempt to |
to q where it |
solutions attempt to predict |
q where it pretends |
attempt to predict disk |
to predict disk access |
where it pretends to |
since the writer is |
the writer is up |
writer is up to |
predict disk access to |
it pretends to send |
disk access to determine |
pretends to send more |
access to determine which |
to send more data |
to determine which disks |
send more data to |
determine which disks to |
more data to p |
slower when using sirp |
which disks to power |
data to p than |
disks to power down |
c compared to sirp |
to p than it |
p than it actually |
than it actually did |
the lfs automatically provides |
lfs automatically provides a |
automatically provides a perfect |
selective invalidation is clearly |
n s goal would |
invalidation is clearly beneficial |
provides a perfect prediction |
s goal would be |
a perfect prediction mechanism |
goal would be to |
would be to send |
be to send less |
to send less data |
sirp has the highest |
has the highest average |
the highest average execution |
highest average execution time |
simply by virtue of |
send less data while |
by virtue of the |
less data while not |
virtue of the fact |
of the fact that |
data while not being |
while not being caught |
the fact that all |
fact that all write |
not being caught by |
being caught by any |
caught by any of |
by any of its |
any of its neighbors |
accesses go to the |
go to the log |
to the log head |
but this is because |
this is because it |
is because it provides |
the process of publishing |
because it provides the |
it provides the best |
provides the best consistency |
the best consistency of |
explains and expands on |
and expands on this |
expands on this idea |
best consistency of all |
consistency of all the |
of all the schemes |
process of publishing a |
of publishing a node |
publishing a node s |
if a reader reads |
a reader reads more |
reader reads more up |
a node s history |
node s history to |
s history to a |
history to a predefined |
expression for ri in |
idea overview to see |
to a predefined set |
for ri in a |
overview to see why |
a predefined set of |
ri in a system |
to see why lfs |
then it transfers more |
it transfers more data |
in a system with |
see why lfs is |
predefined set of neighbors |
a system with pools |
why lfs is a |
set of neighbors ensures |
system with pools of |
lfs is a natural |
of neighbors ensures that |
with pools of equal |
pools of equal size |
is a natural solution |
neighbors ensures that the |
the reader execution time |
a natural solution to |
ensures that the node |
reader execution time for |
natural solution to the |
that the node cannot |
execution time for each |
solution to the problem |
the node cannot send |
time for each case |
to the problem of |
node cannot send conflicting |
cannot send conflicting histories |
the problem of disk |
problem of disk power |
of disk power management |
for each case is |
send conflicting histories to |
consider some of the |
conflicting histories to different |
histories to different neighbors |
some of the challenges |
of the challenges involved |
to different neighbors undetected |
each case is proportional |
case is proportional to |
is proportional to the |
proportional to the amount |
to the amount of |
the amount of data |
therefore avoiding this problem |
server systems typically are |
amount of data transferred |
of data transferred between |
data transferred between the |
transferred between the reader |
between the reader and |
the reader and server |
systems typically are not |
a node could also |
typically are not idle |
node could also lie |
are not idle long |
though lack of space |
lack of space precludes |
of space precludes showing |
space precludes showing this |
precludes showing this in |
showing this in a |
this in a graph |
could also lie about |
not idle long enough |
also lie about the |
idle long enough to |
long enough to make |
lie about the set |
we thank robbert van |
thank robbert van renesse |
about the set of |
enough to make it |
the set of packets |
to make it worthwhile |
set of packets sent |
make it worthwhile to |
of packets sent to |
it worthwhile to incur |
worthwhile to incur the |
to incur the time |
emin gu n sirer |
packets sent to or |
sent to or received |
to or received from |
or received from a |
power expense of switching |
received from a particular |
expense of switching the |
from a particular neighbor |
rimon barr and stephen |
barr and stephen rago |
and stephen rago for |
stephen rago for comments |
rago for comments regarding |
for comments regarding this |
comments regarding this work |
a particular neighbor p |
q mi q mi |
of switching the disk |
switching the disk to |
the disk to a |
disk to a lowpower |
to a lowpower mode |
p will be able |
and switching it back |
will be able to |
switching it back when |
be able to identify |
it back when it |
able to identify that |
back when it is |
when it is accessed |
to identify that the |
identify that the node |
that the node has |
the node has lied |
node has lied and |
this is a notable |
has lied and will |
is a notable point |
lied and will therefore |
a notable point of |
and will therefore stop |
evaluation of an adaptive |
of an adaptive transport |
an adaptive transport protocol |
notable point of difference |
will therefore stop exchanging |
point of difference between |
therefore stop exchanging packets |
stop exchanging packets with |
exchanging packets with n |
in proceedings of the |
proceedings of the twenty |
of difference between server |
difference between server systems |
given that an opportunistic |
between server systems and |
second annual joint conference |
that an opportunistic node |
server systems and typical |
systems and typical mobile |
an opportunistic node s |
annual joint conference of |
and typical mobile device |
opportunistic node s goal |
node s goal is |
typical mobile device scenarios |
joint conference of the |
s goal is to |
goal is to maximize |
is to maximize its |
to maximize its utility |
conference of the ieee |
of the ieee computer |
the ieee computer and |
ieee computer and communications |
computer and communications societies |
it should have no |
should have no interest |
have no interest in |
which makes it hard |
no interest in losing |
makes it hard to |
interest in losing data |
it hard to translate |
in losing data exchange |
hard to translate the |
losing data exchange partners |
to translate the solutions |
translate the solutions devised |
the solutions devised for |
solutions devised for mobile |
devised for mobile devices |
for mobile devices to |
mobile devices to server |
devices to server systems |
opportunistic nodes have no |
nodes have no incentive |
have no incentive to |
as we shall see |
no incentive to publish |
incentive to publish incorrect |
to publish incorrect histories |
access to a small |
to a small subset |
a small subset of |
small subset of disks |
local auditing ensures that |
auditing ensures that correct |
ensures that correct information |
that correct information is |
correct information is available |
information is available regarding |
is available regarding the |
available regarding the set |
when combined with a |
regarding the set of |
combined with a cache |
the set of data |
with a cache that |
set of data sent |
a cache that absorbs |
of data sent and |
cache that absorbs read |
data sent and received |
sent and received by |
and received by any |
received by any node |
and allows nodes to |
results in long disk |
allows nodes to monitor |
in long disk idle |
long disk idle periods |
nodes to monitor each |
to monitor each other |
monitor each other s |
each other s contribution |
other s contribution rates |
low predictability of idle |
predictability of idle periods |
q symmetric equilibrium values |
symmetric equilibrium values for |
equilibrium values for a |
values for a system |
for a system of |
a system of q |
system of q pools |
of q pools of |
q pools of equal |
pools of equal sizes |
often publish this data |
publish this data to |
have shown that there |
this data to demonstrate |
shown that there exists |
data to demonstrate their |
that there exists low |
to demonstrate their honesty |
global auditors global auditors |
there exists low correlation |
demonstrate their honesty to |
their honesty to their |
exists low correlation between |
auditors global auditors are |
honesty to their miners |
low correlation between a |
global auditors are trusted |
correlation between a given |
auditors are trusted components |
between a given idle |
are trusted components with |
a given idle period |
trusted components with global |
given idle period s |
components with global membership |
idle period s duration |
with global membership knowledge |
period s duration and |
s duration and the |
duration and the duration |
and the duration of |
the duration of previous |
duration of previous idle |
who interact with one |
of previous idle periods |
interact with one another |
with one another and |
one another and with |
another and with the |
and with the local |
with the local auditors |
this variability makes it |
variability makes it difficult |
makes it difficult to |
it difficult to devise |
difficult to devise effective |
as shown in figure |
to devise effective predictive |
devise effective predictive mechanisms |
effective predictive mechanisms for |
predictive mechanisms for disk |
mechanisms for disk idle |
for disk idle times |
the importance of translucence |
importance of translucence in |
of translucence in mobile |
translucence in mobile computing |
in mobile computing systems |
global auditors execute on |
the lfs neatly circumvents |
auditors execute on nodes |
lfs neatly circumvents this |
execute on nodes external |
on nodes external to |
neatly circumvents this problem |
acm transactions on computer |
nodes external to the |
external to the system |
circumvents this problem by |
this problem by predetermining |
problem by predetermining which |
by predetermining which disk |
predetermining which disk is |
their main roles are |
which disk is written |
disk is written to |
is written to at |
written to at all |
a pool can infiltrate |
define the minimum upload |
pool can infiltrate each |
to at all times |
can infiltrate each of |
the minimum upload threshold |
infiltrate each of the |
each of the other |
of the other pools |
the other pools with |
global auditors periodically sample |
other pools with some |
auditors periodically sample the |
server systems are often |
pools with some nominal |
periodically sample the state |
systems are often constrained |
with some nominal probing |
sample the state of |
are often constrained by |
some nominal probing mining |
the state of the |
often constrained by service |
nominal probing mining power |
state of the system |
constrained by service level |
probing mining power and |
of the system by |
by service level agreements |
mining power and measure |
the system by querying |
service level agreements to |
power and measure the |
system by querying local |
level agreements to guarantee |
and measure the revenue |
by querying local auditors |
agreements to guarantee a |
measure the revenue density |
to guarantee a certain |
the revenue density directly |
guarantee a certain level |
they then cooperate to |
revenue density directly by |
a certain level of |
then cooperate to analyze |
density directly by monitoring |
certain level of performance |
cooperate to analyze the |
directly by monitoring the |
to analyze the collected |
by monitoring the probe |
analyze the collected samples |
monitoring the probe s |
so that finding a |
the probe s rewards |
that finding a solution |
probe s rewards from |
and on this basis |
finding a solution that |
s rewards from the |
rewards from the pool |
a solution that provides |
on this basis compute |
solution that provides acceptable |
this basis compute the |
that provides acceptable performance |
basis compute the minimum |
provides acceptable performance to |
compute the minimum upload |
acceptable performance to only |
the minimum upload contribution |
block withholding recycling we |
performance to only a |
minimum upload contribution threshold |
withholding recycling we assume |
to only a fraction |
recycling we assume that |
only a fraction of |
we assume that the |
assume that the infiltrating |
a fraction of the |
different strategies may be |
strategies may be employed |
that the infiltrating miners |
fraction of the incoming |
of the incoming requests |
may be employed for |
the infiltrating miners are |
infiltrating miners are loyal |
be employed for choosing |
albeit a large fraction |
miners are loyal to |
employed for choosing the |
for choosing the best |
are loyal to the |
may often not be |
often not be sufficient |
loyal to the attacker |
tolerant mechanism for distributed |
mechanism for distributed file |
for distributed file cache |
as we shall show |
distributed file cache consistency |
choosing the best possible |
the best possible threshold |
the lfs provides an |
in proceedings of the |
proceedings of the twelth |
of the twelth symposium |
the twelth symposium on |
twelth symposium on operating |
symposium on operating systems |
once thresholds are varied |
some of the pool |
of the pool s |
lfs provides an applicationindependent |
on operating systems principles |
the pool s members |
provides an applicationindependent solution |
they are gossiped to |
pool s members may |
an applicationindependent solution that |
are gossiped to all |
s members may be |
applicationindependent solution that allows |
gossiped to all local |
members may be disloyal |
solution that allows the |
to all local auditors |
may be disloyal infiltrators |
that allows the system |
allows the system to |
the system to perform |
system to perform consistently |
who then enforce the |
to perform consistently across |
when sending disloyal miners |
then enforce the determined |
perform consistently across a |
sending disloyal miners to |
enforce the determined threshold |
consistently across a wide |
disloyal miners to perform |
across a wide range |
miners to perform block |
a wide range of |
wide range of datasets |
to perform block withholding |
expurge nodes from the |
nodes from the system |
perform block withholding at |
block withholding at other |
withholding at other pools |
the law of large |
law of large numbers |
global auditors are also |
auditors are also responsible |
are also responsible for |
an attacker takes a |
large scale server systems |
also responsible for verifying |
this experiment demonstrates that |
scale server systems process |
attacker takes a significant |
responsible for verifying accusations |
experiment demonstrates that sirp |
server systems process incredibly |
takes a significant risk |
for verifying accusations issued |
demonstrates that sirp is |
systems process incredibly large |
verifying accusations issued by |
accusations issued by local |
process incredibly large request |
incredibly large request loads |
issued by local auditors |
by local auditors against |
local auditors against particular |
auditors against particular nodes |
can use a loyal |
directing these to a |
use a loyal miner |
a loyal miner w |
these to a small |
and after validating the |
loyal miner w to |
miner w to infiltrate |
to a small fraction |
after validating the accusation |
that sirp is preferable |
sirp is preferable to |
is preferable to asynchronous |
preferable to asynchronous writeback |
expurging misbehaving nodes from |
misbehaving nodes from the |
nodes from the system |
a small fraction of |
w to infiltrate pool |
to asynchronous writeback at |
asynchronous writeback at low |
writeback at low bandwidth |
small fraction of the |
validation involves verifying that |
fraction of the total |
involves verifying that the |
and adds little additional |
adds little additional overhead |
verifying that the accused |
of the total number |
that the accused node |
the total number of |
the accused node s |
thinking the miner is |
total number of disks |
accused node s history |
the miner is loyal |
miner is loyal to |
is loyal to it |
the difference between asynchronous |
difference between asynchronous schemes |
between asynchronous schemes is |
asynchronous schemes is minimal |
might use it to |
node s history indeed |
the fraction that is |
use it to attack |
it to attack pool |
fraction that is in |
that is in high |
s history indeed indicates |
but any scheme improves |
any scheme improves over |
scheme improves over synchronous |
improves over synchronous writeback |
history indeed indicates that |
the miner m can |
indeed indicates that the |
can significantly raise the |
miner m can perform |
indicates that the node |
for the same reasons |
the same reasons that |
same reasons that it |
reasons that it improves |
that it improves performance |
m can perform honest |
that the node is |
significantly raise the probability |
can perform honest mining |
the node is sending |
node is sending less |
raise the probability of |
perform honest mining for |
honest mining for pool |
is sending less data |
the probability of error |
probability of error and |
of error and failure |
asynchronous writeback reduces staleness |
sending less data than |
less data than the |
data than the current |
rather than withhold its |
than withhold its blocks |
the fact that the |
than the current threshold |
and sirp makes it |
sirp makes it an |
makes it an acceptable |
it an acceptable choice |
an acceptable choice at |
acceptable choice at low |
choice at low bandwidth |
expurging a node involves |
and not return any |
fact that the disks |
a node involves informing |
not return any revenue |
that the disks used |
node involves informing the |
return any revenue to |
the disks used in |
involves informing the nodes |
any revenue to pool |
disks used in these |
informing the nodes immediate |
used in these contexts |
the nodes immediate neighbors |
in these contexts are |
nodes immediate neighbors of |
these contexts are typically |
immediate neighbors of its |
contexts are typically low |
neighbors of its status |
of its status and |
its status and forcing |
it will take its |
status and forcing the |
will take its share |
end with relatively weak |
and forcing the removal |
take its share of |
with relatively weak reliability |
forcing the removal of |
its share of pool |
relatively weak reliability guarantees |
the removal of the |
removal of the node |
of the node from |
the node from the |
node from the overlay |
from the overlay mesh |
which thinks the miner |
thinks the miner is |
as we shall see |
the miner is loyal |
the number of global |
miner is loyal to |
number of global auditors |
is loyal to it |
of global auditors may |
our solution alleviates this |
global auditors may vary |
solution alleviates this problem |
and deliver it back |
auditors may vary according |
alleviates this problem by |
deliver it back to |
it back to pool |
this problem by making |
may vary according to |
problem by making sure |
vary according to different |
by making sure that |
according to different parameters |
making sure that the |
sure that the live |
to avoid such a |
avoid such a risk |
that the live subset |
such as the size |
the live subset of |
as the size of |
live subset of disks |
a pool needs a |
the size of the |
subset of disks is |
pool needs a sufficient |
size of the system |
of disks is not |
needs a sufficient number |
disks is not constant |
a sufficient number of |
sufficient number of verified |
the use of more |
number of verified miners |
scale and performance in |
and performance in a |
performance in a distributed |
in a distributed file |
a distributed file system |
of verified miners miners |
verified miners miners that |
acm transactions on computer |
transactions on computer systems |
use of more global |
miners miners that it |
the rest of this |
of more global auditors |
miners that it knows |
rest of this paper |
more global auditors distributes |
that it knows to |
of this paper is |
global auditors distributes the |
it knows to be |
this paper is organized |
auditors distributes the load |
knows to be loyal |
paper is organized as |
distributes the load of |
is organized as follows |
the load of sampling |
load of sampling and |
of sampling and improves |
sampling and improves efficiency |
and improves efficiency in |
improves efficiency in reacting |
the optimal infiltration rate |
efficiency in reacting to |
optimal infiltration rate may |
in reacting to accusations |
describes some of the |
infiltration rate may be |
reacting to accusations against |
some of the solutions |
rate may be as |
to accusations against nodes |
of the solutions explored |
may be as high |
the solutions explored in |
be as high as |
solutions explored in the |
global auditors are also |
explored in the first |
auditors are also perfect |
in the first three |
are also perfect candidates |
the first three quadrants |
also perfect candidates to |
first three quadrants mentioned |
perfect candidates to perform |
three quadrants mentioned above |
candidates to perform membership |
of the pool size |
to perform membership tasks |
perform membership tasks such |
membership tasks such as |
tasks such as acting |
such as acting as |
but this is only |
as acting as entry |
presents and analyzes our |
and analyzes our solution |
acting as entry points |
this is only in |
as entry points to |
is only in extreme |
entry points to the |
points to the p |
only in extreme cases |
in extreme cases when |
extreme cases when pools |
discusses our evaluation methodology |
cases when pools are |
when pools are large |
our evaluation methodology and |
evaluation methodology and results |
since they are required |
for practical pool sizes |
they are required to |
we conclude in section |
are required to have |
required to have full |
to have full membership |
have full membership knowledge |
full membership knowledge of |
membership knowledge of the |
a pool may need |
knowledge of the system |
pool may need up |
of the system for |
may need up to |
the system for performing |
system for performing their |
for performing their auditing |
performing their auditing roles |
based solutions the concept |
solutions the concept of |
the concept of a |
concept of a memory |
of a memory hierarchy |
a memory hierarchy arose |
of its mining power |
global auditing monitors the |
memory hierarchy arose as |
its mining power for |
auditing monitors the global |
hierarchy arose as a |
mining power for infiltration |
monitors the global health |
arose as a result |
the global health of |
as a result of |
global health of the |
a result of the |
health of the system |
result of the natural |
of the system to |
of the natural tradeoff |
pools typically have loyal |
the system to identify |
the natural tradeoff between |
typically have loyal mining |
system to identify the |
natural tradeoff between memory |
have loyal mining power |
to identify the best |
tradeoff between memory speed |
loyal mining power either |
identify the best value |
between memory speed and |
mining power either run |
the best value for |
memory speed and memory |
power either run directly |
best value for the |
speed and memory cost |
either run directly by |
value for the minimum |
run directly by the |
for the minimum upload |
directly by the pool |
the minimum upload threshold |
by the pool owners |
minimum upload threshold at |
the pool owners or |
upload threshold at any |
pool owners or sold |
threshold at any time |
owners or sold as |
at any time during |
or sold as a |
any time during a |
sold as a service |
time during a streaming |
as a service but |
during a streaming session |
a service but run |
service but run on |
but run on the |
run on the pool |
on the pool owners |
that there exists a |
the pool owners hardware |
and makes final decisions |
there exists a similar |
makes final decisions regarding |
exists a similar tradeoff |
final decisions regarding punishment |
a similar tradeoff between |
decisions regarding punishment of |
similar tradeoff between performance |
regarding punishment of nodes |
tradeoff between performance and |
between performance and power |
performance disks and low |
performance disks such as |
disks such as laptop |
adaptive threshold strategies choosing |
such as laptop disks |
threshold strategies choosing an |
strategies choosing an upload |
choosing an upload threshold |
an upload threshold requires |
upload threshold requires care |
they explore the possibility |
mobile computing with the |
computing with the rover |
with the rover toolkit |
a low threshold may |
explore the possibility of |
low threshold may not |
the possibility of setting |
however the size of |
threshold may not be |
may not be sufficient |
possibility of setting up |
the size of this |
ieee transactions on computers |
not be sufficient to |
of setting up a |
size of this mining |
be sufficient to identify |
setting up a disk |
of this mining power |
sufficient to identify opportunistic |
up a disk hierarchy |
this mining power is |
to identify opportunistic nodes |
a disk hierarchy by |
mining power is considered |
disk hierarchy by using |
power is considered a |
hierarchy by using high |
is considered a trade |
while high thresholds may |
considered a trade secret |
high thresholds may incorrectly |
a trade secret and |
thresholds may incorrectly punish |
trade secret and is |
may incorrectly punish correct |
performance disks in conjunction |
secret and is not |
incorrectly punish correct nodes |
disks in conjunction with |
and is not published |
in conjunction with each |
conjunction with each other |
we considered different strategies |
considered different strategies for |
different strategies for the |
in a related vein |
strategies for the choice |
for the choice of |
countermeasures as in the |
the choice of the |
as in the case |
choice of the minimum |
in the case of |
of the minimum contribution |
the case of classical |
the minimum contribution t |
case of classical block |
minimum contribution t hreshold |
of classical block withholding |
contribution t hreshold used |
classical block withholding explained |
t hreshold used for |
block withholding explained in |
hreshold used for identifying |
withholding explained in section |
used for identifying misbehaving |
explained in section ii |
for identifying misbehaving nodes |
the simplest strategy sets |
simplest strategy sets a |
strategy sets a fixed |
sets a fixed threshold |
a pool might detect |
pool might detect that |
might detect that it |
detect that it is |
that it is being |
it is being attacked |
propose dynamic rotations per |
dynamic rotations per minute |
but cannot detect which |
cannot detect which of |
detect which of its |
which of its miners |
of its miners is |
its miners is the |
miners is the attacker |
therefore a pool cannot |
a pool cannot block |
pool cannot block or |
cannot block or punish |
block or punish withholding |
or punish withholding miners |
various techniques can be |
techniques can be used |
whereby disks can be |
can be used to |
disks can be run |
be used to encourage |
can be run at |
used to encourage miners |
be run at multiple |
to encourage miners to |
run at multiple speeds |
independent of the current |
encourage miners to submit |
miners to submit full |
to submit full blocks |
and performance in a |
performance in a wide |
of the current state |
at multiple speeds depending |
the current state of |
a pool can pay |
multiple speeds depending on |
current state of the |
pool can pay a |
in proceedings of the |
proceedings of the first |
of the first usenix |
can pay a bonus |
speeds depending on whether |
state of the system |
the first usenix conference |
first usenix conference on |
usenix conference on file |
conference on file and |
on file and storage |
file and storage technologies |
depending on whether power |
pay a bonus for |
any node contributing at |
on whether power or |
a bonus for submitting |
node contributing at a |
whether power or performance |
bonus for submitting a |
contributing at a rate |
power or performance takes |
for submitting a full |
at a rate of |
a rate of less |
submitting a full proof |
a full proof of |
full proof of work |
or performance takes precedence |
rate of less than |
this would increase the |
would increase the revenue |
increase the revenue of |
the revenue of the |
revenue of the miner |
of the miner that |
the miner that found |
this paper has described |
paper has described mafs |
miner that found a |
of the stream rate |
that found a block |
the stream rate would |
a new file system |
found a block while |
stream rate would be |
rate would be removed |
a block while reducing |
poses a significant engineering |
new file system for |
block while reducing the |
a significant engineering challenge |
file system for mobile |
while reducing the revenue |
one downside of using |
significant engineering challenge whose |
system for mobile clients |
reducing the revenue of |
downside of using a |
engineering challenge whose feasibility |
challenge whose feasibility is |
the revenue of the |
of using a fixed |
for mobile clients that |
whose feasibility is far |
revenue of the other |
using a fixed threshold |
mobile clients that is |
feasibility is far from |
of the other miners |
the other miners from |
other miners from this |
miners from this block |
a fixed threshold is |
clients that is tailored |
is far from obvious |
fixed threshold is that |
that is tailored for |
while the average revenue |
threshold is that opportunistic |
is tailored for wireless |
the average revenue of |
another approach is proposed |
is that opportunistic nodes |
tailored for wireless networks |
average revenue of each |
approach is proposed by |
that opportunistic nodes that |
for wireless networks by |
revenue of each miner |
is proposed by colarelli |
opportunistic nodes that learn |
wireless networks by incorporating |
networks by incorporating automatic |
by incorporating automatic adaptation |
incorporating automatic adaptation to |
automatic adaptation to the |
adaptation to the available |
to the available bandwidth |
of each miner would |
proposed by colarelli et |
nodes that learn the |
each miner would stay |
miner would stay the |
would stay the same |
that learn the threshold |
mafs differs from previous |
learn the threshold can |
differs from previous designs |
small miners will suffer |
the threshold can simply |
from previous designs in |
miners will suffer from |
threshold can simply contribute |
previous designs in making |
will suffer from higher |
can simply contribute at |
simply contribute at the |
suffer from higher variance |
from higher variance in |
contribute at the lowest |
using massive arrays of |
massive arrays of inexpensive |
higher variance in revenue |
at the lowest possible |
the lowest possible upload |
arrays of inexpensive disks |
designs in making use |
lowest possible upload factor |
in making use of |
making use of asynchronous |
use of asynchronous writeback |
of asynchronous writeback at |
asynchronous writeback at all |
writeback at all bandwidth |
at all bandwidth levels |
another approach is to |
approach is to introduce |
from the graphs in |
they propose the use |
is to introduce a |
the graphs in section |
rather than switching from |
propose the use of |
to introduce a joining |
than switching from synchronous |
the use of a |
introduce a joining fee |
switching from synchronous to |
use of a small |
it is clear that |
a joining fee by |
from synchronous to asynchronous |
synchronous to asynchronous writeback |
to asynchronous writeback when |
asynchronous writeback when bandwidth |
writeback when bandwidth is |
when bandwidth is insufficient |
joining fee by paying |
of a small number |
is clear that such |
fee by paying new |
a small number of |
clear that such a |
that such a stretagy |
by paying new miners |
small number of cache |
paying new miners less |
such a stretagy may |
rpc priorities and a |
priorities and a new |
and a new update |
a new update propagation |
new update propagation algorithm |
new miners less for |
a stretagy may disrupt |
number of cache disks |
miners less for their |
stretagy may disrupt the |
of cache disks in |
less for their work |
may disrupt the streaming |
cache disks in addition |
disks in addition to |
for their work until |
disrupt the streaming session |
reduce a client s |
a client s contention |
client s contention for |
s contention for wireless |
contention for wireless bandwidth |
in addition to the |
their work until they |
addition to the maid |
to the maid disks |
and permit a degree |
choosing a high threshold |
work until they have |
until they have established |
a high threshold is |
high threshold is not |
they have established a |
the data in these |
permit a degree of |
threshold is not a |
have established a reputation |
data in these cache |
a degree of consistency |
is not a practical |
established a reputation with |
in these cache disks |
degree of consistency that |
not a practical option |
a reputation with the |
these cache disks is |
of consistency that is |
reputation with the pool |
cache disks is updated |
consistency that is equivalent |
that is equivalent to |
is equivalent to instantaneous |
equivalent to instantaneous propagation |
to instantaneous propagation of |
instantaneous propagation of updates |
miners that seek flexibility |
disks is updated to |
since correct nodes would |
correct nodes would get |
nodes would get unfairly |
would get unfairly punished |
experiments demonstrate that these |
that seek flexibility may |
is updated to reflect |
demonstrate that these techniques |
seek flexibility may not |
to avoid this problem |
updated to reflect the |
to reflect the workload |
flexibility may not accept |
may not accept this |
reflect the workload that |
the workload that is |
we have explored adaptive |
not accept this policy |
accept this policy and |
workload that is currently |
have explored adaptive strategies |
that these techniques allow |
this policy and choose |
these techniques allow mafs |
one simple strategy starts |
techniques allow mafs to |
policy and choose another |
and choose another pool |
simple strategy starts with |
strategy starts with a |
allow mafs to achieve |
that is currently being |
is currently being accessed |
mafs to achieve performance |
starts with a minimum |
the pool can use |
pool can use a |
with a minimum threshold |
the maid disks can |
maid disks can then |
to achieve performance that |
can use a honeypot |
disks can then be |
can then be powered |
achieve performance that is |
then be powered down |
use a honeypot trap |
a honeypot trap by |
honeypot trap by sending |
performance that is at |
trap by sending the |
and need only be |
need only be spun |
that is at least |
by sending the miners |
only be spun up |
be spun up when |
is at least equal |
sending the miners tasks |
spun up when a |
up when a cache |
at least equal to |
the miners tasks which |
when a cache miss |
miners tasks which it |
a cache miss occurs |
tasks which it knows |
increasing it only if |
which it knows will |
it only if the |
it knows will result |
only if the system |
upon which their contents |
knows will result in |
if the system is |
which their contents are |
will result in a |
the system is compromised |
their contents are copied |
and in most cases |
result in a full |
contents are copied onto |
global auditors sample the |
in a full proof |
a full proof of |
in most cases superior |
are copied onto the |
auditors sample the system |
full proof of work |
copied onto the cache |
onto the cache disks |
most cases superior to |
sample the system to |
the system to identify |
system to identify the |
this approach has several |
approach has several of |
to identify the average |
identify the average download |
has several of the |
several of the weaknesses |
the average download factor |
cases superior to that |
of the weaknesses that |
and if this factor |
if a miner fails |
a miner fails to |
the weaknesses that memory |
weaknesses that memory caches |
if this factor is |
this factor is lower |
factor is lower than |
superior to that achievable |
miner fails to submit |
that memory caches suffer |
to that achievable by |
fails to submit the |
that achievable by conventional |
to submit the full |
only on a larger |
on a larger scale |
submit the full proof |
achievable by conventional file |
the full proof of |
full proof of work |
proof of work it |
if the cache disks |
by conventional file system |
conventional file system designs |
file system designs that |
once the download factor |
the cache disks are |
system designs that switch |
designs that switch between |
that switch between lowand |
switch between lowand high |
of work it is |
the download factor reaches |
cache disks are insufficient |
work it is tagged |
download factor reaches a |
factor reaches a satisfactory |
reaches a satisfactory level |
it is tagged as |
is tagged as an |
tagged as an attacker |
a satisfactory level again |
bandwidth modes according to |
modes according to thresholds |
disks are insufficient to |
to prevent the attacker |
are insufficient to store |
the threshold may be |
prevent the attacker from |
insufficient to store the |
to store the entire |
threshold may be reduced |
the attacker from learning |
attacker from learning them |
store the entire working |
may be reduced back |
be reduced back to |
the entire working set |
the honeypot tasks have |
reduced back to its |
entire working set of |
working set of the |
honeypot tasks have to |
back to its initial |
to its initial value |
set of the current |
tasks have to be |
have to be regularly |
to be regularly refreshed |
mafs is therefore able |
of the current workload |
this stepwise approach allows |
is therefore able to |
stepwise approach allows the |
therefore able to make |
pools can also incorporate |
approach allows the system |
able to make efficient |
can also incorporate out |
with considerable latency penalties |
allows the system to |
to make efficient use |
also incorporate out of |
the system to catch |
make efficient use of |
incorporate out of band |
system to catch opportunistic |
efficient use of the |
the cache disks represent |
out of band mechanisms |
to catch opportunistic nodes |
use of the network |
cache disks represent a |
of band mechanisms to |
catch opportunistic nodes in |
of the network and |
the network and provide |
network and provide predictable |
and provide predictable file |
provide predictable file system |
predictable file system semantics |
opportunistic nodes in case |
disks represent a significant |
band mechanisms to deter |
nodes in case their |
represent a significant added |
mechanisms to deter attacks |
regardless of the available |
of the available bandwidth |
a significant added cost |
in case their presence |
significant added cost in |
such as verifying the |
case their presence starts |
added cost in themselves |
as verifying the identity |
their presence starts affecting |
verifying the identity of |
presence starts affecting the |
the identity of miners |
starts affecting the performance |
disk management solutions pinheiro |
identity of miners or |
affecting the performance of |
management solutions pinheiro and |
of miners or using |
the performance of the |
solutions pinheiro and bianchini |
miners or using trusted |
performance of the system |
or using trusted computing |
using trusted computing technologies |
while avoiding incorrect accusations |
avoiding incorrect accusations of |
incorrect accusations of correct |
accusations of correct nodes |
automated hoarding for mobile |
hoarding for mobile computers |
we also considered a |
suggest that if data |
also considered a second |
that if data is |
considered a second adaptive |
a second adaptive strategy |
that assure no block |
if data is laid |
in proceedings of the |
assure no block withholding |
data is laid out |
is laid out on |
no block withholding is |
block withholding is taking |
laid out on disks |
out on disks according |
withholding is taking place |
proceedings of the sixteenth |
of the sixteenth acm |
the sixteenth acm symposium |
sixteenth acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
on disks according to |
for computing the threshold |
this would require miners |
disks according to frequency |
computing the threshold based |
would require miners to |
according to frequency of |
the threshold based on |
require miners to use |
to frequency of access |
threshold based on periodically |
miners to use specialized |
based on periodically sampled |
to use specialized hardware |
on periodically sampled download |
use specialized hardware and |
with the most popular |
periodically sampled download and |
specialized hardware and software |
the most popular files |
sampled download and upload |
most popular files being |
download and upload factors |
an overhead miners may |
popular files being located |
overhead miners may not |
files being located in |
miners may not accept |
being located in one |
the average download factors |
located in one set |
average download factors once |
in one set of |
one set of disks |
download factors once again |
factors once again are |
once again are used |
there is no known |
again are used for |
is no known silver |
and the least popular |
are used for detecting |
no known silver bullet |
the least popular ones |
used for detecting whether |
least popular ones in |
for detecting whether the |
popular ones in another |
detecting whether the threshold |
all these techniques reduce |
whether the threshold should |
these techniques reduce the |
the threshold should be |
techniques reduce the pool |
then the latter set |
threshold should be varied |
reduce the pool s |
the latter set of |
should be varied or |
the pool s attractiveness |
latter set of disks |
be varied or not |
pool s attractiveness and |
set of disks could |
s attractiveness and deter |
of disks could be |
attractiveness and deter miners |
disks could be powered |
could be powered down |
be powered down to |
powered down to conserve |
down to conserve energy |
our initial threshold is |
initial threshold is set |
threshold is set to |
is set to null |
their scheme is called |
block withholding in practice |
scheme is called popular |
withholding in practice long |
is called popular data |
and the threshold is |
in practice long term |
called popular data concentration |
the threshold is chosen |
practice long term block |
threshold is chosen from |
long term block withholding |
is chosen from sampled |
term block withholding attacks |
block withholding attacks are |
chosen from sampled upload |
from sampled upload factors |
withholding attacks are difficult |
and they implement and |
exploiting weak connectivity for |
weak connectivity for mobile |
connectivity for mobile file |
for mobile file access |
they implement and evaluate |
attacks are difficult to |
if the system seems |
implement and evaluate a |
are difficult to hide |
the system seems to |
system seems to be |
and evaluate a prototype |
in proceedings of the |
since miners using an |
evaluate a prototype file |
seems to be in |
to be in a |
miners using an attacked |
a prototype file server |
prototype file server called |
be in a compromised |
using an attacked pool |
proceedings of the fifteenth |
file server called nomad |
server called nomad fs |
an attacked pool would |
attacked pool would notice |
in a compromised state |
of the fifteenth acm |
pool would notice the |
would notice the reduced |
which runs on top |
the collected upload factors |
notice the reduced revenue |
the reduced revenue density |
the fifteenth acm symposium |
fifteenth acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
runs on top of |
collected upload factors are |
on top of the |
such attacks are rarely |
upload factors are ordered |
top of the file |
attacks are rarely reported |
factors are ordered and |
of the file system |
are ordered and the |
the file system and |
ordered and the value |
file system and monitors |
and we can therefore |
and the value dividing |
system and monitors data |
we can therefore conclude |
the value dividing the |
and monitors data layout |
can therefore conclude that |
value dividing the lowest |
monitors data layout on |
therefore conclude that they |
data layout on disks |
conclude that they are |
that they are indeed |
they are indeed rare |
their findings are that |
percent is used as |
findings are that if |
is used as the |
a recent exception is |
are that if the |
that if the low |
recent exception is an |
used as the new |
exception is an attack |
as the new threshold |
is an attack on |
access disks are powered |
an attack on the |
disks are powered down |
attack on the eligius |
this approach relies on |
on the eligius pool |
approach relies on efficiently |
the eligius pool performed |
relies on efficiently sampling |
this results in a |
eligius pool performed in |
on efficiently sampling the |
results in a considerable |
pool performed in may |
efficiently sampling the system |
in a considerable performance |
performed in may and |
a considerable performance hit |
in may and june |
and on fact that |
on fact that if |
fact that if the |
that if the system |
they suggest instead that |
if the system s |
suggest instead that they |
the system s performance |
instead that they be |
system s performance is |
that they be run |
s performance is not |
they be run at |
performance is not satisfactory |
be run at low |
run at low speed |
while their idea is |
their idea is sound |
it is not clear |
percent of the nodes |
is not clear whether |
of the nodes are |
not clear whether this |
bandwidth network file system |
the nodes are opportunistic |
clear whether this scheme |
whether this scheme would |
this scheme would adapt |
scheme would adapt to |
would adapt to different |
adapt to different workloads |
in proceedings of the |
proceedings of the eighteenth |
of the eighteenth acm |
the eighteenth acm symposium |
eighteenth acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
evaluation in this section |
bitcoin before detecting the |
before detecting the attack |
we evaluate the performance |
propose another data layout |
at which point payouts |
evaluate the performance of |
another data layout management |
which point payouts to |
the performance of our |
data layout management scheme |
point payouts to the |
performance of our proposed |
layout management scheme to |
payouts to the attackers |
of our proposed auditing |
management scheme to optimize |
to the attackers were |
our proposed auditing strategy |
scheme to optimize disk |
the attackers were blocked |
proposed auditing strategy over |
to optimize disk access |
auditing strategy over the |
optimize disk access patterns |
strategy over the original |
the attackers continued the |
over the original streaming |
attackers continued the attack |
the original streaming protocol |
we built an event |
driven simulator and used |
simulator and used it |
and used it to |
used it to simulate |
it to simulate streaming |
to simulate streaming sessions |
simulate streaming sessions on |
more bitcoin before realizing |
their approach uses finer |
streaming sessions on networks |
bitcoin before realizing they |
sessions on networks with |
before realizing they were |
realizing they were not |
grained control over data |
they were not receiving |
control over data layout |
were not receiving their |
over data layout on |
not receiving their payout |
data layout on disk |
the reasons the attack |
tuning it on a |
it on a per |
reasons the attack was |
nodes and an average |
the attack was so |
and an average of |
attack was so easily |
was so easily subverted |
so easily subverted is |
easily subverted is the |
subverted is the limited |
applications are instrumented and |
is the limited efforts |
are instrumented and then |
the limited efforts of |
instrumented and then profiled |
limited efforts of the |
and then profiled to |
efforts of the attackers |
then profiled to obtain |
of the attackers to |
profiled to obtain array |
the attackers to hide |
the target streaming rate |
to obtain array access |
obtain array access sequences |
target streaming rate in |
attackers to hide themselves |
streaming rate in the |
rate in the experiments |
in the experiments was |
the experiments was fixed |
which their system then |
experiments was fixed to |
they have only used |
their system then uses |
have only used two |
system then uses to |
only used two payout |
then uses to determine |
used two payout addresses |
uses to determine optimal |
two payout addresses to |
to determine optimal disk |
payout addresses to collect |
determine optimal disk layouts |
addresses to collect their |
optimal disk layouts by |
to collect their payouts |
disk layouts by computing |
layouts by computing optimal |
by computing optimal stripe |
computing optimal stripe factor |
and all our experiments |
and so it was |
all our experiments were |
so it was possible |
our experiments were repeated |
it was possible for |
was possible for the |
possible for the alert |
for the alert pool |
the alert pool manager |
alert pool manager to |
pool manager to cluster |
manager to cluster the |
the wisdom of marrying |
managing update conflicts in |
confidence intervals were small |
wisdom of marrying the |
of marrying the disk |
to cluster the attacking |
update conflicts in bayou |
marrying the disk layout |
cluster the attacking miners |
and for simplicity are |
the disk layout to |
disk layout to the |
a weakly connected replicated |
weakly connected replicated storage |
the attacking miners and |
for simplicity are omitted |
layout to the application |
to the application seems |
the application seems questionable |
simplicity are omitted from |
are omitted from the |
omitted from the graphs |
connected replicated storage system |
attacking miners and obtain |
miners and obtain a |
and obtain a statistically |
obtain a statistically significant |
proposed by zhu et |
in proceedings of the |
a statistically significant proof |
the source of the |
proceedings of the fifteenth |
statistically significant proof of |
source of the stream |
of the fifteenth acm |
significant proof of their |
of the stream has |
the fifteenth acm symposium |
fifteenth acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
proof of their wrongdoing |
combines a number of |
a number of ideas |
the stream has an |
stream has an upload |
has an upload capacity |
an upload capacity of |
it is unknown whether |
upload capacity of four |
it assumes multispeed disks |
is unknown whether this |
capacity of four times |
unknown whether this was |
of four times the |
whether this was a |
four times the stream |
and computes online the |
this was a classical |
times the stream rate |
computes online the optimal |
was a classical block |
online the optimal speed |
a classical block withholding |
the optimal speed that |
classical block withholding attack |
optimal speed that each |
speed that each disk |
that each disk should |
each disk should run |
disk should run at |
with the goal of |
the goal of sabotage |
and is connected to |
to minimize speed transition |
minimize speed transition overheads |
or a more elaborate |
a more elaborate scheme |
disks maintain their speeds |
maintain their speeds for |
their speeds for a |
to verify the effectiveness |
speeds for a fixed |
verify the effectiveness of |
other nodes have enough |
the effectiveness of block |
nodes have enough download |
effectiveness of block withholding |
have enough download capacity |
of block withholding for |
enough download capacity to |
block withholding for profit |
download capacity to receive |
capacity to receive the |
to receive the stream |
they call this the |
call this the coarse |
and upload factor of |
hibernator includes a file |
includes a file server |
a file server that |
file server that sits |
server that sits on |
that sits on top |
sits on top of |
we defined an availability |
on top of the |
implemented an experimental bitcoin |
defined an availability window |
top of the file |
an experimental bitcoin test |
file system usage in |
system usage in windows |
usage in windows nt |
experimental bitcoin test network |
an availability window of |
of the file system |
bitcoin test network and |
the file system and |
test network and demonstrated |
file system and manipulates |
network and demonstrated the |
system and manipulates data |
and demonstrated the practicality |
and manipulates data layout |
seconds and an interest |
demonstrated the practicality of |
manipulates data layout to |
and an interest window |
an interest window of |
the practicality of the |
data layout to put |
layout to put the |
practicality of the attack |
in proceedings of the |
to put the most |
proceedings of the seventeenth |
to evaluate the quality |
evaluate the quality of |
the quality of each |
accessed data on the |
quality of each auditing |
of each auditing strategy |
data on the highest |
on the highest speed |
the highest speed disks |
bitcoin s health large |
of the seventeenth acm |
s health large pools |
we evaluate the average |
the authors address the |
health large pools hinder |
the seventeenth acm symposium |
seventeenth acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
authors address the issue |
large pools hinder bitcoin |
evaluate the average download |
address the issue of |
pools hinder bitcoin s |
the average download factors |
the issue of performance |
hinder bitcoin s distributed |
average download factors of |
issue of performance guarantees |
bitcoin s distributed nature |
download factors of correct |
of performance guarantees by |
s distributed nature as |
factors of correct nodes |
performance guarantees by stipulating |
distributed nature as they |
of correct nodes during |
guarantees by stipulating that |
nature as they put |
correct nodes during a |
by stipulating that if |
as they put a |
stipulating that if performance |
they put a lot |
that if performance drops |
put a lot of |
if performance drops below |
a lot of mining |
performance drops below some |
lot of mining power |
drops below some threshold |
of mining power in |
second time interval after |
mining power in the |
time interval after auditing |
power in the hands |
interval after auditing is |
then all disks are |
in the hands of |
after auditing is first |
all disks are spun |
the hands of a |
auditing is first applied |
disks are spun up |
hands of a few |
is first applied to |
are spun up to |
of a few pool |
a few pool managers |
spun up to their |
first applied to the |
up to their highest |
applied to the system |
to their highest speed |
this has been mostly |
has been mostly addressed |
been mostly addressed by |
mostly addressed by community |
addressed by community pressure |
caching solutions zhu et |
by community pressure on |
community pressure on miners |
pressure on miners to |
on miners to avoid |
miners to avoid forming |
to avoid forming large |
avoid forming large pools |
we considered that global |
considered that global auditors |
that global auditors collected |
global auditors collected information |
auditors collected information from |
observe that the storage |
that the storage cache |
the storage cache management |
storage cache management policy |
cache management policy is |
management policy is pivotal |
nodes between each interval |
policy is pivotal in |
between each interval of |
however such recommendations had |
is pivotal in determining |
such recommendations had only |
pivotal in determining the |
recommendations had only had |
in determining the sequence |
had only had limited |
determining the sequence of |
only had limited success |
the sequence of requests |
sequence of requests that |
of requests that access |
requests that access disks |
and mining is still |
notice that the sample |
mining is still dominated |
that the sample size |
is still dominated by |
the sample size does |
still dominated by a |
sample size does not |
cache management policies could |
dominated by a small |
size does not increase |
management policies could be |
by a small number |
does not increase with |
policies could be tailored |
a small number of |
not increase with the |
could be tailored to |
small number of large |
increase with the size |
be tailored to change |
number of large pools |
with the size of |
tailored to change the |
the size of the |
to change the average |
size of the system |
change the average idle |
as a characteristic example |
the average idle time |
average idle time between |
idle time between disk |
time between disk requests |
which is a positive |
in the period of |
is a positive aspect |
the period of november |
a positive aspect of |
thus providing more opportunities |
positive aspect of the |
providing more opportunities for |
aspect of the auditing |
more opportunities for reducing |
of the auditing approach |
opportunities for reducing disk |
for reducing disk energy |
reducing disk energy consumption |
cache policies that are |
policies that are aware |
that are aware of |
are aware of the |
aware of the underlying |
of the underlying disk |
the underlying disk management |
we discuss the costs |
underlying disk management schemes |
discuss the costs involved |
the costs involved in |
costs involved in collecting |
involved in collecting these |
in collecting these samples |
three pools generated over |
which disks are running |
disks are running at |
are running at which |
running at which speeds |
of the proofs of |
the proofs of work |
can make more intelligent |
make more intelligent replacement |
more intelligent replacement decisions |
the authors present both |
authors present both offline |
present both offline and |
both offline and online |
offline and online power |
aware cache replacement algorithms |
cache replacement algorithms to |
replacement algorithms to optimize |
algorithms to optimize read |
to optimize read accesses |
the fact that block |
fact that block withholding |
that block withholding attacks |
they also show through |
block withholding attacks are |
also show through experiments |
withholding attacks are rarely |
show through experiments the |
attacks are rarely observed |
through experiments the somewhat |
are rarely observed may |
experiments the somewhat obvious |
rarely observed may indicate |
the somewhat obvious fact |
observed may indicate that |
somewhat obvious fact that |
may indicate that the |
obvious fact that for |
indicate that the active |
fact that for write |
that the active pools |
that for write accesses |
the active pools have |
active pools have reached |
pools have reached an |
have reached an implicit |
reached an implicit or |
an implicit or explicit |
implicit or explicit agreement |
or explicit agreement not |
explicit agreement not to |
agreement not to attack |
back policies offer more |
not to attack one |
policies offer more opportunities |
to attack one another |
offer more opportunities to |
number of false positives |
more opportunities to save |
of false positives download |
opportunities to save power |
false positives download factor |
to save power than |
save power than write |
an attacked pool cannot |
attacked pool cannot detect |
pool cannot detect which |
cannot detect which of |
detect which of its |
which of its miners |
of its miners are |
its miners are attacking |
miners are attacking it |
in the context of |
let alone which pool |
the context of write |
alone which pool controls |
which pool controls the |
pool controls the miners |
at some point a |
some point a pool |
a very natural candidate |
point a pool might |
very natural candidate is |
natural candidate is the |
candidate is the log |
a pool might miscalculate |
pool might miscalculate and |
might miscalculate and decide |
miscalculate and decide to |
and decide to try |
decide to try and |
to try and increase |
try and increase its |
and increase its revenue |
one pool might be |
pool might be enough |
might be enough to |
be enough to break |
enough to break the |
to break the agreement |
possibly leading to a |
leading to a constant |
to a constant rate |
a constant rate of |
we now give a |
constant rate of attacks |
now give a brief |
rate of attacks among |
give a brief overview |
of attacks among pools |
a brief overview of |
attacks among pools and |
brief overview of the |
among pools and a |
overview of the log |
pools and a reduced |
and a reduced revenue |
structured file system before |
file system before describing |
system before describing the |
if open pools reach |
before describing the power |
open pools reach a |
pools reach a state |
reach a state where |
a state where their |
state where their revenue |
saving opportunity it represents |
where their revenue density |
their revenue density is |
revenue density is reduced |
density is reduced due |
is reduced due to |
reduced due to attacks |
miners will leave them |
will leave them in |
leave them in favor |
them in favor of |
in favor of other |
favor of other available |
of other available options |
miners of sufficient size |
of sufficient size can |
structured file system the |
file system the log |
sufficient size can mine |
size can mine solo |
smaller miners can form |
miners can form private |
can form private pools |
form private pools with |
private pools with closed |
pools with closed access |
was motivated by a |
motivated by a need |
by a need to |
limited to trusted participants |
a need to optimize |
need to optimize the |
to optimize the latency |
optimize the latency of |
the latency of write |
such a change may |
a change may be |
change may be in |
may be in favor |
be in favor of |
in favor of bitcoin |
favor of bitcoin as |
of bitcoin as a |
bitcoin as a whole |
writing a block of |
a block of data |
block of data to |
of data to a |
since they require such |
data to a seagate |
they require such intimate |
to a seagate barracuda |
require such intimate trust |
a seagate barracuda disk |
seagate barracuda disk costs |
barracuda disk costs about |
private pools are likely |
pools are likely to |
are likely to be |
likely to be smaller |
and form a fine |
form a fine grained |
a fine grained distribution |
fine grained distribution of |
grained distribution of mining |
distribution of mining power |
ms in seek time |
in seek time and |
of mining power with |
mining power with many |
power with many small |
with many small pools |
many small pools and |
small pools and solo |
pools and solo miners |
software defined networks and |
defined networks and gossip |
networks and gossip protocols |
and gossip protocols robert |
gossip protocols robert soule |
kb in transmission time |
protocols robert soule ken |
a pool may engage |
robert soule ken birman |
the key observation here |
pool may engage in |
soule ken birman nate |
key observation here is |
may engage in an |
ken birman nate foster |
observation here is that |
engage in an attack |
birman nate foster university |
here is that seek |
in an attack against |
nate foster university of |
is that seek time |
an attack against another |
foster university of lugano |
that seek time is |
attack against another pool |
against another pool not |
seek time is a |
university of lugano cornell |
another pool not to |
time is a large |
of lugano cornell university |
lugano cornell university cornell |
cornell university cornell university |
university cornell university the |
cornell university the performance |
university the performance of |
the performance of data |
pool not to increase |
is a large and |
not to increase its |
a large and constant |
to increase its absolute |
increase its absolute revenue |
large and constant term |
and constant term in |
constant term in latency |
term in latency computation |
center applications are critically |
applications are critically dependent |
are critically dependent on |
critically dependent on the |
to eliminate this term |
dependent on the underlying |
on the underlying network |
but rather to attract |
rather to attract miners |
the lfs replaces write |
to attract miners by |
lfs replaces write operations |
attract miners by temporarily |
replaces write operations by |
miners by temporarily increasing |
given the complexities associated |
the complexities associated with |
complexities associated with management |
write operations by append |
operations by append operations |
networks today typically provide |
today typically provide little |
typically provide little more |
provide little more than |
little more than best |
secondary storage is treated |
by temporarily increasing its |
storage is treated as |
temporarily increasing its revenue |
is treated as a |
treated as a large |
as a large append |
effort packet delivery between |
packet delivery between hosts |
increasing its revenue relative |
its revenue relative to |
only log and writes |
revenue relative to a |
log and writes always |
and writes always go |
relative to a competing |
to a competing pool |
writes always go to |
always go to the |
go to the log |
to the log head |
the emergence of software |
recent work has investigated |
work has investigated the |
has investigated the motivation |
seek time is thus |
time is thus eliminated |
investigated the motivation of |
the motivation of pools |
motivation of pools to |
of pools to utilize |
pools to utilize part |
and write latency becomes |
to utilize part of |
has created an opportunity |
write latency becomes purely |
utilize part of their |
created an opportunity to |
latency becomes purely a |
part of their resources |
an opportunity to build |
becomes purely a function |
of their resources towards |
their resources towards sabotage |
purely a function of |
a function of the |
resources towards sabotage attacks |
towards sabotage attacks against |
function of the disk |
of the disk bandwidth |
sabotage attacks against each |
attacks against each other |
opportunity to build more |
to build more dynamic |
how do reads in |
do reads in the |
reads in the lfs |
in the lfs work |
build more dynamic networks |
more dynamic networks that |
dynamic networks that can |
networks that can be |
that can be tailored |
can be tailored precisely |
be tailored precisely to |
quality of streaming when |
tailored precisely to the |
precisely to the needs |
to the needs of |
the needs of applications |
of streaming when applying |
in the same way |
streaming when applying the |
the same way as |
when applying the fixed |
same way as in |
applying the fixed threshold |
existing solutions for monitoring |
solutions for monitoring within |
for monitoring within sdns |
monitoring within sdns suffer |
within sdns suffer from |
sdns suffer from several |
suffer from several short |
way as in conventional |
the fixed threshold strategy |
as in conventional file |
in conventional file systems |
the model of those |
model of those works |
threshold is varied from |
either they are inaccurate |
of those works is |
those works is different |
works is different from |
due to eventual consistency |
to eventual consistency of |
eventual consistency of architecture |
is different from the |
and hence do not |
hence do not avoid |
do not avoid seek |
different from the pool |
from the pool game |
the pool game model |
pool game model in |
game model in two |
model in two major |
in two major ways |
two major ways a |
major ways a sabotage |
ways a sabotage attack |
a sabotage attack does |
the assumption is that |
sabotage attack does not |
assumption is that with |
attack does not transfer |
is that with good |
due to limitations of |
to limitations of current |
limitations of current hardware |
and the contribution rate |
does not transfer revenue |
that with good caching |
the contribution rate of |
not transfer revenue from |
with good caching mechanisms |
contribution rate of opportunistic |
transfer revenue from victim |
rate of opportunistic nodes |
revenue from victim to |
of opportunistic nodes is |
from victim to attacker |
reads will be a |
opportunistic nodes is varied |
will be a small |
nodes is varied from |
be a small fraction |
and migrating miners switch |
a small fraction of |
small fraction of disk |
migrating miners switch to |
miners switch to less |
fraction of disk accesses |
or too costly to |
too costly to be |
costly to be practical |
to be practical at |
be practical at scale |
as can be imagined |
switch to less attacked |
to less attacked pools |
due to reliance on |
to reliance on switch |
space reclamation is a |
changing pool sizes and |
reclamation is a tricky |
is a tricky problem |
pool sizes and hence |
sizes and hence revenues |
a tricky problem in |
tricky problem in log |
and hence revenues until |
hence revenues until convergence |
problem in log structured |
presents the average download |
reliance on switch forwarding |
on switch forwarding rules |
switch forwarding rules and |
forwarding rules and centralization |
the model is parametrized |
the average download factors |
in log structured file |
model is parametrized by |
average download factors across |
log structured file systems |
is parametrized by the |
download factors across all |
parametrized by the cost |
factors across all correct |
by the cost of |
across all correct nodes |
the cost of the |
cost of the attack |
of the attack and |
excellent solutions have been |
the attack and by |
solutions have been proposed |
we argue that gossip |
attack and by the |
have been proposed to |
been proposed to solve |
proposed to solve it |
argue that gossip protocols |
and by the mobility |
presents the number of |
and one such is |
by the mobility of |
the number of correct |
number of correct nodes |
one such is of |
the mobility of the |
mobility of the miners |
of correct nodes incorrectly |
such is of interest |
is of interest to |
of interest to us |
that gossip protocols offer |
correct nodes incorrectly punished |
and the analysis demonstrates |
the disk is divided |
the analysis demonstrates that |
disk is divided into |
is divided into large |
analysis demonstrates that when |
gossip protocols offer an |
protocols offer an ideal |
offer an ideal alternative |
an ideal alternative for |
ideal alternative for sdn |
alternative for sdn monitoring |
demonstrates that when considering |
divided into large log |
into large log segments |
that when considering only |
due to their scalability |
to their scalability and |
their scalability and resiliency |
once a log segment |
we consider the use |
when considering only sabotage |
a log segment gets |
log segment gets filled |
considering only sabotage attacks |
only sabotage attacks there |
consider the use of |
the use of fixed |
sabotage attacks there are |
attacks there are regions |
use of fixed thresholds |
a new log segment |
ignored the crucial monitoring |
there are regions where |
new log segment is |
the crucial monitoring component |
crucial monitoring component that |
monitoring component that aggregates |
component that aggregates network |
that aggregates network and |
aggregates network and application |
network and application state |
are regions where no |
we studied the effects |
log segment is allocated |
and sends the events |
sends the events to |
attack is the best |
is the best strategy |
the events to the |
events to the controller |
studied the effects of |
segment is allocated and |
the effects of using |
the miner s dilemma |
is allocated and the |
effects of using different |
of using different values |
miner s dilemma is |
allocated and the log |
and the log head |
using different values for |
s dilemma is therefore |
a complete system would |
complete system would have |
system would have a |
would have a closed |
have a closed loop |
different values for t |
dilemma is therefore not |
the log head moves |
is therefore not manifested |
log head moves to |
head moves to the |
moves to the new |
to the new segment |
therefore not manifested in |
not manifested in that |
manifested in that model |
continuously monitoring applications and |
monitoring applications and the |
applications and the network |
when some threshold of |
some threshold of a |
pool competition for miners |
and increasing it until |
threshold of a segment |
competition for miners is |
of a segment gets |
for miners is an |
a segment gets invalidated |
then adjusting sdn policies |
adjusting sdn policies to |
miners is an incentive |
its valid data is |
valid data is moved |
is an incentive in |
sdn policies to optimize |
policies to optimize the |
to optimize the use |
optimize the use of |
the use of resources |
data is moved to |
an incentive in and |
is moved to another |
incentive in and of |
moved to another segment |
in and of its |
and of its own |
of its own for |
its own for mutual |
own for mutual attacks |
replacing that segment s |
that segment s invalid |
segment s invalid data |
gossip protocols are an |
of the stream rate |
protocols are an ideal |
and a pool may |
are an ideal choice |
a pool may therefore |
an ideal choice for |
ideal choice for implementing |
and present a detailed |
and it is then |
it is then added |
pool may therefore choose |
present a detailed set |
choice for implementing a |
for implementing a wide |
implementing a wide range |
a wide range monitoring |
wide range monitoring tasks |
may therefore choose to |
a detailed set of |
is then added to |
therefore choose to perform |
detailed set of results |
with a gossip protocol |
then added to the |
choose to perform block |
set of results on |
added to the pool |
to perform block withholding |
of results on applying |
results on applying different |
to the pool of |
perform block withholding even |
each node exchanges information |
on applying different thresholds |
the pool of free |
block withholding even if |
node exchanges information with |
applying different thresholds to |
pool of free log |
withholding even if its |
exchanges information with a |
different thresholds to different |
thresholds to different scenarios |
even if its revenue |
information with a randomly |
with a randomly selected |
a randomly selected peer |
randomly selected peer at |
selected peer at periodic |
peer at periodic intervals |
if its revenue would |
of free log segments |
the ratio of opportunistic |
because it is based |
it is based on |
is based on periodic |
based on periodic peer |
ratio of opportunistic nodes |
its revenue would increase |
of opportunistic nodes is |
revenue would increase only |
opportunistic nodes is fixed |
this process results in |
would increase only after |
nodes is fixed to |
process results in a |
increase only after the |
results in a natural |
gossip s network load |
s network load tends |
network load tends to |
load tends to be |
tends to be well |
only after the next |
in a natural division |
after the next difficult |
a natural division of |
the next difficult adjustment |
natural division of allocated |
division of allocated segments |
but their contribution factor |
scaling linearly with system |
linearly with system size |
with system size and |
system size and not |
size and not prone |
and not prone to |
not prone to reactive |
prone to reactive feedback |
the two models are |
of allocated segments into |
two models are therefore |
allocated segments into stable |
models are therefore complimentary |
because peers are selected |
peers are selected randomly |
the analysis of their |
analysis of their combination |
of their combination is |
their combination is left |
combination is left for |
is left for future |
left for future work |
no single node is |
single node is indispensable |
consisting almost entirely of |
almost entirely of data |
entirely of data that |
of data that is |
data that is rarely |
that is rarely invalidated |
so tools built on |
tools built on gossip |
built on gossip are |
on gossip are extremely |
gossip are extremely tolerant |
are extremely tolerant to |
extremely tolerant to disruptions |
tolerant to disruptions and |
to disruptions and able |
disruptions and able to |
and able to rapidly |
able to rapidly recover |
to rapidly recover from |
rapidly recover from failures |
we assumed in our |
assumed in our analysis |
in our analysis that |
which need to be |
need to be constantly |
our analysis that pools |
although individual gossip protocols |
individual gossip protocols are |
gossip protocols are typically |
protocols are typically very |
are typically very simple |
to be constantly cleaned |
analysis that pools do |
that pools do not |
pools do not charge |
composing multiple protocols can |
do not charge fees |
multiple protocols can lead |
not charge fees from |
protocols can lead to |
can lead to complex |
lead to complex interactions |
to complex interactions with |
complex interactions with unpredictable |
interactions with unpredictable behavior |
charge fees from their |
we will see how |
nodes follow the protocol |
we designed the mica |
will see how this |
fees from their members |
see how this feature |
from their members since |
with a maximum contribution |
how this feature can |
their members since such |
a maximum contribution rate |
this feature can be |
members since such fees |
maximum contribution rate set |
contribution rate set to |
feature can be used |
since such fees are |
such fees are typically |
can be used to |
be used to save |
fees are typically nominal |
framework to address this |
to address this problem |
used to save power |
mica allows programmers to |
allows programmers to describe |
programmers to describe gossip |
to describe gossip protocols |
describe gossip protocols with |
gossip protocols with a |
protocols with a small |
of a pool s |
a pool s revenue |
and compose the protocols |
compose the protocols with |
the protocols with a |
protocols with a rich |
with a rich collection |
a rich collection of |
rich collection of operators |
collection of operators to |
of operators to create |
operators to create sophisticated |
to create sophisticated protocols |
create sophisticated protocols in |
sophisticated protocols in a |
protocols in a modular |
in a modular style |
we present the average |
saving opportunity we shall |
present the average download |
opportunity we shall now |
the average download rates |
the model can be |
we shall now argue |
mica ensures that the |
ensures that the composed |
that the composed protocols |
the composed protocols maintain |
composed protocols maintain strong |
model can be extended |
shall now argue that |
and the number of |
can be extended to |
now argue that there |
the number of correct |
be extended to include |
robustness and convergence guarantees |
number of correct nodes |
argue that there remains |
extended to include pools |
to include pools fees |
that there remains an |
of correct nodes mistakenly |
correct nodes mistakenly removed |
there remains an unexplored |
in our evaluation of |
our evaluation of mica |
remains an unexplored quadrant |
fees would add a |
nodes mistakenly removed from |
an unexplored quadrant in |
would add a friction |
mistakenly removed from the |
removed from the system |
unexplored quadrant in this |
add a friction element |
we have built monitoring |
have built monitoring tasks |
built monitoring tasks that |
monitoring tasks that maintain |
tasks that maintain a |
that maintain a predictable |
maintain a predictable performance |
quadrant in this solution |
in this solution space |
a friction element to |
friction element to the |
even when hundreds of |
element to the flow |
caches are used to |
are used to minimize |
to the flow of |
for each of these |
each of these configurations |
used to minimize accesses |
the flow of revenue |
when hundreds of separate |
hundreds of separate instances |
the threshold applied is |
to minimize accesses to |
minimize accesses to disk |
flow of revenue among |
threshold applied is presented |
applied is presented on |
of revenue among infiltrated |
of separate instances are |
separate instances are deployed |
instances are deployed on |
are deployed on the |
deployed on the same |
on the same machines |
good caching algorithms practically |
is presented on the |
revenue among infiltrated and |
caching algorithms practically eliminate |
presented on the x |
among infiltrated and infiltrating |
algorithms practically eliminate read |
infiltrated and infiltrating pools |
practically eliminate read accesses |
eliminate read accesses to |
read accesses to disk |
a control program reacts |
control program reacts to |
program reacts to network |
reacts to network events |
in the left graph |
would change to take |
and updates forwarding rules |
whether synchronous or not |
updates forwarding rules on |
forwarding rules on switches |
rules on switches to |
on switches to manage |
must still eventually access |
change to take into |
switches to manage packets |
as the threshold increases |
still eventually access the |
to take into account |
eventually access the disk |
building on this interface |
take into account a |
higher download averages are |
into account a pool |
download averages are observed |
account a pool fee |
a pool fee of |
pool fee of f |
fee of f pp |
of f pp ri |
since more opportunistic nodes |
disk access will be |
access will be write |
our work on merlin |
more opportunistic nodes are |
opportunistic nodes are detected |
nodes are detected and |
are detected and punished |
putting a disk management |
a disk management layer |
disk management layer on |
management layer on top |
layer on top of |
on top of the |
top of the file |
is novel among network |
novel among network programming |
among network programming languages |
network programming languages in |
programming languages in that |
languages in that it |
in that it determines |
that it determines allocations |
it determines allocations of |
determines allocations of limited |
allocations of limited network |
system to optimize data |
the number of nodes |
to optimize data layout |
wide resources such as |
resources such as bandwidth |
such as bandwidth and |
as bandwidth and paths |
optimize data layout for |
number of nodes incorrectly |
data layout for writes |
of nodes incorrectly accused |
we have used merlin |
layout for writes is |
nodes incorrectly accused also |
incorrectly accused also increases |
for writes is only |
writes is only halfway |
accused also increases with |
also increases with higher |
is only halfway to |
only halfway to the |
increases with higher thresholds |
have used merlin to |
halfway to the solution |
used merlin to improve |
merlin to improve the |
as observed in the |
observed in the right |
in the right graph |
to take this idea |
take this idea to |
this idea to its |
idea to its logical |
to its logical conclusion |
to improve the latency |
scenarios where opportunistic nodes |
where opportunistic nodes contribute |
opportunistic nodes contribute at |
nodes contribute at higher |
contribute at higher rates |
improve the latency of |
it is necessary to |
is necessary to rethink |
necessary to rethink the |
to rethink the file |
rethink the file the |
the file the disk |
the latency of hadoop |
latency of hadoop jobs |
of hadoop jobs running |
hadoop jobs running in |
jobs running in the |
running in the presence |
management policies described in |
in the presence of |
the presence of udp |
presence of udp background |
of udp background traffic |
policies described in the |
are less disruptive to |
described in the related |
less disruptive to the |
disruptive to the system |
in the related works |
or prioritize classes of |
prioritize classes of traffic |
classes of traffic used |
of traffic used for |
traffic used for state |
a pool with a |
the related works section |
but they also require |
pool with a fee |
related works section essentially |
machine replication in fault |
they also require higher |
with a fee of |
works section essentially attack |
also require higher thresholds |
a fee of f |
section essentially attack the |
require higher thresholds to |
fee of f is |
essentially attack the problem |
higher thresholds to be |
of f is a |
attack the problem by |
thresholds to be applied |
f is a less |
the problem by trying |
is a less attractive |
problem by trying to |
a less attractive target |
less attractive target for |
by trying to predict |
different thresholds yield best |
thresholds yield best results |
attractive target for block |
trying to predict in |
these experiments demonstrate that |
experiments demonstrate that an |
demonstrate that an sdn |
that an sdn framework |
yield best results under |
target for block withholding |
to predict in advance |
best results under different |
results under different scenarios |
predict in advance which |
with the correct information |
the correct information as |
correct information as input |
in advance which disk |
since the attacker s |
advance which disk any |
the attacker s revenue |
which disk any given |
disk any given access |
from the results presented |
attacker s revenue is |
s revenue is reduced |
any given access will |
the results presented in |
results presented in figure |
revenue is reduced by |
given access will go |
access will go to |
is reduced by f |
can provide automated network |
provide automated network management |
automated network management customized |
network management customized to |
management customized to the |
they optimize the data |
however it is also |
it is also less |
we concluded that the |
optimize the data layout |
customized to the needs |
to the needs of |
the needs of resident |
needs of resident distributed |
of resident distributed applications |
concluded that the best |
the data layout on |
is also less attractive |
that the best fixed |
data layout on disks |
also less attractive for |
less attractive for miners |
the best fixed threshold |
layout on disks to |
while the merlin compiler |
the merlin compiler generates |
merlin compiler generates static |
compiler generates static network |
generates static network configurations |
best fixed threshold is |
on disks to ensure |
attractive for miners in |
fixed threshold is t |
disks to ensure that |
merlin uses a small |
for miners in general |
to ensure that accesses |
ensure that accesses are |
runtime component to allow |
component to allow for |
to allow for dynamic |
trading off the two |
allow for dynamic adaptation |
that accesses are localized |
off the two for |
accesses are localized to |
the two for best |
are localized to some |
two for best protection |
localized to some fraction |
based approach allows this |
approach allows this adaptation |
allows this adaptation to |
this adaptation to happen |
adaptation to happen safely |
to some fraction of |
providing the best compromise |
for best protection is |
some fraction of the |
fraction of the disks |
by providing policy language |
providing policy language constructs |
policy language constructs that |
language constructs that can |
constructs that can be |
that can be automatically |
can be automatically verified |
the best compromise in |
best protection is left |
so that only these |
best compromise in terms |
protection is left for |
is left for future |
left for future work |
compromise in terms of |
implicit in the design |
in the design of |
the design of this |
design of this runtime |
of this runtime component |
that only these need |
as part of the |
in terms of performance |
only these need be |
part of the treatment |
of the treatment of |
terms of performance and |
these need be powered |
need be powered up |
the treatment of the |
of performance and false |
performance and false positives |
treatment of the miner |
and sdn networks in |
sdn networks in general |
and false positives across |
false positives across all |
these are all probabilistic |
positives across all scenarios |
is the notion that |
are all probabilistic models |
the notion that network |
notion that network events |
that network events are |
r elated w ork |
a new access has |
elated w ork a |
network events are generated |
new access has some |
we compare all three |
compare all three strategies |
the block withholding attack |
events are generated in |
access has some probability |
all three strategies proposed |
block withholding attack the |
are generated in response |
has some probability of |
three strategies proposed in |
withholding attack the danger |
generated in response to |
some probability of not |
strategies proposed in subsection |
attack the danger of |
in response to the |
probability of not fitting |
the danger of a |
response to the situational |
of not fitting this |
danger of a block |
of a block withholding |
not fitting this model |
fitting this model and |
against each other and |
to the situational status |
the situational status culled |
situational status culled from |
status culled from a |
culled from a wide |
from a wide range |
a wide range of |
wide range of sources |
this model and needing |
each other and against |
a block withholding attack |
model and needing to |
other and against a |
block withholding attack is |
and needing to access |
and against a configuration |
withholding attack is as |
needing to access a |
to access a powered |
attack is as old |
against a configuration with |
is as old as |
a configuration with no |
as old as bitcoin |
configuration with no auditing |
old as bitcoin pools |
the attack was described |
attack was described by |
was described by rosenfeld |
packet and drop rates |
disk layout becomes tied |
layout becomes tied to |
becomes tied to particular |
tied to particular applications |
two applications that have |
applications that have completely |
that have completely different |
have completely different access |
for the fixed threshold |
completely different access patterns |
the fixed threshold strategy |
different access patterns might |
fixed threshold strategy and |
access patterns might require |
threshold strategy and as |
patterns might require completely |
strategy and as the |
might require completely different |
and as the initial |
require completely different data |
as the initial threshold |
completely different data layouts |
the initial threshold in |
different data layouts on |
initial threshold in the |
data layouts on disk |
threshold in the stepwise |
as pools were becoming |
layouts on disk leading |
in the stepwise adaptive |
pools were becoming a |
on disk leading to |
the stepwise adaptive strategy |
were becoming a dominant |
disk leading to conflicts |
becoming a dominant player |
leading to conflicts that |
a dominant player in |
to conflicts that reduce |
we summarize the three |
dominant player in the |
conflicts that reduce possible |
that reduce possible powersavings |
player in the bitcoin |
in the bitcoin world |
summarize the three strategies |
the three strategies in |
three strategies in table |
since all writes in |
all writes in an |
the paper described the |
writes in an lfs |
paper described the standard |
in an lfs are |
described the standard attack |
an lfs are to |
we simulated sessions where |
lfs are to the |
are to the log |
to the log head |
used by a miner |
user preferences for a |
preferences for a particular |
for a particular network |
by a miner to |
we know in advance |
a miner to sabotage |
know in advance which |
miner to sabotage a |
of the nodes were |
in advance which disk |
to sabotage a pool |
the nodes were opportunistic |
advance which disk they |
sabotage a pool at |
nodes were opportunistic and |
which disk they will |
disk they will access |
were opportunistic and with |
a pool at the |
opportunistic and with varying |
pool at the cost |
and with varying ratios |
this gives us the |
at the cost of |
with varying ratios of |
gives us the perfect |
the cost of reducing |
varying ratios of contribution |
us the perfect prediction |
cost of reducing its |
the perfect prediction mechanism |
of reducing its own |
reducing its own revenue |
at least for writeaccesses |
a more general view |
more general view of |
general view of fairness |
view of fairness in |
the contribution rate of |
of fairness in proof |
contribution rate of opportunistic |
fairness in proof of |
in proof of work |
this prediction mechanism is |
rate of opportunistic nodes |
of opportunistic nodes is |
proof of work schemes |
prediction mechanism is also |
mechanism is also entirely |
opportunistic nodes is varied |
of work schemes was |
work schemes was discussed |
is also entirely application |
nodes is varied from |
much of this information |
schemes was discussed in |
of this information must |
this information must be |
information must be created |
must be created and |
be created and updated |
created and updated dynamically |
if most accesses to |
most accesses to disks |
accesses to disks were |
to disks were writes |
existing sdn frameworks have |
sdn frameworks have largely |
frameworks have largely closing |
have largely closing the |
largely closing the loop |
we could power down |
all other nodes are |
other nodes are correct |
could power down every |
to accommodate the ever |
power down every disk |
down every disk but |
contributing at a maximum |
every disk but the |
at a maximum rate |
a maximum rate of |
disk but the one |
but the one that |
the one that the |
one that the log |
that the log head |
the log head resides |
log head resides on |
growing demands of cloud |
demands of cloud and |
of cloud and data |
cloud and data center |
and data center application |
in the context of |
the context of the |
context of the hashcash |
of the hashcash system |
networks will need to |
we present both the |
will need to become |
need to become more |
to become more flexible |
become more flexible and |
more flexible and dynamic |
present both the average |
is an ideal case |
an ideal case scenario |
both the average and |
as networks continue to |
networks continue to grow |
continue to grow in |
our view is that |
to grow in complexity |
the average and the |
average and the minimum |
early work did not |
and the minimum download |
it will become increasingly |
work did not address |
with a good caching |
the minimum download factors |
minimum download factors across |
did not address the |
a good caching algorithm |
will become increasingly difficult |
download factors across all |
not address the possibility |
become increasingly difficult for |
factors across all correct |
address the possibility of |
increasingly difficult for network |
across all correct nodes |
aware caching algorithms described |
the possibility of pools |
difficult for network operators |
all correct nodes in |
caching algorithms described in |
possibility of pools infiltrating |
of pools infiltrating other |
correct nodes in the |
algorithms described in the |
for network operators to |
pools infiltrating other pools |
nodes in the system |
described in the related |
in the related works |
infiltrating other pools for |
other pools for block |
pools for block withholding |
network operators to provide |
the related works section |
as the contribution rate |
the contribution rate of |
related works section are |
works section are good |
contribution rate of opportunistic |
rate of opportunistic nodes |
section are good candidates |
operators to provide this |
of opportunistic nodes increases |
to provide this flexibility |
provide this flexibility without |
this flexibility without the |
flexibility without the support |
without the support of |
the download factors are |
download factors are expected |
reads to disk can |
to disk can be |
disk can be minimized |
the support of proper |
support of proper tools |
of proper tools and |
proper tools and infrastructure |
factors are expected to |
and only a small |
are expected to increase |
experimentally demonstrate that block |
only a small fraction |
demonstrate that block withholding |
a small fraction of |
that block withholding can |
which is clear from |
small fraction of the |
provide both the control |
is clear from the |
block withholding can increase |
fraction of the disks |
both the control and |
clear from the curves |
from the curves presented |
of the disks need |
the control and monitoring |
withholding can increase the |
the disks need be |
control and monitoring components |
can increase the attacker |
strategy no auditing fixed |
disks need be powered |
and monitoring components necessary |
increase the attacker s |
the attacker s revenue |
need be powered on |
monitoring components necessary to |
no auditing fixed threshold |
be powered on in |
components necessary to automatically |
auditing fixed threshold stepwise |
they do not address |
powered on in order |
necessary to automatically adapt |
to automatically adapt the |
automatically adapt the network |
adapt the network to |
the network to the |
network to the needs |
to the needs of |
the needs of the |
needs of the applications |
on in order to |
fixed threshold stepwise adaptive |
do not address the |
in order to serve |
threshold stepwise adaptive percentile |
because both systems use |
both systems use a |
systems use a language |
not address the question |
based adaptive description fixed |
order to serve all |
address the question of |
the question of mutual |
to serve all writes |
adaptive description fixed t |
they have rigorous semantics |
have rigorous semantics that |
rigorous semantics that can |
semantics that can be |
that can be formally |
can be formally defined |
question of mutual attacks |
serve all writes as |
all writes as well |
writes as well as |
as well as reads |
they provide predictable operational |
provide predictable operational behavior |
what about the performance |
about the performance and |
the performance and power |
performance and power costs |
and power costs of |
power costs of log |
costs of log cleaning |
they allow for the |
have recently noted that |
allow for the rigorous |
recently noted that a |
for the rigorous expression |
noted that a pool |
the rigorous expression of |
al present some optimizations |
that a pool can |
rigorous expression of algorithms |
present some optimizations in |
a pool can increase |
expression of algorithms for |
of algorithms for monitoring |
algorithms for monitoring or |
for monitoring or managing |
monitoring or managing sdn |
or managing sdn networks |
pool can increase its |
if avg sampled download |
can increase its overall |
avg sampled download factor |
increase its overall revenue |
to hide the performance |
its overall revenue with |
hide the performance penalty |
overall revenue with block |
the performance penalty of |
revenue with block withholding |
performance penalty of log |
with block withholding if |
penalty of log cleaning |
block withholding if all |
of log cleaning even |
withholding if all other |
log cleaning even when |
if all other mining |
cleaning even when the |
all other mining is |
even when the workload |
other mining is performed |
when the workload allows |
mining is performed by |
the workload allows little |
is performed by honest |
performed by honest pools |
workload allows little idle |
allows little idle time |
we consider the general |
consider the general case |
the power costs of |
the general case where |
power costs of log |
general case where not |
costs of log cleaning |
case where not all |
of log cleaning are |
decrease t back to |
where not all mining |
log cleaning are a |
not all mining is |
cleaning are a little |
are a little more |
all mining is performed |
mining is performed through |
is performed through public |
performed through public pools |
a little more tricky |
little more tricky to |
more tricky to justify |
this work was supported |
and analyze situations where |
when avg download is |
analyze situations where pools |
avg download is satisfactory |
situations where pools can |
download is satisfactory again |
where pools can attack |
pools can attack one |
can attack one another |
by a grant from |
a grant from the |
grant from the darpa |
from the darpa mrc |
the darpa mrc program |
this is where the |
the discrepancy between the |
is where the natural |
discrepancy between the calculations |
where the natural division |
between the calculations of |
the natural division of |
natural division of segments |
division of segments into |
of segments into stable |
segments into stable and |
into stable and volatile |
stable and volatile ones |
and volatile ones that |
volatile ones that the |
ones that the log |
if avg sampled download |
that the log cleaning |
avg sampled download factor |
the log cleaning process |
log cleaning process results |
cleaning process results in |
and our results for |
our results for the |
results for the special |
for the special case |
the special case analyzed |
special case analyzed there |
case analyzed there can |
analyzed there can be |
there can be explained |
can be explained by |
be explained by the |
explained by the strong |
by the strong approximations |
after a significant fraction |
the strong approximations in |
a significant fraction of |
strong approximations in that |
significant fraction of segments |
approximations in that work |
fraction of segments on |
of segments on a |
t is chosen based |
is chosen based on |
chosen based on sampled |
based on sampled upload |
on sampled upload factors |
segments on a disk |
on a disk have |
we calculate exactly how |
a disk have been |
disk have been classified |
calculate exactly how infiltrating |
online measurement of large |
measurement of large traffic |
of large traffic aggregates |
large traffic aggregates on |
traffic aggregates on commodity |
aggregates on commodity switches |
exactly how infiltrating miners |
have been classified as |
how infiltrating miners reduce |
been classified as stable |
infiltrating miners reduce the |
miners reduce the revenue |
reduce the revenue density |
the revenue density of |
revenue density of the |
density of the infiltrated |
of the infiltrated pool |
we power the disk |
power the disk on |
temporary block withholding in |
the disk on and |
disk on and copy |
block withholding in the |
strategies used for defining |
on and copy the |
withholding in the block |
used for defining the |
and copy the stable |
in the block withholding |
for defining the minimum |
copy the stable segments |
the block withholding attack |
defining the minimum upload |
the stable segments to |
block withholding attack discussed |
the minimum upload threshold |
stable segments to a |
withholding attack discussed in |
minimum upload threshold t |
segments to a stable |
to a stable disk |
upload threshold t figure |
attack discussed in this |
discussed in this work |
in this work the |
this work the withheld |
volatile segments to a |
work the withheld blocks |
segments to a volatile |
shows that all strategies |
the withheld blocks are |
to a volatile disk |
that all strategies yield |
withheld blocks are never |
all strategies yield significantly |
blocks are never published |
disk is kept on |
strategies yield significantly better |
yield significantly better results |
significantly better results compared |
better results compared to |
results compared to an |
compared to an approach |
to an approach with |
an approach with no |
approach with no auditing |
blocks can be withheld |
and the entire disk |
can be withheld temporarily |
the entire disk is |
entire disk is freed |
while both adaptive strategies |
disk is freed for |
is freed for reuse |
not following the bitcoin |
both adaptive strategies yield |
following the bitcoin protocol |
adaptive strategies yield excellent |
strategies yield excellent download |
this is similar to |
yield excellent download rates |
is similar to the |
excellent download rates to |
to improve an attacker |
similar to the log |
download rates to correct |
improve an attacker s |
to the log cleaning |
rates to correct nodes |
an attacker s revenue |
the log cleaning scheme |
log cleaning scheme described |
cleaning scheme described in |
a compositional architecture for |
a miner or a |
miner or a pool |
the fixed threshold strategy |
compositional architecture for gossip |
architecture for gossip protocols |
fixed threshold strategy s |
or a pool can |
threshold strategy s performance |
a pool can perform |
strategy s performance is |
pool can perform a |
s performance is not |
can perform a selfish |
performance is not as |
perform a selfish mining |
is not as good |
which uses a hidden |
a selfish mining attack |
not as good when |
uses a hidden structure |
as good when opportunistic |
a hidden structure embedded |
good when opportunistic nodes |
hidden structure embedded in |
when opportunistic nodes are |
structure embedded in the |
opportunistic nodes are contributing |
embedded in the log |
nodes are contributing with |
in the log to |
the log to track |
log to track segment |
to track segment utilization |
cleaning an entire disk |
an entire disk amortizes |
entire disk amortizes the |
disk amortizes the cost |
amortizes the cost of |
with selfish mining the |
the cost of powering |
or slightly more kbps |
selfish mining the attacker |
cost of powering the |
of powering the disk |
mining the attacker increases |
powering the disk on |
the attacker increases its |
attacker increases its revenue |
increases its revenue by |
its revenue by temporarily |
number of accesses number |
revenue by temporarily withholding |
of accesses number of |
by temporarily withholding its |
accesses number of files |
temporarily withholding its blocks |
number of files touched |
withholding its blocks and |
of files touched number |
its blocks and publishing |
files touched number of |
blocks and publishing them |
touched number of bytes |
and publishing them in |
number of bytes touched |
at those rates opportunistic |
publishing them in response |
of bytes touched average |
those rates opportunistic nodes |
them in response to |
bytes touched average number |
rates opportunistic nodes are |
in response to block |
touched average number of |
opportunistic nodes are harmful |
nodes are harmful to |
are harmful to the |
harmful to the system |
average number of bytes |
response to block publication |
to block publication by |
block publication by other |
publication by other pools |
yet the fixed threshold |
the fixed threshold of |
by other pools and |
other pools and miners |
this attack is independent |
attack is independent of |
is independent of the |
independent of the block |
of the block withholding |
is not able to |
the block withholding attack |
not able to detect |
able to detect them |
block withholding attack we |
managing the network with |
the network with merlin |
withholding attack we discuss |
attack we discuss here |
we discuss here and |
discuss here and the |
here and the two |
and the two can |
the two can be |
two can be performed |
can be performed in |
be performed in concert |
an attacker can also |
attacker can also perform |
can also perform a |
also perform a double |
perform a double spending |
we consider a scenario |
a double spending attack |
consider a scenario where |
double spending attack as |
a scenario where opportunistic |
spending attack as follows |
scenario where opportunistic nodes |
where opportunistic nodes contribute |
opportunistic nodes contribute with |
nodes contribute with different |
contribute with different rates |
we varied the percentage |
varied the percentage of |
the percentage of opportunistic |
percentage of opportunistic nodes |
of opportunistic nodes in |
opportunistic nodes in the |
nodes in the system |
in the system from |
he intentionally generates two |
intentionally generates two conflicting |
generates two conflicting transactions |
places one in a |
one in a block |
in a block it |
a block it withholds |
and publishes the other |
publishes the other transaction |
and evenly assigned them |
evenly assigned them different |
assigned them different contribution |
them different contribution rates |
after the recipient sees |
based simulator of a |
the recipient sees the |
simulator of a log |
recipient sees the published |
the graphs present the |
sees the published transaction |
graphs present the average |
present the average and |
the average and minimum |
average and minimum download |
given a trace of |
the attacker publishes the |
and minimum download rates |
a trace of read |
attacker publishes the withheld |
minimum download rates for |
trace of read and |
publishes the withheld block |
download rates for these |
of read and write |
the withheld block to |
rates for these scenarios |
read and write requests |
withheld block to revoke |
block to revoke the |
to revoke the former |
revoke the former transaction |
logsim returns the observed |
returns the observed access |
the observed access latencies |
this attack is performed |
a language for provisioning |
language for provisioning network |
for provisioning network resources |
no auditing performs significantly |
attack is performed by |
auditing performs significantly worse |
is performed by miners |
performs significantly worse than |
performed by miners or |
significantly worse than any |
by miners or pools |
worse than any of |
miners or pools against |
than any of the |
or pools against service |
any of the proposed |
pools against service providers |
of the proposed strategies |
against service providers that |
service providers that accept |
providers that accept bitcoin |
for the chosen set |
the chosen set of |
chosen set of configuration |
set of configuration parameters |
and it not directly |
it not directly related |
not directly related to |
the stepwise adaptive approach |
directly related to this |
stepwise adaptive approach yields |
related to this work |
adaptive approach yields the |
world traces for our |
approach yields the best |
traces for our simulations |
yields the best results |
for our simulations from |
the best results when |
our simulations from a |
block withholding defense most |
best results when large |
simulations from a web |
withholding defense most crypto |
results when large percentages |
when large percentages of |
large percentages of opportunistic |
percentages of opportunistic nodes |
server that serves images |
currencies use a proof |
of opportunistic nodes are |
that serves images from |
serves images from a |
images from a database |
opportunistic nodes are present |
nodes are present in |
are present in the |
present in the system |
work architecture similar to |
architecture similar to bitcoin |
it is also simpler |
is also simpler than |
also simpler than the |
simpler than the percentile |
software defined traffic measurement |
defined traffic measurement with |
traffic measurement with opensketch |
where finding proof of |
finding proof of work |
proof of work is |
of work is the |
work is the result |
is the result of |
since it is based |
the result of solution |
it is based only |
result of solution guessing |
is based only on |
of solution guessing and |
based only on samples |
solution guessing and checking |
only on samples of |
describes the characteristics of |
on samples of the |
the characteristics of a |
samples of the download |
characteristics of a sample |
of a sample trace |
of the download rates |
all of the algorithms |
the download rates of |
of the algorithms we |
download rates of nodes |
the algorithms we are |
while a true evaluation |
algorithms we are aware |
a true evaluation of |
we are aware of |
in both sets of |
true evaluation of the |
are aware of are |
both sets of experiments |
evaluation of the feasibility |
aware of are susceptible |
of the feasibility and |
of are susceptible to |
the feasibility and efficacy |
are susceptible to the |
the number of false |
feasibility and efficacy of |
susceptible to the block |
number of false positives |
and efficacy of our |
to the block withholding |
of false positives was |
efficacy of our solution |
the block withholding attack |
false positives was practically |
of our solution can |
positives was practically null |
our solution can only |
was practically null under |
solution can only be |
as in all of |
practically null under all |
can only be achieved |
in all of them |
null under all three |
only be achieved through |
all of them the |
under all three strategies |
be achieved through an |
of them the miner |
all three strategies considered |
achieved through an actual |
them the miner can |
through an actual implementation |
the miner can check |
at most one in |
miner can check whether |
most one in some |
one in some cases |
can check whether she |
simulation provides an elegant |
check whether she found |
provides an elegant way |
whether she found a |
an elegant way to |
she found a full |
elegant way to identify |
found a full or |
way to identify and |
a full or a |
to identify and explore |
full or a partial |
identify and explore some |
and explore some of |
or a partial proof |
explore some of the |
some of the cost |
a partial proof of |
partial proof of work |
benefit tradeoffs in a |
tradeoffs in a scaled |
prominent examples are litecoin |
auditing costs the overheads |
down version of our |
version of our system |
costs the overheads imposed |
the overheads imposed by |
overheads imposed by auditing |
imposed by auditing are |
by auditing are an |
the mechanism we simulate |
auditing are an important |
mechanism we simulate is |
are an important consideration |
we simulate is as |
simulate is as follows |
which we address in |
we address in this |
address in this subsection |
most of the work |
of the work of |
the work of auditing |
work of auditing is |
disks are assumed to |
of auditing is performed |
are assumed to begin |
auditing is performed by |
assumed to begin in |
is performed by local |
to begin in the |
performed by local auditors |
begin in the on |
in the on state |
which are executed on |
are executed on the |
executed on the user |
it is possible to |
and an access count |
on the user nodes |
is possible to use |
possible to use an |
to use an alternative |
use an alternative proof |
the overhead is constant |
an alternative proof of |
is maintained for each |
alternative proof of work |
maintained for each disk |
proof of work mechanism |
independent of the size |
of work mechanism in |
of the size of |
work mechanism in which |
the user specifies the |
the size of the |
mechanism in which miners |
user specifies the maximum |
size of the system |
in which miners would |
specifies the maximum percentage |
which miners would not |
miners would not be |
and is not significant |
would not be able |
not be able to |
be able to distinguish |
able to distinguish partial |
to distinguish partial from |
since nodes only exchange |
of disks that are |
distinguish partial from full |
nodes only exchange a |
disks that are kept |
partial from full proofs |
only exchange a small |
that are kept powered |
from full proofs of |
exchange a small amount |
are kept powered on |
full proofs of work |
a small amount of |
small amount of accounting |
amount of accounting data |
of accounting data at |
accounting data at pre |
defined intervals of time |
a disk check process |
disk check process scans |
check process scans the |
if we consider a |
process scans the access |
we consider a packet |
consider a packet rate |
a packet rate of |
the one issue that |
scans the access count |
one issue that unites |
the access count for |
access count for each |
issue that unites almost |
count for each disk |
for each disk and |
each disk and powers |
disk and powers down |
and powers down all |
powers down all but |
down all but the |
all but the most |
that unites almost all |
such a solution could |
unites almost all approaches |
a solution could reduce |
solution could reduce or |
almost all approaches to |
could reduce or remove |
seconds the maximum number |
all approaches to distributed |
reduce or remove the |
the maximum number of |
as well as any |
approaches to distributed computing |
or remove the danger |
maximum number of packets |
well as any disk |
to distributed computing is |
remove the danger of |
number of packets received |
as any disk which |
distributed computing is the |
the danger of block |
of packets received and |
any disk which does |
disk which does not |
danger of block withholding |
packets received and sent |
received and sent by |
which does not have |
computing is the need |
and sent by each |
sent by each node |
by each node is |
does not have at |
not have at least |
have at least t |
at least t access |
least t access count |
is the need to |
making such a change |
the need to know |
such a change may |
a change may not |
need to know whether |
change may not be |
to know whether certain |
may not be in |
not be in the |
be in the interest |
for each packet sent |
in the interest of |
the interest of the |
interest of the community |
miss results in an |
results in an access |
each packet sent or |
packet sent or received |
in an access to |
an access to a |
access to a powered |
know whether certain components |
or even its potential |
whether certain components in |
certain components in the |
components in the system |
in the system have |
could lead to a |
then this disk is |
this disk is spun |
disk is spun up |
the system have failed |
system have failed or |
have failed or are |
failed or are otherwise |
or are otherwise unavailable |
the history needs to |
to remain powered on |
lead to a reduction |
history needs to indicate |
remain powered on until |
to a reduction of |
a reduction of pool |
reduction of pool sizes |
powered on until the |
on until the next |
needs to indicate which |
when designing and building |
as explained in section |
explained in section ix |
until the next disk |
the next disk check |
to indicate which neighbor |
indicate which neighbor sent |
which neighbor sent or |
designing and building systems |
neighbor sent or received |
sent or received the |
or received the packet |
and building systems that |
building systems that need |
systems that need to |
that need to function |
need to function at |
to function at a |
function at a global |
at a global scale |
and there is a |
decentralized pools although most |
bits to identify each |
to identify each neighbor |
pools although most pools |
there is a corresponding |
is a corresponding latency |
a corresponding latency penalty |
the history s size |
history s size adds |
s size adds up |
size adds up to |
failure management needs to |
although most pools use |
judicious choice of the |
management needs to be |
needs to be considered |
to be considered a |
be considered a fundamental |
considered a fundamental building |
a fundamental building block |
choice of the parameters |
most pools use a |
of the parameters m |
pools use a centralized |
use a centralized manager |
the parameters m and |
this paper describes the |
paper describes the development |
describes the development of |
a prominent exception is |
prominent exception is p |
parameters m and t |
the development of a |
development of a system |
m and t minimizes |
pool a distributed pool |
and t minimizes the |
a distributed pool architecture |
distributed pool architecture with |
t minimizes the probability |
minimizes the probability of |
pool architecture with no |
architecture with no central |
the probability of this |
this is not significant |
with no central manager |
probability of this occurrence |
independent failure management service |
is not significant compared |
not significant compared to |
significant compared to the |
compared to the amount |
to the amount of |
which allows systems and |
the amount of regular |
amount of regular data |
of regular data exchanged |
regular data exchanged in |
data exchanged in a |
exchanged in a streaming |
in a streaming session |
allows systems and applications |
systems and applications to |
and applications to incorporate |
applications to incorporate accurate |
to incorporate accurate detection |
incorporate accurate detection of |
accurate detection of failed |
detection of failed processes |
we also analyzed the |
but the question of |
also analyzed the costs |
the question of whether |
analyzed the costs of |
question of whether a |
the costs of the |
costs of the global |
of the global auditors |
of whether a pool |
without the need for |
methodology we have proposed |
whether a pool is |
the need for making |
need for making compromises |
for making compromises in |
making compromises in their |
compromises in their particular |
in their particular design |
a pool is run |
we have proposed the |
since they are dedicated |
pool is run by |
have proposed the use |
they are dedicated and |
is run by a |
proposed the use of |
are dedicated and external |
dedicated and external to |
and external to the |
the use of lfs |
use of lfs in |
run by a centralized |
external to the system |
with the advent of |
the advent of ubiquitous |
by a centralized manager |
of lfs in lieu |
the overhead imposed by |
a centralized manager or |
lfs in lieu of |
in lieu of ffs |
centralized manager or with |
overhead imposed by them |
manager or with a |
imposed by them is |
or with a decentralized |
it is becoming clear |
or other conventional file |
other conventional file systems |
with a decentralized architecture |
is becoming clear that |
by them is of |
them is of higher |
is of higher concern |
a decentralized architecture is |
becoming clear that the |
center scenarios to achieve |
decentralized architecture is almost |
global auditors main tasks |
scenarios to achieve power |
to achieve power conservation |
architecture is almost immaterial |
auditors main tasks consist |
clear that the systems |
that the systems that |
for this idea to |
is almost immaterial for |
almost immaterial for the |
main tasks consist of |
this idea to be |
idea to be accepted |
immaterial for the attack |
tasks consist of sampling |
the systems that are |
systems that are used |
two questions need to |
for the attack we |
the attack we describe |
consist of sampling the |
questions need to be |
need to be answered |
of sampling the system |
that are used today |
are used today in |
used today in local |
to be answered in |
sampling the system to |
be answered in the |
pool group can be |
the system to collect |
answered in the affirmative |
group can be infiltrated |
can not simply be |
system to collect download |
can be infiltrated and |
be infiltrated and attacked |
to collect download and |
collect download and upload |
download and upload rates |
and upload rates of |
upload rates of nodes |
not simply be employed |
simply be employed in |
be employed in their |
pool code can be |
and of occasionally disseminating |
of occasionally disseminating updates |
code can be changed |
does this new scheme |
this new scheme result |
occasionally disseminating updates to |
can be changed to |
be changed to support |
new scheme result in |
disseminating updates to the |
updates to the threshold |
changed to support attacks |
scheme result in significant |
result in significant power |
to the threshold value |
to support attacks against |
employed in their existing |
in their existing form |
their existing form or |
existing form or trivially |
form or trivially converted |
or trivially converted for |
trivially converted for wide |
in significant power savings |
support attacks against other |
the sample size remains |
attacks against other pools |
sample size remains fixed |
size remains fixed independent |
remains fixed independent of |
fixed independent of the |
independent of the size |
on the other hand |
of the size of |
the size of the |
size of the population |
whatever form such systems |
form such systems may |
such systems may take |
systems may take in |
may take in the |
take in the future |
pool can be used |
does this new scheme |
we ran simulations to |
can be used by |
this new scheme provide |
ran simulations to estimate |
simulations to estimate the |
to estimate the worst |
new scheme provide comparable |
scheme provide comparable performance |
be used by groups |
whether they are replicated |
case standard deviation of |
used by groups of |
by groups of miners |
provide comparable performance to |
standard deviation of the |
deviation of the download |
groups of miners to |
comparable performance to existing |
performance to existing schemes |
of the download rates |
of miners to easily |
miners to easily form |
the download rates across |
download rates across all |
rates across all nodes |
they are replicated databases |
are replicated databases of |
replicated databases of hyper |
to easily form closed |
the answers to these |
easily form closed pools |
answers to these questions |
to these questions must |
we estimate that a |
these questions must be |
estimate that a sample |
these do not accept |
questions must be largely |
that a sample size |
do not accept untrusted |
must be largely applicationindependent |
a sample size of |
view or virtual synchronous |
not accept untrusted miners |
or virtual synchronous groups |
and must apply to |
must apply to a |
and are therefore protected |
apply to a generic |
to a generic data |
a generic data center |
generic data center model |
nodes is sufficient to |
is sufficient to provide |
are therefore protected against |
therefore protected against block |
protected against block withholding |
virtual synchronous groups or |
synchronous groups or agents |
groups or agents employing |
or agents employing lazy |
agents employing lazy consistency |
employing lazy consistency schemes |
to address these questions |
c onclusion we explored |
one of the key |
onclusion we explored a |
of the key problems |
the key problems that |
key problems that needs |
problems that needs to |
that needs to be |
needs to be addressed |
independent of the population |
we present a simulator |
we explored a block |
of the population size |
is that of the |
that of the detection |
of the detection and |
the detection and handling |
detection and handling of |
and handling of faulty |
handling of faulty components |
explored a block withholding |
logsim consists of less |
such as the ones |
a block withholding attack |
consists of less than |
as the ones simulated |
block withholding attack among |
of less than a |
the ones simulated in |
ones simulated in this |
simulated in this work |
less than a thousand |
building distributed systems and |
withholding attack among bitcoin |
than a thousand lines |
a thousand lines of |
even a smaller number |
attack among bitcoin mining |
distributed systems and applications |
thousand lines of java |
a smaller number of |
among bitcoin mining pools |
systems and applications today |
lines of java code |
smaller number of samples |
bitcoin mining pools an |
and applications today is |
of java code and |
number of samples was |
mining pools an attack |
applications today is done |
java code and is |
of samples was found |
pools an attack that |
today is done using |
code and is a |
and is a single |
an attack that is |
is done using a |
samples was found to |
attack that is possible |
done using a variety |
was found to be |
that is possible in |
using a variety of |
found to be sufficient |
is possible in any |
possible in any similar |
to be sufficient to |
be sufficient to yield |
in any similar system |
a variety of systems |
we must turn off |
sufficient to yield satisfactory |
any similar system that |
similar system that rewards |
must turn off some |
to yield satisfactory results |
variety of systems ranging |
system that rewards for |
turn off some percentage |
off some percentage of |
that rewards for proof |
rewards for proof of |
for proof of work |
of systems ranging from |
some percentage of disks |
centralized costs are fixed |
systems ranging from the |
such systems are gaining |
systems are gaining popularity |
ranging from the bare |
percentage of disks in |
and provide a clear |
provide a clear advantage |
of disks in the |
disks in the storage |
in the storage system |
a clear advantage for |
clear advantage for using |
running most digital currencies |
most digital currencies and |
advantage for using auditing |
for using auditing against |
using auditing against tit |
from the bare bone |
digital currencies and related |
there are two opposing |
are two opposing forces |
currencies and related services |
the bare bone protocols |
bare bone protocols interfaces |
bone protocols interfaces like |
protocols interfaces like bsd |
we observe that no |
tat approaches in large |
interfaces like bsd sockets |
like bsd sockets and |
bsd sockets and the |
sockets and the tdi |
two opposing forces at |
opposing forces at play |
forces at play here |
attacks is not a |
is not a nash |
not a nash equilibrium |
to rpc based systems |
a large number of |
large number of powered |
rpc based systems such |
if none of the |
none of the other |
of the other pools |
the other pools attack |
on disks results in |
disks results in good |
heterogenous systems so far |
results in good performance |
systems so far we |
based systems such as |
a pool can increase |
so far we considered |
systems such as dce |
pool can increase its |
far we considered the |
such as dce and |
can increase its revenue |
but also low power |
also low power savings |
we considered the use |
increase its revenue by |
its revenue by attacking |
considered the use of |
on the other hand |
the use of auditing |
as dce and to |
revenue by attacking the |
by attacking the others |
dce and to more |
and to more advanced |
to more advanced distributed |
more advanced distributed support |
when two pools can |
use of auditing to |
advanced distributed support systems |
distributed support systems such |
support systems such as |
systems such as isis |
decreasing the number of |
the number of powered |
of auditing to enforce |
two pools can attack |
auditing to enforce node |
pools can attack each |
on disks incurs two |
can attack each other |
to enforce node contribution |
disks incurs two possible |
enforce node contribution in |
incurs two possible penalties |
they face a version |
node contribution in systems |
face a version of |
contribution in systems where |
a version of the |
in systems where all |
version of the prisoner |
systems where all nodes |
of the prisoner s |
where all nodes are |
the prisoner s dilemma |
all nodes are assumed |
nodes are assumed to |
are assumed to have |
assumed to have homogeneous |
to have homogeneous bandwidth |
have homogeneous bandwidth resources |
if one pool chooses |
one pool chooses to |
pool chooses to attack |
transitions consume power and |
enough to upload and |
consume power and thus |
the victim s revenue |
to upload and download |
power and thus counter |
victim s revenue is |
s revenue is reduced |
and thus counter the |
upload and download at |
thus counter the potential |
and download at a |
counter the potential savings |
and it can retaliate |
download at a rate |
the potential savings achieved |
it can retaliate by |
at a rate close |
potential savings achieved by |
can retaliate by attacking |
a rate close to |
savings achieved by powered |
retaliate by attacking and |
rate close to the |
by attacking and increase |
close to the stream |
attacking and increase its |
and increase its revenue |
to the stream rate |
after years of experience |
years of experience with |
of experience with building |
experience with building these |
with building these systems |
building these systems and |
these systems and applications |
to find the optimal |
pullbased streaming may be |
find the optimal percentage |
streaming may be extended |
at nash equilibrium both |
it is clear that |
the optimal percentage of |
may be extended to |
nash equilibrium both earn |
is clear that failure |
optimal percentage of disks |
be extended to heterogenous |
equilibrium both earn less |
clear that failure management |
percentage of disks to |
extended to heterogenous systems |
both earn less than |
earn less than they |
of disks to be |
to heterogenous systems by |
heterogenous systems by organizing |
less than they would |
disks to be powered |
to be powered down |
systems by organizing nodes |
than they would have |
they would have if |
by organizing nodes into |
organizing nodes into multiple |
would have if neither |
have if neither attacked |
we ran a set |
nodes into multiple groups |
that failure management is |
ran a set of |
failure management is not |
with multiple pools of |
a set of simulations |
management is not just |
is not just a |
not just a essential |
just a essential tool |
a essential tool for |
essential tool for group |
tool for group oriented |
for group oriented systems |
set of simulations on |
multiple pools of equal |
of simulations on logsim |
all which have built |
pools of equal size |
simulations on logsim and |
of equal size a |
on logsim and varied |
equal size a similar |
logsim and varied the |
size a similar situation |
and varied the number |
but that it is |
a similar situation arises |
varied the number of |
that it is a |
similar situation arises with |
the number of disks |
it is a fundamental |
situation arises with a |
number of disks that |
of disks that we |
arises with a symmetric |
no auditing fixed threshold |
disks that we kept |
with a symmetric equilibrium |
is a fundamental service |
auditing fixed threshold stepwise |
that we kept powered |
we kept powered up |
the fact that block |
a fundamental service that |
fixed threshold stepwise percentile |
kept powered up from |
fact that block withholding |
fundamental service that should |
powered up from none |
that block withholding is |
service that should be |
block withholding is not |
that should be placed |
withholding is not common |
should be placed among |
be placed among such |
placed among such established |
among such established basic |
such established basic services |
established basic services as |
basic services as naming |
is not common may |
avg download factor min |
not common may be |
download factor min download |
common may be explained |
factor min download factor |
may be explained by |
be explained by modeling |
explained by modeling the |
by modeling the attack |
modeling the attack decisions |
service brokerage and ipc |
the attack decisions as |
attack decisions as an |
decisions as an iterative |
as an iterative prisoner |
an iterative prisoner s |
iterative prisoner s dilemma |
this paper reports on |
paper reports on an |
reports on an ongoing |
on an ongoing research |
out of a total |
we argue that the |
of a total of |
an ongoing research effort |
argue that the situation |
ongoing research effort to |
that the situation is |
research effort to abstract |
the situation is unstable |
situation is unstable since |
effort to abstract the |
is unstable since the |
unstable since the attack |
since the attack can |
the attack can be |
attack can be done |
can be done anonymously |
no auditing fixed threshold |
auditing fixed threshold stepwise |
fixed threshold stepwise percentile |
to abstract the failure |
abstract the failure handling |
the failure handling strategies |
one pool may decide |
failure handling strategies from |
pool may decide to |
handling strategies from a |
may decide to increase |
strategies from a variety |
decide to increase its |
from a variety of |
to increase its revenue |
a variety of popular |
increase its revenue and |
its revenue and drag |
revenue and drag the |
and drag the others |
drag the others to |
the others to attack |
others to attack as |
to attack as well |
variety of popular distributed |
of popular distributed systems |
popular distributed systems and |
ending with a reduced |
with a reduced revenue |
a reduced revenue for |
reduced revenue for all |
distributed systems and to |
systems and to develop |
and to develop a |
the inferior revenue would |
inferior revenue would push |
revenue would push miners |
would push miners to |
push miners to join |
miners to join private |
to join private pools |
to develop a basic |
develop a basic failure |
disks were kept powered |
were kept powered up |
which can verify that |
a basic failure management |
can verify that their |
verify that their registered |
that their registered miners |
their registered miners do |
registered miners do not |
miners do not withhold |
do not withhold blocks |
basic failure management service |
failure management service that |
management service that can |
service that can be |
this would lead to |
would lead to smaller |
lead to smaller pools |
that can be used |
can be used by |
be used by any |
used by any distributed |
by any distributed system |
and so ultimately to |
any distributed system regardless |
so ultimately to a |
distributed system regardless of |
ultimately to a better |
to a better environment |
a better environment for |
better environment for bitcoin |
environment for bitcoin as |
for bitcoin as a |
bitcoin as a whole |
system regardless of the |
regardless of the purpose |
of the purpose of |
the purpose of that |
purpose of that system |
of that system or |
that system or the |
system or the techniques |
or the techniques used |
for their valuable advice |
the strategies employed by |
the author is grateful |
author is grateful to |
is grateful to ken |
grateful to ken birman |
strategies employed by this |
employed by this basic |
by this basic service |
this basic service are |
basic service are specifically |
service are specifically targeted |
are specifically targeted towards |
specifically targeted towards applications |
targeted towards applications that |
towards applications that need |
applications that need to |
that need to operate |
need to operate on |
emin gu n sirer |
to operate on a |
upload rate of opportunistic |
rate of opportunistic nodes |
operate on a global |
on a global scale |
and the paper shepherd |
the paper shepherd joseph |
paper shepherd joseph bonneau |
to build a successful |
build a successful service |
a successful service the |
successful service the following |
service the following goals |
the following goals were |
following goals were set |
design a failure management |
a failure management system |
failure management system that |
management system that is |
system that is independent |
that is independent of |
is independent of the |
independent of the distributed |
of the distributed systems |
the distributed systems packages |
distributed systems packages in |
systems packages in use |
packages in use and |
in use and provide |
use and provide failure |
and provide failure detection |
provide failure detection of |
failure detection of processes |
peer electronic cash system |
improve the accuracy of |
the accuracy of detection |
accuracy of detection of |
of detection of process |
detection of process and |
of process and node |
process and node failure |
and node failure through |
node failure through systems |
failure through systems support |
design support for failure |
support for failure detectors |
for failure detectors to |
failure detectors to work |
detectors to work in |
to work in large |
work in large scale |
in large scale systems |
while maintaining a high |
maintaining a high level |
a high level of |
high level of accuracy |
provide support for the |
support for the detection |
for the detection of |
the detection of partitions |
detection of partitions in |
of partitions in networks |
build a comprehensive software |
a comprehensive software package |
comprehensive software package that |
software package that can |
package that can be |
that can be easily |
can be easily integrated |
be easily integrated into |
easily integrated into various |
integrated into various distributed |
into various distributed systems |
ebay s paypal unit |
s paypal unit to |
paypal unit to start |
unit to start accepting |
to start accepting bitcoin |
start accepting bitcoin payments |
various distributed systems packages |
distributed systems packages and |
systems packages and applications |
the resulting system is |
resulting system is implemented |
system is implemented and |
is implemented and is |
implemented and is under |
and is under test |
is under test in |
under test in a |
test in a wide |
upload rate of opportunistic |
cdf number of accesses |
rate of opportunistic nodes |
in a local setting |
a local setting of |
local setting of a |
setting of a mix |
of a mix of |
a mix of high |
speed and traditional networks |
and traditional networks and |
traditional networks and in |
networks and in the |
and in the internet |
a first software release |
minimum and average download |
first software release is |
software release is planned |
release is planned for |
is planned for the |
planned for the autumn |
for the autumn of |
and average download factors |
average download factors across |
google adds bitcoin currency |
download factors across all |
adds bitcoin currency conversion |
factors across all correct |
bitcoin currency conversion to |
across all correct nodes |
currency conversion to search |
all correct nodes when |
correct nodes when using |
nodes when using different |
when using different strategies |
using different strategies for |
different strategies for choosing |
strategies for choosing the |
for choosing the threshold |
external failure detector modules |
failure detector modules originate |
detector modules originate in |
modules originate in asynchronous |
originate in asynchronous distributed |
in asynchronous distributed systems |
the upload contribution rate |
upload contribution rate of |
contribution rate of opportunistic |
rate of opportunistic nodes |
where they were introduced |
they were introduced to |
were introduced to de |
of opportunistic nodes is |
opportunistic nodes is varied |
nodes is varied in |
is varied in the |
varied in the x |
couple the mechanism by |
the mechanism by which |
mechanism by which failures |
by which failures are |
which failures are detected |
failures are detected from |
are detected from the |
detected from the protocols |
from the protocols used |
the protocols used to |
protocols used to tolerate |
used to tolerate those |
to tolerate those failures |
and the number of |
the number of opportunistic |
number of opportunistic nodes |
of opportunistic nodes is |
opportunistic nodes is fixed |
nodes is fixed at |
chandra and toueg successfully |
and toueg successfully show |
toueg successfully show that |
successfully show that it |
show that it is |
that it is possible |
it is possible to |
is possible to develop |
possible to develop consensus |
to develop consensus algorithms |
develop consensus algorithms using |
consensus algorithms using failure |
algorithms using failure detectors |
avg download factor min |
download factor min download |
factor min download factor |
even if these failure |
if these failure detectors |
these failure detectors make |
failure detectors make frequent |
detectors make frequent mistakes |
make frequent mistakes in |
frequent mistakes in their |
mistakes in their observations |
the failure detector work |
failure detector work is |
detector work is extended |
no auditing fixed threshold |
auditing fixed threshold stepwise |
fixed threshold stepwise percentile |
work is extended to |
is extended to systems |
extended to systems that |
to systems that also |
systems that also take |
that also take network |
also take network failure |
take network failure into |
network failure into account |
off in designing practical |
in designing practical distributed |
designing practical distributed systems |
practical distributed systems based |
distributed systems based on |
systems based on the |
based on the theory |
on the theory developed |
the theory developed for |
theory developed for asynchronous |
developed for asynchronous systems |
for asynchronous systems is |
asynchronous systems is where |
systems is where and |
is where and how |
where and how to |
and how to introduce |
how to introduce the |
to introduce the notion |
introduce the notion of |
the notion of time |
traditionally failure detectors have |
failure detectors have been |
detectors have been implemented |
have been implemented using |
been implemented using time |
out mechanisms in the |
mechanisms in the transport |
in the transport layer |
the transport layer that |
transport layer that implements |
layer that implements inter |
no auditing fixed threshold |
auditing fixed threshold stepwise |
fixed threshold stepwise percentile |
outs remain an important |
remain an important tool |
an important tool in |
important tool in the |
tool in the failure |
in the failure manager |
the failure manager described |
failure manager described in |
manager described in this |
described in this paper |
the mechanism is integrated |
mechanism is integrated into |
is integrated into a |
integrated into a more |
into a more comprehensive |
a more comprehensive approach |
more comprehensive approach that |
comprehensive approach that treats |
approach that treats failure |
that treats failure detection |
treats failure detection using |
failure detection using methods |
detection using methods based |
using methods based on |
methods based on an |
based on an analogy |
on an analogy with |
an analogy with fault |
detection techniques used in |
techniques used in daily |
used in daily life |
when trying to contact |
trying to contact a |
to contact a person |
contact a person who |
a person who has |
person who has allegedly |
who has allegedly disappeared |
has allegedly disappeared one |
allegedly disappeared one would |
disappeared one would never |
one would never be |
effect of increasing percentage |
of increasing percentage of |
increasing percentage of powered |
would never be satisfied |
never be satisfied with |
be satisfied with making |
satisfied with making repeated |
up disks on performance |
with making repeated phone |
making repeated phone calls |
repeated phone calls to |
phone calls to the |
calls to the same |
to the same location |
the same location for |
same location for half |
location for half an |
for half an hour |
half an hour and |
an hour and then |
hour and then declaring |
and then declaring the |
then declaring the disappearance |
declaring the disappearance a |
the disappearance a fact |
effect of increasing percentage |
of increasing percentage of |
increasing percentage of powered |
no matter whether the |
matter whether the phone |
whether the phone was |
the phone was not |
phone was not picked |
was not picked up |
up disks on power |
disks on power consumption |
on power consumption both |
power consumption both its |
consumption both its performance |
a busy tone was |
busy tone was heard |
tone was heard or |
was heard or the |
heard or the phone |
or the phone was |
the phone was disconnected |
as well as its |
well as its power |
in practice one would |
practice one would work |
one would work to |
would work to gain |
work to gain more |
to gain more confidence |
gain more confidence in |
the former is measured |
former is measured using |
is measured using the |
measured using the observed |
using the observed access |
the observed access latencies |
more confidence in such |
confidence in such a |
in such a decision |
such a decision by |
a decision by talking |
decision by talking to |
by talking to the |
talking to the landlord |
repurposing bitcoin work for |
bitcoin work for data |
work for data preservation |
while the latter is |
the neighbors or others |
the latter is measured |
neighbors or others that |
latter is measured by |
in proceedings of the |
proceedings of the ieee |
is measured by comparing |
or others that may |
of the ieee symposium |
measured by comparing the |
others that may have |
the ieee symposium on |
by comparing the cumulative |
that may have a |
ieee symposium on security |
comparing the cumulative percentage |
the cumulative percentage of |
symposium on security and |
on security and privacy |
cumulative percentage of time |
may have a more |
percentage of time the |
of time the disks |
time the disks are |
the disks are kept |
disks are kept powered |
are kept powered on |
have a more informed |
a more informed idea |
more informed idea about |
informed idea about the |
idea about the situation |
about the situation of |
the situation of the |
situation of the person |
of the person in |
the person in question |
as well as the |
well as the number |
as the number of |
the number of mode |
the failure management described |
failure management described in |
management described in this |
described in this paper |
in this paper is |
this paper is capable |
paper is capable of |
is capable of following |
capable of following a |
of following a similar |
following a similar strategy |
if a process under |
a process under investigation |
process under investigation is |
under investigation is not |
investigation is not responding |
is not responding it |
not responding it will |
namecoin dns dotbit project |
responding it will contact |
it will contact the |
will contact the operating |
contact the operating system |
the operating system under |
operating system under which |
system under which the |
under which the process |
which the process is |
the process is running |
show the results of |
the results of these |
or other nodes on |
other nodes on the |
nodes on the same |
on the same sub |
results of these simulations |
net to help reach |
to help reach a |
help reach a decision |
reach a decision in |
a decision in which |
decision in which one |
in which one can |
which one can have |
one can have greater |
can have greater confidence |
of the disks powered |
the disks powered on |
most distributed systems in |
distributed systems in use |
systems in use today |
in use today deal |
use today deal with |
today deal with failure |
ratio of freeloaders figure |
deal with failure of |
with failure of nodes |
failure of nodes or |
of nodes or networks |
nodes or networks in |
or networks in some |
networks in some way |
in general the problem |
general the problem is |
of the disks can |
minimum and average download |
the problem is detected |
the disks can be |
and average download factors |
problem is detected in |
disks can be spun |
average download factors across |
is detected in the |
can be spun down |
download factors across all |
detected in the communication |
be spun down while |
factors across all correct |
a next generation smart |
next generation smart contract |
spun down while still |
across all correct nodes |
in the communication subsystem |
down while still maintaining |
all correct nodes when |
the communication subsystem where |
while still maintaining performance |
correct nodes when using |
communication subsystem where session |
still maintaining performance comparable |
nodes when using different |
subsystem where session or |
maintaining performance comparable to |
when using different strategies |
using different strategies for |
performance comparable to that |
where session or transport |
different strategies for choosing |
comparable to that of |
to that of a |
strategies for choosing the |
for choosing the threshold |
that of a conventional |
of a conventional file |
a conventional file system |
session or transport protocols |
each session has mixed |
or transport protocols are |
session has mixed set |
the performance of our |
transport protocols are unable |
has mixed set of |
performance of our system |
protocols are unable to |
mixed set of opportunistic |
of our system depends |
are unable to make |
set of opportunistic nodes |
our system depends very |
system depends very heavily |
depends very heavily on |
very heavily on its |
heavily on its cache |
on its cache configuration |
contributing at different rates |
unable to make progress |
to make progress because |
make progress because of |
progress because of the |
since cache optimization is |
because of the lack |
of the lack of |
the lack of response |
lack of response from |
of response from remote |
response from remote nodes |
cache optimization is an |
and percentage of opportunistic |
optimization is an orthogonal |
percentage of opportunistic nodes |
traditionally packets are being |
packets are being retransmitted |
are being retransmitted after |
being retransmitted after a |
retransmitted after a time |
is an orthogonal issue |
of opportunistic nodes is |
an orthogonal issue that |
opportunistic nodes is varied |
nodes is varied on |
is varied on the |
varied on the x |
out period and after |
orthogonal issue that comprises |
issue that comprises an |
that comprises an entire |
comprises an entire field |
an entire field of |
entire field of research |
to their upload bandwidths |
field of research in |
of research in itself |
period and after a |
and after a retry |
after a retry threshold |
nodes able to upload |
a retry threshold is |
it is important to |
able to upload at |
retry threshold is reached |
is important to isolate |
analysis of bitcoin pooled |
of bitcoin pooled mining |
to upload at a |
important to isolate its |
to isolate its effect |
bitcoin pooled mining reward |
upload at a rate |
threshold is reached the |
is reached the remote |
reached the remote destination |
the remote destination is |
remote destination is marked |
destination is marked as |
is marked as unreachable |
isolate its effect on |
its effect on performance |
at a rate higher |
pooled mining reward systems |
a rate higher than |
some systems inject additional |
rate higher than the |
higher than the stream |
than the stream rate |
we implemented an ideal |
the stream rate are |
stream rate are placed |
rate are placed in |
are placed in higher |
implemented an ideal cache |
an ideal cache algorithm |
systems inject additional packets |
inject additional packets into |
additional packets into the |
which we term the |
we term the oracle |
which are closer to |
are closer to the |
closer to the source |
packets into the data |
into the data stream |
this data point represents |
the data stream to |
the source sends data |
data point represents the |
data stream to ensure |
source sends data to |
point represents the best |
stream to ensure timely |
sends data to the |
represents the best performance |
to ensure timely detection |
data to the highest |
the best performance we |
ensure timely detection of |
to the highest level |
best performance we could |
timely detection of failures |
the highest level group |
performance we could achieve |
detection of failures at |
highest level group only |
we could achieve since |
of failures at moments |
failures at moments when |
at moments when the |
who uses the basic |
moments when the traffic |
when the traffic is |
the traffic is low |
traffic is low or |
is low or unidirectional |
could achieve since an |
uses the basic protocol |
achieve since an oracle |
the basic protocol to |
since an oracle has |
basic protocol to disseminate |
an oracle has future |
protocol to disseminate data |
oracle has future knowledge |
to disseminate data among |
has future knowledge and |
disseminate data among each |
future knowledge and is |
data among each other |
knowledge and is able |
and is able to |
is able to replace |
able to replace items |
to replace items accessed |
replace items accessed furthest |
nodes in lower levels |
items accessed furthest in |
in lower levels may |
accessed furthest in the |
lower levels may receive |
furthest in the future |
levels may receive data |
may receive data at |
receive data at smaller |
data at smaller rates |
expect the application to |
the application to handle |
application to handle the |
after some filtering is |
some filtering is applied |
to handle the failure |
handle the failure management |
the failure management as |
failure management as the |
management as the support |
as the support system |
the support system does |
support system does not |
system does not contain |
level nodes may be |
we also wish to |
does not contain any |
not contain any fault |
contain any fault management |
nodes may be used |
also wish to provide |
may be used to |
wish to provide a |
be used to act |
used to act as |
to provide a performance |
often these systems cannot |
these systems cannot distinguish |
systems cannot distinguish between |
cannot distinguish between process |
provide a performance comparison |
to act as sources |
a performance comparison of |
act as sources to |
performance comparison of our |
comparison of our system |
research perspectives on bitcoin |
as sources to the |
sources to the lower |
of our system against |
perspectives on bitcoin and |
on bitcoin and secondgeneration |
bitcoin and secondgeneration cryptocurrencies |
node or network failure |
our system against conventional |
alleviating the burden at |
in ieee symposium on |
the mechanisms used to |
the burden at the |
burden at the source |
mechanisms used to detect |
ieee symposium on security |
symposium on security and |
on security and privacy |
used to detect failure |
auditing can be used |
as an approximation of |
an approximation of such |
can be used to |
to detect failure do |
approximation of such a |
of such a system |
detect failure do not |
failure do not adapt |
do not adapt to |
not adapt to changing |
we implemented a random |
implemented a random placement |
be used to avoid |
adapt to changing network |
to changing network conditions |
used to avoid the |
a random placement algorithm |
to avoid the presence |
avoid the presence of |
the presence of opportunistic |
presence of opportunistic and |
which maps each block |
maps each block to |
of opportunistic and lower |
making it almost impossible |
each block to a |
block to a random |
to a random disk |
opportunistic and lower bandwidth |
and lower bandwidth nodes |
lower bandwidth nodes in |
bandwidth nodes in the |
nodes in the higher |
it almost impossible to |
all disks are kept |
disks are kept powered |
are kept powered up |
almost impossible to use |
impossible to use these |
to use these systems |
it can ensure that |
use these systems unmodified |
can ensure that the |
these systems unmodified in |
ensure that the hierarchy |
systems unmodified in wide |
that the hierarchy of |
the hierarchy of nodes |
having set the context |
hierarchy of nodes is |
of nodes is obeyed |
nodes is obeyed by |
is obeyed by all |
obeyed by all nodes |
unmodified in wide area |
let us examine fig |
in wide area systems |
wide area systems without |
while allowing the system |
area systems without resorting |
allowing the system to |
systems without resorting to |
the system to leverage |
without resorting to heavy |
system to leverage additional |
resorting to heavy weight |
to leverage additional resources |
to heavy weight solutions |
leverage additional resources from |
heavy weight solutions like |
additional resources from privileged |
weight solutions like using |
the additional two data |
resources from privileged altruistic |
solutions like using a |
from privileged altruistic nodes |
points described above are |
described above are represented |
privileged altruistic nodes to |
altruistic nodes to forward |
above are represented in |
are represented in fig |
nodes to forward data |
to forward data to |
forward data to lower |
data to lower level |
to lower level groups |
like using a tcp |
using a tcp connection |
a tcp connection as |
tcp connection as the |
connection as the preferred |
we intend to explore |
intend to explore this |
to explore this further |
explore this further in |
this further in future |
further in future work |
as the preferred transport |
the preferred transport method |
preferred transport method for |
transport method for each |
method for each rpc |
for each rpc call |
related work several p |
especially those designed to |
those designed to support |
designed to support high |
streaming protocols have been |
protocols have been previously |
have been previously proposed |
the first generation of |
first generation of systems |
management in a more |
in a more integrated |
a more integrated way |
many of these systems |
of these systems are |
these systems are structured |
systems are structured as |
are structured as groups |
structured as groups of |
as groups of cooperating |
groups of cooperating processes |
of cooperating processes using |
cooperating processes using some |
processes using some form |
using some form of |
some form of group |
form of group membership |
relied on approaches based |
on approaches based on |
approaches based on pushing |
based on pushing data |
if we imagine a |
on pushing data through |
we imagine a line |
pushing data through a |
imagine a line at |
a line at y |
data through a single |
through a single dissemination |
a single dissemination tree |
detection to be able |
to be able to |
be able to reach |
able to reach consensus |
later approaches focused on |
approaches focused on improving |
various methods are used |
focused on improving fairness |
on improving fairness among |
improving fairness among peers |
of which fault monitors |
fairness among peers and |
among peers and resilience |
peers and resilience to |
and resilience to churn |
resilience to churn by |
to churn by breaking |
churn by breaking data |
by breaking data into |
breaking data into multiple |
data into multiple substreams |
into multiple substreams and |
multiple substreams and sending |
substreams and sending them |
and sending them along |
sending them along disjoing |
them along disjoing paths |
of the accesses live |
the accesses live above |
accesses live above this |
live above this line |
more recent systems like |
recent systems like coolstreaming |
are the most popular |
however in each of |
in each of these |
each of these systems |
based style of data |
style of data dissemination |
of these systems the |
disks on is the |
on is the third |
is the third best |
the third best configuration |
coolstreaming breaks the data |
breaks the data into |
the data into packets |
these systems the failure |
systems the failure management |
next only to the |
only to the oracle |
and peers organized into |
the failure management is |
to the oracle and |
peers organized into a |
failure management is an |
information propagation in the |
organized into a mesh |
management is an integral |
propagation in the bitcoin |
in the bitcoin network |
is an integral part |
into a mesh request |
an integral part of |
a mesh request packets |
integral part of the |
mesh request packets from |
request packets from their |
packets from their neighbors |
part of the particular |
from their neighbors using |
th ieee international conference |
ieee international conference on |
their neighbors using a |
the performance degradation in |
performance degradation in going |
international conference on peer |
neighbors using a scheduling |
using a scheduling algorithm |
degradation in going from |
of the particular membership |
the particular membership or |
particular membership or transport |
as we saw earlier |
membership or transport system |
or transport system and |
transport system and not |
system and not available |
and not available for |
chainsaw uses a simpler |
uses a simpler policy |
a simpler policy for |
simpler policy for requesting |
policy for requesting packets |
not available for general |
available for general use |
randomly fetching them while |
fetching them while respecting |
although some research groups |
them while respecting a |
while respecting a maximum |
respecting a maximum limit |
a maximum limit on |
disks on is negligibly |
on is negligibly small |
maximum limit on the |
limit on the number |
on the number of |
the number of outstanding |
number of outstanding requests |
of outstanding requests to |
outstanding requests to each |
requests to each neighbor |
chainsaw presents smaller delays |
for the system under |
the system under test |
presents smaller delays for |
smaller delays for the |
delays for the receipt |
for the receipt of |
the receipt of packets |
the optimal configuration is |
receipt of packets compared |
optimal configuration is to |
of packets compared to |
configuration is to fig |
packets compared to the |
compared to the coolstreaming |
to the coolstreaming protocol |
are focusing on wide |
focusing on wide area |
on wide area systems |
bitcoin and the age |
in a more recent |
a more recent work |
shows an estimate of |
the majority of the |
and the age of |
an estimate of the |
majority of the existing |
the age of bespoke |
age of bespoke silicon |
of the existing failure |
estimate of the actual |
of the actual power |
the existing failure detectors |
the actual power savings |
in proceedings of the |
existing failure detectors are |
based approaches are shown |
actual power savings achieved |
power savings achieved by |
failure detectors are not |
detectors are not suitable |
are not suitable for |
not suitable for use |
suitable for use in |
for use in large |
use in large scale |
in large scale systems |
savings achieved by our |
approaches are shown to |
achieved by our solution |
are shown to present |
shown to present better |
international conference on compilers |
because of their inflexibility |
we assume the following |
to present better performance |
present better performance over |
assume the following disk |
the following disk specifications |
architectures and synthesis for |
better performance over tree |
of their inflexibility or |
their inflexibility or the |
inflexibility or the simplicity |
or the simplicity of |
the simplicity of their |
simplicity of their assumptions |
and synthesis for embedded |
synthesis for embedded systems |
previous papers have considered |
papers have considered a |
have considered a variety |
considered a variety of |
a variety of possible |
variety of possible mechanisms |
of possible mechanisms to |
possible mechanisms to encourage |
mechanisms to encourage node |
to encourage node contribution |
building a failure detector |
a failure detector that |
failure detector that is |
detector that is not |
that is not an |
is not an integral |
not an integral part |
is a framework proposed |
an integral part of |
a framework proposed to |
integral part of the |
framework proposed to enforce |
proposed to enforce download |
to enforce download rate |
enforce download rate limitations |
download rate limitations on |
rate limitations on p |
part of the communication |
of the communication architecture |
the communication architecture permits |
p media streaming systems |
communication architecture permits the |
architecture permits the implementation |
permits the implementation of |
the protocol relies on |
the implementation of a |
protocol relies on a |
implementation of a collection |
into the bitcoin mines |
relies on a set |
of a collection of |
on a set of |
a collection of failure |
a set of trusted |
collection of failure detection |
set of trusted nodes |
of failure detection techniques |
of trusted nodes that |
failure detection techniques and |
trusted nodes that store |
detection techniques and support |
nodes that store information |
avg time for transition |
techniques and support for |
that store information on |
and support for failure |
store information on the |
support for failure detection |
information on the data |
on the data downloaded |
the data downloaded by |
data downloaded by each |
downloaded by each node |
we see that turning |
see that turning off |
by each node receiving |
each node receiving data |
for failure detection methods |
failure detection methods of |
detection methods of varying |
methods of varying levels |
nodes only send an |
of varying levels of |
only send an object |
varying levels of complexity |
send an object after |
of the disks results |
the disks results in |
an object after consulting |
levels of complexity from |
object after consulting the |
of complexity from which |
after consulting the trusted |
complexity from which the |
consulting the trusted nodes |
from which the system |
the trusted nodes to |
which the system designer |
the system designer can |
system designer can choose |
designer can choose to |
can choose to match |
choose to match the |
to match the system |
match the system requirements |
trusted nodes to verify |
nodes to verify if |
to verify if the |
verify if the nodes |
if the nodes requesting |
the failure management service |
failure management service consists |
management service consists of |
service consists of three |
consists of three functional |
of three functional modules |
the nodes requesting the |
with all the disks |
all the disks off |
nodes requesting the stream |
requesting the stream are |
the stream are not |
stream are not overrequesting |
are not overrequesting data |
while maintaining acceptable performance |
it is targeted to |
is targeted to systems |
targeted to systems where |
to systems where nodes |
systems where nodes upload |
where nodes upload full |
nodes upload full media |
upload full media objects |
full media objects from |
media objects from each |
objects from each other |
a library that implements |
and not for live |
library that implements simple |
shows some of the |
some of the tradeoffs |
of the tradeoffs involved |
streaming systems where all |
that implements simple failure |
systems where all nodes |
implements simple failure management |
note that the y |
where all nodes are |
simple failure management functionality |
failure management functionality and |
management functionality and provide |
axis represents three different |
represents three different quantities |
all nodes are interested |
functionality and provide the |
and provide the api |
provide the api to |
the cumulative percentage of |
the api to the |
api to the complete |
to the complete service |
nodes are interested in |
cumulative percentage of time |
are interested in receiving |
percentage of time the |
of time the disks |
interested in receiving the |
a service implementing per |
service implementing per node |
implementing per node failure |
per node failure management |
in receiving the exact |
time the disks are |
receiving the exact same |
the disks are powered |
the exact same data |
exact same data in |
disks are powered on |
combining fault management with |
same data in close |
data in close to |
in close to real |
close to real time |
the total duration of |
total duration of the |
duration of the simulation |
fault management with other |
management with other local |
with other local nodes |
other local nodes to |
local nodes to exploit |
nodes to exploit locality |
to exploit locality of |
exploit locality of communication |
locality of communication and |
of communication and failure |
communication and failure patterns |
and the cumulative number |
an inquiry service closely |
inquiry service closely coupled |
service closely coupled with |
closely coupled with the |
coupled with the operating |
with the operating system |
the operating system which |
the cumulative number of |
cumulative number of mode |
consider fairness issues in |
fairness issues in the |
issues in the context |
in the context of |
the context of tree |
transitions that the disks |
that the disks undergo |
provides information about the |
information about the state |
about the state of |
the state of local |
state of local participating |
of local participating processes |
both the total duration |
the most fundamental operation |
the total duration of |
total duration of the |
duration of the experiment |
most fundamental operation offered |
the authors present mechanisms |
fundamental operation offered by |
as well as the |
well as the number |
as the number of |
the number of mode |
operation offered by a |
authors present mechanisms that |
offered by a failure |
present mechanisms that rank |
by a failure detection |
increase as the percentage |
mechanisms that rank peers |
a failure detection service |
as the percentage of |
that rank peers according |
failure detection service is |
detection service is that |
rank peers according to |
the percentage of disks |
percentage of disks that |
peers according to their |
according to their level |
of disks that is |
disks that is powered |
to their level of |
their level of cooperation |
that is powered on |
is powered on is |
powered on is decreased |
service is that of |
is that of the |
that of the investigation |
of the investigation of |
the investigation of a |
investigation of a suspected |
of a suspected process |
level of cooperation with |
of cooperation with the |
cooperation with the system |
to make use of |
make use of this |
use of this operation |
one of their techniques |
of this operation it |
of their techniques involves |
this operation it is |
their techniques involves the |
we see that keeping |
operation it is not |
techniques involves the reconstruction |
it is not necessary |
involves the reconstruction of |
is not necessary for |
the reconstruction of trees |
not necessary for either |
reconstruction of trees as |
disks on strikes an |
on strikes an acceptable |
strikes an acceptable balance |
of trees as a |
trees as a way |
as a way of |
a way of punishing |
way of punishing opportunistic |
of punishing opportunistic nodes |
necessary for either the |
for either the local |
conclusion in this paper |
either the local or |
most of their mechanisms |
the local or remote |
we point out a |
point out a new |
of their mechanisms require |
local or remote process |
out a new opportunity |
a new opportunity for |
new opportunity for saving |
opportunity for saving power |
for saving power in |
saving power in large |
or remote process to |
remote process to run |
process to run any |
to run any of |
run any of the |
any of the heartbeat |
of the heartbeat or |
the heartbeat or polling |
heartbeat or polling patterns |
their mechanisms require peers |
mechanisms require peers to |
the idea is elegant |
require peers to keep |
the reasons that the |
idea is elegant in |
peers to keep track |
to keep track of |
is elegant in its |
elegant in its simplicity |
keep track of their |
reasons that the local |
track of their parents |
of their parents and |
log structured file systems |
their parents and children |
parents and children s |
and children s behavior |
that the local process |
structured file systems write |
the local process began |
file systems write only |
local process began to |
systems write only to |
process began to suspect |
studied the effect of |
write only to the |
began to suspect the |
the effect of different |
only to the log |
to the log head |
effect of different types |
of different types of |
different types of incentives |
types of incentives on |
of incentives on the |
incentives on the chainsaw |
on the chainsaw protocol |
to suspect the remote |
suspect the remote process |
the remote process are |
remote process are not |
process are not of |
are not of any |
not of any importance |
of any importance to |
any importance to the |
importance to the failure |
to the failure management |
if read accesses are |
read accesses are served |
accesses are served by |
are served by the |
served by the cache |
tat and some variations |
then write accesses touch |
write accesses touch only |
accesses touch only the |
touch only the log |
only the log head |
the log head disk |
the authors propose an |
authors propose an algorithm |
propose an algorithm that |
an algorithm that sets |
algorithm that sets up |
that sets up local |
potentially allowing us to |
sets up local markets |
up local markets at |
local markets at every |
markets at every node |
allowing us to power |
us to power down |
to power down all |
where neighbors compete for |
power down all the |
the process at address |
neighbors compete for the |
compete for the node |
for the node s |
the node s upload |
node s upload capacity |
down all the other |
process at address is |
all the other disks |
at address is investigated |
nodes favor neighbors who |
favor neighbors who contribute |
neighbors who contribute more |
address is investigated and |
existing solutions like disk |
is investigated and a |
investigated and a report |
and a report is |
a report is returned |
report is returned within |
is returned within the |
returned within the deadline |
within the deadline set |
the deadline set by |
deadline set by the |
set by the local |
by the local process |
solutions like disk management |
with nodes classified as |
like disk management solutions |
nodes classified as fast |
classified as fast or |
as fast or slow |
fast or slow nodes |
the local process does |
local process does not |
process does not have |
does not have to |
the results indicate that |
not have to wait |
results indicate that the |
have to wait for |
indicate that the proposed |
to wait for the |
that the proposed algorithm |
wait for the investigation |
the proposed algorithm improves |
for the investigation to |
proposed algorithm improves the |
the investigation to finish |
algorithm improves the performance |
investigation to finish but |
improves the performance of |
to finish but can |
the performance of the |
finish but can make |
performance of the system |
but can make use |
of the system when |
can make use of |
make use of the |
the system when the |
use of the asynch |
of the asynch interface |
the asynch interface to |
asynch interface to collect |
interface to collect the |
to collect the result |
collect the result at |
system when the total |
the result at a |
result at a later |
the working set model |
at a later moment |
when the total upload |
the total upload capacity |
total upload capacity is |
working set model for |
upload capacity is not |
capacity is not enough |
set model for program |
the report contains information |
is not enough to |
not enough to supply |
enough to supply all |
to supply all the |
supply all the nodes |
model for program behavior |
report contains information on |
contains information on whether |
information on whether the |
how a mining monopoly |
a mining monopoly can |
mining monopoly can attack |
monopoly can attack bitcoin |
on whether the remote |
whether the remote node |
the remote node was |
remote node was reachable |
streaming system where nodes |
node was reachable within |
system where nodes choose |
was reachable within the |
where nodes choose their |
nodes choose their neighbors |
reachable within the deadline |
choose their neighbors based |
their neighbors based on |
neighbors based on their |
based on their history |
on their history of |
their history of interaction |
within the deadline and |
the deadline and whether |
deadline and whether the |
and whether the process |
whether the process under |
the process under investigation |
process under investigation was |
under investigation was still |
investigation was still present |
was still present at |
still present at the |
present at the host |
nodes are placed in |
are placed in the |
placed in the system |
in the system according |
the system according to |
system according to their |
according to their current |
to their current trading |
their current trading performances |
if the mode parameter |
the mode parameter was |
mode parameter was used |
parameter was used to |
was used to request |
encouraging nodes to contribute |
used to request a |
to request a more |
request a more detailed |
a more detailed remote |
more detailed remote reporting |
nodes to contribute more |
to contribute more and |
contribute more and therefore |
more and therefore be |
and therefore be closer |
therefore be closer to |
be closer to the |
closer to the source |
process checkpoint information is |
checkpoint information is returned |
information is returned or |
is returned or the |
returned or the remote |
or the remote process |
the remote process is |
remote process is interrupted |
process is interrupted to |
is interrupted to provide |
interrupted to provide status |
to provide status information |
is a more recent |
a more recent live |
see the section on |
the section on os |
section on os integration |
streaming approach that tolerates |
approach that tolerates the |
that tolerates the existence |
tolerates the existence of |
the existence of opportunistic |
existence of opportunistic and |
of opportunistic and malicious |
opportunistic and malicious nodes |
if the node was |
the node was not |
node was not reachable |
was not reachable and |
not reachable and the |
time is divided into |
is divided into rounds |
reachable and the local |
and the local process |
the local process has |
local process has requested |
process has requested extensive |
in which each peer |
has requested extensive investigation |
which each peer communicates |
each peer communicates with |
peer communicates with another |
communicates with another peer |
with another peer selected |
another peer selected using |
peer selected using a |
selected using a pseudo |
the failure investigator will |
failure investigator will try |
investigator will try to |
will try to contact |
try to contact a |
to contact a failure |
contact a failure manager |
a failure manager at |
failure manager at the |
manager at the node |
peers exchange their current |
exchange their current history |
their current history containing |
current history containing the |
net or within its |
history containing the identifiers |
or within its administrative |
containing the identifiers of |
the identifiers of all |
within its administrative domain |
identifiers of all the |
of all the current |
all the current data |
majority is not enough |
the current data they |
current data they hold |
its administrative domain which |
administrative domain which should |
bitcoin mining is vulnerable |
domain which should be |
time disks on num |
as basis for the |
in financial cryptography and |
financial cryptography and data |
cryptography and data security |
basis for the next |
for the next exchanges |
which should be able |
should be able to |
transitions total time of |
be able to give |
able to give a |
nodes also perform a |
total time of run |
to give a more |
give a more conclusive |
a more conclusive answer |
more conclusive answer about |
conclusive answer about the |
answer about the node |
also perform a phase |
perform a phase of |
a phase of optimistic |
phase of optimistic push |
s failure to respond |
forwarding useful updates to |
useful updates to pseudo |
if network failure is |
network failure is the |
failure is the cause |
is the cause of |
the cause of the |
cause of the loss |
of the loss of |
the loss of connectivity |
randomly picked peers with |
picked peers with no |
peers with no guarantee |
with no guarantee of |
no guarantee of useful |
guarantee of useful return |
the report will indicate |
report will indicate which |
will indicate which part |
indicate which part of |
which part of the |
part of the path |
of the path is |
the path is reachable |
path is reachable and |
is reachable and where |
reachable and where the |
and where the suspected |
conclusion we propose and |
we propose and evaluate |
propose and evaluate a |
and evaluate a scalable |
evaluate a scalable auditing |
based technique for enforcing |
technique for enforcing fairness |
for enforcing fairness in |
if the failure investigator |
enforcing fairness in a |
fairness in a live |
the failure investigator is |
failure investigator is configured |
investigator is configured with |
is configured with alternative |
configured with alternative outgoing |
with alternative outgoing paths |
our approach employs local |
approach employs local auditors |
these paths are probed |
employs local auditors that |
paths are probed to |
local auditors that execute |
auditors that execute on |
that execute on all |
are probed to see |
execute on all nodes |
on all nodes in |
all nodes in a |
nodes in a streaming |
in a streaming session |
probed to see if |
to see if it |
see if it is |
if it is possible |
it is possible to |
is possible to circumvent |
they are responsible for |
possible to circumvent the |
are responsible for collecting |
to circumvent the network |
responsible for collecting auditable |
circumvent the network failure |
for collecting auditable information |
the network failure and |
collecting auditable information about |
network failure and in |
failure and in such |
and in such a |
in such a way |
such a way collect |
a way collect information |
way collect information about |
collect information about the |
information about the remote |
about the remote process |
auditable information about other |
improving the performance of |
information about other neighbors |
about other neighbors data |
cooperative equilibrium for supergames |
the report contains information |
report contains information about |
contains information about the |
information about the results |
the review of economic |
review of economic studies |
about the results of |
the results of these |
results of these probes |
other neighbors data exchanges |
the performance of log |
early triggers many systems |
triggers many systems find |
and for verifying that |
many systems find it |
for verifying that neighbors |
structured file systems with |
systems find it desirable |
verifying that neighbors upload |
file systems with adaptive |
find it desirable to |
that neighbors upload more |
systems with adaptive methods |
it desirable to detect |
neighbors upload more data |
upload more data than |
more data than a |
data than a specified |
than a specified threshold |
desirable to detect failure |
to detect failure of |
detect failure of remote |
failure of remote processes |
of remote processes even |
remote processes even if |
this threshold is defined |
threshold is defined by |
is defined by dedicated |
defined by dedicated global |
by dedicated global auditors |
processes even if there |
even if there is |
if there is no |
there is no data |
is no data exchange |
no data exchange actually |
which periodically sample the |
data exchange actually under |
exchange actually under way |
periodically sample the state |
sample the state of |
the state of the |
state of the system |
systems are free to |
of the system to |
are free to implement |
the system to determine |
free to implement whatever |
system to determine if |
to implement whatever scheme |
to determine if the |
implement whatever scheme they |
determine if the overall |
whatever scheme they find |
if the overall download |
scheme they find appropriate |
the overall download rate |
they find appropriate and |
overall download rate is |
find appropriate and use |
term competition a game |
download rate is compromised |
rate is compromised by |
appropriate and use the |
is compromised by the |
compromised by the presence |
by the presence of |
the presence of opportunistic |
presence of opportunistic nodes |
and use the failure |
use the failure investigator |
the failure investigator from |
global auditing determines the |
auditing determines the minimum |
determines the minimum threshold |
the minimum threshold for |
minimum threshold for uploads |
failure investigator from the |
investigator from the previous |
from the previous section |
the previous section to |
previous section to handle |
section to handle the |
to handle the suspicions |
and works with local |
works with local auditing |
with local auditing to |
local auditing to punish |
or they can make |
auditing to punish nodes |
they can make use |
to punish nodes that |
can make use of |
punish nodes that do |
nodes that do not |
that do not upload |
do not upload enough |
not upload enough data |
make use of two |
use of two standardized |
of two standardized schemes |
two standardized schemes implemented |
standardized schemes implemented by |
we study the efficiency |
schemes implemented by the |
implemented by the failure |
by the failure manager |
the failure manager library |
study the efficiency of |
the efficiency of our |
efficiency of our auditing |
of our auditing approach |
the first scheme uses |
first scheme uses a |
scheme uses a heartbeat |
uses a heartbeat mechanism |
our auditing approach through |
auditing approach through simulation |
which sends out i |
and show that it |
show that it is |
that it is able |
it is able to |
alive messages to a |
messages to a group |
to a group of |
a group of processes |
group of processes using |
of processes using multiple |
processes using multiple point |
is able to maintain |
able to maintain the |
to maintain the throughput |
maintain the throughput of |
the throughput of the |
throughput of the streaming |
point messages or a |
messages or a single |
or a single ip |
of the streaming system |
the streaming system even |
streaming system even in |
system even in the |
even in the presence |
in the presence of |
the presence of a |
presence of a large |
of a large number |
a large number of |
large number of opportunistic |
number of opportunistic nodes |
each process keeps track |
process keeps track of |
keeps track of the |
track of the reception |
of the reception times |
the reception times of |
reception times of messages |
times of messages and |
of messages and if |
messages and if a |
and if a number |
if a number of |
a number of consecutive |
number of consecutive heartbeats |
of consecutive heartbeats from |
consecutive heartbeats from a |
heartbeats from a destination |
from a destination is |
a destination is missed |
destination is missed a |
is missed a suspicion |
missed a suspicion is |
a suspicion is raised |
fixed period or an |
period or an exponential |
or an exponential back |
reducing energy consumption of |
energy consumption of disk |
consumption of disk storage |
of disk storage using |
disk storage using power |
a case for end |
case for end system |
for end system multicast |
fixed or estimated by |
or estimated by the |
estimated by the system |
and multiple suspicion levels |
multiple suspicion levels are |
suspicion levels are configurable |
levels are configurable by |
are configurable by the |
configurable by the application |
the application can provide |
application can provide application |
can provide application specific |
provide application specific data |
application specific data to |
specific data to be |
data to be piggybacked |
to be piggybacked on |
be piggybacked on the |
piggybacked on the heartbeats |
the second scheme uses |
second scheme uses a |
scheme uses a polling |
uses a polling method |
a polling method to |
polling method to collect |
method to collect acknowledgments |
to collect acknowledgments from |
collect acknowledgments from the |
acknowledgments from the peer |
from the peer processes |
if no acknowledgments are |
no acknowledgments are received |
acknowledgments are received after |
are received after a |
received after a number |
after a number of |
a number of retries |
number of retries a |
of retries a suspicion |
retries a suspicion is |
a suspicion is raised |
io bitcoin mining pool |
and retransmission limits are |
retransmission limits are configurable |
limits are configurable by |
are configurable by the |
configurable by the application |
by the application or |
the application or can |
application or can be |
or can be adapted |
can be adapted by |
be adapted by the |
adapted by the failure |
by the failure manager |
the failure manager to |
failure manager to the |
manager to the network |
instrumenting the operating system |
to achieve greater failure |
achieve greater failure detection |
greater failure detection accuracy |
it is necessary to |
is necessary to instrument |
necessary to instrument the |
to instrument the operating |
instrument the operating environment |
the operating environment with |
operating environment with support |
environment with support for |
with support for process |
support for process investigation |
it has always been |
has always been argued |
always been argued that |
been argued that in |
argued that in a |
that in a distributed |
in a distributed system |
a distributed system it |
distributed system it is |
system it is impossible |
reliable multicasting with an |
multicasting with an overlay |
with an overlay network |
it is impossible to |
is impossible to distinguish |
impossible to distinguish a |
to distinguish a crashed |
distinguish a crashed process |
a crashed process from |
effect of increasing percentage |
of increasing percentage of |
increasing percentage of powered |
crashed process from one |
process from one that |
from one that is |
one that is slow |
th symposium on operating |
up disks on power |
symposium on operating systems |
disks on power and |
on operating systems design |
on power and time |
operating systems design and |
systems design and implementation |
and caching solutions are |
caching solutions are typically |
solutions are typically application |
but with the proper |
with the proper system |
the proper system support |
proper system support this |
system support this is |
support this is no |
this is no longer |
is no longer true |
if the node is |
the node is reachable |
node is reachable and |
is reachable and operating |
reachable and operating correctly |
on the other hand |
the operating system can |
operating system can determine |
system can determine whether |
can determine whether or |
determine whether or not |
whether or not the |
or not the process |
not the process has |
the process has crashed |
is applicable to any |
applicable to any cacheable |
to any cacheable dataset |
the failure management integrated |
failure management integrated into |
management integrated into the |
since existing solutions are |
integrated into the os |
existing solutions are typically |
solutions are typically layered |
are typically layered on |
typically layered on top |
layered on top of |
on top of the |
top of the file |
into the os offers |
the os offers processes |
os offers processes a |
offers processes a mechanism |
processes a mechanism to |
a mechanism to register |
mechanism to register and |
to register and request |
register and request a |
and request a certain |
request a certain level |
a certain level of |
certain level of service |
they could be used |
could be used in |
be used in conjunction |
used in conjunction with |
in conjunction with our |
conjunction with our solution |
with our solution to |
our solution to take |
solution to take advantage |
to take advantage of |
take advantage of application |
is a simple binary |
a simple binary test |
simple binary test performed |
binary test performed by |
test performed by the |
performed by the os |
by the os upon |
the os upon receipt |
os upon receipt of |
upon receipt of an |
receipt of an inquiry |
we also provide some |
also provide some initial |
provide some initial simulation |
some initial simulation results |
indicating whether the process |
initial simulation results that |
simulation results that validate |
results that validate our |
that validate our claim |
validate our claim that |
our claim that power |
whether the process is |
the process is still |
process is still present |
is still present in |
savings are possible using |
are possible using a |
possible using a log |
still present in the |
present in the process |
in the process table |
the process table and |
process table and thus |
table and thus not |
and thus not has |
thus not has crashed |
not has crashed or |
has crashed or voluntary |
crashed or voluntary exited |
while simulations can never |
simulations can never provide |
can never provide conclusive |
never provide conclusive evidence |
the two other levels |
two other levels that |
other levels that are |
levels that are currently |
that are currently implemented |
highbandwidth content distribution in |
provide conclusive evidence for |
content distribution in cooperative |
conclusive evidence for the |
distribution in cooperative environments |
provide a remote process |
evidence for the feasibility |
for the feasibility of |
the feasibility of a |
feasibility of a system |
a remote process with |
remote process with information |
process with information about |
with information about the |
information about the progress |
they are an effective |
are an effective means |
an effective means to |
th acm symposium on |
acm symposium on operating |
effective means to identify |
means to identify promising |
symposium on operating systems |
on operating systems principles |
to identify promising solutions |
about the progress the |
the progress the local |
progress the local process |
the local process is |
local process is making |
our principal contribution in |
process is making which |
principal contribution in this |
is making which is |
contribution in this paper |
making which is useful |
in this paper is |
which is useful in |
is useful in the |
useful in the investigation |
in the investigation of |
the investigation of processes |
investigation of processes that |
of processes that are |
processes that are alive |
this paper is in |
paper is in having |
is in having shown |
in having shown a |
having shown a new |
shown a new fit |
a new fit for |
new fit for an |
fit for an old |
for an old idea |
but that appear slow |
that appear slow or |
appear slow or unresponsive |
we believe that the |
believe that the log |
at certain intervals the |
structured file system shows |
certain intervals the process |
file system shows promise |
intervals the process logs |
the process logs checkpoint |
process logs checkpoint timestamps |
logs checkpoint timestamps with |
checkpoint timestamps with the |
timestamps with the failure |
with the failure service |
system shows promise as |
shows promise as a |
promise as a powersaving |
as a powersaving opportunity |
a powersaving opportunity for |
powersaving opportunity for large |
which simultaneously logs the |
simultaneously logs the process |
acknowledgments this work was |
the response to an |
this work was partially |
response to an inquiry |
work was partially funded |
to an inquiry request |
an inquiry request holds |
kncminer bitcoin mining cloud |
bitcoin mining cloud mining |
was partially funded by |
inquiry request holds the |
request holds the last |
holds the last checkpoint |
the last checkpoint timestamp |
partially funded by intel |
funded by intel corporation |
by intel corporation and |
intel corporation and the |
corporation and the national |
and the national science |
the national science foundation |
the current local time |
special thanks to saikat |
whether the process has |
the process has been |
process has been allocated |
eliminating trees from overlay |
trees from overlay multicast |
thanks to saikat guha |
has been allocated cpu |
been allocated cpu time |
allocated cpu time since |
cpu time since the |
time since the last |
since the last checkpoint |
to saikat guha for |
saikat guha for his |
th international workshop on |
guha for his input |
international workshop on peer |
and whether the process |
for his input in |
his input in the |
input in the simulator |
in the simulator design |
whether the process has |
the process has consumed |
process has consumed any |
has consumed any messages |
consumed any messages since |
any messages since the |
messages since the last |
since the last checkpoint |
we also wish to |
also wish to thank |
wish to thank our |
to thank our anonymous |
thank our anonymous reviewers |
our anonymous reviewers for |
anonymous reviewers for their |
reviewers for their valuable |
for their valuable feedback |
upon receipt of an |
receipt of an inquiry |
of an inquiry the |
an inquiry the operating |
inquiry the operating system |
the operating system uses |
operating system uses an |
system uses an upcall |
to interrupt the process |
interrupt the process and |
the process and requests |
process and requests that |
and requests that the |
requests that the process |
that the process prepares |
the process prepares a |
process prepares a special |
prepares a special response |
this response is returned |
response is returned to |
is returned to the |
returned to the caller |
the previous sections all |
previous sections all deal |
sections all deal with |
all deal with provisions |
deal with provisions targeted |
with provisions targeted towards |
provisions targeted towards the |
targeted towards the failure |
towards the failure management |
the failure management of |
failure management of processes |
conserving disk energy in |
disk energy in network |
energy in network servers |
exploiting the close coupled |
the close coupled nature |
close coupled nature of |
coupled nature of a |
nature of a process |
of a process and |
a process and the |
process and the operating |
and the operating system |
the operating system it |
operating system it runs |
system it runs under |
to aid accurate detection |
aid accurate detection in |
accurate detection in the |
detection in the case |
in the case of |
the case of node |
case of node failure |
of node failure the |
node failure the fault |
failure the fault management |
th international conference on |
international conference on supercomputing |
the fault management system |
fault management system implements |
management system implements a |
system implements a node |
implements a node management |
a node management service |
which is based on |
is based on the |
an authorization architecture for |
authorization architecture for trustworthy |
architecture for trustworthy computing |
based on the experience |
on the experience that |
the experience that local |
experience that local failure |
in proceedings of the |
proceedings of the twenty |
that local failure investigation |
driven overlay network for |
overlay network for efficient |
network for efficient live |
for efficient live media |
efficient live media streaming |
local failure investigation on |
third acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
failure investigation on a |
investigation on a subnet |
on a subnet is |
a subnet is more |
subnet is more accurate |
is more accurate than |
more accurate than investigation |
accurate than investigation over |
than investigation over the |
investigation over the internet |
th conference on computer |
conference on computer communications |
on computer communications and |
computer communications and networking |
on a participating subnet |
a participating subnet one |
participating subnet one or |
subnet one or more |
one or more node |
or more node failure |
more node failure monitors |
the case for massive |
case for massive arrays |
for massive arrays of |
massive arrays of idle |
arrays of idle disks |
these are simple services |
are simple services capable |
simple services capable of |
services capable of performing |
capable of performing local |
of performing local failure |
performing local failure investigations |
local failure investigations upon |
failure investigations upon requests |
investigations upon requests from |
upon requests from remote |
requests from remote nodes |
multicast to announce their |
to announce their availability |
announce their availability within |
conference on file and |
on file and storage |
file and storage technologies |
their availability within the |
availability within the organization |
within the organization where |
the organization where their |
organization where their presence |
where their presence is |
their presence is being |
presence is being tracked |
is being tracked by |
being tracked by the |
tracked by the other |
by the other nfm |
an nfm accepts queries |
nfm accepts queries from |
accepts queries from remote |
queries from remote nodes |
from remote nodes about |
defense against intrusion in |
remote nodes about the |
nodes about the availability |
about the availability of |
the availability of a |
availability of a node |
of a node within |
a node within its |
node within its organization |
against intrusion in a |
intrusion in a live |
in a live streaming |
a live streaming multicast |
live streaming multicast system |
it will forward this |
will forward this request |
forward this request to |
this request to an |
request to an nfm |
to an nfm on |
an nfm on the |
nfm on the particular |
on the particular subnet |
the particular subnet which |
particular subnet which will |
th ieee international conference |
ieee international conference on |
international conference on peer |
helping disk arrays sleep |
disk arrays sleep through |
arrays sleep through the |
sleep through the winter |
subnet which will investigate |
which will investigate the |
will investigate the availability |
investigate the availability of |
the availability of the |
availability of the node |
of the node by |
the node by launching |
node by launching a |
by launching a number |
launching a number of |
a number of fault |
number of fault test |
of fault test requests |
if this is support |
this is support by |
proceedings of the twentieth |
is support by the |
of the twentieth acm |
the twentieth acm symposium |
twentieth acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
support by the host |
by the host under |
the host under investigation |
host under investigation or |
under investigation or by |
investigation or by icmp |
or by icmp echo |
by icmp echo requests |
icmp echo requests if |
echo requests if not |
the result of the |
result of the query |
of the query is |
the query is then |
query is then returned |
is then returned to |
then returned to the |
returned to the requesting |
to the requesting node |
the nfm also functions |
nfm also functions as |
also functions as proxy |
functions as proxy for |
as proxy for process |
proxy for process availability |
for process availability queries |
process availability queries in |
availability queries in the |
queries in the case |
in the case where |
the case where a |
case where a firewall |
where a firewall obstructs |
a firewall obstructs the |
firewall obstructs the free |
obstructs the free querying |
the free querying of |
free querying of the |
querying of the nodes |
of the nodes by |
the nodes by their |
nodes by their peers |
interplay of energy and |
of energy and performance |
energy and performance for |
and performance for disk |
s are configured with |
performance for disk arrays |
for disk arrays running |
disk arrays running transaction |
arrays running transaction processing |
running transaction processing workloads |
are configured with domain |
configured with domain and |
with domain and acl |
domain and acl mechanisms |
and acl mechanisms to |
acl mechanisms to control |
mechanisms to control access |
to control access to |
control access to the |
access to the information |
in ieee international symposium |
ieee international symposium on |
international symposium on performance |
symposium on performance analysis |
on performance analysis of |
performance analysis of systems |
analysis of systems and |
of systems and software |
an extension which is |
extension which is under |
which is under investigation |
th conference on computer |
conference on computer communications |
is under investigation is |
under investigation is to |
investigation is to have |
is to have nodes |
to have nodes multicast |
have nodes multicast heartbeats |
nodes multicast heartbeats with |
multicast heartbeats with local |
heartbeats with local node |
with local node information |
local node information periodically |
this information can be |
information can be collected |
can be collected by |
be collected by the |
collected by the local |
by the local nfm |
s and shared in |
and shared in compressed |
shared in compressed form |
in compressed form among |
compressed form among the |
form among the other |
among the other nfm |
s in the organization |
on power splitting games |
power splitting games in |
splitting games in distributed |
games in distributed computation |
local system management tools |
system management tools can |
management tools can connect |
tools can connect to |
the case of bitcoin |
case of bitcoin pooled |
of bitcoin pooled mining |
can connect to an |
connect to an nfm |
to an nfm to |
an nfm to retrieve |
nfm to retrieve the |
to retrieve the information |
retrieve the information and |
the information and set |
information and set trap |
and set trap conditions |
reducing disk power consumption |
disk power consumption in |
power consumption in servers |
consumption in servers with |
in servers with drpm |
in distributed systems build |
distributed systems build on |
systems build on top |
build on top of |
on top of a |
top of a web |
of a web of |
a web of interconnected |
web of interconnected networks |
we have to take |
have to take network |
to take network failure |
take network failure into |
network failure into account |
failures at network level |
at network level are |
network level are in |
level are in general |
are in general related |
in general related to |
general related to crash |
related to crash failures |
to crash failures of |
crash failures of routers |
failures of routers and |
of routers and gateways |
or to severe degradation |
to severe degradation of |
severe degradation of the |
degradation of the service |
of the service level |
the service level due |
service level due to |
level due to network |
due to network congestion |
causing minimum performance requirements |
hiding in plain sight |
minimum performance requirements to |
performance requirements to be |
requirements to be violated |
google seeks more power |
the failure investigator will |
in the new york |
the new york times |
when not able to |
not able to reach |
able to reach the |
to reach the node |
reach the node under |
the node under investigation |
node under investigation or |
under investigation or a |
investigation or a relevant |
or a relevant nfm |
perform a path search |
a path search to |
path search to find |
search to find the |
to find the trouble |
find the trouble spot |
the trouble spot in |
trouble spot in the |
spot in the network |
it uses the traceroute |
uses the traceroute technique |
the traceroute technique of |
traceroute technique of emitting |
technique of emitting small |
of emitting small messages |
emitting small messages with |
small messages with limited |
messages with limited ttl |
th symposium on operating |
symposium on operating systems |
on operating systems design |
triggering icmp responses from |
icmp responses from routers |
responses from routers among |
from routers among the |
routers among the path |
weekly bitcoin network statistics |
operating systems design and |
systems design and implementation |
if an obstruction is |
an obstruction is found |
obstruction is found it |
is found it is |
found it is reported |
it is reported to |
is reported to the |
reported to the caller |
berkeley db java edition |
db java edition architecture |
the failure management library |
failure management library offers |
management library offers functionality |
an oracle white paper |
library offers functionality to |
offers functionality to keep |
functionality to keep the |
to keep the obstruction |
keep the obstruction under |
the obstruction under investigation |
obstruction under investigation and |
under investigation and to |
investigation and to notify |
and to notify the |
to notify the application |
notify the application once |
the application once the |
application once the obstruction |
once the obstruction seems |
the obstruction seems to |
obstruction seems to be |
seems to be removed |
this way the process |
way the process does |
the process does not |
process does not need |
does not need to |
not need to keep |
need to keep the |
to keep the partitioned |
keep the partitioned processes |
the partitioned processes under |
partitioned processes under investigation |
processes under investigation but |
under investigation but can |
investigation but can wait |
but can wait until |
can wait until the |
wait until the connectivity |
until the connectivity is |
the connectivity is restored |
connectivity is restored by |
is restored by simply |
restored by simply monitoring |
by simply monitoring the |
simply monitoring the trouble |
monitoring the trouble spot |
in case the network |
case the network topology |
the network topology permits |
network topology permits it |
the investigator can be |
investigator can be configured |
can be configured to |
be configured to use |
configured to use alternate |
to use alternate paths |
to reach one of |
reach one of the |
one of the destination |
of the destination nfm |
high bandwidth data dissemination |
bandwidth data dissemination using |
data dissemination using an |
dissemination using an overlay |
using an overlay mesh |
eduardo pinheiro and ricardo |
pinheiro and ricardo bianchini |
from cornell for example |
cornell for example it |
for example it is |
example it is possible |
it is possible to |
is possible to construct |
energy conservation techniques for |
conservation techniques for disk |
techniques for disk array |
alternative routes to anywhere |
routes to anywhere in |
to anywhere in california |
th acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
the request contains sufficient |
request contains sufficient information |
contains sufficient information for |
sufficient information for the |
information for the nfm |
for the nfm to |
the nfm to construct |
nfm to construct a |
to construct a symmetric |
construct a symmetric return |
a symmetric return path |
protocols that can exploit |
that can exploit this |
can exploit this type |
exploit this type of |
this type of information |
th annual international conference |
annual international conference on |
international conference on supercomputing |
type of information are |
of information are under |
information are under development |
failure investigation of a |
investigation of a process |
of a process at |
a process at the |
process at the same |
at the same sub |
theoretic analysis of ddos |
analysis of ddos attacks |
of ddos attacks against |
ddos attacks against bitcoin |
net has always been |
has always been viewed |
always been viewed as |
been viewed as a |
viewed as a reasonably |
as a reasonably accurate |
attacks against bitcoin mining |
against bitcoin mining pools |
characteristics of file system |
of file system workloads |
reasons for false suspicions |
for false suspicions were |
false suspicions were overload |
in workshop on bitcoin |
workshop on bitcoin research |
suspicions were overload in |
were overload in the |
overload in the receiver |
in the receiver os |
a comparative study of |
comparative study of live |
study of live p |
which could cause high |
could cause high message |
cause high message loss |
or unresponsiveness due to |
unresponsiveness due to application |
due to application overload |
th conference on computer |
conference on computer communications |
although that could be |
that could be seen |
could be seen as |
be seen as a |
seen as a design |
as a design error |
mendel rosenblum and john |
rosenblum and john k |
although confident about the |
confident about the result |
one was never guaranteed |
was never guaranteed that |
never guaranteed that the |
guaranteed that the process |
that the process had |
the process had truly |
process had truly crashed |
the design and implementation |
design and implementation of |
and implementation of a |
implementation of a log |
using the os failure |
when bitcoin mining pools |
bitcoin mining pools run |
mining pools run dry |
the os failure management |
os failure management extensions |
acm transactions on computer |
in workshop on bitcoin |
transactions on computer systems |
this assurance is now |
assurance is now available |
workshop on bitcoin research |
the time needed by |
time needed by the |
needed by the failure |
by the failure detector |
the failure detector to |
failure detector to come |
detector to come to |
to come to a |
come to a result |
to a result has |
a result has been |
result has been greatly |
has been greatly reduced |
been greatly reduced in |
greatly reduced in the |
reduced in the optimistic |
common case that the |
case that the node |
that the node on |
the node on which |
node on which the |
on which the process |
which the process was |
the process was running |
process was running is |
was running is reachable |
regardless if the process |
if the process has |
the process has failed |
process has failed or |
has failed or not |
preventing dos attacks in |
dos attacks in peer |
the node is able |
node is able to |
comparison of mining pools |
is able to indicate |
able to indicate whether |
to indicate whether or |
indicate whether or not |
whether or not the |
or not the process |
peer media streaming systems |
not the process has |
the process has crashed |
in general a single |
general a single round |
trip time is sufficient |
time is sufficient at |
is sufficient at the |
sufficient at the local |
at the local network |
the local network to |
local network to get |
network to get a |
to get a result |
th annual multimedia computing |
annual multimedia computing and |
multimedia computing and networking |
computing and networking conference |
area case this time |
case this time is |
comparison of mining pools |
this time is a |
time is a function |
is a function of |
a function of the |
function of the level |
of the level of |
the level of congestion |
level of congestion in |
of congestion in the |
congestion in the network |
in the network path |
the os extensions also |
os extensions also improve |
extensions also improve the |
also improve the confidence |
improve the confidence in |
the confidence in the |
confidence in the failure |
in the failure investigation |
the failure investigation process |
failure investigation process in |
investigation process in the |
process in the wide |
disk layout optimization for |
using the old strategy |
the old strategy of |
layout optimization for reducing |
optimization for reducing energy |
for reducing energy consumption |
old strategy of simply |
strategy of simply polling |
of simply polling a |
simply polling a process |
polling a process until |
a process until a |
process until a time |
out occurs gives much |
occurs gives much less |
gives much less confidence |
much less confidence in |
less confidence in the |
confidence in the result |
in the result of |
the result of the |
result of the failure |
of the failure investigation |
hashcash amortizable publicly auditable |
amortizable publicly auditable cost |
if no response was |
no response was received |
response was received after |
was received after the |
received after the maximum |
th annual international conference |
annual international conference on |
international conference on supercomputing |
after the maximum number |
the maximum number of |
maximum number of retransmission |
number of retransmission is |
of retransmission is reached |
it was not certain |
was not certain whether |
not certain whether this |
certain whether this was |
whether this was because |
this was because of |
was because of network |
because of network failure |
host failure or process |
failure or process failure |
with the new scheme |
the new scheme it |
new scheme it is |
scheme it is possible |
it is possible to |
is possible to distinguish |
possible to distinguish among |
to distinguish among these |
distinguish among these different |
among these different failures |
additional information the full |
information the full report |
the full report contains |
full report contains the |
report contains the detailed |
contains the detailed results |
the detailed results of |
detailed results of the |
results of the trace |
of the trace study |
the trace study on |
trace study on the |
study on the accuracy |
on the accuracy and |
the accuracy and performance |
accuracy and performance of |
and performance of the |
nd workshop on the |
workshop on the economics |
on the economics of |
the economics of peer |
performance of the failure |
of the failure detector |
the failure detector in |
failure detector in the |
detector in the internet |
the effectiveness of its |
effectiveness of its partition |
of its partition detection |
its partition detection mechanism |
host failure measurements and |
failure measurements and measurements |
measurements and measurements of |
and measurements of failure |
measurements of failure detection |
of failure detection for |
failure detection for server |
detection for server fail |
it will be available |
will be available later |
be available later this |
available later this year |
later this year through |
this year through the |
year through the cornell |
through the cornell university |
the cornell university technical |
cornell university technical report |
university technical report server |
hashcash a denial of |
a denial of service |
denial of service counter |
improving robustness of peer |
relevant url s the |
url s the horus |
s the horus project |
the horus project the |
peer streaming with incentives |
horus project the cornell |
project the cornell cluster |
the cornell cluster computing |
cornell cluster computing project |
cluster computing project werner |
computing project werner vogels |
project werner vogels personal |
werner vogels personal home |
vogels personal home page |
personal home page papers |
home page papers on |
page papers on failure |
papers on failure detection |
on failure detection http |
st workshop on the |
workshop on the economics |
on the economics of |
the economics of networked |
economics of networked systems |
on subversive miner strategies |
subversive miner strategies and |
miner strategies and block |
strategies and block withholding |
and block withholding attack |
block withholding attack in |
withholding attack in bitcoin |
attack in bitcoin digital |
in bitcoin digital currency |
p live streaming system |
of the ninth ieee |
the ninth ieee global |
ninth ieee global internet |
ieee global internet workshop |
how incentivize large bitcoin |
incentivize large bitcoin mining |
large bitcoin mining http |
transis a communication subsystem |
a communication subsystem for |
communication subsystem for high |
subsystem for high availability |
idigest of papers of |
a scalable services architecture |
scalable services architecture tudor |
services architecture tudor marian |
architecture tudor marian ken |
tudor marian ken birman |
marian ken birman department |
ken birman department of |
birman department of computer |
department of computer science |
of computer science cornell |
computer science cornell university |
fast message ordering and |
message ordering and membership |
ordering and membership using |
and membership using a |
membership using a logical |
using a logical token |
edu abstract data centers |
abstract data centers constructed |
data centers constructed as |
centers constructed as clusters |
constructed as clusters of |
as clusters of inexpensive |
clusters of inexpensive machines |
of inexpensive machines have |
inexpensive machines have compelling |
machines have compelling cost |
but developing services to |
developing services to run |
services to run on |
to run on them |
run on them can |
on them can be |
them can be challenging |
this paper reports on |
paper reports on a |
reports on a new |
on a new framework |
reliable communication in the |
communication in the presence |
the scalable services architecture |
in the presence of |
the presence of failure |
acm transaction on computer |
transaction on computer systems |
which helps developers develop |
helps developers develop scalable |
developers develop scalable clustered |
develop scalable clustered applications |
the work is focused |
work is focused on |
is focused on nontransactional |
focused on nontransactional high |
these are poorly supported |
are poorly supported in |
poorly supported in existing |
supported in existing platforms |
a primary goal was |
primary goal was to |
goal was to keep |
was to keep the |
to keep the ssa |
keep the ssa as |
the ssa as small |
ssa as small and |
as small and simple |
small and simple as |
and simple as possible |
key elements include a |
elements include a tcp |
based chain replication mechanism |
chain replication mechanism and |
replication mechanism and a |
mechanism and a gossip |
based subsystem for managing |
subsystem for managing configuration |
for managing configuration data |
managing configuration data and |
group membership and viewsynchronous |
membership and viewsynchronous communication |
and viewsynchronous communication in |
viewsynchronous communication in partitionable |
communication in partitionable asynchronous |
in partitionable asynchronous systems |
configuration data and repairing |
data and repairing inconsistencies |
and repairing inconsistencies after |
repairing inconsistencies after faults |
our experimental results confirm |
experimental results confirm the |
results confirm the effectiveness |
confirm the effectiveness of |
the effectiveness of the |
effectiveness of the approach |
introduction large computing systems |
large computing systems are |
computing systems are often |
systems are often structured |
are often structured as |
often structured as service |
structured as service oriented |
as service oriented architectures |
for example using web |
example using web services |
using web services platforms |
clients access services in |
access services in a |
services in a request |
each service is self |
offers its own api |
unreliable failure detectors for |
failure detectors for reliable |
detectors for reliable distributed |
for reliable distributed systems |
and handles its own |
handles its own quality |
its own quality of |
own quality of service |
quality of service or |
of service or availability |
service or availability guarantees |
to appear in journal |
appear in journal of |
in journal of the |
journal of the acm |
for example by arranging |
example by arranging to |
by arranging to be |
arranging to be restarted |
to be restarted after |
be restarted after a |
restarted after a failure |
while many services need |
many services need to |
services need to maintain |
need to maintain availability |
to maintain availability in |
maintain availability in the |
availability in the face |
in the face of |
the face of challenging |
face of challenging operating |
of challenging operating conditions |
building services with these |
services with these properties |
with these properties is |
these properties is difficult |
impossibility of distributed consensus |
of distributed consensus with |
distributed consensus with one |
consensus with one faulty |
with one faulty process |
existing web services platforms |
web services platforms offer |
services platforms offer load |
journal of the acm |
balancing and restart mechanisms |
and restart mechanisms for |
restart mechanisms for transactional |
mechanisms for transactional services |
for transactional services implemented |
transactional services implemented using |
services implemented using a |
implemented using a three |
but not for services |
not for services implemented |
for services implemented using |
services implemented using other |
implemented using other technologies |
developers of nontransactional web |
of nontransactional web services |
nontransactional web services must |
web services must implement |
services must implement their |
must implement their own |
implement their own mechanisms |
their own mechanisms for |
own mechanisms for replicating |
mechanisms for replicating data |
tracking membership and live |
r van and vogels |
membership and live this |
and live this work |
live this work was |
this work was supported |
work was supported by |
was supported by darpa |
ipto under the srs |
under the srs program |
the srs program and |
srs program and by |
program and by the |
support for highly reliable |
and by the rome |
by the rome air |
the rome air force |
rome air force research |
air force research laboratory |
under the prometheus program |
acm sigops european workshop |
additional support was provided |
support was provided by |
was provided by the |
provided by the nsf |
robbert van renesse ness |
redirecting requests during failures |
requests during failures to |
during failures to minimize |
failures to minimize client |
to minimize client disruption |
building collaboration applications that |
collaboration applications that mix |
applications that mix web |
and detecting and repairing |
that mix web services |
detecting and repairing inconsistencies |
mix web services hosted |
web services hosted content |
services hosted content with |
hosted content with p |
our premise in this |
premise in this paper |
in this paper is |
this paper is that |
paper is that for |
is that for many |
that for many services |
the transactional model is |
transactional model is a |
model is a poor |
is a poor fit |
a poor fit and |
poor fit and hence |
fit and hence that |
and hence that tools |
hence that tools aimed |
that tools aimed at |
tools aimed at non |
transactional web services systems |
web services systems will |
services systems will be |
systems will be needed |
reliable multicast for distributed |
multicast for distributed interactive |
for distributed interactive simulation |
we recognize that this |
recognize that this is |
that this is debatable |
proceedings of acm sigcomm |
krzysztof ostrowski cornell university |
vendors have generally argued |
have generally argued that |
dept of computer science |
generally argued that only |
argued that only transactional |
that only transactional systems |
only transactional systems offer |
transactional systems offer the |
systems offer the hooks |
offer the hooks needed |
the hooks needed to |
hooks needed to support |
needed to support automated |
to support automated scalability |
repair and restart mechanisms |
key to this argument |
to this argument is |
this argument is the |
argument is the ease |
is the ease with |
the ease with which |
ease with which interrupted |
with which interrupted transactions |
which interrupted transactions can |
interrupted transactions can be |
transactions can be rolled |
can be rolled back |
and the relative simplicity |
the relative simplicity of |
relative simplicity of cleaning |
simplicity of cleaning up |
of cleaning up a |
cleaning up a database |
up a database after |
a database after a |
database after a crash |
view synchronous communication in |
synchronous communication in large |
communication in large scale |
yet the transactional programming |
the transactional programming model |
transactional programming model also |
programming model also brings |
model also brings constraints |
also brings constraints and |
brings constraints and overheads |
nd open broadcast workshop |
were this not the |
this not the case |
the transactional model would |
transactional model would long |
model would long ago |
would long ago have |
long ago have become |
ago have become universal |
edu abstract the most |
abstract the most commonly |
some of these constraints |
the most commonly deployed |
of these constraints relate |
most commonly deployed web |
these constraints relate to |
commonly deployed web service |
constraints relate to the |
deployed web service applications |
relate to the challenges |
web service applications employ |
to the challenges of |
service applications employ client |
the challenges of maintaining |
challenges of maintaining a |
of maintaining a clean |
maintaining a clean separation |
a clean separation of |
clean separation of code |
separation of code and |
of code and data |
with clients running remotely |
clients running remotely and |
running remotely and services |
not all applications can |
remotely and services hosted |
all applications can be |
applications can be structured |
and services hosted in |
services hosted in data |
hosted in data centers |
increasing reliability of communication |
reliability of communication in |
of communication in large |
communication in large scale |
in large scale distributed |
can be structured in |
be structured in this |
structured in this manner |
we make the case |
make the case for |
the case for service |
transactional rollback and restart |
rollback and restart can |
and restart can be |
restart can be costly |
and restarting a database |
restarting a database after |
a database after a |
database after a crash |
applications that combine service |
after a crash incurs |
a crash incurs delays |
crash incurs delays while |
incurs delays while cleanup |
delays while cleanup code |
while cleanup code runs |
hosted data with collaboration |
data with collaboration features |
with collaboration features implemented |
collaboration features implemented using |
features implemented using peerto |
high availability is difficult |
availability is difficult to |
is difficult to acheive |
difficult to acheive in |
to acheive in the |
acheive in the transactional |
in the transactional model |
collaboration features are awkward |
the fastest database replication |
features are awkward to |
fastest database replication schemes |
are awkward to support |
awkward to support solely |
to support solely based |
support solely based on |
solely based on the |
based on the existing |
on the existing web |
the existing web services |
existing web services technologies |
suffer from failure scenarios |
from failure scenarios that |
failure scenarios that can |
scenarios that can require |
indirection through the data |
that can require intervention |
through the data center |
can require intervention by |
the data center introduces |
require intervention by a |
data center introduces high |
intervention by a human |
by a human operator |
center introduces high latencies |
introduces high latencies and |
high latencies and limits |
a generic architecture for |
generic architecture for dependable |
yet the higher fidelity |
the higher fidelity schemes |
latencies and limits scalability |
architecture for dependable distributed |
for dependable distributed computing |
higher fidelity schemes require |
fidelity schemes require expensive |
schemes require expensive multi |
and precludes collaboration between |
precludes collaboration between clients |
collaboration between clients connected |
between clients connected to |
clients connected to one |
phase commit protocols and |
commit protocols and hence |
protocols and hence may |
and hence may not |
hence may not give |
may not give adequate |
another but lacking connectivity |
not give adequate performance |
but lacking connectivity to |
lacking connectivity to the |
connectivity to the data |
to the data center |
cornell s live distributed |
clustered threetier database products |
s live distributed objects |
threetier database products are |
live distributed objects platform |
database products are powerful |
distributed objects platform combines |
products are powerful solutions |
objects platform combines web |
platform combines web services |
combines web services with |
web services with direct |
services with direct peerto |
but they negotiate these |
they negotiate these potential |
negotiate these potential pitfalls |
these potential pitfalls in |
peer communication to eliminate |
potential pitfalls in ways |
communication to eliminate these |
pitfalls in ways that |
to eliminate these issues |
in ways that preclude |
ways that preclude important |
that preclude important classes |
preclude important classes of |
important classes of applications |
our motivation is to |
motivation is to show |
is to show that |
introduction there is a |
to show that a |
there is a growing |
show that a simple |
is a growing opportunity |
a flexible group communications |
flexible group communications system |
a growing opportunity to |
that a simple and |
growing opportunity to use |
a simple and remarkably |
cornell university technical report |
opportunity to use service |
simple and remarkably inexpensive |
and remarkably inexpensive infrastructure |
remarkably inexpensive infrastructure can |
inexpensive infrastructure can support |
infrastructure can support clustered |
can support clustered execution |
support clustered execution of |
clustered execution of a |
execution of a significant |
of a significant class |
a significant class of |
significant class of non |
applications in ways that |
in ways that can |
ways that can slash |
that can slash health |
the work reported here |
work reported here focuses |
reported here focuses on |
here focuses on services |
focuses on services that |
on services that don |
services that don t |
that don t fit |
don t fit the |
t fit the transactional |
fit the transactional paradigm |
permit more effective search |
more effective search and |
effective search and rescue |
search and rescue after |
and rescue after a |
rescue after a disaster |
typically for reasons of |
for reasons of performance |
enable a more nimble |
a more nimble information |
ones that operate directly |
that operate directly on |
operate directly on in |
memory data structures or |
data structures or simple |
structures or simple non |
or make possible a |
make possible a world |
possible a world of |
a world of professional |
managed transactional consistency for |
world of professional dialog |
transactional consistency for web |
of professional dialog and |
to simplify our task |
consistency for web caching |
professional dialog and collaboration |
for web caching ittay |
dialog and collaboration without |
web caching ittay eyal |
and collaboration without travel |
we assume that these |
caching ittay eyal ken |
assume that these services |
ittay eyal ken birman |
that these services are |
eyal ken birman robbert |
soc applications will need |
these services are capable |
ken birman robbert van |
applications will need to |
services are capable of |
birman robbert van renesse |
will need to combine |
are capable of handling |
robbert van renesse cornell |
need to combine two |
capable of handling outof |
van renesse cornell university |
to combine two types |
renesse cornell university abstract |
combine two types of |
two types of content |
cornell university abstract in |
and that processes implementing |
traditional web service hosted |
that processes implementing them |
web service hosted content |
processes implementing them experience |
implementing them experience only |
them experience only crash |
experience only crash failures |
such as data from |
as data from databases |
only caches are widely |
caches are widely used |
as will be shown |
will be shown below |
are widely used in |
widely used in cloud |
used in cloud infrastructure |
in cloud infrastructure to |
cloud infrastructure to reduce |
our assumptions hold for |
infrastructure to reduce access |
assumptions hold for a |
and weather prediction systems |
to reduce access latency |
hold for a very |
reduce access latency and |
for a very large |
access latency and to |
a very large group |
with a variety of |
latency and to reduce |
very large group of |
a variety of collaboration |
and to reduce load |
large group of applications |
variety of collaboration features |
to reduce load on |
reduce load on backend |
load on backend databases |
the ssa was built |
ssa was built using |
such as chat windows |
was built using epidemic |
operators view coherent caches |
view coherent caches as |
coherent caches as impractical |
caches as impractical at |
as impractical at genuinely |
impractical at genuinely large |
at genuinely large scale |
genuinely large scale and |
large scale and many |
scale and many client |
communication protocols in conjunction |
protocols in conjunction with |
peer video and other |
in conjunction with a |
video and other media |
and other media streams |
conjunction with a novel |
facing caches are updated |
with a novel variant |
caches are updated in |
a novel variant of |
are updated in an |
novel variant of the |
updated in an asynchronous |
variant of the chain |
in an asynchronous manner |
of the chain replication |
an asynchronous manner with |
the chain replication scheme |
asynchronous manner with best |
existing web service technologies |
chain replication scheme which |
web service technologies make |
replication scheme which has |
service technologies make it |
scheme which has evolved |
technologies make it easy |
which has evolved from |
make it easy to |
has evolved from the |
existing solutions that support |
it easy to build |
evolved from the mechanism |
solutions that support cache |
easy to build applications |
from the mechanism first |
that support cache consistency |
to build applications in |
the mechanism first proposed |
support cache consistency are |
build applications in which |
mechanism first proposed in |
cache consistency are inapplicable |
applications in which all |
consistency are inapplicable to |
in which all data |
are inapplicable to this |
which all data travels |
inapplicable to this scenario |
all data travels through |
to this scenario since |
data travels through a |
this scenario since they |
travels through a data |
scenario since they require |
through a data center |
since they require a |
they require a round |
require a round trip |
a round trip to |
round trip to the |
trip to the database |
gossip based infrastructures are |
implementing collaboration features using |
to the database on |
based infrastructures are beneficial |
collaboration features using these |
the database on every |
infrastructures are beneficial because |
features using these technologies |
database on every cache |
are beneficial because they |
using these technologies is |
on every cache transaction |
beneficial because they are |
these technologies is problematic |
technologies is problematic because |
is problematic because collaborative |
problematic because collaborative applications |
because collaborative applications can |
simple to implement rapidly |
existing incoherent cache technologies |
collaborative applications can generate |
to implement rapidly self |
incoherent cache technologies are |
applications can generate high |
cache technologies are oblivious |
technologies are oblivious to |
are oblivious to transactional |
oblivious to transactional data |
stabilizing after disruptions analytically |
to transactional data access |
bursty update rates and |
after disruptions analytically appealing |
update rates and yet |
disruptions analytically appealing this |
rates and yet often |
even if the backend |
analytically appealing this paper |
and yet often require |
if the backend database |
appealing this paper reports |
yet often require low |
the backend database supports |
this paper reports on |
often require low latencies |
backend database supports transactions |
a private framework for |
private framework for distributed |
framework for distributed computation |
for distributed computation edward |
distributed computation edward tremel |
require low latencies and |
paper reports on the |
low latencies and tight |
reports on the architecture |
latencies and tight synchronization |
on the architecture and |
and tight synchronization between |
the architecture and performance |
tight synchronization between collaborating |
architecture and performance of |
synchronization between collaborating users |
and performance of the |
aware cache for read |
performance of the platform |
and ma rk jelasity |
one can often achieve |
can often achieve better |
often achieve better performance |
and explores the limitations |
achieve better performance using |
better performance using direct |
explores the limitations of |
the limitations of its |
performance using direct client |
ma rk jelasity there |
limitations of its underlying |
of its underlying techniques |
rk jelasity there is |
cache improves cache consistency |
jelasity there is a |
improves cache consistency despite |
there is a growing |
cache consistency despite asynchronous |
the experiments are designed |
is a growing class |
consistency despite asynchronous and |
experiments are designed to |
a growing class of |
despite asynchronous and unreliable |
are designed to help |
growing class of distributed |
asynchronous and unreliable communication |
designed to help us |
class of distributed systems |
and unreliable communication between |
to help us fully |
but in today s |
help us fully understand |
of distributed systems applications |
in today s soa |
today s soa plat |
us fully understand the |
distributed systems applications in |
unreliable communication between the |
fully understand the fundamental |
systems applications in which |
communication between the cache |
understand the fundamental properties |
applications in which data |
between the cache and |
band communication is hard |
communication is hard to |
the fundamental properties of |
the cache and the |
cache and the database |
is hard to integrate |
fundamental properties of a |
in which data stored |
hard to integrate with |
properties of a single |
which data stored on |
to integrate with hosted |
of a single partitioned |
data stored on client |
integrate with hosted content |
a variant of serializability |
stored on client platforms |
a single partitioned replicated |
variant of serializability that |
of serializability that is |
single partitioned replicated service |
this problem is reflected |
on client platforms must |
serializability that is suitable |
partitioned replicated service and |
problem is reflected by |
client platforms must be |
that is suitable for |
replicated service and thus |
is reflected by a |
platforms must be aggregated |
is suitable for incoherent |
service and thus gain |
reflected by a growing |
must be aggregated or |
suitable for incoherent caches |
and thus gain a |
by a growing number |
be aggregated or analyzed |
thus gain a firm |
a growing number of |
aggregated or analyzed without |
or analyzed without revealing |
analyzed without revealing private |
without revealing private information |
revealing private information to |
private information to the |
information to the operator |
and prove that with |
gain a firm grasp |
growing number of publications |
prove that with unbounded |
a firm grasp on |
number of publications on |
of publications on the |
that with unbounded resources |
firm grasp on the |
grasp on the behavior |
publications on the integration |
with unbounded resources t |
systems such as the |
such as the smart |
as the smart power |
the smart power grid |
on the integration of |
on the behavior of |
the integration of web |
control systems for energy |
the behavior of the |
integration of web services |
behavior of the ssa |
of web services with |
of the ssa s |
web services with peer |
the ssa s building |
ssa s building blocks |
cache allows the system |
allows the system manager |
the system manager to |
system manager to choose |
manager to choose a |
to choose a trade |
and traffic analysis in |
we defer for future |
traffic analysis in large |
off between performance and |
between performance and consistency |
analysis in large cities |
defer for future work |
in large cities all |
our evaluation shows that |
evaluation shows that t |
large cities all depend |
for future work the |
cities all depend on |
future work the full |
cache detects many inconsistencies |
detects many inconsistencies with |
work the full scale |
all depend on the |
depend on the analysis |
on the analysis of |
the analysis of data |
analysis of data supplied |
of data supplied by |
data supplied by measurement |
supplied by measurement devices |
the full scale evaluation |
many inconsistencies with only |
full scale evaluation of |
inconsistencies with only nominal |
with only nominal overhead |
yet the clients being |
scale evaluation of multiple |
the clients being tracked |
evaluation of multiple services |
we use synthetic workloads |
clients being tracked are |
of multiple services deployed |
use synthetic workloads to |
synthetic workloads to demonstrate |
multiple services deployed and |
services deployed and running |
workloads to demonstrate the |
to demonstrate the efficacy |
deployed and running at |
and running at the |
demonstrate the efficacy of |
the efficacy of t |
running at the same |
at the same time |
being tracked are unwilling |
tracked are unwilling to |
are unwilling to reveal |
cache when data accesses |
unwilling to reveal such |
when data accesses are |
the ssa currently runs |
to reveal such measurement |
data accesses are clustered |
ssa currently runs on |
reveal such measurement data |
such measurement data directly |
measurement data directly to |
data directly to the |
directly to the system |
to the system owner |
currently runs on a |
accesses are clustered and |
runs on a tightly |
are clustered and its |
on a tightly coupled |
a tightly coupled cluster |
clustered and its adaptive |
and its adaptive reaction |
tightly coupled cluster of |
coupled cluster of blade |
cluster of blade servers |
who might be curious |
might be curious about |
be curious about private |
curious about private client |
about private client information |
we show that developers |
its adaptive reaction to |
show that developers can |
adaptive reaction to workload |
that developers can tune |
these systems thus may |
reaction to workload changes |
developers can tune parameters |
systems thus may elicit |
can tune parameters to |
thus may elicit public |
with workloads based on |
tune parameters to trade |
may elicit public opposition |
workloads based on the |
based on the real |
elicit public opposition despite |
parameters to trade overhead |
public opposition despite their |
to trade overhead for |
opposition despite their useful |
despite their useful features |
their useful features because |
useful features because of |
features because of a |
because of a perceived |
of a perceived privacy |
a perceived privacy risk |
trade overhead for speed |
overhead for speed of |
for speed of repair |
speed of repair and |
there are ways to |
of repair and we |
repair and we believe |
are ways to upload |
and we believe that |
we believe that our |
believe that our results |
that our results validate |
our results validate the |
results validate the approach |
ways to upload sensitive |
to upload sensitive data |
upload sensitive data to |
sensitive data to an |
of the inconsistencies and |
data to an aggregator |
to an aggregator without |
an aggregator without compromising |
aggregator without compromising privacy |
application model our work |
the inconsistencies and increases |
model our work focuses |
inconsistencies and increases the |
and increases the rate |
our work focuses on |
but existing options have |
existing options have limitations |
work focuses on datacenters |
increases the rate of |
focuses on datacenters supporting |
the rate of consistent |
rate of consistent transactions |
on datacenters supporting one |
one possibility is to |
of consistent transactions by |
datacenters supporting one or |
possibility is to keep |
supporting one or more |
is to keep the |
one or more services |
to keep the data |
keep the data encrypted |
the data encrypted with |
data encrypted with keys |
encrypted with keys known |
with keys known only |
keys known only to |
known only to the |
only to the clients |
or more services deployed |
more services deployed within |
services deployed within a |
deployed within a cluster |
within a cluster of |
a cluster of compute |
cluster of compute nodes |
but this requires expensive |
this requires expensive homomorphic |
yet the issue remains |
the issue remains unresolved |
requires expensive homomorphic encryption |
expensive homomorphic encryption if |
homomorphic encryption if the |
encryption if the aggregator |
if the aggregator is |
the aggregator is to |
aggregator is to compute |
is to compute directly |
tailer might implement a |
might implement a front |
i ntroduction internet services |
to compute directly on |
compute directly on it |
ntroduction internet services like |
end service that builds |
internet services like online |
service that builds web |
that builds web pages |
another is to employ |
is to employ a |
to employ a mechanism |
employ a mechanism to |
a mechanism to de |
services like online retailers |
cornell s live distributed |
parallelizing the task by |
correlate client identifiers from |
client identifiers from their |
identifiers from their data |
the task by dispatching |
task by dispatching sub |
like online retailers and |
s live distributed objects |
live distributed objects platform |
online retailers and social |
tasks to services to |
to services to rank |
retailers and social networks |
as chen et al |
services to rank product |
and social networks store |
to rank product popularity |
social networks store important |
networks store important data |
store important data sets |
important data sets in |
data sets in large |
sets in large distributed |
in large distributed databases |
live objects for short |
but this imposes restrictions |
technical challenges have forced |
allow even a non |
challenges have forced such |
have forced such large |
this imposes restrictions on |
imposes restrictions on the |
restrictions on the kind |
programmer to construct content |
system operators to forgo |
operators to forgo transactional |
to forgo transactional consistency |
on the kind of |
end service would probably |
service would probably just |
would probably just be |
probably just be cloned |
providing perobject consistency instead |
the kind of aggregation |
kind of aggregation that |
of aggregation that can |
with identical replicas that |
identical replicas that build |
rich solutions that blend |
often with some form |
with some form of |
replicas that build pages |
solutions that blend traditional |
that blend traditional web |
some form of eventual |
form of eventual consistency |
blend traditional web services |
traditional web services and |
web services and peer |
end services might be |
aggregation that can be |
that can be done |
services might be partitioned |
might be partitioned into |
be partitioned into subservices |
partitioned into subservices for |
into subservices for scalability |
subservices for scalability using |
for scalability using some |
scalability using some key |
it would be beneficial |
and to share them |
to share them with |
share them with others |
would be beneficial to |
be beneficial to execute |
beneficial to execute needed |
to execute needed computation |
execute needed computation directly |
needed computation directly on |
computation directly on the |
directly on the client |
on the client platforms |
this is like creating |
is like creating a |
like creating a slide |
and subservices cloned for |
so that the system |
creating a slide show |
subservices cloned for faulttolerance |
cloned for faulttolerance and |
for faulttolerance and load |
that the system operator |
the system operator or |
system operator or analyst |
operator or analyst only |
or analyst only sees |
analyst only sees aggregate |
only sees aggregate results |
this is a common |
is a common model |
this approach would provide |
after which the solution |
approach would provide a |
which the solution can |
would provide a better |
jim gray and others |
the solution can be |
provide a better alternative |
a better alternative to |
better alternative to central |
alternative to central aggregation |
to central aggregation provided |
central aggregation provided it |
aggregation provided it is |
provided it is privacy |
solution can be shared |
gray and others have |
support transactions with guarantees |
can be shared in |
and others have suggested |
transactions with guarantees such |
be shared in a |
others have suggested that |
with guarantees such as |
shared in a file |
have suggested that such |
guarantees such as snapshot |
in a file or |
suggested that such a |
such as snapshot isolation |
a file or via |
file or via email |
that such a system |
as snapshot isolation and |
snapshot isolation and even |
or via email and |
such a system be |
a data aggregation system |
data aggregation system based |
aggregation system based on |
system based on client |
isolation and even full |
via email and opened |
a system be termed |
and even full transactional |
email and opened on |
and opened on other |
opened on other machines |
even full transactional atomicity |
side computation suggests a |
computation suggests a purely |
suggests a purely peer |
system be termed a |
our work begins with |
the users are immersed |
be termed a farm |
work begins with the |
users are immersed in |
termed a farm consisting |
begins with the observation |
are immersed in the |
a farm consisting of |
with the observation that |
immersed in the resulting |
farm consisting of raps |
in the resulting collaborative |
the resulting collaborative application |
reliable array of partitioned |
array of partitioned services |
it can be difficult |
they can interact with |
can be difficult for |
can interact with the |
be difficult for client |
interact with the application |
with the application and |
which many systems have |
many systems have used |
systems have used to |
have used to avoid |
used to avoid centralized |
to avoid centralized control |
the application and peers |
tier applications to leverage |
reliable array of cloned |
application and peers see |
applications to leverage the |
array of cloned server |
and peers see the |
to leverage the transactions |
of cloned server processes |
peers see the results |
see the results instantly |
leverage the transactions that |
the transactions that the |
transactions that the databases |
that the databases provide |
updates are applied to |
are applied to all |
applied to all replicas |
to all replicas in |
their reads are satisfied |
all replicas in a |
reads are satisfied primarily |
replicas in a consistent |
are satisfied primarily from |
in a consistent manner |
satisfied primarily from incoherent |
primarily from incoherent cache |
the benefits of caching |
benefits of caching are |
of caching are twofold |
in contrast to today |
contrast to today s |
to today s web |
today s web service |
s web service platforms |
up to the present |
it reduces database load |
peer systems have problems |
systems have problems of |
have problems of their |
problems of their own |
this structure has arisen |
p communication can coexist |
thereby enabling higher throughput |
even if we set |
if we set privacy |
we set privacy concerns |
set privacy concerns aside |
structure has arisen mostly |
communication can coexist with |
has arisen mostly in |
can coexist with more |
the caches are typically |
arisen mostly in very |
by eschewing centralization entirely |
coexist with more standard |
caches are typically placed |
mostly in very large |
with more standard solutions |
are typically placed close |
in very large datacenters |
they can no longer |
more standard solutions that |
typically placed close to |
very large datacenters and |
can no longer take |
standard solutions that reach |
placed close to the |
large datacenters and is |
no longer take advantage |
solutions that reach back |
close to the clients |
datacenters and is supported |
and is supported primarily |
that reach back to |
longer take advantage of |
is supported primarily in |
reach back to the |
take advantage of the |
the problem centers on |
back to the hosted |
supported primarily in the |
primarily in the context |
in the context of |
to the hosted content |
advantage of the powerful |
problem centers on the |
the context of three |
the hosted content and |
of the powerful management |
centers on the asynchronous |
hosted content and trigger |
the powerful management tools |
powerful management tools developed |
management tools developed for |
tools developed for today |
developed for today s |
for today s cloud |
today s cloud computing |
content and trigger updates |
s cloud computing model |
on the asynchronous style |
and trigger updates at |
we believe that similar |
the asynchronous style of |
trigger updates at the |
believe that similar architectures |
asynchronous style of communication |
updates at the associated |
that similar architectures will |
style of communication used |
at the associated data |
similar architectures will be |
of communication used between |
the associated data centers |
clients are isolated network |
architectures will be needed |
communication used between the |
used between the database |
will be needed more |
be needed more widely |
between the database and |
the database and the |
database and the geo |
are isolated network hosts |
isolated network hosts rather |
network hosts rather than |
because the need to |
the need to tolerate |
when an application needs |
an application needs high |
need to tolerate heavy |
to tolerate heavy loads |
application needs high data |
a cache should not |
hosts rather than devices |
rather than devices within |
than devices within a |
devices within a single |
within a single administrative |
a single administrative domain |
cache should not access |
tolerate heavy loads is |
needs high data rates |
should not access the |
heavy loads is increasingly |
loads is increasingly ubiquitous |
not access the database |
access the database on |
the database on every |
database on every transaction |
and often have difficulty |
and economic considerations favor |
economic considerations favor clustered |
considerations favor clustered solutions |
often have difficulty maintaining |
any approach requiring a |
approach requiring a high |
it can use protocols |
have difficulty maintaining connections |
requiring a high rate |
can use protocols that |
difficulty maintaining connections to |
a high rate of |
high rate of round |
use protocols that bypass |
maintaining connections to each |
game servers require scalability |
protocols that bypass the |
connections to each other |
servers require scalability for |
trips to an authoritative |
that bypass the data |
to each other through |
each other through firewalls |
other through firewalls and |
through firewalls and address |
firewalls and address translation |
and address translation barriers |
bypass the data center |
require scalability for situations |
to an authoritative backend |
the data center to |
scalability for situations in |
for situations in which |
an authoritative backend database |
data center to achieve |
center to achieve the |
situations in which there |
authoritative backend database would |
backend database would cause |
to achieve the full |
in which there are |
which there are many |
there are many users |
achieve the full performance |
the full performance of |
database would cause unacceptable |
would cause unacceptable latency |
full performance of the |
performance of the network |
military systems require scalability |
determining the membership of |
a cache must respond |
cache must respond instantly |
this paper makes the |
paper makes the following |
makes the following contributions |
the membership of a |
membership of a peer |
systems require scalability to |
and asynchronous updates rule |
require scalability to support |
we describe a new |
describe a new class |
scalability to support new |
peer network is a |
network is a surprisingly |
is a surprisingly difficult |
a surprisingly difficult problem |
a new class of |
new class of service |
to support new generations |
asynchronous updates rule out |
support new generations of |
new generations of integrated |
updates rule out cache |
since there is no |
generations of integrated applications |
rule out cache coherency |
there is no one |
out cache coherency schemes |
is no one entity |
applications that integrate service |
cache coherency schemes that |
hospital automation is putting |
no one entity that |
one entity that knows |
entity that knows the |
that knows the identities |
knows the identities of |
the identities of all |
identities of all the |
of all the clients |
coherency schemes that would |
automation is putting new |
that integrate service hosted |
schemes that would require |
is putting new demands |
integrate service hosted content |
service hosted content with |
hosted content with peer |
putting new demands on |
new demands on medical |
that would require the |
and changes in membership |
demands on medical information |
would require the backend |
changes in membership may |
on medical information subsystems |
require the backend database |
in membership may not |
we analyze two important |
analyze two important examples |
the backend database to |
membership may not be |
may not be detected |
not be detected and |
be detected and propagated |
backend database to promptly |
two important examples of |
important examples of soc |
in a wide range |
database to promptly invalidate |
detected and propagated in |
and propagated in a |
propagated in a timely |
in a timely fashion |
examples of soc applications |
a wide range of |
to promptly invalidate or |
wide range of everyday |
promptly invalidate or update |
range of everyday settings |
invalidate or update cached |
search and rescue mission |
or update cached this |
and rescue mission and |
update cached this work |
the rollout of soas |
without a centralized service |
a centralized service to |
centralized service to assign |
service to assign and |
to assign and manage |
assign and manage node |
and manage node identities |
cached this work is |
rescue mission and virtual |
rollout of soas and |
this work is supported |
mission and virtual worlds |
of soas and the |
soas and the ease |
and the ease of |
the ease of application |
ease of application integration |
of application integration they |
application integration they support |
integration they support will |
they support will place |
by a grant from |
support will place services |
a grant from the |
will place services under |
grant from the darpa |
place services under growing |
we list the key |
from the darpa mrc |
the darpa mrc program |
list the key challenges |
services under growing load |
peer system is extremely |
the key challenges that |
system is extremely vulnerable |
key challenges that soc |
is extremely vulnerable to |
our goal is to |
challenges that soc applications |
or even to track |
extremely vulnerable to a |
goal is to make |
that soc applications place |
even to track the |
vulnerable to a few |
is to make it |
soc applications place on |
to track the locations |
to a few malicious |
to make it easy |
applications place on their |
track the locations at |
the locations at which |
make it easy to |
place on their runtime |
on their runtime environments |
locations at which cached |
it easy to build |
a few malicious peers |
at which cached objects |
easy to build raps |
to build raps and |
we describe a new |
which cached objects reside |
few malicious peers becoming |
build raps and racs |
describe a new class |
a new class of |
new class of multi |
malicious peers becoming a |
we define a variant |
raps and racs from |
and racs from traditional |
layered mashups and contrast |
mashups and contrast them |
define a variant of |
peers becoming a majority |
becoming a majority of |
a majority of the |
majority of the apparent |
of the apparent nodes |
the apparent nodes in |
apparent nodes in the |
nodes in the system |
a variant of serializability |
and contrast them with |
web service applications designed |
even choosing peers fairly |
choosing peers fairly becomes |
peers fairly becomes difficult |
service applications designed for |
contrast them with more |
them with more traditional |
applications designed for quick |
variant of serializability called |
because peers usually do |
peers usually do not |
designed for quick responsiveness |
of serializability called cacheserializability |
usually do not store |
do not store the |
based approach to building |
approach to building mashups |
serializability called cacheserializability that |
called cacheserializability that is |
cacheserializability that is suitable |
we also want to |
that is suitable for |
is suitable for incoherent |
suitable for incoherent caches |
also want to build |
not store the entire |
store the entire membership |
the entire membership list |
entire membership list locally |
want to build the |
a wide range of |
characteristic of today s |
to build the simplest |
and it is fairly |
of today s web |
today s web development |
build the simplest platform |
the simplest platform capable |
wide range of web |
range of web applications |
simplest platform capable of |
platform capable of accomplishing |
we discuss the relative |
it is fairly easy |
from social networks to |
discuss the relative advantages |
capable of accomplishing this |
of accomplishing this task |
social networks to online |
the relative advantages of |
is fairly easy for |
networks to online retailers |
relative advantages of these |
fairly easy for malicious |
advantages of these two |
of these two approaches |
these two approaches for |
settle for caches that |
a set of racs |
two approaches for building |
for caches that are |
caches that are oblivious |
approaches for building soc |
for building soc applications |
that are oblivious to |
are oblivious to transactions |
easy for malicious peers |
for malicious peers to |
we discuss the advantages |
malicious peers to poison |
discuss the advantages of |
despite the fact that |
peers to poison local |
the advantages of decoupling |
the fact that an |
to poison local mem |
advantages of decoupling transport |
fact that an inconsistent |
poison local mem cornell |
of decoupling transport and |
that an inconsistent read |
local mem cornell bership |
decoupling transport and information |
an inconsistent read access |
mem cornell bership views |
transport and information layers |
inconsistent read access can |
cornell bership views so |
and information layers as |
read access can deter |
access can deter a |
information layers as a |
layers as a means |
can deter a client |
deter a client and |
as a means of |
a means of achieving |
a client and reduce |
client and reduce their |
means of achieving reusability |
bership views so that |
and reduce their income |
views so that they |
so that they will |
that they will be |
they will be preferred |
will be preferred as |
be preferred as neighbors |
preferred as neighbors by |
ability to rapidly deploy |
as neighbors by honest |
neighbors by honest nodes |
to rapidly deploy soc |
they cannot afford consistent |
rapidly deploy soc applications |
cannot afford consistent cache |
deploy soc applications in |
afford consistent cache techniques |
soc applications in new |
gossip traffic chain figure |
consistent cache techniques that |
applications in new environments |
cache techniques that require |
in new environments and |
techniques that require backend |
new environments and adapt |
that require backend accesses |
environments and adapt them |
require backend accesses on |
and adapt them dynamically |
backend accesses on every |
adapt them dynamically this |
accesses on every transaction |
them dynamically this work |
dynamically this work was |
this work was supported |
since neither completely centralized |
neither completely centralized aggregation |
completely centralized aggregation nor |
centralized aggregation nor a |
aggregation nor a completely |
nor a completely peer |
elements of the model |
of the model a |
a novel caching scheme |
the model a service |
novel caching scheme that |
model a service is |
caching scheme that improves |
peer system is adequate |
system is adequate for |
is adequate for our |
adequate for our purposes |
scheme that improves consistency |
a service is simply |
qi huang is a |
that improves consistency at |
service is simply an |
we explore a new |
huang is a visiting |
improves consistency at the |
is simply an application |
explore a new approach |
is a visiting scientist |
consistency at the cache |
simply an application that |
a new approach that |
a visiting scientist from |
at the cache level |
an application that provides |
new approach that combines |
approach that combines the |
that combines the features |
combines the features of |
the features of these |
features of these two |
of these two extremes |
visiting scientist from the |
the cache level with |
application that provides interfaces |
scientist from the school |
cache level with a |
that provides interfaces that |
provides interfaces that manipulate |
from the school of |
level with a nominal |
with a nominal storage |
interfaces that manipulate objects |
the school of computer |
school of computer sci |
a nominal storage and |
that manipulate objects of |
manipulate objects of unspecified |
objects of unspecified nature |
although the idea of |
nominal storage and communication |
storage and communication tradeoff |
huazhong university of sci |
a query operation reads |
the idea of a |
query operation reads some |
operation reads some object |
reads some object and |
some object and returns |
object and returns a |
cache significantly improves consistency |
and returns a computed |
returns a computed value |
supported by the chinese |
by the chinese nsfc |
idea of a communication |
significantly improves consistency for |
of a communication system |
an update operation modifies |
improves consistency for workloads |
consistency for workloads where |
update operation modifies one |
operation modifies one or |
for workloads where data |
workloads where data accesses |
modifies one or more |
one or more objects |
where data accesses are |
data accesses are clustered |
a communication system that |
communication system that combines |
system that combines some |
one unusual assumption made |
that combines some centralized |
combines some centralized control |
some centralized control with |
centralized control with a |
control with a peer |
which is common in |
unusual assumption made in |
is common in today |
assumption made in our |
common in today s |
made in our work |
in today s large |
peer overlay is not |
overlay is not new |
in our work is |
our work is that |
work is that many |
is that many services |
that many services can |
many services can process |
services can process updates |
this is achieved while |
can process updates out |
process updates out of |
updates out of order |
we are the first |
is achieved while retaining |
are the first to |
achieved while retaining the |
while retaining the global |
the first to use |
retaining the global scalability |
the global scalability afforded |
we focus on services |
first to use such |
global scalability afforded by |
focus on services that |
to use such a |
scalability afforded by executing |
on services that can |
use such a system |
afforded by executing read |
services that can respond |
such a system to |
a system to preserve |
system to preserve privacy |
only transactions on the |
layered mashup to the |
mashup to the changing |
to the changing needs |
transactions on the edge |
to preserve privacy while |
preserve privacy while computing |
privacy while computing on |
while computing on sensitive |
computing on sensitive data |
we discuss the resulting |
that can respond correctly |
directly from the cache |
discuss the resulting objectoriented |
the resulting objectoriented perspective |
this combination is a |
can respond correctly to |
combination is a sensible |
is a sensible tradeoff |
in which instances of |
we do this by |
a sensible tradeoff for |
sensible tradeoff for the |
tradeoff for the kinds |
for the kinds of |
the kinds of systems |
kinds of systems we |
of systems we target |
respond correctly to queries |
which instances of distributed |
do this by storing |
correctly to queries even |
instances of distributed communication |
this by storing dependency |
by storing dependency information |
to queries even if |
of distributed communication protocols |
in which there is |
storing dependency information with |
queries even if some |
distributed communication protocols are |
which there is an |
dependency information with the |
even if some updates |
communication protocols are modeled |
there is an owner |
information with the cached |
with the cached objects |
protocols are modeled uniformly |
are modeled uniformly as |
if some updates are |
some updates are temporarily |
modeled uniformly as objects |
uniformly as objects similar |
updates are temporarily missing |
is an owner or |
as objects similar to |
objects similar to those |
similar to those in |
to those in java |
converge into a state |
to identify possible inconsistencies |
an owner or operator |
into a state determined |
identify possible inconsistencies without |
possible inconsistencies without contacting |
a state determined entirely |
state determined entirely by |
inconsistencies without contacting the |
without contacting the database |
determined entirely by the |
entirely by the set |
by the set of |
the set of updates |
owner or operator who |
the user can improve |
the embedded script is |
or operator who can |
so that if two |
embedded script is often |
user can improve the |
operator who can be |
that if two members |
script is often tightly |
can improve the level |
who can be trusted |
if two members of |
is often tightly integrated |
improve the level of |
can be trusted to |
two members of some |
often tightly integrated with |
the level of consistency |
be trusted to provide |
members of some subservice |
tightly integrated with backend |
level of consistency by |
trusted to provide basic |
of some subservice receive |
integrated with backend services |
of consistency by adjusting |
to provide basic services |
some subservice receive the |
with backend services in |
consistency by adjusting the |
by adjusting the size |
subservice receive the same |
backend services in the |
services in the data |
in the data center |
receive the same updates |
provide basic services such |
adjusting the size of |
the same updates they |
making it awkward to |
the size of this |
same updates they will |
updates they will be |
it awkward to access |
size of this dependency |
of this dependency data |
they will be in |
awkward to access the |
basic services such as |
will be in equivalent |
more dependency data leads |
dependency data leads to |
be in equivalent states |
to access the underlying |
services such as node |
data leads to increased |
access the underlying services |
such as node identification |
leads to increased consistency |
even if those updates |
the underlying services directly |
as node identification and |
if those updates were |
underlying services directly from |
node identification and membership |
identification and membership tracking |
and membership tracking but |
membership tracking but not |
tracking but not to |
but not to see |
not to see non |
to demonstrate the efficacy |
those updates were delivered |
services directly from a |
demonstrate the efficacy of |
aggregated raw client data |
directly from a different |
updates were delivered in |
the efficacy of the |
from a different script |
were delivered in different |
efficacy of the proposed |
a different script or |
delivered in different orders |
of the proposed scheme |
we treat the system |
treat the system operator |
the system operator as |
system operator as an |
operator as an honest |
we created a prototype |
different script or a |
created a prototype implementation |
script or a standalone |
a reissued query or |
a prototype implementation and |
or a standalone client |
reissued query or update |
prototype implementation and exposed |
query or update returns |
implementation and exposed it |
or update returns an |
update returns an equivalent |
and exposed it to |
exposed it to workloads |
returns an equivalent result |
the only way such |
it to workloads based |
to workloads based on |
workloads based on graphically |
who will keep the |
what this amounts to |
only way such services |
will keep the system |
this amounts to is |
way such services can |
keep the system running |
amounts to is that |
such services can be |
the system running correctly |
to is that the |
services can be mashed |
such as those seen |
as those seen in |
those seen in social |
can be mashed up |
system running correctly but |
is that the ssa |
be mashed up with |
running correctly but cannot |
that the ssa should |
mashed up with other |
correctly but cannot be |
the ssa should deliver |
up with other web |
but cannot be allowed |
ssa should deliver updates |
with other web content |
cannot be allowed to |
should deliver updates as |
other web content is |
be allowed to see |
deliver updates as soon |
web content is by |
allowed to see more |
to see more information |
see more information than |
more information than he |
information than he or |
than he or she |
he or she needs |
or she needs to |
she needs to know |
updates as soon as |
content is by either |
of the inconsistencies and |
as soon as it |
is by either having |
the inconsistencies and can |
soon as it can |
by either having the |
inconsistencies and can increase |
as it can even |
either having the data |
and can increase the |
it can even if |
having the data center |
can increase the ratio |
can even if they |
the data center compute |
increase the ratio of |
even if they are |
data center compute the |
the ratio of consistent |
if they are not |
they are not in |
are not in order |
ratio of consistent transactions |
center compute the mashup |
we introduce a method |
of consistent transactions by |
introduce a method for |
a method for constructing |
so that it can |
that it can be |
one way that an |
method for constructing a |
it can be accessed |
way that an application |
for constructing a communication |
can be accessed via |
that an application might |
constructing a communication overlay |
be accessed via the |
an application might process |
a communication overlay among |
accessed via the minibrowser |
application might process out |
communication overlay among the |
might process out of |
overlay among the client |
both with low overhead |
process out of order |
among the client nodes |
out of order updates |
or by embedding the |
the client nodes that |
we construct synthetic workloads |
of order updates is |
by embedding the entire |
embedding the entire minibrowser |
construct synthetic workloads and |
order updates is simply |
client nodes that can |
the entire minibrowser window |
synthetic workloads and observe |
updates is simply to |
nodes that can safely |
entire minibrowser window in |
workloads and observe how |
and observe how t |
that can safely be |
minibrowser window in a |
is simply to delay |
can safely be used |
window in a web |
in a web page |
cache reacts to different |
safely be used to |
be used to perform |
reacts to different clustering |
but an embedded minibrowser |
used to perform aggregation |
to perform aggregation and |
perform aggregation and computation |
aggregation and computation on |
and computation on private |
computation on private data |
an embedded minibrowser can |
simply to delay processing |
to different clustering levels |
embedded minibrowser can t |
although this overlay is |
this overlay is set |
overlay is set up |
is set up and |
set up and operated |
up and operated by |
and operated by the |
operated by the system |
by the system owner |
minibrowser can t seamlessly |
different clustering levels and |
to delay processing them |
can t seamlessly blend |
clustering levels and how |
delay processing them until |
processing them until it |
t seamlessly blend with |
levels and how it |
and how it adapts |
them until it can |
seamlessly blend with the |
blend with the surrounding |
how it adapts as |
until it can sort |
it can sort them |
can sort them into |
sort them into order |
it provides minimal opportunity |
with the surrounding content |
it adapts as clusters |
adapts as clusters change |
provides minimal opportunity for |
but we believe that |
we believe that for |
it is like a |
is like a standalone |
believe that for many |
that for many uses |
minimal opportunity for the |
like a standalone browser |
with perfectly clustered workloads |
opportunity for the owner |
a standalone browser within |
it will be possible |
for the owner to |
standalone browser within its |
will be possible to |
cache implements full cache |
browser within its own |
within its own frame |
be possible to act |
the owner to learn |
possible to act on |
owner to learn any |
to act on an |
and runs independent of |
runs independent of the |
to explain this perfect |
act on an update |
on an update or |
independent of the rest |
explain this perfect behavior |
to learn any information |
an update or query |
of the rest of |
this perfect behavior we |
learn any information about |
update or query immediately |
the rest of the |
perfect behavior we prove |
any information about the |
or query immediately upon |
rest of the page |
behavior we prove a |
information about the data |
query immediately upon receiving |
we prove a related |
about the data being |
immediately upon receiving it |
to illustrate this point |
prove a related claim |
the data being aggregated |
a related claim we |
data being aggregated other |
the ssa can support |
ssa can support raps |
being aggregated other than |
related claim we show |
claim we show that |
we show that with |
show that with unbounded |
that with unbounded resources |
with unbounded resources t |
aggregated other than the |
other than the final |
than the final result |
the final result of |
final result of the |
result of the computation |
the figures are screenshots |
a raps of racs |
figures are screenshots of |
are screenshots of web |
screenshots of web applications |
when combined with differential |
combined with differential privacy |
with differential privacy techniques |
a service that can |
with content from multiple |
service that can be |
the contributions of this |
content from multiple sources |
from multiple sources mashed |
that can be structured |
contributions of this work |
can be structured as |
of this work are |
to protect the aggregation |
protect the aggregation results |
the aggregation results themselves |
be structured as a |
structured as a raps |
as a raps must |
it can be used |
was constructed using a |
a raps must have |
can be used to |
constructed using a standard |
raps must have a |
be used to ensure |
using a standard web |
must have a partitioning |
have a partitioning function |
a standard web services |
a variant of serializability |
variant of serializability suitable |
a partitioning function that |
standard web services approach |
used to ensure that |
of serializability suitable for |
partitioning function that can |
pulling content from the |
content from the yahoo |
to ensure that no |
function that can be |
serializability suitable for incoherent |
suitable for incoherent caches |
maps and weather web |
ensure that no query |
that can be used |
and weather web services |
that no query made |
can be used to |
weather web services and |
no query made to |
be used to map |
web services and assembling |
query made to the |
used to map each |
services and assembling it |
and assembling it into |
to map each operation |
made to the system |
which allows trading off |
map each operation to |
each operation to the |
assembling it into a |
allows trading off efficiency |
trading off efficiency and |
operation to the subservice |
it into a web |
into a web page |
off efficiency and transaction |
to the subservice that |
the subservice that should |
a web page as |
web page as a |
subservice that should execute |
that should execute it |
page as a set |
consistency in large scale |
in large scale cache |
large scale cache deployments |
to the system reveals |
existing systems typically implement |
as a set of |
a set of tiled |
set of tiled frames |
the system reveals the |
system reveals the contribution |
reveals the contribution of |
the contribution of any |
contribution of any particular |
of any particular node |
each frame is a |
systems typically implement partitioning |
frame is a minibrowser |
typically implement partitioning functions |
is a minibrowser with |
cache with synthetic workloads |
implement partitioning functions in |
partitioning functions in one |
a minibrowser with its |
minibrowser with its own |
functions in one of |
in one of two |
one of two ways |
demonstrating its adaptivity and |
its adaptivity and sensitivity |
with its own interactive |
its own interactive controls |
adaptivity and sensitivity to |
and sensitivity to clustering |
our overlay network looks |
overlay network looks a |
network looks a bit |
looks a bit like |
a bit like a |
bit like a gossip |
like a gossip infrastructure |
the service exports its |
and comes from a |
service exports its partitioning |
comes from a single |
exports its partitioning function |
from a single content |
a single content source |
cache with workloads based |
to illustrate one of |
so that clients are |
with workloads based on |
and can be used |
can be used to |
be used to run |
used to run gossip |
that clients are able |
illustrate one of the |
workloads based on graphically |
clients are able to |
one of the many |
are able to locally |
of the many restrictions |
able to locally implement |
to locally implement the |
with the key difference |
locally implement the logic |
implement the logic mapping |
if the user pans |
world data demonstrating detection |
data demonstrating detection rates |
the logic mapping requests |
the user pans or |
user pans or zooms |
demonstrating detection rates of |
logic mapping requests to |
mapping requests to subservices |
pans or zooms in |
or zooms in the |
zooms in the map |
in the map frame |
the key difference that |
key difference that the |
difference that the random |
the cluster might control |
cluster might control the |
might control the dns |
the associated map will |
associated map will shift |
map will shift or |
will shift or zoom |
that the random peer |
or could influence the |
the random peer selection |
and consistency improvements of |
could influence the creation |
but the other frames |
random peer selection of |
influence the creation of |
the other frames remain |
peer selection of gossip |
the creation of web |
other frames remain as |
selection of gossip is |
of gossip is replaced |
frames remain as they |
creation of web pages |
of web pages by |
remain as they were |
as they were the |
web pages by modifying |
pages by modifying urls |
they were the frames |
were the frames are |
the frames are not |
frames are not synchronized |
gossip is replaced with |
is replaced with a |
replaced with a completely |
with a completely deterministic |
a completely deterministic function |
so that clients will |
that clients will be |
clients will be directed |
will be directed to |
be directed to an |
directed to an appropriate |
to an appropriate subservice |
nodes are assigned virtual |
here we see a |
cache with unbounded resources |
with unbounded resources implements |
unbounded resources implements cache |
are assigned virtual ids |
we see a similar |
see a similar application |
the servers might export |
servers might export actual |
a similar application constructed |
similar application constructed using |
might export actual code |
export actual code that |
application constructed using live |
constructed using live objects |
actual code that the |
code that the client |
that the client runs |
assigned virtual ids that |
virtual ids that are |
ids that are either |
that are either integers |
are either integers or |
either integers or finite |
integers or finite field |
or finite field elements |
content from different sources |
the complexity of implementing |
the partitioning logic is |
from different sources is |
complexity of implementing geo |
partitioning logic is situated |
and each node uses |
different sources is overlaid |
logic is situated on |
scale databases with strong |
sources is overlaid in |
is overlaid in the |
is situated on a |
databases with strong guarantees |
each node uses a |
overlaid in the same |
situated on a load |
with strong guarantees initially |
strong guarantees initially led |
in the same window |
on a load balancing |
node uses a function |
guarantees initially led companies |
the same window and |
a load balancing component |
load balancing component resident |
initially led companies to |
same window and synchronized |
uses a function based |
balancing component resident in |
led companies to abandon |
companies to abandon cross |
component resident in the |
resident in the server |
we used white backgrounds |
a function based on |
in the server cluster |
used white backgrounds to |
object consistency altogether and |
function based on either |
white backgrounds to highlight |
the load balancer sprays |
based on either modular |
consistency altogether and make |
backgrounds to highlight the |
load balancer sprays requests |
on either modular arithmetic |
altogether and make do |
to highlight the contributions |
balancer sprays requests over |
either modular arithmetic or |
and make do with |
highlight the contributions of |
sprays requests over the |
modular arithmetic or finite |
make do with weak |
the contributions of different |
requests over the subservices |
over the subservices in |
do with weak guarantees |
contributions of different sources |
arithmetic or finite fields |
the subservices in accordance |
with weak guarantees such |
weak guarantees such as |
subservices in accordance with |
but there are no |
there are no frame |
are no frame boundaries |
in accordance with server |
accordance with server logic |
guarantees such as per |
or finite fields to |
elements of this mashup |
the ssa supports the |
ssa supports the latter |
supports the latter approach |
object atomicity or eventual |
atomicity or eventual consistency |
which can include map |
can include map layers |
finite fields to compute |
offering a mechanism that |
a mechanism that assists |
mechanism that assists the |
that assists the load |
tables showing buildings or |
such systems do repair |
showing buildings or points |
buildings or points of |
or points of interest |
balancing component in tracking |
systems do repair any |
do repair any problems |
component in tracking membership |
icons representing severe weather |
repair any problems that |
any problems that arise |
in tracking membership so |
representing severe weather reports |
fields to compute the |
tracking membership so that |
to compute the order |
membership so that it |
compute the order in |
so that it can |
that it can appropriately |
it can appropriately route |
user is sometimes exposed |
can appropriately route queries |
appropriately route queries and |
route queries and updates |
the order in which |
is sometimes exposed to |
sometimes exposed to inconsistency |
order in which it |
in which it should |
which it should communicate |
it should communicate with |
should communicate with the |
we assume that processes |
for some applications this |
some applications this is |
applications this is acceptable |
assume that processes are |
that processes are fail |
exist layers within which |
communicate with the other |
with the other nodes |
and the approach has |
layers within which the |
the approach has been |
within which the end |
approach has been surprisingly |
should a failure occur |
we construct this function |
which the end user |
has been surprisingly successful |
construct this function to |
the end user can |
end user can easily |
user can easily navigate |
in today s cloud |
and will eventually be |
will eventually be detected |
eventually be detected as |
be detected as faulty |
this function to ensure |
data can come from |
relaxed consistency is something |
consistency is something of |
is something of a |
something of a credo |
can come from many |
function to ensure that |
to ensure that the |
ensure that the network |
that the network is |
the network is optimally |
network is optimally robust |
is optimally robust and |
optimally robust and efficient |
come from many kinds |
a failure may be |
failure may be transient |
from many kinds of |
converging in logarithmic time |
in logarithmic time and |
logarithmic time and tolerating |
a process can become |
process can become temporarily |
can become temporarily unavailable |
time and tolerating message |
and tolerating message failures |
tolerating message failures with |
message failures with minimal |
failures with minimal delay |
but then restart and |
many kinds of we |
then restart and recover |
kinds of we discuss |
restart and recover any |
only transactions by accessing |
of we discuss our |
key cryptography to encrypt |
cryptography to encrypt messages |
and recover any missing |
we discuss our live |
transactions by accessing caches |
recover any missing updates |
discuss our live distributed |
ensuring that the the |
our live distributed objects |
that the the system |
which receive their values |
live distributed objects platform |
the the system operator |
receive their values by |
distributed objects platform as |
the system operator cannot |
their values by reading |
objects platform as an |
system operator cannot infer |
values by reading from |
platform as an example |
discussion our model is |
our model is not |
by reading from the |
as an example of |
operator cannot infer anything |
model is not completely |
reading from the database |
an example of a |
cannot infer anything about |
is not completely general |
example of a technology |
of a technology that |
a technology that fits |
technology that fits well |
that fits well with |
fits well with the |
well with the layered |
infer anything about the |
and for this reason |
update transactions go directly |
transactions go directly to |
componentized model we derived |
model we derived through |
for this reason some |
go directly to the |
directly to the database |
we derived through our |
this reason some discussion |
reason some discussion is |
derived through our analysis |
anything about the data |
some discussion is needed |
about the data being |
we compare performance of |
compare performance of hosted |
performance of hosted enterprise |
consider the following example |
of hosted enterprise service |
hosted enterprise service bus |
subsequent cache invalidations can |
the data being aggregated |
data being aggregated by |
being aggregated by observing |
aggregated by observing network |
by observing network traffic |
we wish to support |
cache invalidations can be |
wish to support a |
invalidations can be delayed |
to support a scalable |
even the communication pattern |
can be delayed or |
support a scalable inventory |
peer communication protocols as |
be delayed or even |
delayed or even lost |
a scalable inventory service |
communication protocols as an |
the communication pattern is |
or even lost due |
scalable inventory service that |
protocols as an underlying |
as an underlying communication |
even lost due to |
inventory service that receives |
communication pattern is completely |
an underlying communication substrate |
lost due to race |
service that receives updates |
that receives updates corresponding |
underlying communication substrate for |
due to race conditions |
pattern is completely predictable |
is completely predictable and |
completely predictable and hence |
predictable and hence reveals |
and hence reveals nothing |
receives updates corresponding to |
communication substrate for soc |
leading to a potentially |
updates corresponding to inventory |
substrate for soc applications |
to a potentially inconsistent |
corresponding to inventory consumption |
a potentially inconsistent view |
to inventory consumption and |
inventory consumption and re |
the relative strengths of |
malicious nodes cannot significantly |
potentially inconsistent view by |
relative strengths of each |
nodes cannot significantly deviate |
inconsistent view by the |
strengths of each of |
cannot significantly deviate from |
view by the cache |
by the cache clients |
significantly deviate from correct |
deviate from correct behavior |
from correct behavior without |
correct behavior without being |
behavior without being detected |
of each of the |
queries against such a |
each of the solutions |
against such a service |
of the solutions tested |
such a service would |
the solutions tested and |
so the network encourages |
the network encourages the |
network encourages the operator |
encourages the operator to |
the operator to behave |
operator to behave correctly |
solutions tested and the |
a service would compute |
tested and the lack |
large internet services store |
and it even tolerates |
and the lack of |
service would compute and |
internet services store vast |
services store vast amounts |
the lack of a |
would compute and return |
it even tolerates byzantine |
store vast amounts of |
vast amounts of data |
compute and return an |
even tolerates byzantine failure |
lack of a clear |
and return an inventory |
tolerates byzantine failure by |
byzantine failure by a |
failure by a small |
by a small minority |
a small minority of |
small minority of clients |
return an inventory count |
of a clear winner |
online retailers such as |
an inventory count as |
a clear winner serve |
this ensures that important |
retailers such as amazon |
inventory count as of |
clear winner serve as |
ensures that important queries |
such as amazon and |
count as of the |
winner serve as a |
that important queries will |
as amazon and ebay |
as of the time |
serve as a further |
important queries will not |
amazon and ebay maintain |
of the time the |
as a further justification |
queries will not be |
and ebay maintain product |
the time the query |
a further justification for |
will not be corrupted |
not be corrupted or |
be corrupted or blocked |
corrupted or blocked by |
or blocked by compromised |
blocked by compromised devices |
further justification for the |
ebay maintain product stocks |
time the query was |
the query was processed |
and that an adversary |
justification for the decoupling |
maintain product stocks and |
product stocks and information |
for the decoupling of |
but inventory can change |
inventory can change in |
can change in real |
that an adversary cannot |
and social networking sites |
the decoupling of information |
decoupling of information and |
social networking sites such |
an adversary cannot compromise |
of information and transport |
networking sites such as |
adversary cannot compromise the |
information and transport layers |
sites such as facebook |
cannot compromise the privacy |
reissued a moment later |
and transport layers advocated |
such as facebook and |
compromise the privacy of |
transport layers advocated above |
as facebook and twitter |
the privacy of client |
might yield a different |
facebook and twitter maintain |
privacy of client data |
yield a different result |
and twitter maintain graphical |
of client data by |
a different result and |
twitter maintain graphical databases |
limitations of the existing |
different result and yet |
result and yet both |
maintain graphical databases representing |
of the existing model |
client data by gaining |
and yet both would |
graphical databases representing user |
the existing model there |
data by gaining control |
yet both would be |
both would be correct |
existing model there are |
model there are two |
databases representing user relations |
representing user relations and |
there are two important |
are two important reasons |
user relations and group |
relations and group structures |
two important reasons why |
important reasons why integrating |
responses reflecting a reasonably |
by gaining control of |
gaining control of a |
control of a few |
of a few devices |
a few devices in |
few devices in the |
devices in the system |
reasons why integrating peerto |
reflecting a reasonably current |
a reasonably current server |
reasonably current server state |
current server state are |
server state are acceptable |
peer collaboration with server |
such databases are sharded |
databases are sharded and |
are sharded and replicated |
on the other hand |
hosted content is difficult |
the vast majority of |
vast majority of accesses |
a response reflecting a |
the first is not |
majority of accesses are |
response reflecting a very |
first is not strictly |
of accesses are read |
reflecting a very stale |
is not strictly limited |
a very stale state |
not strictly limited to |
very stale state would |
strictly limited to collaboration |
stale state would be |
state would be incorrect |
ro bert orma ndi |
limited to collaboration and |
to collaboration and peer |
a client should not |
istva n hegedu s |
client should not be |
should not be offered |
not be offered a |
and ma rk jelasity |
be offered a promotional |
offered a promotional price |
a promotional price on |
promotional price on a |
gossip learning with linear |
price on a plasma |
it is a general |
learning with linear models |
on a plasma tv |
is a general weakness |
with linear models on |
a plasma tv if |
a general weakness of |
linear models on fully |
models on fully distributed |
on fully distributed this |
fully distributed this work |
distributed this work was |
this work was supported |
general weakness of the |
plasma tv if the |
weakness of the current |
tv if the last |
of the current web |
if the last unit |
the current web mashup |
the last unit was |
last unit was actually |
unit was actually sold |
was actually sold hours |
actually sold hours ago |
by a grant from |
a grant from the |
grant from the nsf |
from the nsf data |
current web mashup technologies |
to reduce database load |
web mashup technologies that |
reduce database load and |
mashup technologies that makes |
database load and to |
the inventory service should |
practice and exsmart grids |
and exsmart grids program |
technologies that makes it |
inventory service should reflect |
load and to reduce |
that makes it hard |
service should reflect as |
and to reduce access |
makes it hard to |
should reflect as many |
to reduce access latency |
it hard to seamlessly |
reflect as many updates |
hard to seamlessly integrate |
as many updates as |
to seamlessly integrate data |
many updates as possible |
these companies employ a |
seamlessly integrate data from |
updates as possible in |
companies employ a twotier |
integrate data from several |
as possible in the |
employ a twotier structure |
data from several different |
possible in the replies |
from several different sources |
in the replies it |
the replies it gives |
placing layers of cache |
replies it gives to |
it gives to requests |
layers of cache servers |
the web developers community |
of cache servers in |
web developers community has |
cache servers in front |
developers community has slowly |
but any reply is |
servers in front of |
community has slowly converged |
any reply is correct |
in front of the |
has slowly converged towards |
reply is correct provided |
front of the database |
slowly converged towards service |
is correct provided that |
converged towards service platforms |
correct provided that it |
towards service platforms that |
provided that it was |
service platforms that export |
that it was based |
platforms that export autonomous |
it was based on |
that export autonomous interactive |
was based on a |
export autonomous interactive components |
based on a recent |
on a recent state |
autonomous interactive components to |
interactive components to their |
components to their clients |
the caches of primary |
caches of primary interest |
of primary interest to |
primary interest to us |
in the form of |
interest to us are |
we shall see that |
the form of what |
to us are typically |
shall see that the |
form of what we |
us are typically situated |
see that the ssa |
of what we ll |
are typically situated far |
that the ssa allows |
what we ll call |
typically situated far from |
the ssa allows brief |
we ll call minibrowser |
situated far from the |
ssa allows brief inconsistencies |
ll call minibrowser interfaces |
far from the backend |
antony rowstron and peter |
rowstron and peter druschel |
from the backend database |
a minibrowser is an |
allows brief inconsistencies but |
the backend database systems |
minibrowser is an interactive |
brief inconsistencies but that |
backend database systems to |
is an interactive web |
inconsistencies but that they |
database systems to reduce |
an interactive web page |
but that they can |
systems to reduce latency |
interactive web page with |
that they can be |
they can be limited |
web page with embedded |
page with embedded script |
can be limited to |
be limited to a |
companies place caches close |
place caches close to |
caches close to clients |
and routing for large |
limited to a few |
to a few seconds |
timeouts are used to |
are used to ensure |
used to ensure that |
to ensure that stale |
operations against the inventory |
ensure that stale cached |
against the inventory service |
that stale cached objects |
the inventory service happen |
stale cached objects will |
inventory service happen to |
service happen to be |
optimized for displaying a |
cached objects will eventually |
happen to be commutative |
for displaying a single |
objects will eventually be |
displaying a single type |
will eventually be flushed |
a single type of |
single type of content |
hence the service can |
the service can process |
service can process updates |
can process updates out |
but to achieve a |
for example interactive maps |
process updates out of |
updates out of order |
example interactive maps from |
to achieve a high |
interactive maps from google |
achieve a high cache |
maps from google earth |
a high cache hit |
high cache hit ratio |
from google earth or |
but many kinds of |
google earth or virtual |
many kinds of services |
earth or virtual earth |
kinds of services can |
timeout values are generally |
of services can handle |
values are generally large |
services can handle out |
can handle out of |
handle out of order |
out of order updates |
our example actually overlays |
to obtain reasonable consistency |
example actually overlays weather |
if for no other |
actually overlays weather from |
for no other reason |
overlays weather from google |
no other reason than |
the database sends an |
weather from google on |
other reason than that |
database sends an asynchronous |
from google on terrain |
reason than that in |
sends an asynchronous stream |
google on terrain maps |
than that in many |
an asynchronous stream of |
on terrain maps from |
that in many settings |
asynchronous stream of invalidation |
terrain maps from microsoft |
stream of invalidation records |
maps from microsoft s |
of invalidation records or |
from microsoft s virtual |
each update is uniquely |
invalidation records or cache |
microsoft s virtual earth |
update is uniquely sequenced |
records or cache updates |
s virtual earth platform |
is uniquely sequenced by |
virtual earth platform and |
uniquely sequenced by its |
earth platform and extracts |
often using protocols optimized |
sequenced by its source |
platform and extracts census |
using protocols optimized for |
and extracts census data |
protocols optimized for throughput |
extracts census data from |
optimized for throughput and |
permitting the service to |
census data from the |
for throughput and freshness |
the service to sort |
data from the us |
throughput and freshness and |
service to sort updates |
from the us census |
the us census bureau |
correctness of a gossip |
of a gossip based |
a gossip based membership |
gossip based membership protocol |
to sort updates and |
and freshness and lacking |
the lion coexists with |
sort updates and to |
freshness and lacking absolute |
lion coexists with the |
coexists with the lamb |
updates and to process |
and lacking absolute guarantees |
lacking absolute guarantees of |
and to process queries |
to process queries against |
absolute guarantees of order |
guarantees of order or |
of order or reliability |
process queries against the |
queries against the sorted |
the second problem is |
in proceedings of the |
proceedings of the twenty |
second problem is that |
against the sorted database |
problem is that with |
it is difficult to |
is that with the |
that with the traditional |
is difficult to make |
our group has held |
with the traditional style |
the traditional style of |
difficult to make this |
group has held discussions |
fourth annual acm sympo |
traditional style of web |
style of web development |
has held discussions with |
to make this invalidation |
held discussions with operators |
make this invalidation mechanism |
discussions with operators of |
content is assumed to |
this invalidation mechanism reliable |
with operators of several |
is assumed to be |
invalidation mechanism reliable without |
operators of several large |
assumed to be fetched |
mechanism reliable without hampering |
of several large datacenters |
to be fetched from |
reliable without hampering database |
be fetched from a |
without hampering database efficiency |
fetched from a server |
and concluded that many |
concluded that many services |
that many services have |
many services have the |
the issues are many |
services have the kinds |
either directly over http |
have the kinds of |
and ma rk jelasity |
the kinds of properties |
kinds of properties just |
of properties just cited |
or by interacting with |
by interacting with a |
interacting with a web |
with a web service |
a private framework for |
the databases are large |
ability to respond based |
to respond based on |
respond based on a |
web pages downloaded by |
private framework for distributed |
based on a reasonable |
residing on many servers |
pages downloaded by clients |
framework for distributed comsium |
on a reasonable current |
a reasonable current state |
for distributed comsium on |
distributed comsium on principles |
comsium on principles of |
on principles of distributed |
and to handle out |
principles of distributed computing |
downloaded by clients browsers |
databases use locks prudently |
by clients browsers contain |
use locks prudently in |
clients browsers contain embedded |
locks prudently in order |
the ssa is a |
browsers contain embedded addresses |
prudently in order to |
ssa is a good |
contain embedded addresses of |
in order to maximize |
is a good match |
embedded addresses of specific |
order to maximize concurrency |
a good match for |
addresses of specific servers |
good match for personalization |
match for personalization services |
to the extent that |
the extent that the |
technologies such as ajax |
extent that the database |
such as ajax allow |
that the database keeps |
as ajax allow for |
the database keeps track |
ajax allow for asynchronous |
database keeps track of |
keeps track of the |
track of the caches |
of the caches that |
the caches that hold |
caches that hold a |
that hold a copy |
hold a copy of |
a copy of each |
copy of each object |
it may be possible |
may be possible to |
be possible to send |
possible to send an |
to send an invalidation |
but traffic is still |
traffic is still always |
is still always routed |
still always routed through |
always routed through a |
routed through a data |
through a data center |
but tracking the state |
tracking the state of |
the state of caches |
state of caches is |
of caches is complicated |
the clients don t |
caches is complicated and |
clients don t talk |
is complicated and hence |
don t talk to |
complicated and hence if |
t talk to one |
and hence if they |
talk to one another |
hence if they are |
if they are used |
they are used at |
are used at all |
such systems view invalidations |
systems view invalidations as |
live objects allow visual |
view invalidations as a |
objects allow visual content |
invalidations as a kind |
allow visual content and |
as a kind of |
visual content and update |
a kind of hint |
content and update events |
and update events to |
update events to be |
events to be communicated |
to be communicated using |
be communicated using any |
they could be delayed |
communicated using any sort |
using any sort of |
any sort of protocol |
these deal primarily with |
deal primarily with weakly |
primarily with weakly consistent |
with weakly consistent data |
but also overlay multicast |
due to buffering or |
to buffering or retransmissions |
and all sorts of |
buffering or retransmissions after |
all sorts of services |
or retransmissions after message |
sorts of services in |
retransmissions after message loss |
of services in which |
services in which replies |
in which replies are |
which replies are intrinsically |
replies are intrinsically noisy |
even a custom protocol |
a custom protocol designed |
custom protocol designed by |
protocol designed by the |
such as services that |
designed by the content |
as services that report |
uniform node sampling service |
by the content provider |
services that report data |
that report data gathered |
report data gathered from |
data gathered from remote |
gathered from remote sensors |
node sampling service robust |
sampling service robust against |
service robust against collusions |
robust against collusions of |
this makes it possible |
against collusions of malicious |
collusions of malicious nodes |
makes it possible to |
due to an inaccurate |
a datacenter would also |
it possible to achieve |
to an inaccurate list |
datacenter would also host |
possible to achieve extremely |
an inaccurate list of |
would also host some |
to achieve extremely high |
inaccurate list of locations |
also host some kinds |
achieve extremely high levels |
host some kinds of |
extremely high levels of |
some kinds of services |
high levels of throughput |
kinds of services ill |
levels of throughput and |
of throughput and latency |
matched to our model |
it also enhances security |
but because we are |
because we are working |
we are working with |
ifip international conference on |
the data center server |
are working with web |
working with web services |
due to a system |
to a system configuration |
a system configuration change |
international conference on dependable |
conference on dependable systems |
services running on the |
on dependable systems and |
dependable systems and networks |
running on the ssa |
data center server can |
or because of races |
on the ssa can |
center server can t |
because of races between |
the ssa can easily |
server can t see |
of races between reads |
ssa can easily interact |
can t see data |
can easily interact with |
t see data exchanged |
easily interact with services |
see data exchanged directly |
interact with services that |
data exchanged directly between |
with services that employ |
exchanged directly between peers |
services that employ other |
that employ other solutions |
the above discussion motivates |
above discussion motivates our |
discussion motivates our problem |
motivates our problem statement |
a missing invalidation obviously |
missing invalidation obviously leaves |
invalidation obviously leaves the |
obviously leaves the corresponding |
allow web applications to |
leaves the corresponding cache |
web applications to overlay |
the corresponding cache entry |
applications to overlay content |
corresponding cache entry stale |
to overlay content from |
consistency semantics the ssa |
overlay content from multiple |
semantics the ssa implements |
content from multiple sources |
the ssa implements stochastic |
pitfalls of such invalidation |
from multiple sources in |
ssa implements stochastic consistency |
of such invalidation schemes |
multiple sources in a |
implements stochastic consistency semantics |
such invalidation schemes are |
sources in a layered |
invalidation schemes are described |
in a layered fashion |
schemes are described in |
an application will only |
are described in detail |
application will only observe |
described in detail by |
will only observe an |
such that the distinct |
in detail by nishita |
only observe an inconsistency |
that the distinct content |
detail by nishita et |
by nishita et al |
the distinct content layers |
observe an inconsistency if |
distinct content layers share |
an inconsistency if a |
content layers share a |
inconsistency if a fault |
if a fault occurs |
layers share a single |
share a single view |
a single view and |
single view and remain |
view and remain well |
and remain well synchronized |
and even then only |
byzantine resilient random membership |
resilient random membership sampling |
even then only for |
and by bronson et |
by bronson et al |
then only for a |
in proceedings of the |
proceedings of the twenty |
only for a period |
for a period of |
or panning should cause |
a period of time |
seventh acm symposium on |
acm symposium on principles |
symposium on principles of |
on principles of distributed |
principles of distributed computing |
panning should cause all |
period of time associated |
should cause all layers |
of time associated with |
cause all layers to |
time associated with our |
all layers to respond |
but forgoing transactional consistency |
associated with our repair |
layers to respond simultaneously |
forgoing transactional consistency can |
with our repair protocol |
transactional consistency can result |
consistency can result in |
can result in undesired |
and an update in |
result in undesired behavior |
and only if it |
an update in any |
in undesired behavior of |
only if it has |
update in any of |
undesired behavior of a |
if it has the |
in any of the |
behavior of a service |
it has the bad |
any of the layers |
has the bad luck |
of the layers should |
the bad luck to |
the layers should be |
bad luck to query |
consider a buyer at |
layers should be reflected |
luck to query a |
a buyer at an |
should be reflected in |
to query a node |
buyer at an online |
be reflected in all |
query a node impacted |
at an online site |
reflected in all other |
a node impacted by |
an online site who |
in all other layers |
node impacted by the |
online site who looks |
impacted by the failure |
site who looks for |
allow updates to be |
who looks for a |
updates to be carried |
looks for a toy |
to be carried by |
this window can be |
for a toy train |
be carried by the |
window can be made |
a toy train with |
carried by the protocol |
can be made small |
toy train with its |
by the protocol best |
train with its matching |
the protocol best matched |
with its matching tracks |
protocol best matched to |
so that applications are |
its matching tracks just |
best matched to the |
that applications are unlikely |
matching tracks just as |
matched to the setting |
applications are unlikely to |
tracks just as the |
to the setting in |
are unlikely to observe |
just as the vendor |
the setting in which |
unlikely to observe a |
as the vendor is |
setting in which the |
to observe a problem |
the vendor is adding |
in which the application |
vendor is adding them |
which the application is |
is adding them to |
the application is used |
or permitted to grow |
adding them to the |
permitted to grow somewhat |
them to the database |
to grow somewhat larger |
the solutions discussed here |
depending upon the cost |
the client may see |
in proceedings of the |
client may see only |
solutions discussed here are |
may see only the |
upon the cost of |
see only the train |
proceedings of the acm |
of the acm sigcomm |
the cost of inconsistency |
only the train in |
discussed here are based |
cost of inconsistency and |
the train in stock |
here are based on |
of inconsistency and the |
train in stock but |
are based on live |
inconsistency and the relative |
in stock but not |
based on live objects |
and the relative value |
stock but not the |
but not the tracks |
not the tracks because |
the tracks because the |
tracks because the product |
because the product insertion |
the product insertion transaction |
product insertion transaction would |
insertion transaction would often |
transaction would often be |
would often be broken |
often be broken into |
of faster response time |
be broken into two |
faster response time versus |
broken into two or |
response time versus lower |
into two or more |
time versus lower risk |
two or more atomic |
new types of components |
versus lower risk of |
or more atomic but |
types of components must |
lower risk of an |
more atomic but independent |
of components must be |
risk of an observed |
atomic but independent subtransactions |
components must be created |
of an observed fault |
must be created for |
be created for each |
created for each type |
for each type of |
each type of content |
in a social network |
in the experimental work |
the experimental work that |
experimental work that follows |
but the existing collection |
an inconsistency with unexpected |
the existing collection of |
inconsistency with unexpected results |
we measure these windows |
existing collection of components |
with unexpected results can |
measure these windows for |
collection of components provides |
unexpected results can occur |
these windows for scenarios |
of components provides access |
results can occur if |
windows for scenarios representative |
components provides access to |
can occur if a |
for scenarios representative of |
provides access to several |
occur if a user |
scenarios representative of conditions |
access to several different |
if a user x |
representative of conditions that |
to several different types |
a user x s |
of conditions that arise |
several different types of |
user x s record |
conditions that arise in |
different types of web |
x s record says |
that arise in realistic |
types of web services |
s record says it |
arise in realistic settings |
of web services hosted |
record says it belongs |
web services hosted content |
says it belongs to |
it belongs to a |
belongs to a certain |
to a certain group |
including all the examples |
all the examples given |
the ssa framework the |
the examples given above |
but that group s |
ssa framework the basic |
that group s record |
framework the basic operation |
group s record does |
the basic operation of |
s record does not |
basic operation of the |
record does not include |
operation of the ssa |
does not include x |
of the ssa is |
the resulting live application |
the ssa is as |
ssa is as follows |
resulting live application is |
web albums maintain picture |
live application is stored |
albums maintain picture data |
application is stored as |
maintain picture data and |
as queries or updates |
is stored as an |
picture data and access |
queries or updates are |
stored as an xml |
as an xml file |
or updates are received |
data and access control |
updates are received in |
and access control lists |
are received in the |
received in the cluster |
epidemic algorithms for replicated |
algorithms for replicated database |
for replicated database maintenance |
the file can be |
they are passed through |
file can be moved |
are passed through a |
in proceedings of the |
can be moved about |
and it is important |
passed through a partition |
through a partition mapping |
a partition mapping component |
it is important that |
proceedings of the sixth |
be moved about and |
is important that acl |
of the sixth annual |
moved about and even |
which directs the request |
important that acl and |
that acl and album |
about and even embedded |
directs the request to |
the request to an |
acl and album updates |
and even embedded in |
even embedded in email |
request to an appropriate |
and album updates are |
album updates are consistent |
to an appropriate racs |
the sixth annual acm |
sixth annual acm symposium |
annual acm symposium on |
acm symposium on principles |
the classical example involves |
symposium on principles of |
on principles of distributed |
principles of distributed computing |
classical example involves removing |
users that open it |
we will use the |
example involves removing one |
that open it find |
will use the term |
involves removing one s |
open it find themselves |
use the term subservice |
removing one s boss |
it find themselves immersed |
the term subservice rather |
one s boss from |
find themselves immersed into |
term subservice rather than |
s boss from the |
themselves immersed into the |
subservice rather than racs |
boss from the album |
immersed into the application |
rather than racs in |
from the album acl |
than racs in the |
the album acl and |
racs in the remainder |
several transport protocols optimized |
album acl and then |
in the remainder of |
transport protocols optimized for |
acl and then adding |
the remainder of the |
protocols optimized for various |
and then adding unflattering |
remainder of the paper |
optimized for various settings |
then adding unflattering pictures |
for various settings are |
various settings are or |
settings are or will |
to create a subservice |
are or will be |
create a subservice the |
or will be available |
a subservice the developer |
will be available in |
subservice the developer must |
be available in a |
while many of these |
the developer must first |
available in a near |
in a near future |
developer must first implement |
many of these systems |
must first implement a |
first implement a non |
of these systems make |
including support for wan |
these systems make do |
support for wan networks |
systems make do with |
for wan networks with |
make do with weak |
wan networks with nats |
do with weak consistency |
networks with nats and |
this is then cloned |
with nats and firewalls |
is then cloned using |
then cloned using the |
their utility is reduced |
cloned using the ssa |
utility is reduced when |
using the ssa platform |
is reduced when their |
reduced when their clients |
when their clients observe |
their clients observe inconsistencies |
each replica is placed |
replica is placed on |
is placed on a |
placed on a separate |
on a separate node |
there has been a |
has been a wave |
been a wave of |
a wave of recent |
wave of recent innovations |
of recent innovations within |
and the replicas are |
recent innovations within the |
the replicas are then |
innovations within the backend |
replicas are then linked |
are then linked using |
then linked using tcp |
linked using tcp to |
using tcp to create |
tcp to create a |
offering scalable object stores |
to create a chain |
scalable object stores that |
object stores that can |
stores that can efficiently |
that can efficiently support |
can efficiently support transactions |
efficiently support transactions through |
support transactions through snapshot |
transactions through snapshot isolation |
through snapshot isolation and |
snapshot isolation and even |
isolation and even full |
and even full atomicity |
in lecture notes in |
lecture notes in computer |
notes in computer science |
we therefore have a |
high throughput and very |
throughput and very large |
and very large numbers |
very large numbers of |
large numbers of nodes |
mapping between a subservice |
between a subservice and |
a subservice and a |
subservice and a chain |
large numbers of irregularly |
gossip based chain replication |
numbers of irregularly overlapping |
based chain replication the |
of irregularly overlapping multicast |
chain replication the replication |
irregularly overlapping multicast groups |
replication the replication scheme |
the replication scheme has |
replication scheme has evolved |
scheme has evolved out |
has evolved out of |
evolved out of the |
out of the chain |
of the chain replication |
the chain replication mechanism |
chain replication mechanism first |
replication mechanism first introduced |
mechanism first introduced in |
our challenge is to |
challenge is to improve |
is to improve transaction |
to improve transaction consistency |
improve transaction consistency at |
transaction consistency at the |
consistency at the cache |
at the cache layer |
and strong reliability properties |
even when the cache |
when the cache cannot |
the cache cannot access |
cache cannot access the |
cannot access the backend |
the original scheme was |
access the backend on |
original scheme was developed |
the backend on each |
scheme was developed as |
backend on each read |
was developed as a |
developed as a means |
as a means of |
a means of obtaining |
means of obtaining high |
of obtaining high throughput |
obtaining high throughput and |
high throughput and availability |
throughput and availability for |
and availability for query |
availability for query and |
for query and update |
query and update requests |
and update requests without |
update requests without sacrificing |
requests without sacrificing strong |
without sacrificing strong consistency |
today s consistency solutions |
sacrificing strong consistency guarantees |
s consistency solutions are |
consistency solutions are limited |
solutions are limited to |
are limited to the |
limited to the database |
to the database backend |
even when the database |
the gossip based chain |
when the database itself |
before saying more about |
gossip based chain replication |
the database itself is |
saying more about our |
more about our approach |
database itself is consistent |
based chain replication behaves |
chain replication behaves in |
replication behaves in the |
behaves in the following |
the vast majority of |
we analyze a concrete |
in the following manner |
vast majority of operations |
analyze a concrete example |
the following manner during |
majority of operations are |
a concrete example of |
following manner during normal |
of operations are read |
concrete example of a |
manner during normal operation |
example of a soc |
during normal operation when |
of a soc application |
only transactions issued by |
normal operation when nodes |
a soc application more |
transactions issued by edge |
operation when nodes aren |
soc application more carefully |
issued by edge clients |
when nodes aren t |
application more carefully to |
by edge clients and |
nodes aren t failing |
more carefully to expose |
edge clients and are |
aren t failing or |
carefully to expose the |
clients and are at |
t failing or restarting |
to expose the full |
and are at high |
expose the full range |
are at high risk |
the full range of |
at high risk of |
update operations are forwarded |
full range of needs |
high risk of observing |
operations are forwarded to |
range of needs and |
risk of observing inconsistent |
are forwarded to the |
of needs and issues |
of observing inconsistent state |
forwarded to the head |
needs and issues that |
observing inconsistent state in |
to the head of |
and issues that arise |
inconsistent state in the |
state in the cache |
the head of the |
head of the chain |
consider a rescue mission |
a rescue mission coordinator |
the outright loss of |
where the request is |
outright loss of cache |
the request is processed |
loss of cache invalidations |
a police or fire |
request is processed using |
of cache invalidations emerges |
police or fire chief |
is processed using the |
cache invalidations emerges as |
or fire chief coordinating |
processed using the local |
invalidations emerges as an |
based fast overlay topology |
fast overlay topology construction |
using the local replica |
emerges as an especially |
fire chief coordinating teams |
as an especially significant |
chief coordinating teams who |
an especially significant problem |
the state changes are |
coordinating teams who will |
especially significant problem if |
state changes are passed |
teams who will enter |
significant problem if transactional |
changes are passed along |
who will enter a |
problem if transactional consistency |
are passed along down |
will enter a disaster |
if transactional consistency is |
passed along down the |
enter a disaster zone |
transactional consistency is required |
along down the chain |
a disaster zone in |
down the chain to |
disaster zone in the |
the chain to the |
an acceptable solution for |
zone in the wake |
chain to the next |
acceptable solution for a |
in the wake of |
to the next element |
solution for a consistent |
the wake of a |
for a consistent cache |
wake of a catastrophe |
a consistent cache must |
which in turn updates |
of a catastrophe to |
consistent cache must maintain |
in turn updates it |
a catastrophe to help |
cache must maintain the |
turn updates it s |
catastrophe to help survivors |
must maintain the performance |
updates it s state |
maintain the performance properties |
it s state and |
the performance properties of |
s state and performs |
performance properties of the |
state and performs the |
properties of the existing |
and performs the same |
of the existing caching |
performs the same operation |
the existing caching tier |
the same operation until |
same operation until the |
operation until the tail |
until the tail is |
the tail is reached |
we need to maintain |
queries can either be |
need to maintain the |
can either be directed |
to maintain the shielding |
either be directed towards |
maintain the shielding role |
be directed towards a |
the shielding role of |
directed towards a randomly |
and move supplies as |
move supplies as needed |
towards a randomly selected |
shielding role of the |
a randomly selected process |
role of the cache |
randomly selected process in |
selected process in the |
process in the group |
in the group or |
the group or to |
group or to a |
or to a specific |
to a specific one |
the cache hit ratio |
cache hit ratio should |
hit ratio should be |
ratio should be high |
and maarten van steen |
the strongest consistency guarantee |
would arrive on the |
arrive on the scene |
strongest consistency guarantee is |
consistency guarantee is acheived |
guarantee is acheived if |
is acheived if all |
build a new collaboration |
a new collaboration tool |
acheived if all query |
only cache access should |
if all query operations |
cache access should complete |
and distribute it to |
distribute it to his |
access should complete with |
all query operations are |
should complete with a |
complete with a single |
with a single client |
query operations are targeted |
operations are targeted at |
are targeted at the |
targeted at the tail |
each team member would |
at the tail of |
team member would carry |
member would carry a |
would carry a tablet |
the tail of the |
tail of the chain |
of the chain node |
trip on cache hits |
style device with wireless |
device with wireless communication |
with wireless communication capabilities |
which is the case |
is the case for |
this prohibits coherent cache |
the case for the |
prohibits coherent cache solutions |
the application built by |
case for the vanilla |
coherent cache solutions such |
application built by the |
for the vanilla chain |
cache solutions such as |
built by the coordinator |
the vanilla chain replication |
by the coordinator would |
vanilla chain replication scheme |
the coordinator would be |
coordinator would be installed |
would be installed on |
be installed on each |
installed on each team |
however this eliminates the |
on each team member |
this eliminates the opportunity |
each team member s |
eliminates the opportunity to |
team member s mobile |
the opportunity to load |
member s mobile device |
a rchitecture since the |
and in the offices |
rchitecture since the cache |
in the offices in |
faults and node restarts |
since the cache is |
the offices in mission |
and node restarts can |
the cache is required |
offices in mission headquarters |
node restarts can disrupt |
cache is required to |
restarts can disrupt the |
is required to respond |
can disrupt the primary |
required to respond immediately |
the coordinator would then |
disrupt the primary communication |
to respond immediately to |
coordinator would then deploy |
the primary communication pattern |
respond immediately to the |
would then deploy teams |
primary communication pattern of |
immediately to the client |
then deploy teams in |
communication pattern of the |
to the client on |
the client on hits |
pattern of the ssa |
deploy teams in the |
teams in the field |
if the head of |
the head of a |
head of a chain |
of a chain fails |
our rescue workers now |
cache channel is asynchronous |
rescue workers now use |
workers now use the |
now use the solution |
update sources will need |
use the solution to |
we decided to employ |
sources will need to |
the solution to coordinate |
decided to employ a |
will need to discover |
solution to coordinate and |
to employ a transactional |
need to discover a |
to coordinate and prioritize |
employ a transactional consistency |
to discover a new |
coordinate and prioritize actions |
a transactional consistency that |
discover a new head |
transactional consistency that is |
consistency that is weaker |
that is weaker than |
inform each other of |
is weaker than the |
if an inner node |
each other of the |
weaker than the full |
an inner node crashes |
other of the evolving |
than the full acid |
the full acid model |
of the evolving situation |
inner node crashes the |
node crashes the chain |
crashes the chain may |
the chain may break |
steer clear of hazards |
and if the tail |
if the tail crashes |
only transactions and update |
acks might not be |
as new events occur |
transactions and update transactions |
might not be sent |
not be sent back |
and update transactions that |
update transactions that access |
the situational status would |
transactions that access the |
situational status would evolve |
that access the same |
access the same cache |
the same cache are |
same cache are guaranteed |
cache are guaranteed an |
are guaranteed an atomic |
and the team member |
guaranteed an atomic execution |
the team member who |
or some of its |
some of its members |
team member who causes |
member who causes or |
who causes or observes |
causes or observes these |
or observes these status |
observes these status changes |
these status changes would |
only transactions that access |
status changes would need |
transactions that access different |
processes will miss updates |
changes would need to |
that access different caches |
will miss updates and |
would need to report |
access different caches may |
miss updates and hence |
need to report them |
different caches may observe |
updates and hence queries |
to report them to |
caches may observe different |
and hence queries will |
report them to the |
them to the others |
hence queries will return |
may observe different orderings |
queries will return outdated |
observe different orderings for |
will return outdated results |
different orderings for independent |
orderings for independent update |
for independent update transactions |
removing debris blocking access |
to repair these inconsistencies |
debris blocking access to |
blocking access to a |
access to a building |
to a building may |
a building may enable |
the ssa implements a |
building may enable the |
ssa implements a secondary |
may enable the team |
implements a secondary update |
enable the team to |
a secondary update propagation |
the team to check |
secondary update propagation mechanism |
team to check it |
to check it for |
check it for victims |
it uses gossip protocols |
uses gossip protocols to |
gossip protocols to rapidly |
and fire that breaks |
every partial execution that |
protocols to rapidly detect |
fire that breaks out |
partial execution that includes |
to rapidly detect and |
that breaks out in |
execution that includes all |
rapidly detect and repair |
breaks out in a |
that includes all update |
detect and repair inconsistencies |
out in a chemical |
includes all update transactions |
in a chemical storage |
all update transactions in |
a chemical storage warehouse |
update transactions in and |
while simultaneously orchestrating repair |
chemical storage warehouse may |
transactions in and all |
simultaneously orchestrating repair of |
storage warehouse may force |
in and all read |
orchestrating repair of the |
warehouse may force diversion |
repair of the chain |
may force diversion of |
force diversion of resources |
only transactions that go |
transactions that go through |
that go through a |
go through a single |
the gossip rate can |
through a single cache |
gossip rate can be |
as rescue workers capture |
a single cache server |
rate can be tuned |
rescue workers capture information |
with a higher rate |
their mobile devices send |
a higher rate overheads |
mobile devices send updates |
higher rate overheads rise |
our solution seeks to |
devices send updates that |
rate overheads rise but |
solution seeks to approximate |
send updates that must |
overheads rise but repair |
seeks to approximate cache |
updates that must be |
rise but repair occurs |
to approximate cache serializability |
that must be propagated |
but repair occurs more |
approximate cache serializability with |
must be propagated in |
repair occurs more rapidly |
cache serializability with bounded |
be propagated in real |
serializability with bounded caches |
with bounded caches and |
bounded caches and asynchronous |
caches and asynchronous communication |
and asynchronous communication with |
asynchronous communication with the |
communication with the db |
repair is slower but |
is slower but overheads |
slower but overheads drop |
having defined the scenario |
our idea starts with |
idea starts with an |
starts with an observation |
the subsections that follow |
subsections that follow discuss |
now let s analyze |
that follow discuss the |
let s analyze in |
follow discuss the two |
s analyze in more |
discuss the two core |
objects form clusters with |
analyze in more detail |
the two core mechanisms |
form clusters with strong |
in more detail the |
two core mechanisms in |
clusters with strong locality |
more detail the requirements |
core mechanisms in greater |
with strong locality properties |
detail the requirements it |
mechanisms in greater detail |
the requirements it places |
requirements it places on |
it places on our |
transactions are likely to |
places on our collaboration |
are likely to access |
on our collaboration tool |
a second class of |
likely to access objects |
second class of faults |
to access objects that |
class of faults are |
access objects that are |
of faults are transient |
faults are transient and |
are transient and relate |
transient and relate to |
and relate to the |
relate to the behavior |
to the behavior of |
the collaboration tool pulls |
the behavior of tcp |
collaboration tool pulls data |
close to each other |
behavior of tcp when |
tool pulls data from |
of tcp when a |
pulls data from many |
tcp when a node |
data from many kinds |
for retailers this might |
when a node is |
from many kinds of |
retailers this might involve |
a node is subjected |
many kinds of sources |
this might involve related |
node is subjected to |
might involve related products |
is subjected to stress |
it makes far more |
makes far more sense |
far more sense to |
more sense to imagine |
for social networks the |
such as a burst |
as a burst of |
a burst of traffic |
sense to imagine that |
social networks the set |
to imagine that weather |
networks the set of |
imagine that weather information |
the set of friends |
the os tends to |
os tends to lose |
for geographical services physical |
tends to lose packets |
geographical services physical proximity |
to lose packets and |
lose packets and the |
packets and the effect |
and the effect is |
the effect is that |
and for web albums |
effect is that tcp |
for web albums the |
is that tcp will |
web albums the acl |
that tcp will impose |
albums the acl objects |
tcp will impose congestion |
the acl objects and |
will impose congestion control |
acl objects and the |
impose congestion control mechanisms |
objects and the pictures |
messages and alerts come |
congestion control mechanisms and |
and the pictures assigned |
and alerts come from |
control mechanisms and choke |
the pictures assigned to |
alerts come from a |
mechanisms and choke back |
pictures assigned to them |
come from a dozen |
from a dozen providers |
a dozen providers than |
updates will cease to |
dozen providers than to |
will cease to propagate |
providers than to assume |
cease to propagate down |
in some cases applications |
than to assume that |
to propagate down the |
some cases applications explicitly |
to assume that one |
propagate down the chain |
cases applications explicitly cluster |
assume that one organization |
applications explicitly cluster their |
that one organization would |
explicitly cluster their data |
one organization would be |
even though most of |
cluster their data accesses |
organization would be hosting |
though most of the |
their data accesses to |
would be hosting services |
most of the nodes |
data accesses to benefit |
be hosting services with |
of the nodes involved |
accesses to benefit from |
hosting services with everything |
the nodes involved could |
to benefit from improved |
services with everything we |
nodes involved could still |
benefit from improved parallelism |
with everything we need |
involved could still have |
everything we need in |
could still have ample |
we need in one |
still have ample capacity |
need in one place |
data from distinct sources |
from distinct sources could |
we will show that |
distinct sources could have |
the resulting transactions access |
will show that when |
sources could have different |
resulting transactions access objects |
show that when such |
could have different format |
transactions access objects from |
that when such a |
when such a problem |
such a problem arises |
have different format and |
access objects from a |
different format and one |
objects from a single |
format and one will |
from a single cluster |
gossip will route data |
and one will often |
will route data around |
one will often need |
route data around the |
although there will also |
will often need to |
data around the congested |
around the congested nodes |
often need to interface |
there will also be |
need to interface to |
will also be some |
to interface to each |
also be some frequency |
and will also deliver |
interface to each using |
be some frequency of |
will also deliver missed |
to each using its |
some frequency of transactions |
also deliver missed updates |
each using its own |
frequency of transactions that |
deliver missed updates to |
using its own protocols |
of transactions that access |
missed updates to the |
its own protocols and |
transactions that access unrelated |
updates to the overloaded |
own protocols and interfaces |
that access unrelated objects |
to the overloaded nodes |
access unrelated objects in |
the overloaded nodes when |
unrelated objects in different |
overloaded nodes when the |
objects in different clusters |
nodes when the problem |
when the problem ends |
as conditions evolve the |
conditions evolve the team |
evolve the team might |
the team might need |
our solution requires minor |
team might need to |
in the original chain |
solution requires minor changes |
might need to be |
the original chain replication |
requires minor changes to |
need to be modify |
original chain replication scheme |
minor changes to the |
to be modify the |
chain replication scheme the |
changes to the database |
be modify the application |
replication scheme the queries |
to the database object |
scheme the queries are |
the database object representation |
the queries are directed |
database object representation format |
for example adding new |
queries are directed to |
example adding new types |
are directed to the |
adding new types of |
directed to the tail |
imposing a small and |
new types of information |
to the tail of |
a small and constant |
the tail of the |
small and constant memory |
tail of the chain |
and constant memory overhead |
changing the way it |
the way it is |
way it is represented |
since there is no |
there is no additional |
is no additional epidemic |
no additional epidemic communication |
or even modifying the |
even modifying the way |
modifying the way team |
independent of the database |
the way team members |
of the database size |
way team members communicate |
any update known to |
the database size and |
update known to the |
database size and the |
known to the tail |
size and the transaction |
to the tail is |
and the transaction rate |
the tail is stable |
tail is stable because |
is stable because it |
stable because it must |
back network links fail |
because it must first |
it must first have |
must first have been |
first have been seen |
have been seen by |
this overhead involves tracking |
been seen by all |
overhead involves tracking and |
seen by all the |
whereas a minibrowser would |
involves tracking and caching |
by all the members |
a minibrowser would typically |
tracking and caching what |
all the members of |
minibrowser would typically be |
and caching what we |
the members of the |
would typically be prebuilt |
caching what we refer |
members of the chain |
typically be prebuilt with |
what we refer to |
be prebuilt with all |
we refer to as |
prebuilt with all the |
refer to as dependency |
to maintain such an |
with all the available |
to as dependency lists |
maintain such an invariant |
all the available features |
the available features in |
available features in place |
the original paper includes |
original paper includes mechanisms |
paper includes mechanisms to |
length lists of object |
our scenario demands a |
includes mechanisms to ensure |
lists of object identifiers |
scenario demands a much |
mechanisms to ensure that |
of object identifiers and |
demands a much more |
to ensure that a |
object identifiers and the |
a much more flexible |
ensure that a request |
identifiers and the associated |
much more flexible kind |
that a request really |
and the associated version |
more flexible kind of |
a request really reaches |
the associated version numbers |
flexible kind of tool |
request really reaches the |
kind of tool that |
really reaches the head |
of tool that can |
each representing some recently |
reaches the head of |
tool that can be |
representing some recently updated |
the head of the |
head of the chain |
some recently updated objects |
that can be redesigned |
recently updated objects upon |
can be redesigned while |
updated objects upon which |
that updates are passed |
be redesigned while in |
objects upon which the |
updates are passed down |
redesigned while in use |
upon which the cached |
are passed down the |
which the cached object |
passed down the chain |
the cached object depends |
down the chain and |
the chain and applied |
chain and applied in |
depending on the location |
and applied in a |
on the location and |
applied in a strictly |
the location and other |
in a strictly fifo |
sized list can omit |
location and other factors |
a strictly fifo manner |
list can omit dependency |
strictly fifo manner even |
can omit dependency information |
fifo manner even when |
omit dependency information required |
the best networking protocols |
manner even when nodes |
dependency information required to |
best networking protocols and |
even when nodes fail |
information required to detect |
networking protocols and connectivity |
when nodes fail and |
required to detect inconsistencies |
protocols and connectivity options |
nodes fail and the |
and connectivity options may |
fail and the chain |
connectivity options may vary |
and the chain is |
hence it is important |
the chain is restructured |
it is important to |
in our rescue scenario |
is important to use |
important to use a |
to use a bound |
and that queries are |
use a bound large |
the workers may have |
that queries are sent |
a bound large enough |
workers may have to |
queries are sent to |
bound large enough to |
may have to use |
are sent to the |
large enough to capture |
have to use wireless |
sent to the tail |
enough to capture most |
to use wireless p |
to the tail of |
to capture most of |
the tail of the |
tail of the chain |
capture most of the |
p protocols much of |
most of the relevant |
protocols much of the |
much of the time |
strong consistency follows easily |
of the relevant dependencies |
consistency follows easily because |
follows easily because query |
easily because query requests |
reaching back to hosted |
because query requests and |
at present we lack |
back to hosted services |
query requests and update |
present we lack an |
to hosted services only |
requests and update requests |
we lack an automated |
hosted services only intermittently |
and update requests are |
lack an automated way |
services only intermittently when |
update requests are processed |
an automated way to |
only intermittently when a |
requests are processed serially |
automated way to do |
way to do this |
are processed serially at |
intermittently when a drone |
processed serially at the |
when a drone aircraft |
serially at the tail |
we require the developer |
a drone aircraft passes |
at the tail element |
require the developer to |
drone aircraft passes within |
the developer to tune |
aircraft passes within radio |
developer to tune the |
passes within radio range |
the gossip based chain |
to tune the length |
gossip based chain replication |
tune the length so |
based chain replication weakens |
the length so that |
chain replication weakens the |
length so that the |
replication weakens the model |
so that the frequency |
weakens the model in |
the right choice of |
that the frequency of |
the model in two |
right choice of protocol |
the frequency of errors |
model in two key |
choice of protocol should |
frequency of errors is |
in two key respects |
of protocol should reflect |
of errors is reduced |
protocol should reflect the |
errors is reduced to |
should reflect the operating |
is reduced to an |
reflect the operating conditions |
reduced to an acceptable |
to an acceptable level |
our solution might sometimes |
solution might sometimes use |
might sometimes use the |
and if these change |
sometimes use the wrong |
reasoning about the trade |
use the wrong head |
the wrong head of |
wrong head of the |
head of the chain |
the platform should be |
platform should be capable |
should be capable of |
be capable of swapping |
capable of swapping in |
for example if an |
of swapping in a |
example if an update |
swapping in a different |
in a manner we |
if an update source |
in a different protocol |
a manner we discuss |
an update source is |
a different protocol without |
manner we discuss further |
update source is operating |
different protocol without disrupting |
we discuss further below |
source is operating with |
protocol without disrupting the |
is operating with inaccurate |
without disrupting the end |
operating with inaccurate membership |
disrupting the end user |
with inaccurate membership information |
dependency lists should be |
lists should be roughly |
should be roughly the |
this argues for a |
be roughly the same |
argues for a decoupling |
roughly the same size |
for a decoupling of |
the same size as |
updates might sometimes arrive |
a decoupling of functionality |
same size as the |
might sometimes arrive out |
size as the size |
sometimes arrive out of |
as the size of |
arrive out of order |
whereas a minibrowser packages |
the size of the |
a minibrowser packages it |
size of the workload |
minibrowser packages it all |
of the workload s |
for example if the |
packages it all into |
the workload s clusters |
example if the chain |
it all into one |
if the chain is |
all into one object |
the chain is disrupted |
our extensions offer a |
chain is disrupted by |
extensions offer a transactional |
is disrupted by a |
offer a transactional interface |
better is a design |
disrupted by a failure |
a transactional interface to |
is a design in |
by a failure and |
transactional interface to the |
a design in which |
a failure and some |
interface to the cache |
design in which the |
failure and some updates |
to the cache in |
in which the presentation |
and some updates arrive |
the cache in addition |
which the presentation object |
some updates arrive via |
cache in addition to |
the presentation object is |
updates arrive via the |
in addition to the |
presentation object is distinct |
arrive via the gossip |
via the gossip protocol |
object is distinct from |
addition to the standard |
is distinct from objects |
to the standard read |
distinct from objects representing |
these changes substantially simplify |
from objects representing information |
changes substantially simplify the |
objects representing information sources |
substantially simplify the algorithm |
representing information sources and |
simplify the algorithm but |
information sources and objects |
the algorithm but they |
sources and objects representing |
algorithm but they also |
and objects representing transport |
our algorithm detects and |
but they also weaken |
objects representing transport protocols |
algorithm detects and fixes |
they also weaken the |
detects and fixes inconsistent |
also weaken the properties |
and fixes inconsistent read |
decoupling makes it possible |
weaken the properties of |
makes it possible to |
the properties of the |
it possible to dynamically |
properties of the solution |
only transactions at the |
possible to dynamically modify |
transactions at the cache |
to dynamically modify or |
at the cache with |
a less significant change |
dynamically modify or even |
the cache with constant |
less significant change is |
modify or even replace |
cache with constant complexity |
significant change is that |
or even replace a |
change is that we |
is that we load |
even replace a component |
it does so by |
replace a component with |
does so by either |
a component with some |
so by either aborting |
balance queries over the |
component with some other |
by either aborting the |
queries over the members |
either aborting the transaction |
over the members of |
the members of the |
members of the chain |
which can then be |
can then be retried |
option when changing conditions |
when changing conditions require |
changing conditions require it |
but in ways that |
in ways that seem |
ways that seem to |
we have posed what |
or invalidating a cached |
that seem to match |
have posed what may |
invalidating a cached object |
seem to match the |
posed what may sound |
a cached object which |
to match the class |
what may sound like |
cached object which can |
match the class of |
may sound like a |
object which can then |
the class of applications |
sound like a very |
which can then force |
class of applications of |
like a very specialized |
can then force a |
of applications of interest |
a very specialized problem |
then force a read |
force a read from |
a read from the |
read from the database |
and has the potential |
has the potential to |
the potential to greatly |
but in fact we |
potential to greatly improve |
in fact we see |
similar to handling cache |
to greatly improve query |
fact we see this |
to handling cache misses |
greatly improve query performance |
we see this as |
see this as a |
this as a good |
as a good example |
a good example of |
good example of a |
example of a more |
when the dependency lists |
of a more general |
the dependency lists fail |
a more general kind |
dependency lists fail to |
more general kind of |
lists fail to document |
general kind of need |
fail to document a |
kind of need that |
epidemic dissemination as noted |
to document a necessary |
of need that could |
dissemination as noted earlier |
document a necessary dependency |
need that could arise |
that could arise in |
could arise in many |
arise in many kinds |
in many kinds of |
ssa uses gossip to |
an application might be |
uses gossip to detect |
many kinds of settings |
application might be exposed |
gossip to detect and |
might be exposed to |
to detect and repair |
be exposed to stale |
detect and repair the |
exposed to stale values |
and repair the inconsistencies |
repair the inconsistencies that |
consider a physician treating |
the inconsistencies that can |
a physician treating a |
because we have in |
inconsistencies that can arise |
physician treating a patient |
we have in mind |
that can arise after |
treating a patient with |
have in mind client |
can arise after a |
a patient with a |
arise after a failure |
patient with a complex |
after a failure or |
with a complex condition |
side applications that are |
a failure or when |
applications that are unlikely |
failure or when a |
that are unlikely to |
or when a node |
when a node joins |
are unlikely to validate |
who needs collaboration help |
unlikely to validate against |
needs collaboration help from |
to validate against the |
collaboration help from specialists |
the basic idea is |
validate against the back |
basic idea is simple |
and who might even |
who might even be |
might even be working |
each process in the |
even be working in |
process in the system |
be working in a |
in the system runs |
for many of our |
working in a remote |
the system runs a |
many of our intended |
in a remote location |
system runs a periodic |
of our intended uses |
a remote location under |
runs a periodic local |
our intended uses some |
remote location under conditions |
a periodic local timer |
intended uses some level |
location under conditions demanding |
uses some level of |
under conditions demanding urgent |
some level of undetected |
conditions demanding urgent action |
without synchronization across processes |
level of undetected inconsistency |
of undetected inconsistency can |
undetected inconsistency can slip |
inconsistency can slip past |
the mixture of patient |
mixture of patient data |
when a timer expires |
a process computes a |
process computes a summary |
because the developer would |
the developer would often |
developer would often be |
would often be able |
also called a digest |
often be able to |
be able to tune |
able to tune the |
to tune the mechanism |
may be just as |
be just as rich |
just as rich and |
state operation of large |
a list of things |
as rich and dynamic |
operation of large applications |
list of things that |
rich and dynamic as |
of things that it |
and dynamic as in |
things that it knows |
dynamic as in our |
the rate of unnoticed |
as in our search |
rate of unnoticed inconsistencies |
in our search and |
of unnoticed inconsistencies could |
this summary is sent |
our search and rescue |
unnoticed inconsistencies could be |
summary is sent to |
search and rescue scenario |
inconsistencies could be extremely |
is sent to a |
could be extremely low |
sent to a randomly |
to a randomly selected |
a randomly selected peer |
and the underlying communication |
the underlying communication options |
underlying communication options equally |
with clustered workloads we |
or subset of peers |
clustered workloads we will |
communication options equally heterogeneous |
workloads we will demonstrate |
options equally heterogeneous and |
we will demonstrate that |
equally heterogeneous and unpredictable |
will demonstrate that it |
demonstrate that it is |
quick delivery is more |
that it is sufficient |
delivery is more important |
it is sufficient to |
is more important than |
is sufficient to store |
more important than reliability |
designed for a wired |
sufficient to store a |
important than reliability for |
for a wired environment |
to store a small |
than reliability for gossip |
a wired environment might |
store a small set |
reliability for gossip messages |
wired environment might perform |
a small set of |
environment might perform poorly |
small set of dependencies |
might perform poorly or |
set of dependencies to |
hence we favor udp |
perform poorly or fail |
of dependencies to detect |
we favor udp datagrams |
poorly or fail under |
dependencies to detect most |
favor udp datagrams over |
or fail under such |
to detect most inconsistencies |
udp datagrams over tcp |
fail under such conditions |
datagrams over tcp for |
over tcp for this |
tcp for this kind |
for this kind of |
this kind of communication |
we also investigate workloads |
also investigate workloads where |
investigate workloads where the |
workloads where the clustered |
where the clustered access |
if there is a |
the recipient compares the |
the clustered access pattern |
there is a way |
recipient compares the gossiped |
clustered access pattern is |
is a way to |
compares the gossiped information |
access pattern is less |
a way to solve |
the gossiped information with |
pattern is less strongly |
way to solve the |
gossiped information with its |
is less strongly evident |
to solve the problem |
information with its own |
with its own state |
there is a way |
is a way to |
a way to build |
identifying information known to |
our approach is less |
way to build the |
information known to the |
approach is less effective |
to build the desired |
known to the sender |
is less effective even |
build the desired mashup |
to the sender but |
less effective even with |
the sender but unknown |
effective even with longer |
sender but unknown to |
throughout the above we |
even with longer dependency |
but unknown to itself |
the above we noted |
with longer dependency list |
above we noted requirements |
longer dependency list lengths |
or known to it |
known to it but |
to it but apparently |
it but apparently unknown |
but apparently unknown to |
apparently unknown to the |
unknown to the sender |
thus our solution is |
our solution is not |
we now summarize them |
solution is not a |
is not a panacea |
now summarize them below |
it then sends back |
then sends back a |
sends back a gossip |
back a gossip reply |
for applications matched to |
applications matched to our |
matched to our assumptions |
these needs are seen |
needs are seen in |
using an unreliable datagram |
are seen in many |
an unreliable datagram protocol |
seen in many settings |
can be highly effective |
containing information the sender |
information the sender might |
the sender might find |
sender might find useful |
might find useful and |
find useful and requesting |
we believe them to |
database we assume that |
useful and requesting information |
believe them to be |
we assume that the |
and requesting information it |
them to be typical |
assume that the database |
requesting information it lacks |
to be typical of |
that the database tags |
be typical of most |
the database tags each |
typical of most soc |
of most soc applications |
database tags each object |
tags each object with |
each object with a |
the originator of the |
object with a version |
we would like to |
originator of the exchange |
with a version number |
would like to enable |
of the exchange will |
a version number specific |
like to enable a |
to enable a non |
version number specific to |
the exchange will send |
number specific to the |
exchange will send a |
specific to the transaction |
programmer to rapidly develop |
will send a final |
to the transaction that |
to rapidly develop a |
send a final message |
the transaction that most |
rapidly develop a new |
a final message containing |
transaction that most recently |
develop a new collaborative |
final message containing any |
that most recently updated |
a new collaborative application |
message containing any data |
most recently updated it |
new collaborative application by |
containing any data that |
collaborative application by composing |
any data that was |
application by composing together |
data that was solicited |
and that there is |
by composing together and |
that was solicited by |
that there is a |
composing together and customizing |
was solicited by the |
solicited by the receiver |
together and customizing preexisting |
there is a total |
and customizing preexisting components |
is a total ordering |
a total ordering on |
total ordering on version |
ordering on version numbers |
gossip messages are bounded |
messages are bounded in |
are bounded in size |
we would like to |
would like to be |
the version of a |
like to be able |
version of a transaction |
to be able to |
thus during a round |
of a transaction is |
be able to overlay |
during a round each |
a transaction is chosen |
able to overlay data |
a round each process |
transaction is chosen to |
to overlay data from |
round each process will |
is chosen to be |
overlay data from multiple |
each process will send |
chosen to be larger |
data from multiple sources |
process will send a |
to be larger than |
will send a message |
be larger than the |
larger than the versions |
potentially in different formats |
than the versions of |
the versions of all |
perhaps eliciting a reply |
versions of all objects |
of all objects accessed |
obtained using different protocols |
all objects accessed by |
using different protocols and |
objects accessed by the |
and perhaps will respond |
different protocols and inconsistent |
accessed by the transaction |
perhaps will respond to |
protocols and inconsistent interfaces |
will respond to that |
respond to that reply |
the database stores for |
database stores for each |
we would like to |
stores for each object |
in the worst case |
would like to be |
for each object o |
like to be able |
each object o a |
to be able to |
object o a list |
a round results in |
be able to dynamically |
o a list of |
able to dynamically customize |
a list of k |
to dynamically customize the |
list of k dependencies |
dynamically customize the application |
customize the application at |
the application at runtime |
the load imposed on |
load imposed on the |
imposed on the network |
on the network will |
the network will thus |
network will thus be |
will thus be linear |
thus be linear in |
be linear in the |
linear in the number |
in the number of |
the number of processes |
but any individual process |
any individual process will |
individual process will see |
by incorporating new data |
process will see a |
incorporating new data sources |
will see a constant |
new data sources or |
see a constant load |
data sources or changing |
sources or changing the |
or changing the way |
changing the way data |
the way data is |
way data is presented |
independent of system size |
and without disrupting system |
the ssa gossips about |
ssa gossips about membership |
without disrupting system operation |
we would like to |
would like to be |
like to be able |
to be able to |
recoveries and application state |
be able to accommodate |
able to accommodate new |
to accommodate new types |
accommodate new types of |
new types of data |
types of data sources |
using this information to |
this information to initiate |
information to initiate repairs |
new formats or protocols |
formats or protocols that |
one form of repair |
or protocols that we |
form of repair involves |
protocols that we may |
of repair involves disruption |
that we may not |
repair involves disruption to |
we may not have |
involves disruption to a |
may not have anticipated |
disruption to a chain |
not have anticipated at |
have anticipated at the |
anticipated at the time |
at the time the |
the time the system |
time the system was |
if a fault breaks |
the system was released |
this is a list |
a fault breaks a |
is a list of |
fault breaks a chain |
a list of identifiers |
breaks a chain or |
data might be published |
list of identifiers and |
a chain or disables |
might be published by |
of identifiers and versions |
chain or disables the |
be published by the |
identifiers and versions of |
or disables the head |
published by the individual |
by the individual users |
disables the head of |
and versions of other |
the head of a |
versions of other objects |
head of a chain |
and it might be |
of other objects that |
it might be necessary |
other objects that the |
might be necessary for |
objects that the current |
gossip is used to |
be necessary for the |
that the current version |
is used to detect |
necessary for the users |
the current version of |
used to detect the |
for the users to |
current version of o |
to detect the problem |
the users to exchange |
version of o depends |
of o depends on |
users to exchange their |
detect the problem and |
to exchange their data |
the problem and repair |
exchange their data without |
problem and repair involves |
their data without access |
and repair involves designating |
data without access to |
only transaction that sees |
repair involves designating a |
without access to a |
transaction that sees the |
involves designating a new |
access to a centralized |
that sees the current |
designating a new head |
to a centralized repository |
sees the current version |
a new head for |
the current version of |
new head for the |
current version of o |
head for the chain |
data may be obtained |
version of o must |
for the chain or |
may be obtained using |
of o must not |
the chain or establishing |
be obtained using different |
o must not see |
chain or establishing a |
obtained using different types |
must not see object |
or establishing a new |
using different types of |
not see object di |
establishing a new tcp |
different types of network |
see object di with |
a new tcp connection |
types of network protocols |
object di with version |
new tcp connection bridging |
di with version smaller |
tcp connection bridging the |
with version smaller than |
connection bridging the gap |
and the type of |
version smaller than vi |
the type of the |
type of the physical |
of the physical network |
a second form of |
the physical network or |
when a transaction t |
second form of repair |
physical network or protocols |
a transaction t with |
form of repair involves |
network or protocols may |
transaction t with version |
of repair involves lost |
or protocols may not |
t with version vt |
repair involves lost updates |
protocols may not be |
with version vt touches |
may not be known |
version vt touches objects |
vt touches objects o |
not be known in |
if subservice a has |
be known in advance |
subservice a has a |
a has a member |
has a member m |
a member m that |
member m that knows |
it should be possible |
should be possible to |
be possible to rapidly |
possible to rapidly compose |
we assume that all |
it updates both their |
to rapidly compose the |
assume that all forms |
updates both their versions |
rapidly compose the application |
that all forms of |
both their versions and |
compose the application using |
all forms of information |
their versions and their |
the application using whatever |
forms of information are |
versions and their dependency |
application using whatever communication |
of information are uniquely |
and their dependency lists |
using whatever communication infrastructure |
information are uniquely named |
whatever communication infrastructure is |
are uniquely named and |
communication infrastructure is currently |
subsequent accesses to object |
accesses to object o |
infrastructure is currently available |
uniquely named and that |
named and that updates |
and that updates are |
must see object o |
that updates are ordered |
users may be mobile |
updates are ordered separately |
may be mobile or |
are ordered separately by |
be mobile or temporarily |
with a version not |
ordered separately by each |
mobile or temporarily disconnected |
a version not smaller |
separately by each update |
version not smaller than |
by each update source |
not smaller than vt |
and the topology of |
of update x and |
the topology of the |
update x and a |
topology of the network |
it inherits all of |
x and a member |
of the network and |
inherits all of the |
and a member m |
the network and its |
all of the l |
a member m that |
network and its characteristics |
of the l dependencies |
the l dependencies of |
l dependencies of o |
member m that lacks |
m that lacks x |
and its characteristics might |
its characteristics might change |
characteristics might change over |
might change over time |
gossip can be used |
where l is the |
l is the length |
is the length of |
the length of o |
can be used to |
the system should be |
system should be easily |
should be easily reconfigurable |
be used to detect |
used to detect this |
to detect this and |
detect this and m |
this and m can |
and m can then |
m can then send |
so the dependency list |
the dependency list of |
dependency list of o |
the requirements outlined above |
can then send x |
requirements outlined above might |
then send x to |
outlined above might seem |
send x to m |
x to m directly |
above might seem hard |
might seem hard to |
seem hard to satisfy |
without waiting for the |
waiting for the chain |
for the chain to |
the chain to be |
chain to be repaired |
gossip is not a |
is not a particularly |
not a particularly fast |
the solution is surprisingly |
a particularly fast protocol |
solution is surprisingly simple |
our analysis motivates a |
analysis motivates a component |
in which the web |
rounds of the protocol |
which the web services |
of the protocol to |
the web services and |
the protocol to reach |
web services and hosted |
protocol to reach n |
services and hosted content |
to reach n processes |
and hosted content are |
hosted content are modeled |
content are modeled as |
are modeled as reusable |
on the other hand |
modeled as reusable overlayed |
as reusable overlayed information |
reusable overlayed information layers |
overlayed information layers backed |
information layers backed by |
if rounds occur frequently |
layers backed by customizable |
backed by customizable transport |
by customizable transport layers |
the delay before information |
delay before information spreads |
a graph of components |
before information spreads to |
information spreads to all |
spreads to all members |
to all members of |
all members of a |
a collaborative application is |
members of a system |
collaborative application is a |
of a system may |
application is a forest |
a system may still |
system may still be |
may still be small |
a set of such |
set of such graphs |
even in a large |
in a large system |
our vision demands a |
vision demands a new |
demands a new kind |
a new kind of |
new kind of soc |
kind of soc standard |
gossip is astonishingly robust |
in order to facilitate |
order to facilitate the |
to facilitate the side |
there are exponentially many |
are exponentially many paths |
exponentially many paths by |
many paths by which |
paths by which information |
by which information can |
which information can pass |
information can pass from |
can pass from point |
side coexistence of components |
pass from point a |
coexistence of components that |
from point a to |
point a to point |
a to point b |
of components that might |
components that might today |
that might today be |
might today be implemented |
today be implemented as |
be implemented as proprietary |
hence almost any imaginable |
implemented as proprietary minibrowsers |
almost any imaginable disruption |
any imaginable disruption short |
imaginable disruption short of |
disruption short of a |
short of a lasting |
if we enable components |
of a lasting partitioning |
we enable components to |
a lasting partitioning failure |
enable components to talk |
lasting partitioning failure can |
partitioning failure can be |
failure can be overcome |
components to talk to |
to talk to oneanother |
the gossip protocols implemented |
gossip protocols implemented in |
we need to agree |
protocols implemented in the |
need to agree on |
implemented in the ssa |
to agree on the |
in the ssa have |
agree on the events |
the ssa have been |
on the events and |
ssa have been designed |
the events and representation |
have been designed specifically |
events and representation that |
been designed specifically for |
and representation that the |
designed specifically for use |
representation that the dialog |
that the dialog will |
the dialog will employ |
specifically for use in |
for use in our |
use in our modified |
in our modified version |
our modified version of |
modified version of chain |
the decoupling of functionality |
version of chain replication |
decoupling of functionality into |
of functionality into layers |
functionality into layers also |
into layers also suggests |
layers also suggests a |
and with the goal |
also suggests a need |
with the goal of |
suggests a need for |
the goal of running |
a need for a |
goal of running in |
need for a standardized |
of running in large |
for a standardized layering |
running in large clusters |
in large clusters or |
large clusters or datacenters |
in the examples above |
let be a group |
be a group of |
a group of processes |
one can identify at |
can identify at least |
identify at least four |
and let p be |
let p be a |
p be a process |
be a process in |
a process in that |
process in that group |
in that group p |
the linkage layer that |
linkage layer that talks |
layer that talks to |
that talks to the |
talks to the underlying |
to the underlying data |
the underlying data source |
each process has its |
process has its own |
has its own view |
its own view of |
own view of the |
the update generating and |
update generating and interpreting |
generating and interpreting layer |
view of the group |
when a transaction is |
a transaction is committed |
and the transport protocol |
this update is done |
update is done for |
is done for all |
done for all objects |
for all objects in |
all objects in the |
objects in the transaction |
in the transaction at |
we propose that this |
the transaction at once |
propose that this decoupling |
that this decoupling be |
this decoupling be done |
decoupling be done using |
be done using event |
given a read set |
these views can lag |
a read set readset |
views can lag reality |
and a write set |
a write set writeset |
for example if a |
a natural way of |
example if a process |
natural way of thinking |
if a process joins |
way of thinking about |
containing tuples comprised of |
a process joins or |
process joins or leaves |
tuples comprised of the |
comprised of the keys |
of the keys accessed |
of thinking about components |
thinking about components that |
about components that dates |
components that dates back |
that dates back to |
dates back to smalltalk |
their versions and their |
versions and their dependency |
and their dependency lists |
and different members might |
different members might not |
members might not have |
might not have consistent |
not have consistent views |
the database aggregates them |
database aggregates them to |
rather than having the |
aggregates them to a |
our work assumes that |
than having the data |
them to a single |
work assumes that the |
having the data center |
to a single full |
assumes that the network |
the data center developer |
a single full dependency |
that the network within |
data center developer offer |
single full dependency list |
the network within a |
center developer offer content |
full dependency list as |
network within a cluster |
developer offer content through |
dependency list as follows |
within a cluster does |
offer content through proprietary |
a cluster does not |
content through proprietary minibrowser |
cluster does not partition |
through proprietary minibrowser interface |
although there are low |
she would define an |
probability failure patterns that |
would define an event |
failure patterns that could |
patterns that could temporarily |
that could temporarily partition |
could temporarily partition some |
temporarily partition some subservice |
based interface between transport |
partition some subservice in |
interface between transport and |
some subservice in a |
between transport and information |
subservice in a logical |
transport and information layers |
in a logical sense |
the visual events delivered |
visual events delivered by |
events delivered by the |
delivered by the transport |
by the transport could |
the transport could then |
transport could then be |
could then be delivered |
then be delivered to |
be delivered to an |
delivered to an information |
to an information layer |
an information layer responsible |
information layer responsible for |
process p chooses a |
layer responsible for visualizing |
p chooses a random |
responsible for visualizing them |
chooses a random subset |
readset writeset this list |
a random subset of |
writeset this list is |
random subset of a |
this list is pruned |
subset of a particular |
list is pruned to |
of a particular size |
is pruned to match |
a particular size view |
pruned to match the |
to match the target |
match the target size |
the target size using |
target size using lru |
user mouse and keyboard |
mouse and keyboard events |
and keyboard events and |
keyboard events and pass |
and stored with each |
events and pass them |
and pass them down |
stored with each write |
and commences a dialog |
commences a dialog with |
a dialog with each |
dialog with each process |
with each process in |
each process in the |
process in the set |
with this type of |
this type of event |
a list entry can |
the initial message is |
list entry can be |
initial message is a |
entry can be discarded |
message is a compact |
can be discarded if |
is a compact state |
be discarded if the |
a compact state digest |
either layer could easily |
discarded if the same |
compact state digest summarizing |
layer could easily be |
if the same entry |
state digest summarizing the |
could easily be replaced |
the same entry s |
digest summarizing the state |
easily be replaced with |
same entry s object |
summarizing the state of |
be replaced with a |
entry s object appears |
the state of the |
replaced with a different |
with a different one |
state of the sender |
s object appears in |
object appears in another |
appears in another entry |
in another entry with |
another entry with a |
entry with a larger |
the follow up dialog |
with a larger version |
follow up dialog consists |
up dialog consists of |
dialog consists of an |
consists of an explicit |
of an explicit request |
an explicit request of |
explicit request of missing |
request of missing update |
of missing update operations |
were their lengths not |
peer protocols would also |
their lengths not bounded |
protocols would also be |
several details of the |
would also be encapsulated |
details of the epidemic |
also be encapsulated within |
dependency lists could quickly |
of the epidemic protocols |
be encapsulated within their |
lists could quickly grow |
the epidemic protocols employed |
encapsulated within their respective |
could quickly grow to |
epidemic protocols employed in |
within their respective transport |
quickly grow to include |
protocols employed in the |
their respective transport layers |
grow to include all |
employed in the framework |
to include all objects |
in the framework turned |
include all objects in |
the framework turned out |
all objects in the |
framework turned out to |
objects in the database |
turned out to be |
out to be important |
to be important determinants |
be important determinants of |
one version of a |
important determinants of system |
version of a transport |
determinants of system performance |
of a transport layer |
of system performance and |
cache in our scheme |
a transport layer could |
system performance and behavior |
transport layer could fetch |
layer could fetch data |
could fetch data directly |
the cache interacts with |
fetch data directly from |
cache interacts with the |
data directly from a |
suppose that a process |
interacts with the database |
directly from a server |
that a process disseminates |
with the database in |
from a server in |
a process disseminates information |
the database in essentially |
a server in a |
process disseminates information via |
database in essentially the |
server in a data |
in a data center |
in essentially the same |
disseminates information via epidemics |
essentially the same manner |
information via epidemics about |
the same manner as |
via epidemics about a |
whereas a different version |
same manner as for |
epidemics about a subject |
a different version might |
manner as for a |
about a subject s |
different version might use |
as for a consistency |
version might use a |
might use a peer |
process p gossips about |
p gossips about subject |
gossips about subject s |
about subject s a |
subject s a finite |
s a finite number |
a finite number of |
finite number of times |
as long as subject |
long as subject s |
as subject s is |
subject s is hot |
a reliable multicast protocol |
after which subject s |
which subject s is |
it could leverage different |
subject s is no |
could leverage different type |
and receiving invalidations as |
s is no longer |
leverage different type of |
receiving invalidations as the |
is no longer gossiped |
different type of hardware |
invalidations as the database |
no longer gossiped about |
type of hardware or |
as the database updates |
of hardware or be |
the database updates objects |
hardware or be optimized |
explicit requests for copies |
or be optimized for |
requests for copies of |
be optimized for different |
for copies of missed |
optimized for different types |
copies of missed messages |
for different types of |
of missed messages are |
different types of workloads |
missed messages are limited |
messages are limited in |
are limited in size |
the caches read from |
caches read from the |
provided that the different |
read from the database |
that the different versions |
to prevent a process |
from the database not |
the different versions of |
prevent a process that |
the database not only |
different versions of the |
a process that lagged |
database not only the |
versions of the transport |
process that lagged behind |
not only the object |
of the transport layer |
that lagged behind or |
only the object s |
the transport layer conform |
lagged behind or just |
the object s value |
transport layer conform to |
behind or just joined |
layer conform to the |
or just joined from |
conform to the same |
just joined from trying |
but also its version |
to the same standardized |
joined from trying to |
also its version and |
the same standardized event |
from trying to catch |
its version and the |
trying to catch up |
version and the dependency |
to catch up all |
and the dependency list |
catch up all at |
up all at once |
the application could then |
application could then switch |
could then switch between |
then switch between them |
switch between them as |
which would result in |
between them as conditions |
would result in enormous |
the extended cache exports |
them as conditions demand |
result in enormous messages |
extended cache exports a |
in enormous messages and |
cache exports a transactional |
enormous messages and serious |
exports a transactional read |
messages and serious fluctuations |
and serious fluctuations in |
serious fluctuations in system |
fluctuations in system load |
client read requests are |
read requests are extended |
requests are extended with |
users interact through live |
are extended with a |
such a process may |
interact through live objects |
extended with a transaction |
a process may need |
through live objects that |
with a transaction identifier |
process may need to |
live objects that transform |
a transaction identifier and |
may need to catch |
objects that transform actions |
transaction identifier and a |
identifier and a last |
that transform actions into |
need to catch up |
transform actions into updates |
to catch up over |
actions into updates that |
catch up over many |
into updates that are |
up over many seconds |
updates that are communicated |
that are communicated in |
are communicated in the |
communicated in the form |
in the form of |
explicit message requests are |
the form of events |
message requests are honored |
form of events that |
requests are honored if |
of events that are |
are honored if the |
events that are shared |
honored if the requested |
that are shared via |
if the requested messages |
are shared via the |
the requested messages are |
the transaction identifier txnid |
shared via the transport |
requested messages are still |
transaction identifier txnid allows |
via the transport layer |
messages are still in |
identifier txnid allows the |
are still in the |
txnid allows the cache |
still in the bounded |
allows the cache to |
the protocol implemented by |
in the bounded buffers |
the cache to recognize |
protocol implemented by the |
cache to recognize reads |
implemented by the transport |
to recognize reads belonging |
once a message has |
by the transport layer |
recognize reads belonging to |
a message has been |
the transport layer might |
reads belonging to the |
message has been delivered |
transport layer might replicate |
belonging to the same |
has been delivered to |
layer might replicate the |
to the same transaction |
been delivered to the |
might replicate the event |
delivered to the upper |
to the upper levels |
the cache responds with |
cache responds with either |
responds with either the |
deliver it to the |
and it has been |
with either the value |
it to the tablets |
it has been expunged |
either the value of |
to the tablets of |
has been expunged from |
the value of the |
the tablets of our |
been expunged from the |
value of the requested |
tablets of our rescue |
expunged from the buffers |
of the requested object |
of our rescue workers |
from the buffers located |
the buffers located at |
buffers located at the |
located at the gossiper |
at the gossiper level |
or with an abort |
and report it through |
with an abort if |
report it through the |
requests are simply ignored |
an abort if it |
it through the event |
abort if it detects |
if it detects an |
it detects an inconsistency |
the requesting process would |
detects an inconsistency between |
based interface back to |
requesting process would have |
an inconsistency between this |
interface back to the |
process would have to |
inconsistency between this read |
back to the information |
would have to try |
between this read and |
to the information layer |
have to try to |
this read and any |
the information layer at |
to try to find |
read and any of |
information layer at which |
try to find the |
and any of the |
layer at which the |
to find the missing |
any of the previous |
at which the event |
find the missing data |
of the previous reads |
which the event has |
the missing data elsewhere |
the previous reads with |
the event has originated |
previous reads with the |
reads with the same |
with the same transaction |
the same transaction id |
if data cannot be |
data cannot be recovered |
we do not guarantee |
do not guarantee that |
not guarantee that inconsistencies |
guarantee that inconsistencies will |
the transport layer with |
that inconsistencies will be |
we signal this to |
transport layer with the |
inconsistencies will be detected |
layer with the embedded |
signal this to the |
with the embedded distributed |
this to the application |
the embedded distributed protocol |
to the application by |
the lastop allows the |
embedded distributed protocol would |
the application by delivering |
lastop allows the cache |
distributed protocol would behave |
application by delivering an |
allows the cache to |
protocol would behave very |
by delivering an exception |
the cache to garbage |
would behave very much |
delivering an exception upcall |
behave very much like |
very much like an |
much like an object |
like an object in |
an object in smalltalk |
collect its transaction record |
its transaction record after |
transaction record after responding |
record after responding to |
after responding to the |
and leave it to |
it would consume events |
responding to the last |
leave it to the |
would consume events and |
to the last read |
it to the application |
consume events and respond |
the last read operation |
to the application to |
events and respond with |
last read operation of |
the application to decide |
and respond with events |
read operation of the |
application to decide how |
operation of the transaction |
to decide how to |
decide how to handle |
how to handle the |
to handle the problem |
this motivates thinking about |
motivates thinking about communication |
the cache will treat |
thinking about communication protocols |
cache will treat subsequent |
about communication protocols as |
the size of the |
will treat subsequent accesses |
communication protocols as objects |
size of the buffers |
treat subsequent accesses with |
of the buffers is |
subsequent accesses with the |
the buffers is configurable |
accesses with the same |
and indeed in treating |
with the same transaction |
indeed in treating them |
the same transaction id |
but this rule implies |
in treating them as |
same transaction id as |
this rule implies that |
transaction id as new |
treating them as objects |
rule implies that certain |
id as new transactions |
them as objects much |
implies that certain kinds |
as objects much as |
that certain kinds of |
objects much as we |
to implement this interface |
certain kinds of failures |
much as we treat |
kinds of failures may |
as we treat any |
of failures may be |
the cache maintains a |
we treat any other |
failures may be unrecoverable |
cache maintains a record |
treat any other kind |
may be unrecoverable within |
maintains a record of |
any other kind of |
be unrecoverable within the |
a record of each |
other kind of object |
unrecoverable within the ssa |
record of each transaction |
kind of object in |
of each transaction with |
of object in a |
each transaction with its |
object in a language |
digests are bounded in |
transaction with its read |
in a language like |
are bounded in the |
with its read values |
a language like java |
bounded in the number |
language like java or |
in the number of |
like java or in |
the number of messages |
java or in a |
number of messages they |
or in a runtime |
and their dependency lists |
of messages they advertise |
in a runtime environment |
messages they advertise about |
a runtime environment like |
they advertise about in |
on a read of |
a read of keycurr |
advertise about in one |
runtime environment like jini |
about in one single |
environment like jini or |
in one single datagram |
the cache first obtains |
one single datagram packet |
cache first obtains the |
first obtains the requested |
obtains the requested entry |
the requested entry from |
requested entry from memory |
and each round only |
doing so unifies apparently |
each round only a |
so unifies apparently distinct |
round only a single |
unifies apparently distinct approaches |
only a single digest |
a single digest is |
single digest is disseminated |
just as a remotely |
as a remotely hosted |
even if the subset |
a remotely hosted form |
if the subset view |
remotely hosted form of |
the subset view selected |
hosted form of content |
form of content such |
of content such as |
content such as a |
such as a map |
as a map or |
the entry includes the |
a map or an |
entry includes the value |
has cardinality greater than |
map or an image |
cardinality greater than one |
or an image of |
an image of a |
version vercurr and dependency |
image of a raincloud |
vercurr and dependency list |
of a raincloud can |
messages that are potentially |
and dependency list deplistcurr |
a raincloud can be |
that are potentially in |
raincloud can be modeled |
are potentially in transit |
can be modeled as |
the cache checks the |
potentially in transit are |
be modeled as an |
cache checks the currently |
in transit are not |
modeled as an object |
checks the currently read |
transit are not retransmitted |
the currently read object |
are not retransmitted to |
currently read object against |
not retransmitted to requesting |
so can network protocols |
read object against each |
retransmitted to requesting processes |
can network protocols be |
object against each of |
network protocols be treated |
against each of the |
protocols be treated as |
each of the previously |
be treated as objects |
for example if a |
of the previously read |
the previously read objects |
example if a process |
if a process p |
a process p makes |
if a previously read |
process p makes an |
p systems try to |
p makes an explicit |
a previously read version |
makes an explicit request |
systems try to make |
an explicit request for |
previously read version v |
explicit request for a |
try to make everything |
request for a message |
read version v is |
for a message m |
version v is older |
to make everything a |
make everything a p |
v is older than |
a message m and |
is older than expected |
message m and the |
older than expected by |
m and the request |
than expected by the |
and the request lands |
expected by the current |
but in the examples |
the request lands at |
by the current read |
in the examples we |
request lands at process |
the current read s |
the examples we ve |
lands at process q |
current read s dependencies |
examples we ve seen |
at process q that |
read s dependencies v |
process q that has |
s dependencies v k |
q that has already |
several kinds of content |
that has already sent |
kinds of content would |
has already sent p |
of content would more |
already sent p a |
content would more naturally |
sent p a copy |
would more naturally be |
p a copy of |
more naturally be hosted |
a copy of m |
copy of m in |
of m in the |
m in the recent |
in the recent past |
the recent past then |
recent past then m |
past then m will |
then m will not |
m will not be |
will not be retransmitted |
d images of terrain |
images of terrain and |
a process creates a |
of terrain and buildings |
process creates a digest |
creates a digest based |
a digest based upon |
digest based upon all |
based upon all the |
upon all the messages |
all the messages received |
the messages received by |
messages received by means |
received by means of |
by means of any |
means of any communication |
of any communication channels |
not just the epidemics |
on the other hand |
soc applications are likely |
applications are likely to |
are likely to embody |
likely to embody quite |
to embody quite a |
embody quite a range |
or the current read |
quite a range of |
a range of p |
the current read vcurr |
current read vcurr is |
read vcurr is older |
vcurr is older than |
the messages received by |
is older than expected |
messages received by fifo |
older than expected by |
each separate video object |
received by fifo chained |
than expected by the |
by fifo chained channels |
expected by the dependencies |
by the dependencies of |
the dependencies of a |
dependencies of a previous |
of a previous read |
a previous read v |
previous read v v |
the message buffers are |
message buffers are bounded |
may have its own |
have its own associated |
its own associated update |
own associated update stream |
and once a message |
once a message has |
a message has been |
if one thinks of |
message has been delivered |
one thinks of these |
has been delivered by |
thinks of these as |
been delivered by means |
of these as topics |
delivered by means of |
these as topics in |
as topics in publish |
by means of an |
means of an upcall |
of an upcall it |
an upcall it is |
upcall it is prone |
it is prone to |
an inconsistency is detected |
an application could have |
is prone to be |
application could have many |
could have many such |
have many such topics |
prone to be replaced |
otherwise the cache returns |
to be replaced by |
the cache returns the |
and the application instance |
be replaced by the |
cache returns the read |
the application instance running |
replaced by the replacement |
returns the read value |
application instance running on |
by the replacement policy |
the read value to |
instance running on a |
read value to the |
running on a given |
value to the client |
on a given user |
the ssa implements several |
a given user s |
ssa implements several replacement |
upon detecting an inconsistency |
given user s machine |
implements several replacement policies |
user s machine could |
s machine could simultaneously |
machine could simultaneously display |
the cache can take |
could simultaneously display data |
cache can take one |
simultaneously display data from |
can take one of |
display data from several |
take one of three |
one of three paths |
data from several topics |
most advertised message in |
advertised message in digests |
we have previously said |
have previously said that |
previously said that we |
said that we d |
that we d like |
we d like to |
d like to think |
like to think of |
to think of protocols |
think of protocols as |
of protocols as objects |
although the ssa should |
abort the current transaction |
the ssa should work |
ssa should work well |
it now becomes clear |
should work well on |
now becomes clear that |
compared to the other |
work well on clusters |
becomes clear that further |
to the other approaches |
well on clusters with |
clear that further precision |
on clusters with as |
that further precision is |
clusters with as many |
further precision is needed |
this has the benefit |
with as many as |
has the benefit of |
as many as thousands |
the benefit of affecting |
many as thousands of |
the objects aren t |
benefit of affecting only |
as thousands of nodes |
objects aren t merely |
of affecting only the |
aren t merely protocols |
affecting only the running |
only the running transaction |
companies like google and |
the running transaction and |
like google and amazon |
running transaction and limiting |
but in fact are |
google and amazon reportedly |
transaction and limiting collateral |
in fact are individual |
and amazon reportedly operate |
and limiting collateral damage |
fact are individual protocol |
amazon reportedly operate centers |
are individual protocol instances |
reportedly operate centers with |
operate centers with tens |
centers with tens of |
with tens of thousands |
tens of thousands of |
of thousands of machines |
our system will need |
thousands of machines in |
system will need to |
of machines in them |
will need to simultaneously |
need to simultaneously support |
to simultaneously support potentially |
simultaneously support potentially large |
abort the current transaction |
support potentially large numbers |
the current transaction and |
potentially large numbers of |
current transaction and evict |
and are said to |
large numbers of transport |
transaction and evict the |
are said to deploy |
numbers of transport objects |
and evict the violating |
said to deploy some |
of transport objects running |
to deploy some popular |
transport objects running concurrently |
deploy some popular services |
objects running concurrently in |
some popular services on |
running concurrently in the |
popular services on huge |
concurrently in the end |
services on huge numbers |
on huge numbers of |
huge numbers of nodes |
object from the cache |
were we to use |
this approach guesses that |
we to use the |
in support of a |
approach guesses that future |
to use the ssa |
support of a variety |
guesses that future transactions |
use the ssa in |
of a variety of |
that future transactions are |
the ssa in such |
a variety of applications |
future transactions are likely |
ssa in such settings |
variety of applications and |
transactions are likely to |
of applications and uses |
are likely to abort |
likely to abort because |
our gossip protocol might |
to abort because of |
gossip protocol might need |
abort because of this |
all of this leads |
protocol might need to |
because of this object |
of this leads to |
might need to be |
this leads to new |
need to be revisited |
leads to new challenges |
to be revisited to |
be revisited to ensure |
revisited to ensure that |
to ensure that messages |
ensure that messages do |
the obvious one was |
that messages do not |
obvious one was mentioned |
messages do not become |
one was mentioned earlier |
do not become excessively |
not become excessively large |
check which is the |
which is the violating |
is the violating object |
today s web services |
s web services don |
web services don t |
services don t support |
one way to accomplish |
don t support p |
if it is the |
way to accomplish this |
it is the currently |
to accomplish this might |
is the currently accessed |
accomplish this might be |
the currently accessed object |
this might be to |
contemporary web services solutions |
might be to modify |
web services solutions presume |
be to modify the |
services solutions presume a |
to modify the epidemic |
solutions presume a client |
modify the epidemic protocol |
the epidemic protocol using |
epidemic protocol using spatial |
protocol using spatial distributions |
using spatial distributions to |
server style of interaction |
spatial distributions to improve |
distributions to improve the |
to improve the performance |
treat this access as |
this access as a |
with data relayed through |
access as a miss |
data relayed through a |
as a miss and |
relayed through a message |
a miss and respond |
miss and respond to |
and respond to it |
respond to it with |
to it with a |
it with a value |
with a value read |
a value read from |
value read from the |
read from the database |
even if clients are |
such an approach would |
if clients are connected |
an approach would let |
clients are connected to |
approach would let us |
if the violating object |
are connected to one |
would let us restrict |
the violating object was |
let us restrict information |
violating object was returned |
us restrict information to |
object was returned to |
restrict information to the |
was returned to the |
information to the vicinity |
if they lose connectivity |
returned to the user |
to the vicinity of |
they lose connectivity to |
to the user as |
the vicinity of the |
lose connectivity to the |
the user as the |
vicinity of the nodes |
connectivity to the broker |
user as the result |
of the nodes where |
as the result of |
the nodes where it |
the result of a |
nodes where it might |
they can t collaborate |
result of a read |
where it might be |
of a read earlier |
it might be needed |
a read earlier in |
another serious issue arises |
read earlier in the |
serious issue arises if |
earlier in the transaction |
issue arises if the |
in effect adding an |
arises if the clients |
effect adding an additional |
if the clients don |
adding an additional layer |
the clients don t |
an additional layer of |
clients don t trust |
additional layer of hierarchy |
don t trust the |
layer of hierarchy to |
t trust the data |
of hierarchy to the |
trust the data center |
hierarchy to the architecture |
evict the stale object |
the stale object and |
stale object and abort |
object and abort the |
and abort the transaction |
sensitive data will need |
data will need to |
we believe the required |
will need to be |
believe the required changes |
need to be encrypted |
the required changes would |
required changes would be |
changes would be relatively |
would be relatively minor |
consistency with unbounded resources |
the problem here is |
problem here is that |
here is that web |
is that web services |
that web services security |
web services security standards |
services security standards tend |
security standards tend to |
cache detects all inconsistencies |
standards tend to trust |
tend to trust the |
to trust the web |
trust the web services |
the web services platform |
web services platform itself |
as stated in the |
stated in the following |
in the following theorem |
the standards offer no |
standards offer no help |
offer no help at |
no help at all |
help at all if |
at all if we |
epidemic analytical model one |
all if we need |
analytical model one benefit |
if we need to |
model one benefit of |
we need to provide |
one benefit of using |
need to provide end |
benefit of using gossip |
cache with unbounded cache |
of using gossip in |
with unbounded cache size |
using gossip in the |
unbounded cache size and |
gossip in the ssa |
cache size and unbounded |
in the ssa is |
end encryption mechanisms while |
size and unbounded dependency |
the ssa is that |
encryption mechanisms while also |
and unbounded dependency lists |
ssa is that we |
mechanisms while also preventing |
unbounded dependency lists implements |
dependency lists implements cache |
while also preventing the |
is that we can |
also preventing the hosted |
that we can use |
preventing the hosted services |
we can use analytical |
the hosted services from |
can use analytical methods |
hosted services from seeing |
use analytical methods to |
services from seeing the |
analytical methods to predict |
deferred to appendix a |
from seeing the keys |
methods to predict the |
to predict the behavior |
predict the behavior of |
the behavior of a |
behavior of a cluster |
is by constructing a |
by constructing a serialization |
constructing a serialization of |
a serialization of the |
serialization of the transactions |
complementing our experimental work |
of the transactions in |
we encounter debilitating latency |
the transactions in the |
encounter debilitating latency and |
transactions in the database |
debilitating latency and throughput |
a basic result of |
in the database and |
latency and throughput issues |
basic result of epidemic |
the database and in |
result of epidemic theory |
database and in one |
and in one cache |
of epidemic theory states |
hosted services will be |
epidemic theory states that |
services will be performance |
theory states that simple |
based on the fact |
states that simple epidemics |
on the fact that |
that simple epidemics eventually |
the fact that the |
limiting bottlenecks when used |
simple epidemics eventually infect |
fact that the transactions |
bottlenecks when used in |
epidemics eventually infect the |
that the transactions in |
when used in settings |
eventually infect the entire |
the transactions in the |
used in settings with |
infect the entire population |
transactions in the database |
in settings with large |
the entire population with |
in the database are |
settings with large numbers |
entire population with probability |
the database are serializable |
with large numbers of |
database are serializable by |
large numbers of clients |
are serializable by definition |
as we will see |
we will see in |
the implications of theorem |
moreover starting with a |
will see in our |
starting with a single |
see in our experimental |
in our experimental section |
with a single infected |
will be seen in |
a single infected site |
be seen in section |
single infected site this |
seen in section v |
we are left with |
infected site this is |
are left with a |
site this is achieved |
left with a mixture |
this is achieved in |
with a mixture of |
is achieved in expected |
a mixture of good |
achieved in expected time |
mixture of good and |
in expected time proportional |
of good and bad |
good and bad news |
expected time proportional to |
time proportional to the |
proportional to the log |
cache converges to perfect |
to the log of |
web services standardize client |
converges to perfect detection |
the log of the |
services standardize client access |
to perfect detection when |
log of the population |
standardize client access to |
perfect detection when stable |
of the population size |
client access to hosted |
detection when stable clusters |
access to hosted services |
when stable clusters are |
to hosted services and |
stable clusters are as |
hosted services and data |
clusters are as large |
are as large as |
as large as its |
large as its dependency |
as its dependency lists |
we can easily build |
can easily build some |
easily build some form |
in such a scenario |
the protocol roughly falls |
build some form of |
protocol roughly falls under |
some form of multiframed |
roughly falls under the |
the dependency lists are |
form of multiframed web |
falls under the category |
dependency lists are large |
of multiframed web page |
under the category of |
lists are large enough |
multiframed web page that |
the category of a |
are large enough to |
web page that could |
category of a push |
large enough to describe |
page that could host |
enough to describe all |
that could host each |
to describe all relevant |
could host each kind |
describe all relevant dependencies |
host each kind of |
each kind of information |
and the exact formula |
kind of information in |
the exact formula for |
of information in its |
exact formula for it |
information in its own |
formula for it can |
in its own minibrowser |
e xperimental s etup |
for it can be |
xperimental s etup to |
it can be expressed |
s etup to evaluate |
can be expressed as |
be expressed as log |
etup to evaluate the |
when connectivity is adequate |
to evaluate the effectiveness |
evaluate the effectiveness of |
the effectiveness of our |
effectiveness of our scheme |
relaying data via a |
data via a hosted |
via a hosted service |
we implemented a prototype |
a hosted service has |
hosted service has many |
service has many of |
has many of the |
many of the benefits |
to study the properties |
of the benefits of |
study the properties of |
the benefits of a |
the properties of the |
benefits of a publishsubscribe |
properties of the cache |
of a publishsubscribe architecture |
we only need a |
only need a single |
such as robustness as |
need a single column |
as robustness as the |
robustness as the set |
as the set of |
the set of clients |
set of clients changes |
the natural way to |
for large values of |
large values of n |
natural way to think |
way to think of |
to think of our |
namely a single cache |
think of our application |
where n the number |
a single cache backed |
of our application is |
n the number of |
single cache backed by |
our application is as |
the number of sites |
cache backed by a |
application is as an |
number of sites participating |
backed by a single |
is as an object |
of sites participating in |
by a single database |
sites participating in the |
a single database server |
participating in the epidemic |
in the epidemic spread |
but web services provide |
web services provide no |
let pi be the |
services provide no support |
illustrates the structure of |
pi be the probability |
provide no support for |
the structure of our |
be the probability that |
no support for this |
structure of our experimental |
the probability that a |
support for this kind |
of our experimental setup |
probability that a site |
for this kind of |
that a site remains |
this kind of client |
a site remains susceptible |
kind of client application |
a single database implements |
of client application development |
single database implements a |
not touched by the |
database implements a transactional |
touched by the epidemic |
implements a transactional key |
our solution may perform |
solution may perform very |
may perform very poorly |
after the ith round |
the ith round of |
ith round of the |
round of the protocol |
or fail if the |
fail if the hosted |
if the hosted services |
the hosted services are |
hosted services are inaccessible |
a site remains susceptible |
site remains susceptible after |
remains susceptible after the |
susceptible after the i |
all data will probably |
data will probably be |
will probably be visible |
probably be visible to |
be visible to the |
visible to the hosted |
update clients access database |
th round if it |
to the hosted services |
round if it was |
the hosted services unless |
if it was susceptible |
which sends invalidations to |
hosted services unless the |
it was susceptible after |
sends invalidations to the |
services unless the developer |
was susceptible after the |
invalidations to the cache |
unless the developer uses |
susceptible after the ith |
the developer uses some |
after the ith cycle |
developer uses some sort |
the ith cycle and |
uses some sort of |
ith cycle and it |
some sort of non |
only clients access cache |
cycle and it is |
and it is not |
it is not contacted |
is not contacted by |
not contacted by any |
contacted by any infectious |
by any infectious site |
any infectious site in |
infectious site in the |
site in the i |
receives all transactions and |
all transactions and rigorously |
transactions and rigorously detects |
and rigorously detects inconsistencies |
rigorously detects inconsistencies for |
detects inconsistencies for statistics |
using live objects for |
live objects for soc |
objects for soc applications |
for soc applications cornell |
soc applications cornell s |
applications cornell s live |
cornell s live objects |
s live objects platform |
live objects platform supports |
objects platform supports componentized |
relation that we obtain |
that we obtain is |
a set of cache |
set of cache clients |
layered mashup creation and |
of cache clients perform |
mashup creation and sharing |
cache clients perform readonly |
clients perform readonly transactions |
perform readonly transactions through |
readonly transactions through a |
transactions through a single |
and overcomes limitations of |
through a single cache |
a single cache server |
overcomes limitations of existing |
limitations of existing web |
of existing web technologies |
the cache serves the |
cache serves the requests |
serves the requests from |
the major design aspects |
the requests from its |
major design aspects are |
requests from its local |
design aspects are as |
from its local storage |
aspects are as follows |
its local storage if |
since infection starts with |
local storage if possible |
infection starts with one |
starts with one site |
the developer starts by |
developer starts by creating |
or reads from the |
reads from the database |
from the database otherwise |
for any randomly chosen |
or gaining access to |
any randomly chosen site |
randomly chosen site p |
a collection of components |
the cache registers an |
cache registers an upcall |
registers an upcall that |
each component is an |
an upcall that can |
component is an object |
upcall that can be |
is an object that |
that can be used |
can be used by |
an object that supports |
be used by the |
object that supports live |
used by the database |
that supports live functionality |
by the database to |
the database to report |
database to report invalidations |
as a function of |
a function of the |
and exposes eventbased interfaces |
function of the rate |
after each update transaction |
exposes eventbased interfaces by |
of the rate of |
each update transaction the |
eventbased interfaces by which |
the rate of gossip |
update transaction the database |
interfaces by which it |
transaction the database asynchronously |
by which it interacts |
the database asynchronously sends |
we can predict the |
which it interacts with |
can predict the delay |
database asynchronously sends invalidations |
it interacts with other |
predict the delay before |
asynchronously sends invalidations to |
interacts with other components |
the delay before a |
sends invalidations to the |
delay before a typical |
invalidations to the cache |
before a typical process |
to the cache for |
a typical process that |
the cache for all |
typical process that has |
cache for all objects |
components representing hosted content |
process that has been |
representing hosted content sensors |
for all objects that |
hosted content sensors and |
that has been disrupted |
content sensors and actuators |
all objects that were |
sensors and actuators renderers |
has been disrupted by |
and actuators renderers that |
objects that were modified |
actuators renderers that graphically |
been disrupted by a |
renderers that graphically depict |
disrupted by a failure |
that graphically depict events |
by a failure will |
graphically depict events replication |
a failure will learn |
depict events replication protocols |
failure will learn about |
events replication protocols synchronization |
will learn about inconsistency |
replication protocols synchronization protocols |
learn about inconsistency introduced |
protocols synchronization protocols folders |
about inconsistency introduced by |
synchronization protocols folders containing |
inconsistency introduced by the |
protocols folders containing sets |
introduced by the failure |
chosen uniformly at random |
folders containing sets of |
by the failure and |
containing sets of objects |
the failure and can |
are dropped by the |
dropped by the experiment |
sets of objects display |
failure and can initiate |
and can initiate repair |
of objects display interfaces |
objects display interfaces that |
this is extreme and |
display interfaces that visualize |
is extreme and would |
interfaces that visualize folders |
extreme and would only |
and would only be |
would only be seen |
if the model predicts |
only be seen in |
the model predicts that |
mashups of components are |
be seen in the |
model predicts that for |
of components are represented |
seen in the real |
predicts that for a |
components are represented as |
in the real world |
that for a given |
are represented as a |
the real world under |
for a given gossip |
represented as a kind |
real world under conditions |
a given gossip rate |
as a kind of |
world under conditions of |
a kind of xml |
under conditions of overload |
kind of xml web |
of xml web pages |
a broken chain should |
conditions of overload or |
broken chain should be |
of overload or when |
chain should be repaired |
each describing a recipe |
overload or when the |
should be repaired within |
describing a recipe for |
or when the system |
a recipe for obtaining |
when the system configuration |
recipe for obtaining and |
the system configuration is |
for obtaining and parameterizing |
system configuration is changed |
obtaining and parameterizing components |
and parameterizing components that |
parameterizing components that will |
components that will serve |
that will serve as |
will serve as layers |
both the database and |
serve as layers of |
the database and the |
as layers of the |
one can anticipate that |
database and the cache |
can anticipate that the |
layers of the composed |
anticipate that the disruption |
and the cache report |
that the disruption associated |
of the composed mashup |
the cache report all |
the disruption associated with |
cache report all completed |
disruption associated with a |
report all completed transactions |
we call such an |
associated with a failure |
all completed transactions to |
call such an xml |
with a failure should |
completed transactions to a |
such an xml page |
a failure should be |
transactions to a consistency |
an xml page a |
failure should be limited |
to a consistency monitor |
xml page a live |
should be limited to |
page a live object |
be limited to the |
a live object reference |
created in order to |
limited to the maximum |
in order to gather |
to the maximum number |
order to gather statistics |
references can be distributed |
the maximum number of |
to gather statistics for |
can be distributed as |
maximum number of updates |
gather statistics for our |
be distributed as files |
number of updates that |
statistics for our evaluation |
of updates that would |
updates that would be |
that would be sent |
would be sent to |
be sent to a |
sent to a given |
this server collects both |
to a given subservice |
http or other means |
server collects both committed |
a given subservice during |
collects both committed and |
given subservice during a |
both committed and aborted |
an soc application is |
committed and aborted transactions |
soc application is created |
and aborted transactions and |
application is created by |
aborted transactions and it |
is created by building |
transactions and it maintains |
created by building a |
and it maintains the |
by building a forest |
it maintains the full |
building a forest consisting |
maintains the full dependency |
a forest consisting of |
the full dependency graph |
forest consisting of graphs |
consisting of graphs of |
of graphs of references |
if we know how |
graphs of references that |
it performs full serialization |
we know how large |
of references that are |
performs full serialization graph |
know how large the |
references that are mashed |
that are mashed together |
how large the typical |
large the typical update |
the typical update is |
full serialization graph testing |
an automated tool lets |
automated tool lets the |
and we know the |
tool lets the developer |
we know the size |
lets the developer drag |
know the size limit |
and calculates the rate |
the developer drag and |
the size limit on |
calculates the rate of |
developer drag and drop |
size limit on data |
the rate of inconsistent |
drag and drop to |
limit on data sent |
rate of inconsistent transactions |
and drop to combine |
on data sent in |
of inconsistent transactions that |
drop to combine references |
data sent in response |
inconsistent transactions that committed |
to combine references for |
sent in response to |
transactions that committed and |
combine references for individual |
in response to explicit |
that committed and the |
references for individual objects |
response to explicit requests |
committed and the rate |
for individual objects into |
and the rate of |
individual objects into an |
the rate of consistent |
objects into an xml |
we can predict the |
rate of consistent transactions |
into an xml mashup |
can predict the amount |
of consistent transactions that |
an xml mashup of |
predict the amount of |
consistent transactions that were |
xml mashup of references |
the amount of time |
transactions that were unnecessarily |
mashup of references describing |
amount of time that |
that were unnecessarily aborted |
of references describing a |
of time that will |
references describing a graph |
time that will be |
describing a graph of |
our prototype does not |
a graph of objects |
that will be needed |
prototype does not address |
will be needed to |
does not address the |
be needed to repair |
not address the issue |
needed to repair the |
address the issue of |
to repair the resulting |
the issue of cache |
checks mashups to verify |
repair the resulting data |
issue of cache eviction |
mashups to verify that |
the resulting data inconsistency |
of cache eviction when |
to verify that they |
cache eviction when running |
verify that they compose |
eviction when running out |
these capabilities should help |
that they compose correctly |
when running out of |
capabilities should help the |
running out of memory |
should help the developer |
help the developer parameterize |
the developer parameterize the |
developer parameterize the cluster |
parameterize the cluster to |
the cluster to balance |
cluster to balance overhead |
to balance overhead for |
all objects in the |
balance overhead for gossip |
objects in the workload |
overhead for gossip against |
in the workload fit |
d visualization of an |
for gossip against repair |
the workload fit in |
visualization of an airplane |
gossip against repair times |
workload fit in the |
fit in the cache |
against repair times desired |
of an airplane may |
repair times desired by |
an airplane may need |
times desired by the |
and eviction is only |
airplane may need to |
desired by the application |
eviction is only done |
may need to be |
is only done if |
need to be connected |
only done if there |
to be connected to |
done if there is |
be connected to a |
if there is a |
membership some readers may |
connected to a source |
there is a direct |
is a direct reason |
to a source of |
some readers may be |
a source of gps |
readers may be curious |
source of gps and |
may be curious about |
of gps and other |
be curious about what |
gps and other orientation |
had we modeled them |
curious about what will |
and other orientation data |
about what will seem |
what will seem to |
will seem to be |
evictions would reduce the |
seem to be a |
to be a chicken |
would reduce the cache |
which in turn needs |
reduce the cache hit |
in turn needs to |
the cache hit rate |
turn needs to run |
needs to run over |
to run over a |
run over a data |
over a data replication |
but could not cause |
a data replication protocol |
could not cause new |
data replication protocol with |
on the one hand |
not cause new inconsistencies |
replication protocol with specific |
protocol with specific reliability |
we use gossip epidemics |
use gossip epidemics to |
we evaluate the effectiveness |
ordering or security properties |
evaluate the effectiveness of |
gossip epidemics to propagate |
the effectiveness of our |
epidemics to propagate information |
when activated on a |
effectiveness of our transactional |
to propagate information about |
activated on a user |
of our transactional cache |
propagate information about membership |
on a user s |
our transactional cache using |
information about membership changes |
a user s machine |
transactional cache using various |
cache using various workloads |
using various workloads and |
yet the gossip protocol |
an xml mashup yields |
various workloads and varying |
the gossip protocol uses |
xml mashup yields a |
workloads and varying the |
gossip protocol uses membership |
mashup yields a graph |
and varying the size |
protocol uses membership information |
yields a graph of |
varying the size of |
uses membership information to |
a graph of interconnected |
the size of the |
membership information to select |
graph of interconnected proxies |
size of the dependency |
information to select gossip |
of the dependency lists |
to select gossip peers |
the dependency lists maintained |
a proxy is a |
dependency lists maintained by |
proxy is a piece |
lists maintained by the |
is a piece of |
maintained by the cache |
a piece of running |
by the cache and |
piece of running code |
our solution starts with |
the cache and the |
of running code that |
solution starts with approximate |
cache and the database |
running code that may |
code that may render |
starts with approximate membership |
with approximate membership information |
for the cases considered |
extracted from a group |
short dependency lists suffice |
from a group management |
or transform visual content |
a group management service |
group management service component |
management service component that |
service component that list |
encapsulate a protocol stack |
component that list the |
that list the nodes |
list the nodes in |
the nodes in the |
nodes in the cluster |
in the cluster and |
the cluster and the |
cluster and the rough |
and the rough mapping |
the rough mapping of |
an open question for |
rough mapping of services |
open question for further |
mapping of services to |
component in the xml |
question for further study |
of services to those |
in the xml mashup |
for further study is |
services to those nodes |
the xml mashup produces |
further study is whether |
xml mashup produces an |
study is whether there |
mashup produces an associated |
is whether there are |
and then refines this |
produces an associated proxy |
whether there are workloads |
then refines this with |
there are workloads that |
refines this with incremental |
are workloads that might |
this with incremental updates |
the hierarchy of proxies |
workloads that might require |
hierarchy of proxies reflects |
that might require limited |
of proxies reflects the |
might require limited but |
a different concern relates |
proxies reflects the hierarchical |
require limited but larger |
different concern relates to |
reflects the hierarchical structure |
limited but larger values |
concern relates to behavior |
the hierarchical structure of |
relates to behavior when |
hierarchical structure of the |
to behavior when membership |
structure of the xml |
of the xml mashup |
behavior when membership information |
note that dependencies arise |
when membership information is |
that dependencies arise from |
membership information is perceived |
dependencies arise from the |
information is perceived differently |
arise from the topology |
an object proxy can |
is perceived differently at |
from the topology of |
object proxy can initialize |
perceived differently at different |
the topology of the |
proxy can initialize itself |
differently at different nodes |
topology of the object |
can initialize itself by |
of the object graph |
initialize itself by copying |
itself by copying the |
although such a condition |
by copying the state |
such a condition may |
copying the state from |
and not from the |
a condition may arise |
the state from some |
not from the size |
condition may arise during |
state from some active |
from the size of |
may arise during transitional |
from some active proxy |
the size of the |
arise during transitional periods |
size of the transactions |
of the transactions read |
the transactions read and |
our platform assists with |
transactions read and write |
read and write sets |
platform assists with this |
these quickly resolve as |
assists with this sort |
quickly resolve as additional |
with this sort of |
as a baseline for |
a baseline for comparison |
this sort of state |
resolve as additional rounds |
sort of state transfer |
as additional rounds of |
additional rounds of gossip |
we also implemented a |
rounds of gossip replace |
also implemented a timeout |
of gossip replace stale |
gossip replace stale data |
replace stale data with |
stale data with more |
data with more accurate |
the object proxies then |
object proxies then become |
proxies then become active |
it reduces the probability |
reduces the probability of |
the probability of inconsistency |
probability of inconsistency by |
of inconsistency by limiting |
inconsistency by limiting the |
by limiting the life |
limiting the life span |
the life span of |
life span of cache |
we have never observed |
for example by relaying |
span of cache entries |
have never observed a |
example by relaying events |
never observed a membership |
by relaying events from |
observed a membership inconsistency |
relaying events from sensors |
we compare this method |
a membership inconsistency that |
events from sensors into |
compare this method against |
membership inconsistency that persisted |
from sensors into a |
sensors into a replica |
inconsistency that persisted for |
this method against our |
that persisted for longer |
method against our transactional |
persisted for longer than |
against our transactional cache |
for longer than a |
our transactional cache by |
longer than a few |
or by receiving events |
transactional cache by measuring |
than a few hundred |
by receiving events and |
cache by measuring its |
a few hundred milliseconds |
receiving events and reacting |
by measuring its effectiveness |
events and reacting to |
measuring its effectiveness with |
and reacting to them |
its effectiveness with a |
the ssa is quite |
effectiveness with a varying |
ssa is quite tolerant |
with a varying time |
is quite tolerant of |
quite tolerant of short |
by redisplaying an aircraft |
customuserserviceapp heartbeatmonitor gossiper subserviceprocess |
heartbeatmonitor gossiper subserviceprocess chainlink |
gossiper subserviceprocess chainlink subservicecontrol |
subserviceprocess chainlink subservicecontrol nonblockingtransport |
our approach shares certain |
approach shares certain similarities |
shares certain similarities with |
certain similarities with the |
similarities with the existing |
with the existing web |
the existing web development |
existing web development model |
both read and update |
read and update transactions |
and update transactions access |
in the sense that |
the sense that it |
sense that it uses |
that it uses hierarchical |
it uses hierarchical xml |
our experiment satisfies all |
uses hierarchical xml documents |
experiment satisfies all read |
hierarchical xml documents to |
the component stack of |
xml documents to define |
component stack of one |
only transactions from the |
documents to define the |
stack of one subservice |
transactions from the cache |
to define the content |
of one subservice process |
while passing all update |
on the other hand |
passing all update transactions |
all update transactions directly |
update transactions directly to |
transactions directly to the |
directly to the backend |
to the backend database |
we depart from some |
depart from some of |
from some of the |
some of the de |
failure and recovery process |
and recovery process failure |
each cache server is |
recovery process failure detection |
facto stylistic standards that |
cache server is unaware |
process failure detection is |
stylistic standards that have |
server is unaware of |
failure detection is accomplished |
standards that have emerged |
is unaware of the |
detection is accomplished by |
unaware of the other |
is accomplished by means |
of the other servers |
accomplished by means of |
for example if one |
the other servers it |
by means of two |
example if one pulls |
other servers it has |
means of two mechanisms |
if one pulls a |
servers it has its |
one pulls a minibrowser |
it has its own |
pulls a minibrowser from |
has its own clients |
detecting fifo channels that |
a minibrowser from google |
its own clients and |
fifo channels that break |
minibrowser from google earth |
own clients and communicates |
clients and communicates directly |
and communicates directly with |
communicates directly with the |
in our case they |
it expects to interact |
directly with the backend |
our case they are |
expects to interact directly |
with the backend database |
case they are tcp |
to interact directly with |
they are tcp channels |
interact directly with the |
are tcp channels with |
directly with the end |
with the end user |
tcp channels with low |
the percentage of read |
channels with low value |
with low value for |
low value for the |
and includes embedded javascript |
value for the so |
includes embedded javascript that |
for the so timeout |
only transactions can be |
embedded javascript that handles |
the so timeout property |
transactions can be arbitrarily |
javascript that handles such |
can be arbitrarily high |
that handles such interactions |
be arbitrarily high or |
arbitrarily high or low |
high or low in |
or low in this |
low in this situation |
based heartbeat detection mechanism |
the same functionality would |
same functionality would be |
we can push the |
functionality would be represented |
can push the percentage |
once a process is |
a process is deceased |
push the percentage up |
would be represented as |
be represented as a |
represented as a mashup |
the information is propagated |
as a mashup of |
information is propagated within |
our simulation focuses on |
a mashup of a |
is propagated within the |
simulation focuses on just |
mashup of a component |
propagated within the group |
focuses on just a |
of a component that |
within the group in |
on just a single |
a component that fetches |
the group in two |
just a single cache |
component that fetches maps |
group in two ways |
a single cache it |
that fetches maps and |
single cache it would |
fetches maps and similar |
cache it would behave |
maps and similar content |
it would behave the |
and similar content with |
would behave the same |
similar content with a |
the process that has |
behave the same had |
content with a second |
process that has detected |
the same had there |
with a second component |
that has detected the |
same had there been |
a second component that |
has detected the membership |
had there been many |
second component that provides |
detected the membership change |
there been many cache |
component that provides the |
the membership change feeds |
been many cache servers |
that provides the visualization |
membership change feeds the |
provides the visualization interface |
change feeds the event |
feeds the event description |
the event description into |
event description into the |
description into the chain |
into the chain itself |
although the term mashup |
the term mashup may |
term mashup may sound |
mashup may sound static |
this is delivered in |
cache can be used |
is delivered in chain |
in the sense of |
can be used with |
delivered in chain order |
the sense of having |
be used with any |
in chain order to |
sense of having its |
used with any transactional |
chain order to every |
of having its components |
with any transactional backend |
order to every non |
having its components predetermined |
any transactional backend and |
transactional backend and any |
backend and any transactional |
and any transactional workload |
faulty process and where |
process and where necessary |
this is not necessarily |
is not necessarily the |
not necessarily the case |
chain repair procedure is |
repair procedure is undertaken |
one kind of live |
only transactions will be |
kind of live object |
transactions will be similar |
of live object could |
will be similar to |
be similar to non |
live object could be |
the same detector process |
object could be a |
same detector process starts |
could be a folder |
detector process starts up |
be a folder including |
process starts up a |
a folder including a |
starts up a backup |
the underlying database is |
folder including a set |
up a backup gossip |
underlying database is only |
including a set of |
a set of objects |
database is only accessed |
a backup gossip notification |
is only accessed on |
backup gossip notification stream |
only accessed on cache |
accessed on cache misses |
for example extracted from |
example extracted from a |
this is a fast |
is a fast dying |
a fast dying epidemic |
extracted from a directory |
from a directory in |
a directory in a |
inconsistencies may be observed |
directory in a file |
it spreads rapidly but |
in a file system |
spreads rapidly but also |
a file system or |
rapidly but also dies |
file system or pulled |
but also dies out |
system or pulled from |
also dies out rapidly |
we will use synthetic |
or pulled from a |
will use synthetic workloads |
pulled from a database |
use synthetic workloads so |
from a database in |
the fifo channels are |
synthetic workloads so we |
a database in response |
fifo channels are rebuilt |
workloads so we can |
database in response to |
channels are rebuilt appropriately |
so we can evaluate |
in response to a |
are rebuilt appropriately by |
we can evaluate how |
response to a query |
rebuilt appropriately by the |
can evaluate how much |
appropriately by the processes |
evaluate how much inconsistency |
by the processes that |
when the folder contents |
how much inconsistency can |
the processes that identify |
the folder contents change |
much inconsistency can be |
processes that identify themselves |
inconsistency can be observed |
that identify themselves to |
can be observed as |
the mashup is dynamically |
identify themselves to be |
be observed as a |
mashup is dynamically updated |
themselves to be affected |
observed as a function |
to be affected by |
as a function of |
be affected by the |
a function of the |
as might occur when |
affected by the membership |
function of the amount |
might occur when a |
by the membership change |
of the amount of |
occur when a rescue |
the amount of clustering |
when a rescue worker |
amount of clustering in |
a rescue worker enters |
and the group converges |
of clustering in the |
rescue worker enters a |
the group converges to |
clustering in the workload |
worker enters a building |
group converges to a |
enters a building or |
converges to a stable |
a building or turns |
to a stable configuration |
this also allows us |
building or turns a |
or turns a corner |
also allows us to |
allows us to look |
us to look at |
to look at the |
look at the dynamic |
at the dynamic behavior |
the dynamic behavior of |
dynamic behavior of the |
update sources can use |
behavior of the system |
sources can use this |
live objects can easily |
can use this update |
objects can easily support |
use this update to |
when the amount of |
this update to reconnect |
can easily support applications |
the amount of clustering |
update to reconnect to |
easily support applications that |
amount of clustering and |
to reconnect to a |
support applications that dynamically |
of clustering and the |
reconnect to a new |
applications that dynamically recompute |
clustering and the clustering |
to a new head |
that dynamically recompute the |
and the clustering formation |
a new head of |
dynamically recompute the set |
the clustering formation change |
new head of any |
recompute the set of |
clustering formation change over |
head of any chain |
the set of visible |
formation change over time |
of any chain that |
set of visible objects |
any chain that may |
chain that may have |
that may have lost |
may have lost its |
have lost its previous |
as a function of |
lost its previous head |
we will look at |
a function of location |
its previous head as |
will look at workloads |
function of location and |
previous head as a |
look at workloads based |
of location and orientation |
head as a consequence |
at workloads based on |
as a consequence of |
workloads based on amazon |
a consequence of the |
based on amazon s |
and dynamically add or |
consequence of the crash |
on amazon s product |
dynamically add or remove |
amazon s product co |
add or remove them |
or remove them from |
remove them from the |
them from the mashup |
purchasing and orkut s |
if a process wants |
and orkut s social |
a process wants to |
process wants to join |
a rescuer would automatically |
orkut s social network |
rescuer would automatically and |
s social network to |
would automatically and instantly |
social network to see |
it starts by sending |
automatically and instantly be |
network to see how |
starts by sending a |
and instantly be shown |
to see how much |
by sending a request |
instantly be shown the |
see how much inconsistency |
sending a request to |
be shown the avatars |
how much inconsistency t |
a request to a |
shown the avatars of |
request to a random |
the avatars of others |
to a random member |
avatars of others who |
cache can detect as |
a random member of |
of others who are |
can detect as a |
random member of the |
others who are already |
detect as a function |
member of the group |
who are already working |
as a function of |
are already working at |
a function of dependency |
already working at that |
function of dependency list |
working at that site |
of dependency list length |
the group member will |
group member will commence |
member will commence a |
will commence a membership |
and compare this with |
and be able to |
commence a membership change |
compare this with a |
this with a ttl |
a membership change protocol |
be able to participate |
membership change protocol as |
able to participate in |
change protocol as described |
to participate in conference |
protocol as described above |
we are also interested |
are also interested in |
also interested in overhead |
again once all the |
once all the nodes |
all the nodes receive |
the nodes receive the |
particularly the additional load |
nodes receive the membership |
the additional load on |
point dialog with them |
receive the membership event |
additional load on the |
the membership event and |
load on the backend |
membership event and update |
through chat objects that |
on the backend database |
event and update their |
chat objects that run |
the backend database that |
and update their view |
objects that run over |
backend database that could |
that run over multicast |
database that could form |
run over multicast protocol |
that could form if |
over multicast protocol objects |
could form if the |
form if the the |
if the the rate |
the the rate of |
the rate of cache |
rate of cache misses |
of cache misses increases |
implementation details the framework |
this model can support |
details the framework was |
model can support a |
the framework was implemented |
can support a wide |
framework was implemented using |
support a wide variety |
was implemented using the |
a wide variety of |
b presented three strategies |
implemented using the java |
wide variety of collaboration |
presented three strategies for |
using the java language |
variety of collaboration and |
three strategies for responding |
the java language and |
of collaboration and coordination |
strategies for responding to |
java language and its |
collaboration and coordination paradigms |
for responding to inconsistency |
language and its non |
responding to inconsistency detection |
for both the synthetic |
both the synthetic and |
the live objects platform |
the synthetic and realistic |
live objects platform makes |
synthetic and realistic workloads |
objects platform makes it |
platform makes it easy |
the system design was |
makes it easy for |
system design was strongly |
we compare the efficacy |
it easy for a |
design was strongly influenced |
compare the efficacy of |
easy for a non |
was strongly influenced by |
the efficacy of the |
strongly influenced by prior |
efficacy of the three |
programmer to create the |
influenced by prior work |
of the three strategies |
to create the needed |
by prior work on |
create the needed soc |
prior work on highperformance |
the needed soc application |
work on highperformance services |
on highperformance services platforms |
synthetic workloads synthetic workloads |
the rescue coordinator pulls |
workloads synthetic workloads allow |
rescue coordinator pulls prebuilt |
notably welsh s seda |
synthetic workloads allow us |
coordinator pulls prebuilt object |
welsh s seda architecture |
workloads allow us to |
pulls prebuilt object references |
allow us to understand |
prebuilt object references from |
us to understand the |
object references from a |
to understand the efficacy |
references from a folder |
understand the efficacy of |
the efficacy of t |
each corresponding to a |
corresponding to a desired |
cache as a function |
to a desired kind |
as a function of |
a desired kind of |
a function of clustering |
desired kind of information |
components are highly autonomous |
for the experiments described |
the experiments described here |
cache with a maximum |
there are only four |
with a maximum of |
are only four distinct |
only four distinct control |
four distinct control threads |
distinct control threads in |
control threads in the |
elements per dependency list |
would correspond to objects |
threads in the component |
correspond to objects that |
in the component stack |
to objects that point |
the component stack of |
objects that point to |
component stack of a |
that point to a |
stack of a process |
point to a web |
to a web service |
a web service over |
describes synthetic workload generation |
web service over the |
service over the network |
namely one for the |
measures how many inconsistencies |
one for the non |
peer objects would implement |
how many inconsistencies we |
for the non blocking |
objects would implement chat |
many inconsistencies we can |
the non blocking transport |
would implement chat windows |
inconsistencies we can detect |
we can detect as |
can detect as a |
detect as a function |
as a function of |
a function of clustering |
function of clustering and |
of clustering and section |
clustering and section v |
the tcp chain and |
tcp chain and for |
chain and for the |
and for the heartbeat |
for the heartbeat component |
event interfaces allow such |
interfaces allow such objects |
allow such objects to |
considers clustering changes over |
such objects to coexist |
clustering changes over time |
objects to coexist in |
the ssa is roughly |
to coexist in a |
coexist in a shared |
in a shared display |
a shared display window |
shared display window that |
display window that can |
window that can pan |
compares the efficacy of |
the efficacy of various |
efficacy of various approaches |
jump to new locations |
of various approaches to |
various approaches to dealing |
approaches to dealing with |
to dealing with detected |
dealing with detected inconsistencies |
the relative advantages and |
relative advantages and disadvantages |
advantages and disadvantages of |
and disadvantages of our |
disadvantages of our model |
of our model can |
our model can be |
model can be summarized |
can be summarized as |
be summarized as follows |
our basic synthetic workload |
like other modern web |
basic synthetic workload is |
other modern web development |
synthetic workload is constructed |
modern web development tools |
workload is constructed as |
is constructed as follows |
our platform supports drag |
drop style of development |
easy creation of content |
the resulting solutions are |
resulting solutions are easy |
solutions are easy to |
are easy to share |
by selecting appropriate transport |
selecting appropriate transport layers |
functionality such as coordination |
such as coordination between |
the objects are divided |
as coordination between searchers |
objects are divided into |
coordination between searchers can |
are divided into clusters |
between searchers can remain |
divided into clusters of |
searchers can remain active |
into clusters of size |
can remain active even |
remain active even if |
active even if connectivity |
even if connectivity to |
if connectivity to the |
connectivity to the data |
to the data center |
the data center is |
data center is disrupted |
streams of video or |
of video or sensor |
video or sensor data |
or sensor data can |
sensor data can travel |
data can travel directly |
can travel directly and |
travel directly and won |
directly and won t |
and won t be |
won t be delayed |
t be delayed by |
be delayed by the |
delayed by the need |
by the need to |
the need to ricochet |
need to ricochet off |
to ricochet off a |
ricochet off a remote |
off a remote and |
a remote and potentially |
remote and potentially inaccessible |
and potentially inaccessible server |
based interoperability standards are |
interoperability standards are needed |
we could lose access |
could lose access to |
lose access to some |
access to some of |
to some of the |
some of the sophisticated |
of the sophisticated proprietary |
the sophisticated proprietary interactive |
sophisticated proprietary interactive functionality |
proprietary interactive functionality optimized |
interactive functionality optimized for |
functionality optimized for proprietary |
optimized for proprietary minibrowser |
and there are two |
there are two types |
are two types of |
two types of workloads |
based solutions with an |
solutions with an embedded |
with an embedded javascript |
clustering is perfect and |
is perfect and each |
perfect and each transaction |
and each transaction chooses |
each transaction chooses a |
transaction chooses a single |
chooses a single cluster |
a single cluster and |
single cluster and chooses |
peer communication can be |
communication can be much |
can be much harder |
be much harder to |
times with repetitions within |
much harder to use |
with repetitions within this |
harder to use than |
repetitions within this cluster |
to use than relaying |
within this cluster to |
use than relaying data |
this cluster to establish |
than relaying data through |
cluster to establish its |
relaying data through a |
to establish its access |
data through a hosted |
establish its access set |
through a hosted service |
a hosted service that |
hosted service that uses |
service that uses an |
that uses an enterprise |
uses an enterprise service |
in the second type |
an enterprise service bus |
the second type of |
second type of workloads |
type of workloads access |
of workloads access is |
workloads access is not |
access is not fully |
is not fully contained |
not fully contained within |
fully contained within each |
contained within each cluster |
when a transaction starts |
the lack of a |
lack of a one |
it chooses a cluster |
of a one size |
chooses a cluster uniformly |
a one size fits |
one size fits all |
size fits all publish |
a cluster uniformly at |
cluster uniformly at random |
subscribe substrate forces the |
substrate forces the developers |
forces the developers to |
the developers to become |
developers to become familiar |
to become familiar with |
become familiar with and |
familiar with and choose |
with and choose between |
each object is chosen |
and choose between a |
object is chosen using |
choose between a range |
is chosen using a |
between a range of |
chosen using a bounded |
a range of different |
using a bounded pareto |
range of different and |
of different and incompatible |
different and incompatible options |
a bounded pareto distribution |
bounded pareto distribution starting |
pareto distribution starting at |
distribution starting at detected |
starting at detected inconsistencies |
an wrong choice of |
wrong choice of transport |
choice of transport could |
of transport could result |
transport could result in |
could result in degraded |
result in degraded qos |
or even data loss |
update clients access the |
clients access the database |
access the database at |
the database at a |
database at a rate |
at a rate of |
second life as a |
life as a soc |
as a soc application |
a soc application up |
soc application up to |
application up to now |
we have focused on |
have focused on a |
focused on a small |
only clients access the |
clients access the cache |
access the cache at |
the cache at a |
cache at a rate |
at a rate of |
but our longer term |
our longer term goal |
longer term goal is |
term goal is to |
goal is to support |
is to support a |
to support a large |
scale nextgeneration collaboration system |
nextgeneration collaboration system similar |
collaboration system similar to |
system similar to second |
similar to second life |
a virtual reality immersion |
virtual reality immersion system |
reality immersion system created |
immersion system created by |
system created by linden |
created by linden labs |
second life is implemented |
life is implemented with |
is implemented with a |
implemented with a data |
with a data center |
a data center including |
data center including a |
center including a large |
including a large number |
a large number of |
large number of servers |
number of servers storing |
of servers storing the |
servers storing the state |
storing the state of |
the state of the |
state of the virtual |
of the virtual world |
the locations of all |
locations of all users |
then move about and |
move about and interact |
about and interact with |
and interact with others |
one can create a |
can create a cybercaf |
as other second life |
other second life users |
second life users enter |
life users enter the |
users enter the room |
they can interact with |
can interact with the |
interact with the environment |
with the environment and |
the environment and one |
in the second life |
the second life architecture |
whenever an avatar moves |
an avatar moves or |
avatar moves or performs |
moves or performs some |
or performs some action |
performs some action in |
some action in the |
action in the virtual |
in the virtual world |
a request describing this |
request describing this event |
describing this event is |
this event is passed |
event is passed to |
is passed to the |
passed to the hosting |
to the hosting data |
the hosting data center |
hosting data center and |
data center and processed |
center and processed by |
and processed by servers |
processed by servers running |
by servers running there |
clients do perform a |
do perform a variety |
ratio of inconsistencies as |
perform a variety of |
of inconsistencies as a |
a variety of decoding |
inconsistencies as a function |
variety of decoding and |
as a function of |
of decoding and rendering |
decoding and rendering functions |
and rendering functions locally |
the head of its |
head of its cluster |
of its cluster i |
but the data center |
the data center must |
data center must be |
center must be in |
must be in the |
be in the loop |
in the loop to |
the loop to ensure |
loop to ensure that |
to ensure that all |
ensure that all users |
that all users observe |
all users observe consistent |
users observe consistent state |
if the pareto variable |
when the number of |
the pareto variable plus |
the number of users |
pareto variable plus the |
number of users in |
variable plus the offset |
of users in a |
plus the offset results |
users in a scenario |
in a scenario isn |
a scenario isn t |
scenario isn t huge |
the offset results in |
offset results in a |
results in a number |
in a number outside |
a number outside the |
number outside the range |
second life can easily |
life can easily keep |
can easily keep up |
easily keep up using |
keep up using a |
up using a standard |
using a standard workload |
a standard workload partitioning |
standard workload partitioning scheme |
workload partitioning scheme in |
partitioning scheme in which |
scheme in which different |
in which different servers |
which different servers handle |
different servers handle different |
servers handle different portions |
handle different portions of |
different portions of the |
portions of the virtual |
of the virtual world |
for example because large |
example because large numbers |
because large numbers of |
large numbers of users |
numbers of users want |
of users want to |
users want to enter |
want to enter the |
to enter the same |
the count wraps back |
count wraps back to |
enter the same virtual |
the same virtual discotheque |
the servers can become |
servers can become overwhelmed |
can become overwhelmed and |
become overwhelmed and are |
overwhelmed and are forced |
and are forced to |
are forced to reject |
forced to reject some |
to reject some of |
reject some of the |
some of the users |
of the users or |
the users or reduce |
users or reduce their |
or reduce their frame |
inconsistency detection as a |
detection as a function |
as a function of |
rendering rates and resolution |
we start by exploring |
start by exploring the |
by exploring the importance |
exploring the importance of |
the importance of the |
second life might seem |
life might seem jumpy |
might seem jumpy and |
seem jumpy and unrealistic |
importance of the cluster |
of the cluster structure |
the cluster structure by |
cluster structure by varying |
structure by varying the |
second life as a |
by varying the parameter |
life as a live |
varying the parameter of |
as a live objects |
the parameter of the |
a live objects application |
parameter of the pareto |
of the pareto distribution |
live objects application poses |
objects application poses some |
application poses some new |
poses some new challenges |
we vary the pareto |
vary the pareto parameter |
the pareto parameter from |
on the one hand |
many aspects of the |
aspects of the application |
of the application can |
the application can be |
application can be addressed |
can be addressed in |
be addressed in the |
addressed in the same |
in the same manner |
the same manner we |
same manner we ve |
manner we ve outlined |
we ve outlined for |
ve outlined for the |
outlined for the search |
for the search and |
the search and rescue |
search and rescue application |
in this experiment we |
this experiment we are |
experiment we are only |
we are only interested |
are only interested in |
only interested in detection |
one could use microsoft |
could use microsoft virtual |
use microsoft virtual earth |
so we choose the |
we choose the abort |
choose the abort strategy |
as a source of |
shows the ratio of |
d textures representing landscapes |
the ratio of inconsistencies |
ratio of inconsistencies detected |
of inconsistencies detected by |
inconsistencies detected by t |
cache compared to the |
compared to the total |
to the total number |
the total number of |
total number of potential |
number of potential inconsistencies |
as seen by the |
seen by the entire |
by the entire chain |
in standards for creating |
standards for creating mashups |
for creating mashups could |
creating mashups could be |
mashups could be used |
could be used to |
be used to identify |
the distribution is almost |
used to identify sensors |
distribution is almost uniform |
to identify sensors and |
is almost uniform across |
identify sensors and other |
almost uniform across the |
sensors and other data |
uniform across the object |
across the object set |
and other data sources |
and the inconsistency detection |
the inconsistency detection ratio |
which could then be |
inconsistency detection ratio is |
could then be wrapped |
detection ratio is low |
then be wrapped as |
ratio is low the |
be wrapped as live |
is low the dependency |
wrapped as live objects |
low the dependency lists |
as live objects and |
the dependency lists are |
live objects and incorporated |
dependency lists are too |
objects and incorporated into |
lists are too small |
and incorporated into live |
are too small to |
incorporated into live scenes |
too small to hold |
small to hold all |
to hold all relevant |
hold all relevant information |
on top of this |
at the other extreme |
streaming media sources such |
media sources such as |
sources such as video |
such as video cameras |
as video cameras mounted |
video cameras mounted at |
cameras mounted at street |
mounted at street level |
at street level in |
street level in places |
level in places such |
in places such as |
places such as tokyo |
the distribution is so |
such as tokyo s |
distribution is so spiked |
as tokyo s ginza |
is so spiked that |
experimental results and validation |
tokyo s ginza can |
so spiked that almost |
s ginza can be |
spiked that almost all |
ginza can be added |
that almost all accesses |
can be added to |
almost all accesses of |
be added to create |
all accesses of a |
added to create realistic |
accesses of a transaction |
to create realistic experience |
of a transaction are |
a transaction are within |
transaction are within a |
are within a cluster |
the more complex issue |
more complex issue is |
allowing for perfect inconsistency |
complex issue is that |
for perfect inconsistency detection |
issue is that a |
is that a search |
that a search and |
a search and rescue |
search and rescue application |
we note that the |
and rescue application can |
note that the rate |
rescue application can be |
that the rate of |
application can be imagined |
the rate of detected |
can be imagined as |
rate of detected inconsistencies |
be imagined as a |
of detected inconsistencies is |
the tests reported here |
detected inconsistencies is so |
imagined as a situational |
inconsistencies is so high |
tests reported here employ |
reported here employ a |
is so high at |
as a situational state |
here employ a hard |
so high at this |
a situational state fully |
high at this point |
situational state fully replicated |
at this point that |
state fully replicated across |
this point that much |
fully replicated across all |
point that much of |
replicated across all of |
across all of its |
all of its users |
that much of the |
the ssa is a |
much of the load |
ssa is a work |
of the load goes |
is a work in |
the load goes to |
a work in progress |
load goes to the |
all machines would see |
goes to the backend |
machines would see all |
to the backend database |
would see all the |
see all the state |
all the state updates |
the backend database and |
fledged system will use |
backend database and saturates |
system will use a |
database and saturates it |
even if the user |
will use a software |
if the user is |
use a software partitioning |
the user is zoomed |
a software partitioning mechanism |
reducing the overall throughput |
user is zoomed into |
software partitioning mechanism based |
is zoomed into some |
partitioning mechanism based on |
zoomed into some particular |
mechanism based on the |
into some particular spot |
based on the web |
some particular spot within |
on the web services |
particular spot within the |
the web services request |
spot within the overall |
web services request invocation |
within the overall scene |
services request invocation model |
so far we have |
far we have considered |
we have considered behavior |
have considered behavior with |
considered behavior with static |
behavior with static clusters |
although extracting the partitioning |
extracting the partitioning key |
the partitioning key from |
partitioning key from incoming |
one can contemplate such |
key from incoming requests |
can contemplate such an |
from incoming requests will |
contemplate such an approach |
over the entire run |
incoming requests will impose |
requests will impose some |
will impose some overhead |
such an approach because |
the entire run of |
an approach because the |
entire run of each |
we do not expect |
approach because the aggregate |
run of each experiment |
do not expect performance |
because the aggregate amount |
of each experiment accesses |
not expect performance of |
the aggregate amount of |
each experiment accesses are |
expect performance of the |
performance of the full |
experiment accesses are confined |
aggregate amount of information |
accesses are confined to |
amount of information might |
are confined to the |
of information might not |
fledged system to deviate |
confined to the same |
information might not be |
system to deviate significantly |
might not be that |
to deviate significantly from |
not be that large |
deviate significantly from what |
significantly from what is |
from what is reported |
what is reported below |
second life conceptually is |
life conceptually is a |
conceptually is a whole |
is a whole universe |
in a real system |
unbounded in size and |
in size and hence |
size and hence with |
and hence with different |
hence with different users |
and so if t |
with different users in |
different users in very |
users in very distinct |
in very distinct parts |
very distinct parts of |
distinct parts of the |
cache converges to maintain |
parts of the space |
converges to maintain the |
to maintain the correct |
maintain the correct dependency |
the correct dependency lists |
correct dependency lists as |
dependency lists as clusters |
it would make no |
lists as clusters change |
would make no sense |
make no sense for |
no sense for every |
sense for every user |
for every user to |
every user to see |
user to see every |
to see every event |
our setup serves as |
setup serves as a |
serves as a valid |
as a valid quasi |
we would solve this |
would solve this problem |
solve this problem using |
this problem using the |
problem using the dynamic |
using the dynamic database |
the dynamic database querying |
dynamic database querying approach |
we investigate the convergence |
database querying approach outlined |
investigate the convergence of |
querying approach outlined in |
the convergence of t |
approach outlined in section |
cache when clusters change |
when clusters change over |
clusters change over time |
each user would see |
user would see only |
since the dependency lists |
would see only the |
the dependency lists of |
see only the objects |
dependency lists of the |
only the objects within |
the objects within some |
objects within some range |
lists of the objects |
of the objects are |
the objects are updated |
objects are updated using |
are updated using lru |
or within line of |
within line of sight |
the dependency list of |
as a user moves |
dependency list of an |
a user moves about |
list of an object |
of an object o |
an object o tends |
object o tends to |
o tends to include |
the platform would recompute |
tends to include those |
platform would recompute the |
to include those objects |
would recompute the query |
include those objects that |
update injection time against |
recompute the query result |
those objects that are |
injection time against delivery |
objects that are frequently |
time against delivery time |
that are frequently accessed |
against delivery time at |
and then update the |
are frequently accessed together |
delivery time at node |
then update the display |
frequently accessed together with |
update the display accordingly |
accessed together with o |
dependencies in a new |
in a new cluster |
a new cluster automatically |
new cluster automatically push |
cluster automatically push out |
automatically push out dependencies |
push out dependencies that |
that since some live |
out dependencies that are |
since some live objects |
dependencies that are now |
some live objects uses |
that are now outside |
live objects uses p |
are now outside the |
now outside the cluster |
p protocols that might |
protocols that might organize |
that might organize user |
might organize user s |
organize user s machines |
user s machines into |
s machines into groups |
machines into groups forwarding |
into groups forwarding streams |
groups forwarding streams of |
we perform an experiment |
forwarding streams of data |
perform an experiment where |
streams of data to |
an experiment where accesses |
of data to one |
data to one another |
experiment where accesses suddenly |
where accesses suddenly become |
accesses suddenly become clustered |
we end up in |
end up in a |
initially accesses are uniformly |
up in a situation |
accesses are uniformly at |
in a situation where |
are uniformly at random |
a situation where each |
uniformly at random from |
situation where each user |
at random from the |
where each user belongs |
random from the entire |
each user belongs to |
from the entire set |
user belongs to a |
belongs to a potentially |
to a potentially large |
a potentially large number |
potentially large number of |
large number of such |
number of such groups |
and the groups that |
the groups that one |
groups that one user |
that one user is |
one user is a |
user is a part |
is a part of |
a part of might |
part of might be |
of might be very |
might be very different |
be very different from |
very different from the |
different from the groups |
from the groups that |
then at a single |
the groups that other |
at a single moment |
groups that other users |
a single moment they |
that other users belong |
single moment they become |
other users belong to |
moment they become perfectly |
they become perfectly clustered |
become perfectly clustered into |
perfectly clustered into clusters |
clustered into clusters of |
into clusters of size |
to support such a |
support such a model |
we need to be |
need to be able |
to be able to |
transactions are aborted on |
be able to support |
are aborted on detecting |
aborted on detecting an |
on detecting an inconsistency |
able to support very |
to support very large |
support very large numbers |
very large numbers of |
large numbers of publish |
we use a transaction |
use a transaction rate |
a transaction rate of |
transaction rate of approximately |
and with different users |
with different users subscribed |
different users subscribed to |
users subscribed to very |
subscribed to very different |
to very different sets |
very different sets of |
different sets of topics |
up to now we |
to now we have |
now we have been |
we have been fairly |
have been fairly negative |
been fairly negative about |
fairly negative about the |
negative about the trend |
about the trend to |
the trend to standardize |
trend to standardize client |
to standardize client access |
standardize client access to |
client access to hosted |
access to hosted content |
to hosted content through |
shows the percentage of |
hosted content through web |
the percentage of transactions |
content through web minibrowsers |
update delay as seen |
percentage of transactions that |
through web minibrowsers that |
delay as seen by |
as seen by individual |
seen by individual processes |
of transactions that commit |
web minibrowsers that make |
transactions that commit and |
minibrowsers that make the |
that commit and are |
that make the javascript |
commit and are consistent |
make the javascript running |
the javascript running on |
javascript running on a |
running on a user |
on a user s |
a user s machine |
user s machine virtually |
s machine virtually inseparable |
machine virtually inseparable from |
virtually inseparable from the |
inseparable from the data |
from the data center |
the percentage of transactions |
percentage of transactions that |
of transactions that commit |
our core criticism was |
transactions that commit but |
core criticism was that |
that commit but are |
criticism was that for |
commit but are inconsistent |
was that for most |
that for most soc |
for most soc applications |
a minibrowser approach would |
minibrowser approach would lack |
approach would lack the |
would lack the flexibility |
lack the flexibility to |
the flexibility to seamlessly |
and the percentage of |
flexibility to seamlessly combine |
the percentage of transactions |
to seamlessly combine content |
percentage of transactions that |
seamlessly combine content from |
of transactions that abort |
combine content from different |
content from different sources |
and to customize the |
to customize the underlying |
customize the underlying communication |
the underlying communication substrate |
our earlier concerns carry |
earlier concerns carry over |
concerns carry over to |
carry over to the |
over to the second |
to the second life |
the second life scenario |
d texture representing terrain |
texture representing terrain in |
representing terrain in some |
terrain in some region |
our experiments were conducted |
experiments were conducted using |
were conducted using the |
conducted using the ssa |
using the ssa framework |
the ssa framework deployed |
ssa framework deployed on |
framework deployed on a |
deployed on a tightly |
on a tightly coupled |
a tightly coupled homogeneous |
tightly coupled homogeneous cluster |
coupled homogeneous cluster of |
in a minibrowser approach |
the minibrowser generates the |
minibrowser generates the texture |
generates the texture from |
the texture from hosted |
texture from hosted data |
the nodes are connected |
nodes are connected by |
are connected by two |
connected by two separate |
by two separate high |
two separate high speed |
separate high speed ethernet |
high speed ethernet backbone |
speed ethernet backbone planes |
we experimented with several |
this model makes it |
experimented with several configurations |
model makes it difficult |
some placed the control |
placed the control traffic |
the control traffic on |
to superimpose other content |
control traffic on a |
superimpose other content over |
traffic on a different |
other content over the |
on a different switched |
content over the texture |
a different switched ethernet |
different switched ethernet segment |
switched ethernet segment while |
ethernet segment while others |
segment while others aggregated |
abort evict retry behavior |
while others aggregated both |
evict retry behavior on |
we would need to |
others aggregated both the |
retry behavior on inconsistency |
would need to rely |
aggregated both the control |
behavior on inconsistency detection |
need to rely on |
both the control traffic |
to rely on a |
the control traffic and |
rely on a hosting |
control traffic and the |
on a hosting system |
traffic and the data |
a hosting system s |
and the data traffic |
hosting system s mashup |
the data traffic on |
system s mashup technology |
data traffic on the |
s mashup technology to |
mashup technology to do |
technology to do this |
traffic on the same |
on the same segment |
no significant differences were |
significant differences were observed |
if we wanted to |
we wanted to blend |
wanted to blend weather |
to blend weather information |
but this may be |
blend weather information from |
this may be because |
weather information from the |
may be because our |
information from the national |
be because our control |
from the national hurricane |
because our control traffic |
the national hurricane center |
our control traffic consisted |
national hurricane center with |
control traffic consisted mainly |
hurricane center with a |
center with a google |
with a google map |
traffic consisted mainly of |
consisted mainly of fast |
the google map service |
google map service would |
map service would need |
service would need to |
would need to explicitly |
need to explicitly support |
which put little stress |
put little stress on |
to explicitly support this |
little stress on the |
explicitly support this sort |
support this sort of |
stress on the communication |
this sort of embedding |
on the communication channels |
in the future we |
the future we hope |
future we hope to |
we hope to explore |
hope to explore scenarios |
to explore scenarios that |
explore scenarios that generate |
scenarios that generate exceptionally |
in our second life |
our second life scenario |
that generate exceptionally heavy |
generate exceptionally heavy control |
exceptionally heavy control traffic |
the visible portion of |
visible portion of the |
which would allow us |
portion of the scene |
would allow us to |
of the scene the |
allow us to explore |
the scene the part |
us to explore the |
scene the part of |
to explore the benefits |
the part of the |
explore the benefits of |
part of the texture |
the benefits of isolation |
of the texture being |
benefits of isolation of |
the texture being displayed |
of isolation of that |
texture being displayed will |
isolation of that traffic |
being displayed will often |
of that traffic with |
displayed will often be |
that traffic with respect |
will often be controlled |
traffic with respect to |
often be controlled by |
with respect to data |
be controlled by events |
respect to data traffic |
controlled by events generated |
by events generated by |
events generated by other |
generated by other live |
s accesses are uniformly |
by other live objects |
accesses are uniformly at |
in the interest of |
other live objects that |
are uniformly at random |
the interest of brevity |
live objects that share |
interest of brevity we |
objects that share the |
of brevity we did |
that share the display |
brevity we did not |
share the display window |
we did not perform |
did not perform any |
not perform any experiments |
perform any experiments to |
any experiments to evaluate |
perhaps under control of |
experiments to evaluate the |
under control of users |
to evaluate the load |
control of users running |
evaluate the load balancing |
of users running on |
the load balancing component |
users running on machines |
load balancing component but |
running on machines elsewhere |
the efficacy of t |
balancing component but we |
on machines elsewhere in |
component but we plan |
machines elsewhere in the |
elsewhere in the network |
but we plan to |
cache as a function |
we plan to do |
as a function of |
plan to do so |
a function of the |
these remote sources won |
to do so in |
function of the strategy |
remote sources won t |
do so in the |
so in the future |
sources won t fit |
of the strategy taken |
won t fit into |
the strategy taken for |
t fit into the |
strategy taken for handling |
all the experiments involved |
fit into the interaction |
taken for handling detected |
the experiments involved a |
into the interaction model |
for handling detected inconsistencies |
experiments involved a single |
the interaction model expected |
involved a single partitioned |
interaction model expected by |
a single partitioned and |
model expected by the |
single partitioned and replicated |
expected by the minibrowser |
partitioned and replicated service |
for ease of exposition |
of the uncommitable tranasctions |
this service implements a |
service implements a simple |
implements a simple wall |
and evict and retry |
the size and shape |
evict and retry reduce |
size and shape of |
and retry reduce the |
and shape of the |
retry reduce the rate |
shape of the display |
the service itself maintains |
of the display window |
reduce the rate of |
the display window and |
service itself maintains the |
the rate of uncommitable |
display window and other |
itself maintains the time |
rate of uncommitable transactions |
window and other elements |
of uncommitable transactions to |
and other elements of |
uncommitable transactions to about |
with updates coming from |
other elements of the |
updates coming from client |
elements of the runtime |
coming from client applications |
of the runtime environment |
from client applications that |
the runtime environment should |
client applications that read |
runtime environment should be |
applications that read a |
environment should be inherited |
that read a high |
should be inherited from |
be inherited from the |
inherited from the hierarchy |
from the hierarchy structure |
the hierarchy structure of |
quality clock and send |
hierarchy structure of the |
clock and send the |
structure of the object |
and send the current |
send the current value |
of the object mashup |
the middle portion is |
the object mashup used |
middle portion is committed |
as processes forward updates |
object mashup used to |
portion is committed transactions |
processes forward updates along |
mashup used to create |
is committed transactions that |
forward updates along the |
used to create the |
committed transactions that are |
updates along the chain |
to create the application |
transactions that are inconsistent |
they will track the |
will track the clock |
track the clock themselves |
and the top portion |
thus our texture should |
the top portion is |
our texture should learn |
top portion is aborted |
texture should learn its |
all of our partitioning |
portion is aborted transactions |
should learn its size |
of our partitioning scenarios |
learn its size and |
our partitioning scenarios included |
its size and orientation |
partitioning scenarios included at |
size and orientation and |
scenarios included at least |
and orientation and even |
included at least four |
orientation and even the |
at least four subservices |
and even the gps |
even the gps coordinates |
the gps coordinates on |
gps coordinates on which |
coordinates on which to |
and each subservice included |
on which to center |
each subservice included between |
which to center from |
to center from the |
center from the parent |
from the parent object |
the parent object that |
parent object that hosts |
object that hosts it |
and similarly until we |
similarly until we reach |
until we reach the |
we reach the root |
reach the root object |
the root object hosting |
root object hosting the |
object hosting the display |
we expect these to |
hosting the display window |
expect these to be |
these to be typical |
to be typical cases |
be typical cases for |
typical cases for real |
a minibrowser isn t |
cases for real deployments |
for real deployments of |
real deployments of the |
deployments of the ssa |
minibrowser isn t a |
isn t a component |
it should be noted |
should be noted that |
it runs the show |
be noted that small |
noted that small subservice |
that small subservice sizes |
despite all of the |
all of the above |
of the above criticism |
minibrowsers retain one potential |
retain one potential advantage |
one potential advantage over |
potential advantage over the |
advantage over the layered |
can result in degenerate |
over the layered architecture |
result in degenerate behavior |
the layered architecture we |
in degenerate behavior and |
layered architecture we proposed |
degenerate behavior and are |
architecture we proposed earlier |
behavior and are not |
and are not appropriate |
are not appropriate configurations |
not appropriate configurations for |
appropriate configurations for the |
since all aspects of |
configurations for the ssa |
for the ssa architecture |
all aspects of the |
aspects of the view |
of the view are |
the view are optimized |
view are optimized to |
are optimized to run |
optimized to run together |
the interaction controls might |
interaction controls might be |
controls might be far |
might be far more |
be far more sophisticated |
mapping between service processes |
far more sophisticated and |
between service processes and |
more sophisticated and perform |
service processes and physical |
sophisticated and perform potentially |
processes and physical nodes |
and perform potentially much |
perform potentially much better |
potentially much better than |
much better than a |
in order to avoid |
better than a solution |
order to avoid os |
than a solution resulting |
to avoid os resource |
a solution resulting from |
avoid os resource contention |
solution resulting from mashing |
resulting from mashing up |
from mashing up together |
mashing up together multiple |
up together multiple layers |
together multiple layers developed |
we experimented with groups |
multiple layers developed independently |
experimented with groups of |
in many realistic examples |
many realistic examples event |
based interfaces could get |
interfaces could get fairly |
could get fairly complex |
and difficult for most |
difficult for most developers |
for most developers to |
most developers to work |
developers to work with |
this observation highlights the |
observation highlights the importance |
highlights the importance of |
the importance of developing |
importance of developing component |
of developing component interface |
developing component interface and |
component interface and event |
interface and event standards |
and event standards for |
event standards for the |
standards for the layered |
for the layered architecture |
the layered architecture we |
layered architecture we ve |
architecture we ve outlined |
by convention the head |
convention the head of |
the head of the |
head of the chain |
of the chain for |
the chain for each |
the task isn t |
chain for each group |
task isn t really |
for each group was |
each group was called |
group was called node |
isn t really all |
t really all that |
really all that daunting |
the designers of microsoft |
designers of microsoft s |
and all update requests |
of microsoft s object |
all update requests for |
microsoft s object linking |
update requests for a |
s object linking and |
requests for a partition |
object linking and embedding |
for a partition were |
a partition were routed |
partition were routed towards |
were routed towards this |
routed towards this node |
standard faced similar challenges |
since delivery delays in |
delivery delays in the |
delays in the chain |
in the chain were |
the chain were measured |
chain were measured relative |
were measured relative to |
measured relative to node |
their ole interfaces are |
ole interfaces are pervasively |
interfaces are pervasively used |
are pervasively used to |
pervasively used to support |
used to support thousands |
to support thousands of |
all the statistics pertaining |
support thousands of plugins |
the statistics pertaining to |
thousands of plugins that |
statistics pertaining to the |
of plugins that implement |
perfectly clustered synthetic workload |
pertaining to the group |
to the group disregarded |
clustered synthetic workload where |
plugins that implement context |
the group disregarded node |
synthetic workload where the |
that implement context menus |
workload where the clusters |
where the clusters shift |
the clusters shift by |
virtual folders and various |
folders and various namespace |
and various namespace extensions |
we simulated two classes |
simulated two classes of |
two classes of failures |
and drag and drop |
drag and drop technologies |
marked by vertical lines |
lacking the needed standards |
at some time t |
some time t one |
time t one process |
the live objects platform |
live objects platform supports |
objects platform supports both |
platform supports both options |
supports both options today |
s access is unclustered |
in addition to allowing |
addition to allowing hosted |
the system must detect |
and as a result |
to allowing hosted content |
system must detect the |
as a result the |
allowing hosted content to |
must detect the failure |
a result the dependency |
hosted content to be |
result the dependency lists |
content to be pulled |
the dependency lists are |
repair the broken fifo |
to be pulled in |
dependency lists are useless |
the broken fifo channel |
be pulled in and |
pulled in and exposed |
in and exposed via |
and exposed via event |
exposed via event interfaces |
only few inconsistencies are |
few inconsistencies are detected |
components developed by some |
developed by some of |
by some of our |
some of our users |
of our users also |
our users also use |
users also use embedded |
also use embedded minibrowsers |
the failed process recovers |
use embedded minibrowsers to |
failed process recovers and |
embedded minibrowsers to gain |
process recovers and rejoins |
minibrowsers to gain access |
recovers and rejoins the |
and rejoins the chain |
to gain access to |
of the transactions that |
gain access to a |
the transactions that commit |
the join protocol would |
join protocol would run |
transactions that commit have |
access to a wide |
that commit have witnessed |
to a wide range |
commit have witnessed inconsistent |
a wide range of |
and the previously failed |
have witnessed inconsistent data |
wide range of platforms |
the previously failed node |
previously failed node would |
failed node would become |
node would become the |
would become the new |
become the new tail |
the new tail of |
new tail of the |
tail of the chain |
the scenario is intended |
scenario is intended to |
is intended to model |
intended to model a |
to model a common |
model a common case |
a common case in |
common case in which |
case in which the |
in which the failure |
accesses become perfectly clustered |
which the failure detection |
the failure detection mechanism |
failure detection mechanism senses |
detection mechanism senses a |
mechanism senses a transient |
senses a transient problem |
we see fast improvement |
see fast improvement of |
fast improvement of inconsistency |
improvement of inconsistency detection |
a node that has |
node that has become |
performance evaluation central to |
the inconsistency rate drops |
evaluation central to our |
that has become overloaded |
inconsistency rate drops as |
central to our argument |
has become overloaded or |
rate drops as the |
to our argument is |
become overloaded or is |
drops as the abort |
our argument is the |
overloaded or is unresponsive |
as the abort rate |
argument is the assertion |
or is unresponsive for |
the abort rate rises |
is the assertion that |
is unresponsive for some |
abort rate rises this |
the assertion that hosted |
unresponsive for some other |
rate rises this is |
assertion that hosted event |
for some other reason |
rises this is desired |
that hosted event notification |
this is desired as |
hosted event notification solutions |
such as garbage collection |
is desired as well |
event notification solutions scale |
notification solutions scale poorly |
solutions scale poorly and |
scale poorly and stand |
poorly and stand as |
and stand as a |
the overall rate of |
stand as a barrier |
and does not respond |
overall rate of consistent |
as a barrier to |
does not respond to |
rate of consistent committed |
a barrier to collaboration |
not respond to the |
of consistent committed transactions |
barrier to collaboration applications |
respond to the heartbeat |
consistent committed transactions drops |
to the heartbeat within |
committed transactions drops because |
the heartbeat within the |
transactions drops because the |
and that developers will |
heartbeat within the accepted |
drops because the probability |
that developers will want |
within the accepted window |
because the probability of |
developers will want to |
the probability of conflicts |
will want to combine |
probability of conflicts in |
want to combine hosted |
of conflicts in the |
to combine hosted content |
by reconfiguring the chain |
conflicts in the clustered |
combine hosted content with |
in the clustered scenario |
hosted content with p |
the clustered scenario is |
the load on node |
load on node drops |
clustered scenario is higher |
p protocols to overcome |
protocols to overcome these |
to overcome these problems |
and the problem will |
the problem will eventually |
problem will eventually resolve |
in this section we |
this section we present |
to illustrate more realistic |
section we present data |
illustrate more realistic behavior |
it then requests a |
we present data to |
then requests a rejoin |
present data to support |
data to support our |
to support our claims |
we use clustered accesses |
use clustered accesses that |
clustered accesses that slowly |
a node crash that |
accesses that slowly drift |
node crash that results |
some of the results |
crash that results in |
that results in a |
results in a reboot |
transactions are perfectly clustered |
in a reboot would |
a reboot would result |
reboot would result in |
would result in similar |
result in similar behavior |
as in the previous |
in the previous experiment |
minutes the cluster structure |
the cluster structure shifts |
cluster structure shifts by |
are drawn from a |
all the nodes in |
drawn from a widely |
the nodes in the |
from a widely cited |
nodes in the subservice |
a widely cited industry |
in the subservice remain |
widely cited industry whitepaper |
the subservice remain operational |
but one of them |
one of them becomes |
of them becomes overloaded |
causing the tcp link |
the tcp link to |
tcp link to the |
link to the upstream |
to the upstream node |
the upstream node to |
upstream node to become |
node to become congested |
to become congested and |
become congested and starving |
and were obtained using |
congested and starving downstream |
were obtained using a |
and starving downstream nodes |
obtained using a testing |
using a testing methodology |
a testing methodology and |
testing methodology and setup |
methodology and setup developed |
which begin to miss |
and setup developed and |
begin to miss updates |
setup developed and published |
developed and published by |
and published by sonic |
published by sonic software |
this scenario models a |
scenario models a behavior |
models a behavior common |
a behavior common in |
behavior common in experiments |
common in experiments on |
in experiments on our |
experiments on our cluster |
when a node becomes |
a node becomes very |
node becomes very busy |
becomes very busy or |
very busy or the |
busy or the communication |
or the communication subsystem |
the communication subsystem becomes |
communication subsystem becomes heavily |
subsystem becomes heavily loaded |
tcp at the node |
at the node upstream |
the node upstream from |
the remainder was produced |
node upstream from it |
remainder was produced in |
upstream from it will |
was produced in our |
from it will sense |
produced in our own |
it will sense congestion |
in our own experiments |
will sense congestion and |
sense congestion and reduce |
congestion and reduce its |
and reduce its window |
reduce its window size |
if the impacted node |
the impacted node is |
impacted node is in |
node is in the |
and wrapping back to |
is in the middle |
wrapping back to zero |
in the middle of |
back to zero after |
the middle of the |
middle of the chain |
from the industry white |
the industry white paper |
it ceases to relay |
ceases to relay updates |
analyzes the performance of |
the performance of several |
performance of several commercial |
or does so after |
of several commercial enterprise |
does so after long |
so after long delays |
several commercial enterprise service |
commercial enterprise service bus |
hence downstream nodes fall |
downstream nodes fall behind |
shown is the maximum |
is the maximum throughput |
the chain replication scheme |
chain replication scheme slows |
replication scheme slows to |
the objects dependency lists |
scheme slows to a |
objects dependency lists are |
slows to a crawl |
dependency lists are outdated |
this leads to a |
leads to a sudden |
to a sudden increased |
a sudden increased inconsistency |
the ssa benefits from |
ssa benefits from its |
sudden increased inconsistency rate |
benefits from its gossip |
increased inconsistency rate that |
from its gossip repair |
its gossip repair mechanisms |
inconsistency rate that converges |
rate that converges back |
that converges back to |
converges back to zero |
which route missing updates |
route missing updates around |
missing updates around the |
updates around the slow |
until this convergence is |
the experiment varies the |
around the slow node |
this convergence is interrupted |
experiment varies the number |
convergence is interrupted by |
varies the number of |
is interrupted by the |
the number of subscribers |
interrupted by the next |
number of subscribers while |
by the next shift |
route them to that |
of subscribers while using |
them to that node |
subscribers while using a |
while using a single |
using a single publisher |
a single publisher that |
when it recovers and |
single publisher that communicates |
it recovers and needs |
publisher that communicates through |
recovers and needs to |
that communicates through a |
and needs to repair |
communicates through a single |
needs to repair its |
through a single hosted |
to repair its state |
a single hosted message |
single hosted message broker |
hosted message broker on |
message broker on a |
broker on a single |
on a single topic |
b presented three possible |
presented three possible strategies |
three possible strategies for |
possible strategies for the |
strategies for the cache |
for the cache to |
the cache to deal |
cache to deal with |
to deal with inconsistency |
knowing that gossip will |
that gossip will kick |
gossip will kick in |
deal with inconsistency detection |
figured for message durability |
an upstream node can |
upstream node can deliberately |
even if a subscriber |
node can deliberately drop |
if a subscriber experiences |
can deliberately drop updates |
a subscriber experiences a |
deliberately drop updates on |
subscriber experiences a transient |
drop updates on congested |
experiences a transient loss |
updates on congested tcp |
a transient loss of |
on congested tcp connections |
transient loss of connectivity |
we used our wall |
the publisher retains and |
publisher retains and hence |
retains and hence can |
and hence can replay |
hence can replay all |
can replay all messages |
clock service to evaluate |
service to evaluate the |
to evaluate the behavior |
evaluate the behavior of |
as the number of |
the behavior of the |
the number of subscribers |
behavior of the overall |
number of subscribers increases |
of the overall system |
the overall system in |
overall system in various |
system in various scenarios |
aborting and evicting value |
in various scenarios and |
various scenarios and with |
scenarios and with different |
and with different parameters |
a stream of updates |
latency will also soars |
stream of updates of |
will also soars because |
of updates of various |
also soars because the |
updates of various rates |
soars because the amount |
of various rates is |
because the amount of |
various rates is injected |
the amount of time |
rates is injected into |
amount of time the |
is injected into the |
of time the broker |
injected into the head |
time the broker needs |
into the head of |
the broker needs to |
through when possible as |
the head of the |
broker needs to spend |
when possible as in |
head of the chain |
needs to spend sending |
possible as in cache |
as in cache miss |
to spend sending a |
spend sending a single |
sending a single message |
a single message increases |
single message increases linearly |
message increases linearly with |
increases linearly with the |
linearly with the number |
with the number of |
the number of subscribers |
for groups of nodes |
we will now compare |
durability is often not |
established point in time |
is often not required |
will now compare their |
now compare their efficacies |
a victim node receives |
victim node receives a |
node receives a command |
we use the approximate |
receives a command that |
use the approximate clusters |
a command that forces |
the approximate clusters workload |
command that forces it |
approximate clusters workload with |
that forces it to |
forces it to halt |
shows throughput in an |
throughput in an experiment |
in an experiment in |
an experiment in which |
the node continues to |
experiment in which the |
node continues to listen |
in which the publisher |
continues to listen for |
which the publisher does |
to listen for commands |
the publisher does not |
publisher does not log |
does not log data |
listen for commands that |
for commands that would |
commands that would restart |
that would restart it |
a window size of |
a disconnected subscriber would |
disconnected subscriber would experience |
subscriber would experience a |
would experience a loss |
this is accomplished by |
a pareto parameter of |
is accomplished by having |
accomplished by having node |
we find that while |
find that while the |
that while the maximum |
while the maximum throughput |
the maximum throughput is |
maximum throughput is much |
throughput is much higher |
send a crash command |
a crash command to |
crash command to the |
command to the victim |
the degradation of performance |
to the victim node |
degradation of performance is |
the victim node once |
and the maximum dependency |
of performance is even |
victim node once a |
the maximum dependency list |
performance is even more |
is even more dramatic |
maximum dependency list size |
node once a certain |
dependency list size is |
list size is set |
size is set to |
once a certain number |
a certain number of |
certain number of updates |
number of updates were |
of updates were injected |
developers of collaboration applications |
updates were injected into |
of collaboration applications that |
were injected into the |
collaboration applications that need |
injected into the chain |
applications that need good |
that need good scalability |
need good scalability might |
good scalability might discover |
scalability might discover that |
might discover that hosted |
discover that hosted esb |
that hosted esb options |
hosted esb options won |
esb options won t |
options won t achieve |
won t achieve this |
t achieve this goal |
the lower portion of |
the victim node will |
lower portion of the |
victim node will stop |
portion of the graph |
node will stop participating |
of the graph is |
will stop participating in |
we report on some |
the graph is the |
stop participating in the |
report on some experiments |
graph is the ratio |
participating in the normal |
on some experiments we |
is the ratio of |
in the normal protocol |
some experiments we conducted |
the ratio of committed |
the normal protocol and |
experiments we conducted on |
ratio of committed transactions |
normal protocol and will |
we conducted on our |
of committed transactions that |
protocol and will handle |
conducted on our own |
on our own at |
our own at cornell |
committed transactions that the |
and will handle only |
transactions that the abort |
will handle only wakeup |
that the abort strategy |
handle only wakeup commands |
focusing on scalability of |
the abort strategy provides |
only wakeup commands from |
on scalability of event |
abort strategy provides a |
wakeup commands from this |
scalability of event notification |
strategy provides a significant |
commands from this moment |
of event notification platforms |
provides a significant improvement |
from this moment onwards |
event notification platforms that |
a significant improvement over |
notification platforms that leverage |
significant improvement over a |
platforms that leverage peer |
improvement over a normal |
the chain detects the |
chain detects the failure |
repairs and announces the |
and announces the membership |
peer techniques for dissemination |
announces the membership change |
techniques for dissemination and |
for dissemination and recovery |
as the strategy detects |
the strategy detects and |
after a number of |
on the first graph |
strategy detects and aborts |
a number of updates |
detects and aborts over |
number of updates have |
of updates have been |
updates have been injected |
have been injected since |
been injected since the |
injected since the crash |
since the crash command |
the crash command was |
crash command was issued |
of all inconsistent transactions |
we compare the maximum |
all inconsistent transactions that |
sends a wakeup command |
compare the maximum throughput |
inconsistent transactions that would |
a wakeup command to |
the maximum throughput of |
transactions that would have |
wakeup command to the |
maximum throughput of two |
that would have been |
command to the victim |
to the victim node |
would have been committed |
throughput of two decentralized |
of two decentralized reliable |
two decentralized reliable multicast |
decentralized reliable multicast protocols |
but the other strategies |
the other strategies make |
other strategies make further |
strategies make further improvements |
evict reduces uncommittable transactions |
reduces uncommittable transactions to |
the victim node rejoins |
victim node rejoins the |
node rejoins the group |
it has to catch |
has to catch up |
to catch up by |
catch up by obtaining |
up by obtaining copies |
of its value with |
by obtaining copies of |
its value with abort |
obtaining copies of updates |
copies of updates that |
a single topic and |
of updates that it |
single topic and a |
updates that it has |
that it has missed |
topic and a single |
this indicates that violating |
and a single publisher |
we experimentally determined that |
unlike in the previous |
in the previous tests |
repetitions of each experiment |
of each experiment were |
each experiment were enough |
experiment were enough to |
were enough to yield |
cache entries are likely |
enough to yield accurate |
entries are likely to |
to yield accurate measurements |
are likely to be |
yield accurate measurements with |
likely to be repeat |
accurate measurements with low |
to be repeat offenders |
measurements with low variance |
these experiments used a |
they are too old |
are too old for |
too old for objects |
old for objects that |
for objects that are |
shows the update delivery |
objects that are likely |
the update delivery delay |
that are likely to |
update delivery delay for |
are likely to be |
delivery delay for a |
likely to be accessed |
delay for a set |
to be accessed together |
for a set of |
be accessed together with |
a set of four |
this limits the peak |
accessed together with them |
set of four consecutive |
limits the peak performance |
together with them in |
of four consecutive nodes |
the peak performance to |
with them in future |
them in future transactions |
four consecutive nodes in |
consecutive nodes in a |
nodes in a chain |
and so it is |
so it is better |
it is better to |
starting with the victim |
with the victim node |
is better to evict |
better to evict them |
retry reduces uncommittable transactions |
reduces uncommittable transactions further |
uncommittable transactions further to |
transactions further to about |
the chain length is |
and we report on |
of its value with |
its value with abort |
we report on a |
report on a gossip |
on a gossip rate |
a gossip rate of |
realistic workloads we now |
workloads we now evaluate |
we now evaluate the |
now evaluate the efficacy |
evaluate the efficacy of |
the efficacy of t |
achieves stable high throughput |
cache with workloads based |
with workloads based on |
milliseconds at a steady |
workloads based on two |
at a steady update |
based on two sampled |
a steady update injection |
steady update injection rate |
update injection rate of |
on two sampled topologies |
two sampled topologies from |
sampled topologies from the |
topologies from the online |
from the online retailer |
the online retailer amazon |
online retailer amazon and |
runs at about a |
retailer amazon and the |
at about a fifth |
amazon and the social |
about a fifth that |
and the social network |
a fifth that speed |
the social network orkut |
there are three anomalies |
are three anomalies that |
three anomalies that can |
collapsing as the number |
anomalies that can be |
as the number of |
that can be seen |
the number of subscribers |
can be seen on |
number of subscribers increases |
be seen on the |
seen on the graphs |
describes how we generated |
how we generated these |
we generated these workloads |
the first one is |
first one is experienced |
at small loss rates |
one is experienced by |
is experienced by the |
experienced by the victim |
by the victim node |
the victim node for |
latency in qsm is |
victim node for updates |
in qsm is at |
node for updates injected |
measures the efficacy of |
the efficacy of t |
for updates injected between |
qsm is at the |
is at the level |
at the level of |
cache on these workloads |
on these workloads as |
these workloads as a |
workloads as a function |
as a function of |
a function of maximum |
function of maximum dependency |
of maximum dependency list |
maximum dependency list size |
and compares this to |
compares this to a |
seconds after the start |
this to a strategy |
after the start of |
to a strategy based |
the start of the |
start of the experiment |
ms irrespectively of the |
a strategy based on |
irrespectively of the number |
strategy based on ttls |
of the number of |
the second is experienced |
the number of subscribers |
second is experienced by |
is experienced by all |
experienced by all the |
by all the other |
all the other nodes |
when the number of |
the other nodes for |
the number of topics |
other nodes for update |
number of topics is |
nodes for update messages |
compares the efficacy of |
of topics is varied |
for update messages injected |
the efficacy of the |
update messages injected at |
efficacy of the three |
messages injected at around |
qsm maintains its high |
of the three strategies |
maintains its high performance |
the three strategies of |
three strategies of dealing |
strategies of dealing with |
of dealing with detected |
dealing with detected inconsistencies |
on the second graph |
seconds after the start |
after the start of |
the start of the |
start of the experiment |
while the third one |
the third one is |
third one is a |
one is a smaller |
is a smaller mixed |
a smaller mixed burst |
smaller mixed burst for |
mixed burst for updates |
burst for updates injected |
for updates injected at |
we report performance for |
we generated two workloads |
generated two workloads based |
two workloads based on |
workloads based on real |
based on real data |
seconds into the experiment |
note that the y |
but performance for other |
performance for other group |
axes have different scales |
for other group sizes |
have different scales to |
other group sizes is |
we started from a |
different scales to observe |
group sizes is similar |
started from a snapshot |
scales to observe how |
from a snapshot of |
to observe how the |
a snapshot of amazon |
jgroups performance was higher |
observe how the system |
snapshot of amazon s |
performance was higher with |
how the system handles |
of amazon s product |
was higher with smaller |
the system handles the |
amazon s product co |
higher with smaller group |
system handles the transient |
with smaller group sizes |
handles the transient failure |
the transient failure better |
purchasing graph taken early |
but erodes as the |
erodes as the number |
as the number of |
therefore the third anomaly |
the number of topics |
the third anomaly appears |
number of topics increases |
third anomaly appears to |
anomaly appears to grow |
appears to grow with |
to grow with the |
grow with the chain |
with the chain distance |
jgroups failed when we |
the chain distance from |
failed when we attempted |
chain distance from the |
when we attempted to |
distance from the victim |
we attempted to configure |
from the victim node |
attempted to configure it |
to configure it with |
configure it with more |
it with more than |
the growth is not |
growth is not significant |
since the cause of |
the cause of this |
cause of this anomaly |
of this anomaly is |
each product sold by |
this anomaly is an |
product sold by the |
anomaly is an artifact |
sold by the online |
is an artifact of |
by the online retailer |
an artifact of java |
the online retailer is |
artifact of java s |
we look at two |
online retailer is a |
of java s garbage |
look at two scalable |
retailer is a node |
java s garbage collection |
at two scalable protocols |
is a node and |
s garbage collection mechanism |
two scalable protocols under |
a node and each |
garbage collection mechanism kicking |
scalable protocols under conditions |
node and each pair |
collection mechanism kicking in |
protocols under conditions of |
and each pair of |
under conditions of stress |
each pair of products |
as can be noted |
pair of products purchased |
of products purchased in |
products purchased in a |
with a focus on |
purchased in a single |
a focus on delivery |
in a single user |
focus on delivery latency |
a single user session |
performed recovery for the |
single user session is |
recovery for the updates |
user session is an |
session is an edge |
for the updates it |
the updates it has |
updates it has missed |
as a fixed message |
it has missed during |
a fixed message rate |
the original graph contains |
has missed during the |
fixed message rate is |
original graph contains more |
missed during the period |
message rate is spread |
graph contains more than |
during the period it |
rate is spread over |
the period it was |
period it was down |
is spread over varying |
spread over varying numbers |
over varying numbers of |
varying numbers of topics |
because the chain delivers |
the chain delivers new |
chain delivers new updates |
delivers new updates at |
new updates at the |
updates at the moment |
at the moment of |
the moment of rejoin |
subscribers each join some |
all past updates were |
each join some number |
past updates were solely |
join some number of |
updates were solely recovered |
some number of topics |
were solely recovered by |
solely recovered by means |
recovered by means of |
by means of epidemics |
a publisher sends data |
publisher sends data at |
sends data at a |
data at a rate |
at a rate of |
the second anomaly that |
second anomaly that shows |
anomaly that shows up |
that shows up in |
shows up in the |
up in the update |
in the update delivery |
the update delivery delay |
update delivery delay for |
delivery delay for the |
delay for the nodes |
for the nodes downstream |
we used a snapshot |
the nodes downstream from |
used a snapshot of |
nodes downstream from the |
a snapshot of the |
downstream from the victim |
snapshot of the friendship |
from the victim node |
of the friendship relations |
the victim node reflects |
selecting the topic in |
the friendship relations graph |
victim node reflects the |
the topic in which |
friendship relations graph in |
node reflects the period |
topic in which to |
relations graph in the |
reflects the period when |
in which to send |
graph in the orkut |
in the orkut social |
which to send at |
the period when the |
the orkut social network |
to send at random |
period when the chain |
when the chain is |
the chain is broken |
during the time it |
the time it took |
time it took for |
it took for the |
took for the failure |
for the failure detection |
the failure detection mechanism |
failure detection mechanism to |
detection mechanism to declare |
mechanism to declare the |
to declare the node |
declare the node deceased |
to start up the |
start up the membership |
up the membership change |
the membership change protocol |
we see that ricochet |
and for the membership |
for the membership information |
the membership information to |
membership information to propagate |
the chain is interrupted |
chain is interrupted between |
is interrupted between node |
each user is a |
user is a node |
a cornelldeveloped protocol for |
is a node and |
cornelldeveloped protocol for low |
a node and each |
node and each pair |
and each pair of |
and hence the updates |
each pair of users |
hence the updates circumvent |
pair of users with |
the updates circumvent the |
of users with a |
updates circumvent the gap |
users with a friend |
circumvent the gap by |
with a friend relationship |
the gap by means |
a friend relationship is |
gap by means of |
friend relationship is an |
by means of gossip |
relationship is an edge |
updates can bypass nodes |
the original graph contains |
can bypass nodes in |
original graph contains more |
bypass nodes in the |
graph contains more than |
nodes in the chain |
in the chain using |
the chain using the |
chain using the gossip |
using the gossip as |
the gossip as it |
as the number of |
gossip as it can |
the number of topics |
as it can be |
number of topics increases |
it can be seen |
of topics increases to |
can be seen in |
be seen in the |
seen in the figure |
but this phenomenon is |
this phenomenon is less |
phenomenon is less likely |
is less likely as |
less likely as the |
likely as the node |
as the node receiving |
the node receiving the |
node receiving the update |
receiving the update is |
the update is farther |
update is farther away |
is farther away downstream |
farther away downstream from |
away downstream from the |
downstream from the victim |
from the victim node |
because the sampled topologies |
the sampled topologies are |
contains an aggregated view |
sampled topologies are large |
an aggregated view of |
topologies are large and |
aggregated view of the |
are large and we |
latency soars when we |
view of the data |
of the data in |
soars when we repeat |
large and we only |
the data in figure |
when we repeat this |
and we only need |
we repeat this with |
we only need to |
repeat this with the |
for the entire chain |
only need to simulate |
this with the industrystandard |
need to simulate a |
with the industrystandard scalable |
at gossip rates of |
to simulate a single |
the industrystandard scalable reliable |
simulate a single column |
industrystandard scalable reliable multicast |
a single column of |
single column of the |
column of the system |
of the system for |
the system for our |
system for our purposes |
for our purposes one |
our purposes one database |
purposes one database server |
one database server and |
database server and one |
server and one cache |
and one cache server |
widely used for event |
one cache server we |
used for event notification |
cache server we down |
for event notification in |
event notification in their |
notification in their datacenters |
milliseconds showing that the |
sample both graphs to |
showing that the behavior |
that the behavior of |
as can be seen |
the behavior of the |
can be seen in |
behavior of the scheme |
be seen in the |
of the scheme is |
seen in the graph |
the scheme is not |
scheme is not a |
is not a fluke |
srm s recovery latency |
s recovery latency rises |
recovery latency rises linearly |
latency rises linearly in |
note that the delay |
rises linearly in the |
that the delay of |
linearly in the figure |
we use a technique |
the delay of the |
use a technique based |
delay of the updates |
a technique based on |
of the updates delivered |
technique based on random |
the updates delivered at |
based on random walks |
scalability of commercial esbs |
of commercial esbs figure |
on random walks that |
updates delivered at the |
random walks that maintains |
delivered at the victim |
walks that maintains important |
at the victim node |
that maintains important properties |
the victim node is |
scalability of commercial esbs |
maintains important properties of |
victim node is significantly |
of commercial esbs number |
important properties of the |
node is significantly larger |
commercial esbs number of |
properties of the original |
is significantly larger than |
esbs number of topics |
of the original graph |
significantly larger than that |
larger than that of |
than that of the |
that of the nodes |
of the nodes downstream |
the nodes downstream of |
nodes downstream of it |
downstream of it in |
of it in the |
it in the chain |
we observed that even |
observed that even with |
that even with sufficiently |
even with sufficiently high |
with sufficiently high gossip |
sufficiently high gossip rate |
specifically clustering which is |
clustering which is central |
the only node to |
which is central to |
only node to experience |
is central to our |
node to experience any |
central to our experiment |
our experiments confirm that |
to experience any significant |
experience any significant inconsistency |
any significant inconsistency window |
significant inconsistency window is |
we start by choosing |
hosted enterprise service bus |
inconsistency window is the |
start by choosing a |
enterprise service bus architectures |
window is the node |
by choosing a node |
service bus architectures can |
is the node that |
the node that failed |
bus architectures can achieve |
choosing a node uniformly |
architectures can achieve high |
a node uniformly and |
can achieve high levels |
node uniformly and random |
note that when the |
achieve high levels of |
high levels of publish |
that when the failed |
uniformly and random and |
when the failed node |
and random and start |
subscribe performance for small |
the failed node rejoins |
random and start a |
performance for small numbers |
and start a random |
for small numbers of |
start a random walk |
small numbers of subscribers |
a random walk from |
queries are performed against |
random walk from that |
are performed against its |
walk from that location |
but performance degrades very |
performed against its data |
performance degrades very sharply |
against its data before |
degrades very sharply as |
its data before it |
very sharply as the |
data before it has |
sharply as the number |
before it has time |
as the number of |
it has time to |
the number of subscribers |
has time to fully |
number of subscribers or |
time to fully recover |
of subscribers or topics |
subscribers or topics grows |
once the chain is |
the chain is restored |
the jgroups and srm |
jgroups and srm platforms |
the walk reverts back |
walk reverts back to |
reverts back to the |
all new updates are |
back to the first |
new updates are received |
which don t leverage |
don t leverage peer |
to the first node |
the first node and |
first node and start |
node and start again |
there were rare cases |
were rare cases when |
rare cases when gossip |
cases when gossip circumvented |
when gossip circumvented the |
this is repeated until |
gossip circumvented the chain |
is repeated until the |
circumvented the chain replication |
scale poorly in the |
repeated until the target |
the chain replication even |
poorly in the number |
until the target number |
chain replication even though |
in the number of |
the target number of |
replication even though the |
the number of subscribers |
target number of nodes |
even though the chain |
number of subscribers or |
number of nodes have |
though the chain was |
of subscribers or topics |
of nodes have been |
the chain was not |
nodes have been visited |
chain was not broken |
but this happened only |
this happened only for |
happened only for gossip |
only for gossip rates |
for gossip rates close |
scale well in these |
gossip rates close to |
well in these dimensions |
rates close to the |
close to the update |
to the update injection |
the update injection rate |
ricochet achieved the best |
achieved the best recovery |
the best recovery latency |
best recovery latency when |
later in this section |
recovery latency when message |
in this section we |
latency when message loss |
show a further down |
this section we will |
when message loss is |
section we will show |
message loss is an |
loss is an issue |
we will show that |
will show that even |
show that even with |
that even with these |
even with these rapid |
with these rapid repairs |
but at relatively high |
at relatively high overhead |
the gossip overhead is |
gossip overhead is actually |
not shown on these |
overhead is actually low |
nodes to provide some |
shown on these graphs |
to provide some perception |
provide some perception of |
some perception of the |
perception of the topologies |
the graphs are visibly |
graphs are visibly clustered |
qsm at small loss |
at small loss rates |
small loss rates achieves |
loss rates achieves similar |
rates achieves similar average |
the amazon topology more |
achieves similar average latency |
amazon topology more so |
similar average latency with |
topology more so than |
average latency with considerably |
more so than the |
latency with considerably lower |
so than the orkut |
of the messages were |
with considerably lower network |
than the orkut one |
the messages were delivered |
considerably lower network overheads |
messages were delivered by |
were delivered by gossip |
delivered by gossip ahead |
by gossip ahead of |
but if a packet |
gossip ahead of the |
if a packet is |
a packet is lost |
ahead of the chain |
of the chain for |
the chain for gossip |
chain for gossip rate |
for gossip rate identical |
it may take several |
gossip rate identical to |
may take several seconds |
rate identical to the |
take several seconds to |
its topology has a |
identical to the update |
several seconds to recover |
seconds to recover it |
to the update injection |
the update injection rate |
topology has a more |
has a more clustered |
a more clustered structure |
making it less appropriate |
it less appropriate for |
less appropriate for time |
and so the dependency |
so the dependency lists |
the dependency lists hold |
dependency lists hold more |
lists hold more relevant |
hold more relevant information |
contains a plot of |
we don t see |
a plot of update |
don t see any |
treating nodes of the |
plot of update injection |
t see any single |
nodes of the graphs |
of update injection time |
see any single winner |
of the graphs as |
update injection time against |
any single winner here |
the graphs as database |
injection time against update |
graphs as database objects |
time against update delivery |
against update delivery time |
each of the solutions |
update delivery time for |
of the solutions tested |
delivery time for the |
transactions are likely to |
the solutions tested has |
time for the victim |
are likely to access |
solutions tested has some |
for the victim node |
likely to access objects |
tested has some advantages |
has some advantages that |
to access objects that |
some advantages that its |
access objects that are |
ideally this is a |
advantages that its competitors |
objects that are topologically |
this is a straight |
that its competitors lack |
that are topologically close |
is a straight line |
are topologically close to |
a straight line because |
topologically close to one |
straight line because of |
close to one another |
line because of chain |
we re currently developing |
because of chain replication |
re currently developing new |
currently developing new p |
for the online retailer |
note that once the |
that once the victim |
once the victim node |
the victim node recovers |
it is likely that |
is likely that objects |
likely that objects bought |
that objects bought together |
objects bought together are |
bought together are also |
it gracefully catches up |
together are also viewed |
gracefully catches up and |
are also viewed and |
catches up and does |
also viewed and updated |
up and does so |
viewed and updated together |
and does so quickly |
does so quickly for |
so quickly for both |
quickly for both gossip |
for both gossip rates |
it builds an overlay |
both gossip rates identical |
builds an overlay multicast |
gossip rates identical and |
an overlay multicast tree |
rates identical and half |
overlay multicast tree within |
identical and half the |
multicast tree within which |
tree within which events |
within which events travel |
viewing and buying a |
and half the update |
and buying a toy |
buying a toy train |
a toy train and |
toy train and matching |
and is capable of |
half the update injection |
the update injection rate |
is capable of selforganizing |
train and matching rails |
capable of selforganizing in |
of selforganizing in the |
selforganizing in the presence |
now consider the link |
in the presence of |
the presence of firewalls |
consider the link congestion |
the link congestion case |
for the social network |
it is likely that |
is likely that data |
likely that data of |
that data of befriended |
data of befriended users |
of befriended users are |
befriended users are viewed |
users are viewed and |
are viewed and updated |
viewed and updated together |
a separate project is |
separate project is creating |
project is creating a |
is creating a protocol |
creating a protocol suite |
a protocol suite that |
protocol suite that we |
suite that we call |
that we call the |
we call the properties |
call the properties framework |
tagging a person in |
a person in a |
person in a picture |
commenting on a post |
on a post by |
a post by a |
post by a friend |
by a friend s |
a friend s friend |
the goal is to |
or viewing one s |
viewing one s neighborhood |
goal is to offer |
is to offer strong |
to offer strong forms |
offer strong forms of |
strong forms of reliability |
forms of reliability that |
of reliability that can |
reliability that can be |
that can be customized |
we run a set |
can be customized for |
run a set of |
be customized for special |
a set of experiments |
customized for special needs |
set of experiments similar |
of experiments similar to |
experiments similar to the |
similar to the t |
speed and scalability are |
and scalability are only |
scalability are only elements |
are only elements of |
only elements of a |
varying cache entry ttl |
elements of a broader |
cache entry ttl to |
of a broader story |
entry ttl to evaluate |
ttl to evaluate the |
to evaluate the efficacy |
evaluate the efficacy of |
the efficacy of this |
developers will need different |
efficacy of this method |
will need different solutions |
of this method in |
need different solutions for |
this method in reducing |
different solutions for different |
solutions for different purposes |
method in reducing inconsistencies |
in reducing inconsistencies and |
reducing inconsistencies and the |
inconsistencies and the corresponding |
and the corresponding overhead |
by offering a flexible |
offering a flexible yet |
a flexible yet structured |
flexible yet structured component |
yet structured component mashup |
structured component mashup environment |
live objects makes it |
objects makes it possible |
makes it possible to |
it possible to create |
limiting ttl has detrimental |
possible to create applications |
ttl has detrimental effects |
to create applications that |
has detrimental effects on |
create applications that mix |
detrimental effects on cache |
applications that mix hosted |
that mix hosted with |
effects on cache hit |
on cache hit ratio |
mix hosted with p |
quickly increasing the database |
increasing the database workload |
and that can adapt |
that can adapt their |
can adapt their behavior |
by increasing database access |
increasing database access rate |
database access rate to |
access rate to more |
rate to more than |
to more than twice |
more than twice its |
than twice its original |
to achieve desired properties |
twice its original load |
achieve desired properties in |
its original load we |
desired properties in a |
original load we only |
properties in a way |
load we only observe |
in a way matched |
we only observe a |
a way matched to |
way matched to the |
only observe a reduction |
matched to the environment |
observe a reduction of |
a reduction of inconsistencies |
reduction of inconsistencies of |
of inconsistencies of about |
scalability of qsm and |
of qsm and jgroups |
throughput for various group |
for various group sizes |
this is more than |
is more than twice |
more than twice the |
than twice the rate |
twice the rate of |
the rate of inconsistencies |
rate of inconsistencies achieved |
of inconsistencies achieved by |
inconsistencies achieved by t |
prior work the idea |
cache for the retailer |
work the idea of |
for the retailer workload |
the idea of integrating |
the retailer workload and |
idea of integrating web |
retailer workload and only |
of integrating web services |
workload and only slightly |
integrating web services with |
and only slightly better |
web services with peer |
only slightly better than |
slightly better than the |
better than the rate |
than the rate of |
the rate of inconsistencies |
rate of inconsistencies achieved |
of inconsistencies achieved by |
inconsistencies achieved by t |
peer platforms is certainly |
platforms is certainly not |
is certainly not new |
cache for the social |
for the social network |
the social network workload |
and with twice the |
with twice the additional |
twice the additional load |
the additional load on |
additional load on the |
load on the database |
we generate a transactional |
generate a transactional workload |
a transactional workload that |
transactional workload that accesses |
workload that accesses products |
that accesses products that |
accesses products that are |
products that are topologically |
that are topologically close |
we use random walks |
each transaction starts by |
transaction starts by picking |
starts by picking a |
by picking a node |
picking a node uniformly |
a node uniformly at |
node uniformly at random |
uniformly at random and |
at random and takes |
steps of a random |
of a random walk |
the nodes visited by |
nodes visited by the |
visited by the random |
by the random walk |
the random walk are |
random walk are the |
walk are the objects |
are the objects the |
the objects the transaction |
objects the transaction accesses |
update transactions first read |
transactions first read all |
first read all objects |
read all objects from |
all objects from the |
objects from the database |
and then update all |
then update all objects |
update all objects at |
all objects at the |
objects at the database |
read transactions read the |
transactions read the objects |
read the objects directly |
the objects directly from |
objects directly from the |
directly from the cache |
in this section we |
this section we evaluate |
section we evaluate t |
cache using the workloads |
using the workloads described |
the workloads described above |
we found that the |
found that the abort |
that the abort rate |
the abort rate is |
abort rate is negligible |
rate is negligible in |
is negligible in all |
negligible in all runs |
efficacy is therefore defined |
is therefore defined to |
therefore defined to be |
defined to be the |
to be the ratio |
be the ratio of |
the ratio of inconsistent |
ratio of inconsistent transactions |
of inconsistent transactions out |
inconsistent transactions out of |
transactions out of all |
out of all commits |
the overhead of the |
overhead of the system |
of the system is |
the system is twofold |
dependency list maintenance implies |
list maintenance implies storage |
maintenance implies storage and |
implies storage and bandwidth |
storage and bandwidth overhead |
and bandwidth overhead at |
bandwidth overhead at both |
overhead at both the |
at both the database |
both the database and |
the database and the |
database and the cache |
as well as compute |
well as compute overhead |
as compute overhead for |
compute overhead for dependency |
overhead for dependency list |
for dependency list merging |
dependency list merging at |
list merging at the |
merging at the server |
at the server and |
the existing work falls |
the server and consistency |
existing work falls roughly |
server and consistency checks |
work falls roughly into |
and consistency checks at |
falls roughly into two |
roughly into two categories |
consistency checks at the |
checks at the cache |
the first line of |
first line of research |
line of research is |
of research is focused |
research is focused on |
is focused on the |
focused on the use |
on the use of |
the storage required is |
the use of peer |
storage required is only |
required is only for |
is only for object |
only for object ids |
for object ids and |
object ids and versions |
and both updates and |
both updates and checks |
updates and checks are |
and checks are o |
as a basis for |
a basis for scalable |
basis for scalable web |
for scalable web service |
scalable web service discovery |
the second line of |
second line of research |
line of research concentrates |
in the number of |
of research concentrates on |
the number of objects |
research concentrates on the |
number of objects in |
concentrates on the use |
of objects in the |
on the use of |
objects in the system |
the use of replication |
in the system and |
use of replication protocols |
the system and o |
of replication protocols at |
replication protocols at the |
protocols at the web |
at the web service |
the web service backend |
web service backend to |
service backend to achieve |
backend to achieve fault |
in the size of |
the size of the |
size of the dependency |
of the dependency lists |
which is limited to |
p platforms such as |
platforms such as jxta |
such as jxta are |
as jxta are treated |
jxta are treated not |
are treated not as |
treated not as means |
the second and potentially |
not as means of |
second and potentially more |
as means of collaboration |
and potentially more significant |
means of collaboration or |
potentially more significant overhead |
of collaboration or media |
more significant overhead is |
collaboration or media carrying |
significant overhead is the |
or media carrying live |
overhead is the effect |
media carrying live content |
is the effect on |
the effect on cache |
effect on cache hit |
on cache hit ratio |
cache hit ratio due |
but rather as a |
hit ratio due to |
rather as a supporting |
ratio due to evictions |
as a supporting infrastructure |
due to evictions and |
a supporting infrastructure at |
to evictions and hence |
supporting infrastructure at the |
evictions and hence the |
and hence the database |
hence the database load |
infrastructure at the data |
at the data center |
the data center backend |
since cache load is |
cache load is significantly |
load is significantly larger |
is significantly larger than |
significantly larger than database |
larger than database load |
our work is focused |
work is focused on |
is focused on blending |
focused on blending the |
on blending the content |
blending the content available |
the content available through |
content available through p |
orders of magnitude for |
of magnitude for facebook |
p and web service |
and web service protocols |
neither technology is subordinate |
technology is subordinate with |
is subordinate with respect |
subordinate with respect to |
with respect to the |
respect to the other |
technologies that use peer |
even a minor deterioration |
a minor deterioration in |
minor deterioration in hit |
deterioration in hit ratio |
in hit ratio can |
hit ratio can yield |
peer protocols to support |
ratio can yield a |
protocols to support live |
can yield a prohibitive |
to support live and |
yield a prohibitive load |
support live and interactive |
a prohibitive load on |
live and interactive content |
prohibitive load on the |
and interactive content have |
load on the backend |
on the backend database |
interactive content have existed |
content have existed earlier |
an excellent example of |
excellent example of such |
example of such technology |
c shows the experiment |
shows the experiment results |
of such technology is |
such technology is the |
technology is the croquet |
each data point is |
data point is the |
point is the result |
is the result of |
the result of a |
result of a single |
of a single run |
we vary the dependency |
vary the dependency list |
the dependency list size |
dependency list size and |
list size and for |
size and for each |
and for each value |
in which the entire |
for each value run |
which the entire state |
each value run the |
the entire state of |
value run the experiment |
entire state of a |
run the experiment for |
state of a virtual |
the experiment for the |
experiment for the two |
for the two workloads |
the two workloads and |
two workloads and measure |
d world is stored |
workloads and measure the |
world is stored in |
is stored in a |
stored in a peer |
and measure the average |
measure the average values |
the average values of |
average values of these |
values of these metrics |
peer fashion and updated |
fashion and updated using |
and updated using a |
updated using a two |
cache is able to |
is able to reduce |
able to reduce inconsistencies |
to reduce inconsistencies significantly |
other work in this |
for the retailer workload |
work in this direction |
in this direction includes |
a single dependency reduces |
single dependency reduces inconsistencies |
dependency reduces inconsistencies to |
of their original value |
two dependencies reduce inconsistencies |
dependencies reduce inconsistencies to |
none of these systems |
of these systems supports |
these systems supports the |
systems supports the sorts |
supports the sorts of |
the sorts of componentized |
layered architectures that we |
architectures that we have |
that we have advocated |
we have advocated here |
of their original value |
update delay as seen |
the types of peer |
delay as seen by |
as seen by individual |
seen by individual processes |
and three to less |
by individual processes during |
three to less than |
individual processes during persistent |
processes during persistent link |
peer protocols these systems |
during persistent link congestion |
protocols these systems can |
persistent link congestion node |
these systems can leverage |
and the types of |
for the social network |
the types of a |
the social network workload |
types of a traditional |
of a traditional hosted |
a traditional hosted content |
traditional hosted content they |
hosted content they can |
content they can blend |
they can blend with |
can blend with their |
blend with their p |
updates on upstream and |
on upstream and downstream |
upstream and downstream fifo |
and downstream fifo channels |
of the inconsistencies remain |
in both workloads there |
both workloads there is |
workloads there is no |
our platform is designed |
there is no visible |
platform is designed from |
is no visible effect |
is designed from ground |
no visible effect on |
designed from ground up |
visible effect on cache |
effect on cache hit |
from ground up with |
on cache hit ratio |
ground up with extensibility |
up with extensibility in |
with extensibility in mind |
and hence no increased |
hence no increased access |
no increased access rate |
every part of it |
increased access rate at |
access rate at the |
rate at the database |
part of it can |
of it can be |
it can be replaced |
can be replaced and |
be replaced and customized |
the reduction in inconsistency |
reduction in inconsistency ratio |
in inconsistency ratio is |
and different components within |
inconsistency ratio is significantly |
different components within a |
ratio is significantly better |
components within a single |
is significantly better for |
within a single mashup |
significantly better for the |
a single mashup application |
better for the next |
single mashup application can |
for the next we |
mashup application can leverage |
the next we compared |
application can leverage different |
next we compared our |
can leverage different transport |
we compared our technique |
leverage different transport protocols |
compared our technique with |
our technique with a |
technique with a simple |
with a simple approach |
a simple approach in |
simple approach in which |
prior work on typed |
approach in which we |
work on typed component |
in which we limited |
on typed component architectures |
which we limited the |
we limited the life |
typed component architectures includes |
limited the life span |
component architectures includes a |
architectures includes a tremendous |
includes a tremendous variety |
a tremendous variety of |
tremendous variety of programming |
variety of programming languages |
of programming languages and |
programming languages and platforms |
including early languages such |
early languages such as |
languages such as smalltalk |
such as smalltalk alongside |
as smalltalk alongside modern |
smalltalk alongside modern component |
here inconsistencies are not |
inconsistencies are not detected |
based environments such as |
environments such as java |
but their probability of |
their probability of being |
probability of being witnessed |
of being witnessed is |
being witnessed is reduced |
witnessed is reduced by |
is reduced by having |
reduced by having the |
by having the cache |
specialized component architectures such |
having the cache evict |
component architectures such figure |
the cache evict entries |
cache evict entries after |
evict entries after a |
entries after a certain |
after a certain period |
a certain period even |
certain period even if |
period even if the |
even if the database |
scalability qsm and jgroups |
if the database did |
the database did not |
database did not indicate |
did not indicate they |
not indicate they are |
indicate they are invalid |
throughput for various numbers |
for various numbers of |
various numbers of topics |
compares the efficacy of |
the efficacy of the |
efficacy of the abort |
for srm and ricochet |
srm and ricochet with |
and ricochet with varying |
ricochet with varying numbers |
with varying numbers of |
varying numbers of topics |
evict and retry policies |
and retry policies with |
retry policies with the |
policies with the amazon |
with the amazon and |
the amazon and orkut |
as mit s argus |
amazon and orkut workloads |
mit s argus system |
inconsistency window against gossip |
window against gossip rate |
against gossip rate at |
gossip rate at the |
rate at the failed |
in these experiments we |
flexible protocol composition stacks |
at the failed node |
these experiments we use |
protocol composition stacks such |
experiments we use dependency |
composition stacks such as |
stacks such as bast |
we use dependency lists |
use dependency lists of |
dependency lists of length |
just as with the |
as with the synthetic |
with the synthetic workload |
evicting conflicting transactions is |
conflicting transactions is an |
oriented architectures such as |
architectures such as juni |
transactions is an effective |
is an effective way |
an effective way of |
effective way of invalidating |
way of invalidating stale |
of invalidating stale objects |
invalidating stale objects that |
stale objects that might |
objects that might cause |
that might cause problems |
might cause problems for |
cause problems for future |
problems for future transactions |
has been used in |
the effects are more |
been used in the |
effects are more pronounced |
used in the context |
are more pronounced for |
in the context of |
more pronounced for the |
pronounced for the well |
time between node failure |
the context of integrating |
between node failure and |
context of integrating service |
node failure and rejoin |
failure and rejoin as |
and rejoin as number |
rejoin as number of |
as number of consecutive |
with the amazon workload |
number of consecutive updates |
of consecutive updates missed |
consecutive updates missed by |
updates missed by the |
missed by the victim |
abort is able to |
is able to detect |
by the victim node |
discussion of component integration |
of component integration systems |
component integration systems and |
integration systems and their |
systems and their relation |
and their relation to |
their relation to live |
relation to live objects |
of the inconsistent transactions |
is beyond the scope |
beyond the scope of |
whereas with the less |
the scope of this |
scope of this paper |
clustered orkut workload it |
orkut workload it only |
more details can be |
workload it only detects |
details can be found |
can be found in |
in both cases evict |
both cases evict reduces |
cases evict reduces uncommittable |
evict reduces uncommittable transactions |
reduces uncommittable transactions considerably |
relative to their value |
much relevant prior work |
to their value with |
relevant prior work consists |
their value with abort |
prior work consists of |
work consists of the |
consists of the scripting |
of the scripting languages |
the scripting languages mentioned |
scripting languages mentioned in |
languages mentioned in the |
mentioned in the discussion |
in the discussion above |
with the amazon workload |
the amazon workload and |
in the amazon workload |
our belief is that |
belief is that even |
is that even though |
retry further reduces this |
that even though these |
further reduces this value |
even though these languages |
reduces this value to |
though these languages are |
these languages are intended |
languages are intended for |
are intended for fairly |
intended for fairly general |
for fairly general use |
they have evolved to |
have evolved to focus |
evolved to focus on |
of its value with |
to focus on minibrowser |
its value with abort |
focus on minibrowser situations |
on minibrowser situations in |
minibrowser situations in which |
situations in which the |
in which the application |
which the application lives |
the application lives within |
application lives within a |
lives within a dedicated |
within a dedicated browser |
a dedicated browser frame |
r elated w ork |
elated w ork a |
interacts directly with the |
directly with the user |
and cannot be mixed |
cannot be mixed with |
be mixed with content |
mixed with content from |
recent years have seen |
with content from other |
years have seen a |
content from other sources |
have seen a surge |
from other sources in |
seen a surge of |
other sources in a |
a surge of progress |
sources in a layered |
surge of progress in |
in a layered fashion |
of progress in the |
progress in the development |
in the development of |
the development of scalable |
development of scalable object |
live objects can support |
of scalable object stores |
objects can support minibrowsers |
scalable object stores that |
object stores that support |
stores that support transactions |
can support minibrowsers as |
support minibrowsers as objects |
some systems such as |
but we ve argued |
we ve argued that |
ve argued that by |
argued that by modeling |
that by modeling hosted |
by modeling hosted content |
modeling hosted content at |
hosted content at a |
content at a lower |
at a lower level |
a lower level as |
lower level as components |
level as components that |
as components that interact |
components that interact via |
that interact via events |
interact via events and |
via events and focusing |
events and focusing on |
and focusing on the |
focusing on the multi |
layered style of mashups |
style of mashups as |
of mashups as opposed |
mashups as opposed to |
as opposed to the |
opposed to the standard |
to the standard tiled |
the standard tiled model |
conclusions to build ambitious |
to build ambitious collaboration |
build ambitious collaboration application |
the web services community |
web services community will |
services community will need |
community will need ways |
will need ways to |
need ways to combine |
content from multiple sources |
these include hosted sources |
include hosted sources that |
export novel consistency definitions |
hosted sources that run |
novel consistency definitions that |
sources that run in |
consistency definitions that allow |
that run in data |
definitions that allow for |
run in data centers |
that allow for effective |
allow for effective optimizations |
in data centers and |
data centers and support |
centers and support web |
and support web services |
support web services interfaces |
several recent systems implement |
recent systems implement full |
systems implement full fledged |
but also direct peer |
implement full fledged atomicity |
full fledged atomicity while |
fledged atomicity while preserving |
atomicity while preserving the |
while preserving the system |
preserving the system s |
the system s scalability |
system s scalability with |
s scalability with a |
peer protocols capable of |
scalability with a wide |
protocols capable of transporting |
with a wide variety |
a wide variety of |
wide variety of workloads |
capable of transporting audio |
google s spanner utilizes |
s spanner utilizes accurate |
spanner utilizes accurate clock |
utilizes accurate clock synchronization |
whiteboard data and other |
data and other content |
and other content at |
other content at high |
content at high data |
at high data rates |
gossip chain inconsistency window |
a further need is |
further need is to |
by balakrishnan et al |
need is to allow |
is to allow disconnected |
to allow disconnected collaboration |
is constructed on top |
constructed on top of |
on top of the |
top of the scalable |
of the scalable corfu |
back to data centers |
our review of the |
review of the performance |
of the performance of |
the performance of enterprise |
performance of enterprise service |
of enterprise service bus |
enterprise service bus eventing |
service bus eventing solutions |
bus eventing solutions in |
eventing solutions in the |
solutions in the standard |
in the standard hosted |
the standard hosted web |
standard hosted web services |
hosted web services model |
web services model made |
services model made it |
model made it clear |
made it clear that |
utilize a large set |
it clear that hosted |
a large set of |
clear that hosted event |
large set of independent |
that hosted event channels |
set of independent logs |
hosted event channels won |
event channels won t |
channels won t have |
won t have the |
t have the scalability |
have the scalability and |
the scalability and latency |
scalability and latency properties |
and latency properties needed |
latency properties needed by |
properties needed by many |
needed by many applications |
p alternatives often achieve |
alternatives often achieve far |
often achieve far better |
achieve far better scalability |
they also have security |
also have security advantages |
the data center doesn |
data center doesn t |
center doesn t get |
doesn t get a |
t get a chance |
get a chance to |
a chance to see |
use lock chains and |
lock chains and assume |
chains and assume transactions |
and assume transactions are |
assume transactions are known |
transactions are known in |
are known in advance |
these methods all scale |
the live objects platform |
methods all scale well |
live objects platform can |
all scale well and |
objects platform can seamlessly |
scale well and in |
platform can seamlessly support |
well and in many |
can seamlessly support applications |
and in many cases |
seamlessly support applications that |
in many cases allow |
support applications that require |
many cases allow databases |
applications that require a |
cases allow databases to |
that require a mixture |
require a mixture of |
a mixture of data |
mixture of data sources |
allow databases to accept |
databases to accept loads |
to accept loads similar |
accept loads similar to |
loads similar to those |
similar to those handled |
to those handled by |
those handled by non |
including both hosted and |
both hosted and direct |
hosted and direct p |
inconsistency window against gossip |
window against gossip rate |
against gossip rate for |
gossip rate for the |
rate for the whole |
for the whole chain |
they are not expected |
are not expected to |
further benefits include an |
not expected to disrupt |
benefits include an easy |
expected to disrupt the |
include an easy to |
an easy to use |
easy to use drag |
to disrupt the prevailing |
disrupt the prevailing two |
drop programming style that |
programming style that yields |
style that yields applications |
that yields applications represented |
yields applications represented as |
applications represented as xml |
represented as xml files |
note that we are |
that we are addressing |
we are addressing the |
are addressing the problem |
addressing the problem of |
the problem of read |
which can be shared |
can be shared as |
be shared as files |
shared as files or |
as files or even |
files or even via |
or even via email |
only incoherent caches that |
incoherent caches that respond |
caches that respond to |
that respond to queries |
respond to queries without |
to queries without access |
users that open such |
queries without access to |
that open such files |
without access to the |
open such files find |
access to the backend |
such files find themselves |
to the backend database |
files find themselves immersed |
find themselves immersed in |
themselves immersed in a |
immersed in a mediarich |
time between node failure |
previous work on coherent |
in a mediarich collaborative |
between node failure and |
work on coherent caches |
a mediarich collaborative environment |
node failure and rejoin |
mediarich collaborative environment that |
failure and rejoin as |
collaborative environment that also |
and rejoin as number |
environment that also offers |
rejoin as number of |
that also offers strong |
also offers strong reliability |
as number of consecutive |
number of consecutive updates |
of consecutive updates missed |
consecutive updates missed by |
updates missed by the |
missed by the victim |
by the victim node |
in the near future |
most important of all |
live objects are real |
the platform is available |
platform is available for |
is available for free |
available for free download |
for free download from |
free download from cornell |
supports transactions using locks |
transactions using locks or |
using locks or communication |
locks or communication with |
or communication with the |
communication with the database |
with the database on |
the database on each |
database on each transaction |
inconsistency window against the |
these techniques are not |
window against the ratio |
techniques are not applicable |
against the ratio between |
are not applicable in |
the ratio between injection |
not applicable in our |
ratio between injection rate |
applicable in our scenario |
between injection rate and |
injection rate and gossip |
rate and gossip rate |
lateral error correction for |
error correction for time |
different update injection delay |
s overload by dropping |
overload by dropping updates |
by dropping updates on |
dropping updates on its |
updates on its inbound |
on its inbound and |
its inbound and outbound |
inbound and outbound fifo |
and outbound fifo channels |
outbound fifo channels according |
fifo channels according to |
channels according to a |
according to a random |
to a random distribution |
a random distribution throughout |
random distribution throughout the |
distribution throughout the first |
throughout the first three |
the first three quarters |
first three quarters of |
three quarters of the |
quarters of the experiment |
exploiting gossip for self |
and we report on |
management in scalable event |
in scalable event notification |
scalable event notification systems |
updates that were initially |
that were initially dropped |
were initially dropped and |
initially dropped and eventually |
dropped and eventually made |
and eventually made their |
eventually made their way |
made their way through |
their way through gossip |
way through gossip could |
through gossip could later |
gossip could later be |
could later be sent |
later be sent via |
be sent via fifo |
sent via fifo channels |
via fifo channels as |
fifo channels as shown |
channels as shown by |
semantic integration of web |
as shown by the |
integration of web services |
shown by the increasingly |
of web services and |
by the increasingly large |
web services and peer |
the increasingly large density |
increasingly large density of |
large density of dark |
peer networks to achieve |
networks to achieve fault |
plots closer to the |
closer to the tail |
to the tail of |
the tail of the |
tail of the chain |
as before note that |
before note that the |
note that the yaxes |
that the yaxes have |
the yaxes have different |
yaxes have different scales |
have different scales to |
different scales to observe |
scales to observe the |
to observe the delays |
observe the delays better |
the figures show that |
figures show that even |
show that even for |
that even for a |
even for a gossip |
for a gossip rate |
a gossip rate half |
gossip rate half the |
rate half the injection |
half the injection rate |
recall that this is |
that this is the |
this is the rate |
is the rate at |
the rate at which |
rate at which digests |
flexible protocol composition in |
protocol composition in bast |
are exchanged between two |
exchanged between two or |
between two or more |
two or more processes |
the epidemics could deliver |
epidemics could deliver messages |
could deliver messages with |
deliver messages with a |
messages with a delay |
with a delay of |
a delay of about |
self organizing live objects |
s for the rest |
for the rest of |
the rest of the |
rest of the chain |
of the chain during |
the chain during a |
chain during a congestion |
during a congestion that |
a congestion that took |
the plot also shows |
plot also shows that |
also shows that delays |
shows that delays increased |
that delays increased with |
delays increased with time |
therefore if congestion may |
if congestion may span |
congestion may span large |
may span large periods |
span large periods of |
large periods of time |
the gossip rate must |
gossip rate must be |
rate must be carefully |
must be carefully tuned |
be carefully tuned to |
carefully tuned to compensate |
tuned to compensate for |
to compensate for the |
compensate for the losses |
for the losses induced |
the losses induced by |
losses induced by the |
induced by the congested |
by the congested tcp |
the congested tcp channels |
db access rate normed |
jms performance comparison for |
the second round of |
performance comparison for publish |
second round of experiments |
comparison for publish subscribe |
round of experiments quantified |
for publish subscribe messaging |
of experiments quantified the |
experiments quantified the average |
quantified the average and |
the average and maximum |
average and maximum inconsistency |
fiorano software technologies pvt |
and maximum inconsistency window |
db access rate normed |
maximum inconsistency window for |
inconsistency window for a |
window for a service |
under various update injection |
various update injection rates |
update injection rates and |
injection rates and gossip |
rates and gossip rates |
and gossip rates respectively |
we define the inconsistency |
define the inconsistency window |
the inconsistency window as |
inconsistency window as the |
window as the time |
as the time interval |
the time interval during |
time interval during which |
interval during which queries |
during which queries against |
which queries against the |
queries against the service |
against the service return |
the service return a |
service return a stale |
return a stale value |
shows that the inconsistency |
that the inconsistency window |
the inconsistency window grows |
inconsistency window grows slowly |
window grows slowly as |
grows slowly as the |
slowly as the gap |
leveraging collaboration of peer |
as the gap between |
the gap between the |
gap between the update |
between the update injection |
the update injection rate |
update injection rate and |
injection rate and the |
rate and the gossip |
and the gossip rate |
peer and web services |
the gossip rate widens |
the graph s x |
graph s x axis |
s x axis represents |
hit ratio hit ratio |
x axis represents the |
axis represents the ratio |
represents the ratio between |
the ratio between the |
ratio between the update |
between the update injection |
the update injection rate |
update injection rate and |
injection rate and gossip |
rate and gossip rate |
this confirms that epidemics |
confirms that epidemics are |
that epidemics are a |
epidemics are a robust |
are a robust tunable |
a robust tunable mechanism |
robust tunable mechanism providing |
tunable mechanism providing graceful |
mechanism providing graceful degradation |
the inconsistency window shifts |
inconsistency window shifts in |
window shifts in accordance |
shifts in accordance with |
in accordance with the |
accordance with the update |
with the update injection |
the update injection rate |
notice that the difference |
that the difference between |
the difference between the |
difference between the maximum |
product a nity social |
between the maximum inconsistency |
a nity social network |
the maximum inconsistency window |
maximum inconsistency window and |
based web service composition |
inconsistency window and the |
web service composition with |
window and the average |
service composition with jade |
and the average inconsistency |
composition with jade and |
the average inconsistency window |
with jade and jxta |
average inconsistency window is |
inconsistency window is two |
window is two orders |
is two orders of |
two orders of magnitude |
this reflects the degree |
reflects the degree to |
the degree to which |
degree to which the |
to which the victim |
which the victim node |
the victim node lags |
victim node lags the |
node lags the other |
lags the other nodes |
the other nodes during |
other nodes during the |
nodes during the period |
during the period before |
the period before it |
period before it has |
before it has fully |
it has fully caught |
has fully caught up |
next we evaluated the |
we evaluated the inconsistency |
evaluated the inconsistency window |
the inconsistency window of |
inconsistency window of a |
window of a service |
of a service running |
a service running at |
service running at a |
running at a particular |
at a particular update |
a particular update rate |
and for three different |
for three different intervals |
three different intervals in |
different intervals in which |
intervals in which the |
in which the victim |
which the victim node |
the victim node is |
victim node is halted |
based architecture for semanticweb |
architecture for semanticweb service |
for semanticweb service automatic |
semanticweb service automatic composition |
show average and maximum |
average and maximum inconsistency |
and maximum inconsistency windows |
maximum inconsistency windows for |
inconsistency windows for both |
windows for both the |
for both the victim |
both the victim and |
the victim and for |
victim and for the |
and for the other |
for the other processes |
the other processes of |
other processes of one |
processes of one subservice |
the more messages the |
more messages the victim |
messages the victim node |
the victim node needs |
victim node needs to |
node needs to recover |
the larger the inconsistency |
larger the inconsistency window |
again the difference between |
the difference between the |
difference between the average |
between the average and |
the average and maximum |
average and maximum in |
and jong hoon ahnn |
programming with live distributed |
with live distributed objects |
product a nity social |
a nity social network |
achieving reliability through distributed |
reliability through distributed data |
through distributed data flows |
distributed data flows and |
data flows and recursive |
flows and recursive delegation |
changtao qu and wolfgang |
qu and wolfgang nejdl |
limited cache entry ttl |
cache entry ttl fig |
peer network with web |
experiments with workloads based |
network with web services |
with workloads based on |
workloads based on a |
based on a web |
on a web retailer |
a web retailer product |
web retailer product affinity |
retailer product affinity topology |
product affinity topology and |
affinity topology and a |
topology and a social |
and a social network |
a social network topology |
social network topology illustrated |
network topology illustrated in |
compared against the alternative |
against the alternative of |
the alternative of reducing |
alternative of reducing cache |
of reducing cache entry |
reducing cache entry time |
a scalable and ontology |
data points are medians |
points are medians and |
are medians and error |
medians and error bars |
and error bars bound |
error bars bound the |
p infrastructure for semantic |
infrastructure for semantic web |
for semantic web services |
delivery distribution for a |
distribution for a chain |
gossip rate left figure |
this could work well |
could work well if |
work well if a |
well if a system |
if a system has |
a system has multiple |
system has multiple classes |
has multiple classes of |
multiple classes of objects |
all clustered but with |
clustered but with different |
but with different associated |
with different associated clustering |
different associated clustering properties |
a collaboration system architecture |
on each graph left |
each graph left bars |
graph left bars denote |
left bars denote transient |
bars denote transient failure |
consistent inconsistent aborted ab |
sonic performance test suite |
inconsistent aborted ab ev |
aborted ab ev re |
ab ev re ab |
ev re ab ev |
re ab ev re |
right bars denote a |
ab ev re i |
bars denote a transient |
ev re i i |
denote a transient failure |
re i i tr |
a transient failure corroborated |
i i tr tr |
transient failure corroborated with |
i tr tr o |
failure corroborated with a |
tr tr o o |
corroborated with a link |
tr o o rt |
with a link congestion |
o o rt ct |
o rt ct rt |
a link congestion phenomenon |
rt ct rt ct |
link congestion phenomenon modeled |
ct rt ct y |
congestion phenomenon modeled by |
rt ct y y |
ct y y amazon |
y y amazon orkut |
y amazon orkut fig |
message drop on the |
drop on the adjacent |
on the adjacent fifo |
the efficacy of t |
the adjacent fifo channels |
adjacent fifo channels of |
fifo channels of node |
cache as a function |
as a function of |
a function of the |
function of the inconsistency |
of the inconsistency handling |
the inconsistency handling strategy |
inconsistency handling strategy for |
handling strategy for realistic |
strategy for realistic workloads |
much work has been |
work has been done |
has been done on |
been done on creating |
done on creating consistent |
on creating consistent caches |
creating consistent caches for |
consistent caches for web |
caches for web servers |
a demonstration of collaborative |
demonstration of collaborative web |
of collaborative web services |
collaborative web services and |
web services and peer |
p network based architecture |
network based architecture for |
based architecture for web |
architecture for web service |
and higher level objects |
such systems consider only |
systems consider only one |
consider only one object |
only one object at |
one object at a |
object at a time |
and only individual read |
only individual read and |
individual read and write |
read and write operations |
as they do not |
they do not support |
do not support a |
not support a transactional |
support a transactional interface |
there are few if |
are few if any |
few if any multi |
we found that less |
found that less than |
these systems generally try |
systems generally try to |
generally try to avoid |
try to avoid staleness |
to avoid staleness through |
avoid staleness through techniques |
staleness through techniques such |
through techniques such as |
techniques such as time |
of the messages were |
the messages were delivered |
messages were delivered by |
were delivered by gossip |
delivered by gossip for |
by gossip for the |
gossip for the nodes |
for the nodes to |
the nodes to the |
nodes to the left |
to the left of |
the left of the |
left of the victim |
this confirms that gossip |
confirms that gossip rarely |
that gossip rarely is |
gossip rarely is used |
rarely is used to |
our work considers multi |
is used to circumvent |
used to circumvent chain |
to circumvent chain replication |
circumvent chain replication in |
chain replication in the |
object transactional consistency of |
replication in the normal |
in the normal case |
transactional consistency of cache |
consistency of cache access |
a peculiar effect is |
peculiar effect is noticeable |
effect is noticeable in |
is noticeable in figure |
early work on scalable |
work on scalable database |
on scalable database caching |
scalable database caching mostly |
database caching mostly ignored |
caching mostly ignored transactional |
mostly ignored transactional consistency |
in that more messages |
that more messages are |
more messages are delivered |
messages are delivered via |
are delivered via gossip |
even in the prefix |
in the prefix part |
the prefix part of |
prefix part of the |
part of the chain |
although the effect is |
the effect is also |
effect is also evident |
is also evident in |
also evident in the |
evident in the suffix |
work has been done |
it is more significant |
has been done on |
is more significant on |
been done on creating |
more significant on the |
done on creating consistent |
significant on the left |
on creating consistent caches |
on the left hand |
the left hand side |
left hand side figure |
creating consistent caches for |
consistent caches for databases |
where the gossip rate |
the gossip rate is |
gossip rate is higher |
because we observed this |
we observed this phenomenon |
observed this phenomenon only |
this phenomenon only with |
phenomenon only with update |
only with update rates |
with update rates of |
extends a centralized database |
a centralized database with |
centralized database with support |
database with support for |
with support for caches |
support for caches that |
for caches that provide |
caches that provide snapshot |
that provide snapshot isolation |
provide snapshot isolation semantics |
albeit the snapshots seen |
the snapshots seen may |
snapshots seen may be |
we suspect that the |
seen may be stale |
suspect that the network |
that the network stack |
the network stack is |
network stack is more |
to improve the commit |
stack is more efficient |
improve the commit rate |
is more efficient in |
the commit rate for |
more efficient in dealing |
commit rate for read |
efficient in dealing with |
in dealing with udp |
dealing with udp packets |
with udp packets then |
udp packets then with |
packets then with tcp |
then with tcp ones |
with tcp ones under |
tcp ones under heavy |
ones under heavy load |
where the cache holds |
the cache holds several |
cache holds several versions |
holds several versions of |
several versions of an |
versions of an object |
of an object and |
an object and enables |
object and enables the |
and enables the cache |
enables the cache to |
the cache to choose |
cache to choose a |
to choose a version |
choose a version that |
a version that allows |
version that allows a |
that allows a transaction |
allows a transaction to |
a transaction to commit |
this technique could also |
technique could also be |
could also be used |
also be used with |
be used with our |
used with our solution |
delivery distribution for a |
distribution for a chain |
also support snapshot isolation |
but can be used |
can be used with |
be used with any |
used with any backend |
with any backend database |
including ones that are |
ones that are sharded |
that are sharded and |
provides a transactionally consistent |
a transactionally consistent cache |
transactionally consistent cache for |
consistent cache for the |
cache for the jboss |
for the jboss middleware |
support transactions on cached |
transactions on cached enterprise |
on cached enterprise javabeans |
consistency windows is slightly |
windows is slightly more |
is slightly more than |
slightly more than an |
more than an order |
than an order of |
an order of magnitude |
and this is attributable |
this is attributable to |
is attributable to the |
attributable to the victim |
to the victim node |
the victim node observe |
allows update transactions to |
victim node observe that |
update transactions to read |
node observe that the |
transactions to read stale |
observe that the two |
to read stale data |
that the two graphs |
read stale data out |
the two graphs denoting |
stale data out of |
two graphs denoting the |
data out of caches |
graphs denoting the maximum |
out of caches and |
denoting the maximum inconsistency |
of caches and provide |
the maximum inconsistency windows |
caches and provide bounds |
maximum inconsistency windows for |
and provide bounds on |
inconsistency windows for the |
provide bounds on how |
windows for the victim |
bounds on how much |
for the victim node |
on how much staleness |
the victim node and |
how much staleness is |
victim node and for |
much staleness is allowed |
node and for the |
and for the entire |
for the entire chain |
the entire chain are |
entire chain are identical |
these techniques require fast |
techniques require fast communication |
require fast communication between |
fast communication between the |
which means that clients |
communication between the cache |
means that clients perceiving |
between the cache and |
that clients perceiving significant |
the cache and the |
clients perceiving significant inconsistency |
cache and the database |
perceiving significant inconsistency are |
and the database for |
significant inconsistency are the |
the database for good |
database for good performance |
inconsistency are the ones |
are the ones that |
the ones that are |
ones that are querying |
that are querying the |
are querying the victim |
querying the victim node |
the victim node while |
victim node while it |
node while it is |
in our work caches |
while it is still |
our work caches are |
it is still recovering |
work caches are asynchronously |
caches are asynchronously updated |
is still recovering state |
finally we performed a |
we performed a set |
performed a set of |
a set of experiments |
set of experiments to |
which is how caches |
of experiments to determine |
is how caches currently |
experiments to determine the |
how caches currently work |
to determine the distribution |
caches currently work in |
determine the distribution of |
currently work in large |
the distribution of messages |
work in large multi |
distribution of messages delivered |
of messages delivered by |
messages delivered by the |
delivered by the chain |
by the chain vs |
the chain vs delivered |
chain vs delivered by |
research edition where the |
vs delivered by gossip |
edition where the academic |
where the academic knights |
the academic knights meet |
f uture d irections |
academic knights meet the |
uture d irections the |
knights meet the evil |
d irections the dependency |
one transient failure affects |
meet the evil empire |
irections the dependency list |
transient failure affects the |
the evil empire werner |
the dependency list sizes |
failure affects the wall |
evil empire werner vogels |
dependency list sizes for |
empire werner vogels the |
list sizes for all |
werner vogels the rivalry |
sizes for all objects |
vogels the rivalry in |
for all objects in |
the runs are eight |
all objects in t |
the rivalry in the |
runs are eight times |
rivalry in the operating |
are eight times longer |
in the operating system |
eight times longer than |
cache are currently all |
the operating system market |
times longer than the |
are currently all of |
operating system market place |
longer than the runs |
currently all of the |
system market place has |
than the runs before |
all of the same |
market place has a |
of the same maximum |
place has a severe |
the same maximum length |
has a severe impact |
both in total experiment |
a severe impact on |
in total experiment time |
this may not be |
may not be optimal |
total experiment time and |
severe impact on the |
experiment time and time |
impact on the academic |
time and time the |
on the academic world |
and time the victim |
time the victim node |
the victim node is |
if the workload accesses |
victim node is halted |
the workload accesses objects |
where in the old |
workload accesses objects in |
in the old days |
accesses objects in clusters |
the old days intellection |
objects in clusters of |
old days intellection quality |
in clusters of different |
days intellection quality and |
clusters of different sizes |
intellection quality and careful |
quality and careful deliberation |
and careful deliberation would |
careful deliberation would prevail |
objects of larger clusters |
of larger clusters call |
larger clusters call for |
clusters call for longer |
call for longer dependency |
nowadays discussions about operating |
for longer dependency lists |
discussions about operating systems |
about operating systems research |
operating systems research appear |
show the number of |
systems research appear to |
once appropriate real workloads |
the number of messages |
research appear to be |
appropriate real workloads are |
number of messages delivered |
appear to be more |
real workloads are available |
of messages delivered by |
to be more like |
messages delivered by the |
be more like the |
delivered by the chain |
more like the battlefield |
it may be possible |
by the chain replication |
like the battlefield of |
may be possible to |
the chain replication mechanism |
the battlefield of a |
be possible to improve |
chain replication mechanism and |
battlefield of a holy |
of a holy war |
replication mechanism and the |
possible to improve performance |
mechanism and the ones |
to improve performance by |
and the ones delivered |
improve performance by dynamically |
with objectivity as its |
the ones delivered by |
performance by dynamically changing |
objectivity as its main |
as its main victim |
by dynamically changing per |
ones delivered by the |
delivered by the epidemics |
we have tried to |
object dependency list sizes |
have tried to side |
for each of the |
tried to side step |
each of the nodes |
to side step the |
of the nodes in |
side step the emotional |
the nodes in a |
nodes in a chain |
step the emotional current |
balancing between objects to |
between objects to maintain |
objects to maintain the |
to maintain the same |
again we omitted the |
maintain the same overall |
and select an operating |
we omitted the head |
the same overall space |
select an operating system |
omitted the head of |
same overall space overhead |
an operating system that |
the head of the |
operating system that could |
head of the chain |
system that could bring |
of the chain node |
another option is to |
that could bring our |
the chain node because |
option is to explore |
could bring our research |
chain node because its |
is to explore an |
bring our research into |
node because its behavior |
to explore an approach |
our research into the |
because its behavior is |
explore an approach in |
research into the next |
its behavior is not |
an approach in which |
into the next century |
behavior is not representative |
approach in which each |
in which each type |
which each type of |
each type of object |
based on objective technical |
and in this experiment |
type of object would |
on objective technical and |
in this experiment we |
of object would have |
objective technical and organizational |
this experiment we have |
object would have its |
technical and organizational criteria |
experiment we have chains |
would have its own |
we have chains of |
have its own dependency |
have chains of length |
this paper describes how |
its own dependency list |
paper describes how this |
own dependency list bound |
describes how this evaluation |
how this evaluation lead |
this evaluation lead to |
evaluation lead to the |
lead to the insight |
to the insight that |
the insight that microsoft |
insight that microsoft s |
that microsoft s windows |
microsoft s windows nt |
s windows nt is |
windows nt is the |
nt is the operating |
is the operating system |
the operating system that |
operating system that is |
agnostic and treats all |
system that is best |
and treats all objects |
that is best prepared |
treats all objects and |
is best prepared for |
all objects and object |
best prepared for the |
delivered updates by means |
objects and object relations |
prepared for the future |
updates by means of |
and object relations as |
by means of the |
object relations as equal |
means of the gossip |
introduction until recently there |
of the gossip repair |
until recently there was |
the gossip repair mechanism |
recently there was no |
using an lru policy |
there was no doubt |
an lru policy to |
was no doubt in |
lru policy to trim |
as the nodes get |
no doubt in academia |
policy to trim the |
the nodes get further |
doubt in academia which |
to trim the list |
nodes get further away |
in academia which operating |
trim the list of |
get further away from |
academia which operating system |
the list of dependencies |
further away from the |
which operating system to |
away from the victim |
operating system to use |
from the victim node |
system to use for |
to use for systems |
use for systems research |
there may be cases |
more of the messages |
may be cases in |
of the messages were |
be cases in which |
the messages were delivered |
cases in which the |
messages were delivered by |
whether it was a |
in which the application |
were delivered by means |
it was a bsd |
which the application could |
delivered by means of |
was a bsd or |
the application could explicitly |
by means of the |
means of the chain |
application could explicitly inform |
a bsd or system |
could explicitly inform the |
bsd or system v |
explicitly inform the cache |
or system v derivative |
because the repair mechanism |
inform the cache of |
the repair mechanism relinked |
the cache of relevant |
repair mechanism relinked the |
cache of relevant object |
was the predominant choice |
mechanism relinked the chain |
of relevant object dependencies |
relinked the chain and |
the chain and chain |
chain and chain replication |
and chain replication began |
chain replication began to |
replication began to function |
and those could then |
began to function normally |
which had its roots |
those could then be |
had its roots in |
could then be treated |
its roots in research |
then be treated as |
the speed with which |
be treated as more |
speed with which the |
treated as more important |
with which the chain |
was used since its |
as more important and |
which the chain is |
used since its inception |
more important and retained |
the chain is restored |
since its inception to |
chain is restored depends |
its inception to investigate |
is restored depends on |
inception to investigate fundamental |
while other less important |
restored depends on the |
to investigate fundamental system |
other less important ones |
depends on the rate |
investigate fundamental system research |
less important ones are |
on the rate of |
important ones are managed |
the rate of the |
rate of the fast |
and the accumulated knowledge |
ones are managed by |
the accumulated knowledge in |
are managed by some |
accumulated knowledge in academia |
managed by some other |
knowledge in academia about |
by some other policy |
in academia about its |
some other policy such |
and on the responsiveness |
academia about its internals |
other policy such as |
on the responsiveness of |
about its internals and |
policy such as lru |
the responsiveness of the |
its internals and operations |
responsiveness of the failure |
internals and operations was |
of the failure detection |
and operations was significant |
the failure detection mechanism |
in a web album |
a web album the |
other available operating systems |
future development the current |
web album the set |
available operating systems such |
development the current ssa |
album the set of |
operating systems such as |
the current ssa implementation |
the set of pictures |
systems such as vms |
current ssa implementation uses |
set of pictures and |
such as vms and |
as vms and mvs |
of pictures and their |
ssa implementation uses gossip |
pictures and their acl |
implementation uses gossip in |
and their acl is |
uses gossip in situations |
had their roots in |
their acl is an |
their roots in the |
acl is an important |
roots in the commercial |
gossip in situations where |
is an important dependency |
in the commercial world |
in situations where faster |
an important dependency whereas |
the commercial world and |
situations where faster notifications |
important dependency whereas occasional |
commercial world and knowledge |
where faster notifications might |
dependency whereas occasional tagging |
world and knowledge about |
faster notifications might be |
whereas occasional tagging operations |
and knowledge about these |
notifications might be helpful |
occasional tagging operations that |
knowledge about these systems |
tagging operations that relate |
about these systems never |
operations that relate pictures |
these systems never accumulated |
that relate pictures to |
systems never accumulated to |
we believe that when |
relate pictures to users |
never accumulated to the |
believe that when a |
pictures to users may |
accumulated to the critical |
that when a node |
to users may be |
to the critical mass |
when a node fails |
users may be less |
the critical mass were |
a node fails or |
may be less important |
critical mass were these |
node fails or joins |
mass were these systems |
were these systems could |
these systems could be |
systems could be considered |
it may be straightforward |
it would be useful |
may be straightforward to |
could be considered for |
would be useful to |
be straightforward to extend |
be considered for widespread |
be useful to spread |
straightforward to extend the |
considered for widespread research |
useful to spread the |
to extend the cache |
for widespread research tasks |
to spread the news |
extend the cache api |
spread the news as |
the cache api to |
the news as quickly |
cache api to allow |
although new research operating |
news as quickly as |
api to allow the |
new research operating systems |
as quickly as possible |
to allow the application |
research operating systems have |
allow the application to |
operating systems have been |
we realize that for |
the application to specify |
systems have been developed |
realize that for some |
application to specify such |
that for some particular |
to specify such dependencies |
for some particular tasks |
specify such dependencies and |
none have found the |
some particular tasks gossip |
such dependencies and to |
have found the following |
particular tasks gossip could |
dependencies and to modify |
and to modify t |
tasks gossip could be |
found the following that |
gossip could be done |
the following that the |
could be done more |
following that the established |
cache to respect them |
be done more efficiently |
that the established unix |
the established unix s |
established unix s received |
we are therefore exploring |
are therefore exploring the |
c onclusion existing large |
therefore exploring the use |
exploring the use of |
the use of ip |
use of ip multicast |
scale computing frameworks make |
of ip multicast for |
computing frameworks make heavy |
freebsd and others continue |
ip multicast for dissemination |
frameworks make heavy use |
and others continue to |
multicast for dissemination of |
make heavy use of |
others continue to dominate |
for dissemination of urgent |
heavy use of edge |
continue to dominate the |
dissemination of urgent information |
use of edge caches |
to dominate the academic |
of urgent information as |
of edge caches to |
dominate the academic landscape |
urgent information as long |
edge caches to reduce |
information as long as |
caches to reduce client |
as long as the |
to reduce client latency |
but slowly but surely |
long as the physical |
slowly but surely windows |
as the physical nodes |
but surely windows nt |
the physical nodes are |
but this form of |
surely windows nt is |
physical nodes are not |
this form of caching |
windows nt is now |
nodes are not on |
form of caching has |
nt is now entering |
are not on a |
of caching has not |
is now entering the |
not on a public |
caching has not been |
now entering the academic |
on a public network |
has not been available |
entering the academic world |
a public network segment |
not been available for |
the academic world as |
been available for transactional |
academic world as a |
world as a viable |
available for transactional applications |
we plan to include |
alternative platform for research |
we believe this is |
plan to include support |
believe this is one |
to include support for |
this is one reason |
although academia looked with |
include support for the |
is one reason that |
academia looked with fascination |
support for the partitioning |
one reason that transactions |
looked with fascination at |
for the partitioning of |
reason that transactions are |
with fascination at dave |
the partitioning of the |
that transactions are generally |
fascination at dave cutler |
partitioning of the services |
transactions are generally not |
at dave cutler s |
of the services by |
are generally not considered |
dave cutler s attempt |
the services by means |
generally not considered to |
cutler s attempt to |
services by means of |
not considered to be |
s attempt to build |
by means of registering |
considered to be a |
attempt to build a |
means of registering partition |
to be a viable |
to build a new |
of registering partition function |
be a viable option |
build a new operating |
registering partition function handlers |
a viable option in |
a new operating system |
partition function handlers with |
viable option in extremely |
new operating system from |
function handlers with a |
option in extremely large |
operating system from the |
handlers with a global |
in extremely large systems |
system from the ground |
with a global data |
from the ground up |
a variant of serializability |
variant of serializability that |
of serializability that is |
serializability that is suitable |
that is suitable for |
is suitable for incoherent |
suitable for incoherent caches |
we have implemented only |
have implemented only the |
implemented only the server |
only the server side |
the server side load |
which cannot communicate with |
server side load balancing |
all expected that windows |
cannot communicate with the |
expected that windows nt |
side load balancing scheme |
that windows nt would |
communicate with the backend |
windows nt would go |
with the backend database |
nt would go the |
the backend database on |
we are considering ways |
would go the same |
backend database on every |
are considering ways to |
go the same way |
database on every read |
considering ways to extend |
the same way as |
on every read access |
ways to extend our |
same way as the |
to extend our approach |
way as the other |
extend our approach for |
we then presented t |
as the other commercially |
our approach for use |
the other commercially designed |
approach for use in |
other commercially designed operating |
for use in settings |
commercially designed operating systems |
use in settings where |
an architecture for controlling |
designed operating systems before |
in settings where partitioning |
architecture for controlling transaction |
operating systems before it |
settings where partitioning is |
for controlling transaction consistency |
systems before it and |
where partitioning is done |
controlling transaction consistency with |
before it and remain |
partitioning is done on |
transaction consistency with caches |
it and remain in |
is done on the |
and remain in the |
done on the client |
remain in the dark |
on the client side |
the system extends the |
in the dark corner |
system extends the edge |
the dark corner from |
extends the edge cache |
dark corner from a |
the edge cache by |
corner from a research |
edge cache by allowing |
from a research use |
side access to subservice |
cache by allowing it |
a research use point |
access to subservice membership |
by allowing it to |
research use point of |
to subservice membership information |
allowing it to offer |
use point of view |
subservice membership information is |
it to offer a |
membership information is needed |
to offer a transactional |
offer a transactional interface |
about four years ago |
we are also developing |
are also developing a |
we believe that t |
not long after the |
also developing a gui |
long after the final |
developing a gui assisted |
after the final major |
a gui assisted automated |
cache is the first |
the final major release |
gui assisted automated web |
is the first transaction |
final major release of |
assisted automated web service |
major release of academic |
automated web service deployment |
release of academic version |
web service deployment tool |
aware caching architecture in |
of academic version of |
caching architecture in which |
academic version of the |
focused on web service |
on web service applications |
version of the unix |
architecture in which caches |
of the unix operating |
in which caches are |
the unix operating system |
which caches are updated |
developers could simply drop |
caches are updated asynchronously |
could simply drop a |
simply drop a wsdl |
drop a wsdl service |
a wsdl service description |
a lookup request only |
lookup request only requires |
request only requires a |
only requires a round |
and the system will |
trip to the database |
the system will generate |
to the database in |
system will generate a |
the database in case |
will generate a xml |
database in case there |
generate a xml description |
in case there is |
a xml description that |
case there is a |
xml description that can |
there is a cache |
description that can be |
is a cache miss |
that can be used |
a cache miss there |
can be used later |
cache miss there is |
be used later on |
miss there is no |
used later on to |
there is no additional |
later on to actually |
the farewell of the |
is no additional traffic |
on to actually deploy |
farewell of the berkeley |
no additional traffic and |
to actually deploy the |
of the berkeley systems |
additional traffic and delays |
actually deploy the service |
the berkeley systems werner |
traffic and delays to |
deploy the service automatically |
berkeley systems werner vogels |
and delays to ensure |
systems werner vogels is |
delays to ensure cache |
the service will be |
service will be partitioned |
to ensure cache coherence |
werner vogels is a |
vogels is a research |
is a research scientist |
a research scientist at |
research scientist at the |
scientist at the department |
at the department of |
the department of computer |
and deployed on the |
department of computer science |
cache associates dependency information |
deployed on the fly |
of computer science of |
associates dependency information with |
on the fly on |
computer science of cornell |
dependency information with cached |
the fly on top |
science of cornell university |
information with cached database |
fly on top of |
with cached database objects |
on top of the |
top of the processing |
his research targets high |
of the processing nodes |
while leaving the interaction |
leaving the interaction between |
the interaction between the |
availability in distributed systems |
interaction between the backend |
between the backend systems |
the backend systems and |
backend systems and the |
systems and the cache |
and the cache otherwise |
with a particular focus |
the cache otherwise unchanged |
a particular focus on |
particular focus on enterprise |
focus on enterprise cluster |
on enterprise cluster systems |
scaling up to turn |
this information includes version |
up to turn the |
information includes version identifiers |
to turn the ssa |
includes version identifiers and |
turn the ssa into |
version identifiers and bounded |
the ssa into a |
ssa into a full |
into a full scale |
a full scale platform |
president of reliable network |
of reliable network solutions |
one of the immediate |
with this modest amount |
of the immediate future |
this modest amount of |
the immediate future challenges |
modest amount of additional |
immediate future challenges is |
amount of additional information |
future challenges is the |
which specializes in building |
challenges is the necessity |
specializes in building solutions |
is the necessity of |
in building solutions for |
we show that inconsistency |
the necessity of evaluating |
building solutions for very |
solutions for very large |
necessity of evaluating a |
show that inconsistency can |
of evaluating a full |
that inconsistency can be |
scale reliable distributed systems |
evaluating a full raps |
inconsistency can be greatly |
a full raps of |
can be greatly reduced |
full raps of racs |
be greatly reduced or |
raps of racs deployment |
greatly reduced or even |
reduced or even completely |
or even completely eliminated |
even completely eliminated in |
completely eliminated in some |
eliminated in some cases |
multiple partitioned and cloned |
partitioned and cloned services |
and cloned services running |
cloned services running on |
services running on our |
running on our tightly |
on our tightly coupled |
cache is intended for |
our tightly coupled cluster |
is intended for clustered |
usenix windows nt symposium |
tightly coupled cluster would |
intended for clustered workloads |
coupled cluster would lead |
cluster would lead to |
his personal homepage is |
would lead to a |
personal homepage is at |
lead to a series |
and those arise naturally |
homepage is at http |
to a series of |
those arise naturally in |
a series of other |
arise naturally in social |
series of other issues |
naturally in social networks |
of other issues that |
other issues that should |
issues that should be |
that should be investigated |
mobile applications with spatial |
applications with spatial locality |
placement given a set |
given a set of |
a set of services |
our experiments demonstrate t |
how to place the |
to place the clones |
place the clones on |
the clones on physical |
clones on physical nodes |
cache to be effective |
on physical nodes in |
to be effective in |
physical nodes in order |
be effective in realistic |
nodes in order to |
effective in realistic workloads |
in order to satisfy |
in realistic workloads based |
order to satisfy certain |
realistic workloads based on |
to satisfy certain constraints |
workloads based on datasets |
based on datasets from |
on datasets from amazon |
datasets from amazon and |
from amazon and orkut |
using dependency lists of |
dependency lists of size |
group and the early |
and the early demise |
the early demise of |
early demise of mach |
caching placement deciding if |
demise of mach as |
placement deciding if some |
of mach as the |
deciding if some services |
mach as the last |
if some services would |
as the last of |
some services would benefit |
the last of the |
services would benefit if |
last of the research |
would benefit if they |
of the research operating |
benefit if they are |
the research operating systems |
if they are fitted |
they are fitted with |
are fitted with response |
fitted with response caches |
the operating system research |
operating system research world |
system research world was |
research world was at |
and ultimately placing the |
world was at a |
and was also able |
ultimately placing the cache |
was at a crossroads |
was also able to |
placing the cache components |
also able to increase |
the cache components in |
intel based personal computers |
able to increase consistent |
cache components in a |
based personal computers were |
to increase consistent transaction |
components in a smart |
in a smart way |
increase consistent transaction rate |
personal computers were becoming |
consistent transaction rate by |
computers were becoming ubiquitous |
and a myriad of |
location placing multiple service |
a myriad of unix |
placing multiple service clones |
myriad of unix operating |
multiple service clones on |
of unix operating systems |
service clones on the |
unix operating systems was |
clones on the same |
operating systems was available |
on the same physical |
systems was available for |
the same physical node |
was available for this |
same physical node to |
available for this platform |
physical node to exploit |
with only nominal overhead |
node to exploit fast |
only nominal overhead on |
to exploit fast ipc |
nominal overhead on the |
eventually many moved to |
exploit fast ipc communication |
overhead on the database |
many moved to use |
moved to use linux |
fast ipc communication as |
ipc communication as opposed |
our experiments with synthetic |
communication as opposed to |
a popular architectural clone |
as opposed to network |
experiments with synthetic workloads |
popular architectural clone of |
opposed to network messages |
with synthetic workloads showed |
architectural clone of the |
to network messages if |
synthetic workloads showed that |
clone of the traditional |
network messages if the |
workloads showed that t |
of the traditional unix |
messages if the benefits |
if the benefits overweigh |
the benefits overweigh the |
benefits overweigh the cost |
cache s efficacy depends |
at the computer science |
overweigh the cost incurred |
s efficacy depends on |
the computer science department |
the cost incurred by |
efficacy depends on the |
computer science department at |
cost incurred by resource |
depends on the clustering |
science department at cornell |
incurred by resource contention |
on the clustering level |
department at cornell university |
by resource contention on |
the clustering level of |
at cornell university we |
resource contention on the |
clustering level of the |
cornell university we made |
contention on the shared |
level of the workload |
university we made the |
on the shared host |
we made the decision |
made the decision to |
the decision to conduct |
decision to conduct our |
to conduct our research |
conduct our research on |
management tools developing tools |
our research on windows |
research on windows nt |
cache adapts to dynamically |
tools developing tools that |
adapts to dynamically changing |
developing tools that monitor |
to dynamically changing workloads |
by that time we |
tools that monitor service |
dynamically changing workloads where |
that time we had |
that monitor service properties |
changing workloads where clusters |
time we had learned |
monitor service properties such |
workloads where clusters change |
we had learned enough |
service properties such as |
where clusters change over |
had learned enough from |
properties such as response |
clusters change over time |
learned enough from the |
such as response time |
enough from the early |
from the early design |
due to resource limitations |
the early design of |
to resource limitations t |
early design of windows |
design of windows nt |
of windows nt to |
windows nt to realize |
nt to realize that |
cache maintains only a |
to realize that it |
maintains only a short |
realize that it was |
only a short dependency |
that it was a |
a short dependency list |
by restarting new clones |
it was a major |
was a major step |
a major step forward |
major step forward in |
which is naturally imperfect |
step forward in operating |
is naturally imperfect and |
forward in operating system |
naturally imperfect and does |
in operating system design |
using vmm tricks virtual |
imperfect and does not |
vmm tricks virtual machines |
and does not include |
tricks virtual machines can |
does not include all |
it would provide us |
virtual machines can be |
not include all dependencies |
would provide us with |
machines can be used |
provide us with a |
can be used to |
us with a platform |
be used to migrate |
with a platform on |
we proved that when |
a platform on which |
used to migrate transparently |
platform on which we |
proved that when resources |
on which we could |
to migrate transparently a |
which we could perform |
that when resources are |
we could perform research |
migrate transparently a collection |
could perform research more |
when resources are unbounded |
perform research more effectively |
transparently a collection of |
research more effectively and |
a collection of services |
more effectively and it |
collection of services on |
effectively and it would |
of services on a |
and it would allows |
cache s algorithm implements |
it would allows us |
services on a different |
s algorithm implements cache |
would allows us to |
on a different physical |
allows us to focus |
a different physical processor |
us to focus on |
to focus on the |
focus on the future |
on the future directions |
or provide isolation guarantees |
the future directions without |
provide isolation guarantees between |
future directions without having |
isolation guarantees between co |
directions without having to |
without having to worry |
having to worry whether |
to worry whether the |
worry whether the operating |
whether the operating system |
the operating system was |
operating system was capable |
system was capable of |
was capable of supporting |
capable of supporting innovation |
by now our complete |
now our complete educational |
the ssa can be |
our complete educational operation |
ssa can be seen |
complete educational operation and |
can be seen as |
educational operation and the |
be seen as a |
operation and the majority |
seen as a platform |
and the majority of |
as a platform that |
the majority of our |
a platform that leverages |
majority of our research |
platform that leverages tradeoffs |
of our research projects |
that leverages tradeoffs between |
our research projects have |
leverages tradeoffs between weaker |
research projects have switched |
tradeoffs between weaker consistency |
projects have switched to |
have switched to using |
switched to using windows |
to using windows nt |
with a compensating gossip |
a compensating gossip repair |
compensating gossip repair mechanism |
for higher availability and |
higher availability and simplicity |
this is an old |
is an old idea |
an old idea first |
old idea first explored |
idea first explored in |
first explored in the |
explored in the grapevine |
as it now officially |
it now officially has |
now officially has been |
officially has been christened |
and later in systems |
later in systems like |
in systems like bayou |
the ride has been |
ride has been rocky |
has been rocky and |
been rocky and fascinating |
which offer a broad |
offer a broad operational |
a broad operational spectrum |
broad operational spectrum between |
operational spectrum between strong |
in this article i |
this article i want |
acid in the distributed |
article i want to |
in the distributed database |
i want to share |
the distributed database cases |
want to share some |
to share some of |
share some of the |
some of the reasoning |
of the reasoning behind |
the reasoning behind our |
reasoning behind our choice |
several database and distributed |
behind our choice for |
database and distributed systems |
our choice for windows |
and distributed systems take |
choice for windows nt |
distributed systems take advantage |
for windows nt and |
systems take advantage of |
windows nt and to |
take advantage of the |
nt and to share |
advantage of the same |
and to share some |
of the same tradeoff |
to share some our |
share some our experiences |
some our experiences with |
our experiences with windows |
experiences with windows nt |
with windows nt as |
for example allowing multiple |
windows nt as a |
nt as a research |
as a research platform |
example allowing multiple updates |
allowing multiple updates to |
multiple updates to occur |
updates to occur simultaneously |
os research as religion |
to occur simultaneously at |
research as religion the |
occur simultaneously at distinct |
as religion the biggest |
simultaneously at distinct replicas |
religion the biggest hurdle |
at distinct replicas by |
the biggest hurdle in |
distinct replicas by specifying |
biggest hurdle in starting |
replicas by specifying a |
hurdle in starting research |
by specifying a maximum |
in starting research on |
specifying a maximum accepted |
starting research on windows |
a maximum accepted deviation |
research on windows nt |
maximum accepted deviation from |
on windows nt was |
accepted deviation from strong |
windows nt was not |
deviation from strong consistency |
nt was not technical |
it was to overcome |
was to overcome the |
to overcome the skepticism |
overcome the skepticism of |
the skepticism of our |
skepticism of our colleagues |
of our colleagues who |
our colleagues who were |
colleagues who were convinced |
who were convinced that |
were convinced that it |
convinced that it would |
that it would not |
it would not be |
would not be possible |
not be possible to |
be possible to use |
possible to use windows |
to use windows nt |
use windows nt as |
windows nt as a |
nt as a good |
as a good platform |
a good platform for |
good platform for research |
the predictions were fascinating |
we would turn into |
would turn into a |
turn into a bug |
tolerating a bounded number |
a bounded number of |
bounded number of consistency |
number of consistency violations |
of consistency violations to |
consistency violations to increase |
violations to increase concurrency |
to increase concurrency of |
increase concurrency of transactions |
microsoft would sue the |
would sue the department |
sue the department for |
the department for every |
department for every technical |
for every technical publication |
microsoft would hide the |
would hide the pieces |
hide the pieces of |
the pieces of buggy |
pieces of buggy code |
or replication according to |
replication according to the |
according to the need |
of buggy code from |
buggy code from us |
code from us or |
from us or bill |
us or bill gates |
or bill gates would |
bill gates would personally |
gates would personally tell |
would personally tell us |
personally tell us where |
tell us where and |
us where and how |
where and how we |
and how we should |
how we should do |
we should do our |
should do our research |
our work on the |
work on the ssa |
on the ssa is |
the ssa is the |
ssa is the first |
is the first to |
the first to apply |
first to apply such |
to apply such thinking |
apply such thinking to |
such thinking to a |
thinking to a cluster |
to a cluster computing |
a cluster computing environment |
the operating systems research |
operating systems research community |
systems research community has |
research community has not |
community has not remained |
has not remained untouched |
not remained untouched by |
remained untouched by the |
untouched by the market |
by the market place |
the market place rivalry |
market place rivalry between |
place rivalry between microsoft |
rivalry between microsoft and |
between microsoft and the |
microsoft and the group |
platform was designed to |
and the group lead |
was designed to provide |
the group lead by |
designed to provide a |
group lead by sun |
to provide a cluster |
lead by sun microsystems |
provide a cluster based |
a cluster based environment |
cluster based environment for |
based environment for scalable |
environment for scalable internet |
it is even more |
for scalable internet services |
is even more unfortunate |
scalable internet services of |
even more unfortunate that |
internet services of the |
more unfortunate that the |
services of the sort |
unfortunate that the positions |
of the sort used |
that the positions taken |
the sort used in |
the positions taken are |
sort used in web |
used in web servers |
positions taken are not |
taken are not based |
are not based on |
not based on intellectual |
based on intellectual deliberation |
caching proxies and transformation |
on intellectual deliberation but |
proxies and transformation proxies |
intellectual deliberation but purely |
deliberation but purely on |
but purely on emotional |
purely on emotional grounds |
service components are controlled |
components are controlled by |
many see microsoft operating |
are controlled by a |
see microsoft operating systems |
controlled by a front |
microsoft operating systems as |
by a front end |
operating systems as the |
a front end machine |
systems as the evil |
front end machine that |
as the evil empire |
end machine that acts |
machine that acts as |
that acts as a |
acts as a request |
as a request dispatcher |
out to squash every |
a request dispatcher and |
to squash every attempt |
request dispatcher and incorporates |
squash every attempt at |
every attempt at innovation |
dispatcher and incorporates the |
and incorporates the load |
incorporates the load balancing |
the load balancing and |
load balancing and restart |
balancing and restart logics |
and working with them |
working with them is |
with them is seen |
them is seen as |
is seen as collaboration |
seen as collaboration with |
as collaboration with the |
collaboration with the enemy |
with the enemy of |
the enemy of free |
enemy of free academic |
of free academic speech |
end processes are detected |
processes are detected to |
are detected to have |
detected to have failed |
the pros and cons |
pros and cons are |
and cons are often |
cons are often discussed |
new processes are forked |
are often discussed with |
processes are forked to |
often discussed with a |
are forked to take |
discussed with a righteous |
forked to take over |
with a righteous zeal |
to take over the |
a righteous zeal that |
righteous zeal that is |
zeal that is frightening |
take over the load |
our own experiences with |
tacc workers can be |
own experiences with microsoft |
workers can be composed |
experiences with microsoft can |
can be composed to |
with microsoft can only |
be composed to address |
microsoft can only be |
composed to address more |
can only be described |
to address more complex |
only be described as |
address more complex tasks |
be described as extremely |
described as extremely positive |
tacc stands for transformation |
never before have we |
before have we had |
have we had such |
we had such a |
had such a positive |
such a positive relation |
a positive relation with |
positive relation with a |
relation with a vendor |
without any pressure from |
any pressure from their |
pressure from their side |
google s globally distributed |
s globally distributed database |
ssa can be seen |
can be seen as |
be seen as revisiting |
we can only conclude |
acm transactions on computer |
can only conclude that |
seen as revisiting these |
only conclude that the |
transactions on computer systems |
conclude that the reasons |
as revisiting these architectural |
that the reasons for |
revisiting these architectural ideas |
the reasons for the |
these architectural ideas in |
reasons for the controversy |
architectural ideas in conjunction |
for the controversy must |
ideas in conjunction with |
the controversy must be |
in conjunction with chain |
controversy must be found |
conjunction with chain replication |
must be found in |
be found in a |
found in a sort |
in a sort of |
a sort of traditional |
sort of traditional emotional |
of traditional emotional bonding |
traditional emotional bonding of |
emotional bonding of academia |
bonding of academia with |
of academia with the |
academia with the underdog |
with the underdog and |
the underdog and that |
underdog and that no |
and that no real |
have long supported clustered |
that no real experiences |
no real experiences drive |
long supported clustered architectures |
real experiences drive the |
experiences drive the discussion |
and were the first |
were the first systems |
the first systems to |
gaining knowledge the foremost |
first systems to exploit |
knowledge the foremost reasons |
systems to exploit the |
the foremost reasons why |
to exploit the style |
foremost reasons why unix |
exploit the style of |
reasons why unix was |
the style of partitioning |
why unix was such |
style of partitioning that |
unix was such a |
of partitioning that leads |
was such a powerhouse |
partitioning that leads to |
such a powerhouse in |
that leads to a |
a powerhouse in operating |
leads to a raps |
powerhouse in operating system |
to a raps of |
in operating system research |
a raps of racs |
operating system research was |
raps of racs solution |
system research was the |
research was the great |
was the great amount |
the great amount of |
great amount of knowledge |
amount of knowledge accumulated |
of knowledge accumulated over |
knowledge accumulated over the |
accumulated over the years |
over the years about |
the years about the |
years about the internal |
about the internal operation |
most database systems adhere |
the internal operation of |
database systems adhere closely |
internal operation of the |
systems adhere closely to |
operation of the operating |
adhere closely to the |
of the operating system |
closely to the acid |
to the acid model |
many of us had |
at potentially high cost |
of us had become |
potentially high cost in |
us had become gurus |
high cost in terms |
had become gurus about |
cost in terms of |
become gurus about some |
in terms of reduced |
gurus about some part |
terms of reduced availability |
about some part of |
of reduced availability during |
some part of the |
reduced availability during faults |
part of the os |
of the os kernel |
the os kernel and |
os kernel and could |
kernel and could recite |
and could recite the |
could recite the fields |
recite the fields of |
the fields of an |
fields of an i |
discuss this problem in |
node structure at late |
structure at late night |
at late night meetings |
late night meetings or |
night meetings or discuss |
meetings or discuss which |
or discuss which data |
discuss which data structures |
which data structures to |
data structures to modify |
structures to modify to |
to modify to add |
modify to add a |
to add a new |
add a new protocol |
ultimately arguing for precisely |
a new protocol at |
arguing for precisely the |
new protocol at runtime |
for precisely the weak |
protocol at runtime over |
precisely the weak update |
at runtime over an |
the weak update model |
runtime over an early |
weak update model that |
over an early morning |
update model that we |
an early morning cappuccino |
model that we adopted |
that we adopted here |
distributed data structures over |
data structures over a |
many of us were |
application servers like the |
of us were and |
servers like the j |
us were and still |
structures over a shared |
were and still are |
over a shared log |
and still are afraid |
still are afraid to |
are afraid to leave |
in proceedings of the |
afraid to leave this |
to leave this bastion |
leave this bastion of |
this bastion of safety |
bastion of safety behind |
of safety behind and |
th acm symposium on |
safety behind and trade |
acm symposium on operating |
offer persistent state support |
behind and trade it |
symposium on operating systems |
persistent state support by |
and trade it in |
on operating systems principles |
state support by wrapping |
trade it in for |
support by wrapping soft |
it in for working |
by wrapping soft state |
in for working on |
wrapping soft state business |
for working on an |
soft state business logic |
working on an operating |
state business logic components |
on an operating system |
business logic components on |
an operating system that |
logic components on top |
operating system that at |
components on top of |
system that at first |
on top of a |
that at first sight |
top of a relational |
at first sight had |
of a relational or |
first sight had nothing |
a relational or object |
sight had nothing in |
had nothing in common |
nothing in common with |
in common with our |
common with our beloved |
with our beloved unix |
they also target large |
and our annotated version |
our annotated version of |
annotated version of the |
version of the unix |
of the unix version |
scale highly available services |
and hence we believe |
hence we believe they |
we believe they could |
believe they could benefit |
they could benefit from |
could benefit from ssa |
in a similar vein |
wouldn t be of |
t be of much |
be of much help |
of much help any |
much help any more |
help any more either |
any more either it |
more either it took |
either it took more |
framework makes it easy |
it took more then |
makes it easy to |
took more then a |
it easy to create |
more then a year |
easy to create robust |
to create robust scalable |
then a year of |
create robust scalable services |
a year of immersion |
year of immersion in |
of immersion in the |
immersion in the technology |
in the technology to |
ninja is arguably more |
ordering transactions with prediction |
the technology to get |
is arguably more flexible |
transactions with prediction in |
technology to get a |
arguably more flexible than |
with prediction in distributed |
to get a level |
more flexible than application |
prediction in distributed object |
get a level where |
flexible than application servers |
in distributed object stores |
a level where i |
than application servers in |
level where i felt |
application servers in that |
where i felt confident |
servers in that it |
i felt confident again |
in that it performs |
felt confident again to |
that it performs connection |
confident again to direct |
it performs connection management |
again to direct others |
th workshop on large |
performs connection management and |
to direct others in |
connection management and automatically |
direct others in our |
scale distributed systems and |
management and automatically partitions |
others in our research |
distributed systems and middleware |
and automatically partitions and |
in our research group |
automatically partitions and replicates |
partitions and replicates persistent |
and replicates persistent state |
together with the overall |
with the overall organizational |
but the framework takes |
the overall organizational issues |
the framework takes a |
overall organizational issues i |
framework takes a different |
organizational issues i think |
takes a different tiered |
issues i think we |
a different tiered approach |
i think we lost |
different tiered approach to |
think we lost one |
tiered approach to services |
we lost one and |
approach to services based |
lost one and a |
to services based on |
one and a half |
services based on bases |
and a half year |
a half year worth |
half year worth of |
year worth of research |
worth of research time |
active proxies and units |
of research time to |
research time to make |
time to make the |
to make the switch |
make the switch in |
and represents shared state |
the switch in the |
represents shared state by |
switch in the most |
shared state by means |
in the most fundamental |
state by means of |
the most fundamental way |
by means of distributed |
means of distributed data |
of distributed data structures |
others are making the |
are making the switch |
making the switch more |
the switch more gradually |
switch more gradually and |
more gradually and are |
gradually and are experiencing |
conclusion our paper presents |
and are experiencing a |
our paper presents the |
are experiencing a more |
paper presents the scalable |
experiencing a more smooth |
presents the scalable services |
a more smooth transition |
the scalable services architecture |
key transactions for key |
all operation systems are |
a new platform for |
operation systems are created |
new platform for porting |
systems are created equal |
platform for porting a |
are created equal our |
for porting a large |
created equal our experiences |
porting a large class |
equal our experiences with |
a large class of |
our experiences with switching |
large class of service |
experiences with switching to |
with switching to windows |
switching to windows nt |
to windows nt have |
oriented applications onto clusters |
windows nt have made |
nt have made us |
have made us somewhat |
made us somewhat more |
us somewhat more philosophical |
the ssa was designed |
somewhat more philosophical about |
ssa was designed to |
more philosophical about the |
was designed to be |
philosophical about the nature |
designed to be as |
about the nature of |
to be as simple |
the nature of operation |
be as simple as |
nature of operation systems |
as simple as possible |
the most fundamental observation |
and at the core |
most fundamental observation is |
at the core uses |
fundamental observation is that |
the core uses just |
core uses just two |
uses just two primitive |
just two primitive mechanisms |
when stripped to their |
stripped to their core |
tcp chains that support |
chains that support a |
that support a variant |
support a variant of |
all operating systems are |
a variant of chain |
operating systems are equal |
variant of chain replication |
the functionality of the |
and gossip epidemics which |
functionality of the windows |
gossip epidemics which are |
of the windows nt |
epidemics which are used |
the windows nt kernel |
which are used to |
windows nt kernel is |
are used to manage |
nt kernel is just |
used to manage configuration |
kernel is just as |
to manage configuration data |
is just as all |
manage configuration data and |
just as all other |
configuration data and initiate |
as all other kernels |
data and initiate repair |
and initiate repair after |
initiate repair after failures |
it abstracts the hardware |
abstracts the hardware in |
the hardware in the |
with appropriate parameter settings |
hardware in the usual |
in the usual sense |
given a gossip rate |
a gossip rate that |
process and threads hide |
gossip rate that is |
and threads hide the |
rate that is sufficiently |
threads hide the cpu |
that is sufficiently fast |
hide the cpu complexity |
is sufficiently fast relative |
sufficiently fast relative to |
fast relative to the |
relative to the update |
to the update rates |
the update rates seen |
update rates seen in |
rates seen in the |
seen in the cluster |
file systems and files |
systems and files hide |
and files hide the |
files hide the storage |
hide the storage devices |
protocols hide the network |
we find that the |
find that the ssa |
that the ssa can |
shared memory and messages |
the ssa can rapidly |
memory and messages are |
ssa can rapidly and |
and messages are used |
can rapidly and automatically |
messages are used to |
rapidly and automatically reconfigure |
are used to allow |
and automatically reconfigure itself |
used to allow sharing |
automatically reconfigure itself after |
to allow sharing of |
reconfigure itself after a |
allow sharing of resources |
itself after a failure |
after a failure and |
a failure and can |
failure and can rapidly |
what we often call |
and can rapidly repair |
we often call operating |
can rapidly repair data |
often call operating systems |
rapidly repair data inconsistencies |
call operating systems has |
repair data inconsistencies that |
operating systems has nothing |
data inconsistencies that arise |
systems has nothing to |
inconsistencies that arise during |
has nothing to do |
that arise during the |
nothing to do with |
arise during the period |
to do with the |
during the period when |
do with the real |
with the real core |
the period when the |
the real core of |
real core of the |
core of the system |
period when the cluster |
when the cluster configuration |
the cluster configuration was |
cluster configuration was still |
configuration was still disrupted |
facebook s distributed data |
unix for most of |
s distributed data store |
for most of us |
distributed data store for |
most of us is |
our goal is to |
data store for the |
of us is a |
goal is to make |
store for the social |
us is a collection |
is to make the |
for the social graph |
is a collection of |
to make the software |
a collection of shell |
make the software available |
in usenix annual technical |
collection of shell commands |
the software available to |
usenix annual technical conference |
of shell commands and |
software available to a |
shell commands and development |
available to a general |
commands and development libraries |
to a general user |
a general user community |
general user community in |
david korn s uwin |
and softway s interix |
acknowledgments the authors are |
the authors are grateful |
authors are grateful to |
are grateful to the |
grateful to the research |
to the research team |
the research team at |
research team at afrl |
team at afrl in |
at afrl in rome |
both show that you |
show that you can |
that you can give |
you can give users |
can give users and |
give users and developers |
users and developers a |
for their help in |
their help in understanding |
help in understanding the |
in understanding the challenges |
understanding the challenges of |
the challenges of using |
challenges of using service |
of using service oriented |
using service oriented architectures |
service oriented architectures in |
oriented architectures in large |
architectures in large scale |
in large scale settings |
unix experience including x |
and to the researchers |
to the researchers at |
the researchers at amazon |
while running on an |
running on an windows |
on an windows nt |
an windows nt kernel |
for helping us understand |
helping us understand the |
us understand the architectures |
understand the architectures employed |
windows nt for most |
the architectures employed in |
nt for most of |
architectures employed in very |
for most of us |
employed in very large |
most of us is |
in very large data |
of us is the |
very large data centers |
us is the windows |
is the windows explorer |
the windows explorer and |
windows explorer and point |
and according to microsoft |
according to microsoft it |
to microsoft it includes |
microsoft it includes a |
it includes a web |
includes a web browser |
although i have not |
i have not seen |
have not seen a |
not seen a complete |
seen a complete re |
implementation of the explorer |
of the explorer for |
the explorer for unix |
compatible libraries from mainsoft |
scaling memcache at facebook |
used in the port |
in the port of |
the port of internet |
port of internet explorer |
of internet explorer show |
internet explorer show that |
an exercise in distributed |
explorer show that you |
exercise in distributed computing |
show that you do |
that you do not |
th usenix symposium on |
you do not need |
communications of the acm |
usenix symposium on networked |
do not need a |
symposium on networked systems |
not need a windows |
on networked systems design |
need a windows nt |
networked systems design and |
a windows nt kernel |
systems design and implementation |
windows nt kernel to |
nt kernel to get |
kernel to get to |
to get to the |
get to the same |
to the same user |
the same user experience |
many see the rich |
see the rich win |
programming interface as the |
interface as the native |
as the native programming |
the native programming model |
native programming model for |
programming model for windows |
model for windows nt |
and although most windows |
although most windows applications |
most windows applications are |
windows applications are designed |
applications are designed using |
are designed using this |
designed using this interface |
it is not the |
is not the windows |
not the windows nt |
the windows nt kernel |
windows nt kernel interface |
almost no applications are |
no applications are built |
applications are built using |
are built using the |
built using the kernel |
using the kernel interface |
and you would have |
you would have a |
would have a hard |
have a hard time |
a hard time finding |
hard time finding the |
time finding the complete |
finding the complete documentation |
the complete documentation for |
complete documentation for all |
documentation for all the |
for all the system |
all the system calls |
describing windows nt as |
windows nt as a |
nt as a micro |
as the kernel is |
the kernel is certainly |
kernel is certainly not |
is certainly not small |
but it is does |
it is does describe |
is does describe the |
does describe the abstraction |
describe the abstraction correctly |
the abstraction correctly in |
abstraction correctly in which |
correctly in which the |
in which the kernel |
which the kernel provides |
the kernel provides base |
kernel provides base services |
provides base services and |
base services and the |
services and the specific |
and the specific application |
the specific application context |
specific application context is |
application context is provided |
context is provided through |
is provided through subsystem |
an architecture to support |
provided through subsystem servers |
architecture to support scalable |
through subsystem servers or |
to support scalable online |
subsystem servers or personalities |
support scalable online personalization |
scalable online personalization in |
online personalization in the |
personalization in the web |
the international journal on |
international journal on very |
journal on very large |
on very large data |
very large data bases |
is one of the |
one of the personalities |
of the personalities running |
the personalities running on |
personalities running on top |
running on top of |
on top of windows |
top of windows nt |
and posix are others |
posix are others delivered |
are others delivered by |
others delivered by microsoft |
one can run windows |
can run windows nt |
run windows nt without |
windows nt without these |
nt without these standard |
without these standard personalities |
these standard personalities and |
standard personalities and build |
personalities and build your |
and build your own |
what is an operating |
is an operating system |
this question seems to |
question seems to be |
seems to be on |
to be on the |
be on the mind |
on the mind of |
the mind of many |
mind of many people |
of many people these |
many people these days |
transactional consistency and automatic |
infused by the microsoft |
by the microsoft trial |
consistency and automatic management |
and automatic management in |
automatic management in an |
management in an application |
in an application data |
an application data cache |
academics in general have |
in general have taken |
general have taken a |
have taken a very |
taken a very narrow |
a very narrow view |
very narrow view of |
narrow view of what |
view of what an |
of what an operating |
what an operating system |
th usenix symposium on |
an operating system is |
usenix symposium on operating |
symposium on operating systems |
on operating systems design |
operating systems design and |
systems design and implementation |
david faber at microsoft |
faber at microsoft trial |
at microsoft trial defined |
microsoft trial defined an |
trial defined an operating |
defined an operating system |
an operating system as |
operating system as the |
system as the software |
as the software that |
the software that controls |
software that controls the |
that controls the execution |
controls the execution of |
the execution of programs |
execution of programs on |
of programs on computer |
programs on computer systems |
on computer systems and |
computer systems and may |
systems and may provide |
and may provide low |
level services such as |
services such as resource |
such as resource allocation |
output control in a |
control in a form |
in a form which |
a form which is |
form which is sufficiently |
which is sufficiently simple |
is sufficiently simple and |
sufficiently simple and general |
simple and general so |
and general so that |
general so that these |
so that these services |
that these services are |
these services are broadly |
services are broadly useful |
are broadly useful to |
broadly useful to software |
useful to software developers |
epidemic algorithms for replicated |
algorithms for replicated database |
for replicated database maintenance |
in research community this |
research community this strict |
community this strict distinction |
this strict distinction serves |
in proceedings of the |
strict distinction serves to |
proceedings of the sixth |
distinction serves to distinguish |
of the sixth annual |
serves to distinguish the |
the sixth annual acm |
to distinguish the real |
sixth annual acm symposium |
distinguish the real men |
annual acm symposium on |
the real men from |
acm symposium on principles |
real men from the |
symposium on principles of |
men from the boys |
on principles of distributed |
principles of distributed computing |
researchers and hackers that |
and hackers that work |
hackers that work in |
that work in the |
work in the area |
in the area defined |
the area defined by |
area defined by this |
defined by this narrow |
by this narrow definition |
this narrow definition of |
narrow definition of operating |
definition of operating systems |
fast iterative graph computation |
iterative graph computation with |
graph computation with block |
computation with block updates |
consider themselves part of |
themselves part of the |
part of the select |
of the select circle |
the select circle of |
select circle of people |
of the vldb endowment |
circle of people working |
of people working on |
people working on the |
working on the core |
on the core of |
the core of the |
core of the systems |
of the systems area |
the systems area of |
systems area of computer |
area of computer science |
once you are in |
you are in this |
are in this circle |
in this circle you |
this circle you will |
circle you will become |
you will become part |
will become part of |
become part of the |
part of the secret |
of the secret society |
the secret society that |
secret society that practices |
society that practices the |
that practices the black |
practices the black art |
the black art of |
black art of os |
art of os research |
of os research and |
os research and will |
research and will start |
and will start to |
will start to regard |
start to regard any |
to regard any other |
regard any other activity |
any other activity of |
other activity of systems |
activity of systems development |
of systems development as |
systems development as irrelevant |
development as irrelevant to |
as irrelevant to the |
irrelevant to the future |
to the future of |
the future of computer |
future of computer science |
for a long time |
a long time the |
long time the line |
time the line was |
the line was drawn |
line was drawn at |
was drawn at the |
drawn at the kernel |
and one could only |
one could only consider |
could only consider himself |
only consider himself a |
support for data sharing |
consider himself a true |
for data sharing among |
himself a true os |
data sharing among mobile |
a true os researcher |
sharing among mobile users |
true os researcher after |
os researcher after having |
researcher after having developed |
concurrency control and recovery |
after having developed at |
in ieee workshop on |
control and recovery in |
having developed at least |
ieee workshop on mobile |
workshop on mobile computing |
developed at least two |
and recovery in database |
on mobile computing systems |
at least two device |
recovery in database systems |
least two device drivers |
two device drivers and |
device drivers and hacked |
drivers and hacked on |
and hacked on the |
hacked on the terminal |
on the terminal driver |
the terminal driver of |
terminal driver of the |
driver of the bsd |
in modern operating systems |
modern operating systems such |
operating systems such as |
systems such as windows |
such as windows nt |
the notion of where |
notion of where exactly |
of where exactly operating |
where exactly operating systems |
exactly operating systems services |
operating systems services are |
systems services are located |
services are located is |
are located is not |
located is not that |
is not that simple |
not that simple any |
that simple any more |
fundamental services are split |
services are split between |
are split between kernel |
split between kernel and |
between kernel and user |
kernel and user space |
and user space in |
user space in attempts |
space in attempts to |
in attempts to optimise |
attempts to optimise their |
to optimise their efficiency |
optimise their efficiency and |
their efficiency and avoid |
efficiency and avoid uncontrolled |
and avoid uncontrolled growth |
avoid uncontrolled growth of |
uncontrolled growth of kernel |
growth of kernel services |
the pervasiveness of distributed |
pervasiveness of distributed services |
of distributed services in |
distributed services in modern |
services in modern systems |
in modern systems can |
modern systems can be |
systems can be considered |
can be considered a |
be considered a threat |
considered a threat to |
a threat to the |
threat to the traditional |
the dynamics of viral |
to the traditional notion |
dynamics of viral marketing |
the traditional notion of |
traditional notion of operating |
notion of operating systems |
acm transactions on the |
transactions on the web |
many support services are |
support services are required |
services are required to |
are required to make |
required to make distributed |
to make distributed systems |
make distributed systems work |
distributed systems work efficiently |
systems work efficiently and |
work efficiently and effectively |
efficiently and effectively and |
and effectively and these |
effectively and these services |
such as security and |
as security and directory |
security and directory services |
and directory services or |
directory services or distributed |
services or distributed object |
or distributed object support |
distributed object support and |
object support and cluster |
support and cluster management |
are not part of |
not part of a |
part of a traditional |
of a traditional view |
a traditional view of |
traditional view of operating |
view of operating systems |
but they are essential |
they are essential to |
are essential to the |
essential to the operation |
to the operation of |
the operation of modern |
operation of modern operating |
of modern operating systems |
this results in that |
results in that an |
in that an operating |
that an operating system |
an operating system no |
operating system no longer |
system no longer is |
no longer is a |
longer is a simple |
is a simple division |
a simple division between |
simple division between kernel |
division between kernel and |
between kernel and user |
kernel and user space |
but consist of a |
consist of a myriad |
of a myriad of |
a myriad of services |
of which some are |
which some are kernilized |
some are local and |
are local and others |
local and others are |
and others are remote |
operating systems that address |
systems that address the |
that address the needs |
address the needs of |
the needs of current |
needs of current and |
of current and future |
current and future clients |
and future clients and |
future clients and informatik |
clients and informatik informatique |
measurement and analysis of |
and analysis of online |
analysis of online social |
of online social networks |
in proceedings of the |
based scalable network services |
th acm sigcomm conference |
acm sigcomm conference on |
sigcomm conference on internet |
conference on internet measurement |
operating systems servers no |
systems servers no longer |
servers no longer span |
proceedings of the sixteenth |
no longer span a |
of the sixteenth acm |
longer span a single |
the sixteenth acm symposium |
span a single computer |
sixteenth acm symposium on |
a single computer and |
acm symposium on operating |
single computer and they |
symposium on operating systems |
computer and they abstract |
on operating systems principles |
and they abstract services |
they abstract services away |
abstract services away from |
services away from physical |
away from physical nodes |
from physical nodes allowing |
physical nodes allowing user |
nodes allowing user to |
allowing user to be |
user to be part |
to be part of |
be part of a |
part of a larger |
potential global operating environment |
will the real dinosaur |
the real dinosaur please |
real dinosaur please come |
dinosaur please come forward |
until the spring of |
we were deeply committed |
were deeply committed to |
deeply committed to sunos |
and other bsd derivatives |
sampling from large graphs |
in proceedings of the |
at that moment its |
that moment its vendor |
moment its vendor was |
its vendor was discontinuing |
vendor was discontinuing the |
was discontinuing the operating |
discontinuing the operating system |
th acm sigkdd international |
acm sigkdd international conference |
and had designated solaris |
sigkdd international conference on |
international conference on knowledge |
conference on knowledge discovery |
on knowledge discovery and |
knowledge discovery and data |
which had its root |
discovery and data mining |
had its root in |
its root in at |
t s system v |
s system v as |
system v as the |
v as the successor |
this event forced us |
event forced us to |
forced us to take |
us to take a |
to take a step |
take a step back |
a step back and |
step back and evaluate |
back and evaluate our |
and evaluate our research |
evaluate our research directions |
our research directions and |
research directions and our |
directions and our expectations |
and our expectations with |
our expectations with respect |
expectations with respect to |
with respect to the |
respect to the operating |
to the operating systems |
the operating systems to |
operating systems to use |
if one issue in |
one issue in our |
issue in our discussions |
in our discussions was |
our discussions was dominant |
it was the fact |
was the fact that |
the fact that most |
fact that most of |
that most of the |
most of the operating |
of the operating systems |
the operating systems we |
operating systems we were |
systems we were looking |
we were looking at |
were looking at were |
looking at were actually |
at were actually very |
were actually very old |
actually very old fashioned |
in structure and in |
structure and in implementation |
most of these operating |
of these operating systems |
these operating systems had |
operating systems had their |
systems had their conception |
had their conception in |
their conception in the |
don t settle for |
t settle for eventual |
s and did not |
and did not change |
did not change much |
not change much in |
change much in structure |
much in structure since |
scalable causal consistency for |
in structure since then |
causal consistency for wide |
linux could be seen |
area storage with cops |
could be seen as |
be seen as an |
seen as an exception |
as an exception since |
an exception since it |
exception since it was |
since it was developed |
it was developed in |
was developed in the |
developed in the second |
in the second half |
the second half of |
second half of the |
the ninja architecture for |
rd acm symposium on |
ninja architecture for robust |
acm symposium on operating |
architecture for robust internet |
symposium on operating systems |
on operating systems principles |
scale systems and services |
but its structure mirrored |
its structure mirrored that |
structure mirrored that of |
mirrored that of the |
that of the traditional |
of the traditional unix |
the traditional unix systems |
and as such it |
as such it could |
such it could be |
it could be considered |
could be considered one |
be considered one of |
considered one of them |
the significant advances made |
significant advances made in |
advances made in academic |
made in academic computer |
in academic computer science |
in os research and |
os research and in |
research and in system |
and in system software |
in system software engineering |
have had only minimal |
had only minimal impact |
only minimal impact on |
minimal impact on the |
impact on the design |
on the design and |
the design and implementation |
design and implementation of |
and implementation of commercial |
implementation of commercial operating |
of commercial operating systems |
the design of all |
design of all unix |
of all unix systems |
all unix systems violates |
unix systems violates almost |
systems violates almost all |
violates almost all of |
almost all of the |
all of the software |
of the software engineering |
the software engineering principles |
software engineering principles presented |
engineering principles presented to |
principles presented to first |
presented to first year |
to first year s |
first year s computer |
year s computer science |
s computer science students |
transactional storage for geo |
the design is monolithic |
design is monolithic with |
is monolithic with almost |
monolithic with almost no |
with almost no modular |
almost no modular structure |
and the internal kernel |
the internal kernel interfaces |
internal kernel interfaces are |
kernel interfaces are not |
interfaces are not strictly |
are not strictly enforced |
not strictly enforced which |
strictly enforced which introduces |
enforced which introduces dependencies |
rd acm symposium on |
which introduces dependencies on |
acm symposium on operating |
introduces dependencies on the |
symposium on operating systems |
dependencies on the actual |
on operating systems principles |
on the actual implementation |
the actual implementation of |
actual implementation of data |
implementation of data structures |
making it impossible to |
it impossible to upgrade |
spatial gossip and resource |
impossible to upgrade or |
gossip and resource location |
to upgrade or replace |
and resource location protocols |
upgrade or replace modules |
or replace modules without |
replace modules without also |
modules without also redesigning |
without also redesigning several |
in proceedings of the |
also redesigning several other |
proceedings of the thirty |
redesigning several other modules |
third annual acm symposium |
annual acm symposium on |
for example to replace |
acm symposium on theory |
example to replace the |
symposium on theory of |
to replace the scheduler |
on theory of computing |
replace the scheduler in |
the scheduler in any |
scheduler in any of |
in any of the |
any of the bsd |
of the bsd s |
the bsd s one |
bsd s one needs |
s one needs to |
one needs to spend |
needs to spend two |
to spend two weeks |
spend two weeks searching |
two weeks searching for |
weeks searching for all |
searching for all dependencies |
for all dependencies and |
all dependencies and fixing |
dependencies and fixing other |
and fixing other sources |
at the top of |
the top of our |
top of our long |
of our long wish |
our long wish list |
long wish list for |
wish list for an |
list for an ideal |
for an ideal research |
an ideal research operating |
ideal research operating system |
were three important general |
three important general points |
the design and implementation |
design and implementation of |
and implementation of the |
implementation of the operating |
of the operating system |
the operating system should |
operating system should comply |
replicated systems fast as |
system should comply with |
systems fast as possible |
should comply with modern |
comply with modern software |
with modern software engineering |
modern software engineering principles |
allowing researchers to introduce |
researchers to introduce new |
to introduce new components |
and replace core components |
replace core components without |
th usenix symposium on |
core components without redesigning |
usenix symposium on operating |
components without redesigning the |
symposium on operating systems |
without redesigning the complete |
on operating systems design |
redesigning the complete system |
operating systems design and |
a technique for increasing |
systems design and implementation |
technique for increasing concurrency |
for increasing concurrency in |
increasing concurrency in a |
concurrency in a replicated |
in a replicated system |
acm transactions on database |
transactions on database systems |
the overall structure of |
overall structure of the |
structure of the operating |
of the operating system |
user and kernel space |
and kernel space components |
should be designed towards |
be designed towards the |
designed towards the future |
should be pervasive throughout |
be pervasive throughout the |
pervasive throughout the whole |
throughout the whole system |
the operating system vendor |
operating system vendor should |
system vendor should be |
vendor should be open |
should be open to |
be open to innovation |
our experiences in the |
experiences in the past |
in the past had |
the past had been |
past had been that |
had been that vendors |
been that vendors always |
that vendors always ignored |
vendors always ignored important |
always ignored important research |
ignored important research results |
important research results and |
research results and only |
results and only followed |
and only followed very |
only followed very narrow |
followed very narrow paths |
very narrow paths of |
narrow paths of incremental |
paths of incremental improvements |
windows nt was the |
nt was the only |
was the only operating |
the only operating system |
only operating system that |
operating system that came |
system that came close |
combining acid and base |
that came close to |
acid and base in |
came close to matching |
and base in a |
close to matching most |
base in a distributed |
to matching most of |
in a distributed database |
matching most of our |
most of our requirements |
adaptive distributed data management |
with a handful of |
distributed data management with |
a handful of operating |
data management with weak |
handful of operating systems |
th usenix symposium on |
management with weak consistent |
of operating systems such |
usenix symposium on operating |
with weak consistent replicated |
operating systems such as |
symposium on operating systems |
weak consistent replicated data |
systems such as qnx |
on operating systems design |
such as qnx and |
operating systems design and |
in proceedings of the |
as qnx and utah |
systems design and implementation |
qnx and utah s |
and utah s os |
none of the unix |
of the unix based |
the unix based operating |
unix based operating systems |
acm symposium on applied |
based operating systems came |
symposium on applied computing |
operating systems came close |
systems came close to |
came close to fulfilling |
close to fulfilling our |
to fulfilling our requirements |
as noted before the |
noted before the core |
before the core of |
the core of those |
core of those operating |
of those operating systems |
those operating systems is |
operating systems is based |
systems is based on |
year old designs and |
old designs and these |
designs and these operating |
and these operating systems |
these operating systems still |
operating systems still treat |
systems still treat computers |
still treat computers as |
treat computers as single |
computers as single entities |
as single entities without |
single entities without a |
entities without a coherent |
a shared log design |
shared log design for |
log design for flash |
design for flash clusters |
th usenix symposium on |
usenix symposium on networked |
symposium on networked systems |
on networked systems design |
networked systems design and |
systems design and implementation |
aware adaptable web services |
in proceedings of the |
th international world wide |
feet high windows nt |
international world wide web |
high windows nt looked |
world wide web conference |
windows nt looked like |
wide web conference on |
nt looked like the |
web conference on alternate |
looked like the proverbial |
conference on alternate track |
like the proverbial dinosaur |
on alternate track papers |
alternate track papers and |
track papers and posters |
a closer look revealed |
closer look revealed a |
look revealed a truly |
revealed a truly modern |
a truly modern operating |
truly modern operating system |
object oriented design is |
oriented design is pervasive |
design is pervasive through |
is pervasive through the |
pervasive through the system |
through the system including |
the system including the |
system including the kernel |
there is a complete |
is a complete distributed |
a complete distributed strategy |
complete distributed strategy with |
distributed strategy with at |
strategy with at its |
with at its core |
at its core a |
its core a distributed |
core a distributed object |
a distributed object technology |
distributed object technology and |
object technology and includes |
technology and includes a |
and includes a complete |
includes a complete integration |
a complete integration of |
complete integration of distributed |
integration of distributed services |
of distributed services such |
distributed services such as |
services such as security |
and last no but |
last no but least |
there is a real |
is a real desire |
a real desire by |
real desire by the |
desire by the vendor |
by the vendor to |
the vendor to continuously |
vendor to continuously innovate |
to continuously innovate its |
continuously innovate its operating |
innovate its operating system |
its operating system and |
operating system and the |
system and the overall |
and the overall services |
microsoft doesn t hesitate |
doesn t hesitate to |
t hesitate to incorporate |
hesitate to incorporate academic |
to incorporate academic results |
incorporate academic results into |
academic results into operating |
results into operating system |
and is open for |
is open for new |
open for new directions |
innovation as a life |
as a life style |
a life style microsoft |
life style microsoft is |
style microsoft is not |
microsoft is not conservative |
is not conservative in |
not conservative in its |
conservative in its os |
in its os development |
while most vendors only |
most vendors only consider |
vendors only consider changes |
only consider changes to |
consider changes to their |
changes to their core |
to their core os |
their core os services |
core os services under |
os services under extreme |
services under extreme market |
under extreme market pressure |
the core of windows |
core of windows nt |
of windows nt has |
windows nt has changed |
nt has changed significantly |
has changed significantly over |
changed significantly over the |
significantly over the past |
over the past years |
the past years to |
past years to accommodate |
years to accommodate the |
to accommodate the demands |
accommodate the demands of |
the demands of modern |
demands of modern computing |
especially the upcoming release |
the upcoming release of |
upcoming release of windows |
formerly known as windows |
known as windows nt |
profiles for the situated |
for the situated web |
makes that the microsoft |
that the microsoft takes |
the microsoft takes the |
in proceedings of the |
microsoft takes the operating |
proceedings of the eleventh |
takes the operating system |
of the eleventh international |
the operating system functionality |
the eleventh international conference |
operating system functionality to |
eleventh international conference on |
system functionality to the |
international conference on world |
functionality to the next |
conference on world wide |
on world wide web |
to the next level |
the advances in windows |
are too numerous to |
too numerous to enumerate |
numerous to enumerate here |
they range from a |
range from a file |
from a file system |
a file system cache |
file system cache for |
system cache for disconnected |
cache for disconnected operation |
which was originally developed |
was originally developed at |
originally developed at cmu |
developed at cmu in |
at cmu in the |
cmu in the coda |
in the coda project |
to a remote storage |
a remote storage service |
remote storage service that |
storage service that automatically |
service that automatically moves |
that automatically moves old |
automatically moves old data |
moves old data from |
old data from your |
data from your hard |
from your hard disk |
your hard disk to |
hard disk to remote |
disk to remote servers |
to remote servers if |
remote servers if you |
servers if you are |
if you are running |
you are running out |
are running out of |
running out of disk |
out of disk space |
from tight security integration |
van renesse and f |
as the dominant security |
the dominant security provider |
to a complete integration |
chain replication for supporting |
a complete integration of |
replication for supporting high |
complete integration of network |
for supporting high throughput |
integration of network quality |
supporting high throughput and |
of network quality of |
high throughput and availability |
network quality of services |
quality of services tools |
of services tools including |
services tools including data |
tools including data transmission |
in sixth symposium on |
including data transmission shapers |
sixth symposium on operating |
data transmission shapers and |
symposium on operating systems |
transmission shapers and priority |
on operating systems design |
shapers and priority scheduling |
operating systems design and |
and priority scheduling and |
systems design and implementation |
priority scheduling and queuing |
and from attributed based |
from attributed based distributed |
attributed based distributed component |
based distributed component programming |
distributed component programming to |
component programming to indexing |
programming to indexing support |
to indexing support integrated |
indexing support integrated in |
support integrated in the |
integrated in the file |
in the file system |
we are witnesses of |
are witnesses of a |
witnesses of a unique |
of a unique process |
never before have we |
before have we seen |
have we seen such |
we seen such a |
seen such a radical |
such a radical overhaul |
a radical overhaul of |
radical overhaul of an |
overhaul of an operating |
of an operating system |
an operating system targeted |
operating system targeted for |
system targeted for the |
targeted for the enterprise |
for the enterprise market |
in general this market |
general this market is |
this market is very |
market is very conservative |
is very conservative and |
very conservative and not |
conservative and not interested |
and not interested in |
not interested in taking |
interested in taking risks |
however the problems of |
the problems of scale |
management and distribution are |
achieving serializability with low |
and distribution are asking |
serializability with low latency |
distribution are asking for |
with low latency in |
are asking for radical |
low latency in geodistributed |
asking for radical solutions |
latency in geodistributed storage |
for radical solutions to |
in geodistributed storage systems |
radical solutions to get |
solutions to get to |
to get to a |
get to a computing |
to a computing base |
in proceedings of the |
a computing base that |
computing base that can |
base that can bring |
that can bring us |
can bring us into |
bring us into the |
us into the next |
into the next century |
th acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
one of the markets |
enabling scalable online personalization |
of the markets where |
scalable online personalization on |
the markets where we |
online personalization on the |
markets where we will |
personalization on the web |
where we will see |
we will see the |
will see the main |
see the main competitive |
in proceedings of the |
the main competitive battle |
main competitive battle between |
competitive battle between microsoft |
battle between microsoft and |
between microsoft and others |
nd acm conference on |
microsoft and others will |
acm conference on electronic |
and others will be |
conference on electronic commerce |
others will be that |
will be that of |
be that of the |
that of the e |
web farms with hundreds |
farms with hundreds of |
with hundreds of nodes |
with support services for |
support services for load |
services for load balancing |
distributed and single image |
and single image management |
are really pushing the |
really pushing the envelope |
pushing the envelope of |
the envelope of all |
envelope of all operating |
of all operating systems |
all operating systems that |
operating systems that are |
systems that are currently |
that are currently on |
are currently on the |
currently on the market |
windows nt is still |
nt is still considered |
is still considered to |
still considered to be |
considered to be the |
to be the new |
be the new kid |
acm transactions on database |
transactions on database systems |
the new kid on |
new kid on the |
kid on the block |
on the block in |
the block in the |
block in the internet |
in the internet services |
the internet services world |
but it is clear |
it is clear that |
is clear that the |
clear that the risks |
that the risks that |
the risks that are |
risks that are taken |
that are taken now |
are taken now are |
taken now are the |
now are the right |
are the right moves |
the right moves to |
right moves to prepare |
moves to prepare the |
to prepare the operating |
an architecture for well |
prepare the operating system |
the operating system for |
operating system for operation |
system for operation in |
for operation in these |
operation in these emerging |
in these emerging massive |
these emerging massive computing |
emerging massive computing environments |
in symposium on operating |
the bugs innovation comes |
symposium on operating systems |
bugs innovation comes at |
on operating systems principles |
innovation comes at a |
comes at a price |
one of the costs |
of the costs of |
the costs of introducing |
costs of introducing a |
of introducing a significant |
introducing a significant amount |
a significant amount of |
significant amount of new |
amount of new code |
of new code is |
new code is the |
code is the number |
is the number of |
the number of software |
number of software defects |
of software defects per |
software defects per lines |
defects per lines of |
per lines of codes |
lines of codes increases |
while measurements actually let |
measurements actually let us |
actually let us believe |
let us believe that |
us believe that microsoft |
believe that microsoft products |
that microsoft products are |
microsoft products are quite |
products are quite reliable |
are quite reliable at |
quite reliable at operating |
reliable at operating systems |
thousand lines of code |
fresh code has a |
code has a disastrous |
has a disastrous effect |
a disastrous effect on |
disastrous effect on this |
effect on this number |
the outlook becomes even |
outlook becomes even more |
the costs and limits |
becomes even more worrisome |
costs and limits of |
even more worrisome when |
and limits of availability |
more worrisome when we |
limits of availability for |
worrisome when we realize |
of availability for replicated |
when we realize that |
availability for replicated services |
we realize that microsoft |
realize that microsoft is |
that microsoft is not |
microsoft is not only |
is not only introducing |
not only introducing new |
in proceedings of the |
only introducing new code |
proceedings of the eighteenth |
of the eighteenth acm |
the eighteenth acm symposium |
eighteenth acm symposium on |
acm symposium on operating |
but is also changing |
symposium on operating systems |
on operating systems principles |
is also changing all |
also changing all of |
changing all of its |
all of its old |
of its old code |
an automated process is |
automated process is converting |
process is converting all |
is converting all of |
converting all of the |
all of the windows |
of the windows nt |
the windows nt code |
windows nt code to |
nt code to be |
thousand lines of code |
lines of code per |
of code per day |
code per day and |
per day and is |
day and is believed |
and is believed to |
is believed to catch |
believed to catch all |
to catch all pointer |
catch all pointer arithmetic |
all pointer arithmetic cases |
an important question is |
important question is whether |
question is whether the |
is whether the introduced |
whether the introduced functionality |
the introduced functionality is |
introduced functionality is worth |
functionality is worth the |
is worth the unavoidable |
worth the unavoidable initial |
the unavoidable initial instability |
unavoidable initial instability that |
initial instability that is |
instability that is bound |
that is bound to |
is bound to occur |
whenever taking risks to |
taking risks to achieve |
risks to achieve major |
to achieve major improvements |
shoring up persistent applications |
there is always the |
in proceedings of the |
design and evaluation of |
is always the down |
and evaluation of a |
always the down side |
evaluation of a conitbased |
the down side that |
of a conitbased continuous |
down side that there |
a conitbased continuous consistency |
side that there is |
conitbased continuous consistency model |
that there is some |
continuous consistency model for |
there is some change |
consistency model for replicated |
is some change of |
model for replicated services |
some change of failure |
acm sigmod international conference |
change of failure and |
sigmod international conference on |
acm transactions on computer |
of failure and it |
international conference on management |
transactions on computer systems |
failure and it is |
conference on management of |
and it is likely |
on management of data |
it is likely that |
is likely that we |
likely that we will |
that we will see |
we will see a |
will see a number |
see a number of |
a number of components |
number of components of |
of components of nt |
components of nt coming |
of nt coming under |
nt coming under intense |
coming under intense scrutiny |
under intense scrutiny from |
intense scrutiny from industry |
scrutiny from industry and |
from industry and academia |
such as the directory |
as the directory services |
may become a performance |
become a performance bottleneck |
a performance bottleneck in |
performance bottleneck in the |
bottleneck in the overall |
in the overall distributed |
the overall distributed operation |
or the wide spread |
the wide spread security |
wide spread security integration |
spread security integration could |
security integration could introduce |
integration could introduce a |
could introduce a critical |
introduce a critical dependency |
a critical dependency on |
critical dependency on the |
dependency on the high |
availability of the security |
of the security servers |
from a research point |
a research point of |
research point of view |
these problems do not |
problems do not really |
do not really bother |
not really bother us |
the advantage of performing |
advantage of performing research |
of performing research on |
performing research on a |
research on a system |
which has distribution at |
has distribution at its |
distribution at its core |
at its core greatly |
its core greatly outweighs |
core greatly outweighs the |
greatly outweighs the consequences |
outweighs the consequences of |
the consequences of working |
consequences of working with |
of working with a |
working with a cutting |
with a cutting edge |
a cutting edge operating |
cutting edge operating system |
however i must admit |
i must admit that |
must admit that at |
admit that at more |
that at more then |
at more then one |
more then one occasion |
then one occasion my |
one occasion my students |
occasion my students had |
my students had to |
students had to control |
had to control their |
to control their murderous |
control their murderous intentions |
their murderous intentions towards |
murderous intentions towards the |
intentions towards the iis |
towards the iis or |
the iis or mts |
iis or mts developers |
or mts developers or |
mts developers or were |
developers or were they |
or were they kept |
were they kept their |
they kept their good |
kept their good spirits |
their good spirits by |
good spirits by contemplating |
spirits by contemplating the |
by contemplating the horrible |
contemplating the horrible tortures |
the horrible tortures one |
horrible tortures one could |
tortures one could perform |
one could perform on |
could perform on the |
perform on the person |
on the person that |
the person that had |
person that had designed |
that had designed the |
had designed the com |
designed the com security |
the com security architecture |
windows research there are |
research there are some |
there are some properties |
are some properties of |
some properties of windows |
properties of windows nt |
of windows nt that |
windows nt that make |
nt that make it |
that make it particularly |
make it particularly suitable |
it particularly suitable for |
particularly suitable for research |
suitable for research purposes |
the operating system kernel |
operating system kernel for |
system kernel for example |
kernel for example is |
for example is designed |
example is designed with |
is designed with extensibility |
designed with extensibility in |
with extensibility in mind |
to allow developers of |
allow developers of hardware |
developers of hardware based |
of hardware based services |
new protocols and file |
protocols and file systems |
and file systems to |
file systems to add |
systems to add their |
to add their functionality |
add their functionality to |
their functionality to the |
functionality to the system |
to the system without |
the system without much |
system without much effort |
all kernel code is |
kernel code is developed |
code is developed following |
is developed following a |
developed following a strict |
following a strict object |
a strict object oriented |
strict object oriented paradigm |
object oriented paradigm and |
oriented paradigm and its |
paradigm and its functionality |
and its functionality can |
its functionality can only |
functionality can only be |
can only be accessed |
only be accessed through |
be accessed through interfaces |
efficient optimistic concurrency control |
optimistic concurrency control using |
concurrency control using loosely |
control using loosely synchronized |
using loosely synchronized clocks |
none of its implementation |
of its implementation is |
its implementation is visible |
one of the designs |
of the designs abstractions |
the designs abstractions of |
designs abstractions of the |
abstractions of the windows |
of the windows nt |
the windows nt kernel |
windows nt kernel i |
nt kernel i find |
kernel i find it |
i find it particularly |
find it particularly fascinating |
it particularly fascinating to |
particularly fascinating to work |
fascinating to work with |
to work with is |
work with is the |
with is the device |
is the device object |
a device object in |
device object in an |
object in an instance |
in an instance created |
an instance created by |
instance created by driver |
created by driver objects |
which encapsulates a unit |
encapsulates a unit of |
a unit of kernel |
unit of kernel based |
of kernel based software |
whether this is a |
this is a device |
is a device driver |
a network protocol or |
network protocol or a |
protocol or a file |
or a file system |
a file system filter |
these objects have the |
objects have the interesting |
have the interesting property |
the interesting property that |
interesting property that they |
property that they can |
that they can be |
they can be attached |
can be attached to |
be attached to other |
attached to other device |
to other device objects |
and as such can |
as such can intercept |
such can intercept and |
can intercept and manipulate |
intercept and manipulate all |
and manipulate all requests |
manipulate all requests flowing |
all requests flowing to |
requests flowing to and |
flowing to and from |
to and from the |
and from the original |
from the original device |
the original device object |
this way it is |
way it is relatively |
it is relatively simple |
is relatively simple to |
relatively simple to add |
simple to add for |
a scalable system for |
to add for example |
scalable system for consistently |
add for example a |
system for consistently caching |
for example a file |
for consistently caching dynamic |
example a file system |
consistently caching dynamic web |
a file system object |
caching dynamic web data |
file system object that |
system object that compresses |
object that compresses or |
that compresses or encrypts |
compresses or encrypts data |
or encrypts data before |
encrypts data before the |
data before the data |
before the data reaches |
the data reaches the |
data reaches the under |
reaches the under laying |
the under laying file |
under laying file system |
to redirect disk requests |
redirect disk requests to |
disk requests to a |
requests to a replication |
to a replication volume |
or to trace device |
to trace device object |
trace device object interaction |
device object interaction during |
object interaction during development |
interaction during development phases |
the strict object oriented |
strict object oriented approach |
object oriented approach is |
oriented approach is very |
approach is very well |
is very well done |
very well done from |
well done from a |
done from a design |
from a design point |
a design point of |
design point of view |
style hacker s heart |
hacker s heart starts |
s heart starts bleeding |
heart starts bleeding when |
starts bleeding when he |
bleeding when he or |
when he or she |
he or she realizes |
or she realizes that |
she realizes that he |
realizes that he can |
that he can no |
he can no longer |
can no longer do |
no longer do a |
longer do a quick |
a scalable web cache |
do a quick fix |
scalable web cache consistency |
web cache consistency architecture |
inspect a few data |
sigcomm computer communications review |
a few data structures |
few data structures and |
data structures and secretly |
structures and secretly swivel |
and secretly swivel some |
secretly swivel some pointers |
swivel some pointers to |
some pointers to make |
pointers to make things |
to make things work |
make things work better |
things work better or |
work better or make |
better or make more |
or make more informed |
make more informed decisions |
the internal kernel interfaces |
internal kernel interfaces are |
kernel interfaces are elaborate |
but it appears there |
it appears there are |
appears there are always |
there are always some |
are always some things |
always some things one |
some things one cannot |
things one cannot do |
one cannot do as |
cannot do as efficient |
do as efficient as |
as efficient as possible |
in four years of |
four years of nt |
years of nt kernel |
of nt kernel hacking |
nt kernel hacking only |
kernel hacking only on |
hacking only on one |
only on one occasion |
on one occasion we |
one occasion we needed |
occasion we needed to |
we needed to break |
needed to break through |
to break through the |
break through the standard |
through the standard kernel |
the standard kernel interface |
we wanted to add |
wanted to add a |
to add a fast |
add a fast trap |
a fast trap into |
fast trap into the |
trap into the kernel |
into the kernel for |
the kernel for fast |
kernel for fast user |
and the pages which |
the pages which hold |
pages which hold the |
which hold the trap |
hold the trap dispatch |
the trap dispatch tables |
trap dispatch tables were |
dispatch tables were protected |
tables were protected after |
were protected after the |
protected after the system |
after the system boot |
another example of what |
example of what makes |
based cache management for |
of what makes windows |
cache management for dynamic |
what makes windows nt |
management for dynamic web |
makes windows nt particular |
for dynamic web content |
windows nt particular suitable |
nt particular suitable for |
particular suitable for research |
suitable for research is |
for research is the |
research is the fundamental |
is the fundamental manner |
the fundamental manner in |
fundamental manner in which |
manner in which advanced |
in which advanced distributed |
which advanced distributed services |
advanced distributed services are |
distributed services are integrated |
services are integrated into |
are integrated into windows |
integrated into windows nt |
it allows us to |
allows us to rely |
us to rely on |
to rely on ubiquitous |
rely on ubiquitous support |
on ubiquitous support services |
ubiquitous support services and |
support services and concentrate |
services and concentrate on |
and concentrate on advancing |
concentrate on advancing the |
on advancing the state |
advancing the state of |
the state of the |
state of the art |
of the art where |
the art where it |
art where it is |
where it is really |
it is really needed |
windows nt security provides |
nt security provides a |
security provides a complete |
provides a complete set |
a complete set of |
complete set of services |
set of services integrated |
alternative architectures and protocols |
of services integrated into |
architectures and protocols for |
services integrated into all |
and protocols for providing |
integrated into all sections |
protocols for providing strong |
into all sections of |
for providing strong consistency |
all sections of the |
providing strong consistency in |
sections of the operating |
of the operating system |
strong consistency in dynamic |
consistency in dynamic web |
in dynamic web applications |
researchers who are developing |
who are developing an |
are developing an advanced |
world wide web journal |
developing an advanced multi |
node replicated transaction server |
replicated transaction server can |
transaction server can use |
server can use off |
and encryption mechanisms into |
encryption mechanisms into their |
mechanisms into their system |
into their system without |
their system without much |
system without much pain |
the use of the |
use of the com |
of the com object |
the com object model |
com object model in |
object model in all |
model in all the |
in all the windows |
all the windows nt |
the windows nt services |
windows nt services allows |
nt services allows research |
services allows research projects |
allows research projects to |
research projects to import |
projects to import these |
to import these services |
import these services in |
these services in a |
services in a very |
in a very simple |
a very simple manner |
live network streaming with |
network streaming with utilities |
streaming with utilities and |
with utilities and cost |
the existence of com |
utilities and cost ymir |
existence of com makes |
and cost ymir vigfusson |
of com makes it |
com makes it trivial |
makes it trivial for |
it trivial for research |
trivial for research projects |
for research projects to |
research projects to export |
projects to export their |
to export their interfaces |
export their interfaces in |
their interfaces in a |
interfaces in a language |
in a language independent |
a language independent manner |
the ensemble project for |
ensemble project for example |
project for example has |
for example has developed |
example has developed a |
has developed a protocol |
developed a protocol environment |
a protocol environment for |
protocol environment for distributed |
environment for distributed operations |
for distributed operations in |
distributed operations in the |
operations in the ml |
in the ml programming |
the ml programming language |
and by using a |
by using a com |
using a com interface |
a com interface are |
com interface are the |
interface are the services |
are the services offered |
the services offered by |
services offered by ensemble |
offered by ensemble available |
freedman school of computer |
by ensemble available to |
ensemble available to c |
school of computer science |
java and vb programmers |
cache coherence in distributed |
iceland of computer science |
coherence in distributed systems |
this allowed the researchers |
allowed the researchers to |
the researchers to side |
step the time consuming |
the time consuming development |
time consuming development of |
consuming development of native |
development of native language |
of native language interfaces |
usa school of electronics |
school of electronics engineering |
it helps of course |
of electronics engineering and |
helps of course to |
electronics engineering and computer |
engineering and computer science |
of course to have |
course to have all |
to have all the |
have all the tools |
operating system versions and |
system versions and their |
versions and their source |
and their source code |
their source code available |
microsoft is very generous |
is very generous to |
very generous to academia |
generous to academia and |
to academia and makes |
academia and makes all |
and makes all their |
makes all their tools |
all their tools from |
their tools from operating |
tools from operating systems |
from operating systems to |
operating systems to compilers |
including tons of documentation |
tons of documentation as |
of documentation as well |
documentation as well as |
as well as subscriptions |
well as subscriptions to |
as subscriptions to the |
subscriptions to the developer |
to the developer network |
available to the departments |
to the departments free |
the departments free of |
departments free of charge |
source code availability turned |
a global cache coherent |
global cache coherent file |
code availability turned out |
cache coherent file system |
availability turned out to |
turned out to be |
out to be not |
to be not crucial |
and was only once |
was only once used |
only once used to |
once used to make |
used to make actual |
to make actual changes |
department abstract the growth |
make actual changes to |
abstract the growth in |
actual changes to the |
the growth in internet |
changes to the operating |
growth in internet traffic |
to the operating systems |
in internet traffic associated |
internet traffic associated with |
traffic associated with video |
associated with video streaming |
von eicken et al |
with video streaming and |
video streaming and sharing |
streaming and sharing of |
and sharing of videos |
sharing of videos is |
of videos is so |
videos is so rapid |
is so rapid that |
so rapid that it |
rapid that it may |
that it may soon |
it may soon dwarf |
may soon dwarf all |
soon dwarf all other |
dwarf all other forms |
all other forms of |
other forms of internet |
forms of internet content |
the source is extremely |
source is extremely useful |
one reason for this |
is extremely useful as |
reason for this is |
a distributed memory object |
extremely useful as additional |
for this is that |
distributed memory object caching |
memory object caching system |
this is that only |
useful as additional documentation |
is that only some |
that only some forms |
only some forms of |
some forms of content |
forms of content can |
of content can be |
to examine unexpected behaviour |
content can be cached |
examine unexpected behaviour or |
unexpected behaviour or to |
behaviour or to provide |
or to provide templates |
to provide templates for |
provide templates for similar |
templates for similar projects |
as one can perform |
one can perform complete |
data generated in real |
can perform complete source |
generated in real time |
perform complete source code |
in real time such |
complete source code level |
real time such as |
source code level debugging |
time such as by |
code level debugging of |
such as by live |
level debugging of all |
as by live video |
debugging of all parts |
by live video broadcasts |
of all parts of |
all parts of the |
parts of the operating |
of the operating system |
the operating system including |
operating system including the |
system including the kernel |
source codes helps us |
codes helps us to |
helps us to develop |
us to develop experimental |
to develop experimental services |
develop experimental services faster |
experimental services faster and |
iptv or new episodes |
services faster and in |
or new episodes of |
faster and in tune |
new episodes of popular |
and in tune with |
episodes of popular tv |
in tune with existing |
of popular tv shows |
tune with existing functionality |
students are free to |
are free to work |
distributed data structures for |
free to work with |
data structures for internet |
to work with the |
structures for internet service |
immersive virtual reality applications |
work with the source |
for internet service construction |
virtual reality applications and |
with the source code |
reality applications and games |
the source code and |
in proceedings of the |
applications and games typically |
source code and are |
and games typically can |
code and are not |
games typically can t |
th conference on symposium |
and are not prohibited |
typically can t be |
conference on symposium on |
are not prohibited in |
can t be cached |
on symposium on operating |
not prohibited in any |
t be cached at |
be cached at all |
prohibited in any way |
symposium on operating system |
in any way from |
on operating system design |
any way from applying |
and in today s |
in today s systems |
way from applying the |
from applying the knowledge |
applying the knowledge they |
the knowledge they gained |
knowledge they gained in |
each client may pull |
they gained in their |
client may pull such |
gained in their later |
may pull such information |
in their later careers |
pull such information on |
such information on its |
information on its own |
on its own point |
interactions with the evil |
with the evil empire |
the evil empire microsoft |
evil empire microsoft realizes |
empire microsoft realizes the |
microsoft realizes the potential |
realizes the potential of |
the potential of widespread |
stream directly from the |
directly from the data |
from the data center |
potential of widespread adoption |
of widespread adoption of |
widespread adoption of windows |
even if large numbers |
adoption of windows nt |
if large numbers of |
of windows nt for |
large numbers of clients |
windows nt for research |
numbers of clients share |
nt for research purposes |
of clients share interest |
for research purposes and |
clients share interest in |
research purposes and there |
share interest in at |
purposes and there is |
interest in at least |
and there is dedicated |
in at least some |
there is dedicated academic |
at least some aspects |
is dedicated academic relations |
least some aspects of |
dedicated academic relations team |
some aspects of the |
academic relations team whose |
aspects of the data |
relations team whose single |
team whose single task |
whose single task it |
single task it is |
task it is to |
we propose a new |
it is to facilitate |
propose a new system |
is to facilitate the |
a new system called |
to facilitate the technology |
new system called g |
facilitate the technology transfer |
system called g radient |
the technology transfer between |
called g radient aimed |
technology transfer between microsoft |
g radient aimed at |
transfer between microsoft and |
radient aimed at reducing |
between microsoft and academia |
aimed at reducing the |
microsoft and academia and |
at reducing the load |
and academia and vice |
reducing the load on |
academia and vice versa |
the load on providers |
load on providers of |
on providers of such |
providers of such and |
of such and enabling |
such and enabling scalable |
source licensing is very |
licensing is very liberal |
is very liberal compared |
bandwidthsensitive streaming service for |
very liberal compared to |
streaming service for heterogeneous |
liberal compared to other |
service for heterogeneous consumers |
compared to other os |
to other os vendors |
other os vendors and |
os vendors and several |
vendors and several institutions |
the core of the |
and several institutions are |
core of the system |
several institutions are involved |
of the system is |
institutions are involved in |
the system is an |
are involved in active |
system is an overlay |
involved in active exchanges |
is an overlay networking |
in active exchanges with |
an overlay networking architecture |
active exchanges with product |
overlay networking architecture intended |
exchanges with product and |
networking architecture intended to |
with product and research |
architecture intended to run |
product and research groups |
intended to run directly |
and research groups within |
to run directly on |
research groups within microsoft |
run directly on a |
directly on a content |
on a content hosting |
a content hosting platform |
joint projects are in |
projects are in progress |
and which optimizes aggregate |
which optimizes aggregate bandwidth |
optimizes aggregate bandwidth use |
aggregate bandwidth use by |
joint papers are starting |
bandwidth use by transforming |
use by transforming in |
papers are starting to |
are starting to appear |
starting to appear and |
to appear and academics |
appear and academics frequently |
flight data to match |
and academics frequently present |
data to match the |
academics frequently present cutting |
to match the ideal |
frequently present cutting edge |
match the ideal stream |
present cutting edge result |
the ideal stream quality |
cutting edge result to |
ideal stream quality expressed |
edge result to microsoft |
stream quality expressed as |
result to microsoft developers |
quality expressed as an |
to microsoft developers and |
expressed as an economic |
microsoft developers and researchers |
as an economic utility |
an economic utility of |
economic utility of the |
utility of the consuming |
of the consuming client |
introduction recent years have |
recent years have seen |
years have seen skyrocketing |
have seen skyrocketing demand |
seen skyrocketing demand for |
skyrocketing demand for internet |
demand for internet bandwidth |
increasingly dominated by real |
time streaming of short |
operating systems there is |
systems there is a |
there is a direct |
is a direct impact |
a direct impact of |
direct impact of academia |
impact of academia on |
of academia on microsoft |
academia on microsoft products |
but in many forms |
through involvement in the |
involvement in the strategy |
in the strategy phases |
the strategy phases of |
strategy phases of products |
phases of products as |
of products as well |
products as well as |
as well as through |
well as through academic |
as through academic knowledge |
through academic knowledge transfer |
academic knowledge transfer into |
if trends continue then |
knowledge transfer into products |
trends continue then internet |
transfer into products and |
continue then internet video |
into products and design |
then internet video alone |
products and design groups |
internet video alone will |
video alone will generate |
alone will generate almost |
tier database caching for |
database caching for e |
microsoft also provides research |
also provides research funding |
provides research funding for |
research funding for some |
funding for some relevant |
for some relevant groups |
exabytes per month by |
some relevant groups and |
per month by the |
in international conference on |
relevant groups and fellowship |
month by the end |
international conference on management |
groups and fellowship and |
by the end of |
conference on management of |
on management of data |
and fellowship and research |
fellowship and research internships |
and research internships for |
research internships for students |
summary four years of |
four years of research |
years of research on |
of research on windows |
research on windows nt |
on windows nt have |
windows nt have taught |
nt have taught us |
have taught us that |
taught us that we |
us that we made |
that we made the |
we made the right |
made the right choice |
the right choice in |
right choice in leaving |
choice in leaving the |
in leaving the unix |
leaving the unix behind |
percent of all internet |
of all internet traffic |
windows nt is an |
nt is an exiting |
years ahead of its |
ahead of its competition |
faced with a competitive |
with a competitive landscape |
isps and content providers |
and content providers are |
content providers are exploring |
in its implementation and |
providers are exploring technologies |
its implementation and in |
are exploring technologies to |
implementation and in the |
exploring technologies to help |
and in the actual |
technologies to help satisfy |
in the actual services |
to help satisfy the |
the actual services offered |
help satisfy the growing |
satisfy the growing demand |
the growing demand alongside |
growing demand alongside the |
demand alongside the purchase |
alongside the purchase of |
it took quite some |
the purchase of expensive |
took quite some time |
purchase of expensive infrastructure |
quite some time to |
some time to reach |
time to reach the |
to reach the same |
reach the same level |
reducing the bandwidth consumption |
the same level of |
the bandwidth consumption of |
same level of knowledge |
bandwidth consumption of simultaneous |
level of knowledge and |
consumption of simultaneous replicated |
of knowledge and insight |
of simultaneous replicated content |
knowledge and insight we |
simultaneous replicated content is |
and insight we used |
replicated content is a |
insight we used to |
content is a challenge |
we used to have |
is a challenge which |
used to have of |
a challenge which usually |
to have of unix |
challenge which usually leverages |
have of unix systems |
which usually leverages two |
usually leverages two main |
leverages two main tools |
consistent and scalable cache |
but now that we |
and scalable cache replication |
now that we have |
caching of content and |
scalable cache replication for |
cache replication for multi |
of content and multicasting |
that we have arrived |
we have arrived at |
have arrived at that |
arrived at that same |
at that same knowledge |
that same knowledge point |
some forms of video |
forms of video content |
is it clear that |
it clear that our |
such as downloads of |
clear that our research |
as downloads of unencrypted |
that our research is |
downloads of unencrypted movies |
our research is making |
of unencrypted movies or |
research is making progress |
unencrypted movies or films |
is making progress faster |
movies or films where |
making progress faster than |
or films where many |
progress faster than ever |
faster than ever before |
films where many users |
where many users will |
many users will share |
users will share the |
will share the same |
share the same encryption |
the same encryption key |
working with windows nt |
with windows nt requires |
windows nt requires certain |
nt requires certain level |
requires certain level of |
certain level of resilience |
not because of flaws |
because of flaws in |
of flaws in the |
flaws in the operating |
in the operating system |
a wide variety of |
wide variety of caching |
variety of caching options |
of caching options exist |
but because of the |
because of the zealous |
of the zealous attacks |
the zealous attacks by |
zealous attacks by colleagues |
attacks by colleagues and |
by colleagues and other |
colleagues and other researchers |
publishing papers about research |
papers about research performed |
about research performed on |
research performed on windows |
performed on windows nt |
on windows nt is |
windows nt is still |
nt is still quite |
is still quite difficult |
of which is the |
still quite difficult as |
which is the akamai |
quite difficult as many |
is the akamai content |
difficult as many of |
the akamai content distribution |
as many of our |
akamai content distribution network |
many of our peer |
of our peer still |
our peer still believe |
peer still believe that |
still believe that no |
believe that no good |
that no good research |
no good research can |
good research can be |
research can be performed |
is arguably the most |
arguably the most famous |
can be performed on |
be performed on windows |
performed on windows nt |
consistent and scalable caching |
and scalable caching in |
scalable caching in multitier |
caching in multitier architectures |
we hope that eventually |
hope that eventually the |
that eventually the advanced |
the international journal on |
eventually the advanced technical |
international journal on very |
the advanced technical nature |
journal on very large |
on very large data |
very large data bases |
advanced technical nature of |
technical nature of the |
nature of the operating |
multicast techniques can reduce |
of the operating system |
techniques can reduce the |
the operating system will |
can reduce the overall |
operating system will prevail |
reduce the overall network |
system will prevail in |
the overall network traffic |
will prevail in the |
overall network traffic by |
prevail in the discussion |
network traffic by taking |
traffic by taking advantage |
by taking advantage of |
taking advantage of the |
advantage of the packet |
and that we can |
of the packet replication |
that we can have |
the packet replication and |
we can have a |
packet replication and forwarding |
can have a community |
replication and forwarding within |
have a community where |
and forwarding within the |
a community where research |
forwarding within the network |
community where research results |
within the network infrastructure |
where research results can |
research results can be |
results can be shared |
can be shared without |
be shared without sarcasm |
shared without sarcasm or |
without sarcasm or the |
sarcasm or the risk |
or the risk of |
the risk of igniting |
the deployment of the |
risk of igniting yet |
deployment of the efficient |
of the efficient network |
of igniting yet another |
igniting yet another holy |
yet another holy war |
area internet has failed |
and so more expensive |
so more expensive application |
level overlays are generally |
overlays are generally used |
the devices used by |
devices used by content |
used by content subscribers |
by content subscribers have |
content subscribers have become |
subscribers have become increasingly |
have become increasingly heterogeneous |
become increasingly heterogeneous mobile |
increasingly heterogeneous mobile devices |
are projected to consume |
projected to consume over |
improving application throughput with |
application throughput with enterprise |
throughput with enterprise javabeans |
with enterprise javabeans caching |
exabytes of video per |
of video per month |
video per month in |
in international conference on |
international conference on distributed |
conference on distributed computing |
on distributed computing systems |
expert testimony of professor |
testimony of professor david |
implying that a range |
of professor david j |
that a range of |
a range of subscription |
range of subscription rates |
of subscription rates and |
subscription rates and policies |
rates and policies must |
and policies must be |
policies must be applied |
must be applied over |
be applied over the |
applied over the user |
over the user base |
even if multiple users |
if multiple users are |
multiple users are streaming |
users are streaming the |
are streaming the same |
streaming the same event |
such as watching the |
as watching the opening |
watching the opening ceremony |
the opening ceremony of |
opening ceremony of the |
ceremony of the olympics |
a smartphone user will |
smartphone user will need |
user will need a |
currency serializability for middle |
will need a differently |
need a differently transcoded |
a differently transcoded version |
differently transcoded version than |
transcoded version than the |
tier caching and replication |
version than the people |
than the people watching |
the people watching via |
people watching via internet |
watching via internet television |
in international conference on |
international conference on management |
conference on management of |
on management of data |
or on their laptops |
different consumer groups may |
consumer groups may desire |
groups may desire different |
may desire different local |
desire different local ads |
different local ads or |
local ads or sub |
titles to be embedded |
to be embedded into |
be embedded into their |
embedded into their video |
into their video streams |
avatars in a virtual |
in a virtual world |
a virtual world can |
virtual world can be |
world can be viewed |
can be viewed as |
be viewed as subscribers |
viewed as subscribers to |
as subscribers to updates |
subscribers to updates about |
to updates about objects |
updates about objects in |
about objects in their |
objects in their vicinity |
and may want more |
may want more detailed |
want more detailed updates |
more detailed updates for |
detailed updates for objects |
updates for objects that |
for objects that are |
objects that are closer |
that are closer to |
are closer to them |
closer to them in |
to them in this |
them in this world |
a ppendix we now |
ppendix we now prove |
we now prove theorem |
while this growing heterogeneity |
this growing heterogeneity of |
growing heterogeneity of device |
heterogeneity of device types |
research on cdns has |
on cdns has generally |
cdns has generally assumed |
has generally assumed a |
generally assumed a homogeneous |
assumed a homogeneous population |
a homogeneous population of |
homogeneous population of end |
cache with unbounded cache |
with unbounded cache size |
unbounded cache size and |
cache size and unbounded |
size and unbounded dependency |
and unbounded dependency lists |
unbounded dependency lists implements |
dependency lists implements cache |
since we assume that |
we assume that the |
assume that the transactional |
that the transactional db |
the transactional db is |
transactional db is serializable |
uwin unix for windows |
the operations in an |
the usenix windows nt |
operations in an execution |
usenix windows nt workshop |
in an execution of |
an execution of update |
execution of update transactions |
of update transactions update |
update transactions update can |
transactions update can be |
update can be serialized |
can be serialized as |
be serialized as some |
serialized as some serial |
as some serial execution |
thus most current systems |
most current systems assume |
current systems assume multiple |
the next claim trivially |
systems assume multiple video |
next claim trivially follows |
assume multiple video streams |
claim trivially follows from |
multiple video streams to |
trivially follows from the |
video streams to be |
follows from the definition |
streams to be sent |
from the definition of |
to be sent from |
the definition of the |
be sent from the |
definition of the database |
sent from the source |
of the database dependency |
from the source at |
the database dependency list |
the source at different |
database dependency list specification |
source at different resolutions |
at different resolutions or |
different resolutions or that |
resolutions or that a |
or that a single |
that a single highquality |
a single highquality stream |
single highquality stream is |
highquality stream is transcoded |
stream is transcoded by |
is transcoded by the |
transcoded by the receiver |
by the receiver who |
if is a serialization |
the receiver who then |
is a serialization of |
receiver who then incurs |
a serialization of the |
who then incurs cost |
serialization of the update |
then incurs cost for |
of the update transactions |
incurs cost for last |
the update transactions of |
update transactions of an |
transactions of an execution |
of an execution update |
mile traffic owing to |
traffic owing to unnecessarily |
owing to unnecessarily detailed |
to unnecessarily detailed video |
at every step in |
we pose the following |
pose the following question |
the version dependencies of |
version dependencies of every |
how can we deliver |
dependencies of every object |
can we deliver live |
we deliver live dynamic |
deliver live dynamic content |
of every object match |
every object match those |
object match those stored |
match those stored in |
those stored in its |
stored in its dependency |
such as video broadcasts |
in its dependency list |
or financial stock data |
over the internet to |
the internet to large |
internet to large number |
to large number of |
we first describe a |
large number of heterogeneous |
first describe a routine |
number of heterogeneous users |
describe a routine for |
of heterogeneous users simultaneously |
a routine for placing |
heterogeneous users simultaneously while |
routine for placing a |
for placing a read |
users simultaneously while balancing |
simultaneously while balancing bandwidth |
while balancing bandwidth costs |
only transaction from a |
transaction from a cache |
from a cache server |
traffic rates and end |
a cache server in |
cache server in a |
server in a serialization |
in a serialization of |
a serialization of a |
serialization of a subset |
of a subset of |
th edition with source |
edition with source code |
to form a serialization |
form a serialization of |
a serialization of both |
live content refers to |
serialization of both the |
content refers to content |
of both the update |
refers to content streams |
both the update transaction |
to content streams that |
the update transaction and |
content streams that must |
update transaction and the |
streams that must be |
transaction and the read |
that must be transmitted |
must be transmitted to |
be transmitted to multiple |
transmitted to multiple receivers |
to multiple receivers simultaneously |
such as a live |
as a live broadcast |
ticker updates for financial |
updates for financial stocks |
for financial stocks or |
financial stocks or object |
stocks or object updates |
or object updates in |
object updates in a |
updates in a virtual |
in a virtual world |
we are not focused |
are not focused on |
not focused on streams |
focused on streams with |
on streams with a |
streams with a pause |
with a pause or |
a pause or rewind |
pause or rewind functions |
or rewind functions or |
rewind functions or the |
functions or the video |
the gradient cdn to |
gradient cdn to make |
cdn to make progress |
to make progress towards |
make progress towards the |
progress towards the research |
towards the research question |
performing this permutation is |
this permutation is one |
permutation is one step |
is one step of |
one step of the |
step of the routine |
we propose a novel |
propose a novel networked |
a novel networked content |
we repeat this step |
novel networked content delivery |
repeat this step forming |
networked content delivery system |
this step forming a |
content delivery system called |
step forming a series |
delivery system called g |
forming a series of |
system called g radient |
a series of permutations |
called g radient to |
g radient to address |
radient to address the |
to address the complex |
each permutation is a |
address the complex caching |
permutation is a serialization |
the complex caching and |
is a serialization of |
complex caching and multicasting |
a serialization of update |
caching and multicasting issues |
and multicasting issues associated |
multicasting issues associated with |
issues associated with live |
associated with live streaming |
and each permutes a |
with live streaming of |
each permutes a range |
live streaming of dynamic |
permutes a range of |
streaming of dynamic content |
a range of the |
of dynamic content to |
range of the transactions |
dynamic content to a |
content to a heterogeneous |
of the transactions with |
to a heterogeneous user |
a heterogeneous user population |
the transactions with respect |
transactions with respect to |
with respect to the |
respect to the previous |
to the previous step |
the systems architecture consists |
systems architecture consists of |
architecture consists of one |
in each step the |
consists of one or |
each step the right |
of one or more |
step the right end |
one or more content |
the right end of |
or more content providers |
right end of the |
more content providers which |
end of the range |
content providers which together |
of the range is |
providers which together form |
the range is earlier |
which together form a |
range is earlier than |
together form a cooperative |
is earlier than in |
the design and implementation |
form a cooperative network |
earlier than in the |
design and implementation of |
a cooperative network of |
than in the previous |
and implementation of the |
cooperative network of g |
in the previous step |
network of g radient |
of g radient cdn |
g radient cdn nodes |
as one or more |
one or more of |
or more of the |
the cdn nodes form |
more of the objects |
cdn nodes form a |
of the objects is |
nodes form a dynamic |
the objects is closer |
form a dynamic overlay |
objects is closer to |
a dynamic overlay over |
is closer to the |
dynamic overlay over which |
closer to the value |
overlay over which the |
to the value read |
over which the content |
the value read by |
which the content is |
the content is delivered |
value read by t |
and for our initial |
for our initial prototypes |
eventually we therefore reach |
our initial prototypes we |
we therefore reach a |
initial prototypes we will |
therefore reach a permutation |
prototypes we will look |
reach a permutation where |
we will look at |
a permutation where at |
will look at spanning |
permutation where at the |
look at spanning trees |
where at the chosen |
at the chosen time |
the chosen time all |
chosen time all read |
time all read objects |
the concept of cdn |
all read objects are |
concept of cdn nodes |
read objects are at |
of cdn nodes is |
objects are at their |
cdn nodes is general |
are at their correct |
at their correct versions |
an architecture in which |
architecture in which cdn |
we place t there |
in which cdn servers |
place t there to |
which cdn servers are |
t there to obtain |
cdn servers are hosted |
there to obtain the |
servers are hosted by |
to obtain the desired |
are hosted by isps |
obtain the desired serialization |
hosted by isps to |
the desired serialization of |
by isps to reduce |
desired serialization of the |
isps to reduce redundant |
serialization of the update |
to reduce redundant incoming |
of the update transactions |
reduce redundant incoming bandwidth |
the update transactions and |
redundant incoming bandwidth is |
update transactions and t |
incoming bandwidth is a |
bandwidth is a logical |
is a logical scenario |
and another example is |
another example is that |
permutation routine let be |
example is that g |
what s new in |
routine let be an |
is that g radient |
s new in windows |
let be an execution |
that g radient nodes |
be an execution of |
g radient nodes may |
an execution of the |
radient nodes may as |
execution of the t |
nodes may as well |
may as well be |
as well be integrated |
well be integrated into |
be integrated into set |
and denote by update |
denote by update the |
by update the projection |
update the projection of |
the projection of on |
projection of on the |
of on the set |
on the set of |
the set of database |
set of database update |
of database update transactions |
transaction t reads objects |
t reads objects o |
our approach to the |
approach to the problem |
to the problem resembles |
the problem resembles content |
and in fact the |
in fact the expected |
fact the expected deployment |
the expected deployment model |
expected deployment model would |
deployment model would employ |
model would employ a |
would employ a geographically |
employ a geographically distributed |
a geographically distributed set |
geographically distributed set of |
distributed set of isps |
set of isps or |
of isps or small |
isps or small data |
or small data centers |
on with versions v |
small data centers of |
data centers of the |
centers of the kind |
of the kind operated |
the kind operated by |
kind operated by today |
operated by today s |
by today s cdn |
today s cdn providers |
whereas today s content |
hosting sites cache objects |
take any serialization of |
any serialization of update |
one exists according to |
exists according to claim |
our focus is on |
focus is on content |
is on content that |
on content that cannot |
content that cannot be |
that cannot be usefully |
cannot be usefully cached |
and consider the first |
consider the first time |
the first time when |
the g radient project |
first time when all |
g radient project aims |
time when all the |
radient project aims to |
when all the objects |
project aims to exploit |
all the objects the |
aims to exploit and |
the objects the transaction |
to exploit and develop |
objects the transaction reads |
exploit and develop two |
the transaction reads are |
and develop two techniques |
transaction reads are at |
develop two techniques that |
reads are at a |
two techniques that improve |
are at a version |
techniques that improve on |
at a version at |
that improve on existing |
improve on existing cdns |
a version at least |
version at least as |
at least as large |
least as large as |
as large as the |
large as the versions |
as the versions that |
the versions that t |
versions that t reads |
and algorithms to balance |
algorithms to balance bandwidth |
to balance bandwidth costs |
balance bandwidth costs with |
bandwidth costs with end |
at this time at |
this time at least |
time at least one |
at least one object |
least one object read |
one object read by |
object read by t |
our design is focused |
design is focused on |
the last written according |
is focused on modularity |
last written according to |
focused on modularity and |
on modularity and incremental |
modularity and incremental deployment |
has the correct version |
but others might not |
assume without loss of |
without loss of generality |
loss of generality that |
of generality that the |
generality that the last |
that the last version |
the last version written |
last version written is |
version written is vn |
written is vn of |
is vn of object |
vn of object on |
of object on at |
object on at step |
on at step t |
at step t of |
dynamic content has substantial |
content has substantial levels |
has substantial levels of |
denote by t the |
substantial levels of redundancy |
by t the latest |
nick vasilatos and werner |
vasilatos and werner vogels |
t the latest time |
the latest time at |
even when user interests |
latest time at which |
when user interests are |
time at which a |
do you need source |
user interests are relatively |
interests are relatively heterogeneous |
you need source with |
need source with that |
at which a wrong |
which a wrong version |
widespread use of streaming |
use of streaming video |
panel at the usenix |
of streaming video occurs |
at the usenix windows |
not the one read |
streaming video occurs when |
the usenix windows nt |
the one read by |
one read by t |
usenix windows nt workshop |
video occurs when internet |
occurs when internet users |
when internet users watch |
internet users watch major |
users watch major events |
watch major events online |
and assume wlog it |
assume wlog it is |
wlog it is version |
such as superbowl or |
it is version vn |
as superbowl or the |
superbowl or the olympics |
k of object on |
and like television users |
such clients have little |
clients have little tolerance |
have little tolerance for |
rather than the desired |
little tolerance for lagged |
than the desired version |
tolerance for lagged data |
the desired version vn |
large numbers of users |
numbers of users have |
of users have essentially |
users have essentially the |
have essentially the same |
essentially the same needs |
we now describe a |
but since they may |
now describe a single |
since they may access |
describe a single step |
they may access the |
a single step of |
may access the streams |
single step of the |
access the streams from |
step of the routine |
the streams from a |
streams from a variety |
from a variety of |
a variety of devices |
summary in usenix login |
consider the transactions between |
the transactions between t |
transactions between t and |
between t and t |
with different screen sizes |
different screen sizes and |
screen sizes and resolutions |
or different connectivity properties |
divide these transactions into |
these transactions into three |
transactions into three sets |
the current solution is |
current solution is to |
solution is to provide |
is to provide each |
to provide each user |
provide each user with |
each user with a |
user with a direct |
transactions dependent on the |
with a direct connection |
dependent on the transaction |
a direct connection to |
on the transaction at |
direct connection to a |
connection to a content |
the transaction at t |
server due to the |
due to the lack |
to the lack of |
the lack of robust |
lack of robust multicast |
of robust multicast technologies |
similar issues arise for |
unix application portability to |
issues arise for newscasts |
application portability to windows |
arise for newscasts of |
for newscasts of fast |
portability to windows nt |
transactions on which t |
to windows nt via |
on which t is |
windows nt via an |
which t is dependent |
nt via an alternative |
via an alternative environment |
an alternative environment subsystem |
transmission of financial data |
of financial data and |
financial data and virtual |
data and virtual on |
the usenix windows nt |
usenix windows nt workshop |
our insight is that |
insight is that a |
is that a data |
transactions that do not |
that do not belong |
do not belong to |
not belong to either |
belong to either group |
rich channel can be |
channel can be transformed |
can be transformed on |
the following lemma states |
following lemma states that |
lemma states that there |
states that there is |
that there is no |
there is no dependency |
is no dependency among |
no dependency among objects |
network to create the |
dependency among objects in |
to create the dynamic |
among objects in sets |
create the dynamic content |
the dynamic content for |
dynamic content for end |
and hence there is |
hence there is no |
there is no intersection |
we could add personalized |
is no intersection between |
could add personalized advertisements |
no intersection between the |
intersection between the sets |
subtitles or encryption keys |
or encryption keys to |
encryption keys to iptv |
keys to iptv broadcasts |
filters or aggregates to |
or aggregates to financial |
aggregates to financial stock |
to financial stock updates |
or reduce the update |
reduce the update rate |
the update rate for |
update rate for distant |
rate for distant objects |
for distant objects in |
distant objects in the |
objects in the virtual |
in the virtual world |
the virtual world to |
virtual world to which |
if they were dependent |
world to which the |
to which the user |
which the user has |
the user has subscribed |
then version vn of |
version vn of object |
vn of object on |
of object on depends |
the same mechanism will |
object on depends on |
same mechanism will also |
on depends on version |
mechanism will also allow |
depends on version vn |
will also allow the |
also allow the system |
allow the system to |
the system to tailor |
system to tailor to |
to tailor to heterogeneous |
tailor to heterogeneous devices |
k of object on |
and this dependency is |
this dependency is reflected |
dependency is reflected in |
transcoding a high definition |
is reflected in their |
reflected in their t |
a high definition broadcast |
protect the future of |
high definition broadcast to |
the future of computing |
definition broadcast to adapt |
future of computing technology |
broadcast to adapt its |
to adapt its resolution |
because they are unbounded |
adapt its resolution to |
its resolution to serve |
resolution to serve a |
to serve a population |
serve a population of |
a population of heterogeneous |
transaction t has read |
population of heterogeneous devices |
t has read version |
of heterogeneous devices from |
has read version vn |
heterogeneous devices from cell |
devices from cell phones |
from cell phones to |
cell phones to tablets |
phones to tablets to |
to tablets to iptv |
tablets to iptv lowering |
to iptv lowering overall |
iptv lowering overall bandwidth |
lowering overall bandwidth costs |
overall bandwidth costs without |
bandwidth costs without affecting |
costs without affecting viewing |
which is older than |
without affecting viewing experience |
is older than vn |
the read of the |
network transformations will be |
read of the stale |
transformations will be applied |
of the stale version |
will be applied with |
the stale version vn |
be applied with pluggable |
applied with pluggable serverlets |
with pluggable serverlets designed |
pluggable serverlets designed to |
serverlets designed to execute |
designed to execute within |
to execute within the |
execute within the cdn |
within the cdn nodes |
would have been detected |
the cdn nodes of |
have been detected by |
been detected by t |
cdn nodes of g |
nodes of g radient |
cache and the transaction |
and the transaction would |
the transaction would have |
the serverlets encapsulate application |
transaction would have been |
would have been aborted |
speci n ac details |
n ac details such |
therefore the assumption is |
the assumption is wrong |
ac details such as |
details such as the |
such as the stream |
as the stream data |
the stream data format |
and the sets are |
the sets are indeed |
sets are indeed independent |
and the ways to |
the ways to transform |
ways to transform a |
to transform a the |
transform a the data |
perhaps an empty set |
rich objects into more |
objects into more specialized |
into more specialized ones |
is unrelated to sets |
open issues include understanding |
issues include understanding what |
include understanding what kinds |
understanding what kinds of |
what kinds of content |
kinds of content may |
of content may be |
content may be subject |
may be subject to |
we therefore switch sets |
be subject to such |
subject to such transformation |
to such transformation and |
such transformation and which |
transformation and which dynamic |
and which dynamic content |
which dynamic content is |
dynamic content is not |
to assess the effect |
assess the effect of |
the effect of the |
effect of the transformation |
of the transformation on |
the transformation on quality |
transformation on quality and |
on quality and traffic |
quality and traffic rates |
maintaining a serialization of |
a serialization of update |
how transformation should be |
transformation should be meaningfully |
should be meaningfully expressed |
be meaningfully expressed and |
meaningfully expressed and used |
expressed and used by |
and used by content |
used by content providers |
consider the following serialization |
and to learn how |
to learn how computationally |
learn how computationally intensive |
how computationally intensive such |
xi denotes a transaction |
computationally intensive such transformation |
denotes a transaction x |
intensive such transformation methods |
a transaction x in |
such transformation methods can |
transaction x in set |
x in set i |
transformation methods can be |
methods can be without |
can be without overloading |
be without overloading the |
without overloading the nodes |
balancing bandwidth costs with |
bandwidth costs with end |
cache consistency we proceed |
consistency we proceed to |
we proceed to prove |
the g radi ent |
proceed to prove theorem |
g radi ent content |
radi ent content delivery |
ent content delivery system |
content delivery system is |
delivery system is currently |
system is currently designed |
is currently designed to |
currently designed to use |
designed to use a |
to use a spanningtree |
use a spanningtree overlay |
let be an execution |
be an execution of |
an execution of the |
similar to most multicast |
execution of the t |
to most multicast network |
most multicast network architectures |
with virtual links connecting |
virtual links connecting g |
links connecting g radient |
and denote by update |
connecting g radient cdn |
g radient cdn nodes |
denote by update the |
by update the projection |
update the projection of |
the projection of on |
projection of on the |
the question is to |
of on the set |
question is to determine |
on the set of |
is to determine what |
the set of database |
to determine what nodes |
set of database update |
determine what nodes the |
of database update transactions |
what nodes the in |
network processing and connecting |
processing and connecting to |
and connecting to the |
connecting to the diverse |
to the diverse end |
users should be done |
we need to optimize |
need to optimize the |
to optimize the overlay |
optimize the overlay to |
the overlay to deliver |
overlay to deliver the |
to deliver the exact |
deliver the exact stream |
the exact stream quality |
exact stream quality demanded |
stream quality demanded by |
quality demanded by users |
demanded by users while |
by users while minimizing |
tm a set of |
users while minimizing bandwidth |
while minimizing bandwidth costs |
a set of readonly |
set of readonly transactions |
of readonly transactions performed |
readonly transactions performed through |
transactions performed through a |
performed through a single |
through a single t |
we propose to apply |
propose to apply an |
to apply an economics |
apply an economics framework |
if the read sets |
the read sets of |
considering two primary inputs |
read sets of two |
two primary inputs in |
sets of two transactions |
primary inputs in determining |
of two transactions include |
inputs in determining the |
two transactions include the |
in determining the optimal |
determining the optimal network |
the optimal network overlay |
transactions include the same |
include the same object |
the same object o |
on the one hand |
we say the one |
say the one that |
the one that read |
we consider the cost |
one that read a |
consider the cost for |
that read a larger |
the cost for network |
read a larger version |
cost for network edges |
a larger version of |
for network edges to |
network edges to carry |
edges to carry traffic |
larger version of o |
version of o depends |
of o depends on |
o depends on the |
depends on the other |
similar to standard bandwidth |
to standard bandwidth pricing |
all transactions access the |
transactions access the same |
access the same cache |
we leverage the perceived |
and the cache is |
the cache is unbounded |
leverage the perceived utility |
the perceived utility by |
perceived utility by end |
users for receiving the |
for receiving the stream |
values are only replaced |
receiving the stream at |
are only replaced by |
the stream at a |
stream at a given |
at a given quality |
only replaced by newer |
replaced by newer versions |
so it is easy |
it is easy to |
the exact solution for |
is easy to see |
exact solution for this |
process communication primitives for |
easy to see that |
solution for this optimization |
communication primitives for programming |
to see that there |
for this optimization problem |
primitives for programming distributed |
see that there are |
this optimization problem is |
for programming distributed systems |
that there are no |
optimization problem is intractable |
programming distributed systems robbert |
there are no cycles |
problem is intractable it |
distributed systems robbert van |
are no cycles such |
is intractable it is |
systems robbert van renesse |
no cycles such that |
intractable it is np |
cycles such that two |
such that two transactions |
that two transactions depend |
department of computer science |
two transactions depend on |
of computer science cornell |
transactions depend on one |
computer science cornell university |
depend on one another |
science cornell university category |
we have developed algorithms |
have developed algorithms that |
the dependency graph therefore |
representation the following position |
developed algorithms that give |
dependency graph therefore describes |
the following position paper |
algorithms that give an |
graph therefore describes a |
following position paper describes |
that give an approximate |
therefore describes a partial |
position paper describes a |
give an approximate optimal |
describes a partial order |
paper describes a new |
an approximate optimal solution |
a partial order of |
describes a new interprocess |
partial order of the |
order of the read |
a new interprocess communication |
in the case of |
the case of video |
case of video streams |
of video streams whose |
and we choose an |
video streams whose quality |
primitive that is designed |
we choose an arbitrary |
streams whose quality and |
that is designed to |
choose an arbitrary total |
whose quality and traffic |
is designed to make |
an arbitrary total ordering |
quality and traffic rates |
designed to make it |
arbitrary total ordering that |
and traffic rates can |
to make it easier |
total ordering that respects |
traffic rates can be |
make it easier to |
ordering that respects this |
rates can be downgraded |
it easier to program |
that respects this partial |
can be downgraded by |
easier to program distributed |
respects this partial order |
be downgraded by g |
to program distributed algorithms |
downgraded by g radient |
by g radient cdn |
g radient cdn nodes |
assume wlog the order |
wlog the order is |
the order is t |
it is largely based |
is largely based on |
largely based on my |
we have derived a |
based on my experience |
have derived a primaldual |
on my experience in |
derived a primaldual approximation |
my experience in implementing |
a primaldual approximation algorithm |
experience in implementing algorithms |
primaldual approximation algorithm which |
in implementing algorithms such |
approximation algorithm which produces |
implementing algorithms such as |
algorithm which produces a |
algorithms such as distributed |
which produces a solution |
such as distributed consensus |
produces a solution whose |
a solution whose total |
solution whose total cost |
the difference between total |
difference between total network |
between total network traffic |
total network traffic costs |
network traffic costs and |
traffic costs and aggregate |
costs and aggregate end |
we take an initial |
take an initial arbitrary |
an initial arbitrary serialization |
subject to your evaluation |
to your evaluation of |
your evaluation of my |
evaluation of my proposal |
is within a factor |
within a factor of |
of and permute it |
and permute it according |
permute it according to |
i would be happy |
it according to the |
would be happy to |
according to the route |
be happy to present |
to the route above |
happy to present this |
the route above to |
to present this idea |
route above to place |
above to place t |
present this idea at |
this idea at the |
idea at the workshop |
of the optimal in |
the optimal in the |
ipc allows processes to |
optimal in the worst |
allows processes to share |
in the worst case |
processes to share information |
to share information and |
share information and to |
information and to synchronize |
and to synchronize actions |
the result is a |
result is a permutation |
there are two classes |
are two classes of |
two classes of ipc |
we take all transactions |
take all transactions that |
all transactions that precede |
transactions that precede t |
we see that the |
see that the algorithm |
that the algorithm has |
the algorithm has lower |
algorithm has lower total |
has lower total cost |
lower total cost compared |
total cost compared to |
cost compared to a |
does not depend on |
not depend on them |
mc has processes communicate |
compared to a single |
has processes communicate send |
to a single stream |
and place them after |
a single stream source |
place them after t |
processes communicate send and |
single stream source and |
communicate send and receive |
stream source and a |
send and receive messages |
source and a minimum |
and a minimum spanning |
a minimum spanning tree |
we call this permutation |
minimum spanning tree streaming |
while sm allows processes |
spanning tree streaming protocol |
sm allows processes to |
tree streaming protocol in |
allows processes to share |
streaming protocol in a |
processes to share data |
next we place t |
protocol in a simulation |
to share data directly |
in a simulation based |
share data directly while |
a simulation based on |
data directly while synchronizing |
simulation based on a |
directly while synchronizing using |
based on a collection |
while synchronizing using such |
on a collection of |
synchronizing using such primitives |
a collection of as |
using such primitives as |
such primitives as mutexes |
primitives as mutexes and |
can be placed immediately |
as mutexes and condition |
be placed immediately after |
mutexes and condition variables |
placed immediately after t |
where processes are physically |
gradient mst naive broadcast |
we place it there |
processes are physically separated |
mst naive broadcast total |
naive broadcast total cost |
place it there to |
it there to form |
mc is dominant as |
is dominant as e |
dominant as e orts |
as e orts to |
e orts to support |
orts to support the |
to support the sm |
support the sm paradigm |
the sm paradigm have |
sm paradigm have not |
paradigm have not been |
have not been successful |
is independent of t |
examples of sm include |
of sm include tcp |
sm include tcp connections |
then all its preceding |
all its preceding transactions |
according to the dependency |
to the dependency graph |
are unrelated to t |
the mc and sm |
mc and sm paradigms |
and are therefore located |
and sm paradigms are |
are therefore located after |
therefore located after it |
sm paradigms are duals |
paradigms are duals in |
are duals in that |
duals in that one |
in that one can |
the permutations required are |
that one can be |
permutations required are therefore |
one can be implememted |
required are therefore after |
can be implememted using |
be implememted using the |
implememted using the other |
are therefore after t |
but they also each |
they also each have |
also each have their |
each have their advantages |
have their advantages and |
their advantages and disadvantages |
advantages and disadvantages when |
and disadvantages when compared |
disadvantages when compared with |
when compared with one |
compared with one another |
it is useful to |
is useful to consider |
useful to consider how |
to consider how distributed |
consider how distributed algorithms |
how distributed algorithms such |
distributed algorithms such as |
algorithms such as replication |
all relevant update transactions |
relevant update transactions are |
update transactions are located |
transactions are located after |
are located after t |
and therefore the permutations |
typically it has much |
therefore the permutations required |
it has much to |
the permutations required are |
has much to do |
permutations required are all |
much to do with |
to do with progress |
required are all after |
are all after t |
in order for some |
order for some process |
for some process to |
some process to be |
process to be able |
to be able to |
be able to make |
since in all cases |
able to make a |
in all cases the |
to make a transition |
all cases the permutations |
cases the permutations are |
the permutations are after |
permutations are after t |
it needs to know |
needs to know that |
to know that one |
know that one or |
that one or more |
one or more other |
or more other processes |
more other processes have |
other processes have reached |
processes have reached a |
have reached a particular |
reached a particular milestone |
they do not affect |
do not affect the |
not affect the correctness |
affect the correctness of |
the correctness of t |
and some data associated |
some data associated with |
data associated with that |
associated with that milestone |
we take the resulting |
take the resulting permutation |
the resulting permutation that |
resulting permutation that we |
permutation that we call |
a new leader in |
new leader in paxos |
leader in paxos needs |
in paxos needs to |
paxos needs to know |
and move all transactions |
needs to know that |
move all transactions that |
to know that a |
all transactions that neither |
know that a quorum |
transactions that neither t |
that a quorum of |
a quorum of acceptors |
quorum of acceptors have |
of acceptors have progressed |
acceptors have progressed to |
have progressed to its |
progressed to its proposed |
depend on to right |
to its proposed ballot |
on to right after |
its proposed ballot and |
to right after t |
proposed ballot and it |
ballot and it needs |
and it needs to |
it needs to know |
needs to know what |
to know what the |
the g radient optimization |
know what the highest |
g radient optimization is |
what the highest accepted |
the resulting permutation is |
radient optimization is effective |
the highest accepted proposals |
optimization is effective compared |
highest accepted proposals from |
is effective compared to |
accepted proposals from those |
effective compared to a |
proposals from those acceptors |
compared to a centralized |
we repeat this process |
from those acceptors are |
to a centralized source |
repeat this process until |
a centralized source and |
this process until we |
centralized source and a |
process until we place |
many if not all |
source and a minimum |
until we place all |
we place all read |
and a minimum spanning |
if not all distributed |
a minimum spanning tree |
not all distributed algorithms |
all distributed algorithms can |
distributed algorithms can be |
algorithms can be cleanly |
can be cleanly expressed |
be cleanly expressed this |
cleanly expressed this way |
protocol even as system |
even as system sizes |
this is a serialization |
as system sizes scale |
as a collection of |
is a serialization of |
system sizes scale up |
a collection of transition |
a serialization of the |
collection of transition specifications |
serialization of the update |
error bars represent one |
of transition specifications that |
of the update transactions |
bars represent one standard |
transition specifications that specify |
the update transactions in |
represent one standard deviation |
specifications that specify under |
update transactions in and |
one standard deviation over |
that specify under which |
transactions in and all |
specify under which conditions |
in and all read |
under which conditions they |
which conditions they are |
conditions they are enabled |
they are enabled and |
are enabled and what |
only transactions that accessed |
enabled and what state |
transactions that accessed the |
and what state they |
that accessed the same |
what state they need |
accessed the same cache |
state they need from |
they need from other |
need from other processes |
the details are deferred |
we have therefore shown |
details are deferred to |
have therefore shown that |
are deferred to a |
note the similarity to |
the similarity to knowledge |
deferred to a full |
therefore shown that in |
to a full report |
shown that in any |
a full report on |
that in any execution |
full report on g |
in any execution of |
report on g radient |
any execution of t |
while the sm paradigm |
the sm paradigm seems |
sm paradigm seems the |
paradigm seems the best |
seems the best fit |
cache the update transactions |
the best fit for |
the update transactions can |
best fit for this |
update transactions can be |
fit for this model |
transactions can be serialized |
for this model of |
conclusion a number of |
can be serialized with |
this model of distributed |
a number of interesting |
be serialized with readonly |
model of distributed algorithms |
number of interesting open |
serialized with readonly transactions |
of interesting open questions |
with readonly transactions that |
interesting open questions remain |
the paradigm is hard |
readonly transactions that accessed |
open questions remain the |
paradigm is hard to |
transactions that accessed a |
questions remain the focus |
is hard to make |
that accessed a single |
remain the focus of |
hard to make efficient |
accessed a single cache |
the focus of our |
focus of our continued |
of our continued investigation |
which means that t |
and scalable in a |
how diverse are the |
cache implements cache serializability |
scalable in a physically |
diverse are the classes |
in a physically distributed |
are the classes of |
a physically distributed system |
the classes of content |
classes of content that |
of content that are |
content that are amenable |
that are amenable to |
are amenable to our |
amenable to our in |
it is notoriously errorprone |
is notoriously errorprone as |
notoriously errorprone as programmers |
errorprone as programmers are |
as programmers are having |
how do we best |
programmers are having difficulty |
do we best assess |
are having difficulty utilizing |
we best assess the |
having difficulty utilizing the |
best assess the effect |
difficulty utilizing the synchronization |
assess the effect of |
utilizing the synchronization primitives |
the effect of such |
the synchronization primitives correctly |
effect of such transformations |
of such transformations on |
such transformations on stream |
transformations on stream quality |
the mc paradigm can |
mc paradigm can be |
paradigm can be used |
can be used instead |
how should these transformations |
be used instead but |
should these transformations be |
used instead but is |
these transformations be expressed |
instead but is awkward |
but is awkward and |
is awkward and error |
prone as well it |
and utilized by the |
as well it requires |
utilized by the originating |
well it requires the |
by the originating content |
it requires the programmer |
the originating content providers |
requires the programmer to |
originating content providers to |
the programmer to figure |
content providers to best |
programmer to figure out |
providers to best balance |
to figure out which |
to best balance content |
figure out which processes |
out which processes should |
which processes should send |
domain specificity with ease |
processes should send which |
specificity with ease of |
should send which data |
with ease of development |
send which data to |
which data to which |
data to which destinations |
to which destinations at |
which destinations at which |
how can our overlay |
destinations at which times |
can our overlay respond |
at which times in |
our overlay respond to |
which times in order |
overlay respond to churn |
times in order to |
respond to churn among |
in order to ensure |
to churn among g |
order to ensure that |
churn among g radient |
to ensure that recipients |
among g radient nodes |
ensure that recipients of |
g radient nodes realistically |
that recipients of this |
radient nodes realistically low |
recipients of this data |
nodes realistically low in |
of this data can |
realistically low in many |
this data can make |
low in many common |
data can make progress |
in many common cases |
many common cases such |
common cases such as |
cases such as video |
such as video streaming |
sometimes messages are lost |
messages are lost if |
are lost if the |
but higher in alternative |
lost if the receiver |
higher in alternative deployment |
if the receiver starts |
in alternative deployment scenarios |
the receiver starts execution |
receiver starts execution after |
starts execution after the |
execution after the sender |
after the sender has |
the sender has started |
sender has started sending |
has started sending messages |
started sending messages to |
sending messages to it |
how do we ensure |
do we ensure that |
we ensure that the |
ensure that the computational |
that the computational intensity |
the computational intensity of |
computational intensity of our |
intensity of our transformations |
of our transformations do |
our transformations do not |
transformations do not place |
pray semantics of connectionless |
do not place too |
semantics of connectionless or |
not place too much |
of connectionless or non |
place too much load |
too much load on |
much load on our |
load on our g |
on our g radient |
our g radient overlay |
blocking messaging primitives is |
g radient overlay nodes |
messaging primitives is one |
primitives is one example |
g radient contributes a |
often needless information is |
radient contributes a novel |
needless information is sent |
contributes a novel platform |
information is sent as |
a novel platform for |
is sent as more |
novel platform for continued |
sent as more recent |
platform for continued study |
as more recent information |
for continued study and |
more recent information makes |
continued study and progress |
recent information makes old |
study and progress to |
information makes old messages |
makes old messages obsolete |
and progress to ever |
progress to ever more |
to ever more effective |
ever more effective delivery |
more effective delivery mechanisms |
using paxos again as |
paxos again as an |
again as an example |
in the stream of |
the stream of values |
stream of values that |
of values that acceptors |
values that acceptors accept |
only the most recent |
the most recent one |
most recent one is |
recent one is of |
one is of interest |
but most mc implementations |
most mc implementations will |
mc implementations will carefully |
implementations will carefully deliver |
will carefully deliver each |
carefully deliver each and |
deliver each and every |
each and every one |
delaying delivery of the |
delivery of the important |
of the important information |
the important information until |
important information until all |
information until all obsoleted |
until all obsoleted information |
all obsoleted information has |
obsoleted information has been |
information has been delivered |
has been delivered as |
been delivered as well |
this leads to wasting |
leads to wasting resources |
potential deadlock situations due |
deadlock situations due to |
situations due to flow |
due to flow control |
to flow control leading |
flow control leading to |
control leading to deadly |
leading to deadly embrace |
and also obfuscates how |
also obfuscates how the |
obfuscates how the algorithms |
how the algorithms work |
bandwidth multicast in cooperative |
multicast in cooperative environments |
a new class of |
new class of ipc |
that that tries to |
that tries to combine |
tries to combine the |
to combine the best |
combine the best features |
the best features of |
best features of sm |
features of sm and |
of sm and mc |
from sm it inherits |
sm it inherits direct |
it inherits direct access |
inherits direct access to |
direct access to and |
access to and synchro |
nization on state rather |
on state rather than |
state rather than providing |
rather than providing a |
than providing a stream |
providing a stream of |
a stream of state |
stream of state updates |
while from mc it |
from mc it inherits |
mc it inherits an |
it inherits an efficient |
inherits an efficient implementation |
an efficient implementation over |
efficient implementation over the |
implementation over the existing |
over the existing physical |
the existing physical infrastructure |
the concept is that |
concept is that processes |
is that processes publish |
that processes publish facts |
which are information about |
are information about milestones |
information about milestones they |
approaching the zettabyte era |
about milestones they have |
milestones they have reached |
cisco visual networking index |
and subscribe to new |
subscribe to new facts |
the ipc interface is |
ipc interface is similar |
interface is similar to |
is similar to topic |
but there are several |
there are several important |
are several important semantic |
several important semantic differences |
interface is as follows |
it will be the |
global mobile data traffic |
will be the publishers |
mobile data traffic forecast |
be the publishers that |
data traffic forecast update |
the publishers that actively |
publishers that actively try |
that actively try to |
actively try to push |
try to push new |
to push new facts |
push new facts to |
new facts to the |
facts to the subscribers |
paxos leaders publish new |
leaders publish new ballots |
publish new ballots and |
new ballots and push |
ballots and push these |
and push these to |
push these to acceptors |
these to acceptors as |
to acceptors as acceptors |
acceptors as acceptors do |
as acceptors do not |
acceptors do not necessarily |
do not necessarily know |
not necessarily know what |
necessarily know what the |
know what the set |
what the set of |
the set of leaders |
set of leaders is |
old ballots are automatically |
ballots are automatically dropped |
are automatically dropped from |
automatically dropped from the |
dropped from the transmission |
from the transmission queue |
it will be the |
will be the subscribers |
be the subscribers that |
the subscribers that actively |
subscribers that actively poll |
that actively poll the |
actively poll the publishers |
leaders and learners both |
and learners both subscribe |
learners both subscribe to |
both subscribe to acceptors |
subscribe to acceptors accepting |
to acceptors accepting pvalues |
acceptors accepting pvalues and |
accepting pvalues and poll |
pvalues and poll for |
and poll for these |
poll for these facts |
as subscribers that su |
subscribers that su ered |
that su ered communication |
su ered communication loss |
ered communication loss due |
multicast routing in datagram |
communication loss due to |
routing in datagram internetworks |
loss due to a |
in datagram internetworks and |
due to a network |
datagram internetworks and extended |
to a network partition |
internetworks and extended lans |
a network partition or |
network partition or having |
partition or having been |
or having been temporarily |
having been temporarily subscribe |
acm transactions on computer |
transactions on computer systems |
due to a user |
to a user closing |
a user closing a |
user closing a laptop |
will the interface requires |
the interface requires that |
interface requires that the |
requires that the fact |
that the fact type |
the fact type for |
fact type for a |
type for a par |
continue to poll publishers |
to poll publishers to |
poll publishers to receive |
publishers to receive facts |
to receive facts they |
receive facts they have |
facts they have ticular |
they have ticular topic |
have ticular topic is |
ticular topic is totally |
topic is totally ordered |
and those facts will |
those facts will missed |
all this is invisible |
this is invisible to |
is invisible to the |
invisible to the core |
to the core application |
the core application be |
core application be delivered |
application be delivered in |
be delivered in order |
any data can be |
data can be made |
can be made to |
but can be managed |
can be managed through |
be managed through the |
managed through the contally |
through the contally ordered |
the contally ordered by |
contally ordered by tagging |
ordered by tagging it |
by tagging it with |
tagging it with a |
it with a sequence |
with a sequence number |
the hope is that |
hope is that fact |
based ipc will simplify |
ipc will simplify disbut |
will simplify disbut often |
ordering transactions with prediction |
simplify disbut often times |
transactions with prediction in |
disbut often times facts |
with prediction in distributed |
often times facts such |
prediction in distributed object |
times facts such as |
in distributed object stores |
facts such as ballots |
distributed object stores ittay |
such as ballots are |
object stores ittay eyal |
as ballots are totally |
ballots are totally ortributed |
are totally ortributed programming |
totally ortributed programming and |
ortributed programming and make |
programming and make it |
and make it easier |
make it easier to |
it easier to reason |
easier to reason dered |
to reason dered already |
given a stream of |
a stream of facts |
stream of facts on |
of facts on some |
and analysis of a |
analysis of a peer |
facts on some topic |
about safety and liveness |
the argument for this |
argument for this is |
for this is only |
this is only the |
is only the highest |
department of computer science |
most recent fact need |
recent fact need be |
fact need be delivered |
need be delivered that |
be delivered that the |
delivered that the paradigm |
that the paradigm allows |
the paradigm allows the |
paradigm allows the programmer |
allows the programmer to |
the programmer to clearly |
programmer to clearly eventually |
while older facts can |
older facts can be |
facts can be dropped |
department of electrical engineering |
also specify transitions and |
specify transitions and under |
transitions and under which |
and under which conditions |
under which conditions they |
which conditions they di |
conditions they di erent |
they di erent from |
di erent from pub |
israel abstract numbers of |
abstract numbers of storage |
numbers of storage nodes |
if no more facts |
when client transactions access |
no more facts are |
client transactions access data |
more facts are enabled |
transactions access data on |
facts are enabled without |
access data on multiple |
are enabled without having |
data on multiple shards |
enabled without having to |
without having to worry |
having to worry much |
to worry much about |
worry much about how |
the issue of consistency |
much about how are |
issue of consistency arises |
about how are published |
how are published but |
are published but some |
published but some process |
but some process later |
some process later subscribes |
we would use a |
it these conditions are |
would use a system |
these conditions are discovered |
use a system with |
a system with acid |
system with acid transactions |
will eventually receive the |
eventually receive the most |
receive the most recent |
the most recent fact |
assuming both publisher and |
both publisher and subscriber |
publisher and subscriber are |
and subscriber are correct |
scaling virtual worlds with |
virtual worlds with a |
these semantics are similar |
semantics are similar to |
are similar to the |
similar to the anti |
worlds with a physical |
with a physical metaphor |
entropy style of gossip |
style of gossip protocols |
but the underlying implementation |
the underlying implementation can |
because this model facilitates |
underlying implementation can be |
this model facilitates reasoning |
implementation can be anything |
model facilitates reasoning about |
facilitates reasoning about system |
reasoning about system properties |
about system properties and |
system properties and makes |
there is also a |
properties and makes possible |
is also a control |
and makes possible a |
also a control interface |
makes possible a variety |
a control interface that |
possible a variety of |
control interface that controls |
a variety of highassurance |
interface that controls routing |
variety of highassurance guarantees |
that controls routing of |
controls routing of facts |
routing of facts for |
of facts for a |
facts for a particular |
for a particular topic |
the acid model is |
acid model is often |
model is often avoided |
is often avoided in |
often avoided in today |
avoided in today s |
paxos acceptors subscribe to |
in today s large |
acceptors subscribe to ballots |
subscribe to ballots and |
to ballots and to |
ballots and to new |
and to new proposals |
to new proposals from |
new proposals from leaders |
scale systems due to |
systems due to efficiency |
due to efficiency concerns |
when the leader publishes |
the leader publishes one |
leader publishes one of |
publishes one of these |
it is transmitted to |
is transmitted to all |
transmitted to all subscribers |
and the underlying communication |
the underlying communication layer |
underlying communication layer will |
communication layer will continue |
layer will continue retransmission |
existing approaches typically run |
will continue retransmission until |
approaches typically run transactions |
continue retransmission until either |
typically run transactions speculatively |
retransmission until either acknowledged |
run transactions speculatively and |
until either acknowledged or |
transactions speculatively and perform |
either acknowledged or another |
speculatively and perform certification |
acknowledged or another fact |
and perform certification after |
or another fact renders |
perform certification after they |
another fact renders it |
certification after they complete |
fact renders it obsolete |
after they complete to |
they complete to preserve |
complete to preserve consistency |
either committing or aborting |
committing or aborting each |
or aborting each transaction |
aborting each transaction depending |
each transaction depending on |
transaction depending on conflicts |
rain an architecture for |
an architecture for acid |
architecture for acid transactions |
for acid transactions in |
acid transactions in a |
transactions in a resilient |
in a resilient archive |
a resilient archive with |
resilient archive with independent |
archive with independent nodes |
the system orders transactions |
system orders transactions before |
orders transactions before they |
transactions before they begin |
before they begin by |
they begin by employing |
begin by employing predictors |
by employing predictors that |
employing predictors that estimate |
predictors that estimate the |
that estimate the set |
estimate the set of |
the set of objects |
set of objects each |
of objects each transaction |
objects each transaction will |
each transaction will access |
such predictors can be |
predictors can be implemented |
can be implemented with |
be implemented with machine |
implemented with machine learning |
with machine learning tools |
a transaction reserves a |
transaction reserves a version |
reserves a version of |
a version of each |
version of each object |
of each object it |
each object it will |
object it will use |
when later accessing the |
later accessing the objects |
it will see these |
will see these reserved |
see these reserved versions |
leases for future object |
for future object versions |
leases are issued for |
are issued for a |
issued for a predefined |
for a predefined time |
a predefined time period |
not the lease holder |
a platform for distributed |
platform for distributed service |
for distributed service deployment |
swift institute swift institute |
distributed service deployment in |
institute swift institute working |
may unilaterally decide to |
service deployment in end |
swift institute working paper |
unilaterally decide to ignore |
deployment in end user |
institute working paper no |
decide to ignore a |
to ignore a reservation |
in end user homes |
to run effectively at |
run effectively at large |
effectively at large scale |
rain must tolerate performance |
must tolerate performance hiccups |
all of which are |
of which are common |
which are common in |
are common in such |
common in such settings |
progress should never depend |
should never depend on |
never depend on the |
depend on the responsiveness |
on the responsiveness of |
the responsiveness of any |
responsiveness of any single |
of any single machine |
s dilemma ittay eyal |
dilemma ittay eyal publication |
ittay eyal publication date |
rain requires reliable entities |
requires reliable entities in |
reliable entities in cloud |
it is common to |
is common to shard |
data across large numbers |
across large numbers of |
large numbers of nodes |
electronic copy available at |
atomic transactions are typically |
transactions are typically implemented |
are typically implemented by |
typically implemented by running |
implemented by running transactions |
by running transactions speculatively |
and then certifying them |
aborting ones that cause |
ones that cause conflicts |
in high contention scenarios |
this approach has drawbacks |
rather than achieving any |
than achieving any substantial |
achieving any substantial level |
any substantial level of |
substantial level of concurrency |
it prevents concurrency by |
prevents concurrency by aborting |
concurrency by aborting all |
by aborting all but |
aborting all but one |
all but one of |
but one of the |
one of the contending |
of the contending transactions |
our work explores a |
work explores a new |
explores a new option |
the miner s dilemma |
miner s dilemma ittay |
s dilemma ittay eyal |
dilemma ittay eyal cornell |
ittay eyal cornell university |
ordering transactions in advance |
eyal cornell university abstract |
transactions in advance based |
cornell university abstract an |
in advance based on |
university abstract an open |
advance based on the |
abstract an open distributed |
based on the objects |
an open distributed system |
on the objects they |
open distributed system can |
the objects they are |
distributed system can be |
objects they are likely |
system can be secured |
they are likely to |
can be secured by |
are likely to access |
be secured by requiring |
secured by requiring participants |
by requiring participants to |
requiring participants to present |
participants to present proof |
providing acid transactions in |
to present proof of |
acid transactions in a |
present proof of work |
transactions in a resilient |
proof of work and |
in a resilient archive |
of work and rewarding |
a resilient archive with |
work and rewarding them |
resilient archive with independent |
and rewarding them for |
archive with independent nodes |
rewarding them for participation |
the bitcoin digital currency |
bitcoin digital currency introduced |
digital currency introduced this |
currency introduced this mechanism |
which is adopted by |
is adopted by almost |
adopted by almost all |
this preliminary ordering decreases |
by almost all contemporary |
preliminary ordering decreases abort |
ordering decreases abort rate |
almost all contemporary digital |
all contemporary digital currencies |
contemporary digital currencies and |
digital currencies and related |
currencies and related services |
and eliminates aborts in |
eliminates aborts in error |
a natural process leads |
natural process leads participants |
process leads participants of |
leads participants of such |
participants of such systems |
of such systems to |
such systems to form |
to allow fast recovery |
systems to form pools |
allow fast recovery from |
fast recovery from failures |
recovery from failures our |
from failures our scheme |
failures our scheme does |
our scheme does not |
where members aggregate their |
scheme does not introduce |
members aggregate their power |
does not introduce any |
not introduce any locks |
aggregate their power and |
their power and share |
power and share the |
and share the rewards |
the system consistency and |
system consistency and durability |
consistency and durability rely |
and durability rely on |
experience with bitcoin shows |
durability rely on a |
with bitcoin shows that |
rely on a single |
bitcoin shows that the |
on a single scalable |
shows that the largest |
a single scalable tier |
that the largest pools |
single scalable tier of |
scalable tier of highly |
the largest pools are |
largest pools are often |
pools are often open |
allowing anyone to join |
simulations using the transactional |
it has long been |
ycsb workloads show the |
has long been known |
workloads show the scalability |
long been known that |
show the scalability and |
been known that a |
the scalability and benefits |
known that a member |
scalability and benefits of |
that a member can |
and benefits of acidrain |
a member can sabotage |
member can sabotage an |
can sabotage an open |
sabotage an open pool |
an open pool by |
open pool by seemingly |
pool by seemingly joining |
by seemingly joining it |
seemingly joining it but |
joining it but never |
it but never sharing |
but never sharing its |
never sharing its proofs |
sharing its proofs of |
its proofs of work |
center computing systems often |
computing systems often maintain |
the pool shares its |
systems often maintain massive |
pool shares its revenue |
often maintain massive data |
shares its revenue with |
maintain massive data sets |
its revenue with the |
revenue with the attacker |
sharded over large this |
over large this work |
large this work was |
this work was funded |
and so each of |
so each of its |
each of its participants |
of its participants earns |
its participants earns less |
we define and analyze |
by grants from darpa |
define and analyze a |
and analyze a game |
analyze a game where |
a game where pools |
game where pools use |
where pools use some |
pools use some of |
use some of their |
and the elkin research |
some of their participants |
the elkin research fund |
of their participants to |
their participants to infiltrate |
participants to infiltrate other |
to infiltrate other pools |
infiltrate other pools and |
other pools and perform |
pools and perform such |
and perform such an |
perform such an attack |
only at a single |
at a single tier |
a single tier of |
single tier of the |
with any number of |
any number of pools |
tier of the system |
of the system a |
the system a set |
system a set of |
a set of independent |
set of independent highly |
of independent highly available |
independent highly available logs |
used in a novel |
in a novel manner |
attacks is not a |
is not a nash |
not a nash equilibrium |
all other entities may |
other entities may fail |
entities may fail and |
may fail and can |
we study the special |
fail and can be |
study the special cases |
and can be replaced |
the special cases where |
can be replaced instantly |
special cases where either |
be replaced instantly on |
cases where either two |
replaced instantly on failure |
where either two pools |
either two pools or |
two pools or any |
pools or any number |
the architecture maintains consistency |
or any number of |
architecture maintains consistency even |
any number of identical |
maintains consistency even in |
number of identical pools |
consistency even in the |
of identical pools play |
even in the event |
identical pools play the |
in the event of |
pools play the game |
the event of false |
play the game and |
event of false suspicion |
rx for data center |
the game and the |
for data center communication |
game and the rest |
data center communication scalability |
and the rest of |
the rest of the |
rest of the participants |
of the participants are |
the participants are uninvolved |
reservations serve as suggestions |
serve as suggestions a |
as suggestions a reservation |
suggestions a reservation that |
a reservation that is |
reservation that is not |
in both of these |
that is not used |
both of these cases |
is not used because |
of these cases there |
not used because of |
these cases there exists |
used because of a |
cases there exists an |
because of a sluggish |
there exists an equilibrium |
of a sluggish or |
exists an equilibrium that |
a sluggish or dead |
an equilibrium that constitutes |
sluggish or dead owner |
equilibrium that constitutes a |
or dead owner is |
that constitutes a tragedy |
dead owner is ignored |
constitutes a tragedy of |
a tragedy of the |
tragedy of the commons |
of the commons where |
the independence of system |
the commons where the |
independence of system elements |
commons where the participating |
of system elements allows |
where the participating pools |
system elements allows for |
the participating pools attack |
elements allows for good |
participating pools attack one |
allows for good scalability |
pools attack one another |
attack one another and |
one another and earn |
another and earn less |
and earn less than |
earn less than they |
less than they would |
than they would have |
they would have if |
would have if none |
have if none had |
due to the interdependence |
if none had attacked |
to the interdependence of |
the interdependence of the |
interdependence of the log |
of the log contents |
the decision whether or |
decision whether or not |
whether or not to |
or not to attack |
not to attack is |
to attack is the |
attack is the miner |
is the miner s |
the miner s dilemma |
has to be carefully |
to be carefully coordinated |
be carefully coordinated to |
carefully coordinated to maintain |
coordinated to maintain consistency |
an instance of the |
instance of the iterative |
of the iterative prisoner |
the iterative prisoner s |
iterative prisoner s dilemma |
we evaluate our architecture |
evaluate our architecture by |
our architecture by simulation |
architecture by simulation with |
by simulation with the |
the game is played |
simulation with the transactional |
game is played daily |
is played daily by |
played daily by the |
daily by the active |
by the active bitcoin |
the active bitcoin pools |
which apparently choose not |
apparently choose not to |
choose not to attack |
if this balance breaks |
the revenue of open |
revenue of open pools |
of open pools might |
open pools might diminish |
making them unattractive to |
we contrast the effectiveness |
them unattractive to participants |
contrast the effectiveness of |
the effectiveness of employing |
effectiveness of employing prediction |
of employing prediction and |
employing prediction and the |
prediction and the scalability |
and the scalability of |
the scalability of acid |
rain with other approaches |
live streaming with utilities |
is a digital currency |
a digital currency that |
digital currency that is |
tm m om i |
currency that is gaining |
that is gaining acceptance |
om n om i |
with an estimated market |
an estimated market capitalization |
estimated market capitalization of |
log i log n |
market capitalization of over |
i log n figure |
schematic structure of acid |
tms access multiple objects |
access multiple objects per |
multiple objects per transaction |
objects are managed by |
are managed by oms |
is falsely suspected to |
falsely suspected to have |
suspected to have failed |
an architecture for scalable |
architecture for scalable and |
for scalable and fault |
bitcoin s security stems |
and replaced by omi |
s security stems from |
security stems from a |
stems from a robust |
from a robust incentive |
a robust incentive system |
participants are required to |
are required to provide |
required to provide expensive |
to provide expensive proofs |
provide expensive proofs of |
expensive proofs of work |
causing them to concurrently |
them to concurrently serve |
and they are rewarded |
to concurrently serve the |
they are rewarded according |
concurrently serve the same |
serve the same objects |
are rewarded according to |
rewarded according to their |
according to their efforts |
oms are backed by |
are backed by highlyavailable |
backed by highlyavailable logs |
this architecture has proved |
architecture has proved both |
has proved both stable |
proved both stable and |
both stable and scalable |
where they store tentative |
they store tentative transaction |
store tentative transaction entries |
tentative transaction entries for |
transaction entries for serialization |
and it is used |
it is used by |
is used by most |
used by most contemporary |
by most contemporary digital |
most contemporary digital currencies |
contemporary digital currencies and |
digital currencies and related |
currencies and related services |
system structure the structure |
structure the structure of |
the structure of the |
structure of the system |
of the system is |
the system is illustrated |
system is illustrated in |
is illustrated in figure |
at the base of |
the base of acid |
rain are a set |
are a set of |
a set of independent |
set of independent highly |
available logs that together |
logs that together describe |
that together describe the |
together describe the state |
describe the state of |
the state of the |
state of the entire |
of the entire system |
each log is accessed |
log is accessed through |
is accessed through an |
accessed through an object |
through an object manager |
that caches the data |
caches the data and |
the data and provides |
data and provides the |
and provides the data |
provides the data structure |
the data structure abstraction |
data structure abstraction exporting |
structure abstraction exporting read |
abstraction exporting read and |
exporting read and write |
read and write operations |
our results apply to |
results apply to all |
apply to all such |
to all such incentive |
all such incentive systems |
which are managed by |
are managed by transaction |
managed by transaction managers |
but we use bitcoin |
we use bitcoin terminology |
use bitcoin terminology and |
bitcoin terminology and examples |
terminology and examples since |
and examples since it |
examples since it serves |
since it serves as |
it serves as an |
serves as an active |
as an active and |
tms provide the atomic |
an active and archetypal |
provide the atomic transaction |
active and archetypal example |
the atomic transaction abstraction |
bitcoin implements its incentive |
they receive instructions from |
implements its incentive systems |
receive instructions from clients |
its incentive systems with |
instructions from clients to |
incentive systems with a |
from clients to start |
systems with a data |
clients to start and |
with a data structure |
to start and end |
a data structure called |
start and end a |
data structure called the |
and end a transaction |
structure called the blockchain |
and operations to perform |
the blockchain is a |
operations to perform on |
blockchain is a serialization |
to perform on individual |
is a serialization of |
perform on individual objects |
a serialization of all |
on individual objects within |
serialization of all bitcoin |
individual objects within the |
of all bitcoin transactions |
objects within the transaction |
it is a single |
is a single global |
a single global ledger |
single global ledger maintained |
global ledger maintained by |
ledger maintained by an |
the tms predict which |
maintained by an open |
tms predict which objects |
by an open distributed |
predict which objects it |
an open distributed system |
which objects it is |
objects it is likely |
it is likely to |
is likely to access |
since anyone can join |
anyone can join the |
can join the open |
and reserve these object |
join the open system |
reserve these object versions |
the open system and |
open system and participate |
system and participate in |
and participate in maintaining |
participate in maintaining the |
in maintaining the blockchain |
they speculatively perform each |
bitcoin uses a proof |
speculatively perform each operation |
uses a proof of |
perform each operation with |
a proof of work |
each operation with the |
proof of work mechanism |
operation with the help |
of work mechanism to |
with the help of |
work mechanism to deter |
the help of the |
mechanism to deter attacks |
help of the appropriate |
of the appropriate oms |
the appropriate oms and |
appropriate oms and according |
oms and according to |
participation requires exerting significant |
and according to the |
requires exerting significant computational |
according to the order |
exerting significant computational resources |
to the order set |
transparent error correction for |
the order set by |
error correction for lambda |
order set by the |
correction for lambda networks |
a participant who proves |
set by the reservations |
for lambda networks mahesh |
participant who proves she |
lambda networks mahesh balakrishnan |
who proves she has |
proves she has exerted |
she has exerted enough |
has exerted enough resources |
exerted enough resources with |
they certify the transaction |
enough resources with a |
certify the transaction by |
resources with a proof |
the transaction by checking |
with a proof of |
transaction by checking for |
a proof of work |
by checking for conflicts |
proof of work is |
checking for conflicts in |
of work is allowed |
for conflicts in each |
work is allowed to |
conflicts in each log |
is allowed to take |
allowed to take a |
to take a step |
take a step in |
a step in the |
step in the protocol |
in the protocol by |
the protocol by generating |
protocol by generating a |
by generating a block |
membership monitors are in |
participants are compensated for |
monitors are in charge |
are compensated for their |
are in charge of |
compensated for their efforts |
in charge of deciding |
for their efforts with |
charge of deciding and |
their efforts with newly |
of deciding and publishing |
efforts with newly minted |
deciding and publishing which |
with newly minted bitcoins |
and publishing which machines |
publishing which machines perform |
which machines perform which |
machines perform which roles |
the process of creating |
process of creating a |
of creating a block |
creating a block is |
a block is called |
namely which machines run |
block is called mining |
which machines run the |
machines run the log |
run the log and |
the log and model |
log and model and |
and the participants miners |
and model and goal |
model and goal we |
and goal we assume |
goal we assume unreliable |
we assume unreliable servers |
in order to win |
assume unreliable servers that |
order to win the |
unreliable servers that may |
to win the reward |
servers that may crash |
that may crash or |
may crash or hang |
many miners try to |
miners try to generate |
try to generate blocks |
the system automatically adjusts |
system automatically adjusts the |
abstract the global network |
automatically adjusts the difficulty |
the global network of |
adjusts the difficulty of |
global network of datacenters |
the difficulty of block |
to accommodate reliable storage |
network of datacenters is |
difficulty of block generation |
of datacenters is emerging |
datacenters is emerging as |
is emerging as an |
emerging as an important |
as an important distributed |
such that one block |
an important distributed systems |
that one block is |
important distributed systems paradigm |
one block is added |
distributed systems paradigm commodity |
block is added every |
systems paradigm commodity clusters |
paradigm commodity clusters running |
as explained in section |
commodity clusters running high |
minutes to the blockchain |
this means that each |
means that each miner |
that each miner seldom |
each miner seldom generates |
miner seldom generates a |
seldom generates a block |
speed lambda networks across |
the system exposes a |
lambda networks across hundreds |
system exposes a transactional |
networks across hundreds of |
exposes a transactional data |
although its revenue may |
across hundreds of milliseconds |
a transactional data store |
its revenue may be |
hundreds of milliseconds of |
transactional data store supporting |
revenue may be positive |
of milliseconds of network |
data store supporting serializable |
may be positive in |
milliseconds of network latency |
store supporting serializable transactions |
be positive in expectation |
packet loss on long |
a client invokes a |
client invokes a begin |
a miner may have |
miner may have to |
may have to wait |
haul networks can cripple |
have to wait for |
networks can cripple application |
to wait for an |
can cripple application performance |
wait for an extended |
cripple application performance a |
for an extended period |
application performance a loss |
an extended period to |
performance a loss rate |
extended period to create |
a loss rate of |
period to create a |
to create a block |
create a block and |
a block and earn |
block and earn the |
and earn the actual |
earn the actual bitcoins |
a field from a |
field from a table |
miners form mining pools |
is sufficient to reduce |
sufficient to reduce tcp |
where all members mine |
all members mine concurrently |
members mine concurrently and |
ip throughput by an |
mine concurrently and they |
throughput by an order |
concurrently and they share |
by an order of |
and they share their |
setting the value of |
an order of magnitude |
they share their revenue |
the value of a |
order of magnitude on |
share their revenue whenever |
value of a field |
of magnitude on a |
their revenue whenever one |
of a field in |
revenue whenever one of |
a field in a |
field in a table |
whenever one of them |
one of them creates |
of them creates a |
them creates a block |
pools are typically implemented |
are typically implemented as |
finally the client invokes |
typically implemented as a |
the client invokes the |
implemented as a pool |
maelstrom is an edge |
client invokes the endtransaction |
as a pool manager |
is an edge appliance |
invokes the endtransaction command |
a pool manager and |
an edge appliance that |
pool manager and a |
edge appliance that masks |
manager and a cohort |
and the system responds |
appliance that masks packet |
and a cohort of |
a cohort of miners |
that masks packet loss |
the system responds with |
masks packet loss transparently |
system responds with either |
packet loss transparently and |
responds with either a |
the pool manager joins |
loss transparently and quickly |
with either a commit |
pool manager joins the |
transparently and quickly from |
either a commit or |
manager joins the bitcoin |
and quickly from inter |
a commit or an |
joins the bitcoin system |
commit or an abort |
the bitcoin system as |
bitcoin system as a |
system as a single |
as a single miner |
committed transactions form a |
transactions form a serializable |
aggregating traffic for high |
form a serializable execution |
instead of generating proof |
of generating proof of |
generating proof of work |
speed encoding and using |
encoding and using a |
tms are equipped with |
and using a new |
it outsources the work |
are equipped with predictors |
using a new forward |
outsources the work to |
equipped with predictors that |
a new forward error |
the work to the |
work to the miners |
new forward error correction |
with predictors that foresee |
forward error correction scheme |
predictors that foresee which |
error correction scheme to |
in order to evaluate |
that foresee which objects |
correction scheme to handle |
order to evaluate the |
foresee which objects a |
scheme to handle bursty |
to handle bursty loss |
which objects a transaction |
to evaluate the miners |
objects a transaction is |
evaluate the miners efforts |
a transaction is likely |
transaction is likely to |
is likely to access |
likely to access on |
to access on its |
access on its initiation |
the pool manager accepts |
introduction the emergence of |
pool manager accepts partial |
the emergence of commodity |
manager accepts partial proof |
emergence of commodity clusters |
accepts partial proof of |
of commodity clusters and |
partial proof of work |
commodity clusters and datacenters |
proof of work and |
clusters and datacenters has |
of work and estimates |
and datacenters has enabled |
work and estimates each |
datacenters has enabled a |
in an implementation of |
and estimates each miner |
has enabled a new |
an implementation of the |
estimates each miner s |
enabled a new class |
implementation of the system |
each miner s power |
a new class of |
of the system one |
miner s power according |
new class of globally |
the system one may |
s power according to |
class of globally distributed |
system one may use |
power according to the |
of globally distributed highperformance |
one may use multiple |
according to the rate |
globally distributed highperformance applications |
may use multiple oms |
to the rate with |
distributed highperformance applications that |
use multiple oms per |
the rate with which |
highperformance applications that coordinate |
multiple oms per log |
rate with which it |
applications that coordinate over |
with which it submits |
that coordinate over vast |
which it submits such |
coordinate over vast geographical |
dividing the log s |
it submits such partial |
over vast geographical distances |
the log s object |
submits such partial proof |
log s object set |
such partial proof of |
partial proof of work |
or the other way |
the other way around |
a financial firm s |
when a miner generates |
financial firm s new |
a miner generates a |
have multiple logs report |
firm s new york |
miner generates a full |
multiple logs report to |
s new york city |
generates a full proof |
logs report to a |
new york city datacenter |
a full proof of |
full proof of work |
york city datacenter may |
report to a single |
to a single om |
city datacenter may receive |
datacenter may receive real |
it sends it to |
sends it to the |
it to the pool |
the choice depends on |
to the pool manager |
choice depends on the |
time updates from a |
the pool manager which |
depends on the throughput |
updates from a stock |
pool manager which publishes |
on the throughput of |
from a stock exchange |
manager which publishes this |
the throughput of the |
a stock exchange in |
which publishes this proof |
throughput of the specific |
stock exchange in switzerland |
publishes this proof of |
of the specific implementations |
this proof of work |
the specific implementations chosen |
proof of work to |
specific implementations chosen for |
conduct financial transactions with |
of work to the |
implementations chosen for each |
financial transactions with banks |
work to the bitcoin |
to the bitcoin system |
transactions with banks in |
with banks in asia |
chosen for each service |
the pool manager thus |
pool manager thus receives |
in this paper we |
cache data in london |
manager thus receives the |
this paper we use |
paper we use a |
thus receives the full |
data in london for |
receives the full revenue |
in london for locality |
the full revenue of |
london for locality and |
full revenue of the |
for locality and mirror |
revenue of the block |
locality and mirror it |
of the block and |
and mirror it to |
the block and distributes |
mapping for simplicity of |
mirror it to kansas |
block and distributes it |
for simplicity of presentation |
it to kansas for |
and distributes it fairly |
to kansas for disaster |
distributes it fairly according |
it fairly according to |
we now describe the |
fairly according to its |
now describe the operation |
according to its members |
describe the operation of |
to its members power |
the operation of acid |
to interconnect these bandwidth |
many of the pools |
of the pools are |
hungry datacenters across the |
datacenters across the globe |
the pools are open |
we start with an |
pools are open they |
start with an overview |
are open they allow |
with an overview of |
organizations are increasingly deploying |
open they allow any |
an overview of the |
are increasingly deploying private |
they allow any miner |
overview of the system |
increasingly deploying private lambda |
allow any miner to |
of the system s |
deploying private lambda networks |
any miner to join |
the system s structure |
miner to join them |
system s structure in |
to join them using |
s structure in section |
join them using a |
them using a public |
using a public internet |
a public internet interface |
such open pools are |
open pools are susceptible |
pools are susceptible to |
are susceptible to the |
susceptible to the classical |
to the classical block |
the classical block withholding |
classical block withholding attack |
and proceed to describe |
proceed to describe the |
to describe the algorithm |
describe the algorithm in |
the algorithm in section |
raw bandwidth is ubiquitous |
bandwidth is ubiquitous and |
is ubiquitous and cheaply |
ubiquitous and cheaply available |
and cheaply available in |
cheaply available in the |
available in the form |
in the form of |
the form of existing |
form of existing dark |
of existing dark fiber |
where a miner sends |
a miner sends only |
miner sends only partial |
om for each shard |
sends only partial proof |
only partial proof of |
partial proof of work |
proof of work to |
of work to the |
and which tms are |
which tms are available |
work to the pool |
running and maintaining high |
to the pool manager |
the pool manager and |
pool manager and discards |
any client can access |
manager and discards full |
client can access any |
and discards full proof |
can access any tm |
discards full proof of |
access any tm for |
free networks over this |
full proof of work |
any tm for any |
networks over this fiber |
tm for any given |
over this fiber is |
for any given transaction |
due to the partial |
this fiber is difficult |
to the partial proof |
fiber is difficult and |
the partial proof of |
is difficult and expensive |
other than the logs |
partial proof of work |
proof of work it |
of work it sends |
work it sends to |
it sends to the |
sends to the pool |
server role assignment may |
role assignment may be |
assignment may be inconsistent |
capacity optical links are |
optical links are almost |
links are almost never |
are almost never congested |
the miner is considered |
miner is considered a |
is considered a regular |
considered a regular pool |
a regular pool member |
they drop packets for |
regular pool member and |
drop packets for numerous |
pool member and the |
is supposed to be |
packets for numerous reasons |
member and the pool |
supposed to be managed |
for numerous reasons dirty |
and the pool can |
to be managed by |
the pool can estimate |
be managed by a |
pool can estimate its |
managed by a single |
can estimate its power |
by a single om |
the attacker shares the |
attacker shares the revenue |
shares the revenue obtained |
the revenue obtained by |
revenue obtained by the |
obtained by the other |
by the other pool |
the other pool members |
at a given time |
but does not contribute |
but this may change |
this may change due |
may change due to |
it reduces the revenue |
change due to an |
reduces the revenue of |
due to an unjustified |
the revenue of the |
to an unjustified crash |
revenue of the other |
an unjustified crash suspicion |
of the other members |
unjustified crash suspicion whereupon |
crash suspicion whereupon an |
suspicion whereupon an object |
but also its own |
we provide necessary background |
provide necessary background on |
necessary background on the |
background on the bitcoin |
on the bitcoin protocol |
pools and the classical |
may temporarily be managed |
and the classical block |
temporarily be managed by |
the classical block withholding |
be managed by two |
classical block withholding attack |
managed by two oms |
block withholding attack in |
withholding attack in section |
attack in section ii |
and specify our model |
specify our model in |
our model in section |
model in section iii |
for example and in |
example and in different |
and in different patterns |
for a broader view |
a broader view of |
that do not know |
ranging from singleton drops |
broader view of the |
do not know of |
from singleton drops to |
view of the protocol |
not know of one |
singleton drops to extended |
of the protocol and |
know of one another |
drops to extended bursts |
the protocol and ecosystem |
protocol and ecosystem the |
and ecosystem the reader |
ecosystem the reader may |
the reader may refer |
reader may refer to |
may refer to the |
refer to the survey |
to the survey by |
rain uses log servers |
the survey by bonneau |
uses log servers for |
survey by bonneau et |
by bonneau et al |
log servers for reliable |
servers for reliable storage |
each log server provides |
log server provides a |
server provides a sequentially |
provides a sequentially consistent |
a sequentially consistent log |
sequentially consistent log object |
congestion loss has been |
loss has been observed |
in this work we |
has been observed on |
update operations are linearizable |
this work we analyze |
been observed on long |
work we analyze block |
we analyze block withholding |
analyze block withholding attacks |
but reads may return |
block withholding attacks among |
reads may return outdated |
haul networks as well |
withholding attacks among pools |
may return outdated results |
a pool that employs |
pool that employs the |
that employs the pool |
employs the pool block |
multiple machines may append |
the pool block withholding |
machines may append entries |
pool block withholding attack |
may append entries to |
block withholding attack registers |
append entries to a |
entries to a log |
withholding attack registers with |
attack registers with the |
registers with the victim |
with the victim pool |
the victim pool as |
victim pool as a |
machines may register to |
pool as a regular |
as a regular miner |
may register to the |
register to the log |
it receives tasks from |
the log then sends |
receives tasks from the |
log then sends to |
tasks from the victim |
then sends to each |
from the victim pool |
sends to each all |
the victim pool and |
to each all entries |
victim pool and transfers |
pool and transfers them |
and transfers them to |
transfers them to some |
them to some of |
from the first one |
to some of its |
the first one in |
some of its own |
of its own miners |
first one in the |
one in the log |
we call these infiltrating |
call these infiltrating miners |
and then new entries |
and the mining power |
then new entries as |
the mining power spent |
new entries as they |
mining power spent by |
entries as they arrive |
power spent by a |
spent by a pool |
by a pool the |
a pool the infiltration |
pool the infiltration rate |
an om may instruct |
om may instruct the |
may instruct the log |
instruct the log to |
the log to truncate |
when electronic copy available |
log to truncate its |
electronic copy available at |
to truncate its prefix |
algorithm we now describe |
we now describe the |
now describe the acid |
ms w n s |
we explain the reservation |
w n s e |
explain the reservation and |
n s e figure |
the reservation and certification |
reservation and certification protocol |
example lambda network tional |
lambda network tional lambdarail |
then discuss prediction errors |
the attacking pool s |
attacking pool s infiltrating |
pool s infiltrating miners |
s infiltrating miners deliver |
infiltrating miners deliver partial |
miners deliver partial proofs |
a transaction begins with |
deliver partial proofs of |
partial proofs of work |
transaction begins with the |
begins with the tm |
with the tm receiving |
the tm receiving a |
tm receiving a begin |
the attacker transfers them |
attacker transfers them to |
transfers them to the |
them to the victim |
to the victim pool |
transaction instruction from the |
instruction from the client |
letting the attacked pool |
the attacked pool estimate |
the tm assigns it |
attacked pool estimate their |
tm assigns it a |
pool estimate their power |
assigns it a unique |
it a unique txnid |
when the infiltrating miners |
the infiltrating miners deliver |
and predicts which objects |
infiltrating miners deliver a |
predicts which objects the |
miners deliver a full |
which objects the transaction |
as has its crippling |
deliver a full proof |
objects the transaction will |
has its crippling effect |
a full proof of |
full proof of work |
its crippling effect on |
the transaction will access |
crippling effect on commodity |
effect on commodity protocols |
the attacking pool discards |
attacking pool discards it |
it interrogates the oms |
interrogates the oms about |
motivating research into loss |
the oms about all |
oms about all these |
about all these objects |
this attack affects the |
attack affects the revenues |
resistant data transfer protocols |
affects the revenues of |
the revenues of the |
and they respond with |
revenues of the pools |
they respond with the |
of the pools in |
respond with the latest |
the pools in several |
pools in several ways |
with the latest unreserved |
the latest unreserved timestamp |
latest unreserved timestamp of |
unreserved timestamp of each |
timestamp of each object |
the victim pool s |
victim pool s effective |
pool s effective mining |
s effective mining rate |
effective mining rate is |
the tm chooses a |
mining rate is unchanged |
tm chooses a timestamp |
chooses a timestamp larger |
a timestamp larger than |
timestamp larger than maximum |
larger than maximum among |
than maximum among the |
but its total revenue |
maximum among the responses |
its total revenue is |
total revenue is divided |
revenue is divided among |
is divided among more |
divided among more miners |
and asks the oms |
asks the oms to |
the oms to reserve |
oms to reserve the |
to reserve the objects |
the attacker s mining |
reserve the objects with |
attacker s mining power |
the objects with this |
s mining power is |
objects with this timestamp |
mining power is reduced |
with this timestamp to |
this timestamp to txnid |
since some of its |
some of its miners |
of its miners are |
the oms confirm the |
its miners are used |
oms confirm the reservation |
miners are used for |
confirm the reservation if |
are used for block |
the reservation if no |
used for block withholding |
reservation if no concurrent |
if no concurrent tm |
no concurrent tm has |
concurrent tm has reserved |
tm has reserved a |
but it earns additional |
has reserved a larger |
it earns additional revenue |
reserved a larger timestamp |
earns additional revenue through |
conservative flow control mechanisms |
a larger timestamp in |
additional revenue through its |
flow control mechanisms designed |
larger timestamp in the |
revenue through its infiltration |
control mechanisms designed to |
timestamp in the meantime |
through its infiltration of |
mechanisms designed to deal |
its infiltration of the |
designed to deal with |
infiltration of the other |
of the other pool |
to deal with the |
the tm then proceeds |
deal with the systematic |
tm then proceeds to |
with the systematic congestion |
then proceeds to serve |
the systematic congestion of |
proceeds to serve transaction |
systematic congestion of the |
the total effective mining |
to serve transaction operations |
congestion of the commodity |
total effective mining power |
serve transaction operations by |
of the commodity internet |
effective mining power in |
transaction operations by routing |
the commodity internet react |
mining power in the |
operations by routing them |
commodity internet react too |
power in the system |
by routing them to |
internet react too sharply |
in the system is |
routing them to the |
react too sharply to |
the system is reduced |
them to the appropriate |
too sharply to ephemeral |
to the appropriate oms |
sharply to ephemeral loss |
to ephemeral loss on |
ephemeral loss on over |
causing the bitcoin protocol |
the bitcoin protocol to |
bitcoin protocol to reduce |
each operation is sent |
protocol to reduce the |
operation is sent to |
to reduce the difficulty |
provisioned links a single |
is sent to the |
links a single packet |
sent to the om |
a single packet loss |
to the om in |
taking all these factors |
single packet loss in |
the om in charge |
all these factors into |
packet loss in ten |
om in charge of |
these factors into account |
loss in ten thousand |
in charge of the |
in ten thousand is |
charge of the object |
ten thousand is enough |
we observe that a |
thousand is enough to |
observe that a pool |
is enough to reduce |
that a pool might |
enough to reduce tcp |
a pool might be |
pool might be able |
might be able to |
be able to increase |
able to increase its |
ip throughput to a |
to increase its revenue |
an example flow of |
throughput to a third |
increase its revenue by |
example flow of the |
to a third over |
its revenue by attacking |
flow of the algorithm |
a third over a |
revenue by attacking other |
by attacking other pools |
along with the txnid |
each pool therefore makes |
pool therefore makes a |
the oms order accesses |
therefore makes a choice |
oms order accesses based |
makes a choice of |
order accesses based on |
a choice of whether |
and one in a |
accesses based on timestamp |
choice of whether to |
one in a thousand |
based on timestamp reservations |
of whether to attack |
in a thousand drops |
whether to attack each |
a thousand drops it |
to attack each of |
thousand drops it by |
and respond only when |
attack each of the |
drops it by an |
respond only when the |
each of the other |
it by an order |
only when the correct |
of the other pools |
by an order of |
when the correct version |
the other pools in |
an order of magnitude |
the correct version is |
other pools in the |
correct version is available |
pools in the system |
each committed transaction is |
and with what infiltration |
committed transaction is assigned |
time applications are impacted |
with what infiltration rate |
transaction is assigned a |
applications are impacted by |
is assigned a timestamp |
are impacted by the |
impacted by the reliance |
this gives rise to |
by the reliance of |
gives rise to the |
when reading an object |
the reliance of reliability |
rise to the pool |
reliance of reliability mechanisms |
to the pool game |
of reliability mechanisms on |
the timestamp of the |
reliability mechanisms on acknowledgments |
timestamp of the latest |
mechanisms on acknowledgments and |
of the latest transaction |
we specify this game |
on acknowledgments and retransmissions |
the latest transaction that |
specify this game and |
latest transaction that wrote |
this game and provide |
transaction that wrote this |
game and provide initial |
limiting the latency of |
that wrote this object |
and provide initial analysis |
the latency of packet |
wrote this object is |
provide initial analysis in |
latency of packet recovery |
this object is returned |
initial analysis in section |
of packet recovery to |
object is returned to |
analysis in section iv |
packet recovery to at |
is returned to the |
recovery to at least |
returned to the tm |
to at least the |
in section v we |
at least the round |
section v we analyze |
least the round trip |
v we analyze the |
the transaction s timestamp |
the round trip time |
we analyze the scenario |
transaction s timestamp is |
analyze the scenario where |
s timestamp is chosen |
the scenario where exactly |
timestamp is chosen to |
scenario where exactly two |
is chosen to be |
where exactly two of |
chosen to be larger |
exactly two of the |
to be larger than |
two of the pools |
if delivery is sequenced |
be larger than the |
of the pools take |
larger than the largest |
the pools take part |
than the largest timestamp |
pools take part in |
each lost packet acts |
the largest timestamp returned |
take part in the |
lost packet acts as |
largest timestamp returned by |
part in the game |
packet acts as a |
timestamp returned by its |
in the game and |
acts as a virtual |
returned by its operations |
the game and only |
as a virtual road |
game and only one |
and only one can |
only one can attack |
and not larger than |
one can attack the |
can attack the other |
not larger than its |
block in the fifo |
larger than its reserved |
in the fifo channel |
than its reserved timestamp |
the fifo channel until |
fifo channel until it |
channel until it is |
until it is recovered |
the attacker can always |
attacker can always increase |
can always increase its |
always increase its revenue |
increase its revenue by |
its revenue by attacking |
resistant protocols is not |
once a tm receives |
we conclude that in |
protocols is not an |
a tm receives an |
tm receives an end |
is not an alternative |
conclude that in the |
not an alternative in |
that in the general |
an alternative in corporate |
in the general case |
transaction instruction from a |
alternative in corporate datacenters |
instruction from a client |
with any number of |
any number of pools |
where standardization is the |
it notifies the transaction |
standardization is the key |
notifies the transaction s |
is the key to |
the transaction s oms |
the key to low |
key to low and |
to low and predictable |
low and predictable maintenance |
and predictable maintenance costs |
detailing the transaction s |
attacks is not a |
the transaction s timestamp |
is not a nash |
transaction s timestamp and |
not a nash equilibrium |
nei this work was |
s timestamp and log |
this work was supported |
work was supported in |
was supported in part |
supported in part by |
in part by grants |
part by grants from |
by grants from afosr |
section vi deals with |
vi deals with the |
deals with the case |
the logs in charge |
with the case of |
logs in charge of |
the case of two |
case of two pools |
in charge of the |
ther is eliminating loss |
charge of the shards |
is eliminating loss events |
of the shards it |
where each can attack |
eliminating loss events on |
the shards it touched |
each can attack the |
can attack the other |
loss events on a |
events on a network |
on a network that |
a network that could |
network that could nsf |
that could nsf and |
could nsf and intel |
nsf and intel corporation |
when it receives such |
it receives such a |
receives such a notification |
analysis becomes more complicated |
becomes more complicated in |
more complicated in two |
span thousands of miles |
complicated in two ways |
an om appends to |
om appends to its |
appends to its log |
to its log an |
its log an entry |
log an entry consisting |
an entry consisting of |
entry consisting of the |
consisting of the txnid |
there is a need |
is a need to |
the revenue of each |
a need to link |
revenue of each pool |
need to link loss |
of each pool affects |
each pool affects the |
pool affects the revenue |
affects the revenue of |
the revenue of the |
revenue of the other |
of the other through |
the other through the |
other through the infiltrating |
through the infiltrating miners |
such logs may be |
logs may be implemented |
may be implemented with |
side appliance locations of |
be implemented with various |
we prove that for |
appliance locations of packet |
implemented with various techniques |
prove that for a |
locations of packet loss |
that for a static |
of packet loss receive |
for a static choice |
from smr to log |
a static choice of |
smr to log chains |
static choice of infiltration |
side appliance receiver buffer |
choice of infiltration rates |
appliance receiver buffer overflow |
of infiltration rates the |
infiltration rates the pool |
rates the pool revenues |
the pool revenues converge |
local recovery receiving end |
once one pool changes |
one pool changes its |
pool changes its infiltration |
changes its infiltration rate |
its infiltration rate of |
infiltration rate of the |
rate of the other |
the latter may prefer |
kernel code no dropped |
latter may prefer to |
code no dropped packets |
may prefer to change |
no dropped packets figure |
we abstract this write |
prefer to change its |
to change its infiltration |
change its infiltration rate |
its infiltration rate of |
infiltration rate of the |
rate of the former |
maelstrom communication path mask |
communication path mask loss |
therefore the game itself |
path mask loss on |
the game itself takes |
mask loss on the |
loss on the link |
game itself takes multiple |
set with the read |
itself takes multiple rounds |
with the read timestamps |
takes multiple rounds to |
multiple rounds to converge |
we show analytically that |
show analytically that the |
because recovery delays for |
analytically that the game |
and assume highly available |
assume highly available logs |
that the game has |
recovery delays for lost |
the game has a |
delays for lost packets |
game has a single |
for lost packets translate |
has a single nash |
lost packets translate into |
set with written values |
a single nash equilibrium |
packets translate into dramatic |
single nash equilibrium and |
translate into dramatic reductions |
nash equilibrium and numerically |
into dramatic reductions in |
equilibrium and numerically study |
dramatic reductions in application |
and numerically study the |
numerically study the equilibrium |
study the equilibrium points |
the equilibrium points for |
equilibrium points for different |
points for different pool |
for different pool sizes |
for pools smaller than |
action should be either |
should be either committed |
because applications and os |
be either committed or |
applications and os networking |
either committed or aborted |
and os networking stacks |
committed or aborted in |
os networking stacks in |
or aborted in all |
networking stacks in commodity |
aborted in all its |
stacks in commodity datacenters |
in all its logs |
in commodity datacenters cannot |
commodity datacenters cannot be |
at the equilibrium point |
datacenters cannot be rewritten |
the equilibrium point both |
cannot be rewritten from |
and therefore cannot be |
equilibrium point both pools |
be rewritten from scratch |
therefore cannot be removed |
point both pools earn |
cannot be removed from |
both pools earn less |
be removed from any |
pools earn less than |
removed from any of |
earn less than they |
from any of them |
less than they would |
any of them before |
than they would have |
of them before the |
they would have in |
is a promising solution |
them before the result |
would have in the |
a promising solution for |
before the result is |
have in the nonequilibrium |
promising solution for reliability |
the result is published |
in the nonequilibrium no |
solution for reliability over |
for reliability over long |
the committing tm appends |
committing tm appends a |
tm appends a gc |
appends a gc entry |
since pools can decide |
a gc entry to |
pools can decide to |
gc entry to all |
can decide to start |
entry to all the |
decide to start or |
to all the transaction |
to start or stop |
all the transaction s |
packet recovery latency is |
start or stop attacking |
the transaction s logs |
recovery latency is independent |
or stop attacking at |
transaction s logs after |
latency is independent of |
stop attacking at any |
attacking at any point |
is independent of the |
s logs after receiving |
independent of the rtt |
of the rtt of |
logs after receiving an |
the rtt of the |
rtt of the link |
after receiving an acknowledgement |
this can be modeled |
receiving an acknowledgement that |
can be modeled as |
an acknowledgement that they |
be modeled as the |
acknowledgement that they all |
modeled as the miner |
that they all registered |
as the miner s |
they all registered the |
the miner s dilemma |
all registered the transaction |
miner s dilemma an |
registered the transaction s |
s dilemma an instance |
the transaction s result |
dilemma an instance of |
an instance of the |
instance of the iterative |
of the iterative prisoner |
the iterative prisoner s |
iterative prisoner s dilemma |
an om can invoke |
om can invoke log |
can invoke log prefix |
while fec codes have |
invoke log prefix truncation |
attacking is the dominant |
is the dominant strategy |
fec codes have been |
log prefix truncation if |
the dominant strategy in |
dominant strategy in each |
codes have been used |
strategy in each iteration |
prefix truncation if the |
truncation if the prefix |
have been used for |
but if the pools |
if the prefix was |
the prefix was summarized |
been used for decades |
if the pools can |
and all its transactions |
used for decades within |
the pools can agree |
all its transactions have |
its transactions have corresponding |
pools can agree not |
can agree not to |
for decades within link |
transactions have corresponding gc |
agree not to attack |
have corresponding gc entries |
both benefit in the |
benefit in the long |
in the long run |
then waits for the |
waits for the entry |
for the entry to |
the entry to appear |
entry to appear in |
to appear in the |
appear in the log |
we address in section |
a transaction is committed |
address in section vii |
transaction is committed if |
in section vii the |
is committed if and |
section vii the case |
committed if and only |
vii the case where |
if and only if |
the case where the |
and only if it |
case where the participants |
only if it is |
where the participants are |
if it is written |
the participants are an |
participants are an arbitrary |
it is written to |
is written to all |
faster commodity processors have |
are an arbitrary number |
written to all logs |
commodity processors have enabled |
an arbitrary number of |
arbitrary number of identical |
processors have enabled packet |
number of identical pools |
and it does not |
it does not conflict |
does not conflict with |
not conflict with previous |
conflict with previous transactions |
with previous transactions on |
previous transactions on any |
transactions on any of |
on any of them |
there exists a symmetric |
exists a symmetric equilibrium |
a symmetric equilibrium in |
symmetric equilibrium in which |
conflicts are violations of |
level fec at end |
are violations of read |
equilibrium in which each |
in which each participating |
which each participating pool |
each participating pool attacks |
participating pool attacks each |
pool attacks each of |
attacks each of the |
each of the other |
of the other participating |
the other participating pools |
read or writewrite order |
as in the minority |
in the minority two |
each om checks for |
om checks for local |
checks for local conflicts |
for local conflicts by |
local conflicts by checking |
here too at equilibrium |
conflicts by checking timestamps |
too at equilibrium all |
by checking timestamps in |
at equilibrium all pools |
checking timestamps in the |
equilibrium all pools earn |
timestamps in the prefix |
all pools earn less |
in the prefix of |
pools earn less than |
the prefix of the |
earn less than with |
prefix of the log |
less than with the |
of the log up |
than with the no |
the log up to |
log up to the |
up to the transaction |
to the transaction entry |
and sends its local |
sends its local result |
our results imply that |
results imply that block |
imply that block withholding |
that block withholding by |
block withholding by pools |
withholding by pools leads |
by pools leads to |
pools leads to an |
leads to an unfavorable |
to the calling tm |
to an unfavorable equilibrium |
if all return success |
then the transaction has |
the transaction has committed |
due to the anonymity |
to the anonymity of |
the anonymity of miners |
otherwise it has aborted |
a single pool might |
single pool might be |
pool might be tempted |
might be tempted to |
the tm notifies the |
be tempted to attack |
tm notifies the client |
notifies the client of |
the client of the |
client of the transaction |
of the transaction result |
leading the other pools |
the transaction result and |
the other pools to |
transaction result and instructs |
other pools to attack |
result and instructs the |
pools to attack as |
and instructs the oms |
to attack as well |
instructs the oms to |
the oms to place |
oms to place this |
to place this result |
place this result in |
this result in the |
the implications might be |
result in the logs |
implications might be devastating |
might be devastating for |
be devastating for open |
devastating for open pools |
the oms notify the |
oms notify the tm |
notify the tm once |
the tm once the |
tm once the results |
if their revenues are |
their revenues are reduced |
once the results are |
the results are logged |
miners will prefer to |
will prefer to form |
robustness in case of |
prefer to form closed |
in case of a |
to form closed pools |
case of a tm |
form closed pools that |
of a tm or |
closed pools that cannot |
a tm or om |
tm or om crash |
pools that cannot be |
that cannot be attacked |
cannot be attacked in |
be attacked in this |
attacked in this manner |
or a missing result |
a missing result or |
missing result or gc |
result or gc entry |
though this may be |
this may be conceived |
may be conceived as |
be conceived as bad |
conceived as bad news |
as bad news for |
bad news for public |
news for public mining |
for public mining pools |
due to message loss |
on the whole it |
the whole it may |
whole it may be |
it may be good |
may be good news |
be good news to |
another tm may read |
tm may read the |
end fec is very |
good news to the |
news to the bitcoin |
to the bitcoin system |
fec is very attractive |
may read the transaction |
read the transaction entry |
which prefers small pools |
is very attractive for |
the transaction entry in |
transaction entry in one |
very attractive for inter |
entry in one of |
we examine the practicality |
in one of the |
one of the logs |
examine the practicality of |
the practicality of the |
practicality of the attack |
of the attack in |
the attack in section |
attack in section viii |
in section viii and |
section viii and discuss |
viii and discuss implications |
and discuss implications and |
discuss implications and model |
implications and model extensions |
and model extensions in |
and continue the certification |
model extensions in section |
continue the certification and |
extensions in section ix |
the certification and gc |
certification and gc process |
if a tm places |
a tm places a |
tm places a transaction |
our contributions are the |
places a transaction entry |
contributions are the following |
a transaction entry in |
transaction entry in a |
entry in a strict |
in a strict subset |
a strict subset of |
strict subset of the |
subset of the transaction |
of the transaction s |
the transaction s log |
transaction s log set |
when another tm is |
definition of the pool |
another tm is instructed |
tm is instructed to |
easy to deploy and |
of the pool game |
is instructed to fix |
instructed to fix this |
to deploy and customize |
the pool game where |
it cannot tell whether |
pool game where pools |
cannot tell whether the |
game where pools in |
tell whether the original |
where pools in a |
pools in a proof |
whether the original tm |
the original tm is |
original tm is crashed |
tm is crashed or |
is crashed or slow |
ofwork secured system attack |
secured system attack one |
system attack one another |
attack one another with |
one another with a |
another with a pool |
with a pool block |
a pool block withholding |
and does not require |
pool block withholding attack |
we introduce poison entries |
does not require specialized |
the fixing tm places |
fixing tm places a |
tm places a poison |
places a poison entry |
a poison entry in |
poison entry in the |
not require specialized equipment |
in the general case |
entry in the logs |
in the logs that |
require specialized equipment in |
the logs that miss |
logs that miss the |
specialized equipment in the |
that miss the original |
miss the original entry |
equipment in the network |
attacks is not an |
is not an equilibrium |
in the network linking |
a poison is interpreted |
poison is interpreted as |
is interpreted as a |
interpreted as a transaction |
as a transaction entry |
a transaction entry with |
transaction entry with a |
entry with a conflict |
with two minority pools |
two minority pools participating |
the network linking the |
the original entry may |
original entry may either |
the only nash equilibrium |
only nash equilibrium is |
entry may either arrive |
may either arrive eventually |
network linking the datacenters |
nash equilibrium is when |
either arrive eventually or |
equilibrium is when the |
arrive eventually or not |
is when the pools |
when the pools attack |
the pools attack one |
pools attack one another |
and both earn less |
both earn less than |
earn less than if |
less than if none |
than if none had |
if none had attacked |
and the following are |
the following are ignored |
miners therefore face the |
therefore face the miner |
face the miner s |
the miner s dilemma |
any tm can therefore |
tm can therefore observe |
can therefore observe the |
therefore observe the log |
observe the log and |
an instance of the |
the log and consistently |
instance of the iterative |
log and consistently determine |
of the iterative prisoner |
and consistently determine the |
the iterative prisoner s |
consistently determine the state |
iterative prisoner s dilemma |
determine the state of |
the state of the |
state of the transaction |
repeatedly choosing between attack |
choosing between attack and |
between attack and no |
without a race hazard |
host fec has two |
fec has two major |
prediction errors if there |
errors if there are |
has two major issues |
if there are no |
there are no prediction |
two major issues first |
are no prediction errors |
with multiple pools of |
multiple pools of equal |
pools of equal size |
of equal size there |
equal size there is |
size there is a |
there is a symmetric |
is a symmetric nash |
a symmetric nash equilibrium |
where all pools earn |
there are no aborts |
all pools earn less |
pools earn less than |
earn less than if |
less than if none |
if the transaction accesses |
than if none had |
if none had attacked |
it s not transparent |
the transaction accesses an |
transaction accesses an object |
accesses an object that |
an object that was |
object that was not |
that was not predicted |
this object has no |
object has no reserved |
has no reserved version |
no reserved version for |
reserved version for it |
inefficient equilibria for open |
requiring modification of the |
equilibria for open pools |
accessing it can therefore |
it can therefore result |
for open pools may |
open pools may serve |
can therefore result in |
therefore result in a |
pools may serve the |
may serve the system |
result in a conflict |
in a conflict of |
serve the system by |
the system by reducing |
a conflict of the |
conflict of the transaction |
system by reducing their |
by reducing their attraction |
of the transaction or |
the transaction or of |
reducing their attraction and |
their attraction and pushing |
transaction or of the |
or of the following |
modification of the end |
of the following ones |
attraction and pushing miners |
and pushing miners towards |
pushing miners towards smaller |
miners towards smaller closed |
towards smaller closed pools |
the classical block withholding |
classical block withholding attack |
block withholding attack is |
withholding attack is as |
attack is as old |
no conflict would occur |
is as old as |
as old as pools |
old as pools themselves |
but if one does |
if one does it |
one does it will |
but its use by |
does it will be |
its use by pools |
it will be detected |
use by pools has |
will be detected at |
by pools has not |
be detected at certification |
pools has not been |
detected at certification time |
has not been suggested |
not been suggested until |
been suggested until recently |
and result in an |
result in an abort |
in an abort of |
an abort of a |
abort of a transaction |
we overview related attacks |
overview related attacks and |
related attacks and prior |
attacks and prior work |
and prior work in |
prior work in section |
work in section x |
performance may be slightly |
may be slightly reduced |
and conclude with final |
conclude with final remarks |
but consistency is maintained |
with final remarks in |
final remarks in section |
remarks in section xi |
if a transaction does |
a transaction does not |
transaction does not access |
does not access an |
not access an object |
access an object that |
it s not necessarily |
an object that was |
object that was predicted |
s not necessarily rapid |
p reliminaries b itcoin |
the tm must still |
reliminaries b itcoin and |
tm must still release |
b itcoin and p |
must still release the |
itcoin and p ooled |
still release the reservation |
and p ooled m |
release the reservation when |
p ooled m ining |
the reservation when the |
ooled m ining bitcoin |
reservation when the transaction |
m ining bitcoin is |
fec works best over |
when the transaction ends |
ining bitcoin is a |
bitcoin is a distributed |
works best over high |
this reservation might slow |
reservation might slow the |
might slow the processing |
slow the processing of |
the processing of other |
processing of other transactions |
of other transactions that |
other transactions that wait |
transactions that wait for |
that wait for its |
wait for its release |
but would not break |
would not break consistency |
stable traffic rates and |
if a tm is |
a tm is suspected |
traffic rates and performs |
tm is suspected as |
is suspected as failed |
rates and performs poorly |
its reservations are revoked |
and performs poorly if |
this may harm performance |
performs poorly if the |
poorly if the data |
but cannot break consistency |
if the data rate |
the data rate in |
data rate in the |
evaluation we evaluate acid |
rate in the channel |
in the channel is |
rain by comparing its |
the channel is low |
by comparing its performance |
channel is low and |
comparing its performance to |
is low and sporadic |
its performance to the |
clients use the system |
performance to the classical |
use the system by |
to the classical approach |
the system by issuing |
the classical approach that |
system by issuing transactions |
classical approach that does |
approach that does not |
that does not use |
does not use prediction |
not use prediction and |
use prediction and compare |
and the system s |
prediction and compare its |
the system s only |
and compare its certification |
system s only task |
compare its certification protocol |
s only task is |
its certification protocol with |
only task is to |
certification protocol with other |
task is to serialize |
protocol with other certification |
is to serialize transactions |
with other certification schemes |
to serialize transactions in |
serialize transactions in a |
transactions in a single |
in a single ledger |
we use a custom |
a single ledger and |
single ledger and reject |
ledger and reject transactions |
and reject transactions that |
reject transactions that cannot |
transactions that cannot be |
that cannot be serialized |
cannot be serialized due |
be serialized due to |
serialized due to conflicts |
due to conflicts with |
to conflicts with previous |
conflicts with previous transactions |
simulating each of the |
each of the agents |
of the agents in |
the agents in the |
agents in the system |
in the system clients |
bitcoin transactions are protected |
transactions are protected with |
are protected with cryptographic |
protected with cryptographic techniques |
with cryptographic techniques that |
cryptographic techniques that ensure |
techniques that ensure that |
that ensure that only |
ensure that only the |
that only the rightful |
as in a single |
only the rightful owner |
our workloads are an |
workloads are an adaptation |
in a single end |
the rightful owner of |
are an adaptation of |
rightful owner of a |
an adaptation of the |
owner of a bitcoin |
adaptation of the transactional |
of a bitcoin can |
of the transactional ycsb |
a bitcoin can transfer |
bitcoin can transfer it |
the transactional ycsb specification |
the transaction ledger is |
transaction ledger is stored |
ledger is stored by |
is stored by a |
stored by a network |
by a network of |
a network of miners |
network of miners in |
of miners in a |
miners in a data |
in a data structure |
a data structure caller |
data structure caller the |
structure caller the blockchain |
based on the original |
revenue for proof of |
for proof of work |
proof of work the |
of work the blockchain |
work the blockchain records |
the blockchain records the |
blockchain records the transactions |
records the transactions in |
the transactions in units |
transactions in units of |
in units of blocks |
dubbed the genesis block |
is defined as part |
defined as part of |
as part of the |
part of the protocol |
each transaction has a |
we present the maelstrom |
transaction has a set |
a valid block contains |
has a set of |
a set of read |
valid block contains the |
block contains the hash |
present the maelstrom error |
contains the hash of |
update operations spread along |
the hash of the |
hash of the previous |
the maelstrom error correction |
operations spread along its |
of the previous block |
spread along its execution |
maelstrom error correction appliance |
the hash of the |
object accesses follow one |
hash of the transactions |
of the transactions in |
error correction appliance a |
accesses follow one of |
the transactions in the |
transactions in the current |
correction appliance a rack |
follow one of two |
in the current block |
appliance a rack of |
one of two different |
and a bitcoin address |
a bitcoin address which |
of two different random |
two different random distributions |
a rack of proxies |
bitcoin address which is |
rack of proxies residing |
address which is to |
of proxies residing between |
which is to be |
is to be credited |
to be credited with |
be credited with a |
where each object is |
credited with a reward |
with a reward for |
proxies residing between a |
each object is chosen |
a reward for generating |
reward for generating the |
residing between a datacenter |
object is chosen uniformly |
for generating the block |
between a datacenter and |
is chosen uniformly at |
chosen uniformly at random |
a datacenter and its |
any miner may add |
miner may add a |
datacenter and its wan |
may add a valid |
add a valid block |
and its wan link |
a valid block to |
valid block to the |
gc logs are truncated |
block to the chain |
to the chain by |
logs are truncated to |
are truncated to conserve |
truncated to conserve resources |
to conserve resources and |
conserve resources and to |
resources and to reduce |
and to reduce log |
to reduce log replay |
reduce log replay time |
log replay time on |
replay time on om |
time on om recovery |
proving that it has |
that it has spent |
it has spent a |
has spent a certain |
each om occasionally summarizes |
spent a certain amount |
om occasionally summarizes the |
a certain amount of |
occasionally summarizes the log |
certain amount of work |
summarizes the log prefix |
amount of work and |
of work and publishing |
work and publishing the |
and publishing the block |
and places this summary |
publishing the block with |
places this summary in |
the block with the |
this summary in the |
block with the proof |
summary in the log |
with the proof over |
the proof over an |
proof over an overlay |
over an overlay network |
an overlay network to |
overlay network to all |
network to all other |
to all other miners |
the presence of a |
presence of a summary |
when a miner creates |
of a summary of |
a miner creates a |
a summary of the |
miner creates a block |
summary of the log |
of the log up |
the log up to |
log up to a |
up to a certain |
it is compensated for |
to a certain entry |
is compensated for its |
a certain entry is |
compensated for its efforts |
certain entry is not |
for its efforts with |
its efforts with bitcoins |
maelstrom encodes fec packets |
entry is not sufficient |
this compensation includes a |
compensation includes a per |
encodes fec packets over |
is not sufficient to |
transaction fee paid by |
not sufficient to allow |
sufficient to allow truncation |
fec packets over traffic |
fee paid by the |
to allow truncation at |
allow truncation at that |
truncation at that entry |
packets over traffic flowing |
paid by the users |
this reason is that |
by the users electronic |
the users electronic copy |
over traffic flowing through |
reason is that truncation |
users electronic copy available |
electronic copy available at |
traffic flowing through it |
is that truncation must |
flowing through it and |
that truncation must not |
through it and routes |
truncation must not break |
it and routes them |
must not break transaction |
and routes them to |
not break transaction certification |
routes them to a |
them to a corresponding |
to a corresponding appliance |
prediction our first test |
our first test scenario |
first test scenario imposes |
test scenario imposes a |
scenario imposes a load |
imposes a load substantially |
a load substantially below |
load substantially below the |
substantially below the system |
a corresponding appliance at |
below the system s |
the system s capacity |
system s capacity with |
corresponding appliance at the |
appliance at the destination |
at the destination datacenter |
whose transactions are included |
each transaction reads and |
transaction reads and writes |
and an amount of |
an amount of minted |
amount of minted bitcoins |
of minted bitcoins that |
minted bitcoins that are |
bitcoins that are thus |
that are thus introduced |
are thus introduced into |
thus introduced into the |
introduced into the system |
which decodes them and |
the simulation is faithful |
the work which a |
work which a miner |
simulation is faithful to |
is faithful to the |
decodes them and recovers |
which a miner is |
faithful to the algorithm |
them and recovers lost |
a miner is required |
miner is required to |
with the exception of |
the exception of a |
is required to do |
required to do is |
exception of a small |
of a small shortcut |
to do is to |
do is to repeatedly |
a small shortcut oms |
small shortcut oms grant |
is to repeatedly calculate |
to repeatedly calculate a |
shortcut oms grant reservations |
oms grant reservations by |
repeatedly calculate a a |
calculate a a hash |
grant reservations by arrival |
reservations by arrival time |
a a hash function |
a hash function specifically |
by arrival time rather |
arrival time rather than |
and recovers lost data |
hash function specifically the |
time rather than by |
function specifically the sha |
rather than by timestamp |
this results in deadlocks |
results in deadlocks in |
in deadlocks in high |
deadlocks in high contention |
in high contention scenarios |
and these are resolved |
these are resolved with |
are resolved with timeouts |
maelstrom is completely transparent |
first we vary prediction |
we vary prediction accuracy |
is completely transparent it |
completely transparent it does |
transparent it does not |
of a block header |
it does not require |
does not require modification |
to indicate that he |
the average ratio of |
average ratio of objects |
indicate that he has |
that he has performed |
not require modification of |
he has performed this |
has performed this work |
require modification of end |
ratio of objects the |
the miner provides a |
of objects the predictor |
miner provides a probabilistic |
objects the predictor guesses |
provides a probabilistic proof |
the predictor guesses out |
a probabilistic proof as |
predictor guesses out of |
probabilistic proof as follows |
guesses out of the |
out of the set |
of the set the |
the set the transaction |
set the transaction eventually |
the transaction eventually accesses |
the generated block has |
generated block has a |
block has a nonce |
has a nonce field |
host software and is |
software and is agnostic |
is equivalent to no |
and is agnostic to |
which can contain any |
can contain any value |
is agnostic to the |
equivalent to no prediction |
to no prediction and |
the miner places different |
miner places different values |
no prediction and no |
prediction and no reservation |
agnostic to the network |
places different values in |
different values in this |
values in this field |
in this field and |
this field and calculates |
field and calculates the |
and calculates the hash |
calculates the hash for |
the hash for each |
hash for each value |
to the network connecting |
and an accuracy of |
the network connecting the |
if the result of |
the result of the |
result of the hash |
of the hash is |
the hash is smaller |
hash is smaller than |
is smaller than a |
smaller than a target |
than a target value |
network connecting the datacenter |
means predicting all accesses |
the nonce is considered |
nonce is considered a |
is considered a solution |
and the block is |
the block is valid |
the number of attempts |
number of attempts to |
of attempts to find |
attempts to find a |
to find a single |
find a single hash |
a single hash is |
single hash is therefore |
hash is therefore random |
is therefore random with |
therefore random with a |
random with a geometric |
with a geometric distribution |
as each attempt is |
each attempt is a |
attempt is a bernoulli |
is a bernoulli trial |
it eliminates the dependence |
increasing contention by decreasing |
eliminates the dependence of |
a bernoulli trial with |
the dependence of fec |
contention by decreasing the |
dependence of fec recovery |
bernoulli trial with a |
by decreasing the number |
decreasing the number of |
of fec recovery latency |
trial with a success |
the number of objects |
fec recovery latency on |
with a success probability |
a success probability determined |
success probability determined by |
probability determined by the |
determined by the target |
by the target value |
recovery latency on the |
latency on the data |
load with a hot |
at the existing huge |
the existing huge hashing |
existing huge hashing rates |
huge hashing rates and |
hashing rates and small |
rates and small target |
and small target values |
on the data rate |
the data rate in |
the time to find |
time to find a |
to find a single |
find a single hash |
a single hash can |
single hash can be |
data rate in any |
hash can be approximated |
can be approximated by |
rate in any single |
be approximated by an |
approximated by an exponential |
in any single node |
by an exponential distribution |
the average time for |
average time for a |
time for a miner |
for a miner to |
a miner to find |
increasing contention by increasing |
miner to find a |
contention by increasing the |
by increasing the hot |
to find a solution |
find a solution is |
a solution is therefore |
solution is therefore proportional |
is therefore proportional to |
therefore proportional to its |
proportional to its hashing |
to its hashing rate |
its hashing rate or |
hashing rate or mining |
rate or mining power |
commit rate drops as |
to maintain a constant |
rate drops as contention |
node channel by encoding |
maintain a constant rate |
drops as contention rises |
channel by encoding over |
a constant rate of |
constant rate of bitcoin |
rate of bitcoin generation |
by encoding over the |
accurate prediction reduces or |
and as part of |
encoding over the aggregated |
prediction reduces or even |
as part of its |
part of its defense |
reduces or even eliminates |
or even eliminates this |
over the aggregated traffic |
of its defense against |
even eliminates this drop |
the aggregated traffic leaving |
its defense against denial |
defense against denial of |
aggregated traffic leaving the |
against denial of service |
in highest contention scenarios |
traffic leaving the datacenter |
denial of service and |
even with moderate prediction |
with moderate prediction accuracy |
of service and other |
service and other attacks |
we obtain significant improvement |
obtain significant improvement over |
the system normalizes the |
significant improvement over the |
system normalizes the rate |
improvement over the classical |
normalizes the rate of |
over the classical approach |
the rate of block |
rate of block generation |
the protocol deterministically defines |
protocol deterministically defines the |
deterministically defines the target |
defines the target value |
the target value for |
maelstrom uses a new |
target value for each |
value for each block |
uses a new encoding |
we define slack to |
for each block according |
each block according to |
define slack to be |
slack to be the |
block according to the |
according to the time |
a new encoding scheme |
to be the average |
to the time required |
the time required to |
new encoding scheme called |
be the average ratio |
time required to generate |
required to generate recent |
encoding scheme called layered |
the average ratio between |
to generate recent blocks |
scheme called layered interleaving |
average ratio between the |
ratio between the number |
between the number of |
the number of accesses |
number of accesses predicted |
of accesses predicted and |
accesses predicted and the |
predicted and the number |
and the number of |
is updated once every |
the number of objects |
number of objects accessed |
of objects accessed by |
objects accessed by the |
accessed by the transaction |
designed especially for time |
if a transaction accesses |
blocks such that the |
such that the average |
that the average time |
the average time for |
average time for each |
time for each block |
for each block to |
then with a slack |
each block to be |
with a slack of |
sensitive packet recovery in |
block to be found |
to be found is |
packet recovery in the |
recovery in the presence |
in the presence of |
the presence of bursty |
it would reserve another |
note that the exponential |
presence of bursty loss |
that the exponential distribution |
the exponential distribution is |
exponential distribution is memoryless |
if all miners mine |
all miners mine for |
miners mine for block |
mine for block number |
for block number b |
now with uniform random |
with uniform random load |
uniform random load and |
random load and a |
once the block is |
the contributions of this |
load and a variable |
the block is found |
block is found at |
contributions of this paper |
and a variable number |
is found at time |
found at time t |
of this paper are |
a variable number of |
variable number of objects |
this paper are as |
all miners switch to |
the effect of using |
paper are as follows |
miners switch to mine |
effect of using a |
switch to mine for |
of using a perfect |
to mine for the |
using a perfect predictor |
mine for the subsequent |
for the subsequent block |
the subsequent block b |
at t without changing |
t without changing their |
without changing their probability |
changing their probability distribution |
their probability distribution of |
with predictors that overpredict |
probability distribution of finding |
predictors that overpredict by |
distribution of finding a |
that overpredict by factors |
of finding a block |
overpredict by factors of |
finding a block after |
a block after t |
the probability that a |
the impact of overprediction |
probability that a miner |
impact of overprediction is |
that a miner i |
of overprediction is surprisingly |
overprediction is surprisingly minor |
end fec for long |
a miner i with |
a finding that should |
miner i with mining |
i with mining power |
with mining power mi |
mining power mi finds |
power mi finds the |
mi finds the next |
finds the next block |
the next block is |
next block is its |
block is its ratio |
is its ratio out |
its ratio out of |
ratio out of the |
out of the total |
of the total mining |
the total mining power |
total mining power m |
mining power m in |
power m in the |
distance communication between datacenters |
m in the system |
ordering transactions in advance |
miner miner miner pool |
transactions in advance reduces |
in advance reduces conflicts |
advance reduces conflicts and |
reduces conflicts and increases |
conflicts and increases commit |
and increases commit ratio |
miner miner miner pool |
and argue that the |
high conflict rates occur |
argue that the rate |
conflict rates occur without |
rates occur without with |
that the rate sensitivity |
occur without with uniform |
without with uniform access |
with uniform access to |
uniform access to a |
access to a small |
to a small number |
a small number of |
small number of objects |
the rate sensitivity of |
rate sensitivity of fec |
sensitivity of fec codes |
and high probability of |
high probability of accessing |
probability of accessing a |
of accessing a hotzone |
of fec codes and |
fec codes and the |
codes and the opacity |
and the opacity of |
the opacity of their |
even inaccurate prediction is |
and one miner mines |
one miner mines solo |
opacity of their implementations |
inaccurate prediction is significant |
prediction is significant in |
is significant in high |
significant in high contention |
of their implementations present |
pools datacenters are built |
datacenters are built around |
compared to the the |
to the the classical |
their implementations present major |
the the classical approach |
are built around the |
built around the world |
implementations present major obstacles |
present major obstacles to |
major obstacles to their |
obstacles to their usage |
commit ratio is affected |
ratio is affected if |
is affected if the |
mining is only profitable |
affected if the predictor |
is only profitable using |
if the predictor reserves |
only profitable using dedicated |
the predictor reserves unnecessary |
profitable using dedicated hardware |
predictor reserves unnecessary objects |
using dedicated hardware in |
reserves unnecessary objects by |
dedicated hardware in cutting |
unnecessary objects by a |
a gateway appliance that |
hardware in cutting edge |
in cutting edge mining |
cutting edge mining rigs |
gateway appliance that transparently |
objects by a factor |
by a factor of |
appliance that transparently aggregates |
otherwise the energy costs |
the energy costs exceed |
energy costs exceed the |
costs exceed the expected |
exceed the expected revenue |
a factor of slack |
that transparently aggregates traffic |
transparently aggregates traffic and |
although expected revenue from |
expected revenue from mining |
revenue from mining is |
from mining is proportional |
mining is proportional to |
is proportional to the |
proportional to the power |
to the power of |
the power of the |
note that when all |
power of the mining |
of the mining rigs |
the mining rigs used |
aggregates traffic and encodes |
that when all accesses |
when all accesses are |
a single home miner |
single home miner using |
all accesses are to |
accesses are to the |
are to the hot |
to the hot zone |
traffic and encodes over |
home miner using a |
miner using a small |
using a small rig |
a small rig is |
small rig is unlikely |
rig is unlikely to |
and encodes over the |
is unlikely to mine |
unlikely to mine a |
to mine a block |
mine a block for |
a block for years |
encodes over the resulting |
over the resulting high |
commit rates are lower |
rates are lower with |
are lower with imperfect |
lower with imperfect prediction |
with imperfect prediction than |
imperfect prediction than in |
prediction than in the |
than in the uniform |
in the uniform random |
the uniform random case |
uniform random case with |
miners often organize themselves |
often organize themselves into |
organize themselves into mining |
themselves into mining pools |
we describe layered interleaving |
a pool is a |
pool is a group |
is a group of |
a group of miners |
group of miners that |
of miners that share |
miners that share their |
a new fec scheme |
that share their revenues |
share their revenues when |
their revenues when one |
revenues when one of |
when one of them |
one of them successfully |
of them successfully mines |
them successfully mines a |
successfully mines a block |
new fec scheme used |
fec scheme used by |
for each block found |
scheme used by maelstrom |
this is because all |
is because all accesses |
because all accesses to |
all accesses to the |
accesses to the hot |
the revenue is distributed |
revenue is distributed among |
is distributed among the |
distributed among the pool |
zone go through a |
used by maelstrom where |
among the pool members |
by maelstrom where for |
go through a single |
maelstrom where for constant |
the pool members in |
where for constant encoding |
through a single om |
for constant encoding overhead |
pool members in proportion |
constant encoding overhead the |
a single om that |
members in proportion to |
in proportion to their |
single om that becomes |
om that becomes a |
that becomes a bottleneck |
encoding overhead the latency |
proportion to their mining |
on the bright side |
overhead the latency of |
to their mining power |
since object access conflicts |
object access conflicts occur |
access conflicts occur only |
conflicts occur only at |
occur only at a |
only at a single |
at a single shard |
the latency of packet |
the expected revenue of |
the reservations prevent deadlocks |
reservations prevent deadlocks and |
expected revenue of a |
revenue of a pool |
prevent deadlocks and result |
deadlocks and result in |
of a pool member |
a pool member is |
and result in perfect |
result in perfect commit |
pool member is therefore |
member is therefore the |
in perfect commit ratio |
perfect commit ratio with |
latency of packet recovery |
is therefore the same |
commit ratio with perfect |
ratio with perfect prediction |
of packet recovery degrades |
therefore the same as |
the same as its |
same as its revenue |
as its revenue had |
its revenue had it |
revenue had it mined |
packet recovery degrades gracefully |
had it mined solo |
recovery degrades gracefully as |
where some of the |
some of the objects |
of the objects belong |
degrades gracefully as losses |
due to the large |
the objects belong to |
objects belong to a |
gracefully as losses get |
to the large power |
belong to a so |
to a so called |
a so called hot |
as losses get burstier |
the large power of |
large power of the |
power of the pool |
and each access is |
each access is either |
access is either to |
it finds blocks at |
is either to the |
either to the hot |
finds blocks at a |
blocks at a much |
at a much higher |
a much higher rate |
we discuss implementation considerations |
and so the frequency |
or outside of it |
so the frequency of |
the frequency of revenue |
frequency of revenue collection |
of revenue collection is |
revenue collection is higher |
chosen uniformly within each |
uniformly within each zone |
we built two versions |
allowing for a stable |
for a stable daily |
a stable daily or |
stable daily or weekly |
daily or weekly income |
built two versions of |
we set an average |
set an average transaction |
an average transaction per |
average transaction per unit |
two versions of maelstrom |
most pools are controlled |
pools are controlled by |
are controlled by a |
controlled by a centralized |
by a centralized pool |
a centralized pool manager |
one runs in user |
and transactions arrivals are |
transactions arrivals are governed |
miners register with the |
register with the pool |
arrivals are governed by |
are governed by a |
with the pool manager |
the pool manager and |
governed by a poisson |
by a poisson process |
pool manager and mine |
manager and mine on |
and mine on its |
mine on its behalf |
runs in user mode |
a poisson process with |
poisson process with the |
process with the required |
the pool manager generates |
with the required tput |
pool manager generates tasks |
manager generates tasks and |
generates tasks and the |
tasks and the miners |
and the miners search |
the miners search for |
miners search for solutions |
search for solutions based |
for solutions based on |
solutions based on these |
based on these tasks |
we are unaware of |
on these tasks that |
these tasks that can |
are unaware of work |
unaware of work that |
tasks that can serve |
that can serve as |
of work that uses |
work that uses prediction |
can serve as proof |
serve as proof of |
while the other runs |
as proof of work |
that uses prediction to |
uses prediction to order |
prediction to order distributed |
to order distributed transactions |
once they find a |
they find a solution |
the other runs within |
order distributed transactions before |
they send it to |
other runs within the |
distributed transactions before certification |
send it to the |
it to the pool |
runs within the linux |
to the pool manager |
within the linux kernel |
the pool manager behaves |
pool manager behaves as |
manager behaves as a |
behaves as a single |
as a single miner |
a single miner in |
single miner in the |
uses static analysis to |
miner in the bitcoin |
in the bitcoin system |
static analysis to allow |
analysis to allow separate |
to allow separate workers |
allow separate workers to |
once it obtains a |
separate workers to process |
workers to process independent |
it obtains a legitimate |
obtains a legitimate block |
to process independent transactions |
process independent transactions without |
a legitimate block from |
legitimate block from one |
independent transactions without synchronization |
we evaluate maelstrom on |
block from one of |
from one of its |
one of its miners |
evaluate maelstrom on emulab |
rain s suggestive prediction |
gargamel determines the final |
the block transfers the |
determines the final transaction |
block transfers the revenue |
the final transaction order |
transfers the revenue to |
the revenue to the |
revenue to the control |
to the control of |
the control of the |
control of the pool |
of the pool manager |
and does not tolerate |
does not tolerate false |
not tolerate false positive |
tolerate false positive prediction |
false positive prediction errors |
the pool manager then |
pool manager then distributes |
manager then distributes the |
then distributes the revenue |
distributes the revenue among |
the revenue among the |
revenue among the miners |
among the miners according |
the miners according to |
it targets a different |
miners according to their |
targets a different setting |
according to their mining |
a different setting than |
to their mining power |
different setting than acid |
the architecture is illustrated |
architecture is illustrated in |
is illustrated in figure |
and show that it |
it is a fully |
is a fully replicated |
in order to estimate |
order to estimate the |
a fully replicated data |
fully replicated data store |
to estimate the mining |
estimate the mining power |
the mining power of |
mining power of a |
power of a miner |
show that it provides |
with a centralized scheduler |
the pool manager sets |
pool manager sets a |
manager sets a partial |
sets a partial target |
that it provides near |
a partial target for |
partial target for each |
target for each member |
it provides near lossless |
for an increasing number |
an increasing number of |
increasing number of shards |
provides near lossless tcp |
we run multiple simulations |
run multiple simulations to |
multiple simulations to find |
simulations to find the |
to find the maximal |
find the maximal tput |
the maximal tput the |
maximal tput the system |
tput the system can |
the system can handle |
ip throughput and latency |
than the target of |
a global log forms |
global log forms a |
log forms a bottleneck |
throughput and latency over |
the target of the |
target of the bitcoin |
of the bitcoin system |
and latency over lossy |
pc with smr tms |
with smr tms is |
smr tms is blocked |
each miner is required |
latency over lossy links |
tms is blocked by |
miner is required to |
is blocked by contention |
is required to send |
blocked by contention much |
required to send the |
by contention much earlier |
to send the pool |
contention much earlier than |
send the pool manager |
much earlier than acid |
the pool manager blocks |
and recovers packets with |
pool manager blocks that |
recovers packets with latency |
rain due to its |
packets with latency independent |
manager blocks that are |
due to its longer |
to its longer certification |
its longer certification time |
with latency independent of |
blocks that are correct |
we briefly review here |
that are correct according |
are correct according to |
briefly review here work |
review here work related |
correct according to the |
according to the partial |
to the partial target |
latency independent of the |
here work related to |
the partial target is |
work related to acidrain |
related to acidrain s |
partial target is chosen |
target is chosen to |
is chosen to be |
chosen to be large |
independent of the rtt |
to acidrain s certification |
acidrain s certification protocol |
such that partial solutions |
of the rtt of |
that partial solutions arrive |
one approach for certification |
approach for certification is |
partial solutions arrive frequently |
solutions arrive frequently enough |
for certification is to |
certification is to use |
arrive frequently enough for |
frequently enough for the |
is to use a |
to use a single |
use a single highly |
the rtt of the |
enough for the manager |
available service that orders |
for the manager to |
the manager to accurately |
service that orders all |
that orders all transactions |
manager to accurately estimate |
to accurately estimate the |
orders all transactions in |
all transactions in the |
accurately estimate the power |
estimate the power of |
the power of the |
power of the miner |
transactions in the system |
rtt of the link |
of the link and |
the link and the |
link and the rate |
and the rate in |
the rate in any |
to reduce management overhead |
rate in any single |
in any single channel |
as the value of |
the value of bitcoin |
value of bitcoin rose |
bitcoin mining has become |
mining has become a |
has become a rapidly |
become a rapidly advancing |
a rapidly advancing industry |
technological advancements lead to |
advancements lead to ever |
a transaction commits if |
lead to ever more |
transaction commits if and |
to ever more efficient |
commits if and only |
ever more efficient hashing |
if and only if |
more efficient hashing asics |
and only if it |
only if it has |
if it has no |
model our focus is |
it has no conflicts |
our focus is on |
has no conflicts with |
no conflicts with previous |
conflicts with previous committed |
with previous committed transactions |
focus is on pairs |
is on pairs of |
on pairs of geographically |
pairs of geographically distant |
this is a simplification |
is a simplification that |
a simplification that is |
simplification that is sufficient |
that is sufficient for |
is sufficient for our |
sufficient for our analysis |
of geographically distant datacenters |
transaction rate is high |
the intricacies of reward |
intricacies of reward systems |
of reward systems are |
reward systems are explained |
systems are explained in |
such a global service |
a global service becomes |
global service becomes a |
service becomes a bottleneck |
geographically distant datacenters that |
distant datacenters that coordinate |
datacenters that coordinate with |
our system has no |
system has no such |
has no such bottleneck |
that coordinate with each |
coordinate with each other |
with each other in |
each other in real |
a notable exception is |
notable exception is p |
serialized all transactions when |
all transactions when they |
transactions when they enter |
when they enter the |
they enter the system |
enter the system to |
the system to achieve |
system to achieve a |
to achieve a deterministic |
achieve a deterministic order |
this has long been |
despite nondeterministic operations the |
which we discuss in |
we discuss in section |
discuss in section ix |
has long been a |
nondeterministic operations the transactions |
forks block propagation in |
operations the transactions take |
long been a critical |
block propagation in the |
propagation in the overlay |
in the overlay network |
been a critical distributed |
the overlay network takes |
they consider only stored |
consider only stored procedures |
overlay network takes seconds |
a critical distributed computing |
which enable this approach |
therefore it is possible |
it is possible for |
is possible for two |
possible for two distant |
whereas we address long |
for two distant miners |
two distant miners to |
we address long running |
address long running transactions |
distant miners to generate |
miners to generate competing |
to generate competing blocks |
critical distributed computing paradigm |
long running transactions and |
both of which name |
running transactions and use |
transactions and use prediction |
of which name the |
which name the same |
and use prediction to |
use prediction to infer |
prediction to infer an |
to infer an order |
distributed computing paradigm in |
name the same block |
the same block as |
same block as their |
block as their predecessor |
computing paradigm in application |
paradigm in application domains |
in application domains such |
application domains such as |
domains such as finance |
such as finance and |
are rare since the |
transactions are also serialized |
are also serialized by |
rare since the average |
since the average mining |
also serialized by a |
serialized by a central |
the average mining interval |
average mining interval is |
by a central service |
as finance and aerospace |
and then scheduled according |
then scheduled according to |
scheduled according to this |
according to this global |
to this global order |
and they occur on |
they occur on average |
occur on average once |
on average once every |
rain avoids a central |
avoids a central service |
similar requirements are arising |
requirements are arising across |
are arising across the |
arising across the board |
across the board as |
targets a different problem |
the board as globalized |
the system has a |
system has a mechanism |
has a mechanism to |
a mechanism to solve |
mechanism to solve forks |
to solve forks when |
solve forks when they |
forks when they do |
board as globalized enterprises |
when they do occur |
where it embraces non |
as globalized enterprises rely |
causing one of the |
one of the blocks |
determinism and separates execution |
and separates execution from |
of the blocks to |
the blocks to be |
blocks to be discarded |
globalized enterprises rely on |
separates execution from verification |
we ignore bifurcations for |
enterprises rely on networks |
ignore bifurcations for the |
the result is somewhat |
bifurcations for the sake |
for the sake of |
the sake of simplicity |
rely on networks for |
result is somewhat analogous |
since the choice of |
is somewhat analogous to |
somewhat analogous to our |
the choice of the |
choice of the discarded |
analogous to our separation |
to our separation of |
of the discarded block |
the discarded block on |
our separation of optimistic |
separation of optimistic ordering |
discarded block on bifurcation |
block on bifurcation is |
on bifurcation is random |
on networks for high |
of optimistic ordering and |
optimistic ordering and conservative |
one may incorporate this |
ordering and conservative certification |
may incorporate this event |
incorporate this event into |
this event into the |
event into the probability |
into the probability of |
the probability of finding |
make it easier to |
probability of finding a |
it easier to create |
of finding a block |
speed communication and collaboration |
easier to create a |
and consider instead the |
to create a practical |
consider instead the probability |
create a practical predictor |
instead the probability of |
the probability of finding |
probability of finding a |
of finding a block |
finding a block that |
a block that is |
certification scalability to evaluate |
block that is not |
scalability to evaluate the |
that is not discarded |
to evaluate the scalability |
evaluate the scalability of |
the scalability of acid |
pools often charge a |
often charge a small |
charge a small percentage |
rain s certification mechanism |
the most general case |
a small percentage of |
we avoid prediction and |
small percentage of the |
percentage of the revenue |
of the revenue as |
the revenue as fee |
avoid prediction and measure |
prediction and measure the |
and measure the maximal |
measure the maximal commit |
we discuss in section |
most general case of |
the maximal commit rate |
discuss in section ix |
in section ix the |
maximal commit rate it |
commit rate it can |
section ix the implications |
ix the implications of |
rate it can accommodate |
it can accommodate with |
the implications of such |
implications of such fees |
of such fees to |
such fees to our |
fees to our analysis |
general case of inter |
can accommodate with an |
accommodate with an increasing |
many pools are open |
with an increasing number |
pools are open and |
an increasing number of |
are open and accept |
increasing number of shards |
open and accept any |
and accept any interested |
accept any interested miner |
cluster communication is one |
a pool interface is |
communication is one where |
pool interface is typically |
is one where any |
writes of objects chosen |
one where any node |
interface is typically comprised |
of objects chosen uniformly |
objects chosen uniformly at |
is typically comprised of |
typically comprised of a |
chosen uniformly at random |
uniformly at random from |
comprised of a web |
of a web interface |
at random from a |
random from a small |
a web interface for |
web interface for registration |
from a small set |
a small set of |
interface for registration and |
for registration and a |
registration and a miner |
and a miner interface |
a miner interface for |
miner interface for the |
interface for the mining |
for the mining software |
where any node in |
any node in one |
in order to mine |
order to mine for |
to mine for a |
node in one cluster |
mine for a pool |
in one cluster can |
one cluster can communicate |
a miner registers with |
miner registers with the |
acidrain against two approaches |
cluster can communicate with |
registers with the web |
more details in section |
with the web interface |
can communicate with any |
communicate with any node |
supplies a bitcoin address |
a bitcoin address to |
bitcoin address to receive |
with any node in |
address to receive its |
to receive its future |
smr tms is two |
any node in the |
receive its future shares |
its future shares of |
phase commit with reliable |
commit with reliable coordinators |
future shares of the |
shares of the revenue |
node in the other |
in the other cluster |
and receives from the |
receives from the pool |
from the pool credentials |
the pool credentials for |
pool credentials for mining |
global log is an |
log is an architecture |
is an architecture where |
then he feeds his |
he feeds his credentials |
an architecture where tms |
we make no assumptions |
feeds his credentials and |
architecture where tms submit |
make no assumptions about |
his credentials and the |
where tms submit all |
no assumptions about the |
credentials and the pool |
tms submit all transactions |
assumptions about the type |
and the pool s |
submit all transactions to |
all transactions to a |
the pool s address |
pool s address to |
transactions to a single |
to a single global |
s address to its |
address to its mining |
to its mining rig |
about the type of |
a single global log |
single global log and |
global log and check |
log and check conflicts |
and check conflicts on |
check conflicts on that |
the mining rig obtains |
conflicts on that single |
on that single log |
mining rig obtains its |
rig obtains its tasks |
obtains its tasks from |
its tasks from the |
tasks from the pool |
from the pool and |
the pool and sends |
pool and sends partial |
and sends partial and |
sends partial and full |
partial and full proof |
and full proof of |
full proof of work |
the type of traffic |
type of traffic flowing |
of traffic flowing through |
typically with the stratum |
with the stratum protocol |
traffic flowing through the |
flowing through the link |
has lower latency for |
lower latency for a |
latency for a given |
for a given throughput |
pc since its faster |
since its faster certification |
its faster certification reduces |
faster certification reduces contention |
as it finds blocks |
critical applications could send |
it has no bottleneck |
has no bottleneck as |
the pool manager credits |
no bottleneck as with |
bottleneck as with a |
as with a global |
with a global log |
applications could send dynamically |
pool manager credits the |
manager credits the miner |
that has less overhead |
could send dynamically generated |
credits the miner s |
has less overhead in |
less overhead in small |
overhead in small scale |
send dynamically generated real |
the miner s account |
miner s account according |
s account according to |
account according to its |
according to its share |
to its share of |
its share of the |
share of the work |
while the parameters we |
the parameters we choose |
time data such as |
parameters we choose are |
and transfers these funds |
we choose are arbitrary |
data such as stock |
such as stock quotes |
transfers these funds either |
the trends are robust |
these funds either on |
funds either on request |
either on request or |
on request or automatically |
request or automatically to |
or automatically to the |
choosing other parameters would |
automatically to the aforementioned |
to the aforementioned bitcoin |
the aforementioned bitcoin address |
financial transactions and battleground |
other parameters would provide |
parameters would provide similar |
too big pools despite |
would provide similar trends |
transactions and battleground location |
and battleground location updates |
big pools despite their |
pools despite their important |
despite their important role |
their important role of |
important role of enabling |
role of enabling small |
while enterprise applications could |
enterprise applications could send |
applications could send voip |
could send voip streams |
pools can constitute a |
can constitute a threat |
constitute a threat to |
a threat to the |
threat to the bitcoin |
to the bitcoin system |
the bitcoin system if |
bitcoin system if their |
system if their size |
if their size is |
ssh sessions and synchronous |
their size is too |
size is too large |
sessions and synchronous file |
and synchronous file updates |
synchronous file updates between |
file updates between offices |
if one pool controls |
one pool controls the |
pool controls the majority |
controls the majority of |
the majority of mining |
majority of mining power |
the system becomes unstable |
phase commit for transaction |
commit for transaction certification |
packet loss typically occurs |
loss typically occurs at |
typically occurs at two |
the downside of these |
downside of these approaches |
of these approaches compared |
these approaches compared to |
approaches compared to acid |
occurs at two points |
at two points in |
two points in an |
rain is that they |
is that they require |
that they require a |
they require a coordinator |
require a coordinator that |
a coordinator that performs |
coordinator that performs transactions |
that performs transactions to |
performs transactions to be |
transactions to be highly |
to be highly available |
points in an end |
this requires another consensus |
in addition to the |
addition to the one |
to the one at |
the one at the |
one at the shard |
at the shard itself |
end communication path between |
warns that the system |
that the system is |
the system is unstable |
system is unstable with |
is unstable with even |
unstable with even smaller |
with even smaller pools |
communication path between two |
related work our transaction |
work our transaction ordering |
our transaction ordering protocol |
transaction ordering protocol is |
ordering protocol is inspired |
protocol is inspired by |
is inspired by a |
inspired by a state |
path between two datacenters |
in realistic scenarios of |
realistic scenarios of the |
machine ordering mechanism suggested |
scenarios of the bitcoin |
ordering mechanism suggested by |
of the bitcoin system |
mechanism suggested by lamport |
the bitcoin system no |
bitcoin system no pool |
system no pool controls |
no pool controls a |
pool controls a majority |
controls a majority of |
a majority of the |
majority of the mining |
of the mining power |
as shown in figure |
for one day in |
one day in june |
but we have generalized |
we have generalized the |
have generalized the protocol |
generalized the protocol to |
the protocol to work |
protocol to work with |
to work with arbitrary |
work with arbitrary overlapping |
with arbitrary overlapping par |
area network connecting them |
network connecting them and |
references the approaches of |
the approaches of mdcc |
connecting them and at |
a single pool called |
single pool called ghash |
them and at the |
and at the receiving |
at the receiving end |
of the blocks in |
the blocks in the |
blocks in the bitcoin |
in the bitcoin main |
the bitcoin main chain |
loss in the lambda |
in the lambda link |
the lambda link can |
the bitcoin community backlashed |
bitcoin community backlashed at |
community backlashed at the |
backlashed at the pool |
are close to acid |
lambda link can occur |
link can occur for |
can occur for many |
occur for many reasons |
rain s certification mechanism |
which has done nothing |
has done nothing worse |
done nothing worse than |
nothing worse than being |
worse than being extremely |
than being extremely successful |
rain separates the om |
separates the om abstraction |
the om abstraction from |
om abstraction from the |
abstraction from the highly |
io reduced its relative |
reduced its relative mining |
its relative mining power |
relative mining power and |
mining power and publicly |
power and publicly committed |
dirty or degraded fiber |
and publicly committed to |
publicly committed to stay |
committed to stay away |
to stay away from |
leasing mechanism and fast |
stay away from the |
mechanism and fast recovery |
malfunctioning or misconfigured equipment |
we also address garbage |
also address garbage collection |
which cannot be done |
cannot be done independently |
low receiver power and |
be done independently at |
done independently at the |
independently at the logs |
receiver power and burst |
power and burst switching |
block withholding and its |
withholding and its detection |
and its detection classical |
its detection classical block |
detection classical block withholding |
and burst switching contention |
burst switching contention are |
switching contention are some |
contention are some reasons |
is an attack performed |
an attack performed by |
attack performed by a |
performed by a pool |
by a pool member |
a pool member against |
pool member against the |
member against the other |
against the other pool |
the other pool members |
the attacking miner registers |
attacking miner registers with |
miner registers with the |
registers with the pool |
with the pool and |
the pool and apparently |
pool and apparently starts |
and apparently starts mining |
apparently starts mining honestly |
starts mining honestly it |
mining honestly it regularly |
honestly it regularly sends |
it regularly sends the |
regularly sends the pool |
sends the pool partial |
the pool partial proof |
pool partial proof of |
partial proof of work |
the attacking miner sends |
attacking miner sends only |
miner sends only partial |
sends only partial proof |
only partial proof of |
partial proof of work |
a new paradigm for |
new paradigm for building |
if it finds a |
paradigm for building scalable |
it finds a full |
for building scalable distributed |
finds a full solution |
building scalable distributed systems |
a full solution that |
full solution that constitutes |
solution that constitutes a |
that constitutes a full |
constitutes a full proof |
a full proof of |
full proof of work |
proof of work it |
of work it discards |
work it discards the |
it discards the solution |
reducing the pool s |
the pool s total |
pool s total revenue |
this attack is illustrated |
attack is illustrated in |
is illustrated in figure |
the attacker does not |
attacker does not change |
does not change the |
not change the pool |
change the pool s |
the pool s effective |
pool s effective mining |
s effective mining power |
uses an architecture similar |
an architecture similar to |
and does not affect |
architecture similar to our |
does not affect directly |
similar to our certification |
not affect directly the |
to our certification mechanism |
affect directly the revenue |
directly the revenue of |
the revenue of other |
revenue of other pools |
but addresses minitransactions that |
addresses minitransactions that are |
minitransactions that are submitted |
that are submitted as |
are submitted as a |
submitted as a whole |
the attacked pool shares |
attacked pool shares its |
pool shares its revenue |
with no attempt to |
shares its revenue with |
its revenue with the |
revenue with the attacker |
loss can also occur |
no attempt to order |
attempt to order potentially |
therefore each miner earns |
each miner earns less |
to order potentially conflicting |
order potentially conflicting transactions |
can also occur at |
as the same revenue |
the same revenue is |
same revenue is distributed |
we address full transactions |
also occur at receiving |
revenue is distributed among |
is distributed among more |
distributed among more miners |
where the clients sequentially |
the clients sequentially access |
clients sequentially access objects |
sequentially access objects before |
recall that the proof |
access objects before ending |
objects before ending a |
that the proof of |
the proof of work |
before ending a transaction |
occur at receiving endhosts |
proof of work is |
of work is only |
work is only valid |
and use prediction to |
use prediction to order |
prediction to order them |
to order them in |
order them in advance |
at receiving endhosts within |
is only valid for |
only valid for a |
we believe our techniques |
valid for a specific |
for a specific block |
believe our techniques could |
receiving endhosts within the |
our techniques could be |
as it is the |
endhosts within the destination |
techniques could be used |
it is the nonce |
is the nonce with |
could be used to |
be used to reduce |
the nonce with which |
nonce with which the |
used to reduce abort |
within the destination datacenter |
with which the block |
to reduce abort rates |
which the block s |
reduce abort rates of |
the block s hash |
abort rates of systems |
block s hash is |
rates of systems using |
s hash is smaller |
of systems using sinfonia |
hash is smaller than |
is smaller than its |
smaller than its target |
these are usually cheap |
systems using sinfonia or |
using sinfonia or a |
the attacking miner cannot |
attacking miner cannot use |
miner cannot use it |
are usually cheap commodity |
sinfonia or a similar |
or a similar certification |
a similar certification mechanism |
usually cheap commodity machines |
although the term block |
the term block withholding |
term block withholding has |
block withholding has become |
withholding has become canonical |
cheap commodity machines prone |
commodity machines prone to |
note that the block |
machines prone to temporary |
that the block is |
prone to temporary overloads |
the block is discarded |
to temporary overloads that |
block is discarded and |
temporary overloads that cause |
is discarded and never |
overloads that cause packets |
discarded and never introduced |
that cause packets to |
and never introduced into |
never introduced into the |
introduced into the system |
into the system as |
the system as the |
system as the name |
as the name block |
the name block withholding |
name block withholding implies |
cause packets to be |
packets to be dropped |
to be dropped by |
be dropped by the |
dropped by the kernel |
by the kernel in |
miners miners miners pool |
the kernel in bursts |
classical block withholding attack |
a group of miners |
group of miners attack |
of miners attack pool |
with a block withholding |
a block withholding attack |
this loss mode occurs |
loss mode occurs with |
mode occurs with udp |
denoted by a dashed |
by a dashed red |
a dashed red arrow |
based traffic but not |
traffic but not with |
but not with tcp |
this attack reduces the |
attack reduces the attacker |
reduces the attacker s |
the attacker s revenue |
attacker s revenue compared |
s revenue compared to |
revenue compared to solo |
compared to solo mining |
to solo mining or |
solo mining or honest |
mining or honest pool |
or honest pool participation |
it suffers from the |
which advertises receiver windows |
suffers from the reduced |
from the reduced revenue |
the reduced revenue like |
reduced revenue like the |
revenue like the other |
like the other pool |
the other pool participants |
advertises receiver windows to |
receiver windows to prevent |
windows to prevent end |
and its revenue is |
its revenue is less |
revenue is less than |
is less than its |
less than its share |
than its share of |
its share of the |
share of the total |
highly available storage for |
of the total mining |
available storage for interactive |
the total mining power |
storage for interactive services |
total mining power in |
mining power in the |
power in the system |
what are typical loss |
are typical loss rates |
the classical block withholding |
typical loss rates on |
loss rates on long |
classical block withholding attack |
block withholding attack can |
withholding attack can therefore |
attack can therefore only |
can therefore only be |
therefore only be used |
only be used for |
be used for sabotage |
at a cost to |
a cost to the |
cost to the attacker |
one source of information |
source of information is |
of information is teragrid |
even if a pool |
if a pool detects |
a pool detects that |
pool detects that it |
detects that it is |
that it is under |
it is under a |
is under a block |
under a block withholding |
a block withholding attack |
it might not be |
might not be able |
not be able to |
be able to detect |
able to detect which |
to detect which of |
detect which of its |
which of its registered |
of its registered miners |
its registered miners are |
registered miners are the |
miners are the perpetrators |
a pool can estimate |
pool can estimate its |
can estimate its expected |
an optical network interconnecting |
estimate its expected mining |
optical network interconnecting major |
its expected mining power |
network interconnecting major supercomputing |
expected mining power and |
interconnecting major supercomputing sites |
mining power and its |
major supercomputing sites in |
power and its actual |
a transactional record manager |
transactional record manager for |
record manager for shared |
manager for shared flash |
and its actual mining |
supercomputing sites in the |
sites in the us |
its actual mining power |
actual mining power by |
mining power by the |
power by the rates |
by the rates of |
the rates of partial |
rates of partial proofs |
of partial proofs of |
partial proofs of work |
proofs of work and |
of work and full |
work and full proofs |
and full proofs of |
full proofs of work |
teragrid has a monitoring |
has a monitoring framework |
a monitoring framework within |
monitoring framework within which |
supplied by its miners |
framework within which ten |
within which ten sites |
which ten sites periodically |
a difference above a |
difference above a set |
above a set confidence |
a set confidence interval |
set confidence interval indicates |
confidence interval indicates an |
interval indicates an attack |
ten sites periodically send |
sites periodically send each |
periodically send each other |
to detect whether a |
detect whether a single |
whether a single miner |
a single miner is |
single miner is attacking |
miner is attacking it |
the pool must use |
pool must use a |
must use a similar |
use a similar technique |
gbps streams of udp |
streams of udp packets |
of udp packets and |
comparing the estimated mining |
udp packets and measure |
the estimated mining power |
packets and measure the |
estimated mining power of |
and measure the resulting |
mining power of the |
power of the attacker |
a middleware for highperformance |
of the attacker based |
measure the resulting loss |
the resulting loss rate |
the attacker based on |
middleware for highperformance transaction |
attacker based on its |
for highperformance transaction processing |
based on its partial |
on its partial proof |
its partial proof of |
partial proof of work |
proof of work with |
of work with the |
work with the fact |
with the fact it |
the fact it never |
fact it never supplies |
it never supplies a |
never supplies a full |
supplies a full proof |
a full proof of |
full proof of work |
if the attacker has |
the attacker has a |
attacker has a small |
has a small mining |
a small mining power |
it will send frequent |
will send frequent partial |
send frequent partial proofs |
frequent partial proofs of |
partial proofs of work |
each site measures the |
site measures the loss |
measures the loss rate |
but the pool will |
the pool will only |
pool will only expect |
will only expect to |
the loss rate to |
only expect to see |
expect to see a |
to see a full |
see a full proof |
a full proof of |
full proof of work |
proof of work at |
of work at very |
work at very low |
at very low frequency |
loss rate to every |
rate to every other |
to every other site |
every other site once |
other site once an |
site once an hour |
it cannot obtain statistically |
cannot obtain statistically significant |
obtain statistically significant results |
statistically significant results that |
significant results that would |
results that would indicate |
that would indicate an |
would indicate an attack |
resulting in a total |
in a total of |
an attacker can use |
attacker can use multiple |
can use multiple small |
use multiple small block |
boosting dbms performance by |
multiple small block withholding |
dbms performance by parallelising |
small block withholding miners |
performance by parallelising write |
block withholding miners and |
by parallelising write transactions |
withholding miners and replace |
miners and replace them |
and replace them frequently |
loss rate measurements collected |
rate measurements collected across |
a small miner is |
measurements collected across the |
collected across the network |
across the network every |
the network every hour |
a miner whose expected |
miner whose expected full |
whose expected full proof |
expected full proof of |
full proof of work |
proof of work frequency |
of work frequency is |
work frequency is yearly |
such a miner will |
a miner will see |
miner will see a |
will see a non |
prediction of transaction behavior |
negligible average daily revenue |
of transaction behavior has |
transaction behavior has the |
behavior has the potential |
has the potential to |
the potential to significantly |
potential to significantly decrease |
to significantly decrease abort |
significantly decrease abort rates |
decrease abort rates in |
abort rates in large |
rates in large scale |
in large scale transactional |
large scale transactional systems |
scale transactional systems with |
transactional systems with high |
systems with high contention |
rain we employ prediction |
we employ prediction to |
employ prediction to obtain |
prediction to obtain soft |
to obtain soft reservations |
obtain soft reservations and |
soft reservations and implement |
reservations and implement atomic |
and implement atomic transactions |
implement atomic transactions while |
atomic transactions while requiring |
transactions while requiring high |
while requiring high availability |
requiring high availability only |
high availability only in |
availability only in a |
only in a single |
in a single tier |
a single tier of |
single tier of independent |
tier of independent logs |
this allows for low |
if the attacker replaces |
the attacker replaces such |
attacker replaces such a |
replaces such a small |
such a small miner |
a small miner every |
small miner every month |
he will collect about |
will collect about b |
rain s operations never |
at the end of |
s operations never depend |
the end of each |
operations never depend on |
end of each month |
never depend on a |
depend on a single |
on a single machine |
a single machine by |
single machine by allowing |
the pool must decide |
machine by allowing fast |
pool must decide within |
by allowing fast recovery |
must decide within this |
allowing fast recovery from |
decide within this month |
fast recovery from failures |
within this month whether |
recovery from failures and |
this month whether the |
from failures and performance |
month whether the miner |
failures and performance hiccups |
whether the miner is |
the miner is an |
miner is an attacker |
and revoke its earnings |
or just an unlucky |
just an unlucky honest |
an unlucky honest miner |
since an honest miner |
an honest miner of |
honest miner of this |
miner of this power |
of all such measurements |
all such measurements were |
such measurements were over |
of this power is |
this power is unlikely |
power is unlikely to |
is unlikely to find |
unlikely to find a |
to find a full |
find a full proof |
a full proof of |
full proof of work |
proof of work within |
of work within a |
work within a month |
according to the exponential |
to the exponential distribution |
a pool that rejects |
pool that rejects miners |
that rejects miners based |
rejects miners based on |
miners based on this |
based on this criterion |
on this criterion would |
this criterion would reject |
criterion would reject the |
would reject the majority |
reject the majority of |
benchmarking cloud serving systems |
cloud serving systems with |
serving systems with ycsb |
the majority of its |
majority of its honest |
of its honest miners |
of them were over |
the alternative of rejecting |
alternative of rejecting small |
of rejecting small miners |
rejecting small miners in |
small miners in general |
miners in general or |
in general or distributing |
general or distributing revenue |
or distributing revenue on |
distributing revenue on a |
revenue on a yearly |
on a yearly basis |
a yearly basis contradicts |
yearly basis contradicts the |
basis contradicts the goal |
contradicts the goal of |
the goal of pooled |
goal of pooled mining |
after eliminating a single |
eliminating a single site |
m odel and s |
odel and s tandard |
and s tandard o |
s tandard o peration |
tandard o peration we |
o peration we specify |
peration we specify the |
we specify the basic |
specify the basic model |
the basic model in |
basic model in which |
model in which participants |
that dropped incoming packets |
in which participants operate |
which participants operate in |
participants operate in section |
operate in section iii |
dropped incoming packets steadily |
incoming packets steadily at |
packets steadily at a |
steadily at a rate |
at a rate of |
proceed to describe how |
to describe how honest |
describe how honest miners |
how honest miners operate |
honest miners operate in |
miners operate in this |
operate in this environment |
in this environment in |
this environment in sections |
environment in sections iii |
and how the classical |
how the classical block |
the classical block withholding |
classical block withholding attack |
block withholding attack is |
withholding attack is implemented |
attack is implemented with |
is implemented with our |
implemented with our model |
with our model in |
our model in section |
model in section iii |
we plan to build |
plan to build on |
to build on our |
build on our simulation |
on our simulation results |
our simulation results by |
model the system is |
simulation results by implementing |
the system is comprised |
results by implementing acid |
of the remainder were |
the remainder were over |
system is comprised of |
rain and exploring the |
is comprised of the |
and exploring the different |
comprised of the bitcoin |
exploring the different aspects |
of the bitcoin network |
the different aspects of |
the bitcoin network and |
different aspects of its |
bitcoin network and nodes |
aspects of its performance |
network and nodes with |
and nodes with unique |
nodes with unique ids |
of its performance in |
its performance in realistic |
performance in realistic settings |
and progresses in steps |
of particular interest are |
a node i generates |
node i generates tasks |
i generates tasks which |
generates tasks which are |
tasks which are associated |
which are associated with |
are associated with its |
associated with its id |
with its id i |
different network topologies with |
network topologies with a |
a node can work |
topologies with a single |
node can work on |
with a single datacenter |
can work on a |
a single datacenter and |
work on a task |
single datacenter and with |
on a task for |
datacenter and with multiple |
a task for the |
and with multiple datacenters |
task for the duration |
for the duration of |
the duration of a |
duration of a step |
the result of this |
result of this work |
of this work is |
this work is a |
work is a set |
is a set of |
a set of partial |
set of partial proofs |
of partial proofs of |
behavior in face of |
partial proofs of work |
proofs of work and |
in face of high |
face of high contention |
of work and a |
work and a set |
and a set of |
a set of full |
set of full proofs |
of full proofs of |
full proofs of work |
these numbers reflect the |
rain should prove efficient |
numbers reflect the loss |
the number of proofs |
number of proofs in |
of proofs in each |
proofs in each set |
in each set has |
each set has a |
where its overhead may |
its overhead may be |
overhead may be wasteful |
set has a poisson |
has a poisson distribution |
reflect the loss rate |
the loss rate experienced |
loss rate experienced for |
rate experienced for udp |
experienced for udp traffic |
for udp traffic on |
udp traffic on an |
traffic on an end |
partial proofs with a |
proofs with a large |
with a large mean |
a large mean and |
large mean and full |
mean and full proofs |
and full proofs with |
full proofs with a |
proofs with a small |
with a small mean |
behavior in error prone |
in error prone scenarios |
end path and may |
nodes that work on |
that work on tasks |
work on tasks are |
on tasks are called |
tasks are called a |
are called a miners |
path and may not |
and may not generalize |
may not generalize to |
not generalize to tcp |
generalize to tcp packets |
miners have identical power |
performance with predictors of |
with predictors of different |
predictors of different qualities |
and hence identical probabilities |
hence identical probabilities to |
identical probabilities to generate |
probabilities to generate proofs |
to generate proofs of |
generate proofs of work |
we do not know |
do not know if |
the bitcoin network pays |
bitcoin network pays for |
network pays for full |
pays for full proofs |
for full proofs of |
full proofs of work |
not know if packets |
know if packets were |
if packets were dropped |
to acquire this payoff |
packets were dropped within |
acquire this payoff an |
were dropped within the |
this payoff an entity |
dropped within the optical |
payoff an entity publishes |
within the optical network |
an entity publishes a |
the optical network or |
entity publishes a task |
publishes a task task |
optical network or at |
a task task and |
task task and its |
task and its corresponding |
and its corresponding proof |
its corresponding proof of |
corresponding proof of work |
proof of work to |
of work to the |
work to the network |
network or at intermediate |
or at intermediate devices |
at intermediate devices within |
intermediate devices within either |
devices within either datacenter |
the payoff goes to |
lightweight elasticity in shared |
payoff goes to the |
elasticity in shared storage |
goes to the id |
in shared storage databases |
though it s unlikely |
to the id associated |
shared storage databases for |
it s unlikely that |
the id associated with |
storage databases for the |
databases for the cloud |
id associated with task |
s unlikely that they |
for the cloud using |
the cloud using live |
cloud using live data |
the bitcoin protocol normalizes |
using live data migration |
unlikely that they were |
that they were dropped |
bitcoin protocol normalizes revenue |
they were dropped at |
were dropped at the |
dropped at the end |
protocol normalizes revenue such |
normalizes revenue such that |
revenue such that the |
such that the average |
that the average total |
the average total revenue |
average total revenue distributed |
total revenue distributed in |
revenue distributed in each |
distributed in each step |
in each step is |
each step is a |
step is a constant |
is a constant throughout |
a constant throughout the |
constant throughout the execution |
throughout the execution of |
the execution of the |
execution of the system |
many of the mea |
any node can transact |
node can transact bitcoins |
can transact bitcoins to |
surements lost just one |
transact bitcoins to another |
bitcoins to another node |
to another node by |
another node by issuing |
node by issuing a |
by issuing a bitcoin |
issuing a bitcoin transaction |
lost just one or |
just one or two |
one or two packets |
or two packets whereas |
two packets whereas kernel |
nodes that generate tasks |
that generate tasks but |
generate tasks but outsource |
tasks but outsource the |
but outsource the work |
outsource the work are |
the work are called |
nic losses are known |
losses are known to |
are known to be |
known to be bursty |
work are called pools |
pools send tasks to |
send tasks to miners |
tasks to miners over |
to miners over the |
miners over the network |
the miners receive the |
miners receive the tasks |
and send the partial |
live migration in shared |
send the partial and |
migration in shared nothing |
the partial and full |
loss occurred on paths |
in shared nothing databases |
partial and full proofs |
and full proofs of |
full proofs of work |
proofs of work to |
of work to the |
work to the pool |
shared nothing databases for |
nothing databases for elastic |
databases for elastic cloud |
for elastic cloud platforms |
apart from working on |
from working on tasks |
occurred on paths where |
on paths where levels |
paths where levels of |
where levels of optical |
levels of optical link |
of optical link utilization |
and receipt are instantaneous |
we assume that the |
assume that the number |
that the number of |
the number of miners |
number of miners is |
of miners is large |
miners is large enough |
is large enough such |
large enough such that |
were consistently lower than |
enough such that mining |
such that mining power |
that mining power can |
mining power can be |
power can be split |
can be split arbitrarily |
be split arbitrarily without |
split arbitrarily without resolution |
arbitrarily without resolution constraints |
denote the number of |
the number of pools |
number of pools with |
of pools with p |
the total number of |
total number of mining |
number of mining power |
ruling out congestion as |
out congestion as a |
congestion as a possible |
as a possible cause |
of mining power in |
mining power in the |
power in the system |
in the system with |
the system with m |
system with m and |
with m and the |
m and the miners |
and the miners participating |
the miners participating in |
miners participating in pool |
participating in pool i |
a conclusion supported by |
conclusion supported by dialogue |
supported by dialogue with |
by dialogue with the |
dialogue with the network |
with the network administrators |
we use a quasistatic |
use a quasistatic analysis |
a quasistatic analysis where |
quasistatic analysis where miner |
analysis where miner participation |
where miner participation in |
miner participation in a |
participation in a pool |
in a pool does |
a pool does not |
pool does not change |
does not change over |
not change over time |
solo mining a solo |
mining a solo miner |
a solo miner is |
solo miner is a |
miner is a node |
is a node that |
a node that generates |
node that generates its |
that generates its own |
generates its own tasks |
points are provided by |
are provided by the |
provided by the back |
in every step it |
every step it generates |
step it generates a |
it generates a task |
bone networks of tier |
works on it for |
on it for the |
it for the duration |
for the duration of |
the duration of the |
duration of the step |
of the step and |
the step and if |
step and if it |
and if it finds |
if it finds a |
it finds a full |
finds a full proof |
a full proof of |
full proof of work |
global crossing reports average |
it publishes this proof |
publishes this proof of |
this proof of work |
proof of work to |
of work to earn |
work to earn the |
to earn the payoff |
crossing reports average loss |
reports average loss rates |
average loss rates between |
pools a pool is |
the dangers of replication |
a pool is a |
dangers of replication and |
pool is a node |
of replication and d |
is a node that |
a node that serves |
node that serves as |
that serves as a |
serves as a coordinator |
as a coordinator and |
a coordinator and multiple |
coordinator and multiple miners |
and multiple miners can |
multiple miners can register |
miners can register to |
can register to a |
register to a pool |
fast distributed transactions a |
to a pool and |
distributed transactions a solution |
a pool and work |
pool and work for |
and work for it |
in every step it |
every step it generates |
step it generates a |
it generates a task |
generates a task for |
a task for each |
task for each registered |
for each registered miner |
each registered miner and |
registered miner and sends |
miner and sends it |
and sends it over |
sends it over the |
it over the network |
each miner receives its |
miner receives its task |
receives its task and |
its task and works |
task and works on |
and works on it |
works on it for |
on it for the |
it for the duration |
for partitioned database systems |
on four of its |
four of its six |
of its six inter |
for the duration of |
the duration of the |
duration of the step |
at the end of |
the end of the |
end of the step |
haul links for the |
links for the month |
for the month of |
the month of december |
the miner sends the |
miner sends the pool |
sends the pool the |
the pool the full |
pool the full and |
the full and the |
full and the partial |
and the partial proofs |
the partial proofs of |
partial proofs of work |
proofs of work it |
of work it has |
work it has found |
the pool receives the |
pool receives the proofs |
receives the proofs of |
the proofs of work |
proofs of work of |
of work of all |
work of all its |
of all its miners |
registers the partial proofs |
the partial proofs of |
partial proofs of work |
proofs of work and |
of work and publishes |
work and publishes the |
and publishes the full |
publishes the full proofs |
it calculates its overall |
calculates its overall revenue |
and proceeds to distribute |
proceeds to distribute it |
to distribute it among |
distribute it among its |
it among its miners |
qwest reports loss rates |
reports loss rates of |
each miner receives revenue |
miner receives revenue proportional |
receives revenue proportional to |
revenue proportional to its |
proportional to its success |
to its success in |
distributed main memory transaction |
its success in the |
main memory transaction processing |
success in the current |
memory transaction processing system |
in the current step |
namely the ratio of |
the ratio of its |
ratio of its partial |
of its partial proofs |
its partial proofs of |
partial proofs of work |
proofs of work out |
of work out of |
work out of all |
out of all partial |
of all partial proofs |
all partial proofs of |
partial proofs of work |
proofs of work the |
of work the pool |
work the pool received |
we assume that pools |
assume that pools do |
that pools do not |
pools do not collect |
do not collect fees |
not collect fees of |
collect fees of the |
fees of the revenue |
pool fees and their |
fees and their implications |
and their implications on |
their implications on our |
implications on our analysis |
on our analysis are |
our analysis are discussed |
analysis are discussed in |
are discussed in section |
discussed in section ix |
in either direction on |
either direction on its |
direction on its trans |
block withholding miner a |
pacific link for the |
link for the same |
for the same month |
withholding miner a miner |
miner a miner registered |
a miner registered at |
miner registered at a |
registered at a pool |
at a pool can |
a pool can perform |
pool can perform the |
can perform the classical |
perform the classical block |
the classical block withholding |
classical block withholding attack |
an attacker miner operates |
attacker miner operates as |
miner operates as if |
operates as if it |
as if it worked |
if it worked for |
it worked for the |
worked for the pool |
we expect privately managed |
expect privately managed lambdas |
it receives its tasks |
receives its tasks and |
its tasks and works |
tasks and works on |
and works on them |
privately managed lambdas to |
managed lambdas to exhibit |
lambdas to exhibit higher |
to exhibit higher loss |
only at the end |
exhibit higher loss rates |
at the end of |
higher loss rates due |
the end of each |
end of each round |
of each round it |
each round it sends |
round it sends only |
it sends only its |
sends only its partial |
only its partial proofs |
its partial proofs of |
partial proofs of work |
loss rates due to |
rates due to the |
due to the inherent |
to the inherent trade |
and omits full proofs |
omits full proofs of |
full proofs of work |
proofs of work if |
of work if it |
verify replication for multi |
work if it had |
if it had found |
it had found any |
equipment quality and cost |
the pool registers the |
pool registers the miner |
registers the miner s |
the miner s partial |
miner s partial proofs |
but cannot distinguish between |
cannot distinguish between miners |
distinguish between miners running |
between miners running honestly |
miners running honestly and |
running honestly and block |
honestly and block withholding |
and block withholding miners |
the implications are that |
implications are that a |
are that a miner |
that a miner that |
a miner that engages |
miner that engages in |
that engages in block |
engages in block withholding |
as well as the |
in block withholding does |
block withholding does not |
well as the difficulty |
withholding does not contribute |
does not contribute to |
not contribute to the |
contribute to the pool |
to the pool s |
the pool s overall |
pool s overall mining |
s overall mining power |
as the difficulty of |
the difficulty of performing |
difficulty of performing routine |
of performing routine maintenance |
but still shares the |
performing routine maintenance on |
routine maintenance on longdistance |
still shares the pool |
maintenance on longdistance links |
shares the pool s |
the pool s revenue |
pool s revenue according |
s revenue according to |
revenue according to its |
according to its sent |
to its sent partial |
its sent partial proofs |
sent partial proofs of |
partial proofs of work |
to reason about a |
reason about a pool |
about a pool s |
a pool s efficiency |
pool s efficiency we |
s efficiency we define |
efficiency we define its |
we define its per |
end paths as dropping |
miner revenue as follows |
paths as dropping packets |
as dropping packets at |
dropping packets at rates |
packets at rates of |
the revenue density of |
revenue density of a |
density of a pool |
of a pool is |
a pool is the |
pool is the ratio |
is the ratio between |
the ratio between the |
ratio between the average |
between the average revenue |
the average revenue a |
average revenue a pool |
revenue a pool member |
a pool member earns |
pool member earns and |
member earns and the |
earns and the average |
and the average revenue |
the average revenue it |
average revenue it would |
revenue it would have |
it would have earned |
would have earned as |
have earned as a |
earned as a solo |
as a solo miner |
to capture a wide |
capture a wide range |
a wide range of |
wide range of deployed |
range of deployed networks |
the revenue density of |
revenue density of a |
density of a solo |
of a solo miner |
and that of a |
that of a miner |
of a miner working |
a miner working with |
miner working with an |
working with an unattacked |
with an unattacked pool |
an unattacked pool are |
unattacked pool are one |
existing reliability options tcp |
using time instead of |
if a pool is |
time instead of timeout |
a pool is attacked |
pool is attacked with |
ip is the default |
is attacked with block |
attacked with block withholding |
is the default reliable |
instead of timeout for |
of timeout for fault |
its revenue density decreases |
the default reliable communication |
default reliable communication option |
reliable communication option for |
communication option for contemporary |
option for contemporary networked |
for contemporary networked applications |
continuous analysis because our |
analysis because our analysis |
because our analysis will |
our analysis will be |
analysis will be of |
will be of the |
be of the average |
of the average revenue |
we will consider proofs |
will consider proofs of |
consider proofs of work |
exclusive embeddings in commodity |
embeddings in commodity operating |
in commodity operating systems |
both full and partial |
commodity operating systems and |
operating systems and networking |
systems and networking apis |
as continuous deterministic sizes |
according to their probability |
work on a task |
on a task therefore |
most applications requiring reliable |
a task therefore results |
task therefore results in |
therefore results in a |
results in a deterministic |
in a deterministic fraction |
a deterministic fraction of |
deterministic fraction of proof |
fraction of proof of |
of proof of work |
applications requiring reliable communication |
requiring reliable communication over |
reliable communication over any |
communication over any form |
over any form of |
any form of network |
form of network use |
t he p ool |
he p ool g |
p ool g ame |
ool g ame a |
of network use tcp |
the pool block withholding |
pool block withholding attack |
block withholding attack just |
withholding attack just as |
attack just as a |
just as a miner |
as a miner can |
a miner can perform |
miner can perform block |
can perform block withholding |
perform block withholding on |
block withholding on a |
withholding on a pool |
on a pool j |
a pool i can |
pool i can use |
i can use some |
can use some of |
use some of its |
some of its mining |
of its mining power |
its mining power to |
the problem with commodity |
problem with commodity tcp |
mining power to infiltrate |
power to infiltrate a |
to infiltrate a pool |
infiltrate a pool j |
a pool j and |
pool j and perform |
j and perform a |
and perform a block |
perform a block withholding |
a block withholding attack |
block withholding attack on |
withholding attack on j |
denote the amount of |
the amount of such |
amount of such infiltrating |
of such infiltrating mining |
such infiltrating mining power |
infiltrating mining power at |
ip uses positive acknowledgments |
mining power at step |
power at step t |
at step t by |
step t by xi |
uses positive acknowledgments and |
positive acknowledgments and retransmissions |
acknowledgments and retransmissions to |
and retransmissions to ensure |
retransmissions to ensure reliability |
to ensure reliability the |
ensure reliability the sender |
reliability the sender buffers |
the sender buffers packets |
sender buffers packets until |
buffers packets until their |
packets until their receipt |
until their receipt is |
their receipt is acknowledged |
receipt is acknowledged by |
is acknowledged by the |
acknowledged by the receiver |
miners working for pool |
working for pool i |
and resends if an |
resends if an acknowledgment |
either mining honestly or |
mining honestly or used |
honestly or used for |
or used for infiltrating |
used for infiltrating pool |
for infiltrating pool j |
if an acknowledgment is |
an acknowledgment is not |
from paxos to corfu |
acknowledgment is not received |
is not received within |
not received within some |
received within some time |
within some time period |
are loyal to pool |
loyal to pool i |
at the end of |
the end of a |
end of a round |
a lost packet is |
lost packet is received |
packet is received in |
is received in the |
received in the form |
pool i aggregates its |
in the form of |
i aggregates its revenue |
the form of a |
form of a retransmission |
of a retransmission that |
a retransmission that arrives |
retransmission that arrives no |
that arrives no earlier |
arrives no earlier than |
aggregates its revenue from |
its revenue from mining |
revenue from mining in |
from mining in the |
mining in the current |
in the current round |
the current round and |
current round and from |
round and from its |
and from its infiltration |
from its infiltration in |
its infiltration in the |
infiltration in the previous |
in the previous round |
rtts after the original |
after the original send |
the original send event |
it distributes the revenue |
distributes the revenue evenly |
the sender has to |
sender has to buffer |
the revenue evenly among |
has to buffer each |
to buffer each packet |
buffer each packet until |
each packet until it |
packet until it s |
until it s acknowledged |
revenue evenly among all |
evenly among all its |
among all its loyal |
all its loyal miners |
its loyal miners according |
loyal miners according to |
miners according to their |
according to their partial |
to their partial proofs |
their partial proofs of |
partial proofs of work |
rtt in lossless operation |
the pool s miners |
and it has to |
pool s miners are |
it has to perform |
s miners are oblivious |
has to perform additional |
miners are oblivious to |
to perform additional work |
are oblivious to their |
perform additional work to |
oblivious to their role |
to their role and |
their role and they |
role and they operate |
and they operate as |
they operate as regular |
operate as regular honest |
as regular honest miners |
additional work to retransmit |
work to retransmit the |
to retransmit the packet |
retransmit the packet if |
the packet if it |
packet if it does |
if it does not |
it does not receive |
does not receive the |
not receive the acknowledgment |
concurrency control and availability |
any packets that arrive |
control and availability in |
and availability in multi |
packets that arrive with |
that arrive with higher |
arrive with higher sequence |
revenue convergence note that |
with higher sequence numbers |
convergence note that pool |
higher sequence numbers than |
note that pool j |
sequence numbers than that |
that pool j sends |
numbers than that of |
pool j sends its |
than that of a |
j sends its revenue |
that of a lost |
sends its revenue to |
of a lost packet |
its revenue to infiltrators |
a lost packet must |
revenue to infiltrators from |
lost packet must be |
to infiltrators from pool |
infiltrators from pool i |
from pool i at |
pool i at the |
i at the end |
at the end of |
the end of the |
end of the step |
packet must be queued |
must be queued while |
be queued while the |
queued while the receiver |
while the receiver waits |
and this revenue is |
the receiver waits for |
receiver waits for the |
waits for the lost |
for the lost packet |
the lost packet to |
lost packet to arrive |
this revenue is calculated |
revenue is calculated in |
is calculated in pool |
calculated in pool i |
in pool i at |
pool i at the |
i at the beginning |
at the beginning of |
the beginning of the |
beginning of the subsequent |
of the subsequent step |
throughput financial banking application |
financial banking application running |
banking application running in |
application running in a |
running in a datacenter |
if there is a |
there is a chain |
is a chain of |
a chain of pools |
in a datacenter in |
a datacenter in new |
datacenter in new york |
in new york city |
on predictive modeling for |
sending updates to a |
updates to a sister |
to a sister site |
a sister site in |
sister site in switzerland |
predictive modeling for optimizing |
modeling for optimizing transaction |
for optimizing transaction execution |
optimizing transaction execution in |
transaction execution in parallel |
execution in parallel oltp |
in parallel oltp systems |
the rtt value between |
rtt value between these |
value between these two |
between these two centers |
these two centers is |
two centers is typically |
where each pool infiltrates |
each pool infiltrates the |
pool infiltrates the previous |
infiltrates the previous one |
the pool revenue will |
pool revenue will not |
revenue will not be |
will not be static |
since the revenue from |
the revenue from infiltration |
revenue from infiltration takes |
in the case of |
the case of a |
case of a lost |
of a lost packet |
from infiltration takes one |
infiltration takes one step |
takes one step to |
one step to take |
step to take each |
all packets received within |
packets received within the |
to take each hop |
from the first step |
the revenue of pool |
milliseconds between the original |
between the original packet |
the original packet send |
original packet send and |
packet send and the |
send and the a |
since it is only |
it is only infiltrated |
is only infiltrated and |
only infiltrated and loses |
infiltrated and loses some |
and loses some of |
loses some of its |
some of its revenue |
of its revenue for |
its revenue for pool |
scalable deferred update replication |
starting from the second |
from the second step |
h ets are generated |
ets are generated from |
are generated from alternate |
generated from alternate disjoint |
the revenue of pool |
from alternate disjoint sub |
streams of data rather |
of data rather than |
data rather than from |
rather than from consecutive |
comprised of its own |
of its own mining |
its own mining and |
own mining and its |
than from consecutive packets |
mining and its revenue |
and its revenue from |
its revenue from the |
revenue from the infiltration |
from the infiltration of |
the infiltration of pool |
with an interleave index |
an interleave index of |
with some revenue lost |
some revenue lost due |
revenue lost due to |
lost due to its |
due to its infiltration |
to its infiltration by |
its infiltration by pool |
the encoder would a |
starting from the third |
from the third step |
g create correction packets |
the revenue of pool |
create correction packets separately |
correction packets separately from |
packets separately from three |
separately from three disjoint |
from three disjoint sub |
the case for determinism |
case for determinism in |
for determinism in database |
determinism in database systems |
the first containing data |
first containing data packets |
containing data packets numbered |
data packets numbered a |
packets numbered a c |
numbered a c e |
a c e g |
c e g x |
e g x x |
max is the longest |
is the longest chain |
the longest chain in |
longest chain in the |
chain in the system |
the revenue stabilizes after |
if there are loops |
there are loops in |
are loops in the |
loops in the infiltration |
in the infiltration graph |
the system will converge |
system will converge to |
will converge to a |
converge to a certain |
to a certain revenue |
as stated in the |
stated in the following |
in the following lemma |
the second with data |
second with data packets |
with data packets numb |
data packets numb d |
packets numb d f |
numb d f h |
d f h x |
f h x x |
h x x bered |
if infiltration rates are |
infiltration rates are constant |
the pool revenues converge |
pool revenues converge to |
revenues converge to a |
converge to a limit |
to a limit as |
a limit as time |
limit as time progresses |
denote the revenue density |
the revenue density of |
revenue density of pool |
density of pool i |
of pool i at |
pool i at the |
i at the end |
at the end of |
the end of step |
end of step t |
of step t by |
step t by ri |
and define the revenue |
define the revenue density |
the revenue density vector |
revenue density vector r |
and the third with |
the third with data |
third with data b |
the revenues at all |
revenues at all pools |
at all pools converge |
all pools converge as |
pools converge as follows |
interleaving adds burst tolerance |
adds burst tolerance to |
burst tolerance to fec |
tolerance to fec but |
to fec but exacerbates |
fec but exacerbates its |
but exacerbates its sensitivfigure |
separate encoding for ity |
encoding for ity to |
for ity to sending |
ity to sending rate |
to sending rate with |
sending rate with an |
rate with an interleave |
with an interleave index |
an interleave index of |
interleave index of i |
index of i and |
of i and an |
i and an encoding |
and an encoding rate |
an encoding rate of |
the sender would have |
sender would have to |
would have to wait |
have to wait for |
to wait for odd |
wait for odd and |
for odd and even |
odd and even packets |
and even packets i |
p in every round |
pool i uses its |
i uses its mining |
uses its mining power |
its mining power of |
mining power of m |
packets before sending any |
before sending any redundancy |
sending any redundancy information |
j used for direct |
used for direct mining |
for direct mining p |
receipt of its retransmission |
of its retransmission have |
its retransmission have to |
retransmission have to be |
have to be buffered |
to be buffered at |
be buffered at the |
buffered at the rethese |
at the rethese two |
the rethese two obstacles |
rethese two obstacles to |
two obstacles to using |
obstacles to using fec |
to using fec in |
using fec in time |
and shares it among |
shares it among its |
it among its m |
tings rate sensitivity and |
rate sensitivity and burst |
sensitivity and burst susceptibility |
and burst susceptibility are |
burst susceptibility are innotice |
susceptibility are innotice that |
are innotice that for |
innotice that for this |
that for this commonplace |
for this commonplace scenario |
the loss of terlinked |
loss of terlinked through |
of terlinked through the |
terlinked through the tuning |
through the tuning knobs |
all sums are over |
sums are over the |
are over the range |
an interleave of i |
interleave of i and |
of i and a |
i and a single |
and a single packet |
a single packet stops |
single packet stops all |
packet stops all traffic |
stops all traffic in |
all traffic in the |
traffic in the channel |
in the channel to |
the channel to the |
channel to the apa |
to the apa rate |
the apa rate of |
provides tolerance to a |
tolerance to a burst |
to a burst of |
a burst of up |
burst of up to |
of up to c |
up to c i |
to c i plication |
c i plication for |
i plication for a |
plication for a seventh |
for a seventh of |
a seventh of a |
seventh of a second |
denote the direct mining |
the direct mining revenue |
direct mining revenue density |
mining revenue density of |
revenue density of each |
density of each pool |
a sequence of such |
sequence of such consecutive |
of such consecutive packets |
which is a constant |
is a constant factor |
the burst tolerance of |
burst tolerance of blocks |
tolerance of blocks can |
of blocks can have |
blocks can have devastating |
can have devastating effect |
have devastating effect on |
devastating effect on a |
effect on a high |
throughput an fec code |
an fec code can |
fec code can be |
code can be changed |
can be changed by |
be changed by modulating |
changed by modulating either |
by modulating either the |
modulating either the c |
either the c system |
the c system where |
c system where every |
system where every spare |
where every spare cycle |
every spare cycle counts |
in applior the i |
applior the i parameters |
increasing c enhances burst |
c enhances burst tolercations |
enhances burst tolercations with |
burst tolercations with many |
tolercations with many fine |
a lost packet ance |
lost packet ance at |
packet ance at the |
ance at the cost |
at the cost of |
the cost of network |
cost of network and |
of network and encoding |
network and encoding overhead |
potencan potentially trigger a |
potentially trigger a butterfly |
trigger a butterfly effect |
a butterfly effect of |
butterfly effect of missed |
effect of missed deadtially |
of missed deadtially worsening |
missed deadtially worsening the |
deadtially worsening the packet |
worsening the packet loss |
the packet loss experienced |
packet loss experienced and |
loss experienced and reducing |
experienced and reducing lines |
and reducing lines along |
the pool game in |
reducing lines along a |
lines along a distributed |
along a distributed workflow |
pool game in the |
game in the pool |
in the pool game |
the pool game pools |
pool game pools try |
game pools try to |
pools try to optimize |
try to optimize their |
to optimize their infiltration |
optimize their infiltration rates |
their infiltration rates of |
infiltration rates of other |
rates of other pools |
of other pools to |
other pools to maximize |
pools to maximize their |
to maximize their revenue |
increasing i trades off |
i trades off recovery |
trades off recovery periods |
off recovery periods market |
recovery periods market crashes |
the overall number of |
periods market crashes at |
market crashes at stock |
crashes at stock exchanges |
overall number of miners |
number of miners and |
of miners and the |
miners and the number |
and the number of |
christmas latency for better |
the number of miners |
latency for better burst |
number of miners loyal |
for better burst tolerance |
of miners loyal to |
miners loyal to each |
loyal to each pool |
to each pool remain |
each pool remain constant |
pool remain constant throughout |
remain constant throughout the |
constant throughout the game |
better burst tolerance without |
burst tolerance without adding |
tolerance without adding overhead |
without adding overhead sales |
adding overhead sales at |
overhead sales at online |
sales at online stores |
time progresses in rounds |
winter storms at air |
let s be a |
s be a constant |
be a constant integer |
traffic control as mentioned |
a constant integer large |
constant integer large enough |
integer large enough that |
large enough that revenue |
for higher values of |
higher values of i |
enough that revenue can |
that revenue can be |
revenue can be approximated |
can be approximated as |
be approximated as its |
approximated as its convergence |
as its convergence limit |
the encoder has to |
encoder has to centers |
has to centers overloaded |
to centers overloaded networks |
centers overloaded networks and |
overloaded networks and end |
in each round the |
each round the system |
round the system takes |
hosts can exhibit wait |
the system takes s |
system takes s steps |
can exhibit wait for |
takes s steps and |
s steps and then |
steps and then a |
and then a single |
then a single pool |
exhibit wait for more |
wait for more data |
for more data packets |
more data packets to |
data packets to be |
picked with a round |
packets to be transmitted |
to be transmitted before |
be transmitted before it |
transmitted before it can |
before it can continuous |
it can continuous packet |
can continuous packet loss |
may change its infiltration |
change its infiltration rates |
its infiltration rates of |
infiltration rates of all |
rates of all other |
of all other pools |
with each lost packet |
each lost packet driving |
lost packet driving the |
packet driving the send |
driving the send error |
the send error correction |
send error correction packets |
the total revenue of |
total revenue of each |
revenue of each step |
of each step is |
each step is normalized |
step is normalized to |
system further and further |
further and further out |
and further out of |
further out of sync |
out of sync with |
of sync with respect |
sync with respect to |
with respect to its |
respect to its importantly |
once the fec encoding |
the fec encoding is |
fec encoding is parameterized |
encoding is parameterized real |
so the revenue per |
the revenue per round |
revenue per round is |
per round is one |
with a rate and |
the pool taking a |
a rate and an |
pool taking a step |
rate and an interleave |
and an interleave to |
an interleave to tolerate |
interleave to tolerate a |
to tolerate a certain |
tolerate a certain burst |
a certain burst sensitive |
certain burst sensitive flow |
burst sensitive flow control |
taking a step knows |
a step knows the |
step knows the rate |
knows the rate of |
the rate of infiltrators |
rate of infiltrators attacking |
of infiltrators attacking it |
ip is unable to |
is unable to distinguish |
unable to distinguish length |
to distinguish length b |
though not their identity |
and the revenue rates |
the revenue rates of |
revenue rates of each |
rates of each of |
of each of the |
each of the other |
of the other pools |
this knowledge is required |
knowledge is required to |
is required to optimize |
required to optimize a |
to optimize a pool |
optimize a pool s |
a pool s revenue |
as we see next |
we explain in section |
explain in section viii |
in section viii how |
to between ephemeral loss |
section viii how a |
between ephemeral loss modes |
viii how a pool |
how a pool can |
a pool can technically |
pool can technically obtain |
can technically obtain this |
technically obtain this knowledge |
ephemeral loss modes due |
loss modes due to |
modes due to transient |
due to transient contolerate |
to transient contolerate a |
transient contolerate a burst |
contolerate a burst of |
a burst of length |
general analysis recall that |
analysis recall that mi |
recall that mi is |
that mi is the |
mi is the number |
is the number of |
the number of miners |
number of miners loyal |
of miners loyal to |
miners loyal to pool |
loyal to pool i |
all losses occurring gestion |
is the number of |
the number of miners |
number of miners used |
of miners used by |
miners used by pool |
used by pool i |
by pool i to |
pool i to infiltrate |
i to infiltrate pool |
to infiltrate pool j |
infiltrate pool j at |
pool j at step |
j at step t |
or dirty fiber and |
dirty fiber and persistent |
fiber and persistent in |
and persistent in bursts |
persistent in bursts of |
in bursts of size |
the mining rate of |
bursts of size less |
mining rate of pool |
of size less than |
size less than or |
less than or equal |
than or equal to |
or equal to b |
equal to b are |
to b are recovered |
b are recovered with |
are recovered with congestion |
rate of pool i |
of pool i is |
pool i is therefore |
i is therefore the |
the loss of one |
is therefore the number |
loss of one packet |
therefore the number of |
of one packet out |
one packet out of |
packet out of ten |
out of ten thousand |
of ten thousand is |
ten thousand is sufficient |
thousand is sufficient to |
is sufficient to reduce |
sufficient to reduce tcp |
the number of its |
number of its loyal |
of its loyal miners |
its loyal miners minus |
loyal miners minus the |
miners minus the miners |
minus the miners it |
the miners it uses |
miners it uses for |
it uses for infiltration |
ip throughput to a |
throughput to a third |
to a third of |
a third of its |
third of its the |
this effective mining rate |
of its the same |
effective mining rate is |
its the same latency |
mining rate is divided |
the same latency and |
same latency and this |
latency and this latency |
and this latency depends |
this latency depends on |
latency depends on the |
depends on the i |
on the i palossless |
the i palossless maximum |
rate is divided by |
is divided by the |
divided by the total |
by the total mining |
if one packet is |
one packet is lost |
packet is lost out |
is lost out of |
lost out of a |
out of a thousand |
the total mining rate |
total mining rate in |
mining rate in the |
rate in the system |
namely the number of |
the number of all |
number of all miners |
of all miners that |
all miners that do |
miners that do not |
that do not engage |
do not engage in |
not engage in block |
engage in block withholding |
we d like to |
d like to parameterize |
like to parameterize the |
to parameterize the encoding |
parameterize the encoding to |
the encoding to tolerate |
encoding to tolerate a |
denote the direct mining |
to tolerate a maximum |
the direct mining rate |
tolerate a maximum burst |
direct mining rate of |
a maximum burst length |
mining rate of pool |
rate of pool i |
of pool i at |
pool i at step |
i at step t |
at step t by |
step t by pp |
t by pp mi |
by pp mi j |
maximum burst length and |
burst length and then |
length and then have |
and then have recovthroughput |
then have recovthroughput collapses |
have recovthroughput collapses to |
recovthroughput collapses to a |
collapses to a thirtieth |
to a thirtieth of |
a thirtieth of the |
thirtieth of the maximum |
ery latency depend on |
latency depend on the |
depend on the actual |
on the actual burstiness |
the actual burstiness of |
actual burstiness of the |
burstiness of the loss |
at the same time |
we would like the |
would like the encoding |
like the encoding to |
the encoding to have |
encoding to have a |
fec constant rate for |
constant rate for network |
rate for network provisioning |
for network provisioning and |
network provisioning and stability |
k the revenue of |
the revenue of pool |
revenue of pool i |
of pool i in |
pool i in step |
i in step t |
in step t taken |
an fec scheme is |
step t taken through |
fec scheme is required |
t taken through infiltration |
scheme is required where |
taken through infiltration from |
through infiltration from pool |
infiltration from pool j |
from pool j s |
pool j s revenue |
j s revenue in |
is required where latency |
s revenue in step |
required where latency of |
revenue in step t |
where latency of fec |
latency of fec encoders |
of fec encoders are |
fec encoders are typically |
encoders are typically parameterized |
are typically parameterized with |
typically parameterized with an |
pool i distributes this |
i distributes this revenue |
distributes this revenue among |
this revenue among its |
revenue among its mi |
i members loyal and |
members loyal and infiltrators |
define the p p |
the p p infiltration |
p p infiltration matrix |
p infiltration matrix by |
infiltration matrix by its |
matrix by its i |
recovery degrades gracefully as |
degrades gracefully as losses |
gracefully as losses get |
as losses get burstier |
even tuple for each |
tuple for each outgoing |
for each outgoing sequence |
each outgoing sequence of |
outgoing sequence of r |
sequence of r data |
of r data packets |
a as the encoding |
as the encoding overhead |
the encoding overhead stays |
encoding overhead stays constant |
i ij the revenue |
ij the revenue density |
the revenue density of |
revenue density of pool |
density of pool i |
of pool i at |
c data and error |
data and error correction |
and error correction packets |
error correction packets are |
correction packets are sent |
pool i at the |
i at the end |
at the end of |
the end of step |
end of step t |
of step t is |
step t is its |
t is its revenue |
is its revenue from |
its revenue from direct |
revenue from direct mining |
redundancy information cannot be |
from direct mining together |
direct mining together with |
mining together with its |
together with its revenue |
with its revenue from |
its revenue from infiltrated |
revenue from infiltrated pools |
information cannot be generated |
cannot be generated and |
be generated and sent |
generated and sent until |
and sent until all |
divided by the number |
sent until all r |
until all r data |
all r data packets |
r data packets are |
data packets are available |
packets are available for |
are available for sending |
by the number of |
the number of its |
number of its loyal |
of its loyal miners |
its loyal miners together |
loyal miners together with |
miners together with block |
the latency of packet |
latency of packet recovery |
withholding infiltrators that attack |
infiltrators that attack it |
of packet recovery is |
packet recovery is determined |
recovery is determined by |
is determined by the |
determined by the rate |
by the rate at |
the rate at which |
rate at which the |
at which the sender |
which the sender transmits |
the sender transmits data |
generating error correction packets |
maelstrom design and implemenfrom |
design and implemenfrom less |
and implemenfrom less than |
implemenfrom less than r |
less than r data |
than r data packets |
r data packets at |
data packets at the |
packets at the sender |
at the sender is |
the sender is not |
sender is not a |
is not a viable |
not a viable tation |
a viable tation option |
viable tation option even |
tation option even though |
option even though the |
even though the data |
though the data rate |
the data rate in |
data rate in this |
rate in this channel |
in this channel is |
this channel is low |
or network could be |
network could be operating |
could be operating at |
be operating at near |
operating at near full |
at near full capacity |
near full capacity with |
full capacity with data |
capacity with data from |
with data from other |
data from other senders |
we describe the maelstrom |
describe the maelstrom appliance |
the maelstrom appliance as |
maelstrom appliance as a |
appliance as a single |
as a single machine |
a single machine fec |
single machine fec is |
machine fec is also |
fec is also very |
is also very susceptible |
also very susceptible to |
very susceptible to bursty |
susceptible to bursty losses |
and the revenue vector |
the revenue vector at |
revenue vector at step |
we will show how |
will show how more |
show how more machines |
how more machines can |
more machines can be |
machines can be added |
can be added to |
be added to terleaving |
vector at step t |
at step t is |
step t is hereinafter |
t is hereinafter we |
is hereinafter we move |
hereinafter we move to |
we move to a |
move to a static |
to a static state |
a static state analysis |
static state analysis and |
state analysis and omit |
analysis and omit the |
and omit the t |
omit the t argument |
the t argument in |
t argument in the |
argument in the expressions |
is a standard encoding |
a standard encoding technique |
standard encoding technique used |
encoding technique used the |
technique used the appliance |
used the appliance to |
the appliance to balance |
appliance to balance encoding |
to balance encoding load |
balance encoding load and |
encoding load and scale |
load and scale to |
and scale to multo |
scale to multo combat |
to multo combat bursty |
multo combat bursty loss |
where error correction pack |
tiple gigabits per second |
gigabits per second of |
per second of traffic |
a b c d |
b c d x |
c d x x |
d x x e |
x x e f |
x e f g |
e f g h |
f g h x |
g h x x |
h x x appliance |
since the row sums |
the row sums of |
row sums of the |
sums of the infiltration |
of the infiltration matrix |
the infiltration matrix are |
infiltration matrix are smaller |
matrix are smaller than |
are smaller than one |
its largest eigenvalue is |
largest eigenvalue is smaller |
eigenvalue is smaller than |
recall that difficulty is |
that difficulty is only |
difficulty is only adjusted |
is only adjusted periodically |
and there are transient |
there are transient effects |
are transient effects that |
transient effects that are |
effects that are not |
that are not covered |
are not covered by |
not covered by this |
covered by this stable |
lan mtu lambda jumbo |
we discuss this in |
discuss this in section |
this in section viii |
mtu lambda jumbo mtu |
lambda jumbo mtu recipe |
jumbo mtu recipe list |
miners miners miners the |
miners miners the revenue |
miners the revenue its |
the revenue its infiltrators |
revenue its infiltrators obtained |
its infiltrators obtained from |
infiltrators obtained from pool |
the revenue per loyal |
revenue per loyal pool |
miner is therefore r |
controls its infiltration rate |
its infiltration rate of |
infiltration rate of pool |
and will choose the |
will choose the value |
choose the value that |
the value that maximizes |
value that maximizes the |
that maximizes the revenue |
maximizes the revenue density |
on the first round |
the first round of |
first round of the |
round of the pool |
of the pool game |
repair packets are injected |
packets are injected into |
are injected into stream |
injected into stream transparently |
the value of r |
is maximized at a |
maximized at a single |
at a single point |
a single point in |
single point in the |
point in the feasible |
in the feasible range |
basic mechanism the basic |
mechanism the basic operation |
the basic operation of |
basic operation of maelstrom |
operation of maelstrom is |
of maelstrom is shown |
maelstrom is shown in |
is shown in figure |
it intercepts outgoing data |
intercepts outgoing data packets |
outgoing data packets and |
data packets and routes |
packets and routes them |
and routes them to |
routes them to the |
them to the destination |
to the destination datacenter |
cannot not react to |
not react to pool |
generating and injecting fec |
and injecting fec repair |
injecting fec repair packets |
fec repair packets into |
repair packets into the |
packets into the stream |
into the stream in |
the stream in their |
stream in their wake |
this point is the |
point is the stable |
is the stable state |
the stable state of |
stable state of the |
state of the system |
a repair packet consists |
repair packet consists of |
packet consists of a |
consists of a recipe |
and we denote the |
we denote the value |
denote the value of |
the value of x |
of a recipe list |
a recipe list of |
recipe list of data |
list of data packet |
of data packet identifiers |
data packet identifiers and |
packet identifiers and fec |
identifiers and fec information |
and fec information generated |
fec information generated from |
information generated from these |
generated from these packets |
in the example in |
the example in figure |
this information is a |
information is a simple |
is a simple xor |
the size of the |
size of the xor |
of the xor is |
the xor is equal |
xor is equal to |
is equal to the |
equal to the mtu |
to the mtu of |
the mtu of the |
mtu of the datacenter |
of the datacenter network |
and to avoid fragmentation |
to avoid fragmentation of |
avoid fragmentation of repair |
fragmentation of repair packets |
of repair packets we |
repair packets we require |
packets we require that |
we require that the |
require that the mtu |
that the mtu of |
the mtu of the |
mtu of the long |
and the values of |
the values of the |
values of the corresponding |
of the corresponding revenues |
haul network be set |
network be set to |
be set to a |
set to a slightly |
to a slightly larger |
a slightly larger value |
the corresponding revenues of |
corresponding revenues of the |
revenues of the pools |
of the pools with |
the pools with r |
this requirement is usually |
requirement is usually satisfied |
is usually satisfied in |
usually satisfied in practical |
satisfied in practical deployments |
since gigabit links very |
gigabit links very often |
links very often use |
very often use jumbo |
often use jumbo frames |
use jumbo frames of |
substituting the stable value |
the stable value x |
jumbo frames of up |
frames of up to |
we obtain the revenues |
obtain the revenues of |
the revenues of the |
revenues of the two |
of the two pools |
all are given in |
are given in figure |
while lan networks have |
lan networks have standard |
networks have standard mtus |
have standard mtus of |
to simplify the expressions |
at the receiving datacenter |
the appliance examines incoming |
appliance examines incoming repair |
examines incoming repair packets |
incoming repair packets and |
repair packets and uses |
packets and uses them |
no attack if no |
attack if no pool |
if no pool engages |
no pool engages in |
pool engages in block |
engages in block withholding |
and uses them to |
uses them to recover |
them to recover missing |
to recover missing data |
recover missing data packets |
the data packet is |
data packet is injected |
packet is injected transparently |
is injected transparently into |
injected transparently into the |
transparently into the stream |
into the stream to |
the stream to the |
stream to the receiving |
to the receiving end |
recovered data packets will |
data packets will typically |
packets will typically arrive |
will typically arrive out |
and we have i |
but this behavior is |
this behavior is expected |
behavior is expected by |
is expected by communication |
expected by communication stacks |
by communication stacks designed |
communication stacks designed for |
stacks designed for the |
designed for the commodity |
for the commodity internet |
flow control while relaying |
control while relaying tcp |
each miner s revenue |
miner s revenue is |
s revenue is proportional |
revenue is proportional to |
is proportional to its |
proportional to its power |
maelstrom has two flow |
has two flow control |
two flow control modes |
be it in a |
it in a pool |
in a pool or |
a pool or working |
pool or working solo |
o ne attacker we |
ne attacker we begin |
attacker we begin our |
we begin our analysis |
begin our analysis with |
our analysis with a |
analysis with a simplified |
with a simplified game |
a simplified game of |
simplified game of two |
game of two pools |
the appliance routes packets |
appliance routes packets through |
routes packets through without |
packets through without modification |
control between the endhosts |
the appliance acts as |
appliance acts as a |
acts as a tcp |
terminating connections and sending |
connections and sending back |
and sending back acks |
sending back acks immediately |
back acks immediately before |
acks immediately before relaying |
immediately before relaying data |
before relaying data on |
relaying data on appliance |
this is particularly useful |
is particularly useful for |
particularly useful for applications |
useful for applications with |
for applications with short |
miners outside both pools |
outside both pools mine |
both pools mine solo |
lived flows that need |
flows that need to |
that need to ramp |
need to ramp up |
or with closed pools |
with closed pools that |
to ramp up throughput |
ramp up throughput quickly |
up throughput quickly and |
throughput quickly and avoid |
quickly and avoid the |
and avoid the slow |
closed pools that do |
pools that do not |
that do not attack |
do not attack and |
not attack and cannot |
attack and cannot be |
and cannot be attacked |
start effects of tcp |
ip on a long |
on a long link |
this scenario is illustrated |
scenario is illustrated in |
is illustrated in figure |
the performance advantages of |
performance advantages of splitting |
advantages of splitting longdistance |
of splitting longdistance connections |
splitting longdistance connections into |
longdistance connections into multiple |
connections into multiple hops |
into multiple hops are |
multiple hops are well |
hops are well known |
the dashed red arrow |
dashed red arrow indicates |
red arrow indicates that |
arrow indicates that x |
and orthogonal to this |
orthogonal to this work |
we are primarily interested |
are primarily interested in |
primarily interested in isolating |
s mining power infiltrates |
mining power infiltrates pool |
interested in isolating the |
in isolating the impact |
isolating the impact of |
the impact of rapid |
with a block withholding |
a block withholding attack |
impact of rapid and |
of rapid and transparent |
rapid and transparent recovery |
and transparent recovery of |
transparent recovery of lost |
recovery of lost packets |
of lost packets by |
lost packets by maelstrom |
packets by maelstrom on |
by maelstrom on tcp |
does not engage in |
not engage in block |
engage in block withholding |
all of its m |
rather than the buffering |
than the buffering and |
the buffering and slow |
loyal miners work on |
miners work on its |
work on its behalf |
start avoidance benefits of |
avoidance benefits of generic |
benefits of generic performance |
in the remainder of |
the remainder of the |
remainder of the paper |
on the other hand |
the other hand does |
other hand does not |
hand does not employ |
does not employ x |
we describe maelstrom with |
describe maelstrom with end |
of its loyal miners |
and its direct mining |
its direct mining power |
direct mining power is |
mining power is only |
power is only m |
while maelstrom respects end |
end flow control connections |
or splits them and |
splits them and implements |
them and implements its |
and implements its own |
implements its own proxy |
the bitcoin system normalizes |
bitcoin system normalizes these |
system normalizes these rates |
proxy flow control as |
flow control as described |
control as described above |
normalizes these rates by |
these rates by the |
rates by the total |
by the total number |
the total number of |
total number of miners |
number of miners that |
of miners that publish |
miners that publish full |
that publish full proofs |
it is not designed |
is not designed for |
not designed for routinely |
designed for routinely congested |
for routinely congested networks |
namely all miners but |
all miners but x |
the addition of fec |
addition of fec under |
of fec under tcp |
ip flow control allows |
flow control allows it |
control allows it to |
allows it to steal |
it to steal bandwidth |
to steal bandwidth from |
steal bandwidth from other |
bandwidth from other competing |
from other competing flows |
other competing flows running |
competing flows running without |
flows running without fec |
running without fec in |
without fec in the |
fec in the link |
the pools direct revenues |
pools direct revenues are |
direct revenues are therefore |
revenues are therefore m |
though maintaining fairness versus |
maintaining fairness versus similarly |
fairness versus similarly fec |
friendliness with conventional tcp |
ip flows is not |
flows is not a |
is not a primary |
not a primary protocol |
a primary protocol design |
primary protocol design goal |
protocol design goal on |
design goal on over |
which are often dedicated |
are often dedicated to |
often dedicated to specific |
dedicated to specific highvalue |
to specific highvalue applications |
we see evidence for |
see evidence for this |
evidence for this assertion |
for this assertion in |
this assertion in the |
assertion in the routine |
in the routine use |
the routine use of |
routine use of parallel |
use of parallel flows |
and udp blast protocols |
divides its revenue among |
its revenue among its |
revenue among its loyal |
among its loyal miners |
its loyal miners and |
loyal miners and the |
miners and the miners |
and the miners that |
the miners that infiltrated |
miners that infiltrated it |
its revenue density is |
revenue density is therefore |
density is therefore r |
both in commercial deployments |
in commercial deployments and |
commercial deployments and by |
deployments and by researchers |
and by researchers seeking |
by researchers seeking to |
researchers seeking to transfer |
seeking to transfer large |
to transfer large amounts |
transfer large amounts of |
large amounts of data |
amounts of data over |
of data over high |
layered interleaving in layered |
interleaving in layered interleaving |
an fec protocol with |
fec protocol with rate |
is produced by running |
produced by running c |
by running c multiple |
running c multiple instances |
c multiple instances of |
multiple instances of an |
fec protocol simultaneously with |
protocol simultaneously with increasing |
simultaneously with increasing interleave |
with increasing interleave indices |
increasing interleave indices i |
game progress bitcoin network |
progress bitcoin network figure |
we obtain the expression |
obtain the expression for |
the expression for r |
three instances of an |
the first instance with |
first instance with interleave |
instance with interleave i |
divides its revenue among |
its revenue among its |
revenue among its registered |
among its registered miners |
the second with interleave |
second with interleave i |
the revenue includes both |
revenue includes both its |
includes both its direct |
both its direct mining |
its direct mining revenue |
direct mining revenue and |
mining revenue and b |
numerical analysis we analyze |
analysis we analyze this |
we analyze this game |
analyze this game numerically |
this game numerically by |
game numerically by finding |
numerically by finding the |
by finding the x |
and the third with |
the third with interleave |
third with interleave i |
and substituting this value |
substituting this value for |
this value for r |
we vary the sizes |
vary the sizes of |
the sizes of the |
sizes of the pools |
of the pools through |
the pools through the |
pools through the entire |
through the entire feasible |
the entire feasible range |
fec encoding is simply |
entire feasible range and |
feasible range and depict |
range and depict the |
and depict the optimal |
depict the optimal x |
encoding is simply an |
is simply an xor |
simply an xor of |
an xor of the |
xor of the r |
of the r data |
the r data packets |
r data packets hence |
in layered interleaving each |
layered interleaving each data |
interleaving each data packet |
each data packet is |
data packet is included |
packet is included in |
is included in c |
included in c xors |
and the corresponding revenues |
the corresponding revenues in |
corresponding revenues in figure |
each of which is |
of which is generated |
which is generated at |
is generated at different |
generated at different interleaves |
at different interleaves from |
different interleaves from the |
interleaves from the original |
from the original data |
the original data stream |
each point in each |
point in each graph |
in each graph represents |
each graph represents the |
graph represents the equilibrium |
represents the equilibrium point |
the equilibrium point of |
equilibrium point of a |
as we shall describe |
we shall describe shortly |
point of a game |
of a game with |
a game with the |
game with the corresponding |
with the corresponding m |
ensures that the c |
that the c xors |
the c xors containing |
c xors containing a |
xors containing a data |
containing a data packet |
a data packet do |
data packet do not |
packet do not have |
do not have any |
not have any other |
where we normalize m |
the top right half |
top right half of |
right half of the |
half of the range |
of the range in |
the range in all |
range in all graphs |
in all graphs is |
all graphs is not |
graphs is not feasible |
as the sum of |
the sum of m |
we use this range |
use this range as |
this range as a |
range as a reference |
as a reference color |
and we use a |
we use a dashed |
use a dashed line |
a dashed line to |
dashed line to show |
line to show the |
to show the bound |
show the bound between |
the bound between this |
bound between this value |
between this value within |
this value within the |
value within the feasible |
within the feasible range |
a shows the optimal |
shows the optimal infiltration |
the optimal infiltration rate |
in the entire feasible |
the entire feasible range |
entire feasible range we |
feasible range we see |
range we see that |
we see that pool |
chooses a strictly positive |
a strictly positive value |
strictly positive value for |
positive value for x |
the revenue of pool |
is depicted in figure |
b and in the |
and in the entire |
in the entire feasible |
the entire feasible region |
entire feasible region it |
feasible region it is |
region it is strictly |
it is strictly larger |
is strictly larger than |
which the pool would |
data packet in common |
the pool would have |
pool would have gotten |
would have gotten without |
have gotten without attacking |
the resulting protocol effectively |
resulting protocol effectively has |
protocol effectively has a |
effectively has a rate |
has a rate of |
with each xor generated |
each xor generated from |
xor generated from r |
generated from r data |
from r data packets |
r data packets and |
data packets and each |
packets and each data |
and each data packet |
each data packet included |
data packet included in |
packet included in c |
included in c xors |
c depicts the revenue |
illustrates layered interleaving for |
layered interleaving for a |
depicts the revenue of |
the revenue of pool |
which is strictly smaller |
is strictly smaller than |
in the entire range |
note that the total |
that the total system |
the total system mining |
total system mining power |
system mining power is |
mining power is reduced |
power is reduced when |
is reduced when pool |
chooses to infiltrate pool |
the revenue of third |
revenue of third parties |
miners not in either |
not in either pool |
standard fec schemes can |
fec schemes can be |
schemes can be made |
can be made resistant |
be made resistant to |
made resistant to a |
resistant to a certain |
to a certain loss |
a certain loss burst |
certain loss burst length |
loss burst length at |
burst length at the |
length at the cost |
at the cost of |
the cost of increased |
cost of increased recovery |
of increased recovery latency |
increased recovery latency for |
recovery latency for all |
latency for all lost |
for all lost packets |
including smaller bursts and |
smaller bursts and singleton |
bursts and singleton drops |
therefore pays for the |
pays for the increased |
for the increased revenue |
layered interleaving provides graceful |
the increased revenue of |
increased revenue of its |
revenue of its attacker |
interleaving provides graceful degradation |
of its attacker and |
its attacker and everyone |
attacker and everyone else |
and everyone else in |
everyone else in the |
else in the system |
provides graceful degradation in |
graceful degradation in the |
degradation in the face |
in the face of |
the face of bursty |
face of bursty loss |
of bursty loss for |
bursty loss for constant |
implications to the general |
to the general case |
the general case consider |
general case consider the |
case consider the case |
consider the case of |
the case of p |
case of p pools |
loss for constant encoding |
for constant encoding overhead |
constant encoding overhead singleton |
encoding overhead singleton random |
for any choice of |
any choice of the |
choice of the pools |
of the pools sizes |
the pools sizes m |
overhead singleton random losses |
singleton random losses are |
random losses are recovered |
losses are recovered as |
are recovered as quickly |
recovered as quickly as |
as quickly as possible |
by xors generated with |
xors generated with an |
generated with an interleave |
with an interleave of |
and each successive layer |
each successive layer of |
successive layer of xors |
layer of xors generated |
of xors generated at |
xors generated at a |
generated at a higher |
at a higher interleave |
a higher interleave catches |
higher interleave catches larger |
interleave catches larger bursts |
catches larger bursts missed |
larger bursts missed by |
bursts missed by the |
missed by the previous |
by the previous layer |
at least one pool |
least one pool will |
one pool will choose |
pool will choose to |
will choose to perform |
choose to perform block |
to perform block withholding |
the implementation of this |
implementation of this algorithm |
of this algorithm is |
this algorithm is simple |
algorithm is simple and |
is simple and shown |
simple and shown in |
and shown in figure |
a set of repair |
set of repair bins |
of repair bins is |
repair bins is maintained |
bins is maintained for |
is maintained for each |
maintained for each layer |
with i bins for |
i bins for a |
bins for a layer |
for a layer with |
a layer with interleave |
layer with interleave i |
a repair bin consists |
repair bin consists of |
bin consists of a |
consists of a partially |
of a partially constructed |
a partially constructed repair |
partially constructed repair packet |
an xor and the |
xor and the recipe |
and the recipe list |
the recipe list of |
recipe list of identifiers |
list of identifiers of |
of identifiers of data |
identifiers of data packets |
of data packets that |
data packets that compose |
packets that compose the |
that compose the xor |
each intercepted data packet |
intercepted data packet is |
data packet is added |
packet is added to |
is added to each |
added to each layer |
to each layer where |
each layer where adding |
layer where adding to |
where adding to a |
adding to a layer |
to a layer simply |
a layer simply means |
layer simply means choosing |
simply means choosing a |
means choosing a repair |
choosing a repair bin |
a repair bin from |
repair bin from the |
bin from the layer |
from the layer s |
the layer s set |
incrementally updating the xor |
updating the xor with |
the xor with the |
xor with the new |
with the new data |
the new data packet |
and adding the data |
adding the data packet |
the data packet s |
data packet s header |
packet s header to |
s header to the |
header to the recipe |
to the recipe list |
a counter is incremented |
counter is incremented as |
is incremented as each |
incremented as each data |
as each data packet |
each data packet arrives |
data packet arrives at |
packet arrives at the |
arrives at the appliance |
and choosing the repair |
choosing the repair bin |
the repair bin from |
repair bin from the |
bin from the layer |
from the layer s |
the layer s set |
layer s set is |
s set is done |
set is done by |
is done by taking |
done by taking the |
by taking the modulo |
taking the modulo of |
the modulo of the |
modulo of the counter |
of the counter with |
the counter with the |
counter with the number |
with the number of |
the number of bins |
number of bins in |
of bins in each |
bins in each layer |
for a layer with |
a layer with interleave |
the xth intercepted packet |
xth intercepted packet is |
intercepted packet is added |
packet is added to |
is added to the |
when a repair bin |
a repair bin fills |
repair bin fills up |
bin fills up its |
fills up its recipe |
up its recipe list |
its recipe list contains |
recipe list contains r |
list contains r data |
contains r data packets |
r data packets it |
data packets it fires |
a repair packet is |
repair packet is generated |
packet is generated consisting |
is generated consisting of |
generated consisting of the |
consisting of the xor |
of the xor and |
the xor and the |
xor and the recipe |
and the recipe list |
the recipe list and |
recipe list and is |
list and is scheduled |
and is scheduled for |
is scheduled for sending |
while the repair bin |
the repair bin is |
repair bin is re |
initialized with an empty |
with an empty recipe |
an empty recipe list |
empty recipe list and |
recipe list and blank |
list and blank xor |
incoming repair packets are |
repair packets are processed |
packets are processed as |
are processed as follows |
if all the data |
all the data packets |
the data packets contained |
data packets contained in |
packets contained in the |
contained in the repair |
in the repair s |
the repair s recipe |
repair s recipe list |
s recipe list have |
recipe list have been |
list have been received |
have been received successfully |
the repair packet is |
repair packet is discarded |
if the repair s |
the repair s recipe |
repair s recipe list |
s recipe list contains |
recipe list contains a |
list contains a single |
contains a single missing |
a single missing data |
single missing data packet |
recovery can occur immediately |
can occur immediately by |
occur immediately by combining |
immediately by combining the |
by combining the xor |
combining the xor in |
the xor in the |
xor in the repair |
in the repair with |
the repair with layer |
stable state where only |
state where only pool |
layer with interleave of |
two pools where one |
pools where one infiltrates |
where one infiltrates the |
one infiltrates the other |
optimal infiltration rate x |
as a function of |
a function of pool |
function of pool sizes |
and the lines in |
show the revenue density |
the revenue density of |
in a system with |
a system with p |
system with p pools |
the other successfully received |
other successfully received data |
successfully received data packets |
if the repair contains |
the repair contains multiple |
repair contains multiple missing |
contains multiple missing data |
multiple missing data packets |
is not an equilibrium |
it cannot be used |
cannot be used immediately |
be used immediately for |
used immediately for recovery |
immediately for recovery it |
for recovery it is |
recovery it is instead |
it is instead stored |
assume towards negation this |
towards negation this is |
negation this is not |
this is not the |
is not the case |
is instead stored in |
instead stored in a |
stored in a table |
in a table that |
a table that maps |
table that maps missing |
that maps missing data |
maps missing data packets |
missing data packets to |
data packets to repair |
packets to repair packets |
whenever a data packet |
a data packet is |
data packet is subsequently |
packet is subsequently received |
is subsequently received or |
subsequently received or recovered |
is an equilibrium point |
this table is checked |
now consider a setting |
consider a setting with |
a setting with only |
setting with only pools |
table is checked to |
is checked to see |
checked to see if |
to see if any |
see if any xors |
if any xors now |
any xors now have |
xors now have singleton |
now have singleton losses |
have singleton losses due |
and treat the other |
treat the other pools |
the other pools as |
other pools as independent |
pools as independent miners |
singleton losses due to |
losses due to the |
due to the presence |
to the presence of |
this is the setting |
the presence of the |
is the setting analyzed |
presence of the new |
the setting analyzed above |
setting analyzed above and |
analyzed above and we |
above and we have |
and we have seen |
we have seen there |
have seen there that |
seen there that pool |
of the new packet |
the new packet and |
new packet and can |
packet and can be |
and can be used |
can increase its revenue |
can be used for |
be used for recovering |
used for recovering other |
for recovering other missing |
recovering other missing packets |
increase its revenue by |
its revenue by performing |
revenue by performing a |
by performing a block |
performing a block withholding |
a block withholding attack |
block withholding attack on |
withholding attack on pool |
xors received from different |
received from different layers |
from different layers interact |
different layers interact to |
layers interact to recover |
interact to recover missing |
to recover missing data |
recover missing data packets |
s infiltration rate by |
infiltration rate by x |
since an xor received |
an xor received at |
xor received at a |
received at a higher |
at a higher interleave |
a higher interleave can |
higher interleave can recover |
interleave can recover a |
can recover a packet |
recover a packet that |
a packet that makes |
packet that makes an |
that makes an earlier |
makes an earlier xor |
an earlier xor at |
earlier xor at a |
xor at a lower |
at a lower interleave |
a lower interleave usable |
lower interleave usable hence |
though layered interleaving is |
layered interleaving is equivalent |
interleaving is equivalent to |
is equivalent to c |
equivalent to c different |
take this values back |
this values back to |
values back to the |
back to the setting |
to the setting at |
the setting at hand |
setting at hand with |
at hand with p |
hand with p pools |
the revenue of pool |
instances in terms of |
is better when x |
in terms of overhead |
terms of overhead and |
of overhead and design |
its recovery power is |
recovery power is much |
power is much higher |
is much higher and |
much higher and comes |
higher and comes close |
and comes close to |
comes close to standard |
name size discusfish antpool |
size discusfish antpool ghash |
io btchine btcguild eligius |
btchine btcguild eligius others |
second set of rsized |
set of rsized xors |
of rsized xors staggered |
rsized xors staggered start |
xors staggered start xors |
the six largest open |
six largest open pool |
largest open pool sizes |
open pool sizes as |
pool sizes as of |
sizes as of january |
their optimal infiltration rates |
of each pool as |
each pool as a |
pool as a fraction |
as a fraction of |
a fraction of its |
fraction of its size |
if it attacked all |
it attacked all others |
attacked all others without |
all others without reciprocation |
and their revenue density |
their revenue density when |
revenue density when attacking |
can improve its revenue |
improve its revenue by |
its revenue by attacking |
revenue by attacking pool |
attacks is not an |
is not an equilibrium |
not an equilibrium point |
case as a test |
as a test case |
we take the pool |
take the pool distribution |
the pool distribution in |
pool distribution in january |
we analyze the cases |
analyze the cases where |
the cases where each |
cases where each of |
where each of the |
each of the pools |
of the pools attacks |
the pools attacks all |
pools attacks all other |
attacks all other open |
all other open pools |
all of which behave |
of which behave honestly |
note that attacking all |
that attacking all pools |
attacking all pools with |
all pools with force |
pools with force proportional |
with force proportional to |
force proportional to their |
proportional to their size |
to their size yields |
their size yields the |
size yields the same |
yields the same results |
the same results as |
same results as attacking |
results as attacking a |
as attacking a single |
attacking a single pool |
a single pool of |
single pool of their |
pool of their aggregate |
of their aggregate size |
plugging in the numbers |
in the numbers into |
the numbers into the |
numbers into the analysis |
into the analysis above |
the analysis above shows |
analysis above shows that |
above shows that a |
shows that a larger |
that a larger pool |
a larger pool needs |
larger pool needs to |
pool needs to use |
needs to use a |
to use a smaller |
use a smaller ratio |
a smaller ratio of |
smaller ratio of its |
ratio of its mining |
of its mining power |
its mining power for |
mining power for infiltration |
power for infiltration and |
for infiltration and can |
infiltration and can increase |
and can increase its |
can increase its revenue |
increase its revenue density |
its revenue density more |
revenue density more than |
density more than a |
more than a small |
than a small pool |
achieves its optimum attack |
its optimum attack rate |
optimum attack rate at |
of the pool s |
the pool s mining |
pool s mining power |
increasing its revenue by |
its revenue by almost |
this amounts to a |
amounts to a daily |
to a daily revenue |
a daily revenue increase |
daily revenue increase of |
revenue increase of b |
usd at the exchange |
at the exchange rate |
the exchange rate on |
exchange rate on that |
rate on that date |
this represents a considerable |
represents a considerable increase |
a considerable increase of |
considerable increase of the |
increase of the pools |
of the pools net |
the pools net revenue |
for the smallest pool |
the attack is much |
attack is much less |
is much less profitable |
to reach the optimum |
reach the optimum it |
the optimum it needs |
optimum it needs almost |
it needs almost a |
needs almost a third |
almost a third of |
a third of its |
third of its power |
of its power for |
its power for attacking |
power for attacking but |
for attacking but increases |
attacking but increases its |
but increases its revenue |
increases its revenue density |
its revenue density by |
revenue density by merely |
comparison of packet recovery |
of packet recovery probability |
optimizations staggered start for |
staggered start for rate |
limiting in the naive |
in the naive implementation |
the naive implementation of |
naive implementation of the |
implementation of the layered |
of the layered interleaving |
the layered interleaving algorithm |
repair packets are transmitted |
packets are transmitted as |
are transmitted as soon |
transmitted as soon as |
as soon as repair |
soon as repair bins |
as repair bins fill |
repair bins fill and |
bins fill and allow |
fill and allow them |
and allow them to |
allow them to be |
them to be constructed |
all the repair bins |
the repair bins in |
repair bins in a |
bins in a layer |
in a layer fill |
a layer fill in |
layer fill in quick |
fill in quick succession |
two attacking pools system |
the arrival of packets |
as a function of |
a function of pool |
function of pool sizes |
will successively fill the |
successively fill the four |
fill the four repair |
the four repair bins |
four repair bins in |
repair bins in layer |
this behavior leads to |
behavior leads to a |
leads to a large |
to a large number |
a large number of |
large number of repair |
number of repair packets |
of repair packets being |
repair packets being generated |
packets being generated and |
being generated and sent |
generated and sent within |
and sent within a |
sent within a short |
within a short period |
a short period of |
short period of time |
which results in undesirable |
results in undesirable overhead |
in undesirable overhead and |
undesirable overhead and traffic |
overhead and traffic spikes |
we would like to |
would like to rate |
limit transmissions of repair |
transmissions of repair packets |
of repair packets to |
repair packets to one |
packets to one for |
to one for every |
one for every r |
for every r data |
every r data packets |
this problem is fixed |
problem is fixed by |
is fixed by staggering |
fixed by staggering the |
by staggering the starting |
staggering the starting sizes |
the starting sizes of |
starting sizes of the |
sizes of the bins |
analogous to the starting |
to the starting positions |
the starting positions of |
starting positions of runners |
positions of runners in |
of runners in a |
runners in a sprint |
the very first time |
very first time bin |
first time bin number |
time bin number x |
bin number x in |
number x in a |
x in a layer |
in a layer of |
a layer of interleave |
layer of interleave i |
of interleave i fires |
it does so at |
does so at size |
so at size x |
at size x mod |
size x mod r |
the first repair bin |
first repair bin in |
repair bin in the |
bin in the second |
in the second layer |
the second layer with |
second layer with interleave |
t wo p ools |
wo p ools we |
p ools we proceed |
ools we proceed to |
would fire at size |
we proceed to analyze |
proceed to analyze the |
to analyze the case |
analyze the case where |
the case where two |
case where two pools |
where two pools may |
two pools may attack |
pools may attack each |
the second would fire |
second would fire at |
would fire at size |
may attack each other |
attack each other and |
each other and the |
other and the other |
and the other miners |
the other miners mine |
other miners mine solo |
again we have pool |
for the first i |
the first i data |
first i data packets |
i data packets added |
data packets added to |
packets added to a |
added to a layer |
to a layer with |
a layer with interleave |
layer with interleave i |
r fire immediately with |
fire immediately with just |
immediately with just one |
with just one packet |
just one packet in |
one packet in them |
controls its infiltration rate |
its infiltration rate x |
for the next i |
the next i data |
next i data packets |
i data packets added |
r fire immediately with |
fire immediately with two |
immediately with two data |
with two data packets |
two data packets in |
data packets in them |
and so on until |
so on until r |
also controls its infiltration |
controls its infiltration rate |
its infiltration rate x |
on until r i |
until r i data |
r i data packets |
i data packets have |
data packets have been |
packets have been added |
have been added to |
been added to the |
added to the layer |
to the layer and |
the layer and all |
layer and all bins |
and all bins have |
all bins have fired |
bins have fired exactly |
have fired exactly once |
this scenario is illustrated |
scenario is illustrated in |
is illustrated in figure |
all bins fire at |
bins fire at size |
fire at size r |
the total mining power |
total mining power in |
mining power in the |
power in the system |
in the system is |
the system is m |
system is m x |
now that they have |
that they have been |
they have been staggered |
have been staggered at |
been staggered at the |
staggered at the start |
r fire for any |
fire for any i |
for any i data |
any i data packets |
the outlined scheme works |
outlined scheme works when |
scheme works when i |
works when i is |
when i is greater |
i is greater than |
is greater than or |
greater than or equal |
than or equal to |
or equal to r |
the direct revenues r |
as is usually the |
is usually the case |
if i is smaller |
of the pools from |
i is smaller than |
is smaller than r |
the pools from mining |
pools from mining are |
from mining are their |
mining are their effective |
are their effective mining |
their effective mining rates |
the bin with index |
bin with index x |
with index x fires |
index x fires at |
without infiltrating mining power |
divided by the total |
by the total mining |
the total mining rate |
the initial firing sizes |
initial firing sizes would |
firing sizes would be |
for the first bin |
the first bin and |
for the second bin |
if r and i |
r and i are |
and i are not |
i are not integral |
are not integral multiples |
not integral multiples of |
integral multiples of each |
multiples of each other |
limiting still works but |
still works but is |
works but is slightly |
but is slightly less |
is slightly less effective |
slightly less effective due |
less effective due to |
effective due to rounding |
due to rounding errors |
delaying xors in the |
xors in the naive |
in the naive implementation |
repair packets are transmitted |
packets are transmitted as |
are transmitted as soon |
transmitted as soon as |
as soon as they |
soon as they are |
as they are generated |
this results in the |
results in the repair |
in the repair packet |
the repair packet leaving |
repair packet leaving immediately |
packet leaving immediately after |
leaving immediately after the |
immediately after the last |
after the last data |
the last data packet |
last data packet that |
data packet that was |
packet that was added |
that was added to |
was added to it |
which lowers burst tolerance |
lowers burst tolerance if |
burst tolerance if the |
tolerance if the repair |
if the repair packet |
the repair packet was |
repair packet was generated |
packet was generated at |
was generated at interleave |
generated at interleave i |
the resulting protocol can |
resulting protocol can tolerate |
protocol can tolerate a |
can tolerate a burst |
tolerate a burst of |
a burst of i |
burst of i lost |
of i lost data |
i lost data packets |
lost data packets excluding |
data packets excluding the |
packets excluding the repair |
the total revenue of |
total revenue of each |
revenue of each pool |
of each pool is |
each pool is its |
pool is its direct |
is its direct mining |
its direct mining revenue |
but the burst could |
the burst could swallow |
burst could swallow both |
could swallow both the |
swallow both the repair |
both the repair and |
the repair and the |
repair and the last |
and the last data |
the last data packet |
last data packet in |
data packet in it |
packet in it as |
in it as they |
it as they are |
as they are not |
they are not separated |
are not separated by |
not separated by the |
separated by the requisite |
by the requisite interleave |
the solution to this |
solution to this is |
to this is simple |
this is simple delay |
is simple delay sending |
simple delay sending the |
delay sending the repair |
sending the repair packet |
the repair packet generated |
repair packet generated by |
packet generated by a |
generated by a repair |
by a repair bin |
a repair bin until |
repair bin until the |
bin until the next |
until the next time |
the next time a |
next time a data |
time a data packet |
a data packet is |
data packet is added |
packet is added to |
is added to the |
added to the now |
to the now empty |
the now empty bin |
two pools infiltrating each |
pools infiltrating each other |
which happens i packets |
happens i packets later |
i packets later and |
packets later and introduces |
later and introduces the |
and introduces the required |
and the infiltration revenue |
the infiltration revenue from |
infiltration revenue from the |
revenue from the previous |
from the previous round |
introduces the required interleave |
the required interleave between |
required interleave between the |
interleave between the repair |
between the repair packet |
which is the attacked |
the repair packet and |
repair packet and the |
packet and the last |
and the last data |
the last data packet |
last data packet included |
data packet included in |
packet included in it |
is the attacked pool |
the attacked pool s |
attacked pool s total |
pool s total revenue |
s total revenue multiplied |
total revenue multiplied by |
revenue multiplied by its |
multiplied by its infiltration |
by its infiltration rate |
notice that although transmitting |
that although transmitting the |
although transmitting the xor |
transmitting the xor immediately |
the xor immediately results |
xor immediately results in |
immediately results in faster |
results in faster recovery |
the pool s total |
pool s total revenue |
s total revenue is |
total revenue is divided |
doing so also reduces |
revenue is divided among |
so also reduces the |
is divided among its |
divided among its loyal |
among its loyal miners |
its loyal miners and |
loyal miners and miners |
miners and miners that |
and miners that infiltrated |
miners that infiltrated it |
also reduces the probability |
reduces the probability of |
the probability of a |
probability of a lost |
of a lost packet |
a lost packet being |
lost packet being recovered |
at stable state this |
stable state this is |
state this is r |
off results in a |
results in a minor |
in a minor control |
a minor control knob |
minor control knob permitting |
control knob permitting us |
knob permitting us to |
permitting us to balance |
us to balance speed |
to balance speed against |
balance speed against burst |
speed against burst tolerance |
our default configuration is |
default configuration is to |
configuration is to transmit |
is to transmit the |
to transmit the xor |
transmit the xor immediately |
envelope analysis to start |
analysis to start with |
we note that no |
note that no two |
that no two repair |
no two repair packets |
two repair packets generated |
repair packets generated at |
packets generated at different |
generated at different interleaves |
at different interleaves i |
will have more than |
have more than one |
more than one data |
than one data packet |
one data packet in |
data packet in common |
packet in common as |
in common as long |
common as long as |
as long as the |
long as the least |
as the least common |
the least common multiple |
of the interleaves is |
the interleaves is greater |
interleaves is greater than |
is greater than r |
greater than r i |
pairings of repair bins |
of repair bins in |
repair bins in two |
bins in two different |
in two different layers |
two different layers with |
different layers with interleaves |
layers with interleaves i |
we obtain the following |
obtain the following closed |
the following closed expressions |
following closed expressions for |
closed expressions for each |
we express the revenues |
express the revenues as |
the revenues as functions |
revenues as functions of |
as functions of x |
a good rule of |
good rule of thumb |
rule of thumb is |
of thumb is to |
thumb is to select |
is to select interleaves |
to select interleaves that |
select interleaves that are |
interleaves that are relatively |
that are relatively prime |
are relatively prime to |
relatively prime to maximize |
prime to maximize their |
to maximize their lcm |
and also ensure that |
also ensure that the |
ensure that the larger |
that the larger interleave |
the larger interleave is |
larger interleave is greater |
interleave is greater than |
is greater than r |
let us assume that |
us assume that packets |
assume that packets are |
that packets are dropped |
packets are dropped with |
are dropped with uniform |
given a lost data |
a lost data packet |
what is the probability |
is the probability that |
the probability that we |
probability that we can |
that we can recover |
we can recover it |
we can recover a |
can recover a data |
recover a data packet |
a data packet if |
data packet if at |
packet if at least |
if at least one |
at least one of |
least one of the |
one of the c |
of the c xors |
the c xors containing |
c xors containing it |
xors containing it is |
containing it is re |
local recovery for receiver |
recovery for receiver loss |
for receiver loss ceived |
receiver loss ceived correctly |
loss ceived correctly and |
ceived correctly and usable |
all the other data |
the other data packets |
other data packets in |
data packets in it |
packets in it have |
in it have also |
it have also been |
have also been received |
also been received correctly |
the probability of in |
probability of in the |
of in the absence |
in the absence of |
the absence of intelligent |
absence of intelligent flow |
of intelligent flow control |
intelligent flow control mechanisms |
flow control mechanisms like |
control mechanisms like which |
mechanisms like which is |
like which is simply |
the probability of a |
probability of a received |
of a received tcp |
inexpensive xor being unusable |
xor being unusable is |
being unusable is the |
unusable is the complement |
hosts can be easily |
can be easily overwhelmed |
be easily overwhelmed and |
easily overwhelmed and drop |
overwhelmed and drop packets |
and drop packets during |
drop packets during traffic |
packets during traffic spikes |
during traffic spikes or |
traffic spikes or cpu |
the probability x of |
probability x of a |
x of a sent |
of a sent xor |
a sent xor being |
sent xor being nance |
xor being nance tasks |
being nance tasks like |
nance tasks like garbage |
tasks like garbage collection |
reliable applicationdropped or unusable |
applicationdropped or unusable is |
or unusable is the |
unusable is the sum |
is the sum of |
the sum of the |
sum of the probability |
of the probability that |
the probability that it |
probability that it level |
that it level protocols |
it level protocols layered |
level protocols layered over |
protocols layered over udp |
layered over udp for |
over udp for reliable |
udp for reliable multiwas |
for reliable multiwas dropped |
reliable multiwas dropped and |
multiwas dropped and the |
dropped and the probability |
and the probability that |
the probability that it |
probability that it was |
that it was received |
it was received and |
was received and cast |
or high speed data |
high speed data transfer |
each pool controls only |
pool controls only its |
controls only its own |
only its own infiltration |
its own infiltration rate |
in each round of |
each round of the |
round of the pool |
of the pool game |
each pool will optimize |
pool will optimize its |
will optimize its infiltration |
optimize its infiltration rate |
its infiltration rate of |
infiltration rate of the |
rate of the other |
acts at step t |
it optimizes its revenue |
optimizes its revenue with |
its revenue with r |
would ordinarily go back |
ordinarily go back to |
go back to the |
back to the sender |
to the sender to |
the sender to retrieve |
sender to retrieve the |
to retrieve the lost |
retrieve the lost packet |
even though it was |
though it was dropped |
it was dropped at |
was dropped at the |
dropped at the receiver |
at the receiver after |
the receiver after since |
receiver after since it |
after since it is |
since it is easy |
it is easy to |
is easy to ensure |
easy to ensure that |
to ensure that no |
ensure that no two |
that no two xors |
no two xors share |
two xors share covering |
xors share covering the |
share covering the entire |
covering the entire geographical |
the entire geographical distance |
more than one data |
than one data packet |
the usability probabilities of |
usability probabilities of the |
probabilities of the maelstrom |
of the maelstrom proxy |
the maelstrom proxy acts |
maelstrom proxy acts as |
proxy acts as a |
acts as a local |
as a local packet |
a local packet cache |
stordifferent xors are independent |
the probability of all |
probability of all ing |
of all ing incoming |
all ing incoming packets |
ing incoming packets for |
incoming packets for a |
packets for a short |
for a short period |
a short period of |
short period of time |
period of time and |
of time and prothe |
time and prothe c |
and prothe c xors |
prothe c xors being |
c xors being dropped |
xors being dropped or |
being dropped or unusable |
dropped or unusable is |
or unusable is xc |
viding hooks that allow |
hooks that allow protocols |
that allow protocols to |
allow protocols to first |
protocols to first query |
to first query the |
first query the cache |
query the cache the |
the cache the probability |
cache the probability of |
the probability of correctly |
probability of correctly receiving |
of correctly receiving at |
correctly receiving at least |
receiving at least one |
acts at step t |
at least one usable |
least one usable to |
one usable to locate |
usable to locate missing |
it optimizes its revenue |
optimizes its revenue with |
its revenue with x |
to locate missing packets |
locate missing packets before |
missing packets before sending |
packets before sending retransmission |
before sending retransmission xor |
sending retransmission xor is |
the probability of recovrequests |
probability of recovrequests back |
of recovrequests back to |
recovrequests back to the |
back to the sender |
future versions of maelstrom |
versions of maelstrom ering |
of maelstrom ering the |
maelstrom ering the lost |
ering the lost data |
the lost data packet |
lost data packet is |
which expands to could |
expands to could potentially |
to could potentially use |
could potentially use knowledge |
potentially use knowledge of |
use knowledge of protocol |
knowledge of protocol internals |
of protocol internals to |
by intercepting and this |
intercepting and this closed |
form formula only gives |
formula only gives us |
an equilibrium exists where |
equilibrium exists where neither |
exists where neither pool |
only gives us a |
gives us a lower |
us a lower bound |
a lower bound satisfying |
lower bound satisfying retransmission |
bound satisfying retransmission requests |
satisfying retransmission requests sent |
retransmission requests sent by |
can improve its revenue |
improve its revenue by |
its revenue by changing |
revenue by changing its |
by changing its infiltration |
changing its infiltration rate |
requests sent by the |
sent by the receiver |
by the receiver in |
the receiver in on |
receiver in on the |
in on the recovery |
on the recovery probability |
any pair of values |
pair of values x |
since the xor usability |
the xor usability for |
or by resending packets |
by resending packets when |
resending packets when acmula |
packets when acmula does |
when acmula does not |
such that arg maxx |
acmula does not factor |
does not factor in |
not factor in the |
factor in the probability |
in the probability of |
the probability of the |
probability of the other |
of the other data |
the other data knowledgments |
other data knowledgments are |
data knowledgments are not |
knowledgments are not observed |
are not observed within |
not observed within a |
observed within a certain |
within a certain time |
a certain time period |
certain time period in |
time period in an |
period in an ack |
packets in the xor |
in the xor being |
the xor being dropped |
xor being dropped and |
being dropped and recovered |
we extend the analysis |
extend the analysis to |
the analysis to bursty |
analysis to bursty losses |
if the lost data |
the lost data packet |
lost data packet was |
data packet was part |
packet was part of |
was part of a |
part of a loss |
of a loss burst |
a loss burst of |
loss burst of size |
burst of size b |
repair packets generated at |
packets generated at interleaves |
generated at interleaves less |
at interleaves less than |
interleaves less than b |
less than b are |
than b are dropped |
b are dropped or |
are dropped or useless |
dropped or useless with |
or useless with high |
useless with high probability |
and we can discount |
we can discount them |
probability of recovering the |
of recovering the data |
recovering the data packet |
the data packet is |
data packet is then |
is the number of |
the number of xors |
number of xors generated |
of xors generated at |
xors generated at interleaves |
generated at interleaves greater |
at interleaves greater than |
interleaves greater than b |
the formulae derived for |
formulae derived for xor |
derived for xor usability |
for xor usability still |
xor usability still hold |
since packet losses with |
packet losses with more |
losses with more than |
with more than b |
more than b intervening |
than b intervening packets |
b intervening packets between |
intervening packets between them |
packets between them have |
between them have independent |
them have independent probability |
there is only correlation |
is only correlation within |
only correlation within the |
correlation within the bursts |
how does this compare |
does this compare to |
this compare to traditional |
codes such as reed |
c repair packets are |
repair packets are generated |
packets are generated and |
are generated and sent |
generated and sent for |
and sent for every |
sent for every r |
for every r data |
every r data packets |
and the correct delivery |
the correct delivery of |
correct delivery of any |
delivery of any r |
of any r of |
any r of the |
r of the r |
c packets transmitted is |
packets transmitted is sufficient |
transmitted is sufficient to |
is sufficient to reconstruct |
sufficient to reconstruct the |
to reconstruct the original |
reconstruct the original r |
the original r data |
original r data packets |
given a lost data |
a lost data packet |
we can recover it |
can recover it if |
recover it if at |
it if at least |
if at least r |
at least r packets |
least r packets are |
r packets are received |
packets are received correctly |
are received correctly in |
received correctly in the |
correctly in the encoding |
in the encoding set |
the encoding set of |
encoding set of r |
the feasible region for |
feasible region for the |
region for the pool |
for the pool sizes |
the pool sizes is |
pool sizes is m |
c data and repair |
data and repair packets |
and repair packets that |
repair packets that the |
packets that the lost |
that the lost packet |
the lost packet belongs |
lost packet belongs to |
the probability of recovering |
probability of recovering a |
of recovering a lost |
recovering a lost packet |
a lost packet is |
lost packet is equivalent |
packet is equivalent to |
is equivalent to the |
equivalent to the probability |
to the probability of |
the probability of losing |
probability of losing c |
or less packets from |
less packets from the |
packets from the total |
from the total r |
since the number of |
the number of other |
number of other lost |
the revenue function for |
of other lost packets |
revenue function for ri |
other lost packets in |
function for ri is |
lost packets in the |
for ri is concave |
packets in the xor |
ri is concave in |
in the xor is |
is concave in xi |
concave in xi for |
in xi for all |
xi for all feasible |
for all feasible values |
all feasible values of |
feasible values of the |
values of the variables |
the xor is a |
xor is a random |
is a random variable |
a random variable y |
random variable y and |
variable y and has |
y and has a |
and has a binomial |
has a binomial distribution |
a binomial distribution with |
binomial distribution with parameters |
therefore the solutions for |
the solutions for equations |
is the summation z |
the summation z c |
are unique and are |
unique and are either |
and are either at |
are either at the |
either at the borders |
at the borders of |
the borders of the |
borders of the feasible |
of the feasible region |
the feasible region or |
feasible region or where |
region or where ri |
we plot the recovery |
plot the recovery probability |
the recovery probability curves |
recovery probability curves for |
probability curves for layered |
curves for layered interleaving |
for layered interleaving and |
layered interleaving and reed |
solomon against uniformly random |
against uniformly random loss |
uniformly random loss rate |
from section v we |
section v we know |
v we know that |
we know that no |
attack is not an |
is not an equilibrium |
not an equilibrium point |
since each pool can |
each pool can increase |
pool can increase its |
can increase its revenue |
increase its revenue by |
its revenue by choosing |
revenue by choosing a |
by choosing a strictly |
choosing a strictly positive |
a strictly positive infiltration |
strictly positive infiltration rate |
note that the curves |
that the curves are |
the curves are very |
curves are very close |
are very close to |
very close to each |
close to each other |
especially in the loss |
in the loss range |
the loss range of |
loss range of interest |
range of interest between |
is not a solution |
not a solution to |
a solution to equations |
implementation details we initially |
details we initially implemented |
we initially implemented and |
initially implemented and evaluated |
implemented and evaluated maelstrom |
and evaluated maelstrom as |
evaluated maelstrom as a |
maelstrom as a user |
performance turned out to |
turned out to be |
out to be limited |
to be limited by |
be limited by copying |
limited by copying and |
by copying and context |
nash equilibrium therefore exists |
equilibrium therefore exists with |
therefore exists with x |
and we subsequently reimplemented |
we subsequently reimplemented the |
subsequently reimplemented the system |
reimplemented the system as |
the system as a |
system as a module |
as a module that |
a module that runs |
module that runs within |
that runs within the |
runs within the linux |
at an encoding rate |
an encoding rate of |
the experimental prototype of |
experimental prototype of the |
prototype of the kernel |
of the kernel version |
the kernel version reaches |
kernel version reaches output |
version reaches output speeds |
reaches output speeds close |
output speeds close to |
gigabit per second of |
per second of combined |
second of combined data |
of combined data and |
combined data and fec |
data and fec traffic |
limited only by the |
only by the capacity |
by the capacity of |
the capacity of the |
capacity of the outbound |
of the outbound network |
the outbound network card |
lambda networks are already |
networks are already reaching |
are already reaching speeds |
already reaching speeds of |
and higher speeds are |
higher speeds are a |
speeds are a certainty |
are a certainty down |
a certainty down the |
certainty down the road |
we envision maelstrom as |
envision maelstrom as a |
maelstrom as a small |
as a small rack |
style cluster of blade |
each acting as an |
acting as an individual |
as an individual proxy |
traffic would be distributed |
would be distributed over |
be distributed over such |
distributed over such a |
over such a rack |
such a rack by |
a rack by partitioning |
rack by partitioning the |
by partitioning the address |
partitioning the address space |
the address space of |
address space of the |
space of the remote |
of the remote datacenter |
the remote datacenter and |
remote datacenter and routing |
datacenter and routing different |
and routing different segments |
routing different segments of |
different segments of the |
segments of the space |
of the space through |
the space through distinct |
space through distinct maelstrom |
through distinct maelstrom appliance |
distinct maelstrom appliance pairs |
using symbolic computation tools |
we see that there |
see that there is |
we plan to experiment |
plan to experiment with |
to experiment with such |
experiment with such configurations |
that there is a |
there is a single |
is a single pair |
a single pair of |
which would also permit |
would also permit us |
also permit us to |
permit us to explore |
us to explore faulttolerance |
to explore faulttolerance issues |
single pair of values |
pair of values for |
of values for which |
values for which equation |
if a maelstrom blade |
a maelstrom blade fails |
holds for any feasible |
for any feasible choice |
any feasible choice of |
feasible choice of m |
and to support load |
balancing schemes that might |
schemes that might vary |
that might vary the |
might vary the ip |
vary the ip address |
the ip address space |
ip address space partitioning |
address space partitioning dynamically |
space partitioning dynamically to |
partitioning dynamically to spread |
dynamically to spread the |
to spread the encoding |
numerical analysis a numerical |
analysis a numerical analysis |
a numerical analysis confirms |
numerical analysis confirms these |
analysis confirms these observations |
spread the encoding load |
the encoding load over |
encoding load over multiple |
load over multiple machines |
we simulate the pool |
simulate the pool game |
the pool game for |
pool game for a |
game for a range |
for a range of |
a range of pool |
range of pool sizes |
we present the implementation |
present the implementation and |
the implementation and performance |
implementation and performance of |
and performance of a |
performance of a single |
for each choice of |
each choice of pool |
choice of pool sizes |
we start the simulation |
the kernel implementation is |
kernel implementation is a |
implementation is a module |
is a module for |
a module for linux |
start the simulation when |
the simulation when both |
simulation when both pools |
when both pools do |
both pools do not |
pools do not infiltrate |
do not infiltrate each |
not infiltrate each other |
with hooks into the |
hooks into the kernel |
into the kernel packet |
the kernel packet filter |
maelstrom proxies work in |
proxies work in pairs |
one on each side |
on each side of |
each side of the |
side of the long |
of the long haul |
the long haul link |
and the revenue densities |
the revenue densities are |
each proxy acts both |
proxy acts both as |
acts both as an |
both as an ingress |
as an ingress and |
an ingress and egress |
ingress and egress temporarily |
revenue densities are r |
in case all but |
case all but one |
all but one of |
but one of the |
one of the missing |
of the missing packets |
the missing packets are |
missing packets are router |
packets are router at |
are router at the |
router at the same |
at the same time |
the same time since |
same time since they |
time since they handle |
since they handle duplex |
they handle duplex traffic |
handle duplex traffic in |
duplex traffic in received |
traffic in received later |
in received later or |
received later or recovered |
at each round one |
later or recovered through |
or recovered through other |
recovered through other xors |
each round one pool |
round one pool chooses |
one pool chooses its |
allowing the following manner |
pool chooses its optimal |
chooses its optimal infiltration |
its optimal infiltration rate |
the recovery of the |
recovery of the remaining |
of the remaining missing |
the remaining missing packet |
remaining missing packet from |
missing packet from this |
packet from this xor |
optimal infiltration rate based |
infiltration rate based on |
rate based on the |
based on the pool |
in practice we stored |
on the pool sizes |
practice we stored data |
the pool sizes and |
pool sizes and the |
sizes and the rate |
and the rate with |
the rate with which |
rate with which it |
with which it is |
which it is infiltrated |
we stored data and |
stored data and xor |
data and xor packets |
and xor packets in |
xor packets in dou |
and we calculate the |
we calculate the revenue |
calculate the revenue after |
the revenue after convergence |
revenue after convergence with |
after convergence with equation |
packets in dou the |
in dou the egress |
dou the egress router |
the egress router captures |
egress router captures ip |
router captures ip packets |
captures ip packets and |
ip packets and creates |
packets and creates re |
ble buffered red black |
buffered red black trees |
red black trees for |
recall the players in |
the players in the |
players in the pool |
in the pool game |
the pool game are |
pool game are chosen |
game are chosen with |
are chosen with the |
chosen with the round |
with the round robin |
the round robin policy |
so the pools take |
the pools take turns |
byte packets and dundant |
packets and dundant fec |
and dundant fec packets |
and we let the |
we let the game |
let the game run |
the original ip packets |
original ip packets are |
the game run until |
game run until convergence |
the results are illustrated |
results are illustrated in |
are illustrated in figure |
entries this occupies around |
each run with some |
run with some m |
routed through unaltered as |
through unaltered as they |
unaltered as they would |
as they would have |
they would have been |
would have been at |
have been at the |
been at the send |
values results in a |
results in a single |
in a single point |
a single point in |
single point in each |
point in each graph |
in each graph in |
each graph in figure |
the repair bins in |
repair bins in the |
bins in the layered |
in the layered interoriginally |
the redundant packets are |
we depict the infiltration |
depict the infiltration rates |
the infiltration rates of |
infiltration rates of both |
rates of both pools |
of both pools x |
redundant packets are then |
packets are then forwarded |
are then forwarded leaving |
then forwarded leaving scheme |
forwarded leaving scheme store |
leaving scheme store incrementally |
scheme store incrementally computed |
store incrementally computed xors |
incrementally computed xors and |
computed xors and to |
xors and to the |
and to the remote |
to the remote ingress |
the remote ingress router |
remote ingress router via |
ingress router via a |
router via a udp |
via a udp channel |
lists of data packet |
of data packet headers |
without the data packet |
the data packet payloads |
resulting in low storage |
in low storage overheads |
low storage overheads for |
storage overheads for each |
overheads for each layer |
for each layer the |
each layer the ingress |
b and the pools |
and the pools revenue |
the pools revenue densities |
pools revenue densities r |
layer the ingress router |
the ingress router captures |
ingress router captures and |
router captures and stores |
captures and stores ip |
and stores ip packets |
stores ip packets that |
ip packets that rise |
packets that rise linearly |
that rise linearly with |
rise linearly with the |
linearly with the value |
with the value of |
the value of the |
value of the interleave |
the coming from the |
coming from the direction |
from the direction of |
the direction of the |
direction of the egress |
of the egress router |
for each choice of |
each choice of m |
upon memory footprint for |
memory footprint for a |
footprint for a long |
running proxy was around |
proxy was around receipt |
was around receipt of |
around receipt of a |
receipt of a redundant |
of a redundant packet |
the values of x |
an ip packet is |
ip packet is recov |
mb in our experiments |
ered if there is |
if there is an |
there is an opportunity |
is an opportunity to |
an opportunity to do |
opportunity to do so |
redundant packets that can |
packets that can be |
that can be used |
can be used at |
be used at a |
used at a later |
at a later time |
a later time are |
later time are stored |
if the redundant packet |
the redundant packet is |
redundant packet is useless |
packet is useless it |
is useless it is |
useless it is immediately |
it is immediately dis |
are the points in |
the points in each |
points in each of |
in each of the |
each of the graphs |
of the graphs with |
the graphs with the |
graphs with the respective |
with the respective coordinates |
other performance enhancing roles |
performance enhancing roles carded |
j graphs we draw |
graphs we draw a |
we draw a border |
draw a border around |
a border around the |
border around the region |
around the region where |
the region where there |
region where there is |
where there is no |
upon recovery the ip |
recovery the ip packet |
the ip packet is |
attack by i in |
by i in equilibrium |
ip packet is sent |
packet is sent through |
is sent through maelstrom |
sent through maelstrom appliances |
for the ri graphs |
through maelstrom appliances can |
the ri graphs we |
maelstrom appliances can optionally |
ri graphs we draw |
appliances can optionally aggregate |
graphs we draw a |
can optionally aggregate small |
we draw a line |
optionally aggregate small suba |
aggregate small suba raw |
small suba raw socket |
suba raw socket to |
raw socket to its |
socket to its intended |
to its intended destination |
draw a line around |
a line around the |
line around the region |
around the region where |
the region where the |
kilobyte packets from different |
region where the revenue |
where the revenue is |
the revenue is the |
revenue is the same |
is the same as |
the same as in |
same as in the |
as in the no |
packets from different flows |
from different flows into |
different flows into larger |
flows into larger ones |
into larger ones for |
larger ones for using |
ones for using fec |
for using fec requires |
using fec requires that |
fec requires that each |
requires that each data |
that each data packet |
each data packet have |
data packet have a |
packet have a unique |
have a unique better |
a unique better communication |
unique better communication efficiency |
better communication efficiency over |
communication efficiency over the |
efficiency over the long |
we first observe that |
first observe that only |
observe that only in |
that only in extreme |
distance identifier that the |
identifier that the receiver |
only in extreme cases |
that the receiver can |
the receiver can use |
receiver can use to |
can use to keep |
use to keep track |
to keep track of |
keep track of re |
in extreme cases a |
extreme cases a pool |
cases a pool does |
a pool does not |
pool does not attack |
does not attack its |
not attack its counterpart |
in split flow control |
at equilibrium a pool |
split flow control mode |
equilibrium a pool will |
flow control mode they |
a pool will refrain |
control mode they can |
pool will refrain from |
mode they can ceived |
will refrain from attacking |
refrain from attacking only |
they can ceived data |
can ceived data packets |
ceived data packets and |
from attacking only if |
attacking only if the |
only if the other |
if the other pool |
the other pool is |
other pool is larger |
pool is larger than |
is larger than about |
data packets and to |
packets and to identify |
and to identify missing |
to identify missing data |
identify missing data packets |
missing data packets perform |
data packets perform send |
side buffering of in |
of the total mining |
the total mining power |
flight data for multiin |
data for multiin a |
for multiin a repair |
multiin a repair packet |
if we had access |
we had access to |
had access to end |
we observe that a |
observe that a pool |
that a pool improves |
a pool improves its |
pool improves its revenue |
improves its revenue compared |
its revenue compared to |
revenue compared to the |
compared to the no |
we gigabyte flows that |
gigabyte flows that exceed |
flows that exceed the |
that exceed the sending |
exceed the sending end |
host s buffercould have |
attacks scenario only when |
s buffercould have added |
scenario only when it |
buffercould have added a |
only when it controls |
have added a header |
added a header to |
a header to each |
header to each packet |
to each packet with |
each packet with a |
packet with a unique |
with a unique ing |
a unique ing capacity |
when it controls a |
it controls a strict |
controls a strict majority |
a strict majority of |
strict majority of the |
majority of the total |
of the total mining |
the total mining power |
maelstrom appliances can act |
appliances can act as |
can act as mulsequence |
act as mulsequence number |
these are the small |
are the small triangular |
the small triangular regions |
small triangular regions in |
triangular regions in figures |
in the rest of |
the rest of the |
rest of the space |
we intercept traffic trans |
the trapezoids in the |
trapezoids in the figures |
the revenue of the |
appliances send multicast packparently |
revenue of the pool |
of the pool is |
the pool is inferior |
pool is inferior compared |
is inferior compared to |
inferior compared to the |
compared to the no |
send multicast packparently and |
multicast packparently and need |
packparently and need to |
and need to route |
need to route it |
to route it without |
route it without modification |
it without modification or |
without modification or addi |
ets to each other |
to each other across |
each other across the |
other across the long |
the prisoner s dilemma |
prisoner s dilemma in |
s dilemma in a |
dilemma in a healthy |
in a healthy bitcoin |
a healthy bitcoin environment |
where neither pool controls |
neither pool controls a |
pool controls a strict |
controls a strict majority |
a strict majority of |
strict majority of the |
majority of the mining |
of the mining power |
we identify ip multicast |
both pools will earn |
pools will earn less |
will earn less at |
earn less at equilibrium |
less at equilibrium than |
at equilibrium than if |
equilibrium than if both |
than if both pools |
if both pools ran |
both pools ran without |
pools ran without attacking |
to spread them within |
spread them within their |
them within their datacenters |
we can analyze in |
can analyze in this |
analyze in this case |
in this case a |
ip packets by a |
this case a game |
packets by a tuple |
by a tuple consisting |
a tuple consisting of |
tuple consisting of the |
consisting of the source |
of the source and |
the source and des |
case a game where |
a game where each |
game where each pool |
where each pool chooses |
each pool chooses either |
pool chooses either to |
chooses either to attack |
either to attack and |
to attack and optimize |
attack and optimize its |
and optimize its revenue |
appliances can take on |
can take on other |
take on other existing |
on other existing roles |
other existing roles in |
or to refrain from |
to refrain from attacking |
existing roles in the |
roles in the tination |
in the tination ip |
the tination ip address |
without loss of generality |
size of the ip |
of the ip datacenter |
as we have seen |
we have seen in |
have seen in section |
seen in section v |
acting as security and |
as security and vpn |
security and vpn gateways |
and vpn gateways and |
vpn gateways and as |
gateways and as header |
and as header plus |
as header plus data |
and a checksum over |
a checksum over the |
checksum over the ip |
over the ip data |
the ip data pay |
can increase its revenue |
increase its revenue above |
conventional performance enhancing proxies |
does attack but pool |
we denote the revenue |
denote the revenue of |
the revenue of pool |
the checksum over the |
checksum over the payload |
over the payload is |
the payload is necessary |
payload is necessary since |
is necessary since the |
necessary since the ip |
since the ip identification |
the ip identification field |
ip identification field is |
identification field is only |
the exact value of |
exact value of r |
depends on the values |
on the values of |
the values of m |
bits long and a |
long and a single |
and a single pair |
a single pair of |
single pair of end |
hosts communicating at high |
communicating at high speeds |
at high speeds will |
but it is always |
it is always smaller |
is always smaller than |
always smaller than one |
evaluation use the same |
use the same identifier |
the same identifier for |
as we have seen |
we have seen above |
same identifier for different |
identifier for different data |
for different data packets |
different data packets within |
data packets within a |
packets within a fairly |
does choose to attack |
within a fairly short |
a fairly short interval |
fairly short interval unless |
short interval unless the |
interval unless the checksum |
unless the checksum is |
the checksum is added |
but does not surpass |
does not surpass one |
checksum is added to |
is added to we |
added to we evaluated |
to we evaluated maelstrom |
the game is summarized |
game is summarized in |
is summarized in figure |
we evaluated maelstrom on |
evaluated maelstrom on the |
maelstrom on the emulab |
on the emulab testbed |
the emulab testbed at |
emulab testbed at utah |
testbed at utah differentiate |
at utah differentiate between |
utah differentiate between them |
this is the classical |
is the classical prisoner |
the classical prisoner s |
classical prisoner s dilemma |
attack is the dominant |
is the dominant strategy |
chooses to attack or |
to attack or not |
the revenue of pool |
for all the experiments |
is larger when attacking |
larger when attacking than |
when attacking than when |
attacking than when refraining |
than when refraining from |
when refraining from attack |
we used a dumbbell |
used a dumbbell topoltifiers |
a dumbbell topoltifiers result |
dumbbell topoltifiers result in |
topoltifiers result in garbled |
result in garbled recovery |
in garbled recovery by |
garbled recovery by maelstrom |
and the same for |
the same for xxx |
same for xxx xxx |
for xxx xxx pool |
an event ogy of |
event ogy of two |
ogy of two clusters |
no attack xxx pool |
of two clusters of |
two clusters of nodes |
clusters of nodes connected |
of nodes connected via |
nodes connected via routing |
connected via routing nodes |
via routing nodes which |
routing nodes which will |
nodes which will be |
which will be caught |
will be caught by |
be caught by higher |
caught by higher level |
by higher level checksums |
higher level checksums designed |
level checksums designed with |
checksums designed with a |
designed with a high |
latency link in between |
link in between them |
designed to emto deal |
to emto deal with |
emto deal with tranmission |
deal with tranmission errors |
with tranmission errors on |
tranmission errors on commodity |
errors on commodity networks |
on commodity networks ulate |
commodity networks ulate the |
networks ulate the setup |
ulate the setup in |
the setup in figure |
and ran the proxy |
ran the proxy code |
the proxy code on |
proxy code on and |
code on and hence |
on and hence does |
and hence does not |
hence does not have |
does not have significant |
not have significant consequences |
have significant consequences unless |
significant consequences unless the |
consequences unless the routers |
shows the performance of |
the performance of the |
performance of the kernel |
of the kernel version |
the kernel version at |
kernel version at gigabit |
version at gigabit speeds |
the remainder of the |
remainder of the graphs |
of the graphs it |
the graphs it occurs |
graphs it occurs frequently |
the kernel version of |
kernel version of maelstrom |
version of maelstrom can |
of maelstrom can generate |
maelstrom can generate up |
can generate up to |
generate up to a |
up to a show |
to a show the |
a show the performance |
show the performance of |
the performance of the |
performance of the user |
space version at slower |
version at slower gigabit |
at slower gigabit per |
slower gigabit per second |
gigabit per second of |
per second of data |
second of data and |
of data and fec |
data and fec traffic |
to emulate the mtu |
emulate the mtu difference |
the mtu difference between |
mtu difference between the |
difference between the longput |
between the longput data |
the longput data rate |
longput data rate depending |
data rate depending on |
rate depending on the |
depending on the encoding |
on the encoding rate |
haul link and the |
link and the datacenter |
and the datacenter network |
we were able to |
were able to saturate |
able to saturate the |
to saturate the outgoing |
saturate the outgoing card |
the outgoing card at |
outgoing card at set |
card at set an |
at set an mtu |
set an mtu of |
bytes on the network |
on the network connecting |
the network connecting the |
network connecting the rates |
connecting the rates as |
the rates as high |
rates as high as |
prisoner s dilemma for |
s dilemma for two |
dilemma for two pools |
the revenue density of |
revenue density of each |
density of each pool |
of each pool is |
each pool is determined |
pool is determined by |
is determined by the |
determined by the decision |
by the decision of |
the decision of both |
decision of both pools |
of both pools whether |
both pools whether to |
pools whether to attack |
whether to attack or |
to attack or not |
with cpu overload occurring |
cpu overload occurring at |
overload occurring at end |
the dominant strategy of |
dominant strategy of each |
strategy of each player |
of each player is |
each player is to |
player is to attack |
hosts to the proxy |
to the proxy and |
the proxy and an |
proxy and an mtu |
and an mtu of |
however the payoff of |
the payoff of both |
payoff of both would |
of both would be |
both would be larger |
would be larger if |
be larger if they |
larger if they both |
if they both refrain |
they both refrain from |
both refrain from attacking |
at equilibrium of this |
equilibrium of this attack |
where each incoming data |
each incoming data packet |
incoming data packet had |
data packet had to |
when both pools attack |
packet had to be |
had to be xored |
to be xored long |
the revenue of each |
revenue of each pool |
haul link between proxies |
of each pool is |
each pool is smaller |
pool is smaller than |
is smaller than its |
the only exception is |
only exception is figure |
smaller than its revenue |
than its revenue if |
its revenue if neither |
revenue if neither pool |
if neither pool attacked |
where we maintained equal |
we maintained equal mtus |
the game is not |
game is not played |
is not played once |
maintained equal mtus of |
where each pool can |
each pool can change |
pool can change its |
can change its strategy |
change its strategy between |
its strategy between attack |
strategy between attack and |
between attack and no |
the pools can agree |
to refrain from attacking |
and in each round |
in each round a |
throughput metrics at the |
metrics at the receive |
each round a pool |
round a pool can |
a pool can detect |
pool can detect whether |
can detect whether it |
detect whether it is |
whether it is being |
incoming data packets are |
it is being attacked |
data packets are buffered |
is being attacked and |
packets are buffered so |
being attacked and deduce |
are buffered so that |
attacked and deduce that |
and deduce that the |
deduce that the other |
that the other pool |
the other pool is |
other pool is violating |
buffered so that they |
so that they can |
that they can be |
they can be used |
can be used in |
be used in conjunction |
used in conjunction with |
in conjunction with figures |
pool is violating the |
is violating the agreement |
cooperation where neither pool |
where neither pool attacks |
neither pool attacks is |
pool attacks is a |
attacks is a possible |
is a possible stable |
a possible stable state |
show that commodity tcp |
ip throughxors to recover |
throughxors to recover missing |
to recover missing data |
recover missing data packets |
any received put collapses |
received put collapses in |
put collapses in the |
collapses in the presence |
in the presence of |
the presence of non |
and xor that is |
xor that is missing |
that is missing more |
is missing more than |
missing more than one |
more than one data |
than one data packet |
one data packet is |
despite the fact that |
data packet is stored |
the fact that the |
packet is stored that |
fact that the single |
is stored that maelstrom |
stored that maelstrom successfully |
that maelstrom successfully masks |
maelstrom successfully masks loss |
successfully masks loss and |
masks loss and prevents |
loss and prevents this |
that the single nash |
the single nash equilibrium |
single nash equilibrium in |
nash equilibrium in every |
equilibrium in every round |
in every round is |
every round is to |
round is to attack |
case as an example |
as an example we |
an example we take |
example we take again |
we take again the |
take again the pool |
again the pool sizes |
the pool sizes shown |
pool sizes shown in |
sizes shown in figure |
and study the case |
study the case where |
the case where the |
case where the two |
where the two largest |
the two largest pools |
the optimal infiltration rates |
out of the total |
of the total system |
the total system mining |
total system mining power |
and the pools would |
the pools would lose |
ip no loss maelstrom |
no loss maelstrom no |
loss maelstrom no loss |
maelstrom no loss maelstrom |
compared to the no |
q i dentical p |
i dentical p ools |
dentical p ools let |
p ools let there |
ools let there be |
let there be q |
there be q pools |
be q pools of |
q pools of identical |
pools of identical size |
of identical size that |
identical size that engage |
size that engage in |
that engage in block |
engage in block withholding |
in block withholding against |
block withholding against one |
withholding against one another |
other miners neither attack |
miners neither attack nor |
neither attack nor are |
attack nor are being |
nor are being attacked |
in this case there |
this case there exists |
case there exists a |
there exists a symmetric |
exists a symmetric equilibrium |
without loss of generality |
a step of pool |
it controls its attack |
controls its attack rates |
its attack rates each |
attack rates each of |
rates each of the |
each of the other |
of the other pools |
and due to symmetry |
due to symmetry they |
to symmetry they are |
symmetry they are all |
they are all the |
are all the same |
the attack rate of |
attack rate of pool |
against any other pool |
each of the other |
of the other pools |
the other pools can |
other pools can attack |
pools can attack its |
can attack its peers |
attack its peers as |
its peers as well |
all attack rates by |
attack rates by all |
rates by all attackers |
by all attackers are |
all attackers are identical |
the attack rate of |
attack rate of any |
rate of any pool |
of any pool other |
any pool other than |
against any other pool |
the direct revenue of |
direct revenue of each |
revenue of each of |
of each of the |
each of the other |
of the other pools |
similarly denote by r |
the revenue densities of |
revenue densities of pool |
are instantiated to mi |
tcp no loss maelstrom |
no loss maelstrom no |
loss maelstrom no loss |
maelstrom no loss maelstrom |
one way link latency |
and solving we obtain |
solving we obtain a |
we obtain a single |
obtain a single expression |
a single expression for |
single expression for any |
expression for any ri |
since in the symmetric |
in the symmetric case |
the symmetric case we |
symmetric case we have |
case we have r |
way latency collapse from |
latency collapse from occurring |
shows the performance of |
the performance of the |
performance of the user |
the expression is shown |
expression is shown in |
is shown in equation |
space version on a |
mbps link and figure |
shows the kernel version |
the kernel version on |
kernel version on a |
given any value of |
any value of q |
value of q and |
of q and mi |
the experiment in each |
experiment in each case |
in each case involves |
each case involves running |
case involves running iperf |
flows from one node |
from one node to |
the feasible range of |
feasible range of the |
range of the infiltration |
of the infiltration rates |
the infiltration rates is |
one node to another |
node to another across |
to another across the |
another across the long |
distance link with and |
link with and without |
with and without intermediary |
and without intermediary maelstrom |
without intermediary maelstrom proxies |
intermediary maelstrom proxies and |
maelstrom proxies and measuring |
proxies and measuring obtained |
and measuring obtained throughput |
measuring obtained throughput while |
obtained throughput while varying |
throughput while varying loss |
while varying loss rate |
within this range ri |
this range ri is |
range ri is continuous |
left graph on each |
graph on each figure |
and concave in x |
the error bars on |
error bars on the |
bars on the graphs |
on the graphs to |
the graphs to the |
graphs to the left |
to the left are |
the left are standard |
left are standard errors |
the optimal point for |
optimal point for pool |
are standard errors of |
standard errors of the |
errors of the throughput |
of the throughput over |
the throughput over ten |
throughput over ten runs |
ip s cache of |
s cache of tuning |
cache of tuning parameters |
of tuning parameters to |
tuning parameters to allow |
parameters to allow for |
to allow for repeatable |
allow for repeatable results |
the clients in the |
clients in the experiment |
in the experiment are |
the experiment are running |
experiment are running tcp |
ip reno on a |
reno on a linux |
since the function is |
the function is concave |
function is concave the |
is concave the equation |
concave the equation yields |
the equation yields a |
equation yields a single |
yields a single feasible |
a single feasible solution |
which is a function |
is a function of |
a function of the |
function of the attack |
of the attack rates |
the attack rates of |
attack rates of the |
rates of the other |
of the other pools |
the maelstrom parameters used |
maelstrom parameters used are |
parameters used are r |
to find a symmetric |
find a symmetric equilibrium |
space version involved running |
version involved running a |
and obtain a single |
obtain a single feasible |
a single feasible solution |
involved running a single |
the equilibrium infiltration rate |
equilibrium infiltration rate and |
infiltration rate and the |
rate and the matching |
and the matching revenues |
the matching revenues are |
matching revenues are shown |
revenues are shown in |
are shown in equation |
second iperf flow from |
iperf flow from one |
flow from one node |
from one node to |
one node to another |
node to another with |
to another with and |
another with and without |
with and without maelstrom |
and without maelstrom running |
without maelstrom running on |
maelstrom running on the |
running on the routers |
on the routers and |
the routers and measuring |
routers and measuring throughput |
and measuring throughput while |
measuring throughput while varying |
throughput while varying the |
while varying the random |
varying the random loss |
the random loss rate |
random loss rate on |
loss rate on the |
rate on the link |
on the link and |
the link and the |
link and the one |
as in the two |
to test the kernel |
test the kernel version |
the kernel version at |
kernel version at gigabit |
version at gigabit speeds |
the revenue at the |
revenue at the symmetric |
at the symmetric equilibrium |
the symmetric equilibrium is |
we ran eight parallel |
symmetric equilibrium is inferior |
equilibrium is inferior to |
is inferior to the |
inferior to the no |
ran eight parallel iperf |
eight parallel iperf flows |
parallel iperf flows from |
iperf flows from one |
flows from one node |
from one node to |
one node to another |
node to another for |
the curves obtained from |
curves obtained from the |
obtained from the two |
from the two versions |
the two versions are |
two versions are almost |
versions are almost identical |
up our analysis addresses |
our analysis addresses the |
analysis addresses the eventual |
addresses the eventual revenue |
the eventual revenue of |
eventual revenue of the |
revenue of the pools |
we present both to |
present both to show |
both to show that |
to show that the |
show that the kernel |
assuming the mining difficulty |
that the kernel version |
the mining difficulty is |
mining difficulty is set |
difficulty is set based |
is set based on |
set based on the |
based on the effective |
on the effective mining |
the effective mining power |
the kernel version successfully |
kernel version successfully scales |
version successfully scales up |
successfully scales up the |
scales up the performance |
up the performance of |
the performance of the |
performance of the user |
not including mining power |
including mining power used |
mining power used for |
power used for withholding |
space version to hundreds |
version to hundreds of |
to hundreds of megabits |
hundreds of megabits of |
of megabits of traffic |
megabits of traffic per |
of traffic per second |
difficulty is updated only |
is updated only periodically |
updated only periodically every |
when mining power in |
mining power in the |
power in the system |
in the system is |
the system is regularly |
system is regularly increasing |
we show how tcp |
which has been true |
has been true for |
been true for the |
true for the majority |
for the majority of |
the majority of bitcoin |
majority of bitcoin s |
of bitcoin s history |
ip performance degrades on |
performance degrades on a |
ms link as the |
link as the loss |
as the loss rate |
the loss rate is |
loss rate is increased |
rate is increased from |
no adjustment may be |
adjustment may be necessary |
if an attacker purchases |
an attacker purchases new |
attacker purchases new mining |
purchases new mining hardware |
new mining hardware and |
mining hardware and employs |
hardware and employs it |
and employs it directly |
employs it directly for |
it directly for block |
directly for block withholding |
this mining power is |
mining power is never |
maelstrom masks loss up |
masks loss up to |
power is never included |
is never included in |
never included in the |
included in the difficulty |
in the difficulty calculation |
the difficulty calculation the |
difficulty calculation the system |
calculation the system is |
the system is never |
system is never aware |
is never aware of |
never aware of it |
without significant throughput degradation |
the difficulty is therefore |
with the kernel version |
difficulty is therefore already |
the kernel version achieving |
kernel version achieving two |
version achieving two orders |
achieving two orders of |
is therefore already correctly |
two orders of magnitude |
orders of magnitude higher |
of magnitude higher throughput |
magnitude higher throughput that |
higher throughput that conventional |
throughput that conventional tcp |
therefore already correctly calculated |
already correctly calculated and |
correctly calculated and the |
calculated and the attack |
and the attack is |
the attack is profitable |
attack is profitable immediately |
if the mining power |
the mining power is |
mining power is static |
the graphs on the |
graphs on the right |
on the right side |
the right side of |
right side of figures |
the attack becomes profitable |
attack becomes profitable only |
becomes profitable only after |
profitable only after the |
only after the bitcoin |
after the bitcoin system |
the bitcoin system has |
bitcoin system has normalized |
system has normalized the |
has normalized the revenues |
normalized the revenues by |
the revenues by adjusting |
revenues by adjusting difficulty |
ip throughput declining on |
throughput declining on a |
declining on a link |
on a link of |
a link of increasing |
link of increasing length |
of increasing length when |
increasing length when subjected |
length when subjected to |
when subjected to uniform |
subjected to uniform loss |
to uniform loss rates |
uniform loss rates of |
the revenue of an |
revenue of an attacking |
of an attacking pool |
an attacking pool is |
attacking pool is reduced |
pool is reduced due |
is reduced due to |
reduced due to the |
due to the reduction |
to the reduction in |
the reduction in block |
reduction in block generation |
in block generation of |
block generation of both |
generation of both the |
of both the attacking |
both the attacking and |
the attacking and attacked |
attacking and attacked pools |
the top line in |
top line in the |
line in the graphs |
in the graphs is |
the graphs is the |
graphs is the performance |
is the performance of |
the performance of tcp |
ip without loss and |
without loss and provides |
loss and provides an |
and provides an upper |
provides an upper bound |
an upper bound for |
upper bound for performance |
bound for performance on |
for performance on the |
performance on the link |
space and kernel versions |
maelstrom masks packet loss |
masks packet loss and |
packet loss and tracks |
loss and tracks the |
and tracks the lossless |
tracks the lossless line |
the lossless line closely |
lagging only when the |
only when the link |
when the link latency |
the link latency is |
link latency is low |
latency is low and |
is low and tcp |
ip s throughput is |
s throughput is very |
throughput is very high |
ip to attain very |
to attain very high |
attain very high speeds |
very high speeds on |
high speeds on the |
speeds on the gi |
expression for ri in |
for ri in a |
ri in a system |
in a system with |
a system with pools |
system with pools of |
with pools of equal |
pools of equal size |
q mi q mi |
way delivery latency against |
delivery latency against loss |
latency against loss rate |
q symmetric equilibrium values |
symmetric equilibrium values for |
equilibrium values for a |
values for a system |
for a system of |
a system of q |
system of q pools |
of q pools of |
q pools of equal |
pools of equal sizes |
countermeasures in order to |
in order to choose |
order to choose its |
to choose its optimal |
choose its optimal infiltration |
its optimal infiltration rate |
a pool has to |
pool has to know |
has to know the |
to know the rate |
know the rate at |
the rate at which |
rate at which it |
at which it is |
which it is attacked |
and the revenue density |
the revenue density of |
revenue density of potential |
density of potential victim |
of potential victim pools |
a pool can estimate |
pool can estimate the |
can estimate the rate |
estimate the rate with |
the rate with which |
rate with which it |
with which it is |
which it is attacked |
it is attacked by |
is attacked by comparing |
attacked by comparing the |
by comparing the rates |
comparing the rates of |
the rates of partial |
rates of partial and |
of partial and full |
partial and full proofs |
and full proofs of |
full proofs of work |
proofs of work it |
of work it receives |
work it receives from |
it receives from its |
receives from its miners |
as explained in section |
explained in section ii |
in order to estimate |
order to estimate the |
to estimate the revenue |
estimate the revenue densities |
the revenue densities of |
revenue densities of the |
densities of the other |
of the other pools |
a pool can use |
pool can use one |
can use one of |
use one of two |
one of two methods |
pools often publish this |
often publish this data |
publish this data to |
this data to demonstrate |
data to demonstrate their |
to demonstrate their honesty |
demonstrate their honesty to |
their honesty to their |
honesty to their miners |
a pool can infiltrate |
pool can infiltrate each |
can infiltrate each of |
infiltrate each of the |
each of the other |
of the other pools |
the other pools with |
other pools with some |
pools with some nominal |
with some nominal probing |
some nominal probing mining |
nominal probing mining power |
probing mining power and |
mining power and measure |
power and measure the |
and measure the revenue |
measure the revenue density |
the revenue density directly |
revenue density directly by |
density directly by monitoring |
directly by monitoring the |
by monitoring the probe |
monitoring the probe s |
the probe s rewards |
probe s rewards from |
s rewards from the |
rewards from the pool |
as in the case |
in the case of |
the case of classical |
case of classical block |
of classical block withholding |
classical block withholding explained |
block withholding explained in |
withholding explained in section |
explained in section ii |
a pool might detect |
pool might detect that |
might detect that it |
detect that it is |
that it is being |
it is being attacked |
but cannot detect which |
cannot detect which of |
detect which of its |
which of its miners |
of its miners is |
its miners is the |
miners is the attacker |
therefore a pool cannot |
a pool cannot block |
pool cannot block or |
cannot block or punish |
block or punish withholding |
or punish withholding miners |
various techniques can be |
techniques can be used |
can be used to |
be used to encourage |
used to encourage miners |
to encourage miners to |
encourage miners to submit |
miners to submit full |
to submit full blocks |
a pool can pay |
pool can pay a |
can pay a bonus |
pay a bonus for |
a bonus for submitting |
bonus for submitting a |
for submitting a full |
submitting a full proof |
a full proof of |
full proof of work |
this would increase the |
would increase the revenue |
increase the revenue of |
the revenue of the |
revenue of the miner |
of the miner that |
the miner that found |
miner that found a |
that found a block |
found a block while |
a block while reducing |
block while reducing the |
while reducing the revenue |
reducing the revenue of |
the revenue of the |
revenue of the other |
of the other miners |
the other miners from |
other miners from this |
miners from this block |
while the average revenue |
the average revenue of |
average revenue of each |
revenue of each miner |
of each miner would |
each miner would stay |
miner would stay the |
would stay the same |
small miners will suffer |
miners will suffer from |
will suffer from higher |
suffer from higher variance |
from higher variance in |
higher variance in revenue |
another approach is to |
approach is to introduce |
packet delivery latencies gabit |
delivery latencies gabit link |
is to introduce a |
to introduce a joining |
introduce a joining fee |
we had to set |
a joining fee by |
had to set the |
to set the mtu |
set the mtu of |
joining fee by paying |
fee by paying new |
by paying new miners |
paying new miners less |
new miners less for |
miners less for their |
less for their work |
for their work until |
their work until they |
work until they have |
until they have established |
they have established a |
have established a reputation |
established a reputation with |
a reputation with the |
reputation with the pool |
the mtu of the |
mtu of the entire |
miners that seek flexibility |
that seek flexibility may |
seek flexibility may not |
flexibility may not accept |
may not accept this |
not accept this policy |
of the entire path |
accept this policy and |
this policy and choose |
the entire path to |
policy and choose another |
and choose another pool |
entire path to be |
path to be the |
to be the maximum |
the pool can use |
pool can use a |
can use a honeypot |
use a honeypot trap |
a honeypot trap by |
honeypot trap by sending |
trap by sending the |
by sending the miners |
sending the miners tasks |
the miners tasks which |
miners tasks which it |
tasks which it knows |
which it knows will |
it knows will result |
knows will result in |
will result in a |
result in a full |
in a full proof |
a full proof of |
full proof of work |
if a miner fails |
a miner fails to |
miner fails to submit |
fails to submit the |
to submit the full |
submit the full proof |
the full proof of |
full proof of work |
proof of work it |
of work it is |
work it is tagged |
it is tagged as |
is tagged as an |
tagged as an attacker |
to prevent the attacker |
prevent the attacker from |
the attacker from learning |
attacker from learning them |
the honeypot tasks have |
honeypot tasks have to |
tasks have to be |
have to be regularly |
to be regularly refreshed |
which meant that the |
pools can also incorporate |
meant that the longhaul |
that the longhaul link |
can also incorporate out |
also incorporate out of |
incorporate out of band |
out of band mechanisms |
of band mechanisms to |
band mechanisms to deter |
mechanisms to deter attacks |
the longhaul link had |
longhaul link had the |
link had the same |
had the same mtu |
the same mtu as |
same mtu as the |
mtu as the inter |
such as verifying the |
as verifying the identity |
verifying the identity of |
the identity of miners |
identity of miners or |
of miners or using |
miners or using trusted |
or using trusted computing |
this resulted in the |
using trusted computing technologies |
resulted in the fragmentation |
in the fragmentation of |
the fragmentation of repair |
fragmentation of repair packets |
of repair packets sent |
repair packets sent over |
packets sent over udp |
sent over udp on |
over udp on the |
udp on the long |
haul link into two |
link into two ip |
into two ip packet |
two ip packet fragments |
that assure no block |
assure no block withholding |
no block withholding is |
block withholding is taking |
withholding is taking place |
since the loss of |
the loss of a |
loss of a single |
of a single fragment |
a single fragment resulted |
this would require miners |
single fragment resulted in |
fragment resulted in the |
resulted in the loss |
in the loss of |
the loss of the |
loss of the repair |
would require miners to |
require miners to use |
miners to use specialized |
to use specialized hardware |
use specialized hardware and |
specialized hardware and software |
we observed a higher |
observed a higher loss |
a higher loss rate |
higher loss rate for |
loss rate for repairs |
an overhead miners may |
overhead miners may not |
miners may not accept |
rate for repairs than |
for repairs than for |
repairs than for data |
than for data packets |
there is no known |
is no known silver |
no known silver bullet |
we expect performance to |
expect performance to be |
performance to be better |
to be better on |
be better on a |
better on a network |
on a network where |
a network where the |
network where the mtu |
where the mtu of |
the mtu of the |
mtu of the long |
all these techniques reduce |
these techniques reduce the |
techniques reduce the pool |
haul link is truly |
link is truly larger |
is truly larger than |
truly larger than the |
larger than the mtu |
than the mtu within |
the mtu within each |
mtu within each cluster |
reduce the pool s |
the pool s attractiveness |
pool s attractiveness and |
s attractiveness and deter |
attractiveness and deter miners |
block withholding recycling we |
latency metrics to measure |
metrics to measure the |
to measure the latency |
measure the latency effects |
the latency effects of |
latency effects of tcp |
withholding recycling we assume |
recycling we assume that |
we assume that the |
assume that the infiltrating |
that the infiltrating miners |
the infiltrating miners are |
infiltrating miners are loyal |
miners are loyal to |
are loyal to the |
loyal to the attacker |
some of the pool |
of the pool s |
the pool s members |
pool s members may |
s members may be |
members may be disloyal |
may be disloyal infiltrators |
mbps stream between two |
stream between two nodes |
between two nodes over |
two nodes over a |
when sending disloyal miners |
sending disloyal miners to |
disloyal miners to perform |
miners to perform block |
to perform block withholding |
perform block withholding at |
block withholding at other |
withholding at other pools |
an attacker takes a |
attacker takes a significant |
takes a significant risk |
and simultaneously ran a |
can use a loyal |
use a loyal miner |
a loyal miner w |
loyal miner w to |
miner w to infiltrate |
w to infiltrate pool |
mbps flow alongside on |
flow alongside on the |
alongside on the same |
on the same link |
the same link to |
same link to simulate |
link to simulate a |
to simulate a real |
time stream combined with |
stream combined with other |
combined with other intercluster |
with other intercluster traffic |
thinking the miner is |
the miner is loyal |
miner is loyal to |
is loyal to it |
might use it to |
use it to attack |
it to attack pool |
shows the average delivery |
the average delivery latency |
average delivery latency of |
the miner m can |
level packets in the |
miner m can perform |
m can perform honest |
can perform honest mining |
perform honest mining for |
honest mining for pool |
rather than withhold its |
as loss rates go |
loss rates go up |
than withhold its blocks |
and not return any |
not return any revenue |
return any revenue to |
any revenue to pool |
shows the same scenario |
the same scenario with |
same scenario with a |
it will take its |
will take its share |
take its share of |
its share of pool |
scenario with a constant |
with a constant uniformly |
a constant uniformly random |
constant uniformly random loss |
uniformly random loss rate |
random loss rate of |
which thinks the miner |
thinks the miner is |
the miner is loyal |
miner is loyal to |
is loyal to it |
and deliver it back |
deliver it back to |
it back to pool |
and varying oneway latency |
to avoid such a |
avoid such a risk |
maelstrom s delivery latency |
s delivery latency is |
delivery latency is almost |
latency is almost exactly |
is almost exactly equal |
a pool needs a |
almost exactly equal to |
exactly equal to the |
equal to the one |
pool needs a sufficient |
needs a sufficient number |
a sufficient number of |
sufficient number of verified |
way latency on the |
latency on the link |
number of verified miners |
of verified miners miners |
verified miners miners that |
miners miners that it |
miners that it knows |
that it knows to |
it knows to be |
knows to be loyal |
ip takes more than |
takes more than twice |
more than twice as |
than twice as long |
twice as long once |
as long once one |
the optimal infiltration rate |
way latencies go past |
optimal infiltration rate may |
infiltration rate may be |
rate may be as |
may be as high |
be as high as |
of the pool size |
but this is only |
this is only in |
is only in extreme |
only in extreme cases |
in extreme cases when |
extreme cases when pools |
cases when pools are |
when pools are large |
plots delivery latency against |
delivery latency against message |
latency against message identifier |
for practical pool sizes |
the spikes in latency |
spikes in latency are |
in latency are triggered |
latency are triggered by |
are triggered by losses |
triggered by losses that |
a pool may need |
pool may need up |
may need up to |
by losses that lead |
losses that lead to |
that lead to packets |
lead to packets piling |
to packets piling up |
packets piling up at |
piling up at the |
up at the receiver |
a key point is |
of its mining power |
its mining power for |
mining power for infiltration |
key point is that |
point is that we |
is that we are |
that we are plotting |
we are plotting the |
are plotting the delivery |
plotting the delivery latency |
the delivery latency of |
delivery latency of all |
latency of all packets |
pools typically have loyal |
typically have loyal mining |
have loyal mining power |
not just lost ones |
loyal mining power either |
mining power either run |
power either run directly |
either run directly by |
run directly by the |
directly by the pool |
by the pool owners |
the pool owners or |
ip delays correctly received |
pool owners or sold |
delays correctly received packets |
owners or sold as |
correctly received packets while |
or sold as a |
received packets while waiting |
sold as a service |
as a service but |
packets while waiting for |
a service but run |
service but run on |
but run on the |
run on the pool |
on the pool owners |
the pool owners hardware |
while waiting for missing |
waiting for missing packets |
for missing packets sequenced |
missing packets sequenced earlier |
packets sequenced earlier by |
sequenced earlier by the |
earlier by the sender |
by the sender the |
the sender the effect |
sender the effect of |
the effect of this |
effect of this is |
of this is shown |
this is shown in |
is shown in figure |
where single packet losses |
single packet losses cause |
packet losses cause spikes |
losses cause spikes in |
cause spikes in delivery |
spikes in delivery latency |
in delivery latency that |
delivery latency that last |
latency that last for |
that last for hundreds |
last for hundreds of |
for hundreds of packets |
however the size of |
the low data rate |
low data rate in |
data rate in the |
rate in the flow |
in the flow of |
the flow of roughly |
the size of this |
size of this mining |
of this mining power |
this mining power is |
mining power is considered |
power is considered a |
is considered a trade |
considered a trade secret |
a trade secret and |
trade secret and is |
secret and is not |
and is not published |
kb packets per rtt |
packets per rtt makes |
per rtt makes tcp |
ip flow control delays |
flow control delays at |
block withholding in practice |
control delays at the |
delays at the sender |
at the sender unlikely |
withholding in practice long |
in practice long term |
practice long term block |
long term block withholding |
term block withholding attacks |
block withholding attacks are |
withholding attacks are difficult |
attacks are difficult to |
are difficult to hide |
given that the congestion |
that the congestion control |
the congestion control algorithm |
congestion control algorithm is |
control algorithm is reno |
since miners using an |
miners using an attacked |
using an attacked pool |
an attacked pool would |
attacked pool would notice |
which implements fast recovery |
pool would notice the |
would notice the reduced |
notice the reduced revenue |
the reduced revenue density |
implements fast recovery and |
fast recovery and halves |
recovery and halves the |
and halves the congestion |
halves the congestion window |
the congestion window on |
congestion window on packet |
window on packet loss |
such attacks are rarely |
attacks are rarely reported |
on packet loss rather |
packet loss rather than |
loss rather than resetting |
rather than resetting it |
than resetting it completely |
and we can therefore |
we can therefore conclude |
can therefore conclude that |
therefore conclude that they |
conclude that they are |
that they are indeed |
they are indeed rare |
a recent exception is |
recent exception is an |
exception is an attack |
is an attack on |
an attack on the |
attack on the eligius |
on the eligius pool |
the eligius pool performed |
eligius pool performed in |
pool performed in may |
the maelstrom configuration used |
maelstrom configuration used is |
performed in may and |
in may and june |
bitcoin before detecting the |
before detecting the attack |
at which point payouts |
which point payouts to |
point payouts to the |
payouts to the attackers |
to the attackers were |
the attackers were blocked |
the attackers continued the |
attackers continued the attack |
more bitcoin before realizing |
bitcoin before realizing they |
before realizing they were |
realizing they were not |
they were not receiving |
were not receiving their |
not receiving their payout |
the reasons the attack |
reasons the attack was |
the attack was so |
attack was so easily |
was so easily subverted |
so easily subverted is |
easily subverted is the |
subverted is the limited |
is the limited efforts |
the limited efforts of |
limited efforts of the |
efforts of the attackers |
of the attackers to |
the attackers to hide |
attackers to hide themselves |
they have only used |
have only used two |
only used two payout |
used two payout addresses |
two payout addresses to |
payout addresses to collect |
addresses to collect their |
to collect their payouts |
and so it was |
so it was possible |
it was possible for |
was possible for the |
possible for the alert |
for the alert pool |
the alert pool manager |
alert pool manager to |
pool manager to cluster |
manager to cluster the |
to cluster the attacking |
cluster the attacking miners |
the attacking miners and |
attacking miners and obtain |
miners and obtain a |
and obtain a statistically |
obtain a statistically significant |
a statistically significant proof |
statistically significant proof of |
significant proof of their |
proof of their wrongdoing |
it is unknown whether |
is unknown whether this |
unknown whether this was |
whether this was a |
this was a classical |
was a classical block |
a classical block withholding |
classical block withholding attack |
with the goal of |
the goal of sabotage |
or a more elaborate |
a more elaborate scheme |
to verify the effectiveness |
verify the effectiveness of |
the effectiveness of block |
effectiveness of block withholding |
of block withholding for |
block withholding for profit |
implemented an experimental bitcoin |
an experimental bitcoin test |
experimental bitcoin test network |
bitcoin test network and |
test network and demonstrated |
network and demonstrated the |
and demonstrated the practicality |
demonstrated the practicality of |
the practicality of the |
practicality of the attack |
bitcoin s health large |
s health large pools |
health large pools hinder |
large pools hinder bitcoin |
pools hinder bitcoin s |
hinder bitcoin s distributed |
bitcoin s distributed nature |
s distributed nature as |
distributed nature as they |
nature as they put |
as they put a |
they put a lot |
put a lot of |
a lot of mining |
lot of mining power |
of mining power in |
mining power in the |
power in the hands |
in the hands of |
the hands of a |
hands of a few |
of a few pool |
a few pool managers |
this has been mostly |
has been mostly addressed |
been mostly addressed by |
relatively prime interleaves offer |
prime interleaves offer better |
interleaves offer better performance |
offer better performance r |
mostly addressed by community |
addressed by community pressure |
by community pressure on |
community pressure on miners |
pressure on miners to |
on miners to avoid |
miners to avoid forming |
to avoid forming large |
avoid forming large pools |
however such recommendations had |
such recommendations had only |
recommendations had only had |
had only had limited |
only had limited success |
and mining is still |
mining is still dominated |
is still dominated by |
still dominated by a |
dominated by a small |
by a small number |
a small number of |
small number of large |
number of large pools |
as a characteristic example |
in the period of |
the period of november |
layered interleaving and bursty |
interleaving and bursty loss |
and bursty loss thus |
bursty loss thus far |
loss thus far we |
thus far we have |
far we have shown |
we have shown how |
have shown how maelstrom |
shown how maelstrom effectively |
how maelstrom effectively hides |
maelstrom effectively hides loss |
effectively hides loss from |
hides loss from tcp |
ip for packets dropped |
for packets dropped with |
packets dropped with uniform |
dropped with uniform randomness |
three pools generated over |
we examine the performance |
examine the performance of |
the performance of the |
performance of the layered |
of the layered interleaving |
the layered interleaving algorithm |
showing how different parameterizations |
how different parameterizations handle |
different parameterizations handle bursty |
parameterizations handle bursty loss |
handle bursty loss patterns |
of the proofs of |
the proofs of work |
we use a loss |
use a loss model |
a loss model where |
loss model where packets |
model where packets are |
where packets are dropped |
packets are dropped in |
are dropped in bursts |
dropped in bursts of |
in bursts of fixed |
bursts of fixed length |
allowing us to study |
us to study the |
to study the impact |
study the impact of |
the impact of burst |
impact of burst length |
of burst length on |
burst length on performance |
the fact that block |
fact that block withholding |
the link has a |
link has a one |
that block withholding attacks |
block withholding attacks are |
withholding attacks are rarely |
attacks are rarely observed |
are rarely observed may |
rarely observed may indicate |
observed may indicate that |
may indicate that the |
indicate that the active |
ms and a loss |
and a loss rate |
a loss rate of |
that the active pools |
the active pools have |
active pools have reached |
pools have reached an |
have reached an implicit |
reached an implicit or |
an implicit or explicit |
implicit or explicit agreement |
or explicit agreement not |
explicit agreement not to |
agreement not to attack |
not to attack one |
to attack one another |
an attacked pool cannot |
attacked pool cannot detect |
pool cannot detect which |
cannot detect which of |
detect which of its |
which of its miners |
of its miners are |
its miners are attacking |
miners are attacking it |
where it is varied |
let alone which pool |
alone which pool controls |
which pool controls the |
pool controls the miners |
at some point a |
some point a pool |
point a pool might |
a pool might miscalculate |
pool might miscalculate and |
mbps flow of udp |
flow of udp packets |
of udp packets is |
udp packets is sent |
packets is sent over |
is sent over it |
might miscalculate and decide |
miscalculate and decide to |
and decide to try |
decide to try to |
to try to increase |
try to increase its |
to increase its revenue |
one pool might be |
we show that our |
show that our observation |
that our observation in |
our observation in section |
pool might be enough |
might be enough to |
be enough to break |
enough to break the |
to break the agreement |
possibly leading to a |
leading to a constant |
is correct for high |
correct for high loss |
for high loss rates |
high loss rates if |
loss rates if the |
rates if the interleaves |
if the interleaves are |
the interleaves are relatively |
interleaves are relatively prime |
to a constant rate |
a constant rate of |
constant rate of attacks |
rate of attacks among |
performance improves substantially when |
improves substantially when loss |
substantially when loss rates |
when loss rates are |
loss rates are high |
rates are high and |
are high and losses |
high and losses are |
and losses are bursty |
of attacks among pools |
attacks among pools and |
among pools and a |
pools and a reduced |
and a reduced revenue |
the graph plots the |
graph plots the percentage |
plots the percentage of |
the percentage of lost |
percentage of lost packets |
of lost packets successfully |
if open pools reach |
lost packets successfully recovered |
packets successfully recovered on |
successfully recovered on the |
recovered on the y |
open pools reach a |
pools reach a state |
reach a state where |
a state where their |
state where their revenue |
where their revenue density |
their revenue density is |
revenue density is reduced |
density is reduced due |
is reduced due to |
reduced due to attacks |
axis against an x |
miners will leave them |
axis of loss rates |
of loss rates on |
loss rates on a |
rates on a log |
on a log scale |
will leave them in |
leave them in favor |
them in favor of |
in favor of other |
favor of other available |
of other available options |
the maelstrom configuration used |
maelstrom configuration used is |
configuration used is r |
miners of sufficient size |
of sufficient size can |
sufficient size can mine |
size can mine solo |
smaller miners can form |
miners can form private |
can form private pools |
form private pools with |
private pools with closed |
pools with closed access |
limited to trusted participants |
such a change may |
a change may be |
change may be in |
may be in favor |
be in favor of |
in favor of bitcoin |
favor of bitcoin as |
of bitcoin as a |
bitcoin as a whole |
since they require such |
they require such intimate |
require such intimate trust |
private pools are likely |
pools are likely to |
are likely to be |
likely to be smaller |
and form a fine |
form a fine grained |
a fine grained distribution |
fine grained distribution of |
grained distribution of mining |
distribution of mining power |
of mining power with |
mining power with many |
power with many small |
with many small pools |
many small pools and |
small pools and solo |
pools and solo miners |
a pool may engage |
pool may engage in |
may engage in an |
engage in an attack |
in an attack against |
an attack against another |
attack against another pool |
against another pool not |
another pool not to |
pool not to increase |
not to increase its |
to increase its absolute |
increase its absolute revenue |
but rather to attract |
we show the ability |
rather to attract miners |
show the ability of |
to attract miners by |
the ability of layered |
attract miners by temporarily |
ability of layered interleaving |
miners by temporarily increasing |
by temporarily increasing its |
temporarily increasing its revenue |
increasing its revenue relative |
its revenue relative to |
revenue relative to a |
relative to a competing |
to a competing pool |
of layered interleaving to |
layered interleaving to provide |
interleaving to provide gracefully |
to provide gracefully degrading |
provide gracefully degrading performance |
recent work has investigated |
gracefully degrading performance in |
degrading performance in the |
performance in the face |
in the face of |
the face of bursty |
face of bursty loss |
work has investigated the |
has investigated the motivation |
investigated the motivation of |
the motivation of pools |
motivation of pools to |
of pools to utilize |
pools to utilize part |
we plot the percentage |
to utilize part of |
plot the percentage of |
utilize part of their |
the percentage of lost |
part of their resources |
percentage of lost packets |
of their resources towards |
their resources towards sabotage |
of lost packets successfully |
resources towards sabotage attacks |
towards sabotage attacks against |
sabotage attacks against each |
attacks against each other |
lost packets successfully recovered |
packets successfully recovered against |
successfully recovered against the |
recovered against the length |
against the length of |
the length of loss |
length of loss bursts |
of loss bursts for |
loss bursts for two |
bursts for two different |
for two different sets |
two different sets of |
different sets of interleaves |
and in the bottom |
in the bottom graph |
the bottom graph we |
bottom graph we plot |
graph we plot the |
we plot the average |
plot the average latency |
the average latency at |
average latency at which |
latency at which the |
at which the packets |
which the packets were |
the packets were recovered |
recovery latency is defined |
latency is defined as |
is defined as the |
defined as the difference |
as the difference between |
the difference between the |
difference between the eventual |
between the eventual delivery |
the eventual delivery time |
eventual delivery time of |
the model of those |
delivery time of the |
time of the recovered |
of the recovered packet |
the recovered packet and |
recovered packet and the |
packet and the one |
model of those works |
of those works is |
those works is different |
way latency of the |
latency of the link |
works is different from |
is different from the |
different from the pool |
we confirmed that the |
from the pool game |
confirmed that the emulab |
the pool game model |
that the emulab link |
the emulab link had |
emulab link had almost |
link had almost no |
had almost no jitter |
almost no jitter on |
no jitter on correctly |
jitter on correctly delivered |
on correctly delivered packets |
pool game model in |
game model in two |
model in two major |
in two major ways |
two major ways a |
major ways a sabotage |
ways a sabotage attack |
way latency an accurate |
latency an accurate estimate |
an accurate estimate of |
accurate estimate of expected |
estimate of expected lossless |
of expected lossless delivery |
expected lossless delivery time |
a sabotage attack does |
sabotage attack does not |
attack does not transfer |
does not transfer revenue |
not transfer revenue from |
transfer revenue from victim |
revenue from victim to |
from victim to attacker |
increasing the interleaves results |
and migrating miners switch |
migrating miners switch to |
miners switch to less |
switch to less attacked |
to less attacked pools |
the interleaves results in |
interleaves results in much |
results in much higher |
in much higher recovery |
much higher recovery percentages |
changing pool sizes and |
pool sizes and hence |
sizes and hence revenues |
and hence revenues until |
hence revenues until convergence |
higher recovery percentages at |
recovery percentages at large |
percentages at large burst |
at large burst sizes |
the model is parametrized |
model is parametrized by |
is parametrized by the |
but percentage of packets |
percentage of packets recovered |
parametrized by the cost |
by the cost of |
the cost of the |
cost of the attack |
of the attack and |
the attack and by |
attack and by the |
and by the mobility |
by the mobility of |
the mobility of the |
mobility of the miners |
and the analysis demonstrates |
the analysis demonstrates that |
analysis demonstrates that when |
demonstrates that when considering |
that when considering only |
when considering only sabotage |
considering only sabotage attacks |
only sabotage attacks there |
sabotage attacks there are |
attacks there are regions |
there are regions where |
are regions where no |
percentage of packets recovered |
attack is the best |
is the best strategy |
the miner s dilemma |
miner s dilemma is |
s dilemma is therefore |
dilemma is therefore not |
is therefore not manifested |
therefore not manifested in |
not manifested in that |
manifested in that model |
pool competition for miners |
competition for miners is |
for miners is an |
miners is an incentive |
is an incentive in |
an incentive in and |
incentive in and of |
in and of its |
and of its own |
of its own for |
its own for mutual |
own for mutual attacks |
and a pool may |
a pool may therefore |
pool may therefore choose |
may therefore choose to |
therefore choose to perform |
choose to perform block |
to perform block withholding |
perform block withholding even |
block withholding even if |
withholding even if its |
even if its revenue |
if its revenue would |
its revenue would increase |
revenue would increase only |
would increase only after |
increase only after the |
only after the next |
after the next difficult |
the next difficult adjustment |
the two models are |
two models are therefore |
models are therefore complementary |
the analysis of their |
analysis of their combination |
of their combination is |
their combination is left |
combination is left for |
is left for future |
left for future work |
we assumed in our |
assumed in our analysis |
in our analysis that |
our analysis that pools |
analysis that pools do |
that pools do not |
pools do not charge |
do not charge fees |
not charge fees from |
charge fees from their |
fees from their members |
from their members since |
their members since such |
members since such fees |
since such fees are |
such fees are typically |
fees are typically nominal |
of a pool s |
a pool s revenue |
the model can be |
model can be extended |
can be extended to |
be extended to include |
extended to include pools |
to include pools fees |
fees would add a |
would add a friction |
add a friction element |
a friction element to |
friction element to the |
element to the flow |
to the flow of |
the flow of revenue |
flow of revenue among |
of revenue among infiltrated |
revenue among infiltrated and |
among infiltrated and infiltrating |
infiltrated and infiltrating pools |
would change to take |
change to take into |
to take into account |
take into account a |
into account a pool |
account a pool fee |
a pool fee of |
pool fee of f |
fee of f pp |
of f pp ri |
a pool with a |
pool with a fee |
with a fee of |
a fee of f |
fee of f is |
of f is a |
f is a less |
is a less attractive |
a less attractive target |
less attractive target for |
attractive target for block |
target for block withholding |
since the attacker s |
the attacker s revenue |
attacker s revenue is |
s revenue is reduced |
revenue is reduced by |
is reduced by f |
however it is also |
it is also less |
is also less attractive |
also less attractive for |
less attractive for miners |
attractive for miners in |
for miners in general |
trading off the two |
off the two for |
the two for best |
two for best protection |
for best protection is |
best protection is left |
protection is left for |
is left for future |
left for future work |
as part of the |
part of the treatment |
of the treatment of |
the treatment of the |
treatment of the miner |
r elated w ork |
elated w ork a |
layered interleaving recovery percentage |
interleaving recovery percentage and |
recovery percentage and latency |
the block withholding attack |
percentage and latency comes |
and latency comes at |
latency comes at the |
comes at the cost |
at the cost of |
the cost of higher |
cost of higher recovery |
of higher recovery latency |
block withholding attack the |
withholding attack the danger |
attack the danger of |
the danger of a |
danger of a block |
of a block withholding |
a block withholding attack |
block withholding attack is |
withholding attack is as |
attack is as old |
is as old as |
as old as bitcoin |
old as bitcoin pools |
the attack was described |
attack was described by |
was described by rosenfeld |
set of interleaves catches |
of interleaves catches almost |
interleaves catches almost all |
catches almost all packets |
almost all packets in |
all packets in an |
packets in an extended |
in an extended burst |
an extended burst of |
as pools were becoming |
packets at an average |
at an average latency |
an average latency of |
average latency of around |
pools were becoming a |
were becoming a dominant |
becoming a dominant player |
a dominant player in |
dominant player in the |
player in the bitcoin |
in the bitcoin world |
the paper described the |
paper described the standard |
described the standard attack |
while repairing all random |
repairing all random singleton |
all random singleton losses |
random singleton losses within |
used by a miner |
by a miner to |
a miner to sabotage |
miner to sabotage a |
to sabotage a pool |
sabotage a pool at |
a pool at the |
pool at the cost |
at the cost of |
the cost of reducing |
cost of reducing its |
of reducing its own |
reducing its own revenue |
the graphs also show |
graphs also show recovery |
a more general view |
also show recovery latency |
more general view of |
show recovery latency rising |
general view of fairness |
recovery latency rising gracefully |
latency rising gracefully with |
rising gracefully with the |
gracefully with the increase |
with the increase in |
the increase in loss |
increase in loss burst |
in loss burst length |
view of fairness in |
of fairness in proof |
fairness in proof of |
in proof of work |
the longer the burst |
proof of work schemes |
of work schemes was |
work schemes was discussed |
schemes was discussed in |
the longer it takes |
longer it takes to |
it takes to recover |
takes to recover the |
to recover the lost |
recover the lost packets |
the maelstrom configuration used |
maelstrom configuration used is |
configuration used is r |
in the context of |
the context of the |
context of the hashcash |
of the hashcash system |
early work did not |
work did not address |
did not address the |
not address the possibility |
address the possibility of |
the possibility of pools |
possibility of pools infiltrating |
of pools infiltrating other |
pools infiltrating other pools |
infiltrating other pools for |
other pools for block |
pools for block withholding |
experimentally demonstrate that block |
demonstrate that block withholding |
that block withholding can |
block withholding can increase |
withholding can increase the |
can increase the attacker |
increase the attacker s |
the attacker s revenue |
they do not address |
do not address the |
not address the question |
address the question of |
the question of mutual |
question of mutual attacks |
we show histograms of |
show histograms of recovery |
histograms of recovery latencies |
of recovery latencies for |
recovery latencies for the |
latencies for the two |
for the two interleave |
the two interleave configurations |
two interleave configurations under |
interleave configurations under different |
configurations under different burst |
under different burst lengths |
the histograms confirm the |
histograms confirm the trends |
confirm the trends described |
the trends described above |
have recently noted that |
recently noted that a |
packet recoveries take longer |
noted that a pool |
recoveries take longer from |
that a pool can |
take longer from left |
longer from left to |
from left to right |
left to right as |
to right as we |
right as we increase |
as we increase loss |
we increase loss burst |
increase loss burst length |
a pool can increase |
pool can increase its |
can increase its overall |
and from top to |
from top to bottom |
top to bottom as |
to bottom as we |
bottom as we increase |
as we increase the |
we increase the interleave |
increase the interleave values |
increase its overall revenue |
its overall revenue with |
overall revenue with block |
revenue with block withholding |
with block withholding if |
block withholding if all |
withholding if all other |
if all other mining |
all other mining is |
other mining is performed |
mining is performed by |
is performed by honest |
performed by honest pools |
illustrates the difference between |
the difference between a |
difference between a traditional |
between a traditional fec |
a traditional fec code |
we consider the general |
traditional fec code and |
fec code and layered |
code and layered interleaving |
and layered interleaving by |
layered interleaving by plotting |
interleaving by plotting a |
consider the general case |
the general case where |
general case where not |
case where not all |
where not all mining |
not all mining is |
all mining is performed |
mining is performed through |
is performed through public |
performed through public pools |
element moving average of |
moving average of recovery |
average of recovery latencies |
of recovery latencies for |
recovery latencies for both |
latencies for both codes |
and analyze situations where |
analyze situations where pools |
situations where pools can |
where pools can attack |
pools can attack one |
can attack one another |
the channel is configured |
channel is configured to |
is configured to lose |
configured to lose singleton |
to lose singleton packets |
the discrepancy between the |
discrepancy between the calculations |
between the calculations of |
lose singleton packets randomly |
singleton packets randomly at |
packets randomly at a |
randomly at a loss |
at a loss rate |
a loss rate of |
for the special case |
the special case analyzed |
special case analyzed there |
and additionally lose long |
additionally lose long bursts |
lose long bursts of |
case analyzed there and |
analyzed there and our |
there and our results |
and our results can |
our results can be |
results can be explained |
can be explained by |
be explained by the |
explained by the strong |
by the strong approximations |
the strong approximations in |
strong approximations in that |
approximations in that work |
packets at occasional intervals |
both codes recovery latency |
we calculate exactly how |
calculate exactly how infiltrating |
exactly how infiltrating miners |
how infiltrating miners reduce |
infiltrating miners reduce the |
miners reduce the revenue |
reduce the revenue density |
the revenue density of |
revenue density of the |
density of the infiltrated |
of the infiltrated pool |
reed solomon layered interleaving |
temporary block withholding in |
block withholding in the |
withholding in the block |
in the block withholding |
the block withholding attack |
block withholding attack discussed |
withholding attack discussed in |
attack discussed in this |
discussed in this work |
in this work the |
this work the withheld |
work the withheld blocks |
the withheld blocks are |
withheld blocks are never |
blocks are never published |
blocks can be withheld |
can be withheld temporarily |
not following the bitcoin |
following the bitcoin protocol |
to improve an attacker |
improve an attacker s |
an attacker s revenue |
a miner or a |
miner or a pool |
or a pool can |
a pool can perform |
pool can perform a |
can perform a selfish |
perform a selfish mining |
a selfish mining attack |
with selfish mining the |
selfish mining the attacker |
mining the attacker increases |
the attacker increases its |
attacker increases its revenue |
increases its revenue by |
its revenue by temporarily |
revenue by temporarily withholding |
by temporarily withholding its |
temporarily withholding its blocks |
withholding its blocks and |
its blocks and publishing |
blocks and publishing them |
and publishing them in |
publishing them in response |
them in response to |
in response to block |
response to block publication |
to block publication by |
block publication by other |
publication by other pools |
by other pools and |
other pools and miners |
this attack is independent |
attack is independent of |
is independent of the |
independent of the block |
of the block withholding |
the block withholding attack |
block withholding attack we |
withholding attack we discuss |
attack we discuss here |
we discuss here and |
discuss here and the |
here and the two |
solomon versus layered interleaving |
versus layered interleaving are |
layered interleaving are configured |
interleaving are configured with |
are configured with r |
and the two can |
the two can be |
two can be performed |
can be performed in |
be performed in concert |
an attacker can also |
attacker can also perform |
can also perform a |
also perform a double |
perform a double spending |
a double spending attack |
double spending attack as |
spending attack as follows |
and recover all lost |
recover all lost packets |
all lost packets reed |
solomon uses an interleave |
uses an interleave of |
and layered interleaving uses |
layered interleaving uses interleaves |
interleaving uses interleaves of |
he intentionally generates two |
intentionally generates two conflicting |
generates two conflicting transactions |
places one in a |
one in a block |
in a block it |
a block it withholds |
and publishes the other |
publishes the other transaction |
after the recipient sees |
the recipient sees the |
recipient sees the published |
sees the published transaction |
and consequently both have |
consequently both have a |
both have a maximum |
have a maximum tolerable |
a maximum tolerable burst |
the attacker publishes the |
maximum tolerable burst length |
tolerable burst length of |
attacker publishes the withheld |
publishes the withheld block |
the withheld block to |
withheld block to revoke |
block to revoke the |
to revoke the former |
revoke the former transaction |
this attack is performed |
we use a publicly |
use a publicly available |
a publicly available implementation |
publicly available implementation of |
available implementation of a |
implementation of a reed |
attack is performed by |
is performed by miners |
performed by miners or |
by miners or pools |
miners or pools against |
or pools against service |
pools against service providers |
against service providers that |
service providers that accept |
providers that accept bitcoin |
solomon code based on |
code based on vandermonde |
based on vandermonde matrices |
and it not directly |
it not directly related |
not directly related to |
directly related to this |
related to this work |
block withholding defense most |
withholding defense most crypto |
currencies use a proof |
the code is plugged |
code is plugged into |
is plugged into maelstrom |
plugged into maelstrom instead |
into maelstrom instead of |
maelstrom instead of layered |
instead of layered interleaving |
work architecture similar to |
architecture similar to bitcoin |
showing that we can |
that we can use |
we can use new |
can use new encodings |
use new encodings within |
new encodings within the |
encodings within the same |
within the same framework |
the same framework seamlessly |
where finding proof of |
finding proof of work |
proof of work is |
of work is the |
work is the result |
is the result of |
the result of solution |
result of solution guessing |
of solution guessing and |
solution guessing and checking |
solomon code recovers all |
code recovers all lost |
recovers all lost packets |
all lost packets with |
all of the algorithms |
lost packets with roughly |
of the algorithms we |
packets with roughly the |
the algorithms we are |
with roughly the same |
algorithms we are aware |
we are aware of |
are aware of are |
aware of are susceptible |
of are susceptible to |
are susceptible to the |
susceptible to the block |
to the block withholding |
the block withholding attack |
roughly the same latency |
the same latency whereas |
same latency whereas layered |
latency whereas layered interleaving |
as in all of |
whereas layered interleaving recovers |
in all of them |
layered interleaving recovers singleton |
all of them the |
interleaving recovers singleton losses |
of them the miner |
recovers singleton losses almost |
them the miner can |
singleton losses almost immediately |
the miner can check |
losses almost immediately and |
miner can check whether |
almost immediately and exhibits |
can check whether she |
immediately and exhibits latency |
and exhibits latency spikes |
check whether she found |
exhibits latency spikes whenever |
latency spikes whenever the |
spikes whenever the longer |
whenever the longer loss |
the longer loss burst |
longer loss burst occurs |
whether she found a |
she found a full |
found a full or |
a full or a |
full or a partial |
or a partial proof |
a partial proof of |
partial proof of work |
related work a significant |
work a significant body |
a significant body of |
significant body of work |
prominent examples are litecoin |
body of work on |
of work on application |
work on application and |
on application and tcp |
ip performance over high |
distance networks exists in |
networks exists in the |
exists in the context |
in the context of |
the context of high |
the use of parallel |
use of parallel sockets |
of parallel sockets for |
parallel sockets for higher |
sockets for higher throughput |
for higher throughput in |
higher throughput in the |
throughput in the face |
in the face of |
the face of non |
it is possible to |
congestion loss was proposed |
loss was proposed in |
was proposed in psockets |
is possible to use |
possible to use an |
to use an alternative |
use an alternative proof |
an alternative proof of |
alternative proof of work |
proof of work mechanism |
of work mechanism in |
work mechanism in which |
mechanism in which miners |
in which miners would |
which miners would not |
miners would not be |
would not be able |
not be able to |
be able to distinguish |
a number of protocols |
number of protocols have |
of protocols have been |
protocols have been suggested |
have been suggested as |
been suggested as replacements |
suggested as replacements for |
as replacements for tcp |
able to distinguish partial |
to distinguish partial from |
distinguish partial from full |
partial from full proofs |
ip in such settings |
in such settings xcp |
from full proofs of |
full proofs of work |
such a solution could |
a solution could reduce |
solution could reduce or |
could reduce or remove |
reduce or remove the |
or remove the danger |
remove the danger of |
the danger of block |
danger of block withholding |
are a few but |
a few but all |
few but all require |
but all require modifications |
all require modifications to |
require modifications to end |
making such a change |
such a change may |
a change may not |
change may not be |
may not be in |
not be in the |
be in the interest |
in the interest of |
the interest of the |
interest of the community |
or the intervening network |
some approaches seek to |
approaches seek to differentiate |
seek to differentiate between |
to differentiate between congestion |
differentiate between congestion and |
between congestion and non |
or even its potential |
could lead to a |
lead to a reduction |
to a reduction of |
a reduction of pool |
reduction of pool sizes |
as explained in section |
explained in section ix |
maelstrom is a transparent |
is a transparent performance |
a transparent performance enhancing |
transparent performance enhancing proxy |
as defined in rfc |
decentralized pools although most |
pools although most pools |
although most pools use |
most pools use a |
pools use a centralized |
use a centralized manager |
a prominent exception is |
prominent exception is p |
pool a distributed pool |
a distributed pool architecture |
distributed pool architecture with |
pool architecture with no |
architecture with no central |
with no central manager |
numerous implementations of peps |
implementations of peps exist |
of peps exist for |
peps exist for improving |
exist for improving tcp |
for improving tcp performance |
improving tcp performance on |
tcp performance on satellite |
but the question of |
the question of whether |
question of whether a |
of whether a pool |
whether a pool is |
a pool is run |
pool is run by |
is run by a |
run by a centralized |
by a centralized manager |
a centralized manager or |
centralized manager or with |
manager or with a |
or with a decentralized |
with a decentralized architecture |
a decentralized architecture is |
decentralized architecture is almost |
architecture is almost immaterial |
is almost immaterial for |
almost immaterial for the |
immaterial for the attack |
for the attack we |
the attack we describe |
but we are not |
we are not aware |
are not aware of |
not aware of any |
aware of any peps |
of any peps that |
any peps that use |
peps that use fec |
that use fec to |
use fec to mask |
pool group can be |
group can be infiltrated |
can be infiltrated and |
be infiltrated and attacked |
fec to mask errors |
to mask errors on |
mask errors on long |
pool code can be |
code can be changed |
can be changed to |
be changed to support |
changed to support attacks |
to support attacks against |
support attacks against other |
attacks against other pools |
based fec for reliable |
fec for reliable communication |
for reliable communication was |
reliable communication was first |
communication was first explored |
was first explored by |
first explored by rizzo |
on the other hand |
pool can be used |
can be used by |
be used by groups |
used by groups of |
by groups of miners |
groups of miners to |
of miners to easily |
miners to easily form |
to easily form closed |
easily form closed pools |
these do not accept |
do not accept untrusted |
not accept untrusted miners |
and are therefore protected |
are therefore protected against |
therefore protected against block |
protected against block withholding |
c onclusion we explored |
onclusion we explored a |
suggested the use of |
the use of fec |
use of fec for |
of fec for tcp |
we explored a block |
explored a block withholding |
a block withholding attack |
ip retransmissions over aggregated |
block withholding attack among |
retransmissions over aggregated traffic |
withholding attack among bitcoin |
over aggregated traffic within |
aggregated traffic within an |
traffic within an overlay |
within an overlay network |
an overlay network in |
overlay network in the |
network in the commodity |
in the commodity internet |
attack among bitcoin mining |
among bitcoin mining pools |
bitcoin mining pools an |
mining pools an attack |
pools an attack that |
an attack that is |
attack that is possible |
that is possible in |
is possible in any |
possible in any similar |
in any similar system |
any similar system that |
similar system that rewards |
system that rewards for |
that rewards for proof |
rewards for proof of |
for proof of work |
uses fec for real |
such systems are gaining |
systems are gaining popularity |
modulating the rate of |
the rate of encoding |
rate of encoding adaptively |
running most digital currencies |
most digital currencies and |
digital currencies and related |
currencies and related services |
the use of end |
we observe that no |
host fec under tcp |
ip has been explored |
has been explored in |
attacks is not a |
is not a nash |
not a nash equilibrium |
if none of the |
none of the other |
of the other pools |
the other pools attack |
a pool can increase |
pool can increase its |
can increase its revenue |
a multitude of different |
multitude of different fec |
of different fec encodings |
different fec encodings exist |
fec encodings exist in |
encodings exist in literature |
increase its revenue by |
its revenue by attacking |
revenue by attacking the |
by attacking the others |
they can broadly be |
can broadly be categorized |
broadly be categorized into |
be categorized into optimal |
categorized into optimal erasure |
when two pools can |
two pools can attack |
pools can attack each |
can attack each other |
into optimal erasure codes |
optimal erasure codes and |
erasure codes and near |
they face a version |
face a version of |
a version of the |
version of the prisoner |
of the prisoner s |
the prisoner s dilemma |
if one pool chooses |
one pool chooses to |
pool chooses to attack |
known optimal code is |
optimal code is reed |
the victim s revenue |
victim s revenue is |
s revenue is reduced |
which we described previously |
we described previously as |
described previously as generating |
and it can retaliate |
it can retaliate by |
can retaliate by attacking |
retaliate by attacking and |
by attacking and increase |
attacking and increase its |
and increase its revenue |
previously as generating c |
as generating c repair |
generating c repair packets |
c repair packets from |
repair packets from r |
packets from r source |
from r source packets |
any r of the |
r of the resulting |
of the resulting r |
at nash equilibrium both |
nash equilibrium both earn |
equilibrium both earn less |
c packets can be |
packets can be used |
can be used to |
be used to reconstruct |
used to reconstruct the |
to reconstruct the r |
reconstruct the r source |
the r source packets |
both earn less than |
earn less than they |
less than they would |
than they would have |
they would have if |
would have if neither |
have if neither attacked |
optimal codes such as |
codes such as tornado |
such as tornado and |
as tornado and lt |
with multiple pools of |
multiple pools of equal |
pools of equal size |
of equal size a |
equal size a similar |
size a similar situation |
a similar situation arises |
similar situation arises with |
situation arises with a |
arises with a symmetric |
with a symmetric equilibrium |
the fact that block |
fact that block withholding |
that block withholding is |
block withholding is not |
off encoding speed for |
withholding is not common |
encoding speed for large |
is not common may |
speed for large data |
not common may be |
for large data sizes |
common may be explained |
large data sizes against |
may be explained by |
data sizes against a |
be explained by modeling |
sizes against a loss |
explained by modeling the |
against a loss of |
by modeling the attack |
a loss of optimality |
modeling the attack decisions |
the attack decisions as |
attack decisions as an |
decisions as an iterative |
as an iterative prisoner |
an iterative prisoner s |
iterative prisoner s dilemma |
loss of optimality the |
of optimality the receiver |
optimality the receiver needs |
the receiver needs to |
receiver needs to receive |
needs to receive slightly |
to receive slightly more |
receive slightly more than |
we argue that the |
slightly more than r |
argue that the situation |
more than r source |
that the situation is |
than r source or |
r source or repair |
the situation is unstable |
situation is unstable since |
is unstable since the |
unstable since the attack |
since the attack can |
the attack can be |
attack can be done |
can be done anonymously |
source or repair packets |
or repair packets to |
repair packets to regenerate |
packets to regenerate the |
to regenerate the original |
regenerate the original r |
the original r data |
original r data packets |
one pool may decide |
pool may decide to |
may decide to increase |
decide to increase its |
to increase its revenue |
increase its revenue and |
optimal codes are extremely |
its revenue and drag |
revenue and drag the |
and drag the others |
drag the others to |
the others to attack |
others to attack as |
to attack as well |
codes are extremely fast |
are extremely fast for |
extremely fast for encoding |
fast for encoding over |
ending with a reduced |
with a reduced revenue |
a reduced revenue for |
reduced revenue for all |
for encoding over large |
encoding over large sets |
over large sets of |
large sets of data |
sets of data but |
of data but not |
data but not of |
but not of significant |
not of significant importance |
of significant importance for |
significant importance for real |
the inferior revenue would |
inferior revenue would push |
revenue would push miners |
would push miners to |
push miners to join |
miners to join private |
to join private pools |
since optimal codes perform |
optimal codes perform equally |
codes perform equally well |
perform equally well with |
which can verify that |
can verify that their |
verify that their registered |
that their registered miners |
equally well with small |
well with small data |
with small data sizes |
their registered miners do |
registered miners do not |
miners do not withhold |
do not withhold blocks |
of particular relevance are |
particular relevance are growth |
relevance are growth codes |
this would lead to |
would lead to smaller |
lead to smaller pools |
and so ultimately to |
so ultimately to a |
ultimately to a better |
to a better environment |
a better environment for |
better environment for bitcoin |
environment for bitcoin as |
for bitcoin as a |
bitcoin as a whole |
which use multiple encoding |
use multiple encoding rates |
multiple encoding rates for |
encoding rates for different |
rates for different overhead |
for different overhead levels |
for their valuable advice |
the author is grateful |
author is grateful to |
layered interleaving uses multiple |
is grateful to ken |
grateful to ken birman |
interleaving uses multiple interleaves |
uses multiple interleaves for |
multiple interleaves for different |
interleaves for different burst |
for different burst resilience |
different burst resilience levels |
burst resilience levels without |
resilience levels without modulating |
levels without modulating the |
without modulating the encoding |
modulating the encoding rate |
emin gu n sirer |
the effect of random |
effect of random losses |
of random losses on |
random losses on tcp |
ip has been studied |
has been studied in |
been studied in depth |
studied in depth by |
in depth by lakshman |
and the paper shepherd |
the paper shepherd joseph |
paper shepherd joseph bonneau |
padhye s analytical model |
provides a means to |
a means to gauge |
means to gauge the |
to gauge the impact |
gauge the impact of |
the impact of packet |
impact of packet loss |
of packet loss on |
packet loss on tcp |
peer electronic cash system |
while most published studies |
most published studies of |
published studies of packet |
studies of packet loss |
of packet loss are |
packet loss are based |
loss are based on |
are based on the |
based on the commodity |
on the commodity internet |
the commodity internet rather |
commodity internet rather than |
internet rather than highspeed |
rather than highspeed lambda |
than highspeed lambda links |
study the sprint backbone |
the sprint backbone and |
sprint backbone and make |
backbone and make two |
and make two observations |
make two observations that |
two observations that could |
observations that could be |
that could be explained |
could be explained by |
be explained by non |
ebay s paypal unit |
s paypal unit to |
paypal unit to start |
unit to start accepting |
to start accepting bitcoin |
start accepting bitcoin payments |
links are rarely loaded |
are rarely loaded at |
rarely loaded at more |
loaded at more than |
of capacity and b |
packet reordering events occur |
reordering events occur for |
events occur for some |
occur for some flows |
possibly indicating packet loss |
indicating packet loss followed |
packet loss followed by |
loss followed by retransmissions |
future work scaling maelstrom |
work scaling maelstrom to |
scaling maelstrom to multiple |
maelstrom to multiple gigabits |
to multiple gigabits per |
multiple gigabits per second |
gigabits per second of |
per second of traffic |
second of traffic will |
of traffic will require |
traffic will require small |
will require small rack |
google adds bitcoin currency |
adds bitcoin currency conversion |
bitcoin currency conversion to |
currency conversion to search |
style clusters of tens |
clusters of tens of |
of tens of machines |
tens of machines to |
of machines to distribute |
machines to distribute encoding |
to distribute encoding load |
distribute encoding load over |
we need to design |
need to design intelligent |
to design intelligent load |
over mechanisms for such |
mechanisms for such a |
for such a scheme |
we have described layered |
have described layered interleaving |
described layered interleaving with |
layered interleaving with fixed |
and the next step |
the next step in |
next step in extending |
step in extending this |
in extending this protocol |
extending this protocol is |
this protocol is to |
protocol is to make |
is to make it |
to make it adaptive |
changing interleaves and rate |
interleaves and rate as |
and rate as loss |
rate as loss patterns |
as loss patterns in |
loss patterns in the |
patterns in the link |
in the link change |
conclusion modern distributed systems |
modern distributed systems are |
distributed systems are compelled |
systems are compelled by |
are compelled by real |
world imperatives to coordinate |
imperatives to coordinate across |
to coordinate across datacenters |
coordinate across datacenters separated |
across datacenters separated by |
repurposing bitcoin work for |
bitcoin work for data |
work for data preservation |
in proceedings of the |
proceedings of the ieee |
of the ieee symposium |
the ieee symposium on |
ieee symposium on security |
symposium on security and |
on security and privacy |
namecoin dns dotbit project |
a next generation smart |
next generation smart contract |
latency histograms for i |
analysis of bitcoin pooled |
of bitcoin pooled mining |
bitcoin pooled mining reward |
pooled mining reward systems |
research perspectives on bitcoin |
perspectives on bitcoin and |
on bitcoin and secondgeneration |
bitcoin and secondgeneration cryptocurrencies |
in ieee symposium on |
ieee symposium on security |
symposium on security and |
on security and privacy |
latency histograms for i |
packet loss cripples the |
loss cripples the performance |
cripples the performance notes |
the performance notes of |
performance notes of such |
notes of such systems |
and reliability and flow |
are increasingly popular and |
increasingly popular and designed |
popular and designed for |
and designed for lans |
designed for lans and |
or the commodity internet |
the commodity internet fail |
commodity internet fail to |
internet fail to used |
fail to used for |
to used for applications |
used for applications such |
for applications such as |
applications such as efficiently |
such as efficiently distributing |
as efficiently distributing bulk |
efficiently distributing bulk data |
achieve optimal performance on |
optimal performance on the |
performance on the high |
it is not obvious |
is not obvious that |
not obvious that these |
obvious that these have |
that these have utility |
these have utility in |
have utility in real |
time communi lambda networks |
communi lambda networks linking |
lambda networks linking datacenters |
protocols is not an |
is not an option |
not an option for |
an option for commodity |
option for commodity clusters |
for commodity clusters where |
commodity clusters where standardization |
clusters where standardization is |
where standardization is critical |
standardization is critical for |
is critical for cost |
critical for cost mitigation |
maelstrom is an edge |
is an edge appliance |
an edge appliance that |
edge appliance that uses |
appliance that uses forward |
that uses forward error |
uses forward error correction |
forward error correction references |
error correction references to |
correction references to mask |
references to mask packet |
to mask packet loss |
mask packet loss from |
packet loss from end |
information propagation in the |
propagation in the bitcoin |
in the bitcoin network |
th ieee international conference |
ieee international conference on |
international conference on peer |
global crossing current network |
crossing current network performance |
ip throughput and latency |
throughput and latency by |
and latency by orders |
latency by orders of |
by orders of magninetwork |
last tude when loss |
tude when loss occurs |
maelstrom is easy to |
is easy to install |
easy to install and |
to install and accessed |
install and accessed feb |
bitcoin and the age |
and the age of |
the age of bespoke |
age of bespoke silicon |
in proceedings of the |
and is completely transparent |
is completely transparent to |
completely transparent to applications |
transparent to applications and |
international conference on compilers |
architectures and synthesis for |
and synthesis for embedded |
synthesis for embedded systems |
qwest ip network statistics |
protocols literally providing reliability |
literally providing reliability in |
providing reliability in an |
reliability in an inexpennet |
into the bitcoin mines |
acknowledgments we would like |
we would like to |
would like to thank |
like to thank our |
to thank our shepherd |
thank our shepherd robert |
our shepherd robert morris |
shepherd robert morris and |
robert morris and the |
morris and the other |
and the other reviewers |
the other reviewers for |
other reviewers for extensive |
reviewers for extensive comments |
for extensive comments that |
extensive comments that significantly |
comments that significantly shaped |
that significantly shaped the |
significantly shaped the final |
shaped the final version |
the final version of |
final version of the |
version of the paper |
vidhyashankar venkataraman and vivek |
venkataraman and vivek vishnumurthy |
and vivek vishnumurthy provided |
vivek vishnumurthy provided useful |
vishnumurthy provided useful comments |
tom boures provided valuable |
boures provided valuable insight |
provided valuable insight into |
valuable insight into the |
insight into the quality |
into the quality of |
the quality of existing |
quality of existing fiber |
of existing fiber links |
stanislav shalunov provided information |
shalunov provided information on |
provided information on loss |
information on loss rates |
on loss rates on |
loss rates on internet |
and paul wefel gave |
paul wefel gave us |
wefel gave us access |
gave us access to |
us access to teragrid |
access to teragrid loss |
to teragrid loss measurements |
nat and packet mangling |
and packet mangling for |
packet mangling for linux |
lateral error correction for |
error correction for timecritical |
correction for timecritical multicast |
fourth usenix symposium on |
usenix symposium on networked |
symposium on networked systems |
on networked systems design |
networked systems design and |
systems design and implementation |
performance enhancing proxies intended |
enhancing proxies intended to |
proxies intended to mitigate |
intended to mitigate link |
enhanced loss differentiation algorithms |
loss differentiation algorithms for |
differentiation algorithms for use |
algorithms for use in |
for use in tcp |
use in tcp sources |
in tcp sources over |
tcp sources over heterogeneous |
sources over heterogeneous wireless |
over heterogeneous wireless networks |
how a mining monopoly |
a mining monopoly can |
mining monopoly can attack |
monopoly can attack bitcoin |
ieee global telecommunications conference |
flow aggregation for enhanced |
aggregation for enhanced tcp |
for enhanced tcp over |
enhanced tcp over wide |
tcp over wide area |
over wide area wireless |
vice president of research |
president of research and |
of research and t |
majority is not enough |
bitcoin mining is vulnerable |
in financial cryptography and |
financial cryptography and data |
cryptography and data security |
multicast routing in datagram |
routing in datagram internetworks |
in datagram internetworks and |
datagram internetworks and extended |
internetworks and extended lans |
cooperative equilibrium for supergames |
the review of economic |
review of economic studies |
level traffic measurements from |
traffic measurements from the |
measurements from the sprint |
from the sprint ip |
the sprint ip backbone |
term competition a game |
a transport protocol for |
transport protocol for grid |
protocol for grid computing |
journal of grid computing |
optical domain performance monitoring |
optical fiber communication conference |
io bitcoin mining pool |
end performance effects of |
performance effects of parallel |
effects of parallel tcp |
of parallel tcp sockets |
parallel tcp sockets on |
tcp sockets on a |
sockets on a lossy |
on a lossy wide |
the effects of systemic |
effects of systemic packet |
of systemic packet loss |
systemic packet loss on |
packet loss on aggregate |
loss on aggregate tcp |
on aggregate tcp flows |
ieee conference on supercomputing |
predictable high performance bulk |
high performance bulk data |
performance bulk data transfer |
ieee international conference on |
international conference on cluster |
conference on cluster computing |
the case for packet |
case for packet level |
for packet level fec |
proceedings of the tc |
kncminer bitcoin mining cloud |
bitcoin mining cloud mining |
fifth international workshop on |
international workshop on protocols |
workshop on protocols for |
on protocols for high |
gigabit ethernet on commodity |
ethernet on commodity systems |
an authorization architecture for |
authorization architecture for trustworthy |
architecture for trustworthy computing |
in proceedings of the |
proceedings of the twenty |
third acm symposium on |
acm symposium on operating |
symposium on operating systems |
on operating systems principles |
where did my performance |
did my performance go |
rate limiting rears its |
limiting rears its ugly |
rears its ugly head |
isn t quite enough |
on power splitting games |
power splitting games in |
splitting games in distributed |
games in distributed computation |
the case of bitcoin |
case of bitcoin pooled |
of bitcoin pooled mining |
modified tcp congestion avoidance |
tcp congestion avoidance algorithm |
physical layer impact upon |
layer impact upon packet |
impact upon packet errors |
passive and active measurement |
and active measurement workshop |
weekly bitcoin network statistics |
maximizing sensor network data |
sensor network data persistence |
in proceedings of acm |
proceedings of acm sigcomm |
congestion control for high |
control for high bandwidth |
and protocols for computer |
protocols for computer communications |
theoretic analysis of ddos |
analysis of ddos attacks |
of ddos attacks against |
ddos attacks against bitcoin |
attacks against bitcoin mining |
against bitcoin mining pools |
in workshop on bitcoin |
workshop on bitcoin research |
when bitcoin mining pools |
bitcoin mining pools run |
mining pools run dry |
in workshop on bitcoin |
workshop on bitcoin research |
journal of lightwave technology |
comparison of mining pools |
comparison of mining pools |
hashcash amortizable publicly auditable |
amortizable publicly auditable cost |
a cross layer study |
cross layer study of |
layer study of packet |
study of packet loss |
of packet loss in |
packet loss in all |
the performance of tcp |
ip for networks with |
for networks with high |
networks with high bandwidth |
delay products and random |
products and random loss |
hashcash a denial of |
a denial of service |
denial of service counter |
acm transactions on networking |
rd annual ieee symposium |
annual ieee symposium on |
ieee symposium on foundations |
symposium on foundations of |
on foundations of computer |
foundations of computer science |
on subversive miner strategies |
subversive miner strategies and |
miner strategies and block |
strategies and block withholding |
and block withholding attack |
block withholding attack in |
withholding attack in bitcoin |
attack in bitcoin digital |
in bitcoin digital currency |
end forward error correction |
international zurich seminar on |
zurich seminar on communications |
how to disincentivize large |
to disincentivize large bitcoin |
disincentivize large bitcoin mining |
large bitcoin mining pools |
rateless codes and big |
codes and big downloads |
paritybased loss recovery for |
loss recovery for reliable |
recovery for reliable multicast |
for reliable multicast transmission |
in proceedings of the |
proceedings of the acm |
of the acm sigcomm |
a simple model and |
simple model and its |
model and its empirical |
and its empirical validation |
an adaptive forward error |
adaptive forward error correction |
forward error correction protocol |
error correction protocol for |
correction protocol for end |
computer communications and networks |
th international conference on |
businesses see the light |
effective erasure codes for |
erasure codes for reliable |
codes for reliable computer |
for reliable computer communication |
reliable computer communication protocols |
on the feasibility of |
the feasibility of software |
feasibility of software fec |
the case for application |
level network striping for |
network striping for data |
striping for data intensive |
for data intensive applications |
data intensive applications using |
intensive applications using high |
applications using high speed |
using high speed wide |
high speed wide area |
speed wide area networks |
ieee conference on supercomputing |
google s secret plans |
s secret plans for |
secret plans for all |
plans for all that |
for all that dark |
all that dark fiber |
an overlay based architecture |
overlay based architecture for |
based architecture for enhancing |
architecture for enhancing internet |
for enhancing internet qos |
first usenix symposium on |
usenix symposium on networked |
symposium on networked systems |
on networked systems design |
networked systems design and |
systems design and implementation |
udp bandwidth measurement tool |
a tcp performance enhancing |
tcp performance enhancing proxy |
performance enhancing proxy for |
enhancing proxy for satellite |
proxy for satellite links |
proceedings of the second |
of the second international |
the second international ifip |
networking conference on networking |
conference on networking technologies |
performance of computer and |
of computer and communication |
computer and communication networks |
and mobile and wireless |
mobile and wireless communications |
tsunami file transfer protocol |
workshop on protocols for |
on protocols for fast |
protocols for fast longdistance |
for fast longdistance networks |
the university of illinois |
university of illinois national |
of illinois national center |
illinois national center for |
national center for supercomputing |
center for supercomputing applications |
an integrated experimental environment |
integrated experimental environment for |
experimental environment for distributed |
environment for distributed systems |
for distributed systems and |
distributed systems and networks |
of the fifth symposium |
the fifth symposium on |
fifth symposium on operating |
symposium on operating systems |
on operating systems design |
operating systems design and |
systems design and implementation |
solomon codes and their |
codes and their applications |
the: 7744
of: 4121
a: 3489
to: 3267
and: 3193
in: 2417
is: 1914
for: 1353
that: 1296
with: 990
on: 965
are: 940
we: 925
as: 917
it: 771
by: 745
be: 695
this: 681
data: 659
pool: 659
s: 654
an: 631
at: 630
can: 574
system: 559
its: 497
from: 483
not: 466
or: 452
r: 429
which: 418
each: 404
file: 401
all: 377
systems: 372
m: 368
if: 362
figure: 357
x: 343
one: 338
time: 335
nodes: 332
pools: 325
revenue: 325
t: 325
packets: 320
rate: 320
other: 317
cache: 310
but: 309
our: 291
have: 289
work: 287
i: 282
performance: 281
such: 271
when: 268
loss: 258
p: 258
miners: 257
has: 252
bandwidth: 251
packet: 244
c: 243
network: 242
their: 236
will: 232
attack: 230
block: 230
mining: 230
j: 228
these: 223
than: 222
only: 221
end: 220
use: 220
they: 218
more: 216
node: 209
bitcoin: 204
no: 204
high: 203
number: 202
services: 200
latency: 197
b: 196
may: 193
transactions: 192
would: 192
server: 190
two: 188
where: 188
update: 187
power: 182
between: 180
used: 177
based: 174
d: 173
over: 171
any: 170
different: 169
distributed: 166
miner: 164
new: 164
single: 164
also: 162
client: 161
some: 161
large: 159
tcp: 159
was: 157
web: 157
since: 153
objects: 152
application: 150
ip: 150
service: 150
using: 149
updates: 146
e: 144
protocol: 144
them: 144
set: 140
read: 139
access: 138
applications: 137
process: 137
files: 134
transaction: 133
maelstrom: 132
traffic: 132
there: 131
operating: 130
gossip: 129
however: 129
into: 129
section: 129
withholding: 129
rates: 128
example: 127
mfs: 127
so: 127
communication: 124
consistency: 124
both: 122
same: 122
size: 122
object: 121
priorities: 120
repair: 120
even: 119
peer: 119
throughput: 119
chain: 118
g: 116
control: 114
failure: 114
information: 113
while: 113
first: 112
recovery: 112
were: 112
results: 111
database: 110
protocols: 110
case: 109
acm: 106
link: 106
low: 106
therefore: 106
then: 105
without: 105
rpcs: 104
small: 104
clients: 103
writes: 103
networks: 102
could: 101
second: 101
ms: 100
rpc: 99
do: 98
many: 98
asynchronous: 97
writeback: 97
log: 96
model: 96
within: 96
group: 95
send: 95
does: 94
proof: 94
most: 93
up: 93
memory: 92
state: 91
user: 91
average: 90
content: 90
version: 90
level: 89
order: 89
back: 87
been: 87
support: 87
less: 86
through: 85
windows: 85
available: 84
groups: 84
long: 84
out: 84
see: 84
after: 83
another: 83
approach: 83
fec: 83
full: 83
how: 83
against: 82
architecture: 82
infiltration: 82
message: 82
o: 82
disk: 81
k: 81
messages: 81
need: 81
qsm: 81
about: 80
kb: 80
multicast: 80
sender: 80
uses: 80
management: 79
n: 79
q: 79
way: 79
delivery: 78
total: 78
disks: 77
experiments: 77
possible: 77
write: 77
design: 76
higher: 76
delay: 75
increase: 75
layer: 75
local: 75
research: 75
scale: 75
upload: 75
computer: 74
f: 74
implementation: 74
might: 74
source: 74
analysis: 73
burst: 73
live: 73
probability: 73
workloads: 73
accesses: 72
because: 72
every: 72
lost: 72
solution: 71
cost: 70
due: 70
step: 70
v: 70
value: 70
equilibrium: 69
like: 69
multiple: 69
manager: 68
per: 68
priority: 68
well: 68
list: 67
overhead: 67
computing: 66
load: 66
running: 66
cornell: 65
http: 65
mechanism: 65
opportunistic: 65
run: 65
should: 65
under: 65
attacking: 64
cluster: 64
operations: 64
proceedings: 64
servers: 64
show: 64
shown: 64
test: 64
attacks: 63
layered: 63
much: 63
paper: 63
partial: 63
received: 63
stream: 63
attacker: 62
dependency: 62
kernel: 62
point: 62
solutions: 62
event: 61
l: 61
maximum: 61
must: 61
scheme: 61
shows: 61
sizes: 61
code: 60
game: 60
interleave: 60
prefetching: 60
proofs: 60
replication: 60
result: 60
round: 60
storage: 60
us: 60
perform: 59
sending: 59
very: 59
inconsistency: 58
once: 58
provide: 58
threshold: 58
users: 58
workload: 58
flow: 57
scalable: 57
sent: 57
similar: 57
streaming: 57
being: 56
conference: 56
symposium: 56
download: 55
nt: 55
problem: 55
random: 55
receiver: 55
reduce: 55
requests: 55
until: 55
before: 54
correct: 54
factor: 54
global: 54
graph: 54
interleaving: 54
larger: 54
open: 54
processes: 54
range: 54
retrieved: 54
among: 53
auditing: 53
caching: 53
cannot: 53
h: 53
scenario: 53
center: 52
fetch: 52
mode: 52
real: 52
synchronous: 52
take: 52
transactional: 52
according: 51
form: 51
ieee: 51
increasing: 51
internet: 51
make: 51
present: 51
reads: 51
xor: 51
able: 50
algorithm: 50
current: 50
had: 50
inconsistencies: 50
mobile: 50
store: 50
components: 49
contention: 49
either: 49
existing: 49
hence: 49
mechanisms: 49
mi: 49
now: 49
three: 49
whether: 49
encoding: 48
general: 48
host: 48
implemented: 48
own: 48
prefetch: 48
recovered: 48
reliable: 48
values: 48
although: 47
important: 47
pp: 47
side: 47
w: 47
behavior: 46
execution: 46
fixed: 46
function: 46
generated: 46
graphs: 46
operation: 46
platform: 46
request: 46
speed: 46
th: 46
consider: 45
designed: 45
shared: 45
significant: 45
university: 45
victim: 45
window: 45
attacked: 44
blocks: 44
com: 44
community: 44
delays: 44
density: 44
error: 44
future: 44
hosted: 44
kbps: 44
left: 44
pages: 44
smaller: 44
standard: 44
wide: 44
appliance: 43
changes: 43
component: 43
costs: 43
events: 43
fig: 43
here: 43
makes: 43
ratio: 43
required: 43
right: 43
thus: 43
y: 43
allows: 42
amount: 42
change: 42
developers: 42
distribution: 42
experiment: 42
just: 42
often: 42
rather: 42
scalability: 42
seen: 42
start: 42
tasks: 42
uniform: 42
what: 42
cloud: 41
effect: 41
mafs: 41
missing: 41
numbers: 41
optimal: 41
reduced: 41
simple: 41
ssa: 41
strategy: 41
across: 40
address: 40
detection: 40
down: 40
further: 40
given: 40
hosts: 40
lower: 40
next: 40
non: 40
receive: 40
sends: 40
software: 40
token: 40
typically: 40
allow: 39
caches: 39
cases: 39
congestion: 39
directly: 39
entire: 39
increases: 39
independent: 39
interface: 39
length: 39
original: 39
overheads: 39
part: 39
structure: 39
times: 39
compared: 38
described: 38
direct: 38
during: 38
microsoft: 38
region: 38
require: 38
revenues: 38
world: 38
accessed: 37
al: 37
birman: 37
centers: 37
codes: 37
effective: 37
enough: 37
et: 37
improve: 37
losses: 37
membership: 37
provides: 37
xors: 37
better: 36
clusters: 36
consistent: 36
describe: 36
expected: 36
fact: 36
fast: 36
loyal: 36
previous: 36
related: 36
relative: 36
techniques: 36
today: 36
types: 36
adaptation: 35
additional: 35
almost: 35
commodity: 35
environment: 35
https: 35
international: 35
last: 35
links: 35
longer: 35
minimum: 35
needs: 35
org: 35
performed: 35
proxy: 35
reliability: 35
still: 35
though: 35
above: 34
acid: 34
earlier: 34
evaluation: 34
factors: 34
injection: 34
interleaves: 34
ken: 34
levels: 34
managed: 34
percentage: 34
remote: 34
sets: 34
several: 34
virtual: 34
www: 34
constant: 33
denote: 33
limited: 33
note: 33
overall: 33
particular: 33
receiving: 33
top: 33
working: 33
assume: 32
become: 32
clustered: 32
detect: 32
find: 32
including: 32
period: 32
replicated: 32
scenarios: 32
seconds: 32
space: 32
stable: 32
table: 32
technologies: 32
technology: 32
those: 32
trace: 32
versions: 32
added: 31
ensure: 31
evaluate: 31
finally: 31
follows: 31
immediately: 31
invalidations: 31
least: 31
mb: 31
overlay: 31
prediction: 31
principles: 31
receivers: 31
requires: 31
runs: 31
sirp: 31
target: 31
udp: 31
achieve: 30
adaptive: 30
amazon: 30
auditors: 30
collaboration: 30
correction: 30
dropped: 30
good: 30
incoming: 30
lists: 30
members: 30
performs: 30
policy: 30
recent: 30
ri: 30
schemes: 30
security: 30
share: 30
third: 30
usenix: 30
z: 30
associated: 29
availability: 29
close: 29
commit: 29
complete: 29
delivered: 29
edu: 29
head: 29
key: 29
later: 29
platforms: 29
pull: 29
receives: 29
recover: 29
reducing: 29
science: 29
settings: 29
task: 29
varying: 29
xi: 29
best: 28
configuration: 28
core: 28
dilemma: 28
feasible: 28
implements: 28
issues: 28
making: 28
never: 28
obtain: 28
occur: 28
others: 28
repository: 28
resulting: 28
style: 28
tools: 28
transport: 28
type: 28
area: 27
async: 27
build: 27
building: 27
cached: 27
capacity: 27
collection: 27
failures: 27
following: 27
forward: 27
framework: 27
increased: 27
instance: 27
major: 27
mbps: 27
needed: 27
neighbors: 27
nov: 27
participants: 27
reader: 27
resources: 27
solo: 27
speedup: 27
stored: 27
tm: 27
vn: 27
writer: 27
abort: 26
basic: 26
becomes: 26
benefit: 26
bin: 26
bins: 26
certain: 26
channel: 26
classical: 26
common: 26
consumption: 26
controls: 26
discuss: 26
entry: 26
fault: 26
haul: 26
instead: 26
means: 26
mostly: 26
online: 26
os: 26
solomon: 26
sources: 26
tolerance: 26
vol: 26
allowing: 25
backend: 25
bursts: 25
bursty: 25
choice: 25
conditions: 25
considered: 25
contribution: 25
copy: 25
cs: 25
difficulty: 25
distance: 25
estimate: 25
figures: 25
flows: 25
found: 25
goal: 25
hardware: 25
invalidation: 25
machines: 25
observed: 25
properties: 25
queue: 25
rain: 25
reduces: 25
report: 25
spent: 25
split: 25
takes: 25
transmission: 25
abstract: 24
algorithms: 24
around: 24
blockchain: 24
cause: 24
closed: 24
committed: 24
contrast: 24
correctly: 24
corresponding: 24
critical: 24
datacenters: 24
demand: 24
developed: 24
done: 24
equal: 24
experimental: 24
front: 24
having: 24
idea: 24
individual: 24
infiltrating: 24
knowledge: 24
limit: 24
lock: 24
logs: 24
ny: 24
observe: 24
oriented: 24
peers: 24
place: 24
processing: 24
strategies: 24
streams: 24
structured: 24
too: 24
view: 24
again: 23
approaches: 23
called: 23
choose: 23
create: 23
datacenter: 23
detected: 23
duration: 23
include: 23
layers: 23
likely: 23
majority: 23
member: 23
monitoring: 23
ones: 23
powered: 23
product: 23
reed: 23
sufficient: 23
sync: 23
traditional: 23
unix: 23
ways: 23
workshop: 23
york: 23
alternative: 22
always: 22
avoid: 22
built: 22
certification: 22
connected: 22
consequently: 22
context: 22
defined: 22
dependencies: 22
development: 22
efficient: 22
generate: 22
handle: 22
he: 22
made: 22
maintain: 22
mtu: 22
net: 22
occurs: 22
off: 22
optical: 22
parameters: 22
patterns: 22
popular: 22
problems: 22
revision: 22
starts: 22
via: 22
who: 22
wireless: 22
bandwidths: 21
buffers: 21
centralized: 21
configurations: 21
contains: 21
dynamic: 21
easily: 21
easy: 21
equation: 21
etc: 21
garbage: 21
hand: 21
hash: 21
identical: 21
iii: 21
index: 21
let: 21
life: 21
line: 21
mashup: 21
milliseconds: 21
old: 21
path: 21
private: 21
project: 21
proxies: 21
reasons: 21
response: 21
short: 21
significantly: 21
social: 21
staleness: 21
video: 21
vogels: 21
wait: 21
writing: 21
aggregate: 20
analyze: 20
architectures: 20
benefits: 20
buffering: 20
changing: 20
choosing: 20
consists: 20
four: 20
generates: 20
google: 20
grep: 20
honest: 20
inter: 20
interest: 20
interfaces: 20
library: 20
machine: 20
manner: 20
minibrowser: 20
multi: 20
none: 20
potentially: 20
presence: 20
proc: 20
quality: 20
queued: 20
racs: 20
rapidly: 20
references: 20
respectively: 20
simply: 20
site: 20
stale: 20
together: 20
traces: 20
updated: 20
usa: 20
usage: 20
yet: 20
actually: 19
adding: 19
appropriate: 19
clear: 19
convergence: 19
course: 19
currently: 19
digital: 19
expect: 19
explained: 19
extended: 19
extremely: 19
faster: 19
features: 19
inconsistent: 19
investigation: 19
issue: 19
kind: 19
know: 19
mine: 19
month: 19
natural: 19
networking: 19
om: 19
partition: 19
periods: 19
potential: 19
propagation: 19
proposed: 19
query: 19
quickly: 19
re: 19
recipe: 19
reply: 19
sequence: 19
serializability: 19
soc: 19
speeds: 19
subscribers: 19
taken: 19
towards: 19
transfer: 19
transient: 19
upon: 19
whereas: 19
works: 19
active: 18
aggregation: 18
aware: 18
background: 18
bad: 18
chooses: 18
cpu: 18
databases: 18
difficult: 18
divided: 18
drop: 18
earn: 18
effectiveness: 18
employ: 18
eventually: 18
exchange: 18
failed: 18
feb: 18
fiber: 18
foreground: 18
generation: 18
get: 18
gigabit: 18
heavy: 18
history: 18
identify: 18
includes: 18
initial: 18
itself: 18
known: 18
lambda: 18
latencies: 18
logging: 18
moreover: 18
nash: 18
neither: 18
noted: 18
participating: 18
propose: 18
publish: 18
queries: 18
repositories: 18
roundtrip: 18
sigcomm: 18
specific: 18
study: 18
subversion: 18
summary: 18
switching: 18
synthetic: 18
tokens: 18
topics: 18
unique: 18
varied: 18
various: 18
vary: 18
actual: 17
automatically: 17
chosen: 17
coda: 17
communications: 17
developer: 17
device: 17
devices: 17
don: 17
early: 17
enabled: 17
environments: 17
errors: 17
experience: 17
focus: 17
fraction: 17
functionality: 17
grows: 17
highest: 17
highly: 17
hosting: 17
ii: 17
impact: 17
implement: 17
infrastructure: 17
lines: 17
maintains: 17
modified: 17
module: 17
necessary: 17
offer: 17
partitioning: 17
periodically: 17
products: 17
progress: 17
projects: 17
ran: 17
raps: 17
reach: 17
remain: 17
setting: 17
sharing: 17
simultaneous: 17
specifically: 17
standards: 17
subservice: 17
successfully: 17
supported: 17
switch: 17
symmetric: 17
term: 17
transmitted: 17
van: 17
variety: 17
years: 17
acts: 16
already: 16
axis: 16
believe: 16
buffer: 16
bytes: 16
call: 16
chainsaw: 16
clustering: 16
compare: 16
configured: 16
conflicts: 16
connectivity: 16
contents: 16
conventional: 16
created: 16
define: 16
demonstrate: 16
difference: 16
efficacy: 16
examples: 16
fees: 16
few: 16
ghash: 16
go: 16
hard: 16
illustrated: 16
implications: 16
indeed: 16
infiltrate: 16
integration: 16
io: 16
kinds: 16
lead: 16
limiting: 16
linux: 16
little: 16
main: 16
market: 16
measurements: 16
modes: 16
operate: 16
options: 16
page: 16
parallel: 16
physical: 16
points: 16
prisoner: 16
publishes: 16
registered: 16
requirements: 16
serialization: 16
simulation: 16
simultaneously: 16
status: 16
strong: 16
sub: 16
subsystem: 16
themselves: 16
timestamp: 16
topic: 16
transparently: 16
typical: 16
accessing: 15
adapt: 15
applied: 15
arrive: 15
atp: 15
attempt: 15
bar: 15
bc: 15
comparison: 15
containing: 15
contribute: 15
corba: 15
department: 15
describes: 15
diff: 15
edge: 15
effects: 15
exists: 15
fire: 15
gc: 15
greater: 15
idle: 15
included: 15
infiltrated: 15
info: 15
june: 15
latter: 15
linear: 15
maintaining: 15
namely: 15
november: 15
oms: 15
optimize: 15
outgoing: 15
paths: 15
performing: 15
practice: 15
predictable: 15
programming: 15
regions: 15
regular: 15
renesse: 15
represents: 15
respond: 15
sense: 15
sirer: 15
slightly: 15
slow: 15
statistics: 15
stores: 15
supercomputing: 15
teragrid: 15
thousands: 15
tier: 15
underlying: 15
uniformly: 15
whole: 15
accept: 14
addition: 14
arise: 14
balancing: 14
bounded: 14
channels: 14
class: 14
combined: 14
commits: 14
conclusion: 14
concurrency: 14
currency: 14
decrease: 14
deliver: 14
destination: 14
detects: 14
differentiated: 14
directory: 14
dissemination: 14
distinct: 14
drops: 14
engineering: 14
entries: 14
exactly: 14
explore: 14
fail: 14
fifo: 14
financial: 14
finding: 14
growing: 14
guarantees: 14
handling: 14
help: 14
improves: 14
infiltrators: 14
integrated: 14
interested: 14
involves: 14
malicious: 14
modern: 14
option: 14
perfect: 14
policies: 14
prevent: 14
previously: 14
prior: 14
program: 14
providing: 14
published: 14
question: 14
relatively: 14
sabotage: 14
search: 14
singleton: 14
soon: 14
spread: 14
starting: 14
temporarily: 14
thread: 14
tolerate: 14
turn: 14
useful: 14
xj: 14
zookeeper: 14
achieved: 13
add: 13
afs: 13
annual: 13
avg: 13
balance: 13
bound: 13
collaborative: 13
collect: 13
compile: 13
completely: 13
computation: 13
concurrent: 13
consisting: 13
constraints: 13
decreases: 13
depends: 13
determine: 13
determined: 13
did: 13
digests: 13
discarded: 13
dominant: 13
dynamically: 13
embedded: 13
epidemic: 13
exception: 13
eyal: 13
face: 13
far: 13
field: 13
free: 13
frequently: 13
fundamental: 13
generating: 13
gives: 13
grained: 13
growth: 13
his: 13
hit: 13
instances: 13
intended: 13
interactive: 13
interval: 13
intervals: 13
introduction: 13
join: 13
lack: 13
location: 13
magnitude: 13
measure: 13
mentioned: 13
missed: 13
modeless: 13
nfm: 13
normal: 13
notice: 13
ntfs: 13
overview: 13
paradigm: 13
positive: 13
proportional: 13
provided: 13
public: 13
radient: 13
receipt: 13
registers: 13
relevant: 13
remains: 13
researchers: 13
robust: 13
rtt: 13
semantics: 13
setup: 13
shares: 13
situations: 13
special: 13
static: 13
structures: 13
subscribe: 13
thousand: 13
tool: 13
track: 13
trade: 13
tree: 13
unbounded: 13
written: 13
aborted: 12
academic: 12
acceptable: 12
account: 12
accurate: 12
balakrishnan: 12
base: 12
below: 12
ca: 12
capable: 12
caused: 12
challenges: 12
classes: 12
conclude: 12
copies: 12
creating: 12
cumulative: 12
date: 12
decentralized: 12
decide: 12
dedicated: 12
definition: 12
delayed: 12
despite: 12
efficiency: 12
element: 12
enterprise: 12
facts: 12
fairly: 12
footprint: 12
generally: 12
half: 12
hashcash: 12
html: 12
ing: 12
interactions: 12
introduced: 12
iv: 12
ix: 12
jan: 12
java: 12
keep: 12
leads: 12
lfs: 12
li: 12
limitations: 12
locking: 12
maintained: 12
near: 12
obtained: 12
opportunity: 12
oracle: 12
ordering: 12
orders: 12
otherwise: 12
overlap: 12
particularly: 12
past: 12
practical: 12
primary: 12
purposes: 12
push: 12
reason: 12
recently: 12
redundant: 12
rescue: 12
review: 12
roles: 12
roughly: 12
sort: 12
specify: 12
spikes: 12
stack: 12
subset: 12
taking: 12
technique: 12
ten: 12
tms: 12
unif: 12
whenever: 12
you: 12
achieving: 11
acknowledgments: 11
activity: 11
advance: 11
aggregated: 11
argue: 11
authors: 11
automated: 11
basis: 11
begin: 11
callback: 11
complex: 11
converge: 11
crash: 11
deal: 11
deployed: 11
detail: 11
details: 11
detecting: 11
discussion: 11
energy: 11
ensures: 11
equivalent: 11
evict: 11
fa: 11
fee: 11
fetches: 11
fetching: 11
finds: 11
flexible: 11
focused: 11
heterogeneous: 11
hot: 11
hundreds: 11
identifiers: 11
illustrates: 11
implementing: 11
improvements: 11
incorporates: 11
increasingly: 11
indicate: 11
insufficient: 11
interact: 11
introduce: 11
involved: 11
ithaca: 11
largest: 11
layout: 11
linearly: 11
logged: 11
maintenance: 11
measurement: 11
metadata: 11
modal: 11
moving: 11
name: 11
orkut: 11
osdi: 11
pair: 11
parameter: 11
partitioned: 11
prefetches: 11
privacy: 11
processed: 11
prove: 11
providers: 11
randomly: 11
readers: 11
realistic: 11
recovers: 11
replace: 11
replicas: 11
requiring: 11
responsible: 11
retransmission: 11
role: 11
routine: 11
sample: 11
scheduling: 11
sensitive: 11
sep: 11
separate: 11
serve: 11
simplicity: 11
stock: 11
strictly: 11
subsequent: 11
supporting: 11
supports: 11
true: 11
trusted: 11
try: 11
unlikely: 11
unshared: 11
valid: 11
ve: 11
white: 11
whose: 11
xml: 11
accuracy: 10
ack: 10
additionally: 10
along: 10
appear: 10
arg: 10
assumption: 10
asynchronously: 10
becoming: 10
bitcoins: 10
bottleneck: 10
cc: 10
cdn: 10
check: 10
checks: 10
compares: 10
conflict: 10
constructed: 10
continuous: 10
dec: 10
decision: 10
decisions: 10
degenerate: 10
degree: 10
depend: 10
desired: 10
detailed: 10
discussed: 10
distinguish: 10
distributes: 10
effectively: 10
efforts: 10
elements: 10
enable: 10
enhancing: 10
epidemics: 10
especially: 10
evaluated: 10
eventual: 10
examine: 10
expensive: 10
experienced: 10
fairness: 10
false: 10
final: 10
fine: 10
forms: 10
give: 10
gracefully: 10
ideal: 10
improving: 10
infiltrates: 10
injected: 10
ipc: 10
isn: 10
journal: 10
language: 10
leverage: 10
map: 10
maps: 10
mesh: 10
methods: 10
microbenchmarks: 10
minutes: 10
miss: 10
networked: 10
nevertheless: 10
news: 10
novel: 10
overlapping: 10
paxos: 10
pending: 10
possibility: 10
presented: 10
presents: 10
proceed: 10
pushing: 10
rapid: 10
really: 10
recall: 10
remainder: 10
reported: 10
reports: 10
representing: 10
rest: 10
return: 10
rise: 10
robbert: 10
router: 10
routes: 10
routing: 10
runtime: 10
sampling: 10
scales: 10
segment: 10
situation: 10
studies: 10
subject: 10
success: 10
synchrony: 10
tail: 10
team: 10
technical: 10
tests: 10
theorem: 10
think: 10
thresholds: 10
throughout: 10
tion: 10
transparent: 10
unlike: 10
unstable: 10
usually: 10
utility: 10
variant: 10
visible: 10
volume: 10
widely: 10
zone: 10
achieves: 9
advantages: 9
alarm: 9
allowed: 9
appliances: 9
apply: 9
assigned: 9
assigns: 9
assumed: 9
attackers: 9
august: 9
behave: 9
beneficial: 9
break: 9
causing: 9
central: 9
changed: 9
co: 9
commercial: 9
companies: 9
comparing: 9
competing: 9
compute: 9
computers: 9
confidence: 9
connections: 9
continue: 9
curves: 9
daily: 9
default: 9
degradation: 9
depending: 9
deterministic: 9
developing: 9
dirty: 9
discards: 9
disconnected: 9
domain: 9
ec: 9
ee: 9
efficiently: 9
eliminate: 9
en: 9
entirely: 9
execute: 9
explicit: 9
explored: 9
expression: 9
fails: 9
fashion: 9
fd: 9
force: 9
forming: 9
forwarding: 9
frequency: 9
fully: 9
functions: 9
grant: 9
grow: 9
gw: 9
hide: 9
hierarchy: 9
hold: 9
id: 9
ideally: 9
identifier: 9
importance: 9
incentive: 9
inexpensive: 9
infocom: 9
initially: 9
intel: 9
investigate: 9
iperf: 9
iterative: 9
john: 9
kept: 9
knows: 9
leaving: 9
loads: 9
lose: 9
lossless: 9
lowest: 9
maximize: 9
media: 9
merlin: 9
middle: 9
middleware: 9
minor: 9
modifications: 9
modify: 9
modules: 9
nsdi: 9
owner: 9
pattern: 9
permutation: 9
places: 9
plan: 9
profitable: 9
programmer: 9
prone: 9
proportion: 9
quite: 9
reached: 9
reading: 9
records: 9
reflect: 9
respect: 9
retry: 9
ricochet: 9
rings: 9
risk: 9
rounds: 9
rw: 9
sampled: 9
sd: 9
sec: 9
segments: 9
selected: 9
self: 9
session: 9
shall: 9
showing: 9
sigmod: 9
sosp: 9
specialized: 9
steps: 9
susceptible: 9
terms: 9
threads: 9
tolerant: 9
topology: 9
transfers: 9
transformation: 9
transitions: 9
transmitting: 9
trip: 9
ttl: 9
unacknowledged: 9
unless: 9
upcall: 9
vi: 9
viii: 9
want: 9
werner: 9
academia: 8
accordingly: 8
activities: 8
adds: 8
advantage: 8
affect: 8
affects: 8
afrl: 8
aggregates: 8
allocation: 8
amounts: 8
api: 8
arbitrary: 8
arrays: 8
arxiv: 8
aspects: 8
attributes: 8
auditor: 8
automatic: 8
away: 8
backup: 8
behind: 8
beyond: 8
breaks: 8
buffered: 8
byte: 8
cbcb: 8
challenge: 8
charge: 8
checking: 8
clock: 8
collected: 8
combine: 8
come: 8
competition: 8
compromised: 8
concurrently: 8
confirm: 8
congested: 8
connecting: 8
consecutive: 8
contributing: 8
coordinator: 8
corresponds: 8
creates: 8
currencies: 8
dark: 8
david: 8
de: 8
degrades: 8
densities: 8
deploy: 8
deployment: 8
detectors: 8
differs: 8
dogecoin: 8
drag: 8
driven: 8
earns: 8
eligius: 8
employed: 8
engage: 8
equations: 8
equipment: 8
essentially: 8
ever: 8
exact: 8
executed: 8
exist: 8
extensions: 8
external: 8
extreme: 8
favor: 8
filesystem: 8
gib: 8
greatly: 8
header: 8
histograms: 8
honestly: 8
ideas: 8
improvement: 8
input: 8
insight: 8
interaction: 8
jgroups: 8
largely: 8
leader: 8
leading: 8
leave: 8
lemma: 8
light: 8
limits: 8
litecoin: 8
look: 8
mashups: 8
masks: 8
massive: 8
match: 8
max: 8
mc: 8
measuring: 8
method: 8
minimize: 8
misbehaving: 8
mixed: 8
modeled: 8
models: 8
modification: 8
move: 8
neighbor: 8
nominal: 8
nor: 8
notification: 8
notifications: 8
oct: 8
offers: 8
ordered: 8
papers: 8
participation: 8
payoff: 8
perhaps: 8
perturbed: 8
placed: 8
played: 8
plot: 8
portion: 8
prioritised: 8
purpose: 8
put: 8
react: 8
recovering: 8
refer: 8
refrain: 8
replaced: 8
reservation: 8
reservations: 8
retransmissions: 8
returned: 8
reward: 8
robin: 8
sdn: 8
sections: 8
senders: 8
september: 8
series: 8
serves: 8
similarly: 8
simulate: 8
sink: 8
sm: 8
solve: 8
sometimes: 8
span: 8
specification: 8
specified: 8
stacks: 8
staggered: 8
stepwise: 8
strict: 8
subsequently: 8
substituting: 8
suitable: 8
surprisingly: 8
timer: 8
turns: 8
twice: 8
unusable: 8
verify: 8
views: 8
wang: 8
weak: 8
weather: 8
weekly: 8
wiki: 8
ws: 8
xc: 8
aborting: 7
abstraction: 7
acceptors: 7
acknowledged: 7
air: 7
apache: 7
applying: 7
architectural: 7
arises: 7
array: 7
attractive: 7
belongs: 7
big: 7
broadcast: 7
bsd: 7
byzantine: 7
calculate: 7
card: 7
causes: 7
cb: 7
characteristics: 7
cisco: 7
claim: 7
cleaning: 7
cleanup: 7
clearly: 7
closer: 7
collapse: 7
communities: 7
completion: 7
complexity: 7
concept: 7
conflicting: 7
connection: 7
considering: 7
consistently: 7
construct: 7
contemporary: 7
contributions: 7
cooperative: 7
counter: 7
creation: 7
dashed: 7
december: 7
decoupling: 7
degraded: 7
delaying: 7
demers: 7
deploying: 7
dept: 7
derived: 7
designs: 7
deter: 7
determining: 7
display: 7
disrupt: 7
doesn: 7
doing: 7
dolev: 7
downstream: 7
easier: 7
elapsed: 7
electronic: 7
eliminated: 7
eliminates: 7
employs: 7
empty: 7
emulab: 7
enabling: 7
equally: 7
everything: 7
exchanges: 7
experiences: 7
exploit: 7
exponential: 7
extend: 7
feature: 7
feedback: 7
feeds: 7
fires: 7
fit: 7
follow: 7
furthermore: 7
gaining: 7
gray: 7
guarantee: 7
handles: 7
hour: 7
huge: 7
ignored: 7
image: 7
implementations: 7
importantly: 7
incoherent: 7
incorporate: 7
inferior: 7
introduces: 7
inventory: 7
isis: 7
isolation: 7
january: 7
joseph: 7
keys: 7
latest: 7
lbfs: 7
located: 7
locations: 7
ma: 7
mahesh: 7
mapping: 7
mica: 7
mines: 7
ml: 7
mod: 7
modeling: 7
modifying: 7
motivation: 7
multicasts: 7
nature: 7
negligible: 7
nothing: 7
nsf: 7
oblivious: 7
observation: 7
obvious: 7
october: 7
operator: 7
optimistic: 7
overloaded: 7
partitions: 7
percentile: 7
persistent: 7
plus: 7
poorly: 7
population: 7
pre: 7
prefer: 7
press: 7
prime: 7
programs: 7
propagated: 7
prototype: 7
publishing: 7
rack: 7
rarely: 7
rc: 7
reaches: 7
record: 7
reflects: 7
regarding: 7
register: 7
regularly: 7
relaying: 7
rely: 7
repeated: 7
represent: 7
represented: 7
requesting: 7
resistant: 7
restart: 7
retailer: 7
retrieve: 7
rich: 7
route: 7
routers: 7
san: 7
savings: 7
scaling: 7
seamlessly: 7
seek: 7
sharply: 7
she: 7
simplify: 7
simulations: 7
simulator: 7
sites: 7
socket: 7
sockets: 7
springer: 7
stop: 7
storing: 7
subservices: 7
substantially: 7
successful: 7
timeout: 7
tradeoff: 7
trans: 7
transition: 7
transmit: 7
treat: 7
treated: 7
trees: 7
trust: 7
twenty: 7
u: 7
ubiquitous: 7
unaware: 7
unchanged: 7
useless: 7
utilization: 7
validation: 7
variation: 7
vendor: 7
vendors: 7
versus: 7
vii: 7
violating: 7
wan: 7
year: 7
yield: 7
yields: 7
yu: 7
accommodate: 6
achievable: 6
acknowledgement: 6
act: 6
acting: 6
addressed: 6
addresses: 6
adjustment: 6
administrators: 6
affected: 6
afosr: 6
agreement: 6
alternatives: 6
analyzed: 6
apparently: 6
appropriately: 6
argument: 6
arrives: 6
assumptions: 6
atomic: 6
averages: 6
avoids: 6
bars: 6
begins: 6
berkeley: 6
bonneau: 6
bottom: 6
boundaries: 6
broadly: 6
bullet: 6
california: 6
calls: 6
catch: 6
checkpoint: 6
checksum: 6
chen: 6
closely: 6
clouds: 6
clr: 6
coherent: 6
combination: 6
combines: 6
comes: 6
command: 6
comprised: 6
comput: 6
concave: 6
conducted: 6
conjunction: 6
consensus: 6
conservative: 6
considerable: 6
contain: 6
controlled: 6
coordinate: 6
copying: 6
corporation: 6
costly: 6
coupled: 6
crashed: 6
cross: 6
curve: 6
customize: 6
darpa: 6
dates: 6
db: 6
debian: 6
denotes: 6
dependent: 6
deployments: 6
description: 6
detector: 6
determines: 6
develop: 6
digest: 6
discusfish: 6
disjoint: 6
disseminate: 6
divides: 6
document: 6
draw: 6
druschel: 6
durability: 6
earth: 6
ed: 6
effort: 6
egress: 6
eliminating: 6
email: 6
erasure: 6
established: 6
expressions: 6
facebook: 6
feasibility: 6
feed: 6
fifth: 6
fill: 6
focuses: 6
forced: 6
forks: 6
former: 6
foundation: 6
frame: 6
france: 6
gbps: 6
generic: 6
hashing: 6
heartbeat: 6
hidden: 6
histories: 6
hop: 6
huang: 6
imposed: 6
improved: 6
inc: 6
indicates: 6
industry: 6
ingress: 6
intensive: 6
intercepted: 6
intermediate: 6
issued: 6
issuing: 6
kncminer: 6
krzysztof: 6
lacking: 6
lamport: 6
lan: 6
lans: 6
lcm: 6
ledger: 6
loaded: 6
locally: 6
logical: 6
lt: 6
luu: 6
manage: 6
master: 6
matching: 6
maxx: 6
mean: 6
measured: 6
min: 6
mission: 6
modifies: 6
moment: 6
moves: 6
mp: 6
multicasting: 6
my: 6
naturally: 6
nd: 6
nearly: 6
necessarily: 6
noble: 6
nonce: 6
normalizes: 6
notion: 6
numbered: 6
numerical: 6
numerous: 6
occurring: 6
older: 6
operators: 6
optimized: 6
oscillatory: 6
ostrowski: 6
outlined: 6
outperforms: 6
output: 6
overload: 6
pareto: 6
parties: 6
passive: 6
pdf: 6
perfectly: 6
permit: 6
perspective: 6
phase: 6
play: 6
pooled: 6
possibly: 6
powerful: 6
predict: 6
prefix: 6
price: 6
primarily: 6
procedure: 6
produced: 6
publicly: 6
publisher: 6
pulls: 6
punish: 6
questions: 6
queuing: 6
qwest: 6
reachable: 6
red: 6
reduction: 6
redundancy: 6
reject: 6
repeatedly: 6
replay: 6
replicate: 6
resource: 6
resulted: 6
returns: 6
reveals: 6
rewards: 6
rig: 6
ring: 6
rj: 6
rules: 6
samples: 6
satyanarayanan: 6
say: 6
seattle: 6
seems: 6
select: 6
sensitivity: 6
serialized: 6
six: 6
slowly: 6
snapshot: 6
solving: 6
somewhat: 6
sorts: 6
standardized: 6
states: 6
straightforward: 6
stratum: 6
suggested: 6
summarize: 6
sun: 6
super: 6
supplies: 6
switzerland: 6
synchronization: 6
targeted: 6
tat: 6
thank: 6
theory: 6
timeouts: 6
tit: 6
toolkit: 6
tracking: 6
transmits: 6
trigger: 6
trying: 6
txnid: 6
ultimately: 6
understand: 6
unfortunately: 6
unreliable: 6
usability: 6
usable: 6
validate: 6
variability: 6
variations: 6
vast: 6
vector: 6
vldb: 6
welsh: 6
why: 6
withheld: 6
won: 6
workers: 6
worse: 6
xxx: 6
yahoo: 6
zhang: 6
zhu: 6
ability: 5
absence: 5
absolute: 5
acknowledgements: 5
acknowledgment: 5
acl: 5
adapting: 5
adjusting: 5
ago: 5
agree: 5
ahead: 5
allocated: 5
anyone: 5
append: 5
approximate: 5
arbitrarily: 5
arguably: 5
arrival: 5
assuming: 5
atkin: 5
atomicity: 5
attempts: 5
author: 5
avoiding: 5
award: 5
backed: 5
band: 5
behalf: 5
behaves: 5
belong: 5
bit: 5
bits: 5
blocking: 5
brevity: 5
brewer: 5
broken: 5
broker: 5
buildings: 5
bus: 5
calculated: 5
calculates: 5
capture: 5
carry: 5
catches: 5
caught: 5
chains: 5
cheap: 5
cheriton: 5
classified: 5
cloned: 5
collapses: 5
comments: 5
communicate: 5
communicates: 5
compose: 5
concern: 5
concerns: 5
consequence: 5
considerations: 5
constitutes: 5
constrained: 5
consume: 5
consuming: 5
contact: 5
continuously: 5
coolstreaming: 5
cope: 5
count: 5
counts: 5
crashes: 5
credentials: 5
crossing: 5
customers: 5
danny: 5
datagram: 5
day: 5
dealing: 5
defense: 5
demands: 5
demonstrated: 5
denial: 5
denoted: 5
depict: 5
describing: 5
df: 5
dialog: 5
direction: 5
division: 5
dramatic: 5
dsn: 5
edition: 5
eferences: 5
eight: 5
elaborate: 5
elated: 5
embedding: 5
emerging: 5
employing: 5
encourage: 5
encryption: 5
enforce: 5
ephemeral: 5
estimated: 5
ethernet: 5
exceed: 5
except: 5
exhibit: 5
explain: 5
explicitly: 5
exploiting: 5
exploring: 5
expressed: 5
falls: 5
faults: 5
faulty: 5
filtering: 5
firing: 5
flexibility: 5
forces: 5
forwarded: 5
frames: 5
freebsd: 5
frequent: 5
gap: 5
generality: 5
geo: 5
geographical: 5
gigabits: 5
gribble: 5
grid: 5
ground: 5
gu: 5
hacker: 5
health: 5
hierarchical: 5
highperformance: 5
hints: 5
hooks: 5
human: 5
identification: 5
illustrate: 5
imagine: 5
implicit: 5
implies: 5
inaccurate: 5
incorrect: 5
incrementally: 5
incurs: 5
independently: 5
informatik: 5
informatique: 5
innovation: 5
instantly: 5
integrating: 5
interesting: 5
interference: 5
internal: 5
interoperability: 5
invalidate: 5
investigated: 5
investigator: 5
iptv: 5
isps: 5
ittay: 5
johnson: 5
joining: 5
joins: 5
katz: 5
kleinberg: 5
lakshmi: 5
languages: 5
layouts: 5
learn: 5
leases: 5
lengths: 5
lightweight: 5
linking: 5
liu: 5
locality: 5
locks: 5
logic: 5
looking: 5
lossy: 5
mar: 5
marketing: 5
mask: 5
messaging: 5
metrics: 5
minibrowsers: 5
minority: 5
monitors: 5
monthly: 5
moved: 5
mutual: 5
national: 5
normally: 5
ntroduction: 5
observations: 5
obtains: 5
occasional: 5
occurred: 5
offered: 5
omit: 5
omitted: 5
onclusion: 5
onon: 5
optimization: 5
optimizations: 5
optimizes: 5
organization: 5
organizations: 5
organized: 5
originally: 5
orthogonal: 5
outside: 5
overcome: 5
pairs: 5
partially: 5
passed: 5
pause: 5
pay: 5
pays: 5
peerto: 5
people: 5
percentages: 5
permitting: 5
personal: 5
pf: 5
phenomenon: 5
placement: 5
plots: 5
poison: 5
positives: 5
precisely: 5
predictor: 5
predictors: 5
probabilistic: 5
proceeds: 5
progresses: 5
property: 5
proprietary: 5
protected: 5
proved: 5
punished: 5
quick: 5
raise: 5
rare: 5
raw: 5
rd: 5
reaching: 5
regardless: 5
release: 5
reliance: 5
remaining: 5
remove: 5
repairs: 5
repeat: 5
requested: 5
requirement: 5
resilience: 5
resolve: 5
respects: 5
responsiveness: 5
restrictions: 5
reveal: 5
rizzo: 5
road: 5
robustness: 5
satisfactory: 5
satisfied: 5
save: 5
saving: 5
scheduled: 5
schneider: 5
seem: 5
sees: 5
selecting: 5
sensors: 5
separated: 5
separately: 5
sequenced: 5
serializable: 5
sessions: 5
shard: 5
shards: 5
signal: 5
simulated: 5
sized: 5
slack: 5
slower: 5
sophisticated: 5
soule: 5
speculative: 5
sprint: 5
stated: 5
stay: 5
studied: 5
submit: 5
substantial: 5
subsystems: 5
suffer: 5
sum: 5
summarized: 5
suspicion: 5
switched: 5
switches: 5
tech: 5
tell: 5
temporary: 5
texture: 5
thinking: 5
tightly: 5
timely: 5
timestamps: 5
tocs: 5
topologies: 5
tracks: 5
transform: 5
transformations: 5
trap: 5
treating: 5
trend: 5
trends: 5
triggers: 5
tune: 5
tuning: 5
turned: 5
unable: 5
unexpected: 5
unit: 5
unpredictable: 5
untrusted: 5
updating: 5
upper: 5
ut: 5
utilisation: 5
verifying: 5
viewed: 5
volatile: 5
vs: 5
waiting: 5
walk: 5
wall: 5
wants: 5
win: 5
wired: 5
writers: 5
ycsb: 5
yx: 5
ab: 4
abbadi: 4
ac: 4
accepted: 4
acks: 4
action: 4
actions: 4
adopted: 4
advanced: 4
advances: 4
agrawal: 4
alone: 4
alongside: 4
alternate: 4
alvisi: 4
amir: 4
amortizable: 4
analogous: 4
andrew: 4
answer: 4
antpool: 4
applicable: 4
approximated: 4
april: 4
archive: 4
arrow: 4
aspect: 4
assign: 4
assumes: 4
athey: 4
awkward: 4
bahack: 4
ballots: 4
banking: 4
behaviour: 4
benchmark: 4
bernstein: 4
biersack: 4
bifurcations: 4
bitcointalk: 4
blade: 4
blast: 4
blend: 4
blocked: 4
blogspot: 4
border: 4
boxes: 4
brief: 4
briefly: 4
broadcasts: 4
broader: 4
bulk: 4
burstier: 4
calculator: 4
callbacks: 4
caller: 4
capitalization: 4
captures: 4
carefully: 4
certainly: 4
charts: 4
chat: 4
city: 4
clean: 4
clones: 4
closes: 4
cms: 4
collecting: 4
collector: 4
combining: 4
coming: 4
comparable: 4
compensated: 4
compiles: 4
completed: 4
complicated: 4
componentized: 4
composition: 4
comprehensive: 4
compromise: 4
conduct: 4
confirms: 4
consequences: 4
consist: 4
contained: 4
continued: 4
converges: 4
cooperation: 4
correlated: 4
correlation: 4
courtois: 4
crucial: 4
cryptography: 4
cutting: 4
cycle: 4
danger: 4
das: 4
debugging: 4
decades: 4
decided: 4
declining: 4
deep: 4
deferred: 4
defines: 4
demonstrates: 4
desktop: 4
devastating: 4
di: 4
differences: 4
differentiate: 4
differently: 4
directed: 4
directions: 4
directories: 4
disaster: 4
discovery: 4
discussions: 4
disloyal: 4
disrupted: 4
disruption: 4
distant: 4
distribute: 4
distributions: 4
double: 4
ease: 4
ebay: 4
economic: 4
editor: 4
educause: 4
elsewhere: 4
emin: 4
emulate: 4
encoder: 4
encodes: 4
endhosts: 4
enforcing: 4
engages: 4
engineer: 4
enhanced: 4
enormous: 4
enter: 4
envelope: 4
epi: 4
eprint: 4
esb: 4
evenly: 4
evicting: 4
evidence: 4
evil: 4
ex: 4
examines: 4
exchanged: 4
exclusive: 4
executing: 4
existence: 4
export: 4
exposed: 4
extensive: 4
faber: 4
faced: 4
familiar: 4
february: 4
filter: 4
firewalls: 4
five: 4
fixing: 4
flowing: 4
flush: 4
flushes: 4
focusing: 4
followed: 4
formula: 4
foster: 4
fourth: 4
fragmentation: 4
francis: 4
francisco: 4
freedman: 4
friendly: 4
gain: 4
games: 4
gateways: 4
gathered: 4
gets: 4
globally: 4
goes: 4
going: 4
graceful: 4
grants: 4
grateful: 4
grossklags: 4
hackingdistributed: 4
hakim: 4
heartbeats: 4
heavily: 4
helps: 4
hint: 4
holds: 4
home: 4
honeypot: 4
hope: 4
horus: 4
hweather: 4
identified: 4
identifying: 4
identity: 4
ids: 4
ignore: 4
images: 4
impacted: 4
impossible: 4
inaccessible: 4
incorporating: 4
incurred: 4
incurring: 4
inform: 4
initiated: 4
initiative: 4
inquiry: 4
integral: 4
integrate: 4
intelligent: 4
intend: 4
interacts: 4
interrupted: 4
intervening: 4
intrinsically: 4
introducing: 4
invalidated: 4
invalidating: 4
isbn: 4
javascript: 4
jboss: 4
jelasity: 4
joint: 4
jose: 4
july: 4
jumbo: 4
jxta: 4
kaashoek: 4
keeping: 4
keidar: 4
kermarrec: 4
kj: 4
korn: 4
lacks: 4
lakshman: 4
laszka: 4
leaders: 4
learning: 4
leaves: 4
letting: 4
leveraging: 4
libraries: 4
lies: 4
listed: 4
lived: 4
ll: 4
logsim: 4
longdistance: 4
looked: 4
lru: 4
maid: 4
malfunctioning: 4
managing: 4
marked: 4
matched: 4
matrix: 4
maximizes: 4
measures: 4
merely: 4
methodology: 4
miles: 4
military: 4
miller: 4
mind: 4
minimal: 4
minted: 4
minute: 4
misconfigured: 4
misses: 4
mix: 4
mixture: 4
mobility: 4
modulating: 4
monitor: 4
monopoly: 4
moore: 4
msg: 4
mtus: 4
naive: 4
nak: 4
namecoin: 4
narrow: 4
netfilter: 4
normalized: 4
notable: 4
notify: 4
numerically: 4
obstacles: 4
obtaining: 4
offering: 4
ools: 4
operates: 4
optimum: 4
organofcorti: 4
ork: 4
outstanding: 4
owners: 4
ownership: 4
packages: 4
parameterized: 4
participate: 4
parts: 4
patient: 4
paul: 4
payments: 4
payout: 4
payouts: 4
peak: 4
penalty: 4
peps: 4
periodic: 4
permacoin: 4
permutations: 4
person: 4
perspectives: 4
pfldnet: 4
phenomena: 4
php: 4
pi: 4
picked: 4
pictures: 4
placing: 4
player: 4
plotting: 4
podc: 4
poll: 4
polling: 4
positions: 4
practicality: 4
predicted: 4
preferred: 4
preprint: 4
pressure: 4
prevents: 4
pricing: 4
primitives: 4
principle: 4
probabilities: 4
probably: 4
prominent: 4
promising: 4
protect: 4
provisioned: 4
provisioning: 4
pub: 4
publication: 4
pulled: 4
purely: 4
qi: 4
qp: 4
quantities: 4
quantum: 4
querying: 4
readset: 4
reality: 4
realize: 4
reasonable: 4
reference: 4
reflected: 4
regional: 4
rejoin: 4
relation: 4
relations: 4
reliably: 4
removed: 4
reno: 4
repairing: 4
replacement: 4
replicating: 4
repo: 4
reserved: 4
residing: 4
resilient: 4
resolution: 4
resolved: 4
responding: 4
responses: 4
retailers: 4
retransmit: 4
rev: 4
revoke: 4
rigs: 4
rk: 4
robert: 4
root: 4
rosenfeld: 4
routed: 4
rover: 4
rowstron: 4
rule: 4
safety: 4
saturate: 4
saw: 4
scan: 4
secondary: 4
secret: 4
secure: 4
secured: 4
seeks: 4
selective: 4
selfish: 4
separates: 4
sequences: 4
sequentially: 4
sha: 4
shasha: 4
shenker: 4
shift: 4
shut: 4
silver: 4
situational: 4
sixteenth: 4
smalltalk: 4
smart: 4
smr: 4
sold: 4
spanning: 4
spun: 4
srm: 4
standardization: 4
statistically: 4
steadily: 4
steady: 4
stress: 4
stronger: 4
strongly: 4
students: 4
subjected: 4
subsection: 4
successes: 4
suffers: 4
sums: 4
suspected: 4
symmetry: 4
synchronized: 4
tackle: 4
tailored: 4
technological: 4
tens: 4
terminology: 4
terrain: 4
terry: 4
tested: 4
theoretic: 4
things: 4
threaded: 4
took: 4
tornado: 4
touched: 4
towsley: 4
traced: 4
tradeoffs: 4
trading: 4
translate: 4
travel: 4
treats: 4
tremendous: 4
trial: 4
truly: 4
tuple: 4
understanding: 4
undesirable: 4
units: 4
unknown: 4
unusual: 4
upstream: 4
usd: 4
usual: 4
utilities: 4
vahdat: 4
valuable: 4
variable: 4
variants: 4
varies: 4
vfs: 4
viable: 4
vice: 4
visual: 4
von: 4
vulnerable: 4
waits: 4
walsh: 4
washington: 4
weakly: 4
weatherspoon: 4
weight: 4
wish: 4
withhold: 4
worked: 4
worst: 4
worth: 4
writeset: 4
wrong: 4
xk: 4
xkj: 4
yearly: 4
your: 4
abadi: 3
aborts: 3
accepting: 3
accepts: 3
accountable: 3
accumulated: 3
accusations: 3
acidrain: 3
acknowledge: 3
acquire: 3
actively: 3
adapts: 3
adequate: 3
adjust: 3
advancing: 3
advantageous: 3
advertisements: 3
afec: 3
affecting: 3
aggregating: 3
agnostic: 3
aguilera: 3
aimed: 3
aircraft: 3
alan: 3
albeit: 3
alberta: 3
album: 3
alert: 3
alerts: 3
alleviate: 3
amenable: 3
analytical: 3
analytically: 3
anomaly: 3
anything: 3
app: 3
apparent: 3
appears: 3
ar: 3
areas: 3
aren: 3
argued: 3
arising: 3
arla: 3
assertion: 3
assess: 3
assigning: 3
assignment: 3
association: 3
assure: 3
attribute: 3
auditable: 3
aug: 3
authorization: 3
avatars: 3
avoided: 3
backbone: 3
balancer: 3
baltimore: 3
banks: 3
bases: 3
basically: 3
batch: 3
bayou: 3
beginning: 3
bianchini: 3
black: 3
boards: 3
bone: 3
boston: 3
boures: 3
breaking: 3
bring: 3
browser: 3
builds: 3
busy: 3
calling: 3
cambridge: 3
camera: 3
cap: 3
care: 3
carries: 3
categories: 3
chandra: 3
characteristic: 3
checked: 3
children: 3
chronous: 3
chubby: 3
churn: 3
circumvent: 3
claims: 3
clement: 3
closing: 3
colleagues: 3
colorado: 3
column: 3
combinations: 3
commands: 3
commerce: 3
commonly: 3
commun: 3
communicating: 3
company: 3
compatible: 3
compete: 3
competitive: 3
compilers: 3
compiling: 3
completes: 3
composed: 3
compound: 3
comprises: 3
compulsory: 3
computational: 3
computed: 3
con: 3
conceived: 3
concentrate: 3
concluded: 3
conclusions: 3
condition: 3
configurable: 3
confirmed: 3
conservation: 3
conserve: 3
consideration: 3
constructing: 3
construction: 3
consumed: 3
consumes: 3
continues: 3
convinced: 3
convoy: 3
cooperate: 3
coordinates: 3
coordination: 3
copper: 3
corbett: 3
corfu: 3
corporate: 3
correcting: 3
correctness: 3
correlate: 3
criterion: 3
culler: 3
culprit: 3
cumulus: 3
curious: 3
custer: 3
custom: 3
customer: 3
customized: 3
cycles: 3
dahlin: 3
dangers: 3
davis: 3
ddos: 3
deadline: 3
deadlines: 3
deals: 3
decade: 3
deciding: 3
decker: 3
decreasing: 3
deering: 3
degrade: 3
demonstrating: 3
dependable: 3
designers: 3
desire: 3
determinism: 3
deviation: 3
dialogue: 3
differentiation: 3
dis: 3
discover: 3
discrepancy: 3
disruptions: 3
disruptive: 3
disseminated: 3
distributing: 3
dns: 3
documentation: 3
documents: 3
dollars: 3
dominated: 3
dos: 3
drawn: 3
driver: 3
dropping: 3
drpm: 3
dying: 3
economics: 3
eded: 3
edward: 3
eicken: 3
el: 3
elastic: 3
elastras: 3
election: 3
electrical: 3
elegant: 3
else: 3
emergence: 3
emotional: 3
empire: 3
encodings: 3
encouraging: 3
ending: 3
endpoint: 3
endto: 3
enhances: 3
ensuring: 3
enterprises: 3
entities: 3
entity: 3
essay: 3
essential: 3
evaluates: 3
evaluating: 3
eventing: 3
evident: 3
evolution: 3
evolved: 3
exacerbates: 3
excellent: 3
excluding: 3
executes: 3
expands: 3
expelled: 3
experimentally: 3
experimented: 3
expires: 3
explorer: 3
exposes: 3
extends: 3
extension: 3
extent: 3
extra: 3
extracted: 3
fascinating: 3
fewer: 3
fg: 3
fields: 3
fifteenth: 3
finite: 3
firm: 3
flash: 3
flat: 3
fledged: 3
flight: 3
folder: 3
folders: 3
forest: 3
format: 3
formation: 3
franklin: 3
freeloaders: 3
french: 3
friend: 3
fs: 3
ganesh: 3
gargamel: 3
gather: 3
geographically: 3
gf: 3
gfgf: 3
goals: 3
gossiped: 3
government: 3
gps: 3
graphically: 3
great: 3
greatest: 3
grids: 3
grossman: 3
gt: 3
guaranteed: 3
gui: 3
gummadi: 3
guo: 3
gurumurthi: 3
hall: 3
handlers: 3
handley: 3
happen: 3
happy: 3
hauser: 3
haven: 3
heap: 3
helland: 3
helping: 3
hibernator: 3
hierarchically: 3
hierarchies: 3
highspeed: 3
homogeneous: 3
howard: 3
hypothesis: 3
ibm: 3
icdcs: 3
ics: 3
ignores: 3
ignoring: 3
il: 3
immersed: 3
implicitly: 3
impose: 3
imposes: 3
incentives: 3
income: 3
incorporated: 3
incorrectly: 3
incremental: 3
incremented: 3
incur: 3
indiana: 3
indicating: 3
informed: 3
inherits: 3
initiate: 3
innovations: 3
inside: 3
insights: 3
instability: 3
instantaneous: 3
institute: 3
intent: 3
interacting: 3
intercept: 3
intercepting: 3
intercepts: 3
interconnect: 3
interconnected: 3
internals: 3
internetworks: 3
interplay: 3
intervene: 3
inversion: 3
irregular: 3
iteration: 3
jbosscache: 3
jim: 3
jitter: 3
keeps: 3
kenneth: 3
knowing: 3
kuenning: 3
landscape: 3
laptops: 3
larson: 3
late: 3
lateral: 3
lesson: 3
linkage: 3
linked: 3
lions: 3
lloyd: 3
logically: 3
london: 3
looks: 3
loop: 3
losing: 3
lot: 3
luby: 3
mainframe: 3
mainsoft: 3
mainwin: 3
malkhi: 3
malo: 3
managers: 3
marian: 3
markets: 3
marks: 3
mashed: 3
matter: 3
mazie: 3
mckusick: 3
meanwhile: 3
memcached: 3
michael: 3
microbenchmark: 3
mid: 3
migration: 3
minimizing: 3
mirror: 3
mitigate: 3
modular: 3
montresor: 3
motivated: 3
motivates: 3
mountain: 3
movies: 3
multithreaded: 3
nat: 3
native: 3
neighborhood: 3
ninja: 3
nonetheless: 3
noticeable: 3
null: 3
observing: 3
obstruction: 3
occasionally: 3
odel: 3
oneway: 3
onto: 3
opened: 3
operational: 3
opposed: 3
optimizing: 3
optionally: 3
organize: 3
orientation: 3
ousterhout: 3
outbound: 3
outdated: 3
overflows: 3
overlapped: 3
overloads: 3
overwhelmed: 3
pacific: 3
padhye: 3
pai: 3
paid: 3
parameterize: 3
participant: 3
passing: 3
paying: 3
payload: 3
pc: 3
pedone: 3
penalties: 3
perceived: 3
percent: 3
perez: 3
personalities: 3
personalization: 3
pervasive: 3
peter: 3
phone: 3
pinheiro: 3
pisa: 3
players: 3
pleisch: 3
poisson: 3
polls: 3
poor: 3
popek: 3
popularity: 3
portions: 3
pose: 3
posed: 3
positioning: 3
prabhakaran: 3
prebuilt: 3
precedence: 3
predominate: 3
preferentially: 3
prefetched: 3
presentation: 3
preserved: 3
president: 3
preventing: 3
principal: 3
probing: 3
processor: 3
produce: 3
productivity: 3
programmers: 3
promise: 3
propagate: 3
properly: 3
protection: 3
proves: 3
provider: 3
psockets: 3
publishers: 3
punishment: 3
purchases: 3
pushed: 3
putting: 3
qpqp: 3
quanta: 3
queueing: 3
queues: 3
raises: 3
ramp: 3
ranging: 3
rao: 3
raptor: 3
reacting: 3
readonly: 3
realizing: 3
reasoning: 3
recipient: 3
recognize: 3
recommendations: 3
reconstruct: 3
recoveries: 3
reflecting: 3
rejoins: 3
relate: 3
relates: 3
released: 3
releases: 3
remarkably: 3
removing: 3
replaces: 3
replacing: 3
replayed: 3
replica: 3
replies: 3
representation: 3
representative: 3
res: 3
reserve: 3
resort: 3
resp: 3
respective: 3
responds: 3
restarting: 3
restored: 3
restricted: 3
retain: 3
retransmitted: 3
retrieves: 3
revisions: 3
rewarding: 3
rfc: 3
rises: 3
risks: 3
safely: 3
saint: 3
satisfies: 3
satisfy: 3
satisfying: 3
scaled: 3
scene: 3
school: 3
scope: 3
script: 3
semantic: 3
sensor: 3
separation: 3
sequential: 3
served: 3
seventeenth: 3
seventh: 3
severe: 3
sharded: 3
shepherd: 3
showed: 3
sight: 3
simpler: 3
simplest: 3
sinfonia: 3
situated: 3
sixth: 3
sleep: 3
slight: 3
smallest: 3
soft: 3
song: 3
sorrosal: 3
sound: 3
spanner: 3
spare: 3
spatial: 3
specifications: 3
speculatively: 3
splitstream: 3
splitting: 3
sporadic: 3
spot: 3
sprite: 3
sr: 3
ssrn: 3
stability: 3
standardize: 3
started: 3
stays: 3
stems: 3
streamed: 3
struggled: 3
subnet: 3
subscriber: 3
substrate: 3
successive: 3
suddenly: 3
sufficiently: 3
suggests: 3
suite: 3
supplied: 3
surprising: 3
suspicions: 3
symbolic: 3
symbols: 3
synchronously: 3
sys: 3
syst: 3
tables: 3
tacc: 3
tagging: 3
talk: 3
tape: 3
targets: 3
taylor: 3
teams: 3
television: 3
tends: 3
terminating: 3
testing: 3
text: 3
thin: 3
thinks: 3
thirty: 3
thomson: 3
threat: 3
tight: 3
tiled: 3
tolerable: 3
ton: 3
tput: 3
tr: 3
traditionally: 3
train: 3
transferred: 3
transferring: 3
transmissions: 3
triggered: 3
triggering: 3
trivial: 3
trouble: 3
truncation: 3
tsunami: 3
tudor: 3
tudorm: 3
turning: 3
uk: 3
unacceptable: 3
unavailable: 3
unblocks: 3
uncommittable: 3
undetected: 3
unexpectedly: 3
unfairly: 3
unmanaged: 3
unperturbed: 3
unrelated: 3
utah: 3
utilize: 3
uwin: 3
validated: 3
valuation: 3
variables: 3
variance: 3
verified: 3
verlag: 3
viewing: 3
vigfusson: 3
visualization: 3
vt: 3
wake: 3
walli: 3
wanted: 3
warns: 3
watch: 3
wefel: 3
wei: 3
whatever: 3
widespread: 3
winner: 3
wisdom: 3
wobber: 3
worlds: 3
worry: 3
wv: 3
yxyx: 3
zero: 3
zhao: 3
zurich: 3
abandon: 2
abc: 2
abilene: 2
abstractions: 2
academics: 2
acceptance: 2
accessible: 2
accomplished: 2
accordance: 2
accounting: 2
accumulating: 2
accurately: 2
accusation: 2
accused: 2
acquisition: 2
adam: 2
addison: 2
addressing: 2
adjusted: 2
adjusts: 2
administrative: 2
adopt: 2
advancements: 2
advent: 2
adversary: 2
advertises: 2
advice: 2
advocated: 2
aegis: 2
affinity: 2
aforementioned: 2
age: 2
agents: 2
aggregator: 2
aggressive: 2
aict: 2
aim: 2
ajax: 2
akamai: 2
alaska: 2
alberto: 2
albums: 2
alive: 2
alleviating: 2
allocates: 2
allocating: 2
alloscomp: 2
alternatively: 2
altruistic: 2
ame: 2
amortizes: 2
amounting: 2
analyzes: 2
anchorage: 2
anderson: 2
andresen: 2
anomalies: 2
anonymity: 2
anonymously: 2
anti: 2
anticipate: 2
antony: 2
apart: 2
apis: 2
appealing: 2
appeared: 2
appends: 2
applicationindependent: 2
approximately: 2
approximation: 2
approximations: 2
apr: 2
archetypal: 2
argues: 2
arguing: 2
arithmetic: 2
arose: 2
arraystructured: 2
arrived: 2
art: 2
article: 2
articles: 2
asia: 2
asics: 2
asks: 2
asp: 2
aspx: 2
assists: 2
assurance: 2
astonishingly: 2
asynch: 2
atm: 2
attach: 2
attached: 2
attain: 2
attempted: 2
attempting: 2
attestation: 2
attract: 2
attraction: 2
attractiveness: 2
audio: 2
aumann: 2
authentication: 2
automate: 2
autonomous: 2
autotuning: 2
avoidance: 2
ba: 2
baa: 2
babaoglu: 2
bach: 2
backlashed: 2
bailey: 2
baker: 2
ban: 2
barb: 2
barr: 2
barrier: 2
bast: 2
basu: 2
began: 2
behaved: 2
behaving: 2
belonging: 2
benjamin: 2
berlin: 2
bernoulli: 2
besides: 2
bespoke: 2
bhargava: 2
bifurcation: 2
billion: 2
binary: 2
binomial: 2
birrell: 2
bitcoinfoundation: 2
bjornstad: 2
blank: 2
bloomberg: 2
blow: 2
blumenthal: 2
boils: 2
bolton: 2
bonus: 2
borders: 2
box: 2
boycott: 2
bridge: 2
brings: 2
brokerage: 2
bronson: 2
browsers: 2
bruijn: 2
btcguild: 2
btchine: 2
buf: 2
bulpin: 2
burden: 2
burstiness: 2
business: 2
businesses: 2
buterin: 2
butterfly: 2
bypass: 2
caja: 2
calculation: 2
calculations: 2
calvin: 2
came: 2
canada: 2
candidates: 2
canonical: 2
capabilities: 2
carey: 2
carolina: 2
carrera: 2
cash: 2
castro: 2
casual: 2
casually: 2
category: 2
cation: 2
cdns: 2
cease: 2
ceases: 2
ceived: 2
census: 2
centralization: 2
century: 2
certainty: 2
cfm: 2
challenging: 2
chance: 2
characterise: 2
cheaply: 2
checkout: 2
checksums: 2
chemical: 2
chicago: 2
chief: 2
china: 2
chowdhry: 2
cidr: 2
circle: 2
circulate: 2
circulates: 2
circumstances: 2
cited: 2
clark: 2
click: 2
cloudviews: 2
coarse: 2
coexist: 2
coherence: 2
cohort: 2
colarelli: 2
colocated: 2
color: 2
combat: 2
comer: 2
committing: 2
commons: 2
communicated: 2
compelled: 2
compensate: 2
compensation: 2
complement: 2
composing: 2
computes: 2
concentrated: 2
concert: 2
conclusive: 2
confident: 2
confined: 2
connect: 2
cons: 2
considerably: 2
considers: 2
constitute: 2
constraint: 2
contacted: 2
contexts: 2
contract: 2
contradicts: 2
controlling: 2
conversion: 2
converted: 2
converting: 2
cooling: 2
cooper: 2
cording: 2
corner: 2
correspond: 2
countermeasures: 2
counterpart: 2
covered: 2
covering: 2
cox: 2
cpus: 2
credited: 2
credits: 2
cripple: 2
cripples: 2
criticism: 2
croquet: 2
crypto: 2
cryptocurrencies: 2
cryptographic: 2
cryptology: 2
ct: 2
cubic: 2
cypherspace: 2
cz: 2
damage: 2
dan: 2
dangerous: 2
daniel: 2
dast: 2
datasets: 2
datta: 2
days: 2
dbms: 2
dce: 2
dd: 2
deadlocks: 2
dealbook: 2
deceased: 2
decodes: 2
deduce: 2
deeper: 2
deeply: 2
defanti: 2
defects: 2
defer: 2
degradations: 2
degrading: 2
deleting: 2
deliberately: 2
deliberation: 2
delivering: 2
delta: 2
demanding: 2
dentical: 2
dependence: 2
depicted: 2
depicts: 2
deplist: 2
deplistcurr: 2
derive: 2
descriptor: 2
designing: 2
deterministically: 2
deviate: 2
devise: 2
dfreedman: 2
didn: 2
differentiable: 2
diminish: 2
dinosaur: 2
diot: 2
disabled: 2
disadvantage: 2
disadvantages: 2
discount: 2
disincentivize: 2
disrupting: 2
disseminates: 2
dissertation: 2
distances: 2
distinction: 2
diverse: 2
divide: 2
dividing: 2
doi: 2
dok: 2
dominate: 2
dot: 2
dotbit: 2
doubt: 2
downloaded: 2
downloads: 2
downside: 2
drives: 2
driving: 2
dry: 2
ds: 2
dubbed: 2
dugan: 2
dumbbell: 2
duplex: 2
duplicating: 2
dutta: 2
eagerly: 2
earned: 2
earnings: 2
ebling: 2
echo: 2
ecoop: 2
ecosystem: 2
eigenvalue: 2
eighteenth: 2
einar: 2
einstein: 2
elmore: 2
embeddings: 2
emphasis: 2
empirical: 2
enables: 2
encapsulate: 2
encapsulated: 2
encoders: 2
encounter: 2
encountered: 2
encrypted: 2
endhost: 2
ends: 2
ensemble: 2
ent: 2
enters: 2
envision: 2
equate: 2
equilibria: 2
era: 2
ered: 2
esbs: 2
escriva: 2
esign: 2
establishing: 2
estimates: 2
ethereum: 2
ethereumwhitepaper: 2
ets: 2
european: 2
eurosys: 2
ev: 2
eva: 2
eve: 2
eventbased: 2
everyone: 2
eviction: 2
evictions: 2
evolve: 2
exabytes: 2
exceeds: 2
exceptionally: 2
excessively: 2
executions: 2
exerted: 2
exerting: 2
exhibits: 2
expectation: 2
expectations: 2
expedite: 2
explains: 2
explores: 2
exponentially: 2
exports: 2
express: 2
expurging: 2
extensibility: 2
extremes: 2
eyes: 2
facilitate: 2
facto: 2
fair: 2
fall: 2
falling: 2
farms: 2
faulttolerance: 2
featuring: 2
fekete: 2
felser: 2
felten: 2
feng: 2
ferguson: 2
fetched: 2
fills: 2
finer: 2
finished: 2
finishes: 2
fired: 2
firewalling: 2
firoiu: 2
fits: 2
fix: 2
fl: 2
flag: 2
flexibly: 2
fluctuations: 2
fluid: 2
flushed: 2
fold: 2
forbes: 2
forcing: 2
forgo: 2
formats: 2
formulae: 2
forrestv: 2
forth: 2
foundations: 2
fox: 2
fragment: 2
fragments: 2
fraleigh: 2
frameworks: 2
fred: 2
fresh: 2
friction: 2
friedman: 2
friendliness: 2
frobenius: 2
fundamentally: 2
funded: 2
funds: 2
furman: 2
gained: 2
gaps: 2
garbled: 2
gateway: 2
gehrke: 2
generalize: 2
generations: 2
genesis: 2
geometric: 2
ghz: 2
gibbs: 2
gibson: 2
gigabyte: 2
github: 2
glick: 2
globalcrossing: 2
globe: 2
gossiper: 2
gossips: 2
gotten: 2
gr: 2
gradient: 2
gradually: 2
granted: 2
grapevine: 2
grasp: 2
greene: 2
griner: 2
guerraoui: 2
guesses: 2
guessing: 2
gupta: 2
guruprasad: 2
habel: 2
hackers: 2
halfway: 2
halted: 2
handful: 2
hands: 2
happens: 2
harder: 2
harley: 2
harm: 2
hashrate: 2
headers: 2
healthy: 2
heidelberg: 2
height: 2
held: 2
helpful: 2
hereinafter: 2
heterogenous: 2
hey: 2
hibler: 2
hiccups: 2
hides: 2
highlight: 2
highvalue: 2
hinder: 2
histogram: 2
hits: 2
hoarding: 2
hobor: 2
holy: 2
homepage: 2
honesty: 2
honeyman: 2
hops: 2
hotcloud: 2
huitema: 2
hundred: 2
hungry: 2
hurdle: 2
hurwitz: 2
huston: 2
iacr: 2
ic: 2
iciw: 2
icmp: 2
identities: 2
idit: 2
ie: 2
ifip: 2
ih: 2
ij: 2
ill: 2
illinois: 2
im: 2
imagined: 2
immaterial: 2
immediate: 2
immersion: 2
imperatives: 2
imperfect: 2
imply: 2
imposing: 2
impractical: 2
impulse: 2
incorporation: 2
indices: 2
indirection: 2
inefficiency: 2
inefficient: 2
infer: 2
influence: 2
influenced: 2
infrastructures: 2
ingrid: 2
ings: 2
inherent: 2
ining: 2
initialized: 2
initiates: 2
injecting: 2
insertion: 2
inspect: 2
install: 2
installed: 2
instantiated: 2
institutions: 2
instruction: 2
instructs: 2
integer: 2
intentionally: 2
interconnecting: 2
interconnection: 2
interconnects: 2
interix: 2
intermediary: 2
interpret: 2
intersection: 2
intervention: 2
intimate: 2
intricacies: 2
invalid: 2
investment: 2
invoke: 2
invokes: 2
ipdps: 2
iptps: 2
irish: 2
iscussion: 2
island: 2
italy: 2
itcoin: 2
ith: 2
ity: 2
izs: 2
james: 2
javabeans: 2
jimenez: 2
joglekar: 2
jonsson: 2
jsp: 2
juels: 2
justify: 2
kandemir: 2
kansas: 2
kapritsos: 2
karlsson: 2
katabi: 2
kazar: 2
kemme: 2
keycurr: 2
kharif: 2
kiawah: 2
kilper: 2
kim: 2
kimsas: 2
kjkj: 2
knob: 2
knobs: 2
kojo: 2
kroll: 2
krzys: 2
kurose: 2
labelled: 2
labs: 2
lagged: 2
lagging: 2
lake: 2
lambdarail: 2
lambdas: 2
landing: 2
landolsi: 2
laptop: 2
lastly: 2
lastop: 2
launching: 2
laying: 2
le: 2
lease: 2
legitimate: 2
leigh: 2
lepreau: 2
leskovec: 2
leslie: 2
leverages: 2
levy: 2
lightly: 2
lightwave: 2
likewise: 2
lin: 2
liskov: 2
literally: 2
literature: 2
lm: 2
locate: 2
lockstep: 2
longest: 2
longhaul: 2
loops: 2
loosely: 2
louise: 2
lowering: 2
lowers: 2
lows: 2
ltd: 2
luck: 2
lundqvist: 2
lynch: 2
lyon: 2
madden: 2
madhow: 2
magharei: 2
mance: 2
mandatory: 2
mangling: 2
manifested: 2
manipulate: 2
manually: 2
march: 2
marshaling: 2
martinez: 2
matrices: 2
matthews: 2
mature: 2
maximal: 2
maximized: 2
maya: 2
md: 2
mdcc: 2
meant: 2
megabits: 2
memoryless: 2
menees: 2
metacdn: 2
micro: 2
microsystems: 2
migrating: 2
milestone: 2
mined: 2
minimising: 2
minimizes: 2
minus: 2
mirroring: 2
miscalculate: 2
mismatched: 2
mistakenly: 2
mit: 2
mitigated: 2
mitigation: 2
mlml: 2
modem: 2
moderately: 2
modest: 2
modulo: 2
mohr: 2
montenegro: 2
monterey: 2
moshe: 2
mrc: 2
mst: 2
multigrep: 2
multiples: 2
multiplied: 2
multithreading: 2
muri: 2
muthitacharoen: 2
myriad: 2
nakamoto: 2
named: 2
names: 2
naming: 2
nandi: 2
narayanan: 2
naughton: 2
navathe: 2
ncsa: 2
ne: 2
nec: 2
needham: 2
negation: 2
neil: 2
nejdl: 2
newbold: 2
newer: 2
newly: 2
ngan: 2
nic: 2
nichols: 2
nishtala: 2
nity: 2
nlanr: 2
nonequilibrium: 2
nonnenmacher: 2
nontransactional: 2
normalization: 2
normalize: 2
normalizing: 2
normed: 2
notably: 2
notes: 2
notifies: 2
notifying: 2
noting: 2
nutshell: 2
nytimes: 2
obsolete: 2
obviously: 2
occasion: 2
occupies: 2
odd: 2
offices: 2
ofwork: 2
ole: 2
olympics: 2
omi: 2
omits: 2
ool: 2
ooled: 2
op: 2
opacity: 2
opening: 2
operated: 2
opportunities: 2
opt: 2
opted: 2
ordinarily: 2
organizational: 2
organizing: 2
originate: 2
orities: 2
oscillates: 2
ostar: 2
ourselves: 2
outages: 2
outs: 2
outsource: 2
outsources: 2
overcast: 2
overflow: 2
overlays: 2
overqos: 2
pairings: 2
pam: 2
panacea: 2
par: 2
paradigms: 2
parameshwaran: 2
parameterizations: 2
parametrized: 2
parity: 2
park: 2
parno: 2
pass: 2
pathway: 2
patterson: 2
payloads: 2
paypal: 2
pcb: 2
pdcs: 2
pdfs: 2
penalised: 2
pentium: 2
peration: 2
perfor: 2
peris: 2
permits: 2
permitted: 2
perpetrators: 2
perron: 2
petersen: 2
ph: 2
phanishayee: 2
phases: 2
physically: 2
picture: 2
piggybacked: 2
piling: 2
pipeline: 2
pipelines: 2
pitfalls: 2
plague: 2
plays: 2
plication: 2
plugged: 2
plugging: 2
poolattacks: 2
popper: 2
port: 2
porto: 2
ports: 2
poses: 2
position: 2
powersaving: 2
pplive: 2
practically: 2
preceding: 2
precise: 2
precludes: 2
predecessor: 2
predefined: 2
predetermined: 2
predictive: 2
predicts: 2
preferable: 2
prefers: 2
preiss: 2
preliminary: 2
premise: 2
presenting: 2
preservation: 2
preserve: 2
preserving: 2
prevail: 2
prevention: 2
primitive: 2
prioritising: 2
prioritization: 2
prioritize: 2
prioritizing: 2
privately: 2
probabilistically: 2
probe: 2
problematic: 2
processors: 2
produces: 2
professor: 2
profile: 2
profiler: 2
profit: 2
projection: 2
promote: 2
proper: 2
proposals: 2
pros: 2
proving: 2
pseudo: 2
pullbased: 2
pulling: 2
pulse: 2
purchase: 2
purchasing: 2
pure: 2
pursue: 2
pushes: 2
pvldb: 2
qhuang: 2
qin: 2
qmi: 2
qos: 2
quasistatic: 2
quicksilver: 2
quote: 2
race: 2
racticalities: 2
radc: 2
radical: 2
radio: 2
raised: 2
ramakrishnan: 2
ramamritham: 2
randomness: 2
ranges: 2
rank: 2
rateless: 2
rational: 2
ratios: 2
reacts: 2
readily: 2
ready: 2
realizes: 2
rears: 2
reasonably: 2
reception: 2
reciprocation: 2
recognition: 2
recompute: 2
reconciliation: 2
recycling: 2
redesigned: 2
redesigning: 2
reductions: 2
referred: 2
refraining: 2
refreshed: 2
regard: 2
registration: 2
reimplemented: 2
reissue: 2
reissued: 2
rejaie: 2
rejected: 2
rejecting: 2
rejects: 2
relaxed: 2
relay: 2
relevance: 2
relied: 2
relies: 2
reliminaries: 2
relying: 2
remarks: 2
remotely: 2
removes: 2
rendering: 2
rep: 2
repaired: 2
repeatable: 2
repetitions: 2
reporting: 2
repurposing: 2
reputation: 2
requisite: 2
resending: 2
resends: 2
reserves: 2
resident: 2
resolutions: 2
respecting: 2
responsive: 2
restarted: 2
retaliate: 2
retried: 2
retries: 2
reverse: 2
reviewers: 2
revisiting: 2
rewarded: 2
rewritten: 2
reykjavik: 2
reynolds: 2
ricci: 2
rightful: 2
rigid: 2
rigorous: 2
rigorously: 2
rimon: 2
rising: 2
rivalry: 2
roberts: 2
rohrs: 2
rome: 2
roots: 2
rose: 2
rosenblum: 2
ross: 2
rounding: 2
routinely: 2
row: 2
rp: 2
rsized: 2
rt: 2
rtts: 2
ruling: 2
runners: 2
rvr: 2
sabul: 2
safe: 2
saha: 2
said: 2
sake: 2
sales: 2
satellite: 2
saxena: 2
scans: 2
scatter: 2
scattered: 2
scheduler: 2
schedules: 2
sci: 2
scientist: 2
scratch: 2
scsi: 2
seamless: 2
secondgeneration: 2
seda: 2
seeking: 2
seemingly: 2
seldom: 2
seltzer: 2
seminar: 2
senior: 2
sensible: 2
sept: 2
serial: 2
serialize: 2
serially: 2
serious: 2
serverlets: 2
serverpull: 2
settle: 2
shape: 2
shapley: 2
sharp: 2
sheds: 2
shelby: 2
shell: 2
shi: 2
shieh: 2
shifts: 2
shokrollahi: 2
shortcut: 2
shortly: 2
sidebotham: 2
sigact: 2
signs: 2
sigops: 2
sigurbjornsson: 2
silicon: 2
silverlight: 2
simplification: 2
simplified: 2
simulating: 2
singh: 2
sinks: 2
sister: 2
sivakumar: 2
slashdot: 2
slashes: 2
slows: 2
slush: 2
smooth: 2
soar: 2
soars: 2
soas: 2
societies: 2
society: 2
solaris: 2
solely: 2
solheim: 2
solid: 2
solved: 2
something: 2
son: 2
sonic: 2
sons: 2
soper: 2
sourceforge: 2
south: 2
sovran: 2
specialists: 2
speedups: 2
spend: 2
spending: 2
splits: 2
spreads: 2
spreitzer: 2
srs: 2
st: 2
stabilizes: 2
staggering: 2
standalone: 2
stands: 2
stat: 2
statement: 2
station: 2
statqwest: 2
stats: 2
steal: 2
stefan: 2
stephen: 2
stocks: 2
stoller: 2
stops: 2
stories: 2
storms: 2
story: 2
stripe: 2
striping: 2
sturgis: 2
styles: 2
su: 2
subgroup: 2
submits: 2
submitted: 2
submitting: 2
subscribed: 2
subversive: 2
subverted: 2
succession: 2
successively: 2
sudden: 2
suffice: 2
suggest: 2
suggestions: 2
suited: 2
summation: 2
sundr: 2
supergame: 2
supergames: 2
supervisors: 2
supply: 2
suppose: 2
sure: 2
surpass: 2
surprise: 2
survey: 2
susceptibility: 2
suspect: 2
sustain: 2
swallow: 2
swanson: 2
swapping: 2
swift: 2
swinehart: 2
swiss: 2
sybil: 2
synchronize: 2
synthesis: 2
systematic: 2
systemic: 2
tablets: 2
tagged: 2
tailer: 2
tandard: 2
tango: 2
tardos: 2
tation: 2
tauber: 2
tc: 2
technically: 2
tempted: 2
tend: 2
termed: 2
testbed: 2
tgperf: 2
theimer: 2
thick: 2
thing: 2
thirtieth: 2
thumb: 2
tiered: 2
ties: 2
tional: 2
tions: 2
tirumala: 2
toappliance: 2
tock: 2
tods: 2
tolerates: 2
tolerating: 2
topeer: 2
topologically: 2
totally: 2
touch: 2
touches: 2
toueg: 2
tough: 2
toy: 2
tp: 2
tracing: 2
tracked: 2
trades: 2
tragedy: 2
tranmission: 2
transact: 2
transcoded: 2
transforming: 2
trapezoids: 2
treatment: 2
tremel: 2
triangular: 2
tricky: 2
tries: 2
trivially: 2
trol: 2
trsu: 2
trustworthy: 2
tuft: 2
tuned: 2
tv: 2
twentieth: 2
twofold: 2
ugly: 2
umich: 2
un: 2
unaltered: 2
unattacked: 2
unattractive: 2
uncommitable: 2
uncommitted: 2
unexplored: 2
unfavorable: 2
uninvolved: 2
uniquely: 2
united: 2
unlucky: 2
unnecessarily: 2
unnecessary: 2
unreachable: 2
unresponsive: 2
uploading: 2
urgent: 2
userspace: 2
validating: 2
vancouver: 2
vandermeer: 2
vandermonde: 2
vasek: 2
vcurr: 2
vein: 2
venkataramani: 2
ver: 2
verby: 2
versioned: 2
vicinity: 2
viewers: 2
violations: 2
virtualized: 2
visibility: 2
visited: 2
vko: 2
volumes: 2
vpn: 2
wakeup: 2
walks: 2
wallace: 2
war: 2
warehouse: 2
warship: 2
watching: 2
wattenhofer: 2
weakens: 2
weaker: 2
weaknesses: 2
websphere: 2
welch: 2
wesley: 2
west: 2
whereby: 2
whom: 2
wicker: 2
wider: 2
width: 2
wiley: 2
williams: 2
willing: 2
willner: 2
winter: 2
withholds: 2
witnessed: 2
wizkid: 2
wlog: 2
wo: 2
wolfgang: 2
wong: 2
words: 2
workflow: 2
worsening: 2
wrapping: 2
wrongdoing: 2
wvwv: 2
xie: 2
xored: 2
xp: 2
xth: 2
yang: 2
ymir: 2
yxxy: 2
zoom: 2
aaron: 1
abbreviations: 1
abilalso: 1
absorbs: 1
abstracts: 1
abu: 1
accompanied: 1
accomplish: 1
accomplishing: 1
accounted: 1
accumulate: 1
aceves: 1
acheive: 1
acheived: 1
acls: 1
acmula: 1
acomplish: 1
acquires: 1
acquiring: 1
acthe: 1
activated: 1
actuators: 1
acwe: 1
adamic: 1
adaptable: 1
adapted: 1
adaptively: 1
adaptivity: 1
addi: 1
addiserver: 1
additive: 1
addressable: 1
adelaide: 1
adhere: 1
adjacent: 1
administers: 1
admit: 1
admits: 1
adoption: 1
ads: 1
advertise: 1
advertised: 1
adya: 1
aelstrom: 1
aerospace: 1
af: 1
affirmative: 1
afford: 1
afforded: 1
afraid: 1
afterward: 1
agenda: 1
agent: 1
ager: 1
aggregat: 1
aggregrate: 1
aggressively: 1
aggressiveness: 1
agreements: 1
ahnn: 1
aid: 1
aims: 1
airplane: 1
ak: 1
akkus: 1
alarms: 1
albatross: 1
albrecht: 1
alegre: 1
alexander: 1
alfetching: 1
allavena: 1
allegedly: 1
alleviated: 1
alleviates: 1
allo: 1
alloc: 1
allocations: 1
allthingsdistributed: 1
alof: 1
alpha: 1
altogether: 1
altrustic: 1
am: 1
amar: 1
ambitious: 1
america: 1
amortized: 1
ample: 1
amplify: 1
amsden: 1
analogy: 1
analyse: 1
analyst: 1
analytics: 1
ance: 1
anceaume: 1
anddrop: 1
andersen: 1
andre: 1
andreas: 1
ann: 1
anne: 1
annie: 1
annotated: 1
announce: 1
announcement: 1
announces: 1
annoyingly: 1
annually: 1
anonymous: 1
answered: 1
answers: 1
anticipated: 1
antipolis: 1
antonio: 1
anytime: 1
anyway: 1
anywhere: 1
ap: 1
apa: 1
appeal: 1
appendix: 1
applaud: 1
appleton: 1
appli: 1
applicationdropped: 1
appliit: 1
applior: 1
applithe: 1
approaching: 1
approximates: 1
apps: 1
apthe: 1
arbor: 1
architects: 1
archival: 1
archives: 1
argus: 1
arisen: 1
armies: 1
arranging: 1
arrivals: 1
artifact: 1
artificial: 1
ase: 1
aside: 1
ask: 1
asking: 1
assembling: 1
assist: 1
assisted: 1
associates: 1
associating: 1
astrolabe: 1
aswhen: 1
asynbandwidth: 1
asynchrony: 1
asynmicrobenchmarks: 1
asynmobile: 1
asynqueue: 1
ata: 1
atomically: 1
atr: 1
att: 1
attaches: 1
attaching: 1
attar: 1
attention: 1
attr: 1
attracted: 1
attributable: 1
attributed: 1
atypical: 1
audit: 1
audits: 1
australia: 1
authoritative: 1
authorized: 1
autodesk: 1
automation: 1
autotion: 1
autowriteback: 1
autumn: 1
ava: 1
availto: 1
avatar: 1
awaiting: 1
awareness: 1
axes: 1
azim: 1
backgound: 1
backgrounds: 1
backlog: 1
backlogs: 1
backnt: 1
backups: 1
bakalova: 1
balancers: 1
ballance: 1
ballot: 1
banaei: 1
bandcontain: 1
bandhowever: 1
bandwhile: 1
bandwidthdelay: 1
bandwidthsensitive: 1
banff: 1
barcelona: 1
bare: 1
barracuda: 1
barriers: 1
baseline: 1
bastion: 1
batched: 1
batches: 1
batching: 1
batkin: 1
battle: 1
battlefield: 1
battleground: 1
bayeux: 1
bcc: 1
bcq: 1
became: 1
befriended: 1
behren: 1
beijing: 1
belief: 1
believed: 1
beloved: 1
benchmarking: 1
benchmarks: 1
benenational: 1
benoit: 1
bered: 1
berkeleydb: 1
bernd: 1
bershad: 1
bership: 1
bert: 1
bertier: 1
bhattacharjee: 1
biggest: 1
bile: 1
bill: 1
billed: 1
billing: 1
bills: 1
bindel: 1
binds: 1
bio: 1
bitcoinmines: 1
bk: 1
blades: 1
blame: 1
ble: 1
bleeding: 1
blending: 1
blogs: 1
boa: 1
board: 1
body: 1
bold: 1
bologna: 1
bond: 1
bonding: 1
bonn: 1
book: 1
boosting: 1
boot: 1
borisov: 1
bortnikov: 1
boss: 1
bostic: 1
bother: 1
bottlenecks: 1
bought: 1
boundary: 1
bounds: 1
boys: 1
bq: 1
br: 1
brahms: 1
brazil: 1
breakthrough: 1
bregni: 1
breslau: 1
brian: 1
bridging: 1
bright: 1
british: 1
broad: 1
broberg: 1
brokers: 1
brought: 1
bruno: 1
budget: 1
budgets: 1
buffercould: 1
bug: 1
buggy: 1
bugs: 1
builders: 1
burdens: 1
bureau: 1
burgess: 1
buried: 1
burrows: 1
busnel: 1
button: 1
buyer: 1
buying: 1
buys: 1
cabrera: 1
cacheable: 1
cacheserializability: 1
caise: 1
cal: 1
calability: 1
camargos: 1
cameras: 1
cancelled: 1
candidate: 1
cannes: 1
cantwell: 1
capability: 1
cappuccino: 1
captured: 1
caratti: 1
carded: 1
cardinality: 1
cardoso: 1
career: 1
careers: 1
careful: 1
caribbean: 1
carl: 1
carried: 1
carrier: 1
carrying: 1
cart: 1
carzaniga: 1
cas: 1
cascades: 1
cast: 1
castor: 1
catalog: 1
catastrophe: 1
catastrophic: 1
cated: 1
categorized: 1
cations: 1
causal: 1
cbb: 1
cbbc: 1
cbqpcb: 1
ccb: 1
ccdf: 1
cdf: 1
cdrom: 1
ceives: 1
cell: 1
centered: 1
ceremony: 1
certify: 1
certifying: 1
cess: 1
chained: 1
chainlink: 1
chair: 1
chakka: 1
chakravorty: 1
challenger: 1
chang: 1
changtao: 1
chapman: 1
characterised: 1
chawathe: 1
cheat: 1
checkouts: 1
chenchu: 1
cheslack: 1
chicken: 1
chiefly: 1
chien: 1
chinese: 1
ching: 1
chockler: 1
choke: 1
chose: 1
chow: 1
christened: 1
christmas: 1
chronously: 1
chrony: 1
chu: 1
chuck: 1
chunk: 1
chunks: 1
cincilla: 1
circuitous: 1
circulation: 1
circumvented: 1
circumvents: 1
citation: 1
cites: 1
cities: 1
clara: 1
clarity: 1
cleaned: 1
cleanly: 1
clearer: 1
clements: 1
clientserver: 1
clocks: 1
clone: 1
closest: 1
cloudifying: 1
clutter: 1
cmu: 1
codaniques: 1
coded: 1
coding: 1
coexistence: 1
coexists: 1
coherency: 1
coincide: 1
collaborate: 1
collaborating: 1
collapsing: 1
collateral: 1
collects: 1
collusions: 1
columbia: 1
comings: 1
comitting: 1
comm: 1
commatic: 1
commence: 1
commences: 1
commentary: 1
commenting: 1
commercially: 1
commonplace: 1
communal: 1
communi: 1
commutative: 1
comp: 1
compact: 1
comparably: 1
comparaour: 1
comparative: 1
comparisons: 1
compelling: 1
compensating: 1
competitors: 1
compiler: 1
complementary: 1
complementing: 1
complexities: 1
complimentary: 1
comply: 1
compositional: 1
compressed: 1
compresses: 1
comprising: 1
compromises: 1
compromising: 1
computationally: 1
computfits: 1
comsium: 1
concentrates: 1
concentration: 1
conception: 1
conceptually: 1
concludes: 1
concrete: 1
concurby: 1
concuruses: 1
conditioned: 1
conext: 1
configure: 1
conform: 1
conios: 1
conitbased: 1
conjecture: 1
connec: 1
connectionless: 1
conner: 1
consequent: 1
conserving: 1
consisted: 1
consisupdate: 1
consortium: 1
constantly: 1
constituent: 1
constrain: 1
constructs: 1
consulting: 1
consumer: 1
consumers: 1
contacting: 1
contally: 1
contemplate: 1
contemplated: 1
contemplating: 1
contending: 1
conthe: 1
contingencies: 1
contolerate: 1
contractors: 1
contravention: 1
contributes: 1
controller: 1
controversy: 1
convenience: 1
convention: 1
converged: 1
converging: 1
conversely: 1
converts: 1
conveyed: 1
convoys: 1
cooperating: 1
coordinated: 1
coordinating: 1
coordinators: 1
copied: 1
coping: 1
cops: 1
cornelldeveloped: 1
corr: 1
corrected: 1
corrections: 1
correspondingly: 1
corroborated: 1
corrupted: 1
cotton: 1
counters: 1
counting: 1
couple: 1
crashing: 1
crawl: 1
credit: 1
credo: 1
crete: 1
crippling: 1
criteria: 1
critically: 1
crossroads: 1
crowcroft: 1
csd: 1
cstr: 1
culled: 1
cumulatively: 1
customised: 1
customizability: 1
customizable: 1
customization: 1
customizing: 1
customuserserviceapp: 1
cutler: 1
cuts: 1
cybercaf: 1
cyrus: 1
czerwinski: 1
dallas: 1
danielsson: 1
danilov: 1
dantzig: 1
dat: 1
datagrams: 1
dataset: 1
datastores: 1
daunting: 1
dave: 1
davoli: 1
dazzling: 1
dc: 1
dead: 1
deadlock: 1
deadly: 1
deadtially: 1
dean: 1
debatable: 1
debate: 1
debated: 1
debilitating: 1
debris: 1
debugger: 1
declare: 1
declaring: 1
declines: 1
decode: 1
decoder: 1
decoding: 1
decoupled: 1
decouples: 1
decreased: 1
defend: 1
deferplications: 1
deferrable: 1
defers: 1
defgh: 1
defining: 1
definitions: 1
degrees: 1
deit: 1
delegation: 1
delete: 1
deleted: 1
delivers: 1
demanded: 1
demise: 1
demonstration: 1
denning: 1
dennis: 1
denoting: 1
dep: 1
depart: 1
departments: 1
dependalso: 1
dependenrate: 1
depsa: 1
depth: 1
dequeued: 1
der: 1
dered: 1
deregistered: 1
derivative: 1
derivatives: 1
derives: 1
deriving: 1
des: 1
descending: 1
deserver: 1
deshow: 1
designated: 1
designating: 1
designer: 1
desirability: 1
desirable: 1
desktops: 1
destabilize: 1
destinations: 1
detailing: 1
deterioration: 1
determinants: 1
detrimental: 1
dev: 1
developerhours: 1
deviations: 1
devised: 1
devlin: 1
devoted: 1
devoting: 1
dewitt: 1
dexa: 1
dhs: 1
dht: 1
diamond: 1
dictionaries: 1
diego: 1
dies: 1
differany: 1
differential: 1
differentiates: 1
differentiating: 1
differenwith: 1
differing: 1
diffs: 1
dimensions: 1
dimov: 1
ding: 1
directing: 1
directs: 1
disable: 1
disables: 1
disappearance: 1
disappeared: 1
disastrous: 1
disbut: 1
discard: 1
disconnections: 1
disconnects: 1
discontinuing: 1
discotheque: 1
discounts: 1
discovered: 1
discusses: 1
discussing: 1
disguise: 1
disinclined: 1
disjoing: 1
dislike: 1
dismiss: 1
dispatch: 1
dispatcher: 1
dispatching: 1
displayed: 1
displaying: 1
displays: 1
dispools: 1
disregarded: 1
dissatisfied: 1
disseminating: 1
distill: 1
distorted: 1
diverges: 1
diversion: 1
diversity: 1
dll: 1
dlls: 1
documented: 1
dol: 1
domains: 1
dominating: 1
donet: 1
door: 1
dou: 1
doubled: 1
douceur: 1
doug: 1
downgraded: 1
downtime: 1
dozen: 1
dr: 1
drain: 1
drained: 1
drawbacks: 1
drawing: 1
draws: 1
drift: 1
drifting: 1
drive: 1
drivers: 1
drone: 1
duals: 1
ducing: 1
dummynet: 1
dundant: 1
dunn: 1
duplicates: 1
dur: 1
durably: 1
durations: 1
dwarf: 1
dx: 1
dynamics: 1
ear: 1
eastham: 1
economies: 1
ecution: 1
edd: 1
edges: 1
edit: 1
editors: 1
edits: 1
eds: 1
eduardo: 1
educational: 1
edutella: 1
eed: 1
efficacies: 1
eg: 1
egemen: 1
egg: 1
ekin: 1
elasticity: 1
elect: 1
electric: 1
electricity: 1
electronics: 1
eleventh: 1
eliability: 1
elicit: 1
eliciting: 1
elkin: 1
embark: 1
embody: 1
embrace: 1
embraces: 1
emerged: 1
emerges: 1
emitting: 1
emmanuelle: 1
empted: 1
emto: 1
emulating: 1
encapsulates: 1
encod: 1
encode: 1
encompass: 1
encourages: 1
encrypt: 1
encrypts: 1
endeavor: 1
endowment: 1
endpoints: 1
endtransaction: 1
endtransport: 1
enemy: 1
enforced: 1
engine: 1
engineers: 1
enlarge: 1
enlarges: 1
enlarging: 1
enputing: 1
entail: 1
entering: 1
entitled: 1
entropy: 1
enumerate: 1
episodes: 1
epositories: 1
epstein: 1
equeation: 1
equipped: 1
erally: 1
erates: 1
erent: 1
ering: 1
erodes: 1
erred: 1
errorprone: 1
ery: 1
eschewing: 1
esprit: 1
establish: 1
establishes: 1
etup: 1
eugster: 1
evalappended: 1
eventoriented: 1
everyday: 1
everywhere: 1
evocative: 1
evolves: 1
evolving: 1
exacerbating: 1
exaggerated: 1
examined: 1
excellently: 1
excess: 1
exchanging: 1
excitement: 1
exclusively: 1
exec: 1
execusystem: 1
executable: 1
exemplifies: 1
exercise: 1
exhibitthe: 1
existed: 1
exited: 1
exiting: 1
expects: 1
expedited: 1
expense: 1
experiencing: 1
expert: 1
expire: 1
explanation: 1
explanatory: 1
exploits: 1
exponentiated: 1
exporting: 1
expose: 1
exposition: 1
expunged: 1
expurge: 1
exsmart: 1
exspecified: 1
extending: 1
extensible: 1
extensively: 1
extracting: 1
extracts: 1
facilitates: 1
facilitating: 1
facing: 1
factory: 1
failing: 1
failuredetectio: 1
failwhen: 1
faithful: 1
faloutsos: 1
falsely: 1
faltered: 1
famous: 1
farber: 1
farewell: 1
farm: 1
farnoush: 1
farther: 1
fascination: 1
fashioned: 1
fastest: 1
featured: 1
federal: 1
federica: 1
feel: 1
feels: 1
feet: 1
feldman: 1
fell: 1
fellow: 1
fellowship: 1
felt: 1
ferred: 1
ferris: 1
ffs: 1
fic: 1
fidelity: 1
fifteen: 1
figured: 1
fikes: 1
filing: 1
filled: 1
films: 1
filtered: 1
filters: 1
finance: 1
findings: 1
finegrained: 1
finergrained: 1
finish: 1
fiorano: 1
firewall: 1
firms: 1
fisher: 1
fitted: 1
fitting: 1
fixes: 1
flavors: 1
flaws: 1
flickr: 1
flood: 1
flooding: 1
fluctuating: 1
fluke: 1
flushing: 1
fly: 1
focs: 1
football: 1
forcibly: 1
forecast: 1
foregoing: 1
foremost: 1
foresee: 1
forgoing: 1
fork: 1
forked: 1
formal: 1
formally: 1
formed: 1
formerly: 1
fort: 1
fortune: 1
forwards: 1
founder: 1
fractions: 1
franke: 1
frans: 1
freed: 1
freenix: 1
freeze: 1
freshness: 1
fricano: 1
friends: 1
friendship: 1
frightening: 1
frontend: 1
frost: 1
ftcs: 1
fugal: 1
fulfilling: 1
fulfillment: 1
functional: 1
fund: 1
funding: 1
furniture: 1
furthest: 1
gabit: 1
gabriel: 1
gallager: 1
garbinato: 1
garcia: 1
gates: 1
gathering: 1
gauge: 1
gauthier: 1
gave: 1
gb: 1
gbit: 1
gcheap: 1
geambasu: 1
generalized: 1
genercache: 1
generous: 1
geneva: 1
genit: 1
genuinely: 1
geodistributed: 1
geoff: 1
geoffrey: 1
gershinsky: 1
gestion: 1
getting: 1
ghemawat: 1
gi: 1
gian: 1
giardullo: 1
gifford: 1
gilbert: 1
ginting: 1
ginza: 1
gis: 1
gist: 1
giving: 1
glade: 1
glance: 1
glitches: 1
globalized: 1
globecom: 1
goel: 1
gold: 1
goldberg: 1
googles: 1
gov: 1
governed: 1
governmental: 1
grade: 1
gradual: 1
grande: 1
granting: 1
granularity: 1
graphical: 1
grc: 1
gree: 1
greece: 1
grepwe: 1
griffioen: 1
grimm: 1
grips: 1
grochowski: 1
grounds: 1
groundwork: 1
grove: 1
gruber: 1
grunwald: 1
guadelope: 1
gubarev: 1
guha: 1
guis: 1
gunnar: 1
gunnars: 1
gurevich: 1
gurus: 1
guy: 1
guyadec: 1
hacked: 1
hacking: 1
hadoop: 1
haifa: 1
halem: 1
halt: 1
halts: 1
halves: 1
hampering: 1
hanan: 1
handing: 1
handled: 1
handler: 1
handoff: 1
handurukande: 1
hang: 1
hansell: 1
happened: 1
haridasan: 1
haridasana: 1
harmful: 1
harnessing: 1
harpaz: 1
hartman: 1
harwood: 1
hasn: 1
hawaii: 1
hazard: 1
hazards: 1
headquarters: 1
heard: 1
heart: 1
heartbeatmonitor: 1
heat: 1
heavyweight: 1
hegde: 1
hegedu: 1
heidemann: 1
heiser: 1
helen: 1
hellerstein: 1
helped: 1
henceforth: 1
her: 1
herein: 1
hersonissos: 1
hesitate: 1
heterogeneity: 1
heuristic: 1
heuristics: 1
hiding: 1
highassurance: 1
highbandwidth: 1
highbut: 1
highlights: 1
highlyavailable: 1
highpower: 1
highquality: 1
hik: 1
hill: 1
him: 1
himself: 1
hisgen: 1
hjelm: 1
hochschild: 1
holbrook: 1
holder: 1
holding: 1
holte: 1
homes: 1
homomorphic: 1
honolulu: 1
honored: 1
hoon: 1
hopcroft: 1
hoping: 1
horizontal: 1
horn: 1
horrible: 1
hospital: 1
hotice: 1
hotly: 1
hotnets: 1
hotzone: 1
hours: 1
howa: 1
hpca: 1
hreshold: 1
hrs: 1
hsieh: 1
htm: 1
hu: 1
huazhong: 1
huberman: 1
hungary: 1
hurricane: 1
hurting: 1
hyder: 1
hyper: 1
ically: 1
icccn: 1
iceland: 1
icomp: 1
icons: 1
icpads: 1
icsoc: 1
idempotence: 1
iden: 1
idenhigh: 1
identically: 1
idigest: 1
ied: 1
igniting: 1
ignorance: 1
ihkj: 1
iis: 1
ilability: 1
illegal: 1
illusion: 1
imaginable: 1
imation: 1
imc: 1
imlocal: 1
immature: 1
immersive: 1
impacts: 1
implememted: 1
implemenfrom: 1
implemenshared: 1
implementapackages: 1
implosion: 1
implying: 1
import: 1
imported: 1
imporwriteback: 1
imposition: 1
impossibility: 1
imprecise: 1
impressive: 1
improv: 1
inadequacy: 1
inadequate: 1
inadequately: 1
inapplicable: 1
inappropriate: 1
inbound: 1
incentivize: 1
inception: 1
inclusive: 1
incompatible: 1
incomplete: 1
incon: 1
inconsisto: 1
incorpoas: 1
increasess: 1
incredibly: 1
incrementing: 1
indefinitely: 1
independence: 1
indexing: 1
indicators: 1
indictment: 1
indirect: 1
indirectly: 1
indispensable: 1
individinterference: 1
individuals: 1
indranil: 1
induced: 1
industrystandard: 1
inefficiencies: 1
inevitable: 1
inexpennet: 1
inf: 1
infect: 1
infected: 1
infection: 1
infectious: 1
inference: 1
inferred: 1
inflate: 1
inflexibility: 1
inflight: 1
informa: 1
informatics: 1
informing: 1
informs: 1
infrequent: 1
infused: 1
inherited: 1
inhibit: 1
inhibiting: 1
inicontention: 1
initialised: 1
initialize: 1
initiating: 1
initiation: 1
inject: 1
injects: 1
inner: 1
innetwork: 1
innotice: 1
innovate: 1
inprocess: 1
inputs: 1
insecure: 1
insensitive: 1
inseparable: 1
inserted: 1
inserts: 1
inspection: 1
inspired: 1
instruct: 1
instructed: 1
instructing: 1
instructions: 1
instrument: 1
instrumented: 1
instrumenting: 1
int: 1
integers: 1
integrity: 1
intellection: 1
intellectual: 1
intelligence: 1
intem: 1
intense: 1
intensity: 1
intention: 1
intentions: 1
interadditional: 1
intercluster: 1
interdependence: 1
interests: 1
interfere: 1
interferes: 1
interject: 1
interlinked: 1
intermittent: 1
intermittently: 1
internally: 1
internships: 1
interoriginally: 1
interpreted: 1
interpreting: 1
interprocess: 1
interrogates: 1
interrupt: 1
interrupts: 1
interspersed: 1
intervenallows: 1
intra: 1
intractable: 1
intrapartition: 1
intrusion: 1
intrusions: 1
intuitively: 1
invaluable: 1
invariant: 1
invest: 1
investigations: 1
invisible: 1
invocation: 1
invocations: 1
involve: 1
involvement: 1
involving: 1
iperfthe: 1
ipto: 1
irections: 1
irregularity: 1
irregularly: 1
irrelevant: 1
irrespectively: 1
isca: 1
isola: 1
isolate: 1
isolated: 1
isolating: 1
israel: 1
istemi: 1
istva: 1
itcc: 1
items: 1
iterators: 1
ities: 1
itors: 1
iyengar: 1
jacobson: 1
jade: 1
jain: 1
janne: 1
jannotti: 1
jansch: 1
jared: 1
jari: 1
je: 1
jerian: 1
jesi: 1
jian: 1
jiang: 1
jin: 1
jini: 1
jit: 1
jiun: 1
jk: 1
jmc: 1
jms: 1
job: 1
jobs: 1
joined: 1
jones: 1
jong: 1
jorge: 1
jostling: 1
jr: 1
judicious: 1
julkunen: 1
jump: 1
jumpy: 1
juni: 1
junqueira: 1
justice: 1
justification: 1
kallman: 1
kalogeras: 1
kamilmani: 1
kaminsky: 1
kamra: 1
kanthak: 1
karamanolis: 1
karels: 1
karp: 1
kashani: 1
katti: 1
kay: 1
kde: 1
keidl: 1
keith: 1
keller: 1
kempe: 1
kent: 1
kerberos: 1
kernels: 1
kernilized: 1
kevin: 1
keyboard: 1
khan: 1
khorlin: 1
kib: 1
kick: 1
kicking: 1
kicks: 1
kid: 1
kilobyte: 1
kilobytes: 1
kirk: 1
kistler: 1
kit: 1
kk: 1
kleiman: 1
kliot: 1
kloc: 1
knights: 1
knowledgments: 1
kodali: 1
kogan: 1
korhonen: 1
koskela: 1
kostic: 1
kouznetsov: 1
kr: 1
kramer: 1
kraska: 1
krishnakumar: 1
krishnamurthy: 1
kristjan: 1
kristjanvj: 1
krohn: 1
kubiatowicz: 1
kulkarni: 1
kumar: 1
kupfer: 1
kwiatkowski: 1
la: 1
laboratories: 1
laboratory: 1
lacked: 1
ladis: 1
lafayette: 1
lag: 1
lags: 1
laid: 1
laing: 1
lamb: 1
land: 1
landlord: 1
lands: 1
landscapes: 1
lapping: 1
larry: 1
lasting: 1
lauderdale: 1
launch: 1
law: 1
lay: 1
layed: 1
layering: 1
lazy: 1
leaks: 1
learned: 1
learners: 1
leasing: 1
lecture: 1
led: 1
lee: 1
leff: 1
legends: 1
lenient: 1
lenz: 1
lesser: 1
lets: 1
lever: 1
levin: 1
libdeh: 1
liberal: 1
licensing: 1
lie: 1
lied: 1
lieu: 1
lighter: 1
likelihood: 1
limitation: 1
linden: 1
lindsay: 1
linearizable: 1
linger: 1
linkages: 1
lion: 1
listen: 1
listening: 1
littered: 1
liveness: 1
lives: 1
livestreaming: 1
livny: 1
lkjj: 1
ln: 1
lo: 1
localized: 1
localizes: 1
lockfree: 1
logarithmic: 1
logarithmically: 1
logics: 1
login: 1
logstructured: 1
lombard: 1
longput: 1
longrunning: 1
lookup: 1
loose: 1
loses: 1
loudifying: 1
louisiana: 1
lowand: 1
lowbandwidth: 1
lowerfile: 1
lowmfs: 1
lowney: 1
lowpower: 1
lpdc: 1
lr: 1
lugano: 1
luna: 1
luo: 1
lying: 1
lyles: 1
maarten: 1
mach: 1
macrobenchmarks: 1
maffeis: 1
magazine: 1
maglaris: 1
magnetic: 1
magnified: 1
magninetwork: 1
mahajan: 1
maheshwari: 1
mailing: 1
mailoth: 1
mainly: 1
mainteconsequently: 1
mak: 1
maki: 1
malloth: 1
man: 1
mandated: 1
mandreoli: 1
manipulates: 1
manm: 1
mann: 1
mao: 1
marandi: 1
marchukov: 1
marcon: 1
margo: 1
marie: 1
marin: 1
mario: 1
markoff: 1
markus: 1
marrying: 1
marshal: 1
martignon: 1
maryland: 1
marzullo: 1
mash: 1
mashing: 1
masking: 1
mass: 1
massachussetts: 1
matches: 1
materials: 1
matically: 1
matskin: 1
matt: 1
maxcontiguous: 1
maxim: 1
maximizing: 1
maymounkov: 1
mazieres: 1
mazon: 1
mbit: 1
mcauliffe: 1
mcelroy: 1
mckenney: 1
mea: 1
meaning: 1
meaningfully: 1
meantime: 1
mechacies: 1
medians: 1
mediarich: 1
mediately: 1
medical: 1
meet: 1
meetings: 1
megabytes: 1
megastore: 1
meirong: 1
melnik: 1
mem: 1
memcache: 1
memcopy: 1
memoryrelated: 1
men: 1
mendel: 1
menus: 1
mer: 1
merchant: 1
merging: 1
meta: 1
metaphor: 1
miami: 1
miao: 1
mib: 1
migrate: 1
mika: 1
mike: 1
mikhail: 1
mile: 1
milestones: 1
millions: 1
mimic: 1
mindset: 1
minh: 1
minimise: 1
minimised: 1
minimized: 1
minitransactions: 1
minjun: 1
minneapolis: 1
minnesota: 1
minobrowser: 1
mirrored: 1
mirrors: 1
misbehavior: 1
misfinally: 1
miskin: 1
mislove: 1
misra: 1
mistakes: 1
mitigates: 1
mitigating: 1
mitzenmacher: 1
mixes: 1
mmcn: 1
moderate: 1
modewell: 1
modularity: 1
mofavouring: 1
mohan: 1
moll: 1
moments: 1
monetary: 1
monin: 1
monnet: 1
mono: 1
monolithic: 1
monotonically: 1
moon: 1
morning: 1
morris: 1
mostlyreads: 1
motes: 1
motivating: 1
motivations: 1
mounted: 1
mouse: 1
movement: 1
mpi: 1
mplementation: 1
mscorwks: 1
msgs: 1
msiegen: 1
msn: 1
mts: 1
mulsequence: 1
multiframed: 1
multigigabit: 1
multiin: 1
multimedia: 1
multiplexing: 1
multispeed: 1
multitier: 1
multitude: 1
multiversioning: 1
multiwas: 1
multo: 1
mummert: 1
murderous: 1
music: 1
mutexes: 1
mvs: 1
mwaura: 1
na: 1
naaman: 1
nagle: 1
nahrstedt: 1
naively: 1
naks: 1
namespace: 1
nance: 1
napper: 1
narada: 1
nary: 1
nate: 1
nats: 1
naval: 1
navigate: 1
navy: 1
nawab: 1
nca: 1
ndi: 1
neatly: 1
necessity: 1
needing: 1
needless: 1
needlessly: 1
negative: 1
negatively: 1
negligibly: 1
negotiate: 1
nei: 1
neighboring: 1
nelson: 1
ness: 1
netecon: 1
neting: 1
neufeld: 1
newarr: 1
newscasts: 1
nextgeneration: 1
nfs: 1
ngas: 1
nicely: 1
niche: 1
nick: 1
night: 1
nikolov: 1
nimble: 1
ninth: 1
nishimura: 1
nishita: 1
nism: 1
nization: 1
noisy: 1
nomad: 1
nonblockingtransport: 1
noncongestion: 1
nondeterministic: 1
nonempty: 1
nossdav: 1
noteworthy: 1
notified: 1
notoriously: 1
nowadays: 1
np: 1
npapers: 1
nsfc: 1
ntserver: 1
num: 1
numb: 1
numeric: 1
nutanong: 1
nygren: 1
obeyed: 1
obeys: 1
obfuscates: 1
objective: 1
objectivity: 1
objectoriented: 1
obligation: 1
obliging: 1
observable: 1
observes: 1
obsessively: 1
obsoleted: 1
obstacle: 1
obstructs: 1
occurrence: 1
ofc: 1
offenders: 1
offerings: 1
officially: 1
offline: 1
offset: 1
oforder: 1
ogy: 1
oltp: 1
omitting: 1
oneanother: 1
ongoing: 1
ontology: 1
onwards: 1
opearting: 1
openafs: 1
opennt: 1
opens: 1
opensketch: 1
operafrom: 1
operamfs: 1
operat: 1
operatencies: 1
opposing: 1
opposition: 1
optimality: 1
optimally: 1
optimisation: 1
optimisations: 1
optimise: 1
optimised: 1
optimistically: 1
optional: 1
orchestrating: 1
orderings: 1
organised: 1
origin: 1
originated: 1
originating: 1
originator: 1
ority: 1
orks: 1
orleans: 1
orma: 1
ormance: 1
ortributed: 1
orts: 1
oscillate: 1
oscillating: 1
ost: 1
otivation: 1
ource: 1
ous: 1
outcontent: 1
outlook: 1
outof: 1
outperform: 1
outperformed: 1
outright: 1
outweighs: 1
overcomes: 1
overhaul: 1
overlaid: 1
overlayed: 1
overloading: 1
overpredict: 1
overprediction: 1
overreach: 1
overrequest: 1
overrequesting: 1
oversight: 1
oversold: 1
overweigh: 1
overwritten: 1
owing: 1
owned: 1
ozalp: 1
ozsu: 1
pa: 1
pack: 1
package: 1
packparently: 1
packs: 1
pain: 1
pairing: 1
paleczny: 1
pallickara: 1
palossless: 1
pan: 1
panel: 1
pang: 1
panning: 1
pans: 1
paolo: 1
papazoglou: 1
parallelising: 1
parallelism: 1
parallelized: 1
parallelizing: 1
parameterizing: 1
parent: 1
parents: 1
paritybased: 1
parliament: 1
parsa: 1
partitionable: 1
partners: 1
party: 1
passes: 1
pastry: 1
pat: 1
paterson: 1
patin: 1
patino: 1
pavlo: 1
pdc: 1
peculiar: 1
peek: 1
peep: 1
peking: 1
penalized: 1
pennsylvania: 1
penzo: 1
perceive: 1
perceiving: 1
percentiles: 1
perception: 1
perdichizzi: 1
perf: 1
performances: 1
perience: 1
periments: 1
permission: 1
permute: 1
permutes: 1
permuting: 1
perobject: 1
persisted: 1
persistence: 1
persisting: 1
personalize: 1
personalized: 1
personally: 1
pertaining: 1
perturbances: 1
perturbation: 1
perturbations: 1
perv: 1
pervasively: 1
pervasiveness: 1
petko: 1
petrov: 1
pfhsn: 1
phani: 1
philadelphia: 1
philosophical: 1
phones: 1
phpmyadmin: 1
physician: 1
pianese: 1
picconi: 1
picking: 1
picks: 1
piece: 1
pieces: 1
piles: 1
pirahesh: 1
pittsburgh: 1
pivotal: 1
plain: 1
planes: 1
planned: 1
planning: 1
plans: 1
plants: 1
plasma: 1
plat: 1
plausible: 1
please: 1
plentiful: 1
plotted: 1
pluggable: 1
plugins: 1
pn: 1
podcasts: 1
pointer: 1
pointers: 1
poirier: 1
police: 1
political: 1
portability: 1
portal: 1
porting: 1
portob: 1
portray: 1
posix: 1
post: 1
postava: 1
posted: 1
posters: 1
postponed: 1
postponing: 1
potencan: 1
potholes: 1
powell: 1
powerhouse: 1
powering: 1
powers: 1
powersavings: 1
ppendix: 1
practices: 1
pratt: 1
pray: 1
preallocating: 1
precede: 1
precious: 1
precision: 1
preclude: 1
predetermining: 1
predictability: 1
predicting: 1
predictions: 1
predominant: 1
predominantly: 1
preempted: 1
preexisting: 1
preferences: 1
prefetchthe: 1
preguica: 1
preparation: 1
prepare: 1
prepared: 1
prepares: 1
preprocessing: 1
pressing: 1
presume: 1
pretend: 1
pretending: 1
pretends: 1
prevailing: 1
prevalent: 1
previewer: 1
previwhen: 1
prices: 1
prifetched: 1
priin: 1
primaldual: 1
princehouse: 1
priorispeedup: 1
prioritized: 1
priortwo: 1
prito: 1
priviledges: 1
privileged: 1
pro: 1
probed: 1
probes: 1
procedures: 1
proceedin: 1
professional: 1
profiled: 1
profiles: 1
profiling: 1
programmed: 1
progressed: 1
prohibited: 1
prohibitive: 1
prohibitively: 1
prohibits: 1
projected: 1
proliferating: 1
prometheus: 1
prominently: 1
promised: 1
promotional: 1
promptly: 1
pronounced: 1
propagates: 1
propagating: 1
propel: 1
propgated: 1
proportionally: 1
proposal: 1
proposes: 1
prothe: 1
prototypes: 1
protruding: 1
proverbial: 1
provers: 1
provisions: 1
provoke: 1
proximity: 1
prudently: 1
pruned: 1
ptions: 1
publications: 1
publishsubscribe: 1
pubsub: 1
punishing: 1
purchased: 1
purdue: 1
putation: 1
puter: 1
puts: 1
puzar: 1
pvalues: 1
pvm: 1
pvt: 1
qnx: 1
qppq: 1
qu: 1
quadrant: 1
quadrants: 1
qualities: 1
quantified: 1
quantity: 1
quarterman: 1
quarters: 1
quasi: 1
quema: 1
questionable: 1
quinlan: 1
quired: 1
quorum: 1
quotes: 1
raab: 1
races: 1
rachid: 1
racing: 1
radar: 1
radi: 1
rago: 1
raid: 1
rails: 1
raincloud: 1
raisepriority: 1
raising: 1
rameter: 1
ramifications: 1
randomised: 1
ranks: 1
ratnasamy: 1
ratner: 1
rayfield: 1
rbudp: 1
rchitecture: 1
reaction: 1
reactive: 1
readiness: 1
readwrite: 1
realistically: 1
realities: 1
realization: 1
realtime: 1
reardon: 1
reboot: 1
rebuilt: 1
recast: 1
rechecks: 1
recipients: 1
recite: 1
reclamation: 1
recode: 1
recommendation: 1
recommended: 1
recommends: 1
reconfigurable: 1
reconfiguration: 1
reconfigure: 1
reconfiguring: 1
reconnect: 1
reconstruction: 1
recorded: 1
recov: 1
recovrequests: 1
recovthroughput: 1
recurrence: 1
recursive: 1
recursively: 1
redesign: 1
redirect: 1
redirected: 1
redirecting: 1
redisplaying: 1
reedsolomon: 1
referenced: 1
referring: 1
refers: 1
refines: 1
reflectsan: 1
refuse: 1
reg: 1
regenerate: 1
registering: 1
registry: 1
regularity: 1
reid: 1
reiher: 1
reimplementing: 1
relational: 1
relationship: 1
relationships: 1
relayed: 1
religion: 1
relinked: 1
remained: 1
removal: 1
ren: 1
rename: 1
rency: 1
render: 1
renderers: 1
renders: 1
rendezvous: 1
renessea: 1
renewed: 1
rently: 1
reordering: 1
replacements: 1
replicates: 1
reportedly: 1
repre: 1
reprefetch: 1
representa: 1
reproduced: 1
rescuer: 1
researcher: 1
resembles: 1
resend: 1
resetting: 1
reside: 1
resides: 1
resiliency: 1
resolves: 1
resolving: 1
resorting: 1
respected: 1
restarts: 1
restrict: 1
restructured: 1
resumed: 1
retained: 1
retaining: 1
retains: 1
rethese: 1
rethink: 1
retriev: 1
retrieving: 1
reusability: 1
reusable: 1
reuse: 1
reused: 1
revalidate: 1
revealed: 1
revealing: 1
reverts: 1
revisited: 1
revived: 1
revoked: 1
revolution: 1
rewind: 1
rexford: 1
rhee: 1
ricardo: 1
ride: 1
righteous: 1
rio: 1
rive: 1
rlogin: 1
ro: 1
roads: 1
rockell: 1
rocky: 1
rodrigues: 1
rodriguez: 1
rolig: 1
roll: 1
rollback: 1
rolled: 1
rollout: 1
room: 1
rooted: 1
roselli: 1
rotating: 1
rotations: 1
rough: 1
roundrobin: 1
roussel: 1
roy: 1
rss: 1
ru: 1
rubenstein: 1
ruichuan: 1
rush: 1
rushed: 1
rx: 1
saab: 1
sacrificing: 1
saikat: 1
saito: 1
sakoda: 1
salt: 1
sambamurthy: 1
samet: 1
sandber: 1
sankaran: 1
santa: 1
sarana: 1
sarcasm: 1
saroiu: 1
sata: 1
satpep: 1
saturated: 1
saturates: 1
saturating: 1
saturation: 1
savage: 1
saying: 1
says: 1
scaleable: 1
scarce: 1
scenarmobile: 1
scenes: 1
schedule: 1
schematic: 1
schiper: 1
schizophrenic: 1
schlosser: 1
schmidt: 1
schroeder: 1
schuh: 1
schultz: 1
sciascia: 1
scott: 1
screen: 1
screenshots: 1
scripting: 1
scripts: 1
scrutiny: 1
sdns: 1
seagate: 1
searchers: 1
searching: 1
searing: 1
sears: 1
secretly: 1
seeing: 1
seely: 1
seemed: 1
selec: 1
selection: 1
selectively: 1
selfinterested: 1
selforganizing: 1
semanticweb: 1
senses: 1
sensitivfigure: 1
sentative: 1
separating: 1
sequencing: 1
ser: 1
serialised: 1
sericola: 1
serverless: 1
servicing: 1
serving: 1
setceiver: 1
setups: 1
seven: 1
severely: 1
shacham: 1
shaded: 1
shah: 1
shahabi: 1
shalunov: 1
shao: 1
shaped: 1
shapers: 1
shapiro: 1
sharding: 1
shayee: 1
shed: 1
shelf: 1
shenghua: 1
shielding: 1
shim: 1
shipping: 1
shirriff: 1
shop: 1
shopping: 1
shoring: 1
shortcomings: 1
shorter: 1
shouldn: 1
shraer: 1
shrideep: 1
shtml: 1
shupp: 1
shutdown: 1
si: 1
sidebar: 1
siegenthaler: 1
siena: 1
sig: 1
sigkdd: 1
sigmetrics: 1
signature: 1
signed: 1
signers: 1
significance: 1
signing: 1
silberstein: 1
silently: 1
similarities: 1
similarity: 1
simon: 1
simulaneous: 1
simulates: 1
singhai: 1
sintek: 1
sishim: 1
sistencies: 1
sitaraman: 1
sits: 1
sivasubramaniam: 1
sive: 1
sjsu: 1
skepticism: 1
sky: 1
skyrocketing: 1
slash: 1
slay: 1
sleeps: 1
slide: 1
slip: 1
slowdowns: 1
sluggish: 1
smartphone: 1
smith: 1
smoothly: 1
snapshots: 1
snooping: 1
soa: 1
socc: 1
sock: 1
softway: 1
solicited: 1
solves: 1
somefound: 1
sonicmq: 1
sonicsoftware: 1
sooner: 1
sophia: 1
sorted: 1
sought: 1
spain: 1
spanningtree: 1
spans: 1
spared: 1
spawned: 1
speaking: 1
speaks: 1
speci: 1
specializes: 1
specificity: 1
specifies: 1
specifying: 1
spectrum: 1
speech: 1
spends: 1
spielman: 1
spiked: 1
spinning: 1
spirits: 1
spix: 1
splay: 1
splitx: 1
sponse: 1
sporting: 1
sports: 1
sprays: 1
spring: 1
squash: 1
squirrelmail: 1
sridharan: 1
srrs: 1
srsr: 1
ssh: 1
stabilizing: 1
stadrops: 1
stafford: 1
stand: 1
standardizing: 1
stanford: 1
stanislav: 1
stanton: 1
startup: 1
starved: 1
starving: 1
statemachine: 1
statems: 1
stationary: 1
statistic: 1
stead: 1
steen: 1
steep: 1
steer: 1
steere: 1
stepping: 1
stipulating: 1
sto: 1
stochastic: 1
stocking: 1
stodolsky: 1
stoica: 1
stor: 1
stordifferent: 1
straight: 1
street: 1
strengths: 1
stretagy: 1
strike: 1
strikes: 1
strikingly: 1
strings: 1
stripped: 1
strongest: 1
stronglytraces: 1
structuring: 1
studying: 1
stumbled: 1
stylistic: 1
suba: 1
subing: 1
subintervals: 1
subj: 1
subkilobyte: 1
submission: 1
subnetworks: 1
subordinate: 1
subramanian: 1
subscribes: 1
subscription: 1
subscriptions: 1
subsections: 1
subsequence: 1
subservicecontrol: 1
subserviceprocess: 1
substandard: 1
substitute: 1
substreams: 1
subtitles: 1
subtransactions: 1
succeeds: 1
successor: 1
sue: 1
suffix: 1
suggestive: 1
sul: 1
summarise: 1
summarised: 1
summarizes: 1
summarizing: 1
summer: 1
sunos: 1
sup: 1
superbowl: 1
superceded: 1
superfluous: 1
superimpose: 1
superior: 1
superlinearly: 1
supersede: 1
superseded: 1
supervisory: 1
supplementing: 1
supposed: 1
suppressing: 1
surely: 1
surements: 1
surge: 1
surplus: 1
surrounding: 1
surtani: 1
survivors: 1
suryanarayana: 1
suspended: 1
sussman: 1
sw: 1
swart: 1
swivel: 1
swws: 1
sympo: 1
syn: 1
synchro: 1
synchronise: 1
synchronizing: 1
systraditional: 1
szeged: 1
szymaniak: 1
tablet: 1
tag: 1
tags: 1
tailor: 1
tains: 1
talking: 1
talks: 1
tam: 1
tamma: 1
tan: 1
tance: 1
tanin: 1
tao: 1
tapped: 1
tapping: 1
tari: 1
taught: 1
tdi: 1
te: 1
technetwork: 1
technicalsessions: 1
technion: 1
technologists: 1
telecommunications: 1
telemetry: 1
templates: 1
tempt: 1
tems: 1
tency: 1
tended: 1
tension: 1
tent: 1
tentative: 1
tention: 1
terleaving: 1
terlinked: 1
terminal: 1
terminate: 1
terminated: 1
testimony: 1
textures: 1
thanks: 1
thefly: 1
ther: 1
thereafter: 1
thereby: 1
thorsten: 1
thrashing: 1
threading: 1
threetier: 1
throughputs: 1
throughxors: 1
tial: 1
tiate: 1
tib: 1
ticast: 1
ticipant: 1
ticker: 1
ticular: 1
tied: 1
tightrope: 1
timecritical: 1
timeframe: 1
timeline: 1
timers: 1
timescales: 1
timesharing: 1
timo: 1
tination: 1
tings: 1
tiple: 1
titles: 1
tity: 1
tively: 1
tivity: 1
todd: 1
todisincentivize: 1
toend: 1
toknow: 1
tokyo: 1
tolercations: 1
tom: 1
tone: 1
tons: 1
toplas: 1
topoltifiers: 1
tortures: 1
touted: 1
traceroute: 1
traf: 1
trafficshaping: 1
trailing: 1
tranasctions: 1
transactionally: 1
transactypes: 1
transcoding: 1
transformed: 1
transis: 1
transit: 1
transitional: 1
translated: 1
translates: 1
translation: 1
translators: 1
translucence: 1
transportation: 1
transporting: 1
travels: 1
treatments: 1
tri: 1
trials: 1
tricks: 1
tried: 1
trillion: 1
trim: 1
trips: 1
truncate: 1
truncated: 1
truong: 1
tsatalos: 1
ttls: 1
tude: 1
tudy: 1
tunable: 1
tung: 1
tuples: 1
turing: 1
tus: 1
tweb: 1
twelth: 1
twin: 1
twitter: 1
twotier: 1
tx: 1
txcache: 1
txn: 1
typed: 1
typwrite: 1
ual: 1
ubicomm: 1
ubiquitously: 1
ublcs: 1
uc: 1
ucb: 1
ufrgs: 1
ular: 1
ulate: 1
ultrareliable: 1
unacceptably: 1
unavoidable: 1
unbe: 1
uncertain: 1
unclustered: 1
unconstrained: 1
uncontrolled: 1
uncorrelated: 1
underdog: 1
undergo: 1
underlies: 1
underneath: 1
underperform: 1
understandable: 1
understanddevices: 1
understands: 1
understood: 1
undertake: 1
undertaken: 1
underutilisation: 1
underway: 1
undesired: 1
undisturbed: 1
unencrypted: 1
unflattering: 1
unfortunate: 1
unidirectional: 1
unifies: 1
uniformally: 1
unilaterally: 1
unintended: 1
uninterference: 1
unites: 1
univ: 1
univerisity: 1
universal: 1
universe: 1
universita: 1
unjustified: 1
unlink: 1
unlinking: 1
unmodified: 1
unnoticed: 1
unparalleled: 1
unrealistic: 1
unreasonable: 1
unrecoverable: 1
unreserved: 1
unresilient: 1
unresolved: 1
unresponsiveness: 1
unrpcs: 1
unspecified: 1
unsuitable: 1
untouched: 1
unusually: 1
unwilling: 1
upare: 1
upcalls: 1
upcan: 1
upcations: 1
upcoming: 1
upgrade: 1
upgrades: 1
upisting: 1
uploads: 1
upreader: 1
upson: 1
upstudies: 1
upthe: 1
upwidth: 1
ures: 1
urgently: 1
url: 1
urls: 1
usages: 1
usdoj: 1
usefully: 1
usermakes: 1
uservisible: 1
utilising: 1
utilized: 1
utilizes: 1
utilizing: 1
utrsut: 1
utt: 1
uture: 1
uut: 1
uutt: 1
validations: 1
vanilla: 1
vanishes: 1
var: 1
variances: 1
vasilatos: 1
vb: 1
vectored: 1
vehicles: 1
veitch: 1
velenis: 1
venkataraman: 1
vercurr: 1
verification: 1
versa: 1
vertical: 1
victims: 1
videos: 1
vidhyashankar: 1
viding: 1
viewer: 1
viewsynchronous: 1
violated: 1
violates: 1
viral: 1
vironment: 1
virtually: 1
virtue: 1
vishnumurthy: 1
visibly: 1
vision: 1
visit: 1
visiting: 1
vista: 1
visualize: 1
visualizing: 1
vital: 1
vivek: 1
vlo: 1
vmm: 1
vms: 1
voelker: 1
vogel: 1
voip: 1
vollset: 1
voluntary: 1
vrable: 1
wa: 1
waived: 1
wallach: 1
wans: 1
warp: 1
wasn: 1
wasteful: 1
wastes: 1
wasting: 1
watches: 1
wave: 1
wcnc: 1
weaken: 1
weakness: 1
webfs: 1
weblogs: 1
webtier: 1
weeks: 1
weighed: 1
welldefined: 1
weng: 1
wes: 1
westerlund: 1
wg: 1
whatsnew: 1
whatsoever: 1
wheeler: 1
whereupon: 1
whiteboard: 1
whitepaper: 1
whithout: 1
wholefile: 1
wicom: 1
widens: 1
wieloch: 1
wilma: 1
windowsnt: 1
winnie: 1
wires: 1
withuated: 1
witnesses: 1
wolf: 1
wonder: 1
woo: 1
woodford: 1
worker: 1
worries: 1
worrisome: 1
worthwhile: 1
wouldn: 1
wrapped: 1
wraps: 1
writclassification: 1
writeaccesses: 1
writeinvalidations: 1
writequirement: 1
writeserver: 1
writetive: 1
writewrite: 1
wrote: 1
wscompatible: 1
wsdl: 1
wspds: 1
wstransactions: 1
wu: 1
xaxis: 1
xcp: 1
xiao: 1
xisting: 1
xperimental: 1
xu: 1
xyx: 1
yaghmazadeh: 1
yann: 1
yaxes: 1
yee: 1
yielded: 1
yin: 1
ylianttila: 1
youtube: 1
yuanchao: 1
yuanyuan: 1
yum: 1
yushprakh: 1
zahorjan: 1
zdonik: 1
zeal: 1
zealous: 1
zelenka: 1
zephyr: 1
zettabyte: 1
zhen: 1
zhenqi: 1
zhou: 1
zhuang: 1
zoomed: 1
zooming: 1
zooms: 1
zou: 1
zuck: 1
zwilling: 1
