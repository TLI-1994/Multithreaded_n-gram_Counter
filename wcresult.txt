web technologies can web
technologies can web services
can web services scale
web services scale up
cornell university i n
university i n the
i n the past
only major internet players
major internet players such
internet players such as
players such as amazon
implementing high performance multicast
high performance multicast in
and google were interested
performance multicast in a
google were interested in
multicast in a managed
were interested in deploying
in a managed environment
interested in deploying large
a managed environment krzysztof
managed environment krzysztof ostrowski
environment krzysztof ostrowski cornell
krzysztof ostrowski cornell university
ostrowski cornell university ken
cornell university ken birman
university ken birman cornell
ken birman cornell university
birman cornell university abstract
cornell university abstract motes
university abstract motes end
this is changing rapidly
transparent error correction for
is changing rapidly all
error correction for communication
changing rapidly all sorts
correction for communication between
user application development using
for communication between data
an adaptive distributed file
rapidly all sorts of
application development using c
communication between data centers
adaptive distributed file system
between data centers mahesh
all sorts of companies
distributed file system for
data centers mahesh balakrishnan
sorts of companies and
file system for mobile
system for mobile hosts
of companies and governmental
for mobile hosts benjamin
companies and governmental organizations
mobile hosts benjamin atkin
hosts benjamin atkin and
and governmental organizations are
benjamin atkin and kenneth
atkin and kenneth p
governmental organizations are suddenly
the company s own
organizations are suddenly looking
company s own products
are suddenly looking towards
s own products are
suddenly looking towards web
own products are still
products are still implemented
looking towards web services
are still implemented primarily
towards web services as
still implemented primarily in
web services as a
implemented primarily in unmanaged
services as a platform
birman department of computer
primarily in unmanaged c
department of computer science
as a platform that
of computer science cornell
a platform that might
computer science cornell university
platform that might support
that might support a
might support a wide
support a wide range
a wide range of
wide range of demanding
range of demanding applications
by building xyx in
building xyx in the
xyx in the recommended
examples of such systems
in the recommended manner
of such systems include
such systems include big
systems include big banking
include big banking and
big banking and brokerage
banking and brokerage data
we found ourselves breaking
and brokerage data centers
found ourselves breaking new
ourselves breaking new ground
online service centers for
service centers for companies
edu abstract mfs using
centers for companies that
the multicast protocols employed
for companies that operate
abstract mfs using file
companies that operate on
multicast protocols employed by
that operate on a
mfs using file access
operate on a global
protocols employed by qsm
on a global scale
using file access traces
employed by qsm were
file access traces from
by qsm were designed
access traces from windows
qsm were designed for
traces from windows nt
were designed for performance
systems to operate critical
designed for performance and
from windows nt and
for performance and scalability
windows nt and unix
to operate critical infrastructures
operate critical infrastructures like
critical infrastructures like electric
infrastructures like electric power
incorporating a mixture of
like electric power and
a mixture of new
electric power and transportation
and a synthetic workload
mixture of new ideas
a synthetic workload designed
of new ideas and
synthetic workload designed to
new ideas and ideas
workload designed to emulate
and government and military
ideas and ideas drawn
designed to emulate sharing
and ideas drawn from
government and military systems
to emulate sharing patterns
ideas drawn from prior
and military systems responsible
drawn from prior systems
emulate sharing patterns seen
military systems responsible for
sharing patterns seen in
systems responsible for everything
patterns seen in mobility
responsible for everything from
seen in mobility is
for everything from intelligence
abstract the global network
everything from intelligence gathering
in mobility is a
the global network of
mobility is a critical
from intelligence gathering to
is a critical feature
global network of data
intelligence gathering to issuing
the aspects on which
gathering to issuing social
network of data centers
to issuing social security
aspects on which we
of data centers is
issuing social security checks
a critical feature of
on which we focus
critical feature of computer
data centers is emerging
feature of computer systems
which we focus here
centers is emerging as
we focus here reflect
is emerging as an
this emerging trend presents
focus here reflect architectural
emerging trend presents developers
emerging as an important
trend presents developers with
and while collaborative engineering
presents developers with a
while collaborative engineering systems
developers with a new
as an important distributed
with a new challenge
here reflect architectural responses
an important distributed systems
reflect architectural responses to
important distributed systems paradigm
architectural responses to scheduling
wireless networks are common
building web services solutions
responses to scheduling delays
web services solutions that
distributed systems paradigm commodity
services solutions that scale
systems paradigm commodity clusters
paradigm commodity clusters running
commodity clusters running high
most applications that run
overheads associated with threads
applications that run on
that run on existing
run on existing work
on existing work in
and costs arising in
a scalable system is
costs arising in the
existing work in cache
arising in the memory
scalable system is one
in the memory management
work in cache management
the memory management subsystem
system is one that
in cache management for
is one that can
cache management for mobile
one that can flexibly
speed lambda networks across
that can flexibly accommodate
management for mobile file
can flexibly accommodate growth
lambda networks across hundreds
flexibly accommodate growth in
for mobile file systems
accommodate growth in its
networks across hundreds of
mobile file systems mobile
growth in its client
over the period during
in its client base
file systems mobile hosts
across hundreds of milliseconds
the period during which
hundreds of milliseconds of
systems mobile hosts lack
of milliseconds of network
period during which qsm
milliseconds of network latency
mobile hosts lack flexible
during which qsm was
such systems typically run
which qsm was developed
hosts lack flexible mechanisms
systems typically run on
lack flexible mechanisms for
typically run on a
flexible mechanisms for data
packet loss on long
run on a clustered
mechanisms for data access
for data access in
on a clustered computer
data access in an
access in an en
a clustered computer or
haul networks can cripple
clustered computer or in
networks can cripple the
computer or in a
can cripple the performance
these had pervasive consequences
or in a large
cripple the performance of
in a large data
the performance of applications
a large data center
performance of applications and
large data center and
of applications and protocols
forcing us to redesign
applications and protocols a
us to redesign and
data center and must
and protocols a loss
to redesign and recode
protocols a loss rate
center and must be
a loss rate as
redesign and recode one
and must be able
loss rate as low
and recode one layer
rate as low as
must be able to
recode one layer of
be able to handle
one layer of the
able to handle high
layer of the system
to handle high loads
of the system after
handle high loads or
the system after another
high loads or sudden
loads or sudden demand
or sudden demand bursts
sudden demand bursts and
demand bursts and a
bursts and a vast
and a vast number
a vast number of
vast number of users
the original system was
original system was multithreaded
is sufficient to reduce
sufficient to reduce tcp
they must reliably respond
must reliably respond even
reliably respond even in
ip throughput by an
respond even in the
throughput by an order
even in the event
by an order of
in the event of
o calls and was
the event of failures
an order of magnitude
event of failures or
calls and was rather
of failures or reconfiguration
incorporates mechanisms for making
order of magnitude on
and was rather casual
of magnitude on a
mechanisms for making efficient
was rather casual about
for making efficient vironment
rather casual about buffering
making efficient vironment with
casual about buffering and
efficient vironment with large
about buffering and caching
vironment with large and
with large and frequent
large and frequent variations
and frequent variations in
frequent variations in network
variations in network connec
the current system is
current system is single
managed and automate as
and automate as many
automate as many routine
use of available bandwidth
as many routine services
many routine services such
routine services such as
services such as backups
such as backups and
as backups and component
backups and component upgrades
and component upgrades as
maelstrom is an edge
it has mostly focused
component upgrades as possible
has mostly focused on
is an edge appliance
mostly focused on tivity
an edge appliance that
edge appliance that masks
appliance that masks packet
and obsessively minimizes memory
that masks packet loss
many settings also require
obsessively minimizes memory consumption
masks packet loss transparently
settings also require security
packet loss transparently and
also require security against
loss transparently and quickly
require security against attempted
transparently and quickly from
security against attempted intrusions
and quickly from inter
against attempted intrusions and
attempted intrusions and distributed
in collaborative work adapting
intrusions and distributed denial
collaborative work adapting existing
work adapting existing systems
adapting existing systems to
existing systems to cope
systems to cope with
to cope with periods
cope with periods of
aggregating traffic for high
with periods of low
periods of low bandwidth
performs well and is
well and is stable
and is stable at
is stable at high
speed encoding and using
stable at high data
encoding and using a
at high data rates
and using a new
using a new forward
particularly when wireless and
a new forward error
when wireless and wired
new forward error correction
wireless and wired users
forward error correction scheme
large scale and under
error correction scheme to
scale and under stress
correction scheme to handle
and wired users share
scheme to handle bursty
wired users share in
to handle bursty loss
users share in a
share in a style
in a style which
the finished system achieves
a style which we
finished system achieves extremely
style which we will
system achieves extremely high
which we will refer
achieves extremely high performance
we will refer to
extremely high performance with
will refer to as
high performance with relatively
refer to as modal
performance with relatively modest
to as modal adaptation
with relatively modest cpu
relatively modest cpu and
modest cpu and memory
cpu and memory loads
the second builds on
when files or databases
second builds on the
builds on the first
on the first and
although our paper is
the first and supports
our paper is not
first and supports a
paper is not about
and supports a way
is not about setting
we describe some techniques
supports a way to
describe some techniques bandwidth
not about setting performance
some techniques bandwidth is
a way to build
techniques bandwidth is high
about setting performance records
way to build scripts
setting performance records the
to build scripts of
performance records the absolute
build scripts of simpler
records the absolute numbers
scripts of simpler transactions
the absolute numbers are
the application communicates normally
absolute numbers are good
some might argue that
when for adapting data
might argue that all
for adapting data access
qsm outperforms the multicast
argue that all reliability
adapting data access to
outperforms the multicast platforms
data access to network
that all reliability needs
access to network variability
the multicast platforms we
to network variability in
all reliability needs can
network variability in the
multicast platforms we ve
variability in the context
reliability needs can be
in the context of
i ntroduction t a
the context of bandwidth
needs can be recast
context of bandwidth falls
ntroduction t a conference
of bandwidth falls below
can be recast in
bandwidth falls below a
t a conference version
falls below a threshold
be recast in terms
platforms we ve worked
recast in terms of
a conference version of
in terms of transactions
we ve worked with
conference version of this
ve worked with in
version of this paper
the application enters a
of this paper appeared
application enters a lowmfs
this paper appeared in
worked with in the
paper appeared in nsdi
with in the past
in the past systems
the past systems that
a client cache manager
past systems that run
the past three decades
systems that run in
client cache manager for
that run in unmanaged
past three decades have
run in unmanaged settings
cache manager for a
three decades have seen
manager for a distributed
decades have seen one
for a distributed file
have seen one failed
a distributed file system
seen one failed attempt
this paper won t
one failed attempt after
paper won t tell
failed attempt after another
won t tell the
attempt after another to
t tell the blow
we bandwidth mode in
after another to build
bandwidth mode in which
another to build everything
mode in which communication
to build everything over
in which communication is
fifth usenix symposium on
build everything over a
usenix symposium on networked
everything over a database
which communication is restricted
over a database system
symposium on networked systems
communication is restricted or
on networked systems design
is restricted or deshow
networked systems design and
restricted or deshow how
systems design and implementation
or deshow how mfs
and it s now
deshow how mfs is
it s now clear
how mfs is able
s now clear that
mfs is able to
we use qsm in
is able to adapt
now clear that many
use qsm in a
clear that many kinds
qsm in a series
able to adapt to
in a series of
to adapt to widely
that many kinds of
adapt to widely varying
a series of experiments
to widely varying bandwidth
many kinds of systems
widely varying bandwidth ferred
series of experiments that
kinds of systems just
of experiments that highlight
of systems just don
experiments that highlight fundamental
systems just don t
that highlight fundamental factors
just don t match
don t match the
t match the model
an application has a
these reveal linkages between
application has a small
reveal linkages between achievable
these intrinsically distributed systems
has a small number
linkages between achievable performance
a small number of
intrinsically distributed systems make
small number of levels
between achievable performance and
number of levels through
distributed systems make use
of levels through the
achievable performance and the
levels through the use
systems make use of
through the use of
performance and the costs
the use of modeless
make use of direct
use of modeless adaptation
and the costs and
ms index terms data
the costs and characteristics
index terms data centers
costs and characteristics of
use of direct communication
and characteristics of the
of direct communication between
and evaluate the possible
characteristics of the managed
direct communication between programs
of the managed framework
evaluate the possible modes
communication between programs via
the possible modes and
between programs via the
possible modes and chooses
programs via the trans
modes and chooses the
doing so sheds light
and chooses the appropriate
so sheds light on
chooses the appropriate one
sheds light on the
current web services standards
the appropriate one based
light on the challenges
web services standards have
appropriate one based on
services standards have many
on the challenges of
standards have many critical
he emergence of commodity
one based on the
have many critical limitations
emergence of commodity clusters
the challenges of working
based on the benefit
of commodity clusters and
challenges of working in
on the benefit of
commodity clusters and data
of working in a
the benefit of mechanisms
clusters and data centers
working in a kind
benefit of mechanisms for
and data centers has
of mechanisms for improving
in a kind of
data centers has enabled
mechanisms for improving file
today s web services
for improving file system
centers has enabled a
improving file system performance
s web services standards
has enabled a new
file system performance currently
a kind of environment
system performance currently available
enabled a new class
performance currently available bandwidth
kind of environment that
a new class of
web services standards seem
of environment that will
new class of globally
services standards seem to
environment that will be
class of globally distributed
that will be more
standards seem to answer
will be more and
seem to answer these
be more and more
to answer these needs
of globally distributed highperformance
more and more prevalent
in the coda file
and more prevalent in
globally distributed highperformance applications
more prevalent in years
the coda file and
distributed highperformance applications that
prevalent in years to
coda file and cache
highperformance applications that coordinate
file and cache consistency
in years to come
and cache consistency using
applications that coordinate over
a more probing analysis
cache consistency using microbenchmarks
more probing analysis reveals
consistency using microbenchmarks and
probing analysis reveals many
using microbenchmarks and file
analysis reveals many critical
microbenchmarks and file system
that coordinate over vast
and file system system
reveals many critical limitations
coordinate over vast geographical
over vast geographical distances
our insights should be
insights should be of
should be of value
be of value to
of value to developers
value to developers of
to developers of other
developers of other high
a financial firm s
financial firm s new
the major web services
firm s new york
performance communication and event
s new york city
major web services standards
new york city data
web services standards dealing
york city data center
services standards dealing with
city data center may
standards dealing with reliability
data center may receive
the cache manager operates
center may receive real
cache manager operates in
manager operates in either
operates in either a
in either a stronglytraces
time updates from a
updates from a stock
from a stock exchange
a stock exchange in
stock exchange in switzerland
conduct financial transactions with
financial transactions with banks
we propose a new
reliability provides for reliable
propose a new positioning
transactions with banks in
provides for reliable handoff
with banks in asia
a new positioning of
for reliable handoff between
new positioning of multicast
reliable handoff between a
positioning of multicast technology
which affects the policy
handoff between a client
affects the policy for
cache data in london
the policy for writing
between a client system
policy for writing changes
data in london for
a client system and
as an extension of
for writing changes to
in london for locality
writing changes to files
an extension of the
client system and a
extension of the component
changes to files back
of the component integration
to files back to
london for locality and
files back to the
the component integration features
back to the server
for locality and mirror
system and a queuing
locality and mirror it
component integration features of
and mirror it to
and a queuing system
mirror it to kansas
integration features of the
it to kansas for
modal adaptation schemes are
to kansas for disaster
adaptation schemes are well
a queuing system residing
features of the microsoft
queuing system residing between
system residing between the
residing between the client
between the client and
the client and some
client and some service
net managed runtime environment
introduction in which changes
to interconnect these bandwidth
in which changes in
which changes in bandwidth
changes in bandwidth are
in bandwidth are relatively
bandwidth are relatively predictable
hungry data centers across
data centers across the
the standard isn t
centers across the globe
standard isn t nearly
such as switching network
isn t nearly as
as switching network access
t nearly as comprehensive
switching network access from
nearly as comprehensive as
network access from an
although we started with
as comprehensive as the
we started with a
comprehensive as the name
started with a sophisticated
as the name implies
with a sophisticated multicast
access from an ethernet
a sophisticated multicast protocol
from an ethernet to
organizations are increasingly deploying
an ethernet to a
are increasingly deploying private
ethernet to a modem
increasingly deploying private lambda
deploying private lambda networks
experiments reveal a series
reveal a series of
it s limited to
a series of problematic
s limited to pipelines
but mobility is now
limited to pipelines that
mobility is now an
raw bandwidth is ubiquitous
series of problematic interactions
to pipelines that include
of problematic interactions between
pipelines that include queuing
problematic interactions between its
that include queuing subsystems
interactions between its high
bandwidth is ubiquitous and
is now an major
is ubiquitous and cheaply
now an major feature
ubiquitous and cheaply available
an major feature of
and cheaply available in
major feature of computer
cheaply available in the
feature of computer systems
available in the form
in the form of
the form of existing
processing logic and the
form of existing dark
logic and the properties
of existing dark fiber
and the properties of
over the not as
the properties of the
the not as appropriate
properties of the managed
not as appropriate in
of the managed framework
as appropriate in for
reliability boils down to
appropriate in for wireless
in for wireless networks
boils down to a
down to a few
running and maintaining high
to a few options
in which bandwidth past
a few options that
which bandwidth past decade
few options that a
options that a client
that a client can
a client can use
client can use to
free networks over this
can use to tell
networks over this fiber
use to tell the
held devices capable of
over this fiber is
we addressed these and
this fiber is difficult
devices capable of wireless
fiber is difficult and
addressed these and achieved
is difficult and expensive
capable of wireless availability
to tell the queuing
of wireless availability is
these and achieved high
wireless availability is less
tell the queuing system
availability is less predictable
and achieved high performance
is less predictable and
the queuing system whether
less predictable and varies
achieved high performance by
predictable and varies over
capacity optical links are
high performance by making
and varies over a
optical links are almost
performance by making some
links are almost never
queuing system whether or
are almost never congested
by making some unusual
varies over a larger
making some unusual architectural
over a larger possible
some unusual architectural decisions
a larger possible network
system whether or not
larger possible network access
they drop packets for
whether or not to
drop packets for numerous
possible network access have
or not to reissue
network access have become
packets for numerous reasons
not to reissue a
access have become common
to reissue a request
for numerous reasons dirty
reissue a request if
which we distill into
a request if a
we distill into general
request if a failure
distill into general insights
and wireless networks are
if a failure occurs
wireless networks are range
component integration environments such
integration environments such as
and a way to
the notion of insufficient
a way to timestamp
notion of insufficient bandwidth
environments such as microsoft
of insufficient bandwidth can
way to timestamp requests
insufficient bandwidth can vary
to timestamp requests so
bandwidth can vary dependalso
timestamp requests so that
can vary dependalso proliferating
requests so that a
so that a service
that a service can
a service can detect
service can detect duplicates
applications that run on
ee have become widely
that run on hosts
have become widely popular
run on hosts in
become widely popular with
on hosts in wireless
widely popular with application
hosts in wireless neting
popular with application developers
in wireless neting on
wireless neting on how
neting on how much
transactions actually consists of
on how much data
actually consists of two
how much data the
consists of two side
much data the application
who benefit from standardized
data the application is
benefit from standardized memory
the application is trying
from standardized memory management
application is trying to
is trying to send
so that works must
that works must cope
works must cope with
one is aimed at
must cope with constraints
is aimed at applications
cope with constraints on
aimed at applications that
with constraints on access
at applications that perform
constraints on access to
applications that perform database
on access to data
that perform database transactions
and performance analysis tools
perform database transactions with
access to data that
database transactions with the
performance analysis tools that
transactions with the usual
to data that are
with the usual acid
analysis tools that operate
data that are genit
tools that operate across
that are genit may
that operate across component
are genit may make
operate across component boundaries
genit may make sense
may make sense to
make sense to adjust
sense to adjust network
to adjust network usage
this paper describes quicksilver
adjust network usage when
paper describes quicksilver scalable
for example and in
describes quicksilver scalable multicast
network usage when the
example and in different
usage when the bandwidth
and in different patterns
when the bandwidth erally
the bandwidth erally not
bandwidth erally not present
erally not present in
not present in wired
present in wired networks
ranging from singleton drops
from singleton drops to
singleton drops to extended
drops to extended bursts
distance from a base
from a base stadrops
a base stadrops by
base stadrops by half
or the remote procedure
a new multicast platform
rather than just when
new multicast platform designed
the remote procedure call
multicast platform designed to
remote procedure call and
platform designed to achieve
procedure call and that
designed to achieve high
call and that can
than just when it
and that can t
just when it falls
that can t tolerate
when it falls to
can t tolerate delay
to achieve high performance
it falls to modem
achieve high performance in
high performance in managed
performance in managed environments
these systems lack databases
systems lack databases clean
lack databases clean separation
databases clean separation of
clean separation of stored
memoryrelated overheads and phenomena
separation of stored data
of stored data from
overheads and phenomena related
stored data from code
contention with other hosts
and phenomena related to
with other hosts or
other hosts or processes
noncongestion loss has been
hosts or processes on
loss has been observed
or processes on the
and any attempt to
processes on the same
phenomena related to scheduling
has been observed on
related to scheduling are
been observed on long
any attempt to force
on the same host
to scheduling are shown
attempt to force them
scheduling are shown to
to force them into
are shown to dominate
haul networks as well
shown to dominate the
force them into that
to dominate the behavior
selecting a mode according
dominate the behavior of
them into that model
the behavior of the
a mode according to
into that model results
mode according to the
behavior of the system
according to the available
that model results in
to the available bandwidth
model results in unacceptable
the available bandwidth can
results in unacceptable loss
available bandwidth can uninterference
in unacceptable loss of
unacceptable loss of performance
we discuss techniques that
discuss techniques that helped
techniques that helped us
and switching between different
that helped us to
switching between different wireless
helped us to alleviate
intrinsically distributed systems are
us to alleviate these
between different wireless media
to alleviate these problems
distributed systems are common
different wireless media all
wireless media all necessarily
media all necessarily constrain
all necessarily constrain communication
and argue that they
and web services will
argue that they reveal
web services will need
that they reveal general
services will need to
they reveal general principles
will need to support
since it ignores what
need to support them
reveal general principles applicable
it ignores what data
general principles applicable to
ignores what data compound
principles applicable to other
what data compound the
applicable to other kinds
data compound the variability
to other kinds of
compound the variability in
other kinds of high
the variability in network
variability in network performance
the existing reliability options
in network performance to
existing reliability options simply
network performance to which
reliability options simply don
performance to which apthe
options simply don t
to which apthe application
simply don t address
which apthe application actually
don t address the
apthe application actually wants
t address the requirement
application actually wants to
rate protocols and applications
actually wants to send
protocols and applications in
wants to send over
and applications in managed
to send over the
applications in managed settings
send over the network
a lesson from the
lesson from the past
from the past what
the past what sorts
deferplications must adapt if
past what sorts of
must adapt if they
what sorts of scaling
adapt if they are
sorts of scaling and
introduction a component integration
if they are to
of scaling and reliability
a component integration revolution
they are to perform
scaling and reliability features
component integration revolution is
are to perform well
and reliability features are
integration revolution is transforming
reliability features are lacking
revolution is transforming the
features are lacking in
is transforming the development
are lacking in web
transforming the development of
ring writing back all
the development of desktop
lacking in web services
development of desktop applications
in web services standards
writing back all modifications
web services standards today
the inadequacy of commodity
back all modifications to
inadequacy of commodity tcp
all modifications to files
platforms such as windows
modifications to files may
a good example is
to files may not
good example is data
ip in high bandwidthdelay
files may not be
example is data replication
in high bandwidthdelay product
may not be a
high bandwidthdelay product networks
not be a sensible
bandwidthdelay product networks is
be a sensible this
product networks is extensively
ee promote an application
networks is extensively documented
building a server that
a sensible this paper
a server that scales
promote an application development
server that scales to
sensible this paper focuses
an application development style
that scales to handle
this paper focuses on
application development style in
scales to handle load
development style in which
paper focuses on adaptation
style in which components
to handle load often
in which components are
focuses on adaptation techniques
which components are implemented
handle load often requires
components are implemented independently
on adaptation techniques for
are implemented independently and
load often requires replicating
implemented independently and heavily
adaptation techniques for management
often requires replicating data
techniques for management policy
independently and heavily reused
for management policy if
requires replicating data on
management policy if those
replicating data on multiple
policy if those are
data on multiple nodes
if those are the
on multiple nodes of
by standardizing memory management
multiple nodes of a
standardizing memory management and
nodes of a cluster
those are the only
memory management and type
are the only messages
management and type checking
the only messages available
only messages available to
messages available to send
these platforms enable safe
platforms enable safe and
of data accessed and
enable safe and efficient
data accessed and modified
safe and efficient cross
accessed and modified by
another example is guaranteed
and modified by mobile
example is guaranteed real
modified by mobile hosts
we investigate we describe
investigate we describe mfs
avoiding overheads associated with
overheads associated with protection
associated with protection boundaries
a company that buys
company that buys a
that buys a cluster
buys a cluster probably
a cluster probably wants
cluster probably wants to
ip has three major
a flexible cache adaptation
has three major problems
flexible cache adaptation in
three major problems when
cache adaptation in the
probably wants to guarantee
major problems when used
adaptation in the context
problems when used over
in the context of
when used over such
the context of mfs
used over such networks
wants to guarantee that
to guarantee that some
guarantee that some service
a client cache manager
that some service will
client cache manager for
our project is interested
some service will be
cache manager for a
project is interested in
manager for a manager
service will be responsive
for a manager for
is interested in leveraging
a manager for a
will be responsive enough
manager for a distributed
interested in leveraging these
be responsive enough to
ip suffers throughput collapse
in leveraging these benefits
for a distributed file
responsive enough to keep
a distributed file system
leveraging these benefits to
suffers throughput collapse if
enough to keep its
distributed file system client
to keep its customers
throughput collapse if the
keep its customers happy
these benefits to help
its customers happy even
collapse if the network
benefits to help developers
which differs from distributed
customers happy even when
if the network is
happy even when demand
differs from distributed file
even when demand is
from distributed file system
to help developers implement
the network is even
when demand is high
network is even slightly
help developers implement robust
is even slightly prone
developers implement robust and
we concentrate on distributed
even slightly prone to
concentrate on distributed file
slightly prone to packet
on distributed file systraditional
prone to packet loss
the missing technologies don
implement robust and scalable
missing technologies don t
distributed file systraditional cache
technologies don t stop
robust and scalable computing
file systraditional cache manager
don t stop there
systraditional cache manager design
conservative flow control mechanisms
cache manager design in
and scalable computing services
manager design in two
flow control mechanisms designed
scalable computing services that
design in two important
computing services that will
control mechanisms designed to
in two important respects
mechanisms designed to deal
services that will run
cycle services that can
that will run on
designed to deal with
will run on clusters
services that can launch
run on clusters or
to deal with the
on clusters or in
that can launch an
deal with the systematic
can launch an application
tems because systems in
launch an application on
with the systematic congestion
an application on demand
because systems in this
application on demand or
the systematic congestion of
on demand or restart
systems in this area
demand or restart a
systematic congestion of the
or restart a failed
in this area are
restart a failed component
congestion of the commodity
clusters or in datacenters
of the commodity internet
this area are highly
the commodity internet react
area are highly developed
commodity internet react too
are highly developed and
internet react too sharply
or load balancers and
react too sharply to
early users of our
load balancers and technology
highly developed and have
users of our platform
developed and have mfs
balancers and technology to
and have mfs uses
of our platform are
have mfs uses an
and technology to automate
mfs uses an rpc
our platform are creating
technology to automate management
platform are creating applications
uses an rpc library
to automate management of
an rpc library supporting
are creating applications in
rpc library supporting priorities
automate management of a
library supporting priorities to
creating applications in areas
supporting priorities to enable
management of a machine
priorities to enable modewell
applications in areas such
to enable modewell understood
of a machine cluster
in areas such as
a machine cluster running
areas such as parallelized
machine cluster running web
such as parallelized data
enable modewell understood semantics
as parallelized data mining
cluster running web services
running web services applications
ms w n s
although the techniques we
w n s e
the techniques we describe
event stream filtering software
n s e fig
techniques we describe less
we describe less adaptation
and scalable web services
working groups within the
groups within the world
within the world wide
developers of clustered services
the world wide web
of clustered services need
world wide web consortium
clustered services need reliable
example lambda network ephemeral
services need reliable multicast
lambda network ephemeral loss
need reliable multicast protocols
network ephemeral loss on
reliable multicast protocols for
ephemeral loss on over
which allocates available bandwidth
multicast protocols for data
allocates available bandwidth based
protocols for data replication
available bandwidth based should
bandwidth based should be
based should be broadly
provisioned links a single
should be broadly applicable
links a single packet
be broadly applicable in
a single packet in
and in light of
single packet in ten
broadly applicable in other
packet in ten thousand
applicable in other application
in ten thousand is
in other application environments
in light of our
ten thousand is enough
light of our broader
thousand is enough to
of our broader goal
is enough to reduce
on the types of
our broader goal of
the types of messages
enough to reduce tcp
the primary organization developing
broader goal of leveraging
primary organization developing web
types of messages being
organization developing web services
of messages being sent
developing web services standards
ip throughput to a
goal of leveraging the
throughput to a third
of leveraging the power
to a third over
leveraging the power and
by assigning priorities such
the power and component
a third over a
power and component integration
assigning priorities such as
and component integration features
priorities such as caching
component integration features of
such as caching dynamic
integration features of a
not one is addressing
as caching dynamic internet
features of a managed
one is addressing these
caching dynamic internet content
is addressing these kinds
dynamic internet content or
addressing these kinds of
internet content or caching
these kinds of issues
content or caching to
of a managed framework
and one in a
or caching to improve
one in a thousand
caching to improve appropriately
in a thousand drops
a similar dynamic played
a thousand drops it
similar dynamic played out
the multicast technology must
thousand drops it by
dynamic played out in
drops it by an
played out in the
it by an order
out in the early
by an order of
multicast technology must run
such as retrieving files
technology must run in
an order of magnitude
must run in a
run in a managed
in a managed setting
can the performance of
the performance of interactions
performance of interactions with
of interactions with web
interactions with web services
but little is known
little is known about
is known about highperformance
known about highperformance protocols
about highperformance protocols in
we evaluate proceed concurrently
highperformance protocols in managed
time or interactive applications
evaluate proceed concurrently with
protocols in managed environments
proceed concurrently with background
or interactive applications are
concurrently with background activities
interactive applications are impacted
with background activities such
applications are impacted by
background activities such as
are impacted by the
activities such as writing
impacted by the reliance
such as writing the
by the reliance of
as writing the authors
the reliance of reliability
writing the authors were
reliance of reliability mechanisms
the authors were supported
server computing was touted
of reliability mechanisms on
computing was touted as
reliability mechanisms on acknowledgments
it is interesting to
authors were supported in
is interesting to realize
were supported in part
interesting to realize that
supported in part by
to realize that although
in part by darpa
realize that although microsoft
part by darpa under
was touted as the
mechanisms on acknowledgments and
that although microsoft pro
on acknowledgments and retransmissions
touted as the next
by darpa under afrl
as the next big
darpa under afrl grant
the next big thing
this research was supported
limiting the latency of
research was supported by
the latency of packet
was supported by afrl
under afrl grant radc
latency of packet recovery
afrl grant radc back
of packet recovery to
grant radc back changes
packet recovery to at
a silver bullet to
if with additional support
silver bullet to solve
with additional support from
bullet to solve every
additional support from afosr
under the assurance that
recovery to at least
to solve every problem
to at least the
the assurance that if
at least the round
assurance that if bandwidth
least the round trip
that if bandwidth becomes
the round trip time
if bandwidth becomes f
solve every problem related
every problem related to
problem related to older
related to older mainframe
to older mainframe and
older mainframe and batch
mainframe and batch systems
companies rushed to move
if delivery is sequenced
rushed to move everything
to move everything from
move everything from mainframe
everything from mainframe settings
from mainframe settings to
mainframe settings to client
department of computer science
each lost packet acts
lost packet acts as
there were notable successes
packet acts as a
acts as a virtual
as a virtual road
but it quickly became
it quickly became apparent
quickly became apparent that
block in the fifo
became apparent that the
in the fifo channel
apparent that the early
the fifo channel until
that the early platforms
fifo channel until it
the early platforms were
channel until it is
early platforms were strikingly
until it is recovered
platforms were strikingly immature
processes needed to be
needed to be automated
to be automated and
be automated and standardized
and by afosr under
ip requires massive buffers
and the early generations
requires massive buffers at
the early generations of
by afosr under muri
massive buffers at the
early generations of client
buffers at the communicating
afosr under muri grant
at the communicating endhosts
under muri grant f
the communicating endhosts to
communicating endhosts to fully
server systems cost a
endhosts to fully exploit
systems cost a fortune
to fully exploit the
cost a fortune to
fully exploit the bandwidth
a fortune to build
exploit the bandwidth of
the bandwidth of a
bandwidth of a long
required armies of systems
armies of systems administrators
of systems administrators and
even in the absence
systems administrators and specialists
in the absence of
the absence of packet
absence of packet loss
and were extremely insecure
the total cost of
resistant alternatives to tcp
total cost of ownership
cost of ownership proved
of ownership proved to
ownership proved to be
proved to be unexpectedly
ip is not feasible
to be unexpectedly and
is not feasible in
be unexpectedly and unacceptably
not feasible in corporate
unexpectedly and unacceptably high
feasible in corporate data
the embedding of qsm
in corporate data centers
embedding of qsm into
of qsm into windows
qsm into windows yielded
the lesson of the
into windows yielded an
lesson of the client
where standardization is the
windows yielded an unexpected
standardization is the key
yielded an unexpected benefit
is the key to
the key to low
key to low and
server era is that
to low and predictable
era is that incomplete
low and predictable maintenance
is that incomplete platforms
it enables what we
that incomplete platforms can
and predictable maintenance costs
incomplete platforms can t
enables what we are
platforms can t support
what we are calling
can t support major
we are calling live
are calling live distributed
neither is eliminating loss
calling live distributed objects
is eliminating loss events
rather than the foreground
eliminating loss events on
than the foreground ones
loss events on a
events on a network
as the term suggests
on a network that
my concern is that
a network that could
concern is that the
network that could span
is that the web
that could span thousands
that the web services
could span thousands of
these are abstract data
additional support from microsoft
are abstract data types
support from microsoft research
abstract data types in
from microsoft research and
data types in which
microsoft research and from
span thousands of miles
research and from the
the web services community
types in which content
web services community is
in which content evolves
services community is about
which content evolves over
community is about to
content evolves over time
is about to face
and from the intel
about to face the
from the intel corporation
to face the same
there is a need
face the same problem
is a need to
when an application binds
a need to mask
an application binds to
need to mask loss
application binds to a
to mask loss on
binds to a live
mask loss on the
platform developers are racing
to a live object
loss on the link
application programs background processing
on the link from
developers are racing forward
the link from the
are racing forward at
link from the commodity
racing forward at top
from the commodity protocols
the current state of
the commodity protocols running
forward at top speed
commodity protocols running at
current state of the
programs background processing incoming
protocols running at end
state of the object
background processing incoming traffic
of the object is
jostling for position with
processing incoming traffic cache
for position with ever
the object is imported
position with ever more
incoming traffic cache consistency
with ever more exaggerated
object is imported and
traffic cache consistency demand
ever more exaggerated claims
is imported and the
and to do so
imported and the object
to do so rapidly
cache consistency demand fetch
do so rapidly and
and the object can
while closing their eyes
consistency demand fetch access
closing their eyes to
the object can send
demand fetch access monitoring
their eyes to the
fetch access monitoring prefetch
eyes to the dangerous
so rapidly and transparently
to the dangerous potholes
access monitoring prefetch outgoing
the dangerous potholes in
object can send and
dangerous potholes in the
monitoring prefetch outgoing traffic
can send and receive
potholes in the road
send and receive updates
in the road ahead
and receive updates at
prefetch outgoing traffic synchronous
receive updates at high
updates at high data
because recovery delays for
at high data rates
outgoing traffic synchronous writeback
recovery delays for lost
architectural standards for scalability
traffic synchronous writeback update
standards for scalability to
delays for lost packets
for scalability to properly
synchronous writeback update logging
an object could be
scalability to properly address
object could be a
writeback update logging asynchronous
could be a place
to properly address scalability
be a place in
update logging asynchronous writeback
for lost packets translate
logging asynchronous writeback mfs
lost packets translate into
asynchronous writeback mfs server
packets translate into dramatic
writeback mfs server adaptive
translate into dramatic reductions
properly address scalability in
into dramatic reductions in
mfs server adaptive rpc
dramatic reductions in application
address scalability in web
a place in a
server adaptive rpc library
place in a game
adaptive rpc library mfs
scalability in web services
in a game like
rpc library mfs cache
a game like second
library mfs cache manager
game like second life
mfs cache manager will
cache manager will be
we need more than
manager will be penalised
need more than a
will be penalised first
more than a long
because applications and os
than a long list
applications and os networking
a long list of
and os networking stacks
long list of reliability
os networking stacks in
list of reliability and
modeless adaptation using prioritised
of reliability and management
networking stacks in commodity
adaptation using prioritised communication
reliability and management standards
stacks in commodity data
using prioritised communication also
in commodity data centers
prioritised communication also allows
commodity data centers cannot
communication also allows mfs
data centers cannot be
also allows mfs to
centers cannot be rewritten
we need a new
cannot be rewritten from
need a new methodology
be rewritten from scratch
allows mfs to be
a new methodology suitable
mfs to be more
new methodology suitable for
to be more flexible
methodology suitable for supporting
be more flexible in
live objects are a
more flexible in response
objects are a natural
flexible in response to
are a natural and
in response to bandwidth
a natural and powerful
suitable for supporting a
response to bandwidth variations
for supporting a scalable
to bandwidth variations than
supporting a scalable data
bandwidth variations than would
a scalable data center
natural and powerful idea
variations than would be
scalable data center architecture
than would be possible
would be possible with
be possible with a
possible with a modal
and we plan to
side appliance receiver buffer
we plan to pursue
appliance receiver buffer overflow
plan to pursue the
with a modal scheme
to pursue the concept
pursue the concept in
the concept in future
concept in future work
local recovery locations of
recovery locations of packet
locations of packet loss
of packet loss receive
mfs incorporates a new
incorporates a new cache
a new cache consistency
new cache consistency algorithm
this use of qsm
side appliance receiving end
use of qsm raises
cache consistency algorithm to
of qsm raises performance
consistency algorithm to efficiently
qsm raises performance and
algorithm to efficiently provide
raises performance and scalability
to efficiently provide a
performance and scalability issues
efficiently provide a high
along with pat helland
provide a high degree
with pat helland and
a high degree of
pat helland and dennis
high degree of consistency
helland and dennis shasha
degree of consistency for
and scalability issues beyond
of consistency for access
scalability issues beyond the
consistency for access to
issues beyond the ones
for access to shared
recommends that developers think
access to shared files
maelstrom communication path forward
beyond the ones seen
communication path forward error
the ones seen in
path forward error correction
ones seen in our
which is required for
seen in our original
is required for collaborative
in our original target
required for collaborative work
our original target domain
for collaborative work applications
that developers think in
developers think in terms
think in terms of
in terms of a
is a promising solution
terms of a reliable
the rest of this
of a reliable arraystructured
rest of this paper
a promising solution for
a reliable arraystructured partitioned
promising solution for reliability
of this paper is
solution for reliability over
this paper is organised
for reliability over long
paper is organised as
we leave detailed discussion
reliable arraystructured partitioned service
leave detailed discussion of
is organised as follows
detailed discussion of the
discussion of the idea
of the idea for
the idea for the
idea for the future
implemented as a set
describes the mfs design
as a set of
the mfs design and
a set of reliable
mfs design and differences
set of reliable arraystructured
design and differences from
of reliable arraystructured clustered
and differences from existing
qsm has been available
differences from existing distributed
reliable arraystructured clustered servers
has been available for
packet recovery latency is
been available for free
recovery latency is independent
from existing distributed and
latency is independent of
existing distributed and mobile
is independent of the
distributed and mobile file
independent of the rtt
and mobile file systems
of the rtt of
available for free download
the rtt of the
for free download since
rtt of the link
free download since mid
as well as giving
this architecture offers scalability
well as giving an
architecture offers scalability and
as giving an overview
offers scalability and reliability
while fec codes have
scalability and reliability at
giving an overview of
and reliability at two
an overview of the
reliability at two levels
overview of the mfs
fec codes have been
of the mfs rpc
codes have been used
the mfs rpc library
have been used for
been used for decades
the top level uses
used for decades within
top level uses some
for decades within link
level uses some sort
uses some sort of
some sort of application
describes the use of
the use of prioritised
use of prioritised communication
specific key to partition
of prioritised communication in
key to partition the
and it has a
prioritised communication in mfs
faster commodity processors have
communication in mfs and
it has a number
in mfs and experiments
to partition the service
commodity processors have enabled
partition the service into
processors have enabled packet
the service into subservices
has a number of
mfs and experiments to
a number of users
and experiments to evaluate
experiments to evaluate its
level fec at end
to evaluate its effectiveness
the lower level implements
most working on clustered
lower level implements subservices
working on clustered computing
level implements subservices using
implements subservices using groups
subservices using groups of
using groups of programs
groups of programs that
presents and explains experimental
of programs that run
and explains experimental results
programs that run on
explains experimental results for
that run on multiple
experimental results for the
run on multiple machines
results for the mfs
one large project is
for the mfs prefetching
large project is pairing
the mfs prefetching mechanism
project is pairing qsm
is pairing qsm with
perhaps in a cluster
pairing qsm with high
in a cluster computer
does the same for
speed event stream filtering
the groups replicate data
event stream filtering and
the same for the
stream filtering and data
same for the cache
filtering and data mining
groups replicate data so
and data mining system
for the cache consistency
data mining system to
the cache consistency algorithm
replicate data so that
mining system to obtain
data so that each
system to obtain a
so that each can
to obtain a scalable
that each can handle
each can handle any
can handle any incoming
handle any incoming query
any incoming query for
incoming query for its
query for its range
concludes and describes future
for its range within
and describes future work
its range within the
hosted service capable of
end fec is very
service capable of handling
fec is very attractive
capable of handling very
is very attractive for
of handling very high
very attractive for communication
handling very high event
attractive for communication between
very high event rates
for communication between data
range within the keys
communication between data centers
enabling updates to reach
the most important part
updates to reach all
group used for system
to reach all the
most important part of
used for system management
important part of mfs
reach all the replicas
easy to deploy and
part of mfs is
to deploy and customize
of mfs is the
for system management service
mfs is the cache
system management service b
is the cache manager
management service b x
and does not require
service b x y
does not require specialized
b x y z
not require specialized equipment
x y z x
which intercepts file system
y z x y
require specialized equipment in
intercepts file system operations
specialized equipment in the
z x y z
equipment in the network
a raps that an
x y z x
raps that an e
y z x y
in the network linking
z x y z
the network linking the
x y z a
network linking the data
y z a b
tailer such as amazon
z a b service
file system operations from
a b service c
such as amazon might
linking the data centers
system operations from application
b service c a
operations from application programs
service c a b
as amazon might use
from application programs and
amazon might use to
c a b w
might use to personalize
a b w figure
use to personalize a
application programs and resolves
to personalize a product
programs and resolves them
personalize a product recommendation
endhost fec has two
and resolves them into
fec has two major
resolves them into accesses
has two major issues
depending on the customer
them into accesses to
on the customer s
two major issues first
the customer s profile
into accesses to its
if sets of components
accesses to its local
sets of components are
to its local mfs
of components are replicated
its local mfs cache
it s not transparent
the service ranks matching
local mfs cache or
service ranks matching products
mfs cache or rpcs
ranks matching products differently
cache or rpcs to
requiring modification of the
or rpcs to a
modification of the end
rpcs to a server
the associated multicast groups
matching products differently to
associated multicast groups overlap
products differently to maximize
multicast groups overlap hierarchically
differently to maximize the
the cache manager has
to maximize the chance
cache manager has a
maximize the chance of
manager has a number
the chance of a
has a number of
chance of a purchase
a number of components
the foregoing is the
foregoing is the primary
is the primary use
the primary use scenario
primary use scenario for
those in solid boxes
use scenario for qsm
it s not necessarily
in solid boxes are
s not necessarily rapid
solid boxes are part
if the product is
boxes are part of
are part of the
but may not be
part of the core
may not be the
fec works best over
not be the only
works best over high
be the only one
of the core system
stable traffic rates and
those in dashed boxes
traffic rates and performs
as shown in figure
in dashed boxes are
one could imagine an
dashed boxes are optional
rates and performs poorly
boxes are optional extensions
could imagine an approach
are optional extensions which
and performs poorly if
optional extensions which are
imagine an approach to
performs poorly if the
extensions which are described
poorly if the data
the service assigns the
if the data rate
service assigns the search
which are described in
assigns the search request
are described in subsequent
the search request to
described in subsequent sections
an approach to laying
the data rate in
approach to laying out
data rate in the
search request to the
rate in the channel
request to the racs
in the channel is
to laying out components
the channel is low
to the racs handling
channel is low and
the racs handling all
is low and sporadic
racs handling all ds
laying out components on
mfs overview mfs differs
out components on a
overview mfs differs from
components on a cluster
mfs differs from earlier
on a cluster that
differs from earlier mobile
a cluster that would
from earlier mobile file
cluster that would result
earlier mobile file systems
that would result in
mobile file systems in
would result in irregular
file systems in adjusting
result in irregular layouts
systems in adjusting to
in irregular layouts of
in adjusting to changing
irregular layouts of groups
adjusting to changing network
such as the customer
to changing network conditions
as the customer s
changing network conditions using
the customer s name
network conditions using modeless
customer s name are
qsm can support such
as in a single
conditions using modeless adaptation
s name are equally
can support such layouts
in a single end
name are equally plausible
it comprises a core
comprises a core client
at least to a
least to a degree
the load balancer then
and a number of
load balancer then routes
but for reasons of
balancer then routes the
for reasons of brevity
then routes the request
reasons of brevity the
we present the maelstrom
of brevity the discussion
a number of subsystems
brevity the discussion in
number of subsystems that
the discussion in the
of subsystems that perform
present the maelstrom error
discussion in the remainder
subsystems that perform different
in the remainder of
that perform different kinds
the remainder of the
perform different kinds of
routes the request to
the maelstrom error correction
the request to the
different kinds of adaptation
request to the appropriate
maelstrom error correction appliance
to the appropriate program
remainder of the paper
the appropriate program for
of the paper focuses
appropriate program for processing
the paper focuses on
program for processing in
paper focuses on regular
error correction appliance a
and can be selectively
correction appliance a rack
for processing in this
appliance a rack of
processing in this case
can be selectively enabled
hierarchically structured communication groups
a rack of proxies
structured communication groups with
rack of proxies residing
communication groups with extensive
of proxies residing between
groups with extensive and
proxies residing between a
with extensive and regular
residing between a data
extensive and regular overlap
between a data center
shows the structure of
a data center and
with support for this
the structure of the
data center and its
initial users of our
center and its wan
users of our system
structure of the system
of our system haven
and its wan link
our system haven t
support for this basic
system haven t had
for this basic layout
haven t had any
in this section we
t had any difficulty
this section we describe
had any difficulty with
section we describe the
any difficulty with this
it s possible to
we describe the core
s possible to tackle
describe the core system
possible to tackle a
difficulty with this constraint
to tackle a wide
tackle a wide range
a wide range of
while subsequent sections do
wide range of secondary
subsequent sections do the
range of secondary issues
knowing qsm is particularly
sections do the same
qsm is particularly effective
do the same for
is particularly effective with
the same for the
particularly effective with regular
maelstrom encodes fec packets
same for the three
encodes fec packets over
effective with regular layouts
fec packets over traffic
we could create standards
packets over traffic flowing
could create standards for
for the three main
over traffic flowing through
they just design to
the three main subsystems
create standards for a
traffic flowing through it
just design to favor
flowing through it and
design to favor regularity
through it and routes
standards for a self
it and routes them
we begin with an
and routes them to
begin with an overview
routes them to a
with an overview of
managed raps of racs
usage cases architecture reliable
an overview of mobile
cases architecture reliable multicast
overview of mobile file
architecture reliable multicast is
of mobile file system
reliable multicast is a
mobile file system design
them to a corresponding
or for one that
multicast is a mature
file system design and
to a corresponding appliance
for one that guarantees
a corresponding appliance at
one that guarantees real
corresponding appliance at the
system design and the
is a mature area
appliance at the destination
design and the relation
at the destination data
and the relation of
the destination data center
the relation of mfs
but a review of
such a basic architecture
a review of prior
a basic architecture is
which decodes them and
basic architecture is effectively
relation of mfs to
architecture is effectively a
of mfs to previous
is effectively a framework
decodes them and recovers
review of prior systems
mfs to previous work
of prior systems convinced
them and recovers lost
prior systems convinced us
effectively a framework to
systems convinced us that
a framework to resolve
convinced us that no
and recovers lost data
us that no existing
framework to resolve other
that no existing system
to resolve other related
no existing system would
then briefly describe the
existing system would work
briefly describe the adaptive
system would work well
maelstrom is completely transparent
would work well in
describe the adaptive rpc
resolve other related issues
is completely transparent it
work well in the
completely transparent it does
well in the scenarios
transparent it does not
in the scenarios targeted
it does not require
the scenarios targeted by
does not require modification
scenarios targeted by our
not require modification of
targeted by our project
require modification of end
group replication web services
the adaptive rpc library
replication web services currently
adaptive rpc library used
web services currently lacks
rpc library used in
services currently lacks support
this forced us to
currently lacks support for
forced us to build
lacks support for building
library used in mfs
host software and is
us to build a
software and is agnostic
support for building scalable
to build a new
for building scalable services
and the current mfs
build a new system
and is agnostic to
a new system that
is agnostic to the
new system that combines
agnostic to the network
system that combines features
to the network connecting
the architecture makes it
the current mfs implementation
architecture makes it easy
the network connecting the
that combines features from
makes it easy to
combines features from a
network connecting the data
features from a number
connecting the data centers
from a number of
it easy to build
a number of prior
easy to build a
number of prior systems
to build a single
it eliminates the dependence
mfs design and related
eliminates the dependence of
node server that responds
the dependence of fec
server that responds to
dependence of fec recovery
our decision not to
of fec recovery latency
decision not to use
fec recovery latency on
not to use some
design and related work
that responds to requests
recovery latency on the
to use some existing
and related work the
use some existing multicast
related work the core
some existing multicast system
work the core of
existing multicast system reflects
the core of mfs
multicast system reflects a
core of mfs follows
system reflects a number
of mfs follows a
reflects a number of
mfs follows a design
a number of issues
follows a design common
responds to requests from
latency on the data
a design common to
to requests from some
on the data rate
most prior multicast systems
the data rate in
design common to many
requests from some set
prior multicast systems were
data rate in any
common to many mobile
from some set of
multicast systems were designed
rate in any single
systems were designed to
in any single node
to many mobile file
some set of clients
were designed to replicate
many mobile file systems
designed to replicate state
to replicate state within
replicate state within just
state within just a
but there s no
within just a single
node channel by encoding
there s no way
channel by encoding over
just a single group
by encoding over the
a single group at
encoding over the aggregated
single group at a
over the aggregated traffic
s no way to
group at a time
no way to turn
the aggregated traffic leaving
way to turn that
aggregated traffic leaving the
to turn that single
traffic leaving the data
turn that single server
for example a single
leaving the data center
that single server into
example a single distributed
single server into a
a single distributed service
server into a racs
into a racs or
a racs or turn
racs or turn a
or turn a set
turn a set of
some don t support
maelstrom uses a new
a set of racs
uses a new encoding
set of racs into
a new encoding scheme
of racs into a
new encoding scheme called
racs into a raps
encoding scheme called layered
don t support multiple
scheme called layered interleaving
t support multiple groups
support multiple groups at
multiple groups at all
designed especially for time
it would be easy
which use techniques such
would be easy to
use techniques such as
while others have overheads
be easy to bridge
others have overheads linear
easy to bridge the
have overheads linear in
to bridge the gap
overheads linear in the
techniques such as wholefile
sensitive packet recovery in
bridge the gap if
linear in the number
the gap if vendors
in the number of
gap if vendors and
the number of groups
if vendors and platform
number of groups to
vendors and platform builders
of groups to which
and platform builders wanted
groups to which a
platform builders wanted to
packet recovery in the
such as wholefile caching
to which a node
builders wanted to do
recovery in the presence
which a node belongs
and update logging combined
in the presence of
wanted to do so
update logging combined with
the presence of bursty
logging combined with asynchronous
presence of bursty loss
combined with asynchronous writes
we looked at jgroups
to cope with disconnections
structured partitioned service reliable
maelstrom s positioning as
cope with disconnections or
partitioned service reliable array
s positioning as a
with disconnections or intermittent
positioning as a network
disconnections or intermittent connectivity
as a network appliance
a network appliance reflects
network appliance reflects the
appliance reflects the physical
the design of mfs
reflects the physical infrastructure
a component of the
the physical infrastructure of
component of the jboss
physical infrastructure of modern
of the jboss platform
design of mfs is
the jboss platform which
of mfs is closest
jboss platform which runs
mfs is closest in
platform which runs in
is closest in structure
infrastructure of modern data
closest in structure to
of modern data centers
which runs in a
modern data centers clean
runs in a managed
data centers clean insertion
in a managed java
in structure to that
centers clean insertion points
x y z search
clean insertion points for
y z search for
insertion points for proxy
z search for digital
points for proxy devices
search for digital camera
for proxy devices exist
structure to that of
proxy devices exist on
to that of coda
devices exist on the
a managed java framework
for digital camera figure
exist on the high
jgroups wasn t designed
wasn t designed to
speed lambda links that
t designed to support
lambda links that interconnect
example of raps of
links that interconnect individual
designed to support large
of raps of racs
that interconnect individual data
to support large numbers
interconnect individual data centers
support large numbers of
individual data centers to
the service assigns a
data centers to each
large numbers of overlapping
service assigns a digital
centers to each other
assigns a digital camera
numbers of overlapping groups
a digital camera search
digital camera search request
camera search request to
search request to the
maelstrom can operate as
and if configured to
can operate as either
if configured to do
operate as either a
request to the clustered
configured to do so
to the clustered server
as either a passive
the clustered server handling
either a passive or
clustered server handling all
a passive or active
server handling all ds
passive or active device
a host acting as
or active device on
host acting as a
active device on these
acting as a client
there has been a
device on these links
as a client of
and a load balancer
has been a great
a load balancer routes
been a great deal
load balancer routes it
of the three problems
balancer routes it to
a client of an
a great deal of
the three problems of
routes it to the
client of an mfs
great deal of work
three problems of tcp
it to the appropriate
of an mfs file
deal of work on
to the appropriate process
an mfs file system
of work on p
mfs file system runs
file system runs a
system runs a user
maelstrom solves the first
old and familiar technologies
solves the first two
and familiar technologies the
p pubsub and content
familiar technologies the most
pubsub and content delivery
the first two throughput
and content delivery platforms
technologies the most standard
content delivery platforms in
which receives file system
first two throughput collapse
the most standard form
two throughput collapse and
most standard form of
delivery platforms in recent
standard form of system
platforms in recent years
receives file system operations
throughput collapse and realtime
form of system support
collapse and realtime recovery
of system support for
file system operations intercepted
system support for building
system operations intercepted by
support for building a
often oriented towards content
for building a raps
oriented towards content filtering
building a raps of
towards content filtering in
and realtime recovery delays
operations intercepted by a
realtime recovery delays while
content filtering in document
recovery delays while operating
filtering in document streams
a raps of racs
intercepted by a kernel
delays while operating as
raps of racs would
while operating as a
of racs would draw
operating as a passive
racs would draw on
as a passive device
a good example is
a passive device that
good example is siena
passive device that does
would draw on virtual
by a kernel module
device that does not
draw on virtual synchrony
a system that has
that does not intervene
system that has become
interacting with the vfs
does not intervene in
that has become popular
with the vfs layer
has become popular in
the vfs layer of
become popular in wan
vfs layer of the
popular in wan settings
layer of the local
not intervene in the
group computing model developed
of the local file
computing model developed at
intervene in the critical
model developed at cornell
the local file system
in the critical communication
developed at cornell in
the critical communication path
at cornell in the
we adopt the same
adopt the same approach
the same approach to
same approach to intercepting
approach to intercepting vfs
to intercepting vfs operations
intercepting vfs operations as
vfs operations as lbfs
maelstrom handles the additional
handles the additional problem
the additional problem of
systems in this class
making use of the
in this class incur
use of the kernel
this class incur steep
of the kernel module
class incur steep overheads
s and used today
incur steep overheads associated
and used today to
steep overheads associated with
used today to run
overheads associated with content
today to run the
associated with content filtering
to run the new
the kernel module provided
run the new york
kernel module provided as
the new york and
module provided as part
new york and swiss
provided as part of
york and swiss stock
as part of the
additional problem of massive
part of the arla
problem of massive buffering
and swiss stock exchange
of the arla afs
messages often follow circuitous
of massive buffering requirements
swiss stock exchange systems
the arla afs client
often follow circuitous routes
massive buffering requirements as
follow circuitous routes from
buffering requirements as well
the french air traffic
circuitous routes from source
french air traffic control
routes from source to
air traffic control system
at the cost of
from source to destination
the cost of adding
cost of adding a
of adding a point
adding a point of
and the us navy
a point of failure
the us navy s
point of failure in
the cache manager maintains
us navy s aegis
in high performance settings
cache manager maintains a
of failure in the
manager maintains a cache
failure in the network
maintains a cache of
in the network path
these factors would degrade
a cache of recently
factors would degrade the
ibm s websphere platform
would degrade the performance
s websphere platform and
degrade the performance of
accessed mfs files on
the performance of the
mfs files on the
websphere platform and the
files on the local
the contributions of this
performance of the replicated
platform and the windows
on the local disk
and the windows vista
of the replicated application
the windows vista clustering
contributions of this paper
windows vista clustering system
of this paper are
vista clustering system also
this paper are as
clustering system also use
paper are as follows
system also use versions
when a vfs operation
the spread multicast system
also use versions of
spread multicast system implements
use versions of the
multicast system implements lightweight
versions of the model
system implements lightweight groups
a vfs operation is
vfs operation is intercepted
operation is intercepted for
is intercepted for a
intercepted for a file
end fec for long
although developers can t
for a file that
developers can t access
a file that is
can t access the
file that is not
distance communication between data
that is not in
communication between data centers
is not in the
t access the internal
not in the cache
access the internal mechanisms
the internal mechanisms directly
and argue that the
argue that the rate
it is retrieved in
that the rate sensitivity
the other popular standard
is retrieved in full
other popular standard uses
retrieved in full from
popular standard uses a
in full from the
standard uses a state
full from the appropriate
the rate sensitivity of
the groups seen by
rate sensitivity of fec
groups seen by applications
sensitivity of fec codes
seen by applications are
machine approach to guarantee
from the appropriate server
of fec codes and
by applications are an
approach to guarantee stronger
and the vfs operation
to guarantee stronger durability
the vfs operation is
applications are an illusion
fec codes and the
vfs operation is then
codes and the opacity
operation is then resumed
and the opacity of
leslie lamport s paxos
the opacity of their
lamport s paxos algorithm
opacity of their implementations
there is really only
of their implementations present
mfs uses the writeback
their implementations present major
is really only one
implementations present major obstacles
really only one use
present major obstacles to
which is implemented in
only one use of
is implemented in scalable
major obstacles to their
close semantics first implemented
one use of qsm
implemented in scalable file
semantics first implemented in
in scalable file systems
first implemented in the
scalable file systems and
implemented in the andrew
use of qsm in
in the andrew file
obstacles to their usage
file systems and other
of qsm in our
the andrew file system
qsm in our target
systems and other ultrareliable
in our target settings
and other ultrareliable server
our target settings gives
other ultrareliable server designs
target settings gives rise
a gateway appliance that
settings gives rise to
gateway appliance that transparently
gives rise to potentially
appliance that transparently aggregates
rise to potentially large
that transparently aggregates traffic
to potentially large numbers
transparently aggregates traffic and
potentially large numbers of
aggregates traffic and encodes
large numbers of overlapping
traffic and encodes over
numbers of overlapping communication
one architecture could support
of overlapping communication groups
architecture could support both
and encodes over the
when a dirty file
could support both of
encodes over the resulting
a dirty file is
support both of these
as we have seen
over the resulting high
dirty file is closed
both of these powerful
of these powerful technologies
the primary goal is
the entire file contents
primary goal is to
entire file contents are
we describe layered interleaving
goal is to support
a natural option would
file contents are transferred
natural option would be
is to support data
a new fec scheme
to support data replication
contents are transferred to
option would be to
support data replication in
new fec scheme used
are transferred to the
would be to offer
data replication in scalable
fec scheme used by
transferred to the server
scheme used by maelstrom
be to offer them
used by maelstrom where
to offer them in
by maelstrom where for
offer them in the
maelstrom where for constant
them in the context
where for constant encoding
in the context of
for constant encoding overhead
the context of ws
in which sets of
constant encoding overhead the
which sets of components
though scheme for minimising
sets of components are
scheme for minimising bandwidth
of components are interconnected
for minimising bandwidth utilisation
components are interconnected and
minimising bandwidth utilisation when
are interconnected and cooperate
bandwidth utilisation when transferring
interconnected and cooperate to
utilisation when transferring files
and cooperate to perform
when transferring files is
cooperate to perform requests
transferring files is not
encoding overhead the latency
files is not used
overhead the latency of
is not used in
the latency of packet
not used in mfs
latency of packet recovery
of packet recovery degrades
packet recovery degrades gracefully
if you re replicating
components sets are normally
you re replicating data
recovery degrades gracefully as
re replicating data within
degrades gracefully as losses
replicating data within some
gracefully as losses get
sets are normally colocated
as losses get burstier
data within some form
although it is orthogonal
within some form of
it is orthogonal to
some form of group
is orthogonal to mfs
we discuss implementation considerations
orthogonal to mfs adaptation
when a service is
to mfs adaptation and
a service is replicated
you can just as
mfs adaptation and could
can just as easily
adaptation and could be
just as easily imagine
we built two versions
as easily imagine that
built two versions of
easily imagine that it
and could be added
imagine that it has
could be added to
that it has a
be added to further
two versions of maelstrom
added to further improve
each of its constituent
it has a subject
of its constituent components
has a subject name
its constituent components will
to further improve performance
constituent components will need
a subject name in
one runs in user
components will need to
subject name in a
the server that stores
name in a publish
will need to replicate
server that stores a
runs in user mode
need to replicate its
that stores a file
to replicate its portion
stores a file is
replicate its portion of
a file is responsible
while the other runs
its portion of the
file is responsible for
advantages with this type
is responsible for maintaining
the other runs within
portion of the service
with this type of
responsible for maintaining the
other runs within the
for maintaining the mutual
of the service state
maintaining the mutual consistency
this type of process
runs within the linux
the mutual consistency of
within the linux kernel
mutual consistency of the
if qsm is used
consistency of the copies
qsm is used to
of the copies cached
we evaluate maelstrom on
is used to disseminate
data can be anything
used to disseminate updates
the copies cached by
evaluate maelstrom on emulab
copies cached by clients
this results in a
results in a pattern
it records which clients
in a pattern of
records which clients cache
a pattern of communication
which clients cache the
pattern of communication groups
clients cache the file
of communication groups that
communication groups that are
groups that are exactly
that are exactly overlapped
and is responsible for
and show that it
is responsible for notifying
show that it provides
responsible for notifying them
that it provides near
for notifying them of
it provides near lossless
each replicated component will
provides near lossless tcp
notifying them of changes
replicated component will have
component will have one
will have one or
have one or more
ip throughput and latency
mfs implements a variation
throughput and latency over
implements a variation of
and latency over lossy
a variation of the
latency over lossy links
variation of the scheme
one or more associated
w e b te
of the scheme used
or more associated groups
and recovers packets with
the scheme used by
recovers packets with latency
scheme used by coda
e b te c
packets with latency independent
b te c h
delivering update streams to
when a file is
with latency independent of
te c h n
latency independent of the
a file is retrieved
independent of the rtt
update streams to its
of the rtt of
streams to its replicas
the rtt of the
file is retrieved from
c h n o
rtt of the link
h n o l
is retrieved from the
n o l o
of the link and
o l o g
a datacenter will typically
l o g i
datacenter will typically host
the link and the
retrieved from the server
o g i e
will typically host many
link and the rate
g i e s
typically host many services
i e s concerns
and the rate in
e s concerns experience
the server issues a
s concerns experience with
the rate in any
concerns experience with corba
each with a disjoint
experience with corba even
with a disjoint set
server issues a limited
rate in any single
with corba even good
a disjoint set of
corba even good ideas
disjoint set of components
in any single channel
even good ideas can
good ideas can be
ideas can be used
obliging it to inform
can be used in
it to inform the
and often deployed on
to inform the client
often deployed on disjoint
inform the client through
deployed on disjoint sets
the client through a
on disjoint sets of
client through a callback
disjoint sets of nodes
through a callback if
m odel loss model
be used in ways
a callback if another
used in ways that
callback if another host
in ways that developers
in cases where two
packet loss typically occurs
cases where two services
loss typically occurs at
where two services are
typically occurs at two
two services are co
occurs at two points
ways that developers dislike
if another host modifies
that developers dislike and
another host modifies the
developers dislike and ultimately
host modifies the file
dislike and ultimately reject
at two points in
located on the same
two points in an
on the same node
if the callback promise
points in an end
the callback promise expires
a good example of
callback promise expires without
promise expires without a
good example of this
expires without a callback
we ll still see
example of this occurred
ll still see heavy
without a callback being
of this occurred when
a callback being issued
still see heavy overlap
this occurred when the
end communication path between
communication path between two
occurred when the corba
path between two data
the client must revalidate
but unless the degree
when the corba community
between two data centers
client must revalidate the
unless the degree of
the corba community decided
must revalidate the file
the degree of replication
corba community decided to
as shown in figure
revalidate the file before
degree of replication is
community decided to tackle
the file before using
of replication is identical
decided to tackle replication
file before using it
to tackle replication for
area network connecting them
tackle replication for fault
network connecting them and
there may be two
the cache consistency algorithm
connecting them and at
cache consistency algorithm is
them and at the
consistency algorithm is described
and at the receiving
algorithm is described in
at the receiving end
is described in more
may be two cases
replication for fault tolerance
described in more detail
for fault tolerance but
in more detail in
fault tolerance but then
nodes that host both
more detail in section
loss in the lambda
that host both services
tolerance but then stumbled
in the lambda link
but then stumbled by
the lambda link can
then stumbled by presenting
and hence both sets
stumbled by presenting the
lambda link can occur
by presenting the technology
link can occur for
hence both sets of
can occur for many
both sets of qsm
occur for many reasons
sets of qsm groups
presenting the technology to
the technology to developers
technology to developers in
to developers in a
developers in a way
adaptive rpc library the
in a way that
rpc library the fundamental
a way that was
and nodes that just
library the fundamental difference
way that was much
dirty or degraded fiber
that was much too
nodes that just host
the fundamental difference between
was much too limiting
fundamental difference between mfs
that just host one
difference between mfs and
just host one of
malfunctioning or misconfigured equipment
much too limiting for
between mfs and other
host one of them
mfs and other file
too limiting for general
and other file systems
limiting for general use
low receiver power and
other file systems we
receiver power and burst
cluster management systems use
file systems we have
management systems use groups
systems we have described
systems use groups for
we have described is
use groups for purposes
have described is in
power and burst switching
groups for purposes other
tolerance mechanism is based
described is in the
and burst switching contention
for purposes other than
mechanism is based on
is in the communication
burst switching contention are
purposes other than component
is based on the
in the communication between
switching contention are some
the communication between the
other than component replication
communication between the cache
contention are some reasons
based on the virtual
between the cache manager
on the virtual synchrony
the cache manager and
such as tracking node
the virtual synchrony model
as tracking node status
cache manager and servers
tracking node status and
node status and launching
status and launching applications
but the programming tools
while lbfs uses a
the programming tools built
lbfs uses a variant
programming tools built over
these groups will span
tools built over this
groups will span large
built over this model
will span large numbers
over this model prevent
span large numbers of
uses a variant of
large numbers of nodes
this model prevent developers
a variant of the
model prevent developers from
variant of the nfs
prevent developers from using
of the nfs rpc
developers from using threads
the nfs rpc protocol
perhaps the entire cluster
such groups overlap with
groups overlap with everything
the result is an
guis or other direct
result is an environment
or other direct end
is an environment in
an environment in which
environment in which there
in which there will
which there will be
there will be a
will be a hierarchy
uses a customised rpc
unlike coda s rpc
the rpc used in
rpc used in mfs
used in mfs incorporates
in mfs incorporates novel
mfs incorporates novel features
incorporates novel features to
or even prebuilt libraries
novel features to allow
features to allow it
to allow it to
allow it to adapt
it to adapt to
to adapt to network
in the corba approach
adapt to network variability
loss can also occur
qsm is highly effective
can also occur at
is highly effective in
also occur at receiving
highly effective in supporting
occur at receiving end
effective in supporting this
the mfs rpc library
in supporting this style
mfs rpc library is
supporting this style of
a developer who obeys
hosts within the destination
this style of use
rpc library is implemented
developer who obeys this
within the destination data
who obeys this long
the destination data center
library is implemented on
obeys this long list
is implemented on top
this long list of
implemented on top of
long list of constraints
these are usually cheap
list of constraints can
are usually cheap commodity
of constraints can do
on top of the
constraints can do lockstep
usually cheap commodity machines
recover in y inter
can do lockstep replication
top of the adaptive
do lockstep replication of
of the adaptive transport
lockstep replication of a
the adaptive transport protocol
replication of a program
cheap commodity machines prone
region protocol y intra
commodity machines prone to
of a program for
machines prone to temporary
a program for tolerance
prone to temporary overloads
program for tolerance of
to temporary overloads that
for tolerance of hardware
temporary overloads that cause
consisting of a small
overloads that cause packets
of a small set
in discussing mfs rpc
a small set of
that cause packets to
tolerance of hardware faults
we give an overview
cause packets to be
small set of servers
give an overview of
packets to be dropped
an overview of the
set of servers to
overview of the parts
of servers to which
to be dropped by
of the parts of
servers to which client
be dropped by the
the scheme doesn t
the parts of atp
to which client systems
dropped by the kernel
scheme doesn t protect
parts of atp which
which client systems connect
by the kernel in
doesn t protect against
of atp which are
the kernel in bursts
t protect against software
atp which are most
which are most relevant
are most relevant to
most relevant to mfs
level multicast is vectored
multicast is vectored through
is vectored through a
vectored through a server
atp and its design
and its design motivations
its design motivations have
developers regard the standard
design motivations have been
regard the standard as
motivations have been described
the standard as rigid
have been described in
which multicasts it to
this loss mode occurs
standard as rigid and
been described in more
multicasts it to its
loss mode occurs with
as rigid and limited
described in more detail
it to its peers
mode occurs with udp
in more detail in
they need fault tolerance
more detail in our
detail in our earlier
these filter the ordered
based traffic but not
filter the ordered multicast
but not in this
the ordered multicast stream
not in this very
ordered multicast stream and
in this very narrow
multicast stream and relay
in our earlier work
traffic but not with
this very narrow form
stream and relay messages
but not with tcp
and relay messages back
relay messages back out
messages back out to
back out to receivers
systems like the isis
like the isis toolkit
this approach can support
which advertises receiver windows
approach can support huge
advertises receiver windows to
can support huge numbers
receiver windows to prevent
popular during the early
the hypothesis underlying atp
windows to prevent end
hypothesis underlying atp is
during the early and
underlying atp is that
the early and mid
atp is that adapting
support huge numbers of
is that adapting to
huge numbers of groups
what are typical loss
numbers of groups with
are typical loss rates
of groups with irregular
typical loss rates on
that adapting to network
loss rates on long
groups with irregular overlap
adapting to network variation
with irregular overlap patterns
to network variation by
network variation by structuring
variation by structuring applications
by structuring applications according
structuring applications according to
but the servers are
also used virtual synchrony
the servers are a
applications according to modes
servers are a point
according to modes is
the answer to this
used virtual synchrony but
are a point of
to modes is not
answer to this question
virtual synchrony but had
a point of contention
modes is not always
to this question is
synchrony but had fewer
is not always appropriate
this question is surprisingly
but had fewer limitations
and the indirect communication
question is surprisingly hard
the indirect communication pathway
is surprisingly hard to
indirect communication pathway introduces
and can sometimes lead
communication pathway introduces potentially
they supported many of
can sometimes lead to
pathway introduces potentially high
supported many of the
sometimes lead to poor
many of the mechanisms
introduces potentially high latencies
lead to poor performance
of the mechanisms needed
the mechanisms needed to
mechanisms needed to build
needed to build and
these considerations convinced us
to build and manage
considerations convinced us that
build and manage a
convinced us that a
and manage a raps
shows the results of
us that a new
the results of an
manage a raps of
results of an experiment
that a new system
of an experiment in
a raps of racs
an experiment in which
a new system was
experiment in which modeless
new system was needed
in which modeless adaptation
and their successes have
which modeless adaptation over
their successes have clearly
modeless adaptation over atp
successes have clearly demonstrated
adaptation over atp achieves
have clearly demonstrated the
over atp achieves higher
qsm implements a approach
atp achieves higher bandwidth
implements a approach similar
achieves higher bandwidth utilisation
clearly demonstrated the model
higher bandwidth utilisation than
demonstrated the model s
bandwidth utilisation than we
a approach similar to
the model s effectiveness
utilisation than we will
approach similar to spread
than we will concentrate
similar to spread s
isis is no longer
we will concentrate on
to spread s lightweight
is no longer available
will concentrate on a
spread s lightweight group
no longer available as
concentrate on a system
s lightweight group abstraction
longer available as a
on a system with
available as a product
a system with a
system with a single
but without a separate
with a single server
without a separate server
yet many critical systems
a separate server group
many critical systems continue
critical systems continue to
systems continue to use
mfs is designed to
continue to use isis
we define a region
is designed to support
define a region of
designed to support multiple
a region of overlap
to support multiple mfs
region of overlap to
support multiple mfs file
of overlap to be
based solutions or other
overlap to be a
solutions or other virtual
to be a set
or other virtual synchrony
be a set of
other virtual synchrony implementations
a set of nodes
multiple mfs file servers
set of nodes with
of nodes with approximately
nodes with approximately the
with approximately the same
approximately the same group
the same group membership
machine approach as used
approach as used in
as used in the
modal adaptation modeless adaptation
used in the paxos
in the paxos algorithm
the paxos algorithm is
paxos algorithm is also
algorithm is also becoming
is also becoming more
also becoming more popular
under the assumptions of
the key insight is
true bandwidth bandwidth used
key insight is that
the assumptions of section
insight is that these
is that these successes
that these successes use
these successes use similar
successes use similar ideas
use similar ideas but
similar ideas but in
ideas but in ways
our cluster should be
but in ways very
cluster should be nicely
in ways very different
should be nicely tiled
ways very different from
be nicely tiled by
very different from what
nicely tiled by regions
different from what the
from what the corba
what the corba fault
qsm uses regions for
uses regions for multicast
regions for multicast dissemination
for multicast dissemination and
multicast dissemination and for
dissemination and for recovery
and for recovery of
for recovery of lost
what we need today
recovery of lost packets
we need today is
need today is a
today is a modern
employing different protocols for
different protocols for each
is a modern revisiting
protocols for each purpose
a modern revisiting of
modern revisiting of this
revisiting of this technology
protocol node x recover
node x recover in
of this technology that
x recover in x
recover in x region
this technology that draws
in x region figure
technology that draws on
that draws on group
draws on group communication
on group communication but
of lost packets fig
hierarchical recovery in qsm
group communication but packages
communication but packages it
but packages it in
a group spans multiple
packages it in a
group spans multiple regions
it in a way
in a way that
a way that developers
each region has an
loss rates on teragrid
way that developers perceive
region has an associated
that developers perceive as
rates on teragrid determine
developers perceive as solving
has an associated structure
perceive as solving their
an associated structure of
as solving their most
associated structure of token
solving their most pressing
perhaps because such links
their most pressing scalability
structure of token rings
most pressing scalability problems
because such links are
pressing scalability problems and
such links are a
scalability problems and that
links are a relatively
problems and that flexibly
are a relatively recent
and that flexibly matches
a relatively recent addition
that flexibly matches their
relatively recent addition to
to recover from packet
flexibly matches their preferred
recent addition to the
matches their preferred styles
recover from packet loss
addition to the networking
their preferred styles and
to the networking landscape
preferred styles and tools
the networking landscape and
qsm uses a hierarchical
networking landscape and their
uses a hierarchical structure
landscape and their ownership
a hierarchical structure of
other kinds of persistent
and their ownership is
hierarchical structure of token
their ownership is still
structure of token rings
kinds of persistent objects
ownership is still mostly
is still mostly restricted
still mostly restricted to
we considered using other
mostly restricted to commercial
considered using other structures
restricted to commercial organizations
to commercial organizations disinclined
commercial organizations disinclined to
organizations disinclined to reveal
disinclined to reveal such
to reveal such information
the user simply designs
user simply designs a
simply designs a data
but token rings produce
designs a data structure
token rings produce a
one source of information
a data structure and
source of information is
rings produce a more
data structure and employs
of information is teragrid
structure and employs multicast
produce a more predictable
and employs multicast technology
a more predictable traffic
employs multicast technology to
more predictable traffic pattern
multicast technology to transmit
technology to transmit updates
to transmit updates to
transmit updates to the
updates to the group
to the group members
the importance of this
importance of this will
of this will become
this will become clear
will become clear later
which apply them in
apply them in the
them in the same
in the same order
the same order everywhere
an optical network interconnecting
optical network interconnecting major
the basic structure is
network interconnecting major supercomputing
basic structure is illustrated
interconnecting major supercomputing sites
structure is illustrated in
major supercomputing sites in
is illustrated in figure
supercomputing sites in the
sites in the us
can be done on
be done on any
done on any desired
on any desired copy
teragrid has a monitoring
at the highest level
has a monitoring framework
a monitoring framework within
monitoring framework within which
framework within which ten
within which ten sites
examples of updates include
which ten sites periodically
of updates include a
ten sites periodically send
true bandwidth bandwidth used
sites periodically send each
qsm circulates tokens around
updates include a stock
periodically send each other
circulates tokens around sets
include a stock trade
tokens around sets of
a stock trade or
around sets of regions
gbps streams of udp
stock trade or stock
streams of udp packets
trade or stock market
of udp packets and
or stock market quote
aggregating information that can
udp packets and measure
information that can be
packets and measure the
that can be used
and measure the resulting
can be used by
a new object detected
be used by a
new object detected by
used by a group
object detected by radar
by a group sender
detected by radar in
a group sender to
measure the resulting loss
group sender to retransmit
the resulting loss rate
sender to retransmit packets
by radar in an
to retransmit packets that
radar in an air
retransmit packets that were
in an air traffic
packets that were missed
an air traffic control
that were missed by
air traffic control system
were missed by entire
missed by entire regions
a communication to or
communication to or from
to or from an
or from an aircraft
or the addition of
each site measures the
the addition of a
site measures the loss
addition of a node
measures the loss rate
of a node to
the loss rate to
a token circulates to
a node to a
token circulates to provide
node to a distributed
circulates to provide loss
to a distributed data
loss rate to every
to provide loss recovery
a distributed data structure
provide loss recovery at
rate to every other
distributed data structure containing
to every other site
data structure containing an
loss recovery at the
structure containing an index
recovery at the level
every other site once
containing an index of
at the level of
other site once an
an index of pending
the level of nodes
site once an hour
index of pending orders
level of nodes belonging
of pending orders in
of nodes belonging to
pending orders in an
resulting in a total
nodes belonging to the
orders in an online
in a total of
belonging to the region
in an online warehouse
data replication can be
replication can be remarkably
loss rate measurements collected
can be remarkably cheap
rate measurements collected across
measurements collected across the
collected across the network
if regions become large
across the network every
with modern technology and
the network every hour
modern technology and small
technology and small updates
qsm partitions them into
partitions them into smaller
them into smaller rings
this is illustrated in
shows that between nov
is illustrated in figure
computer chrony service can
chrony service can run
in the experiments reported
service can run at
the experiments reported in
can run at rates
experiments reported in this
run at rates well
reported in this paper
at rates well in
rates well in excess
well in excess of
no token ring ever
token ring ever grows
ring ever grows larger
ever grows larger than
grows larger than about
and the system uses
the system uses single
system uses single and
uses single and two
we plan to experiment
plan to experiment with
to experiment with larger
experiment with larger configurations
ordered updates per second
with larger configurations and
modal versus modeless adaptation
larger configurations and will
versus modeless adaptation with
configurations and will work
modeless adaptation with atp
and will work with
even if an update
will work with deeper
of all such measurements
if an update requires
all such measurements were
work with deeper hierarchies
such measurements were over
the left graph shows
an update requires a
left graph shows performance
update requires a large
the qsm recovery protocol
requires a large message
qsm recovery protocol uses
graph shows performance with
recovery protocol uses tokens
shows performance with modal
protocol uses tokens to
performance with modal adaptation
uses tokens to track
it s possible to
tokens to track message
s possible to maintain
to track message status
possible to maintain rates
and the right graph
to maintain rates of
the right graph shows
maintain rates of thousands
right graph shows a
rates of thousands per
graph shows a scheme
of thousands per second
shows a scheme in
thousands per second on
a scheme in which
per second on typical
scheme in which there
second on typical hardware
in which there are
which there are four
there are four classes
are four classes of
of them were over
four classes of messages
the virtual synchrony and
classes of messages being
of messages being sent
virtual synchrony and statemachine
messages being sent simultaneously
synchrony and statemachine models
the token carries ack
and statemachine models show
token carries ack and
statemachine models show how
carries ack and nak
models show how a
ack and nak information
show how a tremendous
the lowest line corresponds
how a tremendous range
lowest line corresponds to
a tremendous range of
aggregated over the nodes
tremendous range of application
line corresponds to the
range of application requirements
corresponds to the highest
over the nodes below
after eliminating a single
of application requirements can
to the highest priority
application requirements can map
eliminating a single site
the nodes below each
requirements can map down
nodes below each ring
can map down to
map down to a
down to a rigorously
to a rigorously precise
dark horizontal lines represent
token rings avoid the
horizontal lines represent operating
rings avoid the kinds
lines represent operating modes
avoid the kinds of
that dropped incoming packets
the kinds of ack
dropped incoming packets steadily
represent operating modes on
a rigorously precise execution
incoming packets steadily at
operating modes on the
nak implosion problems with
rigorously precise execution model
implosion problems with which
packets steadily at a
modes on the left
problems with which reliable
which in turn can
with which reliable multicast
in turn can be
which reliable multicast protocols
turn can be used
reliable multicast protocols traditionally
can be used to
multicast protocols traditionally have
be used to validate
protocols traditionally have struggled
used to validate a
and the highest priority
steadily at a rate
the highest priority of
at a rate of
to validate a platform
but problems of their
highest priority of data
problems of their own
priority of data being
of data being sent
because the models have
data being sent during
the models have formal
if a message is
being sent during a
models have formal specifications
a message is lost
sent during a second
during a second on
a second on the
second on the right
you can test the
the sender may not
can test the correctness
sender may not find
test the correctness of
the modeless scheme achieves
may not find out
the correctness of an
modeless scheme achieves higher
not find out for
correctness of an implementation
scheme achieves higher utilisation
find out for quite
out for quite a
for quite a while
and even use theorem
of the remainder were
even use theorem provers
the remainder were over
use theorem provers to
theorem provers to assist
provers to assist developers
this isn t a
to assist developers in
isn t a major
assist developers in testing
t a major issue
developers in testing their
a major issue because
in testing their most
major issue because most
testing their most critical
issue because most message
their most critical application
because most message losses
most critical application components
most message losses can
message losses can be
losses can be corrected
mb of data sent
can be corrected locally
one reason that we
reason that we lack
because it always has
that we lack this
through cooperation among receivers
we lack this sort
it always has messages
lack this sort of
always has messages to
this sort of support
the basic idea is
has messages to send
sort of support today
basic idea is to
of support today is
idea is to perform
support today is that
is to perform recovery
while the modal scheme
today is that vendors
the modal scheme is
is that vendors and
modal scheme is dependent
that vendors and platform
scheme is dependent on
vendors and platform developers
is dependent on a
and platform developers worry
dependent on a rapid
platform developers worry that
on a rapid and
developers worry that these
these numbers may look
worry that these forms
numbers may look small
that these forms of
may look small in
these forms of replication
look small in absolute
forms of replication haven
a rapid and accurate
of replication haven t
small in absolute terms
to perform recovery as
rapid and accurate estimate
replication haven t achieved
and accurate estimate of
haven t achieved huge
but they are sufficient
perform recovery as locally
accurate estimate of the
t achieved huge market
estimate of the available
achieved huge market success
of the available bandwidth
recovery as locally as
the available bandwidth in
as locally as possible
available bandwidth in order
they are sufficient to
as the experience with
are sufficient to bring
the experience with corba
sufficient to bring tcp
bandwidth in order to
experience with corba sidebar
in order to select
with corba sidebar describes
order to select its
ip throughput crashing down
to select its correct
throughput crashing down on
select its correct operating
the common object request
crashing down on high
its correct operating mode
common object request broker
if a message is
object request broker architecture
a message is available
request broker architecture offers
message is available within
broker architecture offers a
is available within the
architecture offers a fault
available within the same
within the same token
conventional wisdom states that
the same token ring
wisdom states that optical
tolerant groups mechanism that
states that optical links
groups mechanism that was
that optical links do
mechanism that was based
some process that has
that was based on
process that has a
was based on the
that has a a
optical links do not
based on the virtual
has a a a
links do not drop
on the virtual synchrony
a a a c
do not drop packets
these graphs are reproduced
the virtual synchrony model
a a c ac
graphs are reproduced from
a c ac ab
c ac ab abc
ac ab abc bc
ab abc bc b
grade optical equipment is
abc bc b c
optical equipment is configured
the corba standard is
bc b c b
equipment is configured to
corba standard is widely
b c b figure
is configured to shut
standard is widely viewed
configured to shut down
is widely viewed as
an equivalent modal scheme
widely viewed as rigid
to shut down beyond
viewed as rigid and
shut down beyond bit
groups overlap to form
as rigid and limited
other experiments have shown
overlap to form regions
experiments have shown that
down beyond bit error
have shown that modeless
beyond bit error rates
shown that modeless adaptation
i believe that the
that modeless adaptation can
nodes belong to the
modeless adaptation can achieve
belong to the same
adaptation can achieve improvements
to the same region
can achieve improvements of
the same region if
believe that the corba
bit error rates of
that the corba community
same region if they
the corba community erred
region if they have
corba community erred by
if they have similar
community erred by embedding
they have similar group
erred by embedding a
have similar group membership
by embedding a powerful
embedding a powerful solution
a powerful solution into
powerful solution into a
solution into a tool
into a tool mismatched
a tool mismatched to
tool mismatched to developer
mismatched to developer needs
one out of a
qsm currently uses an
out of a trillion
currently uses an unreliable
of a trillion bits
web services move beyond
uses an unreliable ip
services move beyond corba
an unreliable ip multicast
move beyond corba in
and it is possible
beyond corba in many
it is possible to
corba in many ways
is possible to construct
the reliability of the
possible to construct cases
reliability of the lambda
to construct cases in
of the lambda network
construct cases in which
but the corba community
cases in which the
the lambda network is
since a single group
lambda network is clearly
the corba community s
network is clearly not
corba community s failed
in which the improvement
a single group may
is clearly not equal
community s failed effort
which the improvement is
s failed effort to
the improvement is even
failed effort to implement
clearly not equal to
effort to implement virtual
not equal to the
to implement virtual synchrony
equal to the sum
implement virtual synchrony carries
improvement is even greater
virtual synchrony carries an
to the sum of
single group may span
synchrony carries an important
the sum of its
group may span multiple
carries an important lesson
work on adaptation in
sum of its optical
on adaptation in mobile
of its optical parts
adaptation in mobile file
an important lesson to
may span multiple regions
in mobile file systems
important lesson to current
mobile file systems has
lesson to current researchers
file systems has generally
systems has generally relied
to send to group
has generally relied on
it s less reliable
generally relied on modal
s less reliable by
any technology offered to
less reliable by orders
relied on modal schemes
technology offered to developers
send to group g
offered to developers must
reliable by orders of
to developers must support
by orders of magnitude
developers must support the
a node multicasts a
must support the programming
node multicasts a message
support the programming styles
multicasts a message to
the programming styles they
a message to each
applications and protocols such
message to each of
and protocols such as
to each of the
protocols such as tcp
each of the regions
programming styles they prefer
of the regions separately
ip which expect extreme
which expect extreme reliability
management policies a scalable
expect extreme reliability from
policies a scalable services
extreme reliability from the
a scalable services architecture
but our evaluation of
reliability from the high
our evaluation of atp
scalable services architecture for
evaluation of atp demonstrated
services architecture for building
of atp demonstrated that
architecture for building raps
atp demonstrated that it
for building raps of
demonstrated that it could
our approach makes it
that it could also
approach makes it easy
it could also improve
makes it easy to
could also improve the
it easy to aggregate
also improve the performance
easy to aggregate messages
improve the performance of
to aggregate messages across
the performance of file
aggregate messages across different
performance of file system
messages across different groups
building raps of racs
speed network are instead
raps of racs alone
network are instead subjected
of racs alone isn
are instead subjected to
racs alone isn t
instead subjected to unexpectedly
alone isn t enough
subjected to unexpectedly high
we discuss the implementation
to unexpectedly high loss
discuss the implementation of
unexpectedly high loss rates
the implementation of modeless
if a node has
implementation of modeless adaptation
a node has two
of modeless adaptation in
node has two messages
modeless adaptation in mfs
has two messages to
adaptation in mfs further
two messages to send
in mfs further in
messages to send to
mfs further in section
to send to a
these numbers reflect the
scale systems that will
numbers reflect the loss
systems that will likely
reflect the loss rate
that will likely soon
the loss rate specifically
send to a pair
loss rate specifically experienced
will likely soon rely
atp is implemented at
likely soon rely on
is implemented at user
soon rely on standardized
to a pair of
a pair of groups
rate specifically experienced by
implemented at user level
rely on standardized web
pair of groups g
on standardized web services
specifically experienced by udp
standardized web services including
on top of kernel
experienced by udp traffic
web services including global
top of kernel udp
by udp traffic on
services including global banks
udp traffic on an
which overlap in region
traffic on an end
it has a message
overlap in region r
the entire us air
entire us air force
oriented interface for communication
then while transmitting to
while transmitting to r
end path and may
and the supervisory control
path and may not
in which messages of
the supervisory control and
which messages of an
supervisory control and data
messages of an arbitrary
control and data acquisition
of an arbitrary size
and data acquisition systems
an arbitrary size can
the node can batch
arbitrary size can be
node can batch these
size can be reliably
can batch these messages
can be reliably transmitted
batch these messages together
and may not generalize
data acquisition systems that
be reliably transmitted with
acquisition systems that operate
reliably transmitted with their
systems that operate the
apps send to a
transmitted with their boundaries
send to a send
with their boundaries preserved
to a send to
their boundaries preserved at
may not generalize to
that operate the us
a send to b
boundaries preserved at the
not generalize to tcp
operate the us power
send to b group
the us power grid
generalize to tcp packets
us power grid will
to b group senders
preserved at the receiver
b group senders a
at the receiver s
power grid will also
group senders a b
grid will also require
senders a b c
will also require policies
a b c region
we do not know
b c region senders
do not know if
c region senders a
the receiver s side
region senders a ab
not know if packets
also require policies to
know if packets were
require policies to manage
if packets were dropped
senders a ab ac
packets were dropped within
a ab ac abc
were dropped within the
an application can send
dropped within the optical
application can send a
within the optical network
can send a message
the optical network or
send a message synchronously
optical network or at
ab ac abc b
policies to manage security
a message synchronously or
network or at intermediate
ac abc b c
to manage security keys
message synchronously or asynchronously
or at intermediate devices
abc b c bc
at intermediate devices within
b c bc region
intermediate devices within either
c bc region leader
devices within either data
bc region leader figure
within either data center
in the latter case
the latter case the
latter case the sender
case the sender provides
though it s unlikely
the sender provides a
it s unlikely that
to multicast to a
s unlikely that they
multicast to a group
automated tools for monitoring
unlikely that they were
sender provides a function
tools for monitoring large
provides a function to
qsm sends a copy
a function to be
sends a copy to
function to be executed
a copy to each
to be executed when
copy to each of
that they were dropped
to each of the
they were dropped at
each of the underlying
were dropped at the
of the underlying regions
dropped at the end
for monitoring large complex
be executed when transmission
monitoring large complex systems
executed when transmission of
large complex systems will
when transmission of the
complex systems will be
transmission of the message
many of the measurements
systems will be needed
partition leader token intrapartition
of the message completes
of the measurements lost
will be needed as
the measurements lost just
be needed as well
measurements lost just one
leader token intrapartition token
and the send operation
token intrapartition token partition
the send operation itself
intrapartition token partition figure
send operation itself is
lost just one or
operation itself is non
just one or two
one or two packets
researchers must think about
or two packets whereas
must think about how
two packets whereas kernel
a hierarchy of token
think about how monitoring
hierarchy of token rings
about how monitoring and
this is similar to
how monitoring and management
is similar to the
nic losses are known
monitoring and management policies
similar to the queued
and management policies in
to the queued rpc
losses are known to
management policies in different
the queued rpc developed
policies in different organizations
queued rpc developed for
in different organizations should
are known to be
different organizations should talk
rpc developed for rover
organizations should talk to
naks ack through upcalls
should talk to one
known to be bursty
talk to one another
to one another when
one another when web
another when web services
qsm is also registered
when web services interactions
is also registered as
web services interactions cross
also registered as a
services interactions cross boundaries
registered as a shell
as a shell extension
these are tough problems
making it possible to
atp also allows the
it possible to access
also allows the sender
possible to access the
allows the sender to
to access the communication
the sender to attach
access the communication subsystem
sender to attach a
the communication subsystem directly
but they can be
communication subsystem directly from
loss occurred on paths
subsystem directly from the
to attach a priority
occurred on paths where
they can be solved
on paths where levels
directly from the windows
attach a priority to
paths where levels of
from the windows gui
a priority to each
where levels of optical
priority to each message
at cornell we recently
levels of optical link
cornell we recently developed
of optical link utilization
we recently developed astrolabe
the user can store
to control the order
user can store a
control the order in
can store a shortcut
the order in which
store a shortcut to
a scalable technology for
a shortcut to a
order in which the
scalable technology for distributed
shortcut to a qsm
technology for distributed monitoring
to a qsm stream
for distributed monitoring and
in which the queued
distributed monitoring and control
which the queued messages
monitoring and control that
the queued messages are
a qsm stream in
queued messages are transmitted
were consistently lower than
qsm stream in the
and control that has
stream in the file
control that has attracted
in the file system
messages are queued at
that has attracted tremendous
are queued at the
has attracted tremendous interest
queued at the sender
attracted tremendous interest and
at the sender according
tremendous interest and attention
the sender according to
ruling out congestion as
sender according to their
out congestion as a
according to their receivers
congestion as a possible
researchers at other institutions
as a possible cause
at other institutions are
click to attach a
other institutions are working
to attach a previewer
and each queue is
attach a previewer or
institutions are working on
a previewer or a
are working on other
previewer or a viewer
working on other promising
or a viewer to
on other promising solutions
a viewer to an
each queue is ordered
viewer to an event
queue is ordered by
to an event stream
is ordered by priority
a conclusion supported by
calability isn t just
conclusion supported by dialogue
isn t just a
supported by dialogue with
the overall architecture is
by dialogue with the
overall architecture is summarized
dialogue with the network
architecture is summarized in
with the network administrators
t just a technology
messages of the same
is summarized in figure
of the same priority
the same priority within
same priority within a
it s also a
priority within a queue
s also a mindset
within a queue are
also a mindset with
the system is single
a mindset with ramifications
a queue are transmitted
mindset with ramifications at
queue are transmitted in
with ramifications at many
are transmitted in first
ramifications at many levels
what are some possible
are some possible causes
to ensure true scalability
some possible causes for
we use a windows
possible causes for such
use a windows i
causes for such high
for such high loss
web services platforms must
such high loss rates
services platforms must begin
high loss rates on
platforms must begin to
loss rates on teragrid
must begin to standardize
atp also allows a
begin to standardize application
also allows a sender
henceforth referred to as
to standardize application architectures
allows a sender to
standardize application architectures that
a sender to specify
referred to as an
a likely hypothesis is
application architectures that promote
sender to specify a
architectures that promote reliability
to specify a send
that promote reliability and
likely hypothesis is device
promote reliability and interoperability
specify a send timeout
reliability and interoperability when
to as an i
hypothesis is device clutter
a send timeout for
and interoperability when developers
send timeout for a
interoperability when developers build
timeout for a message
is device clutter the
when developers build systems
device clutter the critical
developers build systems of
clutter the critical communication
build systems of systems
the critical communication path
to collect all asynchronous
critical communication path between
collect all asynchronous i
which causes the transmission
communication path between nodes
causes the transmission to
path between nodes in
work with intrinsically distributed
between nodes in different
with intrinsically distributed programs
nodes in different data
intrinsically distributed programs that
in different data centers
distributed programs that don
different data centers is
programs that don t
data centers is littered
that don t fit
centers is littered with
don t fit a
is littered with multiple
including notifications of any
the transmission to be
t fit a transactional
littered with multiple electronic
notifications of any received
transmission to be suspended
fit a transactional model
with multiple electronic devices
of any received messages
to be suspended if
be suspended if it
suspended if it expires
and must provide responsiveness
must provide responsiveness guarantees
each of which represents
provide responsiveness guarantees to
so that the sender
of which represents a
responsiveness guarantees to their
that the sender can
which represents a potential
guarantees to their users
the sender can react
represents a potential point
sender can react to
a single core thread
can react to it
single core thread synchronously
a potential point of
applications with these sorts
core thread synchronously polls
potential point of failure
an analogous mechanism is
with these sorts of
thread synchronously polls the
these sorts of requirements
synchronously polls the i
analogous mechanism is available
sorts of requirements are
another possibility is that
of requirements are already
possibility is that such
requirements are already in
is that such loss
mechanism is available for
o queue to retrieve
is available for receive
queue to retrieve incoming
available for receive operations
to retrieve incoming messages
are already in the
that such loss rates
already in the pipeline
such loss rates may
in the pipeline and
besides detecting when a
the pipeline and even
detecting when a remote
pipeline and even more
when a remote host
and even more of
the core thread also
loss rates may be
a remote host is
even more of them
core thread also maintains
rates may be typical
remote host is inaccessible
more of them are
thread also maintains an
may be typical for
of them are on
also maintains an alarm
send timeouts do not
maintains an alarm queue
timeouts do not play
them are on drawing
be typical for any
do not play a
are on drawing boards
implemented as a splay
on drawing boards in
typical for any large
not play a major
as a splay tree
drawing boards in government
play a major role
a major role in
major role in mfs
scale network where the
network where the cost
where the cost of
the cost of immediately
cost of immediately detecting
an additional use for
of immediately detecting and
additional use for timeouts
and a request queue
use for timeouts would
the only option for
immediately detecting and fixing
only option for the
detecting and fixing failures
option for the web
implemented as a lockfree
for the web services
as a lockfree queue
the web services community
for timeouts would be
and fixing failures is
timeouts would be to
web services community is
would be to detect
services community is to
be to detect prefetches
fixing failures is prohibitively
to detect prefetches which
failures is prohibitively high
a lockfree queue with
community is to take
detect prefetches which are
lockfree queue with cas
is to take on
prefetches which are not
to take on the
which are not making
take on the challenge
are not making progress
we found through dialogue
not making progress and
for requests from the
found through dialogue with
making progress and reissue
through dialogue with the
progress and reissue a
if they do so
dialogue with the administrators
and reissue a prefetch
with the administrators that
reissue a prefetch for
the administrators that the
a prefetch for a
administrators that the steady
prefetch for a different
solutions will be readily
for a different file
will be readily available
the core thread polls
that the steady loss
core thread polls all
the steady loss rate
thread polls all queues
steady loss rate experienced
web services are going
loss rate experienced by
services are going to
rate experienced by the
are going to be
experienced by the indiana
going to be the
by the indiana university
to be the ubiquitous
polls all queues in
be the ubiquitous platform
all queues in a
the ubiquitous platform technology
the indiana university site
atp administers priorities by
indiana university site was
administers priorities by deriving
ubiquitous platform technology for
priorities by deriving an
platform technology for next
by deriving an estimate
university site was due
deriving an estimate for
site was due to
an estimate for the
was due to a
generation critical computing systems
due to a faulty
estimate for the bandwidth
to a faulty line
for the bandwidth available
queues in a round
the bandwidth available between
a faulty line card
bandwidth available between the
and we ve no
available between the sender
we ve no one
between the sender and
robin fashion and processes
ve no one but
and the measurements showed
fashion and processes the
the measurements showed that
and processes the events
measurements showed that the
no one but ourselves
showed that the error
one but ourselves to
that the error persisting
but ourselves to blame
the error persisting over
ourselves to blame if
error persisting over at
to blame if these
processes the events sequentially
blame if these systems
persisting over at least
the sender and receiver
if these systems don
over at least a
events of the same
at least a three
of the same type
least a three month
the same type are
a three month period
same type are processed
these systems don t
in order to minimise
type are processed in
order to minimise the
are processed in batches
to minimise the transmission
systems don t work
minimise the transmission delay
don t work properly
points for loss rates
the transmission delay when
up to the limit
for loss rates on
transmission delay when a
to the limit determined
loss rates on high
delay when a new
do we really want
the limit determined by
we really want to
limit determined by a
when a new message
really want to create
determined by a quantum
a new message is
haul networks are provided
want to create a
new message is sent
to create a world
networks are provided by
create a world in
are provided by the
a world in which
atp uses a form
provided by the back
world in which minor
uses a form of
in which minor computer
a form of rate
which minor computer glitches
bone networks of tier
minor computer glitches shut
computer glitches shut down
glitches shut down massive
shut down massive critical
down massive critical applications
massive critical applications and
each second is divided
critical applications and in
second is divided into
applications and in which
is divided into twenty
and in which hackers
global crossing reports average
in which hackers can
crossing reports average loss
which hackers can readily
reports average loss rates
hackers can readily disrupt
average loss rates between
there is no limit
can readily disrupt access
divided into twenty send
is no limit for
readily disrupt access to
into twenty send periods
no limit for local
disrupt access to banking
twenty send periods of
limit for local push
access to banking records
pull data sender inter
air traffic control systems
and even shut down
even shut down the
and at most one
shut down the power
down the power grid
pull region partition figure
twentieth of the available
time is running out
of the available bandwidth
the available bandwidth is
available bandwidth is used
bandwidth is used during
is used during a
recovery inside and across
used during a single
inside and across partitions
during a single send
current halfway solutions will
a single send period
halfway solutions will tempt
solutions will tempt developers
copy will forward it
on four of its
will tempt developers to
without such a constraint
tempt developers to embark
four of its six
developers to embark on
of its six inter
to embark on a
will forward it to
embark on a path
forward it to the
on a path that
it to the process
atp would send as
to the process missing
would send as much
a path that will
the process missing the
path that will soon
haul links for the
send as much data
links for the month
as much data as
for the month of
much data as it
the month of december
data as it could
that will soon lead
process missing the message
as it could on
will soon lead many
it could on receipt
soon lead many of
could on receipt of
lead many of them
on receipt of a
many of them into
receipt of a low
of them into real
qsm implements a scheme
them into real trouble
implements a scheme originally
a scheme originally proposed
scheme originally proposed by
originally proposed by zhao
the entire industry clients
and this data could
this data could then
data could then be
could then be buffered
then be buffered at
be buffered at an
buffered at an intermediate
at an intermediate link
and vendors as well
vendors as well as
as well as the
delaying the transmission of
well as the government
even in a large
qwest reports loss rates
in a large ring
as the government have
the transmission of any
the government have a
reports loss rates of
government have a shared
transmission of any high
have a shared obligation
no more than five
a shared obligation to
more than five nodes
shared obligation to make
than five nodes cache
priority message which might
obligation to make web
five nodes cache any
message which might be
to make web services
nodes cache any given
which might be sent
make web services better
cache any given message
might be sent later
s ken birman is
qsm also uses this
ken birman is a
also uses this idea
birman is a professor
uses this idea at
is a professor in
the disadvantage of this
a professor in the
this idea at the
professor in the department
disadvantage of this scheme
idea at the level
in the department of
of this scheme is
at the level of
this scheme is that
the level of partitions
scheme is that heavy
the department of computer
is that heavy contention
department of computer science
in either direction on
of computer science at
that heavy contention at
computer science at cornell
either direction on its
each message is cached
direction on its trans
heavy contention at the
message is cached in
science at cornell university
contention at the sender
is cached in a
at the sender may
pacific link for the
the sender may delay
link for the same
contact him at ken
for the same month
cached in a single
sender may delay a
in a single partition
may delay a new
delay a new message
a new message by
new message by as
message by as much
by as much as
if some partition is
some partition is missing
partition is missing a
is missing a message
we expect privately managed
regardless of its priority
expect privately managed lambdas
the partition caching it
privately managed lambdas to
partition caching it steps
managed lambdas to exhibit
caching it steps in
lambdas to exhibit higher
it steps in to
to exhibit higher loss
department of computer engineering
exhibit higher loss rates
this inefficiency of the
steps in to resend
inefficiency of the atp
in to resend it
san jose state university
higher loss rates due
of the atp implementation
loss rates due to
the atp implementation is
rates due to the
atp implementation is most
due to the inherent
implementation is most visible
to the inherent tradeoff
if an entire region
is most visible when
the inherent tradeoff between
most visible when there
inherent tradeoff between fiber
visible when there is
an entire region is
when there is contention
entire region is missing
there is contention between
region is missing a
is contention between different
equipment quality and cost
contention between different priorities
is missing a message
between different priorities at
different priorities at high
priorities at high bandwidth
the sender becomes involved
sender becomes involved and
becomes involved and re
qsm tokens also carry
tokens also carry other
also carry other information
as well as the
mfs implementation the version
well as the difficulty
implementation the version of
as the difficulty of
the version of mfs
including data used to
version of mfs described
data used to perform
of mfs described in
used to perform rate
mfs described in this
to perform rate control
described in this paper
perform rate control and
in this paper is
rate control and information
this paper is implemented
control and information used
the difficulty of performing
and information used to
difficulty of performing routine
information used to trigger
of performing routine maintenance
used to trigger garbage
performing routine maintenance on
to trigger garbage collection
routine maintenance on longdistance
paper is implemented in
maintenance on longdistance links
is implemented in c
implemented in c and
in c and runs
c and runs on
the overall system configuration
and runs on freebsd
overall system configuration is
system configuration is managed
configuration is managed by
is managed by what
managed by what we
by what we call
what we call the
we call the configuration
call the configuration management
the configuration management service
end paths as dropping
paths as dropping packets
as dropping packets at
dropping packets at rates
packets at rates of
both the client and
the client and server
client and server have
and server have multiple
which handles join and
server have multiple threads
handles join and leave
have multiple threads to
join and leave requests
multiple threads to cope
threads to cope with
to cope with simultaneous
cope with simultaneous file
with simultaneous file system
simultaneous file system requests
and uses these to
and the rpc library
uses these to generate
the rpc library has
these to generate a
rpc library has its
to generate a sequence
library has its own
generate a sequence of
has its own thread
a sequence of membership
sequence of membership views
of membership views for
membership views for each
views for each multicast
to capture a wide
therefore there are two
capture a wide range
there are two mandatory
the cms also determines
a wide range of
cms also determines and
wide range of deployed
also determines and continuously
range of deployed networks
are two mandatory thread
determines and continuously updates
two mandatory thread context
and continuously updates region
mandatory thread context switches
continuously updates region boundaries
thread context switches on
context switches on any
e xisting r eliability
switches on any message
xisting r eliability o
on any message send
maintains sequences of region
r eliability o ptions
any message send or
sequences of region views
eliability o ptions tcp
message send or receive
of region views for
send or receive operation
region views for each
views for each region
ip is the default
is the default reliable
the default reliable communication
as we shall describe
default reliable communication option
we shall describe in
reliable communication option for
shall describe in subsequent
communication option for contemporary
describe in subsequent sections
option for contemporary networked
and tracks the mapping
for contemporary networked applications
tracks the mapping from
the mapping from group
mapping from group views
from group views to
some subsystems have additional
group views to region
subsystems have additional threads
views to region views
have additional threads to
additional threads to carry
threads to carry out
exclusive embeddings in commodity
to carry out background
embeddings in commodity operating
carry out background processing
in commodity operating systems
commodity operating systems and
the cms runs on
operating systems and networking
cms runs on a
systems and networking apis
runs on a single
on a single node
our experiments were conducted
but we intend to
experiments were conducted with
we intend to replace
were conducted with a
most applications requiring reliable
conducted with a default
intend to replace this
with a default client
applications requiring reliable communication
a default client cache
to replace this with
requiring reliable communication over
default client cache size
reliable communication over any
client cache size of
communication over any form
replace this with a
over any form of
this with a state
any form of network
form of network use
of network use tcp
machine replicated version in
replicated version in the
version in the future
in the future to
the future to eliminate
future to eliminate the
to eliminate the risk
eliminate the risk of
the risk of single
rpcs with priorities mfs
with priorities mfs rpcs
ip has three major
in the longer term
has three major problems
the longer term we
three major problems when
longer term we will
major problems when used
term we will move
problems when used over
we will move to
priorities mfs rpcs are
cloudifying source code repositories
when used over high
will move to a
mfs rpcs are implemented
move to a hierarchically
rpcs are implemented on
to a hierarchically structured
are implemented on top
a hierarchically structured cms
implemented on top of
how much does it
on top of atp
much does it cost
top of atp in
of atp in the
atp in the natural
in the natural way
michael siegenthaler hakim weatherspoon
siegenthaler hakim weatherspoon dept
an rpc request constitutes
rpc request constitutes one
request constitutes one message
throughput collapse in lossy
of computer science cornell
collapse in lossy networks
computer science cornell university
and its reply another
science cornell university msiegen
alarm queue application thread
priorities are used to
queue application thread operating
are used to differentiate
ip is unable to
used to differentiate types
is unable to distinguish
to differentiate types of
application thread operating system
differentiate types of rpcs
unable to distinguish between
thread operating system kernel
to distinguish between ephemeral
operating system kernel implementation
distinguish between ephemeral loss
system kernel implementation qsm
between ephemeral loss modes
kernel implementation qsm qsm
ephemeral loss modes due
implementation qsm qsm request
loss modes due to
qsm qsm request queue
modes due to transient
qsm request queue core
due to transient congestion
of computer science cornell
types of rpcs to
computer science cornell university
request queue core thread
science cornell university hweather
queue core thread i
of rpcs to improve
rpcs to improve performance
o queue socket figure
or bad fiber and
bad fiber and persistent
fiber and persistent congestion
edu abstract cloud computing
the loss of one
qsm uses a single
or those which would
loss of one packet
abstract cloud computing provides
of one packet out
cloud computing provides us
those which would cause
one packet out of
computing provides us with
which would cause an
provides us with general
would cause an interactive
us with general purpose
cause an interactive client
with a core thread
with general purpose storage
packet out of ten
general purpose storage and
out of ten thousand
purpose storage and server
of ten thousand is
storage and server hosting
ten thousand is sufficient
and server hosting platforms
thousand is sufficient to
an interactive client to
a core thread that
server hosting platforms at
core thread that controls
hosting platforms at a
thread that controls three
platforms at a reasonable
that controls three queues
at a reasonable price
interactive client to block
is sufficient to reduce
sufficient to reduce tcp
are given high priority
we explore the possibility
ip throughput to a
explore the possibility of
throughput to a third
the possibility of tapping
rpcs for background activities
to a third of
possibility of tapping these
a third of its
of tapping these resources
third of its lossless
tapping these resources for
such as writing back
and requests from the
as writing back files
requests from the possibly
writing back files to
from the possibly multithreaded
back files to the
the possibly multithreaded application
these resources for the
of its lossless maximum
resources for the purpose
files to the server
for the purpose of
when we set out
the purpose of hosting
we set out to
purpose of hosting source
set out to implement
if one packet is
of hosting source code
out to implement qsm
hosting source code repositories
are performed at low
source code repositories for
one packet is lost
code repositories for individual
packet is lost out
repositories for individual projects
our intent was to
for individual projects as
is lost out of
individual projects as well
lost out of a
projects as well as
performed at low priority
intent was to leverage
as well as entire
was to leverage the
well as entire open
to leverage the component
as entire open source
leverage the component integration
out of a thousand
so that they do
entire open source communities
the component integration tools
that they do not
component integration tools available
they do not slow
throughput collapses to a
integration tools available on
do not slow down
collapses to a thirtieth
an analysis of storage
tools available on the
not slow down high
to a thirtieth of
analysis of storage costs
a thirtieth of the
of storage costs is
thirtieth of the maximum
storage costs is presented
available on the windows
on the windows platform
the root cause of
and a complete hosting
root cause of throughput
a complete hosting solution
shows the priority levels
complete hosting solution is
the priority levels for
hosting solution is built
priority levels for different
cause of throughput collapse
we didn t expect
solution is built and
levels for different types
of throughput collapse is
didn t expect that
is built and evaluated
for different types of
throughput collapse is tcp
t expect that co
built and evaluated as
different types of rpcs
and evaluated as a
evaluated as a proof
ip s fundamental reliance
s fundamental reliance on
existence with the managed
fundamental reliance on loss
with the managed environment
reliance on loss as
the managed environment would
on loss as a
managed environment would require
assigning priorities to rpcs
loss as a signal
priorities to rpcs allows
as a signal of
to rpcs allows mfs
environment would require any
rpcs allows mfs to
would require any special
allows mfs to adapt
require any special architectural
mfs to adapt to
any special architectural features
i ntroduction the advent
to adapt to bandwidth
a signal of congestion
adapt to bandwidth variation
ntroduction the advent of
to bandwidth variation in
qsm is implemented much
the advent of cloud
bandwidth variation in a
is implemented much like
while recent approaches have
implemented much like any
advent of cloud computing
variation in a straightforward
recent approaches have sought
of cloud computing has
approaches have sought to
in a straightforward way
have sought to replace
cloud computing has brought
sought to replace loss
to replace loss with
the system is coded
replace loss with delay
system is coded in
loss with delay as
computing has brought us
is coded in c
has brought us a
all rpcs complete quickly
brought us a dazzling
with delay as a
us a dazzling array
delay as a congestion
a dazzling array of
with or without priorities
dazzling array of public
as a congestion signal
array of public computing
of public computing services
public computing services that
computing services that can
services that can be
that can be instantly
can be instantly tapped
be instantly tapped by
instantly tapped by anyone
tapped by anyone with
by anyone with a
anyone with a credit
with a credit card
a credit card number
users are spared from
are spared from having
or to specifically identify
spared from having to
to specifically identify loss
from having to invest
specifically identify loss caused
having to invest in
identify loss caused by
to invest in expensive
loss caused by non
invest in expensive infrastructure
in expensive infrastructure such
expensive infrastructure such as
infrastructure such as servers
corresponding rpc types fetch
rpc types fetch attributes
and cooling equipment because
callbacks fetch file data
cooling equipment because the
equipment because the service
because the service provider
the service provider takes
service provider takes care
directory contents write back
provider takes care of
contents write back directory
takes care of these
write back directory and
care of these and
back directory and metadata
of these and amortizes
to interface to the
older variants prominently reno
directory and metadata updates
variants prominently reno remain
interface to the native
these and amortizes the
and metadata updates write
prominently reno remain ubiquitously
metadata updates write back
reno remain ubiquitously deployed
updates write back shared
and amortizes the cost
write back shared files
amortizes the cost across
back shared files write
the cost across many
to the native windows
shared files write back
cost across many clients
files write back unshared
the native windows asynchronous
write back unshared files
native windows asynchronous i
back unshared files prefetch
unshared files prefetch file
achieving efficiency through economies
files prefetch file data
efficiency through economies of
prefetch file data section
through economies of scale
recovery delays for real
companies are realizing that
are realizing that it
and is accessible from
realizing that it no
is accessible from any
that it no longer
it no longer makes
no longer makes sense
longer makes sense to
ip uses positive acknowledgments
makes sense to build
uses positive acknowledgments and
sense to build and
positive acknowledgments and retransmissions
to build and manage
acknowledgments and retransmissions to
build and manage all
windows understands qsm to
and retransmissions to ensure
understands qsm to be
independently and may compete
and manage all of
retransmissions to ensure reliability
qsm to be the
to ensure reliability the
to be the handler
ensure reliability the sender
be the handler for
manage all of their
the handler for operations
reliability the sender buffers
by making writes asynchronous
all of their own
the sender buffers packets
of their own infrastructure
sender buffers packets until
handler for operations on
buffers packets until their
for operations on new
packets until their receipt
operations on new kind
until their receipt is
and services in the
their receipt is acknowledged
services in the cloud
receipt is acknowledged by
in the cloud are
is acknowledged by the
the cloud are quickly
acknowledged by the receiver
cloud are quickly becoming
on new kind of
update logging pushes read
are quickly becoming popular
new kind of event
kind of event stream
and resends if an
resends if an acknowledgment
write contention into the
if an acknowledgment is
contention into the future
an acknowledgment is not
an application can obtain
acknowledgment is not received
application can obtain handles
is not received within
to occur at the
can obtain handles from
not received within some
occur at the next
that software development projects
obtain handles from these
software development projects will
handles from these qsm
at the next log
development projects will turn
received within some time
projects will turn to
within some time period
will turn to cloud
the next log flush
turn to cloud computing
to cloud computing to
cloud computing to store
computing to store their
to store their master
and can then invoke
the designers of little
can then invoke methods
designers of little work
a lost packet is
of little work incorporated
lost packet is received
little work incorporated a
store their master code
then invoke methods on
packet is received in
work incorporated a low
is received in the
invoke methods on those
received in the form
methods on those handles
in the form of
on those handles to
the form of a
those handles to send
level priority mechanism at
handles to send events
their master code repositories
form of a retransmission
priority mechanism at the
of a retransmission that
mechanism at the ip
a retransmission that arrives
at the ip packet
incoming messages are delivered
either on a project
retransmission that arrives no
the ip packet level
messages are delivered application
ip packet level to
are delivered application requests
that arrives no earlier
packet level to further
arrives no earlier than
level to further reduce
project basis or as
to further reduce interference
basis or as part
further reduce interference between
or as part of
reduce interference between writeback
as part of a
interference between writeback traffic
part of a larger
between writeback traffic and
of a larger migration
o event representing a
a larger migration of
event representing a received
writeback traffic and other
representing a received packet
rtts after the original
a received packet is
larger migration of a
received packet is retrieved
migration of a sourceforge
packet is retrieved for
traffic and other network
is retrieved for a
and other network traffic
retrieved for a given
other network traffic sent
for a given socket
network traffic sent by
the sender has to
traffic sent by the
sender has to buffer
sent by the client
even small code repositories
has to buffer each
small code repositories represent
to buffer each packet
code repositories represent a
buffer each packet until
repositories represent a huge
each packet until it
represent a huge investment
packet until it s
a huge investment of
the socket is drained
until it s acknowledged
huge investment of developerhours
socket is drained to
is drained to minimize
drained to minimize the
to minimize the probability
minimize the probability of
the probability of loss
so the need to
the need to store
rtt in lossless operation
need to store this
to store this data
store this data durably
several aspects of the
this data durably and
aspects of the architecture
data durably and reliably
of the architecture are
durably and reliably is
the architecture are noteworthy
and it has to
architecture are noteworthy because
priority levels for mfs
it has to perform
levels for mfs rpcs
and reliably is obvious
are noteworthy because of
has to perform additional
noteworthy because of their
to perform additional work
because of their performance
perform additional work to
of their performance implications
less obvious are the
symbolic names are given
additional work to retransmit
obvious are the shortcomings
work to retransmit the
are the shortcomings of
names are given for
to retransmit the packet
the shortcomings of traditional
retransmit the packet if
qsm assigns priorities to
the packet if it
assigns priorities to different
packet if it does
priorities to different types
are given for the
to different types of
shortcomings of traditional storage
if it does not
given for the priority
different types of i
of traditional storage systems
it does not receive
for the priority levels
does not receive the
not receive the acknowledgment
the basic idea is
listed from highest to
basic idea is that
from highest to lowest
idea is that when
highest to lowest priority
is that when an
any packets that arrive
that when an i
packets that arrive with
that arrive with higher
the third column gives
arrive with higher sequence
third column gives the
with higher sequence numbers
column gives the section
higher sequence numbers than
gives the section in
we retrieve all events
the section in which
retrieve all events from
section in which the
all events from the
sequence numbers than that
protect against data loss
numbers than that of
events from the i
than that of a
in which the corresponding
that of a lost
which the corresponding rpc
but they are neither
of a lost packet
the corresponding rpc types
a lost packet must
corresponding rpc types are
lost packet must be
rpc types are described
determine the type of
types are described in
the type of each
are described in detail
packet must be queued
they are neither cheap
must be queued while
are neither cheap nor
be queued while the
and then place it
queued while the receiver
neither cheap nor simple
while the receiver waits
then place it in
the receiver waits for
place it in an
receiver waits for the
it in an appropriate
waits for the lost
in an appropriate priority
for the lost packet
an appropriate priority queue
the lost packet to
especially when developers and
lost packet to arrive
when developers and server
developers and server administrators
and server administrators are
asynchronous writeback though it
server administrators are geographically
writeback though it reduces
administrators are geographically spread
the system processes queued
are geographically spread thin
system processes queued events
though it reduces bandwidth
throughput financial banking application
processes queued events in
financial banking application running
queued events in priority
banking application running in
it reduces bandwidth consumption
events in priority order
application running in a
we focus on the
running in a data
focus on the costs
update logging is fundamentally
on the costs of
logging is fundamentally unsuitable
in a data center
is fundamentally unsuitable for
a data center in
the costs of moving
fundamentally unsuitable for use
data center in new
costs of moving source
unsuitable for use at
of moving source code
for use at high
center in new york
by prioritizing incoming i
moving source code repositories
use at high bandwidth
source code repositories to
in new york city
code repositories to the
repositories to the cloud
to the cloud as
since it imposes a
the cloud as an
it imposes a delay
cloud as an example
imposes a delay on
as an example of
a delay on transmitting
an example of moving
delay on transmitting updates
example of moving services
on transmitting updates to
sending updates to a
of moving services in
transmitting updates to the
updates to a sister
moving services in general
updates to the server
to a sister site
services in general to
a sister site in
in general to the
and by prioritizing control
sister site in switzerland
by prioritizing control packets
systems using update logging
prioritizing control packets over
general to the cloud
control packets over data
using update logging must
packets over data we
update logging must therefore
over data we reduce
the rtt value between
data we reduce delays
especially collaborative open source
we reduce delays in
logging must therefore switch
reduce delays in reacting
collaborative open source projects
delays in reacting to
rtt value between these
in reacting to packet
value between these two
reacting to packet loss
between these two centers
to packet loss or
these two centers is
packet loss or other
two centers is typically
loss or other control
must therefore switch to
such an endeavor includes
therefore switch to a
an endeavor includes many
switch to a synchronous
endeavor includes many costs
to a synchronous writes
a synchronous writes when
synchronous writes when bandwidth
writes when bandwidth is
when bandwidth is high
we will see that
the most critical of
will see that this
most critical of which
see that this slashes
with a threshold controlling
that this slashes system
a threshold controlling switches
critical of which is
threshold controlling switches between
of which is storage
controlling switches between the
which is storage since
switches between the two
is storage since that
between the two modes
storage since that is
the pros and cons
since that is the
pros and cons of
that is the simplest
in the case of
the mode switch also
the case of a
mode switch also changes
case of a lost
switch also changes the
is the simplest and
and cons of using
the simplest and likely
of a lost packet
simplest and likely first
cons of using threads
also changes the semantics
and likely first component
of using threads in
changes the semantics of
using threads in eventoriented
all packets received within
threads in eventoriented systems
packets received within the
in eventoriented systems are
the semantics of the
likely first component to
eventoriented systems are hotly
semantics of the file
first component to be
systems are hotly debated
of the file system
component to be moved
and the developers of
we set an agenda
the developers of coda
threads turned out to
developers of coda have
milliseconds or more between
of coda have noted
turned out to be
coda have noted that
out to be a
set an agenda for
or more between the
an agenda for demonstrating
more between the original
agenda for demonstrating the
between the original packet
for demonstrating the financial
the original packet send
demonstrating the financial storage
original packet send and
the financial storage and
packet send and the
financial storage and computing
send and the receipt
storage and computing costs
and the receipt of
and computing costs of
the receipt of its
computing costs of moving
receipt of its retransmission
costs of moving source
of its retransmission have
of moving source code
its retransmission have to
moving source code repositories
retransmission have to be
source code repositories to
have to be buffered
code repositories to the
to be buffered at
repositories to the cloud
have noted that undetected
be buffered at the
noted that undetected mode
buffered at the receiver
to be a bad
that undetected mode changes
be a bad idea
undetected mode changes can
in section ii we
mode changes can surprise
section ii we explain
changes can surprise the
ii we explain what
although we used threads
can surprise the user
we used threads rather
the loss of a
we explain what it
used threads rather casually
surprise the user in
threads rather casually in
the user in undesirable
rather casually in the
user in undesirable ways
casually in the first
explain what it means
loss of a single
what it means to
of a single packet
it means to store
a single packet stops
means to store a
in the first year
to store a code
single packet stops all
store a code repository
packet stops all traffic
a code repository in
stops all traffic in
code repository in the
the first year of
repository in the cloud
all traffic in the
in the cloud and
traffic in the channel
the cloud and why
in the channel to
cloud and why there
such as cache inconsistencies
and why there are
as cache inconsistencies arising
why there are cost
cache inconsistencies arising due
first year of our
the channel to the
there are cost advantages
channel to the application
are cost advantages to
to the application for
cost advantages to doing
the application for a
advantages to doing so
application for a seventh
year of our effort
inconsistencies arising due to
for a seventh of
arising due to unexpectedly
a seventh of a
section iii is a
due to unexpectedly delayed
that version of the
to unexpectedly delayed writes
seventh of a second
iii is a case
version of the system
is a case study
of the system was
a case study on
a sequence of such
rather than relying on
sequence of such blocks
the system was annoyingly
of such blocks can
than relying on a
case study on using
relying on a modal
study on using amazon
system was annoyingly process
such blocks can have
on a modal adaptation
on using amazon s
a modal adaptation scheme
using amazon s s
was annoyingly process requests
blocks can have devastating
modal adaptation scheme incorporating
can have devastating effect
annoyingly process requests incoming
adaptation scheme incorporating a
have devastating effect on
scheme incorporating a transition
devastating effect on a
incorporating a transition to
process requests incoming control
a transition to update
effect on a high
transition to update logging
to host some popular
to update logging when
host some popular open
update logging when bandwidth
some popular open source
logging when bandwidth is
popular open source communities
when bandwidth is low
throughput system where every
requests incoming control outgoing
system where every spare
where every spare cycle
incoming control outgoing control
and includes a cost
every spare cycle counts
mfs uses a modeless
control outgoing control outgoing
includes a cost analysis
outgoing control outgoing data
uses a modeless asynchronous
control outgoing data feed
a modeless asynchronous writeback
outgoing data feed sink
modeless asynchronous writeback mechanism
data feed sink limit
in section iv we
feed sink limit sending
section iv we present
sink limit sending rate
iv we present an
limit sending rate limit
we present an implementation
sending rate limit concurrency
present an implementation that
rate limit concurrency limit
an implementation that ties
limit concurrency limit window
implementation that ties subversion
concurrency limit window size
that ties subversion to
limit window size figure
which is active at
in applications with many
ties subversion to s
is active at all
applications with many fine
active at all bandwidth
at all bandwidth levels
in a pull protocol
a pull protocol a
just as with update
as with update logging
a lost packet can
lost packet can potentially
end servers running on
packet can potentially trigger
servers running on amazon
registers the intent to
running on amazon s
when an application performs
can potentially trigger a
an application performs an
the intent to send
on amazon s ec
intent to send with
application performs an operation
to send with a
performs an operation that
send with a sink
an operation that changes
potentially trigger a butterfly
with a sink that
trigger a butterfly effect
operation that changes a
a butterfly effect of
that changes a file
butterfly effect of missed
a sink that may
effect of missed deadlines
sink that may be
of missed deadlines along
and using yahoo s
missed deadlines along a
such as a write
deadlines along a distributed
as a write or
along a distributed workflow
a write or metadata
using yahoo s zookeeper
that may be controlled
write or metadata update
yahoo s zookeeper for
may be controlled by
s zookeeper for consistency
be controlled by a
controlled by a policy
by a policy limiting
a policy limiting the
policy limiting the send
limiting the send rate
in section v we
section v we evaluate
overloaded networks and end
v we evaluate the
we evaluate the performance
create directory and so
evaluate the performance of
directory and so on
the performance of this
hosts can exhibit continuous
when the sink is
can exhibit continuous packet
the sink is ready
exhibit continuous packet loss
performance of this solution
sink is ready to
is ready to send
with each lost packet
and in section vi
it issues an upcall
the update is then
in section vi we
update is then passed
each lost packet driving
is then passed to
section vi we address
then passed to the
app elements of the
passed to the writeback
elements of the protocol
to the writeback subsystem
of the protocol stack
lost packet driving the
the protocol stack f
vi we address related
packet driving the system
we address related work
which sends it to
driving the system further
sends it to the
the system further and
it to the server
o events according to
to the server when
system further and further
events according to priorities
further and further out
according to priorities incoming
and further out of
c loudifying s ource
further out of sync
loudifying s ource r
out of sync with
s ource r epositories
of sync with respect
ource r epositories in
sync with respect to
r epositories in a
to priorities incoming data
the server when there
with respect to its
epositories in a revision
priorities incoming data policy
server when there is
respect to its real
in a revision control
incoming data policy get
when there is sufficient
a revision control system
data policy get messages
there is sufficient bandwidth
policy get messages pre
a master copy of
master copy of the
copy of the source
asynchronous writeback therefore only
of the source code
writeback therefore only delays
therefore only delays updates
o events process timer
only delays updates when
events process timer events
delays updates when there
process timer events register
updates when there is
timer events register to
when there is foreground
events register to send
there is foreground traffic
register to send app
is stored in a
massive buffering needs for
to send app app
stored in a logically
when bandwidth is high
in a logically centralized
buffering needs for high
send app app f
a logically centralized repository
needs for high throughput
for high throughput applications
the performance of asynchronous
performance of asynchronous writeback
of asynchronous writeback should
asynchronous writeback should be
each developer checks out
writeback should be comparable
developer checks out and
should be comparable to
checks out and then
be comparable to purely
out and then keeps
ip uses fixed size
and then keeps a
uses fixed size buffers
then keeps a working
fixed size buffers at
keeps a working copy
size buffers at receivers
a working copy on
buffers at receivers to
working copy on his
at receivers to prevent
comparable to purely synchronous
copy on his machine
one can think of
receivers to prevent overflows
can think of qsm
on his machine that
think of qsm as
his machine that mirrors
to purely synchronous writes
of qsm as a
machine that mirrors the
qsm as a collection
that mirrors the repository
the sender never pushes
as a collection of
but when bandwidth is
sender never pushes more
the developer edits files
never pushes more unacknowledged
a collection of protocol
pushes more unacknowledged data
developer edits files in
more unacknowledged data into
collection of protocol stacks
unacknowledged data into the
of protocol stacks in
data into the network
protocol stacks in which
into the network than
stacks in which components
the network than the
edits files in his
when bandwidth is insufficient
files in his working
network than the receiver
in his working copy
than the receiver is
his working copy and
the receiver is capable
working copy and periodically
in which components act
copy and periodically commits
which components act as
and periodically commits the
components act as both
periodically commits the changes
act as both feeds
receiver is capable of
asynchronous writes will improve
commits the changes back
as both feeds and
is capable of holding
writes will improve the
the changes back to
both feeds and as
will improve the performance
changes back to the
feeds and as sinks
improve the performance non
back to the repository
the size of the
the overall structure is
size of the fluctuating
overall structure is of
of the fluctuating window
structure is of a
and updates his working
the fluctuating window at
updates his working copy
is of a forest
his working copy to
of a forest of
working copy to reflect
a forest of trees
fluctuating window at the
an implementation without priorities
window at the sender
copy to reflect the
at the sender is
to reflect the changes
the sender is bounded
reflect the changes made
sender is bounded by
the changes made by
is bounded by the
implementation without priorities will
bounded by the size
changes made by other
without priorities will result
by the size of
priorities will result in
o was to reduce
will result in the
made by other developers
result in the completion
was to reduce staleness
in the completion times
the size of the
the completion times for
size of the buffer
completion times for all
each commit is assigned
times for all rpcs
commit is assigned a
for all rpcs increasing
to reduce staleness by
of the buffer at
reduce staleness by postponing
all rpcs increasing uniformly
staleness by postponing the
the buffer at the
by postponing the creation
buffer at the receiver
is assigned a unique
postponing the creation of
when priorities are used
the creation of control
creation of control messages
of control messages until
control messages until the
a backlog of low
messages until the time
until the time when
the repository maintains complete
the time when transmission
time when transmission is
repository maintains complete history
when transmission is actually
priority rpcs will accumulate
transmission is actually about
maintains complete history so
the quantity of inflight
is actually about to
complete history so at
quantity of inflight unacknowledged
while the time taken
history so at any
actually about to take
so at any point
about to take place
of inflight unacknowledged data
the time taken for
inflight unacknowledged data has
time taken for high
at any point in
unacknowledged data has to
any point in time
data has to be
point in time it
has to be extremely
priority rpcs to complete
to be extremely high
rpcs to complete will
be extremely high for
to complete will increase
extremely high for the
complete will increase more
high for the flow
will increase more gradually
for the flow to
in time it is
time information is more
time it is possible
information is more accurate
the flow to saturate
our design is based
flow to saturate the
design is based on
to saturate the network
is based on the
and this makes qsm
based on the assumption
this makes qsm more
on the assumption that
makes qsm more stable
the assumption that when
since the size of
assumption that when bandwidth
the size of the
that when bandwidth is
size of the receiver
it is possible to
of the receiver window
an unintended benefit is
when bandwidth is low
unintended benefit is that
the receiver window limits
benefit is that the
receiver window limits the
is that the pull
window limits the sending
that the pull architecture
an assignment of differentiated
the pull architecture slashes
assignment of differentiated priorities
pull architecture slashes buffering
of differentiated priorities will
architecture slashes buffering and
differentiated priorities will improve
slashes buffering and memory
priorities will improve the
buffering and memory overheads
limits the sending envelope
will improve the response
is possible to check
improve the response times
possible to check out
the response times for
to check out a
response times for interactive
check out a working
times for interactive tasks
out a working copy
it plays a major
a working copy for
plays a major role
working copy for any
as we shall demonstrate
a major role in
copy for any specified
if a task which
major role in determining
a task which predominantly
role in determining tcp
for any specified version
turns out to have
task which predominantly performs
any specified version number
which predominantly performs reads
out to have an
predominantly performs reads executes
to have an enormous
performs reads executes in
have an enormous impact
reads executes in parallel
an enormous impact on
executes in parallel to
enormous impact on performance
in parallel to a
storing a repository in
the default receiver buffer
a repository in the
default receiver buffer sizes
repository in the cloud
receiver buffer sizes in
in the cloud eliminates
in qsm each element
the cloud eliminates worries
buffer sizes in many
cloud eliminates worries of
sizes in many standard
eliminates worries of data
in many standard tcp
worries of data loss
qsm each element of
parallel to a task
each element of a
to a task which
element of a protocol
a task which performs
of a protocol stack
of data loss due
a protocol stack acts
data loss due to
protocol stack acts as
loss due to hardware
stack acts as a
due to hardware failure
acts as a feed
task which performs many
ip implementations are in
as a feed that
implementations are in the
which performs many writes
are in the range
but issues of access
in the range of
issues of access control
the range of tens
of access control and
range of tens of
access control and consistency
of tens of kilobytes
a feed that has
control and consistency must
feed that has data
and consistency must still
the first task will
consistency must still be
first task will receive
and consequently inadequate receiver
task will receive a
that has data to
must still be addressed
consequently inadequate receiver buffering
will receive a higher
inadequate receiver buffering is
receive a higher share
receiver buffering is the
a higher share of
has data to send
higher share of the
authorized users should be
buffering is the first
users should be able
is the first hurdle
should be able to
the first hurdle faced
be able to commit
first hurdle faced by
able to commit new
hurdle faced by most
to commit new versions
faced by most practical
commit new versions of
by most practical deployments
share of the bandwidth
or a sink that
new versions of files
a sink that can
versions of files to
sink that can send
of files to the
a natural solution is
that can send it
natural solution is to
files to the repository
solution is to increase
many applications have patterns
is to increase the
applications have patterns of
to increase the size
have patterns of interactive
increase the size of
patterns of interactive file
the size of the
but not edit existing
of interactive file access
size of the receiver
not edit existing history
interactive file access involving
of the receiver buffers
file access involving both
and many play both
access involving both reads
many play both roles
users expect the repository
involving both reads and
expect the repository to
both reads and writes
the repository to be
in many cases the
repository to be consistent
many cases the receiving
to be consistent and
cases the receiving end
be consistent and for
consistent and for any
and for any changes
for any changes they
any changes they make
compiling source files involves
changes they make not
host may not have
source files involves interspersed
may not have the
files involves interspersed reads
not have the spare
involves interspersed reads and
have the spare memory
interspersed reads and writes
the spare memory capacity
they make not to
spare memory capacity to
make not to be
memory capacity to buffer
rather than creating a
but does not issue
capacity to buffer the
not to be pre
than creating a message
does not issue concurrent
creating a message and
not issue concurrent rpcs
a message and handing
issue concurrent rpcs frequently
message and handing it
to buffer the entire
and handing it down
buffer the entire bandwidth
handing it down to
even in the face
it down to the
in the face of
such an application will
the face of cloud
down to the sink
face of cloud services
an application will have
delay product of the
application will have improved
product of the long
of cloud services that
a feed registers the
cloud services that offer
feed registers the intent
services that offer lesser
registers the intent to
will have improved read
that offer lesser guarantees
have improved read performance
the intent to send
improved read performance when
intent to send a
the need for larger
to send a message
read performance when there
need for larger buffers
performance when there is
for these reasons we
send a message with
these reasons we do
a message with the
for larger buffers is
when there is contention
larger buffers is orthogonal
there is contention with
buffers is orthogonal to
is contention with other
is orthogonal to the
message with the sink
reasons we do not
contention with other applications
we do not expect
orthogonal to the flow
do not expect that
to the flow control
not expect that clients
the message can be
expect that clients will
message can be created
that clients will be
can be created at
clients will be directly
but will correspondingly be
the flow control mechanisms
be created at this
will be directly using
will correspondingly be penalised
be directly using the
flow control mechanisms used
directly using the cloud
control mechanisms used within
using the cloud storage
mechanisms used within tcp
the cloud storage api
correspondingly be penalised on
created at this time
cloud storage api anytime
be penalised on writes
ip and impacts all
storage api anytime soon
at this time and
and impacts all variants
this time and buffered
this does not match
time and buffered in
does not match our
and buffered in the
impacts all variants equally
buffered in the feed
but that they will
not match our design
that they will contact
match our design goal
they will contact one
our design goal of
will contact one of
design goal of having
contact one of a
goal of having interactive
but the creation may
one of a set
the creation may also
of a set of
creation may also be
a set of front
may also be postponed
also be postponed until
be postponed until the
postponed until the time
read applications obtain a
fec fec encoders are
end servers that are
fec encoders are typically
applications obtain a larger
encoders are typically parameterized
obtain a larger share
are typically parameterized with
a larger share of
typically parameterized with an
larger share of bandwidth
until the time when
servers that are responsible
the time when the
that are responsible for
time when the sink
are responsible for enforcing
when the sink polls
responsible for enforcing access
the sink polls the
for enforcing access control
sink polls the feed
we have implemented two
polls the feed for
have implemented two solutions
the feed for messages
implemented two solutions to
feed for messages to
two solutions to this
for messages to transmit
solutions to this problem
tuple for each outgoing
for each outgoing sequence
each outgoing sequence of
and pushing the data
outgoing sequence of r
based on making writes
sequence of r data
on making writes asynchronous
of r data packets
pushing the data into
the sink determines its
the data into the
sink determines its readiness
data into the cloud
determines its readiness to
a total of r
its readiness to send
readiness to send based
to send based on
used in several existing
send based on a
in several existing systems
c data and error
based on a control
data and error correction
on a control policy
and error correction packets
several existing systems and
error correction packets are
these might consist of
existing systems and incorporated
might consist of virtualized
correction packets are sent
systems and incorporated in
consist of virtualized server
packets are sent over
and incorporated in mfs
of virtualized server instances
are sent over the
incorporated in mfs for
virtualized server instances in
sent over the channel
in mfs for the
server instances in the
mfs for the purposes
instances in the cloud
for the purposes of
when the socket at
the purposes of comparison
the socket at the
socket at the root
at the root of
or traditional physical machines
the root of the
redundancy information cannot be
traditional physical machines owned
root of the tree
information cannot be generated
physical machines owned by
cannot be generated and
which is new to
machines owned by the
of the tree is
be generated and sent
is new to mfs
generated and sent until
the tree is ready
owned by the community
and sent until all
tree is ready for
sent until all r
is ready for transmission
until all r data
an alternative approach is
all r data packets
but in either case
alternative approach is to
in either case their
messages will be recursively
approach is to retain
will be recursively pulled
is to retain synchronous
be recursively pulled from
either case their local
recursively pulled from the
to retain synchronous writes
r data packets are
case their local storage
pulled from the tree
their local storage systems
from the tree of
local storage systems are
but assign priorities according
storage systems are allowed
assign priorities according to
systems are allowed to
priorities according to some
are allowed to be
according to some notion
allowed to be cheap
to some notion of
to be cheap and
some notion of relative
be cheap and unresilient
notion of relative importance
cheap and unresilient against
of relative importance of
and unresilient against hardware
relative importance of processes
unresilient against hardware failure
data packets are available
the tree of protocol
packets are available for
tree of protocol stack
are available for sending
another consideration with any
of protocol stack components
consideration with any hosting
with any hosting solution
existing operating systems and
any hosting solution is
operating systems and applications
hosting solution is resource
systems and applications generally
solution is resource provisioning
and applications generally do
applications generally do not
the latency of packet
generally do not provide
latency of packet recovery
do not provide this
of packet recovery is
feeds that no longer
open source communities with
packet recovery is determined
not provide this information
source communities with limited
that no longer have
communities with limited budgets
no longer have data
with limited budgets and
longer have data to
recovery is determined by
limited budgets and private
is determined by the
budgets and private enterprises
determined by the rate
and private enterprises that
by the rate at
so we have not
the rate at which
we have not investigated
rate at which the
have not investigated it
at which the sender
not investigated it further
have data to send
which the sender transmits
private enterprises that are
data to send are
the sender transmits data
enterprises that are increasingly
to send are automatically
the cache manager s
that are increasingly cost
cache manager s writeback
send are automatically deregistered
manager s writeback thread
generating error correction packets
s writeback thread divides
writeback thread divides updates
error correction packets from
thread divides updates into
sensitive may well prefer
correction packets from less
may well prefer to
divides updates into metadata
packets from less than
updates into metadata operations
well prefer to pay
from less than r
prefer to pay just
less than r data
to pay just for
than r data packets
such as directory modifications
pay just for the
r data packets at
just for the resources
sharing and priority i
as directory modifications and
data packets at the
for the resources they
packets at the sender
the resources they use
directory modifications and file
at the sender is
modifications and file status
the sender is not
and file status changes
sender is not a
rather than trying to
is not a viable
than trying to budget
not a viable option
trying to budget in
a viable option even
to budget in advance
viable option even though
budget in advance what
option even though the
in advance what they
even though the data
advance what they are
though the data rate
what they are going
and prone to oscillatory
they are going to
prone to oscillatory throughput
the data rate in
the two types of
are going to need
two types of operations
data rate in this
to oscillatory throughput when
types of operations are
oscillatory throughput when scaled
rate in this channel
of operations are queued
throughput when scaled up
cloud computing makes this
in this channel is
operations are queued and
computing makes this a
are queued and replayed
makes this a possibility
this channel is low
when we decided to
queued and replayed to
we decided to take
and replayed to the
decided to take control
replayed to the server
to take control over
to the server separately
take control over event
and increased competition among
control over event processing
increased competition among providers
over event processing order
competition among providers of
so that a metadata
among providers of commodity
that a metadata rpc
providers of commodity services
a metadata rpc can
we also eliminated multithreading
metadata rpc can proceed
of commodity services will
rpc can proceed in
commodity services will ensure
can proceed in parallel
services will ensure that
proceed in parallel with
will ensure that prices
in parallel with a
ensure that prices are
parallel with a file
that prices are reasonable
with a file writeback
grained scheduling eliminated convoy
scheduling eliminated convoy behavior
eliminated convoy behavior and
when an rpc from
an rpc from a
convoy behavior and oscillatory
rpc from a particular
c ase s tudy
h a b c
from a particular queue
a b c d
behavior and oscillatory throughput
b c d x
a particular queue completes
and oscillatory throughput of
c d x x
oscillatory throughput of the
d x x e
throughput of the sort
x x e f
we say that the
x e f g
of the sort that
say that the update
e f g h
that the update has
f g h x
the update has been
g h x x
update has been committed
h x x a
the sort that can
has been committed at
sort that can disrupt
been committed at the
by far the most
x x a c
far the most popular
x a c b
that can disrupt reliable
committed at the server
can disrupt reliable multicast
a c b e
disrupt reliable multicast systems
c b e d
the most popular general
reliable multicast systems when
b e d a
multicast systems when they
the next update is
systems when they run
next update is then
when they run at
update is then dequeued
they run at high
is then dequeued and
run at high data
most popular general purpose
at high data rates
popular general purpose cloud
high data rates on
general purpose cloud storage
data rates on a
purpose cloud storage service
rates on a large
cloud storage service today
on a large scale
storage service today is
g g x x
service today is amazon
g x x f
update logging an asynchronous
today is amazon s
x x f h
logging an asynchronous rpc
the last aspect relates
an asynchronous rpc for
last aspect relates to
x f h x
is amazon s s
asynchronous rpc for it
aspect relates to the
f h x x
relates to the creation
h x x b
to the creation of
rpc for it is
the creation of new
for it is initiated
creation of new messages
we chose to use
chose to use this
to use this as
separating the small update
particularly by qsm itself
the small update logging
use this as a
this as a basis
as a basis for
a basis for cost
readers who have implemented
basis for cost studies
who have implemented multicast
for cost studies and
have implemented multicast protocols
cost studies and for
which is implemented in
implemented multicast protocols will
is implemented in some
multicast protocols will know
studies and for the
protocols will know that
implemented in some mobile
will know that most
in some mobile file
know that most existing
some mobile file sys
that most existing systems
and for the implementation
most existing systems are
for the implementation of
existing systems are push
the implementation of our
implementation of our system
metadata rpcs from file
separate encoding for odd
rpcs from file writes
encoding for odd and
from file writes allows
for odd and even
file writes allows remote
odd and even packets
writes allows remote clients
and even packets could
allows remote clients to
even packets could be
remote clients to see
packets could be operating
is an appealing choice
could be operating at
clients to see statems
be operating at near
an appealing choice because
operating at near full
some layer initiates a
at near full capacity
appealing choice because amazon
near full capacity with
choice because amazon also
full capacity with data
because amazon also offers
capacity with data from
amazon also offers the
with data from other
layer initiates a new
also offers the ec
data from other senders
initiates a new message
a new message at
new message at will
fec is also very
is also very susceptible
and lower layers then
also very susceptible to
lower layers then buffer
so it is possible
layers then buffer that
it is possible to
then buffer that message
very susceptible to bursty
buffer that message until
susceptible to bursty losses
that message until it
is possible to use
message until it can
possible to use their
until it can be
to use their services
it can be sent
use their services as
their services as a
services as a complete
as a complete hosting
a complete hosting solution
this makes sense under
complete hosting solution with
makes sense under the
hosting solution with low
sense under the assumption
solution with low latency
under the assumption that
with low latency access
the assumption that senders
tus changes to files
assumption that senders often
low latency access to
that senders often generate
latency access to storage
senders often generate bursts
changes to files without
often generate bursts of
to files without having
generate bursts of packets
files without having to
without having to wait
having to wait for
to wait for intervening
wait for intervening writequirement
for intervening writequirement that
intervening writequirement that processes
writequirement that processes wait
that processes wait for
the communication subsystem can
processes wait for writes
communication subsystem can smooth
is a standard encoding
subsystem can smooth the
a standard encoding technique
can smooth the traffic
standard encoding technique used
smooth the traffic flow
encoding technique used to
the traffic flow and
rather than sending an
traffic flow and keep
than sending an back
flow and keep the
sending an back traffic
and keep the network
technique used to combat
keep the network interface
used to combat bursty
the network interface busy
to combat bursty loss
the cost analysis is
cost analysis is based
a similar motivation underlies
analysis is based on
similar motivation underlies the
is based on real
where error correction packets
motivation underlies the cache
error correction packets are
one consequence is that
correction packets are generated
underlies the cache consisupdate
packets are generated from
world traces taken from
are generated from alternate
traces taken from the
generated from alternate disjoint
the cache consisupdate to
consequence is that messages
cache consisupdate to the
is that messages can
consisupdate to the server
that messages can linger
to the server as
messages can linger for
the server as soon
can linger for a
server as soon as
linger for a while
as soon as a
taken from the subversion
soon as a file
from alternate disjoint sub
from the subversion repositories
as a file is
the subversion repositories of
a file is closed
subversion repositories of popular
for a while before
repositories of popular open
streams of data rather
a while before they
the cache manager tency
of data rather than
of popular open source
while before they are
cache manager tency scheme
data rather than from
popular open source projects
before they are sent
manager tency scheme for
rather than from consecutive
tency scheme for high
than from consecutive packets
scheme for high read
subversion represents each revision
not only does this
represents each revision in
only does this increase
each revision in a
does this increase memory
revision in a repository
write contention environments we
this increase memory consumption
with an interleave index
contention environments we logs
in a repository s
an interleave index of
environments we logs the
but if a message
we logs the update
a repository s history
logs the update and
if a message contains
the update and periodically
a message contains current
update and periodically flushes
message contains current state
and periodically flushes logged
regardless of how many
periodically flushes logged updates
contains current state information
flushes logged updates to
of how many changes
the encoder would create
logged updates to the
encoder would create correction
updates to the describe
would create correction packets
to the describe in
how many changes it
that state may be
create correction packets separately
state may be stale
many changes it contains
the describe in section
correction packets separately from
may be stale by
packets separately from three
be stale by the
separately from three disjoint
stale by the time
from three disjoint sub
by the time it
the time it s
time it s sent
the first for data
the chief complexity in
chief complexity in implementing
complexity in implementing asynchronous
in contrast to this
in implementing asynchronous writeserver
contrast to this usual
as a diff against
the first containing data
to this usual approach
first containing data packets
a diff against previous
containing data packets numbered
diff against previous revisions
these systems enable logging
systems enable logging when
enable logging when bandwidth
qsm implements a pull
logging when bandwidth is
implements a pull architecture
and the second for
when bandwidth is low
the second for meta
to improve read performance
data such as the
improve read performance and
such as the author
read performance and reduce
evaluation evaluation of qsm
performance and reduce write
evaluation of qsm could
and reduce write traffic
of qsm could pursue
reduce write traffic by
qsm could pursue many
write traffic by aggregat
and other revision properties
could pursue many directions
back lies in resolving
our cost analysis is
costs of the domain
cost analysis is based
lies in resolving dependencies
analysis is based on
of the domain crossing
is based on the
the domain crossing between
in resolving dependencies between
based on the sizes
resolving dependencies between metadata
on the sizes of
domain crossing between the
the sizes of these
crossing between the application
sizes of these files
between the application and
dependencies between metadata operations
the application and qsm
of these files and
between metadata operations ing
these files and the
metadata operations ing updates
files and the time
operations ing updates to
protocol design and scalability
ing updates to the
and the time at
updates to the same
the time at which
to the same file
time at which each
the same file in
at which each revision
and interactions between protocol
which each revision was
the second with data
each revision was committed
second with data packets
same file in the
interactions between protocol properties
file in the log
with data packets numbered
in the log before
between protocol properties and
the log before they
protocol properties and the
looking up the size
log before they are
properties and the managed
up the size of
before they are transmitted
and the managed framework
the size of these
size of these special
of these special files
and updates to the
here we focus on
updates to the same
we focus on the
to the same file
focus on the latter
these special files is
special files is only
files is only possible
is only possible if
our goal is to
only possible if one
goal is to arrive
a file may be
possible if one has
file may be created
if one has filesystem
is to arrive at
one has filesystem level
to arrive at a
has filesystem level access
arrive at a deep
update logging separates communication
filesystem level access to
logging separates communication with
at a deep understanding
separates communication with the
level access to the
communication with the server
access to the disk
with the server into
a deep understanding of
the server into modified
to the disk on
deep understanding of the
the disk on which
understanding of the performance
disk on which the
server into modified and
of the performance limits
on which the repository
the performance limits of
which the repository is
into modified and closed
performance limits of qsm
the repository is stored
limits of qsm when
of qsm when operating
qsm when operating at
and the length of
when operating at high
the length of the
operating at high data
length of the metadata
at high data rates
so we had to
high data rates with
of the metadata queue
data rates with large
we had to use
rates with large numbers
the metadata queue may
and the third with
metadata queue may two
the third with data
queue may two distinct
had to use subversion
with large numbers of
to use subversion s
large numbers of overlapping
use subversion s mirroring
numbers of overlapping groups
third with data packets
may two distinct streams
subversion s mirroring capability
with data packets numbered
s mirroring capability to
mirroring capability to fetch
for reasons of brevity
capability to fetch revisions
updates to files and
to fetch revisions from
to files and directories
fetch revisions from the
we are unable to
revisions from the network
are unable to undertake
unable to undertake a
to undertake a detailed
and all be enough
undertake a detailed analysis
all be enough to
a detailed analysis of
be enough to mean
detailed analysis of oscillatory
enough to mean that
analysis of oscillatory phenomena
to mean that the
of oscillatory phenomena in
mean that the file
oscillatory phenomena in this
that the file update
phenomena in this paper
the file update would
accessible repository and replay
file update would be
repository and replay them
update would be initiated
and replay them against
also called convoys and
replay them against a
called convoys and broadcast
them against a local
convoys and broadcast storms
against a local copy
would be initiated first
these plague many multicast
plague many multicast and
doing this also implicitly
many multicast and pub
this also implicitly gives
also implicitly gives us
implicitly gives us the
these two types of
gives us the log
two types of communication
us the log of
types of communication are
the log of timestamps
of communication are scheduled
log of timestamps indicating
communication are scheduled this
of timestamps indicating when
are scheduled this case
timestamps indicating when each
scheduled this case the
indicating when each revision
this case the file
when each revision was
case the file update
each revision was committed
the file update must
event prioritization eliminated such
file update must wait
prioritization eliminated such problems
eliminated such problems in
such problems in the
thus it is possible
problems in the configurations
it is possible to
in the configurations tested
is possible to calculate
the configurations tested by
possible to calculate the
configurations tested by our
to calculate the bandwidth
a file may be
tested by our experiments
test activity gc grep
interleaving adds burst tolerance
activity gc grep compile
adds burst tolerance to
gc grep compile grep
burst tolerance to fec
grep compile grep write
transaction costs of pushing
tolerance to fec but
costs of pushing the
compile grep write read
of pushing the two
to fec but exacerbates
pushing the two files
grep write read compile
on varying numbers of
write read compile read
varying numbers of nodes
read compile read write
the two files for
compile read write gw
two files for each
read write gw rc
files for each revision
write gw rc rw
for each revision into
gw rc rw synchronous
each revision into s
rc rw synchronous uniform
fec but exacerbates its
rw synchronous uniform priorities
we ll find that
but exacerbates its sensitivity
ll find that the
exacerbates its sensitivity to
find that the experiments
its sensitivity to sending
that the experiments have
sensitivity to sending rate
based on amazon s
to sending rate with
on amazon s current
sending rate with an
amazon s current pricing
rate with an interleave
s current pricing structure
the experiments have a
with an interleave index
experiments have a pattern
an interleave index of
interleave index of i
shown in table i
index of i and
of i and an
i and an encoding
in scenario after scenario
and an encoding rate
table i a mazon
an encoding rate of
i a mazon s
a mazon s s
the performance of qsm
performance of qsm is
of qsm is ultimately
qsm is ultimately limited
is ultimately limited by
ultimately limited by overheads
limited by overheads associated
by overheads associated with
overheads associated with memory
associated with memory management
with memory management in
memory management in the
management in the managed
in the managed environment
the sender would have
sender would have to
would have to wait
have to wait for
to wait for i
the more memory in
more memory in use
the higher the overheads
higher the overheads of
the overheads of the
overheads of the memory
of the memory management
the memory management subsystem
memory management subsystem and
management subsystem and the
subsystem and the more
packets before sending any
and the more cpu
before sending any redundancy
the more cpu time
sending any redundancy information
more cpu time it
cpu time it consumes
these two obstacles to
two obstacles to using
leaving less time for
obstacles to using fec
less time for qsm
to using fec in
time for qsm to
using fec in time
for qsm to run
sensitive settings rate sensitivity
these aren t just
settings rate sensitivity and
aren t just garbage
rate sensitivity and burst
t just garbage collection
sensitivity and burst susceptibility
just garbage collection costs
and burst susceptibility are
burst susceptibility are interlinked
susceptibility are interlinked through
are interlinked through the
interlinked through the tuning
every aspect of memory
through the tuning knobs
aspect of memory management
of memory management gets
memory management gets expensive
an interleave of i
interleave of i and
of i and a
and the costs grow
i and a rate
the costs grow linearly
and a rate of
costs grow linearly in
grow linearly in the
linearly in the amount
in the amount of
the amount of memory
amount of memory in
of memory in use
when qsm runs flat
provides tolerance to a
tolerance to a burst
to a burst of
a burst of up
burst of up to
of up to c
up to c i
not included in the
to c i consecutive
included in the analysis
c i consecutive packets
cpu cycles are a
in the analysis is
cycles are a precious
the analysis is the
are a precious commodity
analysis is the cost
is the cost of
the cost of fetching
cost of fetching data
of fetching data out
fetching data out of
the burst tolerance of
data out of s
burst tolerance of an
minimizing the memory footprint
tolerance of an fec
the memory footprint turns
of an fec code
memory footprint turns out
to be served to
footprint turns out to
be served to clients
turns out to be
an fec code can
out to be the
fec code can be
to be the key
code can be changed
be the key to
can be changed by
this cost will vary
be changed by modulating
cost will vary depending
changed by modulating either
will vary depending on
by modulating either the
the key to high
modulating either the c
key to high performance
either the c or
vary depending on how
the c or the
depending on how much
c or the i
on how much caching
or the i parameters
how much caching is
all results reported here
much caching is done
results reported here come
caching is done on
reported here come from
is done on the
here come from experiments
increasing c enhances burst
come from experiments on
done on the front
c enhances burst tolerance
from experiments on a
enhances burst tolerance at
burst tolerance at the
tolerance at the cost
at the cost of
the cost of network
cost of network and
of network and encoding
network and encoding overhead
potentially worsening the packet
worsening the packet loss
the packet loss experienced
packet loss experienced and
loss experienced and reducing
experienced and reducing throughput
cluster of pentium iii
increasing i trades off
i trades off recovery
trades off recovery latency
off recovery latency for
recovery latency for better
and dedicated servers potentially
latency for better burst
dedicated servers potentially having
for better burst tolerance
servers potentially having much
better burst tolerance without
potentially having much more
burst tolerance without adding
having much more due
tolerance without adding overhead
much more due to
without adding overhead as
more due to inexpensive
adding overhead as mentioned
due to inexpensive sata
to inexpensive sata disks
for higher values of
higher values of i
it is not unreasonable
connected into a single
is not unreasonable to
into a single broadcast
not unreasonable to assume
a single broadcast domain
unreasonable to assume that
single broadcast domain using
to assume that a
broadcast domain using a
the encoder has to
assume that a cache
encoder has to wait
that a cache hit
domain using a switched
a cache hit rate
has to wait for
cache hit rate of
to wait for more
hit rate of close
wait for more data
rate of close to
for more data packets
more data packets to
data packets to be
packets to be transmitted
to be transmitted before
be transmitted before it
transmitted before it can
before it can send
it can send error
nodes run windows server
can send error correction
send error correction packets
once the fec encoding
the fec encoding is
fec encoding is parameterized
encoding is parameterized with
is parameterized with a
parameterized with a rate
with a rate and
a rate and an
rate and an interleave
and an interleave to
an interleave to tolerate
interleave to tolerate a
to tolerate a certain
tolerate a certain burst
a certain burst length
public subversion repositories of
certain burst length b
subversion repositories of the
repositories of the debian
of the debian linux
the debian linux community
debian linux community amount
linux community amount to
community amount to a
amount to a total
to a total of
a total of only
our benchmark is an
benchmark is an nary
linked to the qsm
to the qsm library
the only outgoing bandwidth
only outgoing bandwidth costs
outgoing bandwidth costs are
bandwidth costs are then
running in the same
costs are then to
in the same process
are then to to
then to to replace
to to replace failed
to replace failed frontend
replace failed frontend servers
failed frontend servers or
frontend servers or to
servers or to synchronize
or to synchronize replicas
to synchronize replicas if
to tolerate a burst
synchronize replicas if more
tolerate a burst of
replicas if more than
a burst of length
if more than one
more than one is
than one is in
one is in use
in the case of
the case of ec
the bandwidth costs are
bandwidth costs are actually
at the maximum possible
costs are actually waived
the maximum possible rate
are actually waived and
actually waived and the
waived and the user
and the user then
the user then pays
user then pays only
then pays only for
pays only for the
only for the traffic
the majority of the
for the traffic between
majority of the figures
the traffic between the
of the figures include
traffic between the front
all losses occurring in
losses occurring in bursts
occurring in bursts of
end servers and their
in bursts of size
servers and their clients
bursts of size less
of size less than
size less than or
less than or equal
table ii shows the
than or equal to
ii shows the cost
or equal to b
but these intervals are
equal to b are
these intervals are sometimes
to b are recovered
intervals are sometimes so
shows the cost of
are sometimes so small
the cost of using
sometimes so small that
cost of using s
b are recovered with
so small that they
are recovered with the
small that they may
recovered with the same
that they may not
for a number of
with the same latency
a number of individual
they may not always
number of individual open
may not always be
of individual open source
not always be visible
individual open source projects
the same latency and
same latency and this
latency and this latency
and this latency depends
this latency depends on
as well as an
latency depends on the
well as an aggregate
depends on the i
as an aggregate for
on the i parameter
an aggregate for the
growing cost of memory
cost of memory allocation
we d like to
d like to parameterize
repositories of the debian
like to parameterize the
of the debian community
to parameterize the encoding
parameterize the encoding to
the encoding to tolerate
also shown is an
encoding to tolerate a
shown is an estimate
to tolerate a maximum
is an estimate for
tolerate a maximum burst
an estimate for the
a maximum burst length
estimate for the apache
maximum burst length and
for the apache software
burst length and then
the apache software foundation
length and then have
and then have recovery
then have recovery latency
have recovery latency depend
recovery latency depend on
apache has taken the
latency depend on the
has taken the unusual
depend on the actual
taken the unusual approach
on the actual burstiness
the unusual approach of
the actual burstiness of
unusual approach of using
actual burstiness of the
approach of using a
burstiness of the loss
of using a single
using a single repository
a single repository for
single repository for all
repository for all of
for all of its
at the same time
all of its projects
throughput as a function
as a function of
a function of the
we would like the
function of the number
would like the encoding
of the number of
both public and restricted
like the encoding to
the number of nodes
the encoding to have
encoding to have a
to have a constant
due to access control
have a constant rate
to access control restrictions
a constant rate for
access control restrictions on
constant rate for network
control restrictions on some
rate for network provisioning
restrictions on some paths
for network provisioning and
network provisioning and stability
subversion s mirroring tool
s mirroring tool was
mirroring tool was unable
tool was unable to
was unable to create
unable to create local
to create local copy
an fec scheme is
fec scheme is required
scheme is required where
is required where latency
the complete log of
required where latency of
complete log of timestamps
where latency of recovery
latency of recovery degrades
of recovery degrades gracefully
recovery degrades gracefully as
degrades gracefully as losses
gracefully as losses get
as losses get burstier
processor utilization as a
utilization as a function
as a function of
a function of the
function of the multicast
even as the encoding
of the multicast rate
as the encoding overhead
the encoding overhead stays
how much does it
encoding overhead stays constant
much does it cost
description monthly storage bandwidth
monthly storage bandwidth in
storage bandwidth in bandwidth
bandwidth in bandwidth out
in bandwidth out per
memory overheads on the
overheads on the sender
on the sender we
the sender we begin
sender we begin by
we begin by showing
begin by showing that
by showing that memory
showing that memory overhead
that memory overhead at
memory overhead at the
overhead at the sender
at the sender is
the sender is a
sender is a central
is a central to
reads apache software foundation
a central to throughput
apache software foundation debian
software foundation debian linux
foundation debian linux community
shows throughput in messages
end flow control x
s in experiments with
flow control x appliance
control x appliance appliance
x appliance appliance end
senders multicasting to a
multicasting to a varying
to a varying number
a varying number of
varying number of receivers
all of which belong
of which belong to
which belong to a
belong to a single
to a single group
with a single sender
no rate limit was
rate limit was used
the sender has more
sender has more work
has more work to
split flow control fig
more work to do
work to do than
to do than the
do than the receivers
than the receivers and
the receivers and on
receivers and on our
and on our clusters
isn t fast enough
t fast enough to
flow control options in
fast enough to saturate
control options in maelstrom
enough to saturate the
to saturate the network
lan mtu lambda jumbo
mtu lambda jumbo mtu
lambda jumbo mtu recipe
jumbo mtu recipe list
we report the highest
report the highest combined
the highest combined send
highest combined send rate
combined send rate that
send rate that the
rate that the system
that the system could
the system could sustain
system could sustain without
could sustain without developing
sustain without developing backlogs
without developing backlogs at
developing backlogs at the
backlogs at the senders
why does performance decrease
does performance decrease with
performance decrease with the
decrease with the number
with the number of
the number of receivers
let s focus on
s focus on a
shows that whereas receivers
that whereas receivers are
whereas receivers are not
receivers are not cpu
and loss rates in
loss rates in this
rates in this experiment
the sender is saturated
and hence is the
hence is the bottleneck
running this test again
this test again in
test again in a
again in a profiler
size of repository stored
in a profiler reveals
of repository stored in
a profiler reveals that
repository stored in s
profiler reveals that the
reveals that the percentage
that the percentage of
the percentage of time
percentage of time spent
of time spent in
time spent in qsm
repair packets are injected
spent in qsm code
packets are injected into
in qsm code is
are injected into stream
qsm code is decreasing
injected into stream transparently
into stream transparently iv
so we based our
we based our analysis
based our analysis on
whereas more and more
our analysis on that
more and more time
analysis on that along
and more time is
m aelstrom d esign
on that along with
more time is spent
aelstrom d esign and
that along with the
d esign and i
along with the assumption
esign and i mplementation
with the assumption each
and i mplementation we
the assumption each revision
time is spent in
assumption each revision data
is spent in mscorwks
each revision data file
i mplementation we describe
revision data file would
mplementation we describe the
data file would be
we describe the maelstrom
describe the maelstrom appliance
the maelstrom appliance as
maelstrom appliance as a
appliance as a single
as a single machine
a single machine later
we will show how
will show how more
show how more machines
how more machines can
more machines can be
machines can be added
kib and each revision
can be added to
and each revision property
be added to the
each revision property file
added to the appliance
to the appliance to
the appliance to balance
appliance to balance encoding
to balance encoding load
balance encoding load and
encoding load and scale
load and scale to
and scale to multiple
scale to multiple gigabits
to multiple gigabits per
multiple gigabits per second
gigabits per second of
per second of traffic
shows that the main
the averages observed for
that the main culprit
averages observed for the
the main culprit behind
observed for the other
main culprit behind the
for the other repositories
culprit behind the increase
the other repositories in
behind the increase of
other repositories in table
basic mechanism the basic
the increase of overhead
mechanism the basic operation
increase of overhead is
the basic operation of
of overhead is a
basic operation of maelstrom
repositories in table ii
overhead is a figure
operation of maelstrom is
of maelstrom is shown
maelstrom is shown in
is shown in figure
table ii m ost
ii m ost recent
m ost recent monthly
ost recent monthly cost
recent monthly cost of
monthly cost of storing
cost of storing repositories
of storing repositories in
storing repositories in s
the percentages of the
percentages of the profiler
of the profiler samples
the profiler samples taken
it intercepts outgoing data
for individual projects and
intercepts outgoing data packets
profiler samples taken from
individual projects and entire
outgoing data packets and
samples taken from qsm
data packets and routes
taken from qsm and
packets and routes them
from qsm and clr
projects and entire communities
and routes them to
qsm and clr dlls
and entire communities software
routes them to the
entire communities software project
them to the destination
communities software project squirrelmail
to the destination data
software project squirrelmail phpmyadmin
the destination data center
project squirrelmail phpmyadmin subversion
squirrelmail phpmyadmin subversion mono
phpmyadmin subversion mono kde
subversion mono kde hosting
generating and injecting fec
mono kde hosting community
and injecting fec repair
kde hosting community debian
injecting fec repair packets
hosting community debian linux
fec repair packets into
community debian linux community
repair packets into the
debian linux community apache
packets into the stream
memory allocation and garbage
linux community apache software
allocation and garbage collection
into the stream in
and garbage collection overheads
the stream in their
garbage collection overheads on
community apache software foundation
stream in their wake
apache software foundation monthly
collection overheads on the
software foundation monthly cost
overheads on the sender
on the sender node
a repair packet consists
repair packet consists of
the former grows by
packet consists of a
consists of a recipe
of a recipe list
a recipe list of
recipe list of data
list of data packet
of data packet identifiers
data packet identifiers and
packet identifiers and fec
identifiers and fec information
and fec information generated
and the latter by
fec information generated from
information generated from these
generated from these packets
in the example in
the example in figure
this information is a
information is a simple
is a simple xor
the size of the
size of the xor
of the xor is
the xor is equal
xor is equal to
is equal to the
equal to the mtu
to the mtu of
this configuration is typical
the mtu of the
configuration is typical of
mtu of the data
is typical of the
of the data center
typical of the host
the data center network
of the host environment
the host environment expected
host environment expected for
environment expected for our
expected for our target
for our target applications
and to avoid fragmentation
to avoid fragmentation of
avoid fragmentation of repair
fragmentation of repair packets
of repair packets we
repair packets we require
packets we require that
we require that the
require that the mtu
that the mtu of
the mtu of the
mtu of the long
haul network be set
of the overhead is
network be set to
the overhead is the
be set to a
overhead is the allocation
set to a slightly
is the allocation of
to a slightly larger
the allocation of byte
a slightly larger value
allocation of byte arrays
of byte arrays to
byte arrays to send
arrays to send in
to send in the
send in the application
this requirement is easily
requirement is easily satisfied
is easily satisfied in
easily satisfied in practice
since gigabit links very
gigabit links very often
links very often use
very often use jumbo
often use jumbo frames
use jumbo frames of
jumbo frames of up
frames of up to
even for the fairly
for the fairly large
the fairly large apache
fairly large apache software
large apache software foundation
while lan networks have
lan networks have standard
networks have standard mtus
have standard mtus of
the current cost of
current cost of using
cost of using s
of time is spent
time is spent exclusively
for storage is less
is spent exclusively on
storage is less than
spent exclusively on copying
exclusively on copying memory
on copying memory in
copying memory in the
memory in the clr
at the receiving data
the receiving data center
it is very unlikely
is very unlikely that
very unlikely that any
even though we used
unlikely that any vendor
the appliance examines incoming
though we used our
appliance examines incoming repair
we used our own
that any vendor could
examines incoming repair packets
used our own scatter
incoming repair packets and
any vendor could provide
repair packets and uses
vendor could provide a
packets and uses them
could provide a traditional
gather serialization scheme that
and uses them to
serialization scheme that efficiently
uses them to recover
scheme that efficiently uses
them to recover missing
that efficiently uses scatter
to recover missing data
provide a traditional storage
recover missing data packets
a traditional storage solution
traditional storage solution consisting
storage solution consisting of
solution consisting of scsi
consisting of scsi disks
of scsi disks and
scsi disks and tape
disks and tape backup
and tape backup at
the data packet is
tape backup at this
data packet is injected
the increase in the
packet is injected transparently
backup at this price
is injected transparently into
increase in the memory
injected transparently into the
in the memory allocation
transparently into the stream
the memory allocation overhead
into the stream to
the amount of s
the stream to the
memory allocation overhead and
stream to the receiving
allocation overhead and the
to the receiving end
overhead and the activity
storage required of course
and the activity of
required of course increases
the activity of the
of course increases each
activity of the garbage
course increases each month
of the garbage collector
increases each month as
the garbage collector are
each month as the
garbage collector are caused
recovered data packets will
collector are caused by
data packets will typically
are caused by the
packets will typically arrive
caused by the increasing
will typically arrive out
by the increasing memory
month as the repository
the increasing memory usage
as the repository grows
but as shown in
as shown in figure
order at the end
reflectsan increase of the
increase of the average
the increase is roughly
of the average number
and hence it is
the average number of
increase is roughly linear
average number of multicasts
hence it is vital
number of multicasts pending
of multicasts pending completion
it is vital that
is vital that packets
as developer productivity remains
vital that packets be
developer productivity remains constant
that packets be recovered
packets be recovered by
be recovered by the
recovered by the appliance
the cost of storage
by the appliance extremely
cost of storage is
the appliance extremely quickly
of storage is declining
appliance extremely quickly to
storage is declining exponentially
extremely quickly to avoid
quickly to avoid triggering
to avoid triggering mechanisms
avoid triggering mechanisms in
triggering mechanisms in commodity
mechanisms in commodity stacks
in commodity stacks that
a copy is kept
commodity stacks that interpret
copy is kept by
stacks that interpret out
is kept by the
kept by the sender
by the sender for
the sender for possible
sender for possible loss
for possible loss recovery
so if amazon s
if amazon s pricing
amazon s pricing stays
s pricing stays competitive
order arrival as congestion
notice that memory consumption
arrival as congestion in
that memory consumption grows
as congestion in the
memory consumption grows nearly
congestion in the network
term trend is towards
times faster than the
trend is towards lower
faster than the number
is towards lower costs
than the number of
the number of messages
flow control while relaying
number of messages pending
control while relaying tcp
of messages pending acknowledgement
additional costs will be
costs will be incurred
will be incurred for
be incurred for front
if we freeze the
we freeze the sender
freeze the sender process
maelstrom has two flow
the sender process and
has two flow control
sender process and inspect
two flow control modes
process and inspect the
for the case of
and inspect the contents
the case of ec
inspect the contents of
the contents of the
contents of the managed
of the managed heap
a standard machine instance
we find that the
standard machine instance is
find that the number
machine instance is billed
that the number of
instance is billed at
the number of objects
number of objects in
of objects in memory
illustrates these two modes
objects in memory is
in memory is more
memory is more than
is more than twice
more than twice the
than twice the number
twice the number of
the number of multicasts
number of multicasts pending
of multicasts pending acknowledgement
although some of these
some of these have
of these have already
these have already been
have already been acknowledged
plus data transfer of
they haven t yet
haven t yet been
t yet been garbage
yet been garbage collected
the appliance treats tcp
the growing amount of
growing amount of unacknowledged
ip packets as conventional
amount of unacknowledged data
packets as conventional ip
of unacknowledged data is
as conventional ip packets
unacknowledged data is caused
conventional ip packets and
data is caused by
ip packets and routes
per gib in and
packets and routes them
is caused by the
and routes them through
caused by the increase
routes them through without
by the increase of
them through without modification
the increase of the
increase of the average
of the average time
the average time to
average time to acknowledge
time to acknowledge a
to acknowledge a message
control to proceed between
to proceed between the
proceed between the end
discounts are available if
are available if data
available if data transfer
if data transfer exceeds
this grows because of
ip s semantics are
grows because of the
s semantics are not
because of the increasing
semantics are not modified
of the increasing time
the increasing time to
increasing time to circulate
and the instance cost
time to circulate a
the instance cost may
to circulate a token
instance cost may be
when the sending endhost
circulate a token around
the sending endhost receives
cost may be reduced
sending endhost receives an
a token around the
endhost receives an acknowledgment
token around the region
may be reduced to
around the region for
the region for purposes
region for purposes of
for purposes of state
it can assume that
purposes of state aggregation
can assume that the
assume that the receiving
that the receiving end
host successfully received the
successfully received the message
the time to acknowledge
time to acknowledge is
to acknowledge is only
per hour by paying
acknowledge is only slightly
hour by paying a
is only slightly higher
only slightly higher than
slightly higher than the
higher than the expected
maelstrom functions as a
functions as a passive
as a passive device
snooping outgoing and incoming
outgoing and incoming traffic
and incoming traffic at
incoming traffic at the
s to wait until
traffic at the data
to wait until the
wait until the next
at the data center
until the next token
the data center s
the next token round
year reservation fee in
data center s edge
reservation fee in advance
center s edge its
s edge its failure
plus the roundtrip time
edge its failure does
its failure does not
this gives an amortized
failure does not disrupt
gives an amortized monthly
does not disrupt the
as we scale up
not disrupt the flow
an amortized monthly cost
disrupt the flow of
amortized monthly cost of
the flow of packets
flow of packets between
of packets between the
packets between the two
roundtrip time becomes dominant
between the two data
the two data centers
these experiments show that
experiments show that the
show that the critical
that the critical factor
the critical factor determining
critical factor determining performance
factor determining performance is
determining performance is the
performance is the time
is the time needed
the time needed for
side appliance acts as
time needed for the
appliance acts as a
needed for the system
acts as a tcp
for the system to
as we show in
the system to aggregate
we show in the
system to aggregate state
show in the next
to aggregate state over
in the next section
aggregate state over regions
terminating connections and sending
connections and sending back
and sending back acks
sending back acks immediately
one instance should be
back acks immediately before
instance should be enough
acks immediately before relaying
should be enough for
immediately before relaying data
they shed light on
before relaying data on
shed light on a
relaying data on appliance
be enough for almost
light on a mechanism
enough for almost any
on a mechanism that
for almost any individual
a mechanism that links
almost any individual project
mechanism that links latency
any individual project or
that links latency to
individual project or moderately
links latency to throughput
project or moderately sized
split mode is extremely
or moderately sized community
mode is extremely useful
is extremely useful when
extremely useful when endhosts
via increased memory consumption
useful when endhosts have
increased memory consumption and
when endhosts have limited
memory consumption and the
endhosts have limited buffering
consumption and the resulting
have limited buffering capacity
and the resulting increase
usage patterns in addition
the resulting increase in
patterns in addition to
resulting increase in allocation
in addition to getting
since it allows the
increase in allocation and
addition to getting a
in allocation and garbage
it allows the receive
allocation and garbage collection
to getting a grasp
and garbage collection overheads
getting a grasp of
a grasp of the
grasp of the costs
side appliance to buffer
of the costs involved
appliance to buffer incoming
the costs involved in
to buffer incoming data
costs involved in moving
buffer incoming data over
involved in moving a
incoming data over the
in moving a repository
data over the highspeed
moving a repository to
over the highspeed long
a repository to s
ms increase in latency
it also mitigates tcp
it is important to
is important to understand
important to understand the
to understand the usage
understand the usage patterns
mb increase in memory
increase in memory consumption
start effects for short
especially the rate at
the rate at which
can inflate overheads by
rate at which commits
at which commits take
which commits take place
since achieving the consistency
achieving the consistency properties
maelstrom has to operate
the consistency properties that
has to operate as
consistency properties that developers
to operate as an
properties that developers expect
operate as an active
that developers expect will
as an active device
developers expect will require
expect will require a
will require a consistency
require a consistency layer
a consistency layer to
consistency layer to be
inserted into the critical
layer to be built
to be built in
into the critical communication
be built in front
the critical communication path
and degrade the throughput
built in front of
critical communication path its
degrade the throughput by
communication path its failure
in front of s
path its failure disconnects
its failure disconnects the
failure disconnects the communication
disconnects the communication path
the communication path between
communication path between the
path between the two
between the two data
the two data centers
it is crucial that
is crucial that any
one way to alleviate
crucial that any such
way to alleviate the
that any such layer
to alleviate the problem
any such layer be
alleviate the problem we
such layer be able
layer be able to
be able to handle
able to handle the
to handle the load
handle the load of
ve identified could be
while maelstrom respects endto
identified could be to
the load of commits
could be to reduce
be to reduce the
to reduce the latency
reduce the latency of
end flow control connections
the latency of state
the critical statistic to
latency of state aggregation
critical statistic to consider
statistic to consider is
to consider is the
or splits them and
consider is the number
splits them and implements
so that it grows
them and implements its
that it grows sub
and implements its own
is the number of
implements its own proxy
the number of simultaneous
number of simultaneous commits
for centralized revision control
centralized revision control system
revision control system such
proxy flow control as
control system such as
flow control as described
system such as subversion
control as described above
this might be achieved
might be achieved by
be achieved by using
achieved by using a
by using a deeper
each commit is assigned
using a deeper hierarchy
commit is assigned a
a deeper hierarchy of
is assigned a unique
deeper hierarchy of rings
it is not designed
is not designed for
not designed for routinely
designed for routinely congested
for routinely congested networks
and by letting tokens
by letting tokens in
letting tokens in each
tokens in each of
and any change to
the addition of fec
any change to a
addition of fec under
in each of these
change to a versioned
each of these rings
of fec under tcp
of these rings circulate
to a versioned file
these rings circulate independently
a versioned file is
versioned file is stored
file is stored as
ip flow control allows
is stored as a
flow control allows it
this would create a
control allows it to
would create a more
stored as a diff
allows it to steal
as a diff against
create a more complex
it to steal bandwidth
a diff against its
to steal bandwidth from
diff against its previous
steal bandwidth from other
against its previous version
a more complex structure
bandwidth from other competing
from other competing flows
performance of mfs priorities
other competing flows running
of mfs priorities and
competing flows running without
but aggregation latency would
flows running without fec
aggregation latency would grow
running without fec in
latency would grow logarithmically
without fec in the
mfs priorities and writeback
a commit must be
would grow logarithmically rather
fec in the link
grow logarithmically rather than
priorities and writeback schemes
logarithmically rather than linearly
commit must be rejected
must be rejected if
though maintaining fairness versus
be rejected if any
maintaining fairness versus similarly
each test consists of
fairness versus similarly fec
test consists of two
is reducing state aggregation
consists of two concurrent
rejected if any of
of two concurrent processes
reducing state aggregation latency
two concurrent processes executing
if any of the
concurrent processes executing different
state aggregation latency the
processes executing different workloads
aggregation latency the only
any of the versioned
latency the only option
of the versioned files
the versioned files that
mean times to completion
versioned files that it
times to completion are
files that it touches
to completion are shown
we evaluated two alternative
completion are shown with
evaluated two alternative approaches
are shown with standard
that it touches have
shown with standard deviations
it touches have been
touches have been changed
but found that neither
have been changed in
found that neither can
been changed in an
that neither can substitute
changed in an earlier
neither can substitute for
in an earlier revision
can substitute for lowering
three different policies for
substitute for lowering the
different policies for writing
for lowering the latency
policies for writing back
lowering the latency of
for writing back files
the latency of the
writing back files are
an earlier revision that
back files are listed
friendliness with conventional tcp
latency of the recovery
earlier revision that the
of the recovery state
revision that the developer
the recovery state aggregation
ip flows is not
that the developer performing
under uniform or differentiated
flows is not a
our first approach varies
is not a primary
the developer performing the
uniform or differentiated priorities
developer performing the commit
first approach varies the
performing the commit was
not a primary protocol
approach varies the rate
the commit was unaware
varies the rate of
reads take precedence over
a primary protocol design
the rate of aggregation
commit was unaware of
primary protocol design goal
take precedence over writes
protocol design goal on
rate of aggregation by
design goal on over
of aggregation by increasing
aggregation by increasing the
this ensures that every
by increasing the rate
ensures that every conflict
increasing the rate at
that every conflict gets
the rate at which
every conflict gets resolved
rate at which tokens
values in bold are
conflict gets resolved by
at which tokens are
gets resolved by a
which tokens are released
in bold are of
which are often dedicated
bold are of particular
are often dedicated to
are of particular significance
often dedicated to specific
resolved by a human
dedicated to specific highvalue
by a human before
to specific highvalue applications
a human before becoming
human before becoming part
note that elapsed times
before becoming part of
that elapsed times for
becoming part of the
elapsed times for write
we see evidence for
times for write workloads
see evidence for this
for write workloads give
evidence for this assertion
write workloads give the
for this assertion in
part of the repository
this assertion in the
workloads give the time
assertion in the routine
this helps only up
in the routine use
of the repository s
the routine use of
the repository s state
routine use of parallel
give the time until
helps only up to
the time until the
use of parallel flows
time until the process
only up to a
until the process running
up to a point
the process running the
process running the workload
exclusive locking is required
running the workload finishes
locking is required on
is required on commits
not when the log
when the log is
taking a loose definition
the log is flushed
a loose definition of
loose definition of simultaneous
and udp blast protocols
definition of simultaneous to
of simultaneous to be
simultaneous to be within
this is shown in
to be within one
is shown in figure
be within one minute
the apache repository had
apache repository had a
repository had a maximum
had a maximum of
more than one aggregation
than one aggregation is
one aggregation is underway
aggregation is underway at
modified and then deleted
simultaneous commits and the
is underway at a
commits and the debian
underway at a time
and the debian community
which requires the file
requires the file update
the file update rpc
and successive tokens perform
file update rpc to
successive tokens perform redundant
ignoring for now that
tokens perform redundant work
for now that their
update rpc to be
now that their use
rpc to be cancelled
that their use of
to be cancelled if
be cancelled if it
cancelled if it is
if it is still
it is still in
processing all these tokens
is still in transmission
all these tokens is
still in transmission when
these tokens is costly
in transmission when the
transmission when the remove
when the remove rpc
the remove rpc is
separate repositories allows for
remove rpc is initiated
repositories allows for finergrained
allows for finergrained locking
both in commercial deployments
in commercial deployments and
an update to a
commercial deployments and by
update to a file
deployments and by researchers
to a file will
an aggregate maximum of
a file will supersede
and by researchers seeking
file will supersede any
by researchers seeking to
will supersede any previous
researchers seeking to transfer
supersede any previous queued
seeking to transfer large
any previous queued updates
to transfer large amounts
s decreases the amount
transfer large amounts of
decreases the amount of
large amounts of data
in determining these numbers
the amount of unacknowledged
amounts of data over
amount of unacknowledged data
of data over high
of unacknowledged data by
determining these numbers we
compiles the entire mfs
the entire mfs file
these numbers we filtered
entire mfs file system
mfs file system and
numbers we filtered out
file system and its
system and its rpc
we filtered out any
and its rpc library
filtered out any sequences
out any sequences of
any sequences of multiple
layered interleaving in layered
interleaving in layered interleaving
sequences of multiple commits
of multiple commits by
but increases throughput by
increases throughput by less
multiple commits by the
an fec protocol with
throughput by less than
commits by the same
fec protocol with rate
by the same author
the same author during
files and directories comprising
same author during a
author during a one
during a one minute
a one minute period
one minute period since
minute period since those
period since those were
is produced by running
since those were likely
produced by running c
those were likely sequential
by running c multiple
were likely sequential rather
running c multiple instances
likely sequential rather than
c multiple instances of
sequential rather than simultaneous
multiple instances of an
rather than simultaneous and
than simultaneous and do
simultaneous and do nor
time spent allocating byte
and do nor represent
spent allocating byte arrays
do nor represent the
allocating byte arrays in
nor represent the common
byte arrays in the
represent the common case
arrays in the application
none of the files
of the files are
the files are initially
files are initially in
are initially in the
the average rates were
initially in the cache
fec protocol simultaneously with
protocol simultaneously with increasing
simultaneously with increasing interleave
with increasing interleave indices
this workload performs an
increasing interleave indices i
workload performs an intensive
performs an intensive pattern
an intensive pattern of
intensive pattern of reads
pattern of reads and
memory used on sender
of reads and writes
used on sender and
reads and writes files
on sender and the
and writes files without
sender and the number
writes files without raising
and the number of
files without raising the
the number of multicast
without raising the issue
number of multicast requests
raising the issue of
of multicast requests in
the issue of concurrent
multicast requests in progress
issue of concurrent accesses
a topic we tackle
topic we tackle in
we tackle in section
so exclusive locking for
exclusive locking for commits
locking for commits should
for commits should not
commits should not pose
token roundtrip time and
should not pose any
roundtrip time and an
not pose any scalability
time and an average
pose any scalability problems
and an average time
any scalability problems in
an average time to
scalability problems in a
average time to acknowledge
problems in a typical
time to acknowledge a
in a typical environment
to acknowledge a message
we did not consider
performance evaluation of these
did not consider the
evaluation of these workloads
not consider the rate
consider the rate of
the rate of read
rate of read operations
of read operations because
we classified grep and
read operations because clients
classified grep and read
operations because clients updating
grep and read as
because clients updating their
varying token circulation rate
clients updating their working
and read as foreground
updating their working copies
read as foreground workloads
or reading from the
and compile and write
reading from the repository
compile and write as
and write as background
write as background workloads
do not require a
not require a lock
our second approach increased
second approach increased the
four combined workloads were
approach increased the amount
combined workloads were then
the debian community today
increased the amount of
debian community today uses
the amount of feedback
workloads were then generated
community today uses only
amount of feedback to
were then generated by
of feedback to the
today uses only a
feedback to the sender
uses only a single
then generated by running
only a single subversion
generated by running a
a single subversion server
by running a foreground
in our base implementation
running a foreground and
a foreground and a
foreground and a background
and a background workload
and the apache foundation
a background workload concurrently
the apache foundation has
each aggregate ack contains
apache foundation has a
aggregate ack contains a
foundation has a master
ack contains a single
has a master server
contains a single value
a master server plus
we denote these as
master server plus a
denote these as gc
server plus a european
a single value maxcontiguous
plus a european mirror
representing the maximum number
primarily for latency reasons
the maximum number such
maximum number such that
number such that messages
such that messages with
that messages with this
messages with this and
with this and all
this and all lower
we expect that most
and all lower numbers
expect that most communities
all lower numbers are
that most communities will
lower numbers are stable
most communities will have
numbers are stable in
communities will have at
are stable in the
will have at most
stable in the region
have at most a
at most a handful
most a handful of
a handful of front
to increase the amount
increase the amount of
the amount of feedback
three instances of an
we permit ack to
permit ack to contain
ack to contain up
to contain up to
contain up to k
achieving consistency amazon s
up to k numeric
consistency amazon s infrastructure
to k numeric ranges
amazon s infrastructure is
s infrastructure is built
infrastructure is built on
is built on the
built on the principle
on the principle of
the principle of eventual
principle of eventual consistency
the first instance with
three types of rpcs
first instance with interleave
types of rpcs predominate
instance with interleave i
and does not directly
does not directly support
not directly support the
directly support the locking
support the locking required
the locking required for
fetches of file data
locking required for revision
required for revision control
and store operations for
store operations for files
originally developed to run
developed to run the
the second with interleave
to run the company
second with interleave i
run the company s
the company s own
in descending order of
company s own online
descending order of priority
s own online store
the aim of the
the system preferred availability
aim of the experiments
system preferred availability over
of the experiments was
preferred availability over consistency
the experiments was to
availability over consistency because
experiments was to demonstrate
over consistency because downtime
was to demonstrate that
consistency because downtime translated
to demonstrate that priorities
because downtime translated directly
demonstrate that priorities improve
downtime translated directly into
and the third with
that priorities improve the
translated directly into lost
priorities improve the performance
directly into lost revenue
improve the performance of
the third with interleave
the performance of the
third with interleave i
performance of the foreground
of the foreground workloads
customers may opt to
may opt to shop
the system can now
opt to shop elsewhere
system can now cleanup
to shop elsewhere or
can now cleanup message
shop elsewhere or to
now cleanup message sequences
the four combined workloads
cleanup message sequences that
elsewhere or to simply
message sequences that have
four combined workloads were
sequences that have as
or to simply forgo
combined workloads were executed
to simply forgo impulse
that have as gaps
simply forgo impulse purchases
workloads were executed on
forgo impulse purchases that
were executed on top
impulse purchases that they
executed on top of
purchases that they didn
on top of mfs
that they didn t
top of mfs configured
they didn t really
of mfs configured with
messages that are still
didn t really need
that are still unstable
t really need anyway
mfs configured with either
configured with either synchronous
with either synchronous writes
an inconsistent shopping cart
update logging or asynchronous
in the experiment shown
logging or asynchronous writeback
the experiment shown in
experiment shown in figures
fec encoding is simply
encoding is simply an
could be resolved by
is simply an xor
the update logging mechanism
simply an xor of
be resolved by heuristics
an xor of the
resolved by heuristics or
xor of the r
by heuristics or user
of the r data
update logging mechanism was
the r data packets
logging mechanism was configured
r data packets hence
mechanism was configured to
intervention at checkout time
was configured to delay
configured to delay flushing
in layered interleaving each
to delay flushing an
we set k to
delay flushing an update
set k to the
flushing an update for
layered interleaving each data
an update for at
it is well known
k to the number
interleaving each data packet
to the number of
is well known that
the number of partitions
update for at least
well known that consistency
each data packet is
for at least a
data packet is included
at least a second
known that consistency and
packet is included in
is included in c
that consistency and availability
included in c xors
consistency and availability cannot
while the amount of
every experiment was repeated
and availability cannot both
experiment was repeated ten
availability cannot both be
the amount of acknowledged
each of which is
amount of acknowledged data
was repeated ten times
of which is generated
of acknowledged data is
which is generated at
acknowledged data is reduced
is generated at different
data is reduced by
repeated ten times at
generated at different interleaves
cannot both be achieved
ten times at each
at different interleaves from
times at each of
both be achieved simultaneously
different interleaves from the
at each of five
interleaves from the original
be achieved simultaneously in
from the original data
each of five possible
the original data stream
of five possible bandwidth
achieved simultaneously in any
five possible bandwidth values
simultaneously in any real
in any real network
any real network where
real network where hosts
network where hosts or
where hosts or entire
as we shall describe
hosts or entire subnetworks
we shall describe shortly
or entire subnetworks are
shows the time taken
and the overall throughput
the time taken for
entire subnetworks are sometimes
time taken for each
the overall throughput is
taken for each workload
subnetworks are sometimes unreachable
for each workload at
are sometimes unreachable due
ensures that the c
overall throughput is actually
that the c xors
sometimes unreachable due to
the c xors containing
unreachable due to connectivity
each workload at a
throughput is actually lower
c xors containing a
is actually lower because
workload at a bandwidth
due to connectivity losses
xors containing a data
actually lower because token
containing a data packet
lower because token processing
a data packet do
because token processing becomes
data packet do not
token processing becomes more
packet do not have
processing becomes more costly
do not have any
at a bandwidth of
not have any other
have any other data
any other data packet
other data packet in
data packet in common
the system becomes unstable
if a cloud service
the resulting protocol effectively
a cloud service is
resulting protocol effectively has
cloud service is designed
protocol effectively has a
notice the large variances
service is designed to
effectively has a rate
is designed to provide
has a rate of
the large variances in
designed to provide high
large variances in figure
to provide high availability
provide high availability but
high availability but an
availability but an application
but an application instead
an application instead requires
application instead requires perfect
instead requires perfect consistency
shows overall results for
overall results for selected
results for selected configurations
additional software infrastructure is
software infrastructure is required
with each xor generated
infrastructure is required to
the results in table
is required to bridge
each xor generated from
required to bridge the
because our flow control
xor generated from r
to bridge the gap
generated from r data
demonstrate the benefit of
from r data packets
the benefit of priorities
r data packets and
our flow control scheme
data packets and each
benefit of priorities when
packets and each data
of priorities when there
and each data packet
for revision control it
each data packet included
priorities when there is
data packet included in
based on limiting the
packet included in c
on limiting the amount
included in c xors
limiting the amount of
revision control it makes
the amount of unacknowledged
control it makes sense
amount of unacknowledged data
it makes sense to
when there is high
makes sense to adopt
there is high contention
sense to adopt eventual
is high contention between
to adopt eventual consistency
high contention between high
adopt eventual consistency for
illustrates layered interleaving for
eventual consistency for read
layered interleaving for a
consistency for read operations
priority rpcs and writes
while the sender can
the sender can cleanup
sender can cleanup any
can cleanup any portion
since at worst an
in both the i
at worst an earlier
cleanup any portion of
worst an earlier revision
any portion of the
an earlier revision will
portion of the message
earlier revision will fig
of the message sequence
bound gw and rw
gw and rw workloads
receivers have to deliver
have to deliver in
to deliver in fifo
deliver in fifo order
adding priorities decreases the
priorities decreases the time
decreases the time required
system architecture be returned
the time required for
the amount of data
time required for the
amount of data they
required for the foreground
of data they cache
for the foreground workload
data they cache is
if the user is
the foreground workload to
they cache is larger
the user is aware
foreground workload to execute
and this reduces their
through some other channel
this reduces their ability
reduces their ability to
their ability to accept
ability to accept incoming
to accept incoming traffic
that a newer version
a newer version should
newer version should exist
notice the linkage to
the linkage to memory
he can retry and
see elapsed times for
can retry and expect
elapsed times for rw
retry and expect that
the growth in memory
and expect that version
growth in memory occurs
expect that version to
in memory occurs on
that version to be
memory occurs on the
version to be available
occurs on the receivers
to be available within
read with synchronous writes
be available within a
with synchronous writes in
available within a short
synchronous writes in the
but the pattern is
writes in the table
within a short timeframe
the pattern is similar
pattern is similar to
is similar to what
similar to what we
to what we saw
what we saw earlier
standard fec schemes can
this is particularly true
fec schemes can be
is particularly true in
merely having more cached
particularly true in the
schemes can be made
perfect consistency is required
true in the rw
consistency is required and
in the rw test
is required and a
can be made resistant
required and a locking
having more cached data
and a locking layer
be made resistant to
a locking layer must
more cached data is
locking layer must be
where the foreground workload
layer must be built
cached data is enough
made resistant to a
the foreground workload generates
resistant to a certain
foreground workload generates heavy
must be built to
workload generates heavy contention
be built to support
generates heavy contention by
to a certain loss
heavy contention by fetching
built to support this
data is enough to
a certain loss burst
contention by fetching a
is enough to slow
certain loss burst length
by fetching a large
this may result in
enough to slow them
may result in a
to slow them down
loss burst length at
fetching a large volume
burst length at the
a large volume of
length at the cost
result in a commit
at the cost of
in a commit being
the cost of increased
a commit being rejected
cost of increased recovery
commit being rejected if
of increased recovery latency
being rejected if consensus
increased recovery latency for
rejected if consensus cannot
recovery latency for all
if consensus cannot be
latency for all lost
consensus cannot be reached
for all lost packets
token roundtrip time increases
large volume of data
but shouldn t be
including smaller bursts and
shouldn t be a
the greatest benefits are
smaller bursts and singleton
greatest benefits are observable
bursts and singleton drops
t be a problem
benefits are observable for
be a problem because
are observable for the
this delays state aggregation
observable for the combination
a problem because code
for the combination of
problem because code changes
the combination of asynchronous
because code changes are
combination of asynchronous writes
increases pending messages and
of asynchronous writes with
layered interleaving provides graceful
asynchronous writes with priorities
code changes are usually
interleaving provides graceful degradation
pending messages and reduces
changes are usually not
messages and reduces throughput
are usually not impulse
provides graceful degradation in
usually not impulse decisions
graceful degradation in the
not impulse decisions and
since here the performance
impulse decisions and the
degradation in the face
decisions and the commit
in the face of
here the performance of
the face of bursty
and the commit can
face of bursty loss
the commit can be
the performance of the
of bursty loss for
commit can be retried
bursty loss for constant
can be retried later
performance of the background
loss for constant encoding
of the background workload
for constant encoding overhead
the background workload can
constant encoding overhead singleton
background workload can also
encoding overhead singleton random
workload can also improve
overhead singleton random losses
can also improve by
d esign as a
singleton random losses are
also improve by not
random losses are recovered
improve by not having
losses are recovered as
esign as a proof
by not having to
are recovered as quickly
not having to wait
recovered as quickly as
more aggressive cleanup with
having to wait for
as quickly as possible
to wait for its
aggressive cleanup with o
wait for its writes
for its writes to
by xors generated with
its writes to be
xors generated with an
writes to be committed
generated with an interleave
to be committed at
with an interleave of
be committed at the
committed at the server
feedback in the token
in the token and
the token and in
token and in acks
a tool for integrating
tool for integrating subversion
in the gc and
for integrating subversion with
the gc and rc
integrating subversion with s
gc and rc tests
and each successive layer
each successive layer of
successive layer of xors
layer of xors generated
where there is lighter
of xors generated at
there is lighter contention
xors generated at a
generated at a higher
at a higher interleave
more work with o
a higher interleave catches
the impact of priorities
higher interleave catches larger
impact of priorities is
vn is colocated with
interleave catches larger bursts
is colocated with subversion
catches larger bursts missed
of priorities is negligible
larger bursts missed by
colocated with subversion and
bursts missed by the
with subversion and inserts
missed by the previous
subversion and inserts a
by the previous layer
and inserts a layer
and in some cases
inserts a layer between
in some cases results
a layer between subversion
some cases results in
layer between subversion and
cases results in a
between subversion and s
results in a slight
and lower rates despite
the implementation of this
lower rates despite saving
in a slight overhead
implementation of this algorithm
rates despite saving on
of this algorithm is
despite saving on memory
this algorithm is simple
algorithm is simple and
as shown in figure
is simple and shown
but this is chiefly
simple and shown in
this is chiefly after
and shown in figure
is chiefly after adding
chiefly after adding priorities
after adding priorities to
adding priorities to rpcs
for simplicity we did
simplicity we did not
we did not modify
it is natural to
did not modify the
is natural to ask
not modify the subversion
memory overheads on the
modify the subversion server
natural to ask when
the subversion server in
to ask when they
subversion server in any
ask when they are
server in any way
overheads on the receiver
when they are beneficial
on the receiver the
a set of repair
the receiver the reader
set of repair bins
receiver the reader may
of repair bins is
the reader may doubt
and to what degree
reader may doubt that
repair bins is maintained
vn is responsible for
bins is maintained for
may doubt that memory
is responsible for receiving
doubt that memory overhead
is maintained for each
that memory overhead on
maintained for each layer
memory overhead on receivers
responsible for receiving event
in addition to comparing
overhead on receivers is
addition to comparing mfs
on receivers is the
to comparing mfs with
receivers is the real
comparing mfs with and
is the real issue
mfs with and without
for receiving event notifications
with i bins for
receiving event notifications from
i bins for a
with and without prioritised
event notifications from subversion
and without prioritised rpcs
considering that their cpus
bins for a layer
notifications from subversion and
that their cpus are
for a layer with
from subversion and transferring
we also investigate the
subversion and transferring data
a layer with interleave
and transferring data between
layer with interleave i
transferring data between the
also investigate the performance
data between the local
their cpus are half
investigate the performance impact
between the local disk
the performance impact of
a repair bin consists
performance impact of replacing
repair bin consists of
impact of replacing synchronous
bin consists of a
of replacing synchronous rpcs
consists of a partially
the local disk on
replacing synchronous rpcs for
of a partially constructed
synchronous rpcs for file
local disk on the
rpcs for file updates
disk on the ec
for file updates with
a partially constructed repair
file updates with asynchronous
partially constructed repair packet
updates with asynchronous writeback
an xor and the
the performance of these
xor and the recipe
performance of these alternatives
can increasing memory consumption
and the recipe list
increasing memory consumption affect
of these alternatives is
memory consumption affect a
the recipe list of
these alternatives is compared
recipe list of identifiers
alternatives is compared in
list of identifiers of
is compared in a
consumption affect a half
vn at the start
of identifiers of data
at the start and
compared in a set
the start and end
in a set of
start and end of
a set of microbenchmarks
and end of each
identifiers of data packets
end of each commit
of data packets that
data packets that compose
packets that compose the
and with workloads gathered
that compose the xor
with workloads gathered from
we performed an experiment
workloads gathered from windows
performed an experiment with
gathered from windows nt
from windows nt file
windows nt file system
vn acquires and releases
nt file system traces
acquires and releases locks
each intercepted data packet
and releases locks using
intercepted data packet is
releases locks using yahoo
data packet is added
our experimental setup consists
locks using yahoo s
experimental setup consists of
packet is added to
using yahoo s open
setup consists of two
is added to each
yahoo s open source
added to each layer
s open source zookeeper
to each layer where
open source zookeeper lock
ghz pentium iii desktop
each layer where adding
pentium iii desktop machines
source zookeeper lock service
layer where adding to
iii desktop machines running
where adding to a
desktop machines running the
adding to a layer
machines running the freebsd
in which we vary
to a layer simply
the difficulty achieving consistency
which we vary the
difficulty achieving consistency with
we vary the number
a layer simply means
vary the number of
achieving consistency with a
the number of receivers
layer simply means choosing
number of receivers that
consistency with a service
of receivers that cache
with a service such
receivers that cache a
a service such as
that cache a copy
service such as amazon
cache a copy of
such as amazon s
a copy of each
one of which acts
simply means choosing a
of which acts as
copy of each message
as amazon s s
means choosing a repair
which acts as an
choosing a repair bin
acts as an mfs
a repair bin from
as an mfs server
replication factor in figure
repair bin from the
stems from the fact
bin from the layer
from the fact that
from the layer s
the fact that files
the layer s set
and the other as
fact that files pushed
the other as an
that files pushed into
other as an mfs
files pushed into the
as an mfs client
pushed into the storage
incrementally updating the xor
into the storage cloud
updating the xor with
the storage cloud do
the xor with the
storage cloud do not
xor with the new
increasing this value results
with the new data
cloud do not simultaneously
the client machine makes
do not simultaneously become
the new data packet
not simultaneously become available
client machine makes use
this value results in
machine makes use of
value results in a
simultaneously become available on
results in a linear
and adding the data
in a linear increase
adding the data packet
a linear increase of
the data packet s
makes use of the
become available on all
use of the dummynet
available on all service
linear increase of memory
data packet s header
increase of memory usage
packet s header to
of the dummynet trafficshaping
on all service endpoints
the dummynet trafficshaping module
s header to the
dummynet trafficshaping module in
header to the recipe
of memory usage on
trafficshaping module in freebsd
if a file is
module in freebsd to
a file is overwritten
in freebsd to limit
to the recipe list
freebsd to limit its
memory usage on receivers
to limit its incoming
limit its incoming and
different clients may read
its incoming and outgoing
clients may read back
a counter is incremented
if memory overheads were
may read back different
incoming and outgoing bandwidth
counter is incremented as
memory overheads were not
read back different versions
is incremented as each
overheads were not a
incremented as each data
were not a significant
as each data packet
not a significant issue
each data packet arrives
a significant issue on
and even the same
significant issue on half
the experiments we conduct
data packet arrives at
experiments we conduct in
packet arrives at the
even the same client
we conduct in this
the same client may
conduct in this section
arrives at the appliance
in this section have
same client may see
this section have a
we would expect performance
section have a constant
would expect performance to
have a constant bandwidth
expect performance to remain
and choosing the repair
performance to remain unchanged
a constant bandwidth over
choosing the repair bin
client may see the
constant bandwidth over the
may see the old
bandwidth over the duration
see the old version
over the duration of
the repair bin from
the old version if
the duration of the
old version if it
duration of the experiment
version if it suddenly
we see a dramatic
if it suddenly switches
repair bin from the
it suddenly switches to
bin from the layer
suddenly switches to speaking
but we analyse the
from the layer s
we analyse the performance
the layer s set
analyse the performance of
switches to speaking with
linear increase of the
to speaking with a
layer s set is
the performance of mfs
s set is done
performance of mfs when
set is done by
of mfs when the
increase of the token
mfs when the bandwidth
of the token roundtrip
when the bandwidth varies
is done by taking
the bandwidth varies over
the token roundtrip time
bandwidth varies over the
done by taking the
varies over the course
speaking with a different
over the course of
with a different s
the course of an
by taking the modulo
a slow increase of
taking the modulo of
slow increase of the
the modulo of the
increase of the number
modulo of the counter
of the number of
of the counter with
the number of messages
the counter with the
the file will always
counter with the number
file will always be
with the number of
will always be internally
the number of bins
always be internally consistent
number of bins in
course of an experiment
number of messages pending
of bins in each
of messages pending ack
bins in each layer
messages pending ack on
of an experiment in
since put and get
pending ack on the
an experiment in section
put and get operations
for a layer with
ack on the sender
and get operations are
a layer with interleave
get operations are atomic
and a sharp decrease
a sharp decrease in
sharp decrease in throughput
but its contents may
its contents may not
contents may not reflect
may not reflect expectations
not reflect expectations that
reflect expectations that the
the xth intercepted packet
expectations that the client
xth intercepted packet is
that the client formed
intercepted packet is added
the client formed based
packet is added to
client formed based on
is added to the
formed based on other
based on other files
on other files and
other files and out
files and out of
and out of band
microbenchmarks the first set
the underlying mechanism is
the first set of
out of band communication
first set of experiments
underlying mechanism is as
set of experiments compares
mechanism is as follows
of experiments compares different
experiments compares different mfs
compares different mfs configurations
different mfs configurations for
mfs configurations for specific
configurations for specific types
the increased activity of
for specific types of
vn works around the
increased activity of the
works around the consistency
specific types of contention
around the consistency problem
activity of the garbage
the consistency problem by
when a repair bin
consistency problem by storing
of the garbage collector
problem by storing the
a repair bin fills
the garbage collector and
by storing the number
four workloads were used
storing the number of
repair bin fills up
the number of the
bin fills up its
number of the latest
garbage collector and allocation
of the latest revision
fills up its recipe
the latest revision into
up its recipe list
collector and allocation overheads
its recipe list contains
executes the grep utility
and allocation overheads slow
the grep utility several
latest revision into zookeeper
grep utility several times
allocation overheads slow the
recipe list contains r
overheads slow the system
list contains r data
slow the system down
contains r data packets
utility several times on
the system down and
r data packets it
system down and processing
data packets it fires
down and processing of
several times on each
and processing of the
times on each of
processing of the incoming
even if multiple files
of the incoming packets
if multiple files were
the incoming packets and
a repair packet is
incoming packets and tokens
multiple files were changed
packets and tokens takes
repair packet is generated
files were changed by
packet is generated consisting
were changed by the
and tokens takes more
is generated consisting of
changed by the client
generated consisting of the
tokens takes more time
consisting of the xor
of the xor and
the xor and the
xor and the recipe
is represented by subversion
and the recipe list
represented by subversion has
the recipe list and
although the effect is
recipe list and is
the files are present
by subversion has a
the effect is not
list and is scheduled
files are present in
subversion has a single
effect is not significant
has a single file
is not significant when
a single file containing
not significant when considering
single file containing binary
significant when considering a
file containing binary diffs
when considering a single
containing binary diffs against
considering a single node
binary diffs against earlier
a single node in
diffs against earlier revisions
are present in the
and is scheduled for
single node in isolation
present in the cache
is scheduled for sending
a revision is never
revision is never changed
is never changed after
never changed after the
a token must visit
changed after the fact
token must visit all
but must be validated
must visit all nodes
must be validated before
visit all nodes in
be validated before they
all nodes in a
validated before they are
nodes in a region
while the repair bin
before they are used
in a region to
the repair bin is
a region to aggregate
repair bin is re
region to aggregate the
end server attempting to
to aggregate the recovery
server attempting to fetch
aggregate the recovery state
attempting to fetch a
to fetch a revision
initialized with an empty
fetch a revision i
with an empty recipe
a revision i from
an empty recipe list
revision i from s
empty recipe list and
and delays are cumulative
recipe list and blank
list and blank xor
will receive either the
receive either the one
either the one true
qsm is configured so
is configured so that
configured so that five
mb files in sequence
so that five nodes
that five nodes in
or a missing file
incoming repair packets are
a missing file error
repair packets are processed
missing file error if
writing the contents of
file error if i
the contents of each
error if i was
contents of each file
if i was posted
of each file to
packets are processed as
five nodes in each
i was posted so
nodes in each region
was posted so recently
in each region cache
posted so recently that
each region cache each
are processed as follows
so recently that it
region cache each packet
recently that it has
that it has not
if all the data
the files are not
if half the nodes
files are not initially
half the nodes in
are not initially present
the nodes in a
not initially present in
all the data packets
initially present in the
the data packets contained
present in the cache
data packets contained in
packets contained in the
contained in the repair
in the repair s
the repair s recipe
repair s recipe list
s recipe list have
recipe list have been
list have been received
have been received successfully
node region cache each
region cache each figure
the repair packet is
repair packet is discarded
if the repair s
the repair s recipe
repair s recipe list
s recipe list contains
mb files from the
recipe list contains a
files from the local
list contains a single
from the local file
contains a single missing
the local file system
a single missing data
local file system into
single missing data packet
file system into the
system into the mfs
into the mfs file
the mfs file system
recovery can occur immediately
can occur immediately by
varying the number of
the number of caching
number of caching replicas
of caching replicas per
caching replicas per message
replicas per message in
per message in a
as the replication factor
the replication factor increasess
the sender s flow
sender s flow control
s flow control policy
flow control policy kicks
control policy kicks in
and the system goes
the system goes into
a form of the
form of the oscillating
of the oscillating state
the oscillating state we
oscillating state we encountered
state we encountered in
we encountered in figure
the amount of memory
amount of memory in
of memory in use
end servers are equivalent
memory in use at
servers are equivalent and
in use at the
are equivalent and clients
use at the sender
equivalent and clients may
at the sender ceases
and clients may interact
the sender ceases to
clients may interact with
sender ceases to be
may interact with any
ceases to be a
interact with any of
to be a good
with any of them
be a good predictor
any of them fig
a good predictor of
good predictor of the
predictor of the amount
of the amount of
the amount of memory
amount of memory in
of memory in use
memory in use at
in use at receivers
violating what turns out
what turns out to
turns out to be
out to be an
e valuation we observe
to be an implicit
valuation we observe that
be an implicit requirement
we observe that running
an implicit requirement of
observe that running multiple
implicit requirement of our
that running multiple front
requirement of our flow
which cloud computing makes
cloud computing makes easy
computing makes easy to
layer with interleave of
makes easy to do
increases the throughput of
the throughput of read
throughput of read operations
overheads in a perturbed
in a perturbed system
a perturbed system the
perturbed system the reader
vn by running a
system the reader might
by running a fixed
the reader might wonder
running a fixed number
reader might wonder whether
a fixed number of
might wonder whether our
fixed number of clients
wonder whether our results
whether our results would
our results would be
results would be different
each repeatedly checking out
would be different if
repeatedly checking out about
be different if the
different if the system
if the system experienced
the system experienced high
system experienced high loss
experienced high loss rates
high loss rates or
loss rates or was
rates or was otherwise
or was otherwise perturbed
we performed an experiment
performed an experiment in
an experiment in which
experiment in which one
in which one of
which one of the
one of the receiver
of the receiver nodes
the receiver nodes experiences
receiver nodes experiences a
nodes experiences a periodic
s the node sleeps
the node sleeps for
yet propagated through s
this simulates the effect
simulates the effect of
the effect of disruptive
in the latter case
the server retries indefinitely
server retries indefinitely until
in the loss scenario
retries indefinitely until the
indefinitely until the file
until the file is
the file is available
zookeeper ensures that the
s the node drops
ensures that the latest
the node drops all
that the latest revision
node drops all incoming
the latest revision number
drops all incoming packets
latest revision number is
all incoming packets for
revision number is incremented
number is incremented atomically
zookeeper maintains a simple
maintains a simple filesystem
a simple filesystem like
simple filesystem like tree
filesystem like tree of
like tree of nodes
nodes may store a
may store a small
store a small amount
a small amount of
small amount of data
amount of data and
of data and can
data and can have
and can have children
the loss rate is
loss rate is higher
vn stores the latest
stores the latest revision
the latest revision number
latest revision number in
because recovery traffic interferes
recovery traffic interferes with
traffic interferes with regular
interferes with regular multicast
supporting multiple named repositories
combining the xor in
multiple named repositories in
the xor in the
named repositories in a
xor in the repair
repositories in a single
in the repair with
in a single zookeeper
the repair with the
a single zookeeper tree
repair with the other
cpu utilization at the
with the other successfully
utilization at the receivers
the other successfully received
at the receivers is
other successfully received data
the receivers is in
before pushing a new
receivers is in the
pushing a new revision
successfully received data packets
gc test rw test
if the repair contains
the repair contains multiple
repair contains multiple missing
end server must acquire
contains multiple missing data
server must acquire a
multiple missing data packets
must acquire a lock
acquire a lock by
a lock by creating
lock by creating a
by creating a sequence
creating a sequence node
it cannot be used
cannot be used immediately
be used immediately for
used immediately for recovery
immediately for recovery it
for recovery it is
range and doesn t
recovery it is instead
and doesn t grow
it is instead stored
doesn t grow with
is instead stored in
t grow with system
instead stored in a
grow with system size
stored in a table
in a table that
a table that maps
table that maps missing
that maps missing data
maps missing data packets
missing data packets to
data packets to repair
packets to repair packets
whenever a data packet
a data packet is
data packet is subsequently
packet is subsequently received
is subsequently received or
subsequently received or recovered
to which zookeeper will
which zookeeper will append
zookeeper will append a
will append a unique
this table is checked
in the sleep scenario
table is checked to
is checked to see
monotonically increasing sequence number
checked to see if
the decrease starts at
to see if any
decrease starts at about
see if any xors
if any xors now
any xors now have
end server then lists
xors now have singleton
server then lists the
nodes and proceeds steadily
now have singleton losses
and proceeds steadily thereafter
then lists the children
have singleton losses due
lists the children of
singleton losses due to
losses due to the
due to the presence
it doesn t appear
to the presence of
doesn t appear to
the presence of the
t appear to be
presence of the new
appear to be correlated
of the new packet
to be correlated to
the new packet and
be correlated to the
new packet and can
correlated to the amount
packet and can be
to the amount of
and can be used
the amount of loss
can be used for
be used for recovering
used for recovering other
for recovering other missing
recovering other missing packets
which oscillates at the
oscillates at the level
at the level of
if its own lock
its own lock node
xors received from different
own lock node has
received from different layers
lock node has the
from different layers interact
node has the lowest
different layers interact to
has the lowest number
layers interact to recover
interact to recover missing
to recover missing data
recover missing data packets
it may proceed with
may proceed with the
proceed with the commit
gw test rc test
since an xor received
an xor received at
xor received at a
otherwise it watches the
received at a higher
it watches the node
at a higher interleave
watches the node with
a higher interleave can
the node with the
higher interleave can recover
node with the next
interleave can recover a
with the next lower
can recover a packet
the next lower number
recover a packet that
in the controlled loss
a packet that makes
the controlled loss scenario
next lower number in
packet that makes an
lower number in order
that makes an earlier
number in order to
makes an earlier xor
in order to be
an earlier xor at
throughput remains fairly constant
earlier xor at a
order to be notified
xor at a lower
to be notified when
at a lower interleave
be notified when that
a lower interleave usable
notified when that node
until it falls sharply
lower interleave usable hence
when that node and
it falls sharply beyond
that node and its
node and its associated
and its associated lock
its associated lock go
though layered interleaving is
associated lock go away
layered interleaving is equivalent
interleaving is equivalent to
is equivalent to c
equivalent to c different
after comitting the revision
comitting the revision to
the revision to s
performance does not appear
does not appear to
not appear to be
appear to be directly
instances in terms of
to be directly correlated
in terms of overhead
be directly correlated to
terms of overhead and
directly correlated to the
of overhead and design
correlated to the observed
to the observed packet
the observed packet loss
its recovery power is
recovery power is much
power is much higher
is much higher and
much higher and comes
higher and comes close
and comes close to
throughput is uncorrelated with
comes close to standard
is uncorrelated with memory
relative speedup relative speedup
uncorrelated with memory use
speedup relative speedup relative
with memory use both
relative speedup relative speedup
memory use both on
it releases its lock
use both on the
releases its lock by
both on the perturbed
its lock by deleting
on the perturbed receiver
lock by deleting the
by deleting the lock
deleting the lock node
lock nodes are marked
nodes are marked with
are marked with zookeeper
marked with zookeeper s
optimizations staggered start for
with zookeeper s ephemeral
staggered start for rate
zookeeper s ephemeral flag
s ephemeral flag to
ephemeral flag to ensure
flag to ensure that
to ensure that the
limiting in the naive
ensure that the lock
in the naive implementation
that the lock is
the naive implementation of
the lock is forcibly
naive implementation of the
lock is forcibly released
uniform priorities async relative
is forcibly released if
implementation of the layered
priorities async relative speedup
of the layered interleaving
async relative speedup gc
forcibly released if the
the layered interleaving algorithm
relative speedup gc test
at scales of up
released if the front
scales of up to
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
as soon as repair
soon as repair bins
zookeeper runs as a
as repair bins fill
runs as a replicated
repair bins fill and
as a replicated service
bins fill and allow
fill and allow them
memory usage actually decreases
and allow them to
allow them to be
them to be constructed
so it remains available
it remains available as
a consequence of the
remains available as long
consequence of the cooperative
available as long as
of the cooperative caching
as long as a
the cooperative caching policy
long as a majority
cooperative caching policy described
as a majority of
caching policy described in
all the repair bins
policy described in section
a majority of the
the repair bins in
majority of the hosts
repair bins in a
of the hosts are
bins in a layer
the hosts are up
in a layer fill
hosts are up and
a layer fill in
are up and reachable
layer fill in quick
fill in quick succession
the shape of the
shape of the performance
of the performance curve
the performance curve does
a client only speaks
client only speaks to
only speaks to one
speaks to one zookeeper
to one zookeeper server
one zookeeper server at
zookeeper server at a
server at a time
correlate closely with the
the arrival of packets
closely with the number
with the number of
though it may fail
the number of unacknowledged
number of unacknowledged requests
over to another server
to another server if
another server if necessary
but the server ensures
the server ensures that
server ensures that the
ensures that the relevant
that the relevant state
the relevant state has
we conclude that the
relevant state has been
conclude that the drop
state has been replicated
that the drop in
has been replicated before
the drop in performance
been replicated before responding
drop in performance in
replicated before responding to
in performance in these
before responding to a
performance in these scenarios
responding to a client
in these scenarios can
to a client s
these scenarios can t
a client s request
scenarios can t be
can t be explained
t be explained by
will successively fill the
be explained by correlation
successively fill the four
explained by correlation with
fill the four repair
by correlation with cpu
the four repair bins
correlation with cpu activity
four repair bins in
in general multiple front
repair bins in layer
end servers may be
servers may be run
or loss rates at
loss rates at the
rates at the receivers
this behavior leads to
each on its own
behavior leads to a
on its own ec
leads to a large
but that it does
to a large number
that it does appear
a large number of
it does appear correlated
large number of repair
does appear correlated to
number of repair packets
appear correlated to slower
of repair packets being
correlated to slower cleanup
the system is organized
to slower cleanup and
repair packets being generated
slower cleanup and the
system is organized as
packets being generated and
is organized as in
cleanup and the resulting
organized as in figure
and the resulting memory
being generated and sent
generated and sent within
and sent within a
sent within a short
within a short period
a short period of
related overheads at the
short period of time
overheads at the sender
unlike the traditional replicated
the traditional replicated subversion
traditional replicated subversion setups
replicated subversion setups that
which results in undesirable
subversion setups that are
results in undesirable overhead
setups that are used
in undesirable overhead and
that are used today
the effect is much
undesirable overhead and traffic
effect is much stronger
overhead and traffic spikes
is much stronger than
much stronger than in
stronger than in the
no single server acts
than in the undisturbed
single server acts as
in the undisturbed experiments
server acts as a
acts as a master
we would like to
would like to rate
the number of pending
number of pending messages
of pending messages starts
pending messages starts at
messages starts at a
vn all are equivalent
limit transmissions of repair
starts at a higher
transmissions of repair packets
at a higher level
of repair packets to
repair packets to one
performance of simultaneous checkouts
packets to one for
to one for every
one for every r
for every r data
every r data packets
this problem is fixed
problem is fixed by
is fixed by staggering
fixed by staggering the
by staggering the starting
staggering the starting sizes
the starting sizes of
starting sizes of the
sizes of the bins
token roundtrip time increases
analogous to the starting
to the starting positions
the starting positions of
starting positions of runners
positions of runners in
relative speedup relative speedup
of runners in a
speedup relative speedup relative
runners in a sprint
relative speedup relative speedup
and if a failure
if a failure occurs
the very first time
very first time bin
first time bin number
time bin number x
bin number x in
number x in a
token rounds before repair
x in a layer
rounds before repair occurs
in a layer of
a layer of interleave
layer of interleave i
of interleave i fires
and then another round
then another round before
another round before cleanup
performance of simultaneous commits
round before cleanup takes
it does so at
before cleanup takes place
does so at size
of simultaneous commits source
so at size x
simultaneous commits source code
at size x mod
commits source code from
size x mod r
source code from an
code from an ec
the first repair bin
first repair bin in
repair bin in the
bin in the second
in the second layer
and varying the number
the second layer with
varying the number of
second layer with interleave
the number of servers
number of servers over
of servers over which
servers over which the
over which the load
would fire at size
these account for the
which the load was
account for the rapid
the load was distributed
for the rapid increase
the rapid increase in
rapid increase in acknowledgement
increase in acknowledgement latency
the second would fire
second would fire at
would fire at size
write performance was measured
performance was measured by
was measured by observing
measured by observing the
by observing the latency
as the number of
observing the latency of
the number of caching
the latency of simultaneous
number of caching replicas
latency of simultaneous commits
of caching replicas increases
of simultaneous commits from
simultaneous commits from different
commits from different clients
since simultaneous commits to
simultaneous commits to a
commits to a single
to a single repository
a single repository would
single repository would not
repository would not be
would not be a
not be a typical
be a typical case
throughput in the experiments
in the experiments with
the experiments with a
experiments with a perturbed
with a perturbed node
vn repositories were used
all sharing the same
sharing the same set
the same set of
same set of front
end servers and same
servers and same set
and same set of
same set of three
set of three zookeeper
of three zookeeper servers
average packet loss observed
packet loss observed at
each client checked out
loss observed at the
client checked out a
observed at the perturbed
checked out a random
at the perturbed node
out a random repository
a random repository from
random repository from a
repository from a random
from a random front
and then repeatedly committed
then repeatedly committed small
repeatedly committed small amounts
committed small amounts of
memory usage at the
small amounts of data
usage at the perturbed
at the perturbed node
changes were propgated in
at unperturbed nodes it
were propgated in the
unperturbed nodes it is
propgated in the background
nodes it is similar
in the background to
the background to the
background to the other
to the other front
although it would be
it would be hard
would be hard to
shows that adding front
be hard to precisely
hard to precisely measure
to precisely measure these
precisely measure these delays
end servers can indeed
servers can indeed alleviate
can indeed alleviate latency
measuring alarm delays sheds
indeed alleviate latency problems
alarm delays sheds light
alleviate latency problems caused
delays sheds light on
latency problems caused by
sheds light on the
problems caused by high
light on the magnitude
caused by high load
on the magnitude of
the magnitude of the
magnitude of the problem
and that the overhead
that the overhead of
recall that our timesharing
the overhead of propagating
that our timesharing policy
overhead of propagating data
our timesharing policy assigns
of propagating data in
timesharing policy assigns quanta
propagating data in the
policy assigns quanta to
data in the backgound
assigns quanta to different
in the backgound is
quanta to different types
the backgound is not
to different types of
backgound is not significant
different types of events
is not significant enough
not significant enough to
significant enough to negatively
enough to negatively affect
to negatively affect performance
high volumes of i
r elated w orks
such as caused by
elated w orks moving
as caused by the
w orks moving services
caused by the increased
orks moving services to
by the increased forwarding
moving services to the
the increased forwarding traffic
services to the cloud
to the cloud has
the cloud has been
cloud has been published
has been published on
been published on in
will cause qsm to
published on in other
cause qsm to use
on in other contexts
qsm to use a
to use a larger
use a larger fraction
a larger fraction of
larger fraction of its
fraction of its i
o quantum to process
quantum to process i
is a backup application
a backup application that
backup application that implements
with the consequence that
application that implements a
the consequence that timers
that implements a custom
consequence that timers will
implements a custom block
that timers will fire
performance of prioritised rpc
timers will fire late
of prioritised rpc with
prioritised rpc with respect
rpc with respect to
based file system to
with respect to bandwidth
file system to store
respect to bandwidth variation
system to store multiple
this effect is magnified
to store multiple versions
effect is magnified each
store multiple versions of
is magnified each time
multiple versions of backup
each pair of graphs
versions of backup data
magnified each time qsm
of backup data on
pair of graphs in
each time qsm is
of graphs in shows
backup data on s
graphs in shows the
time qsm is preempted
in shows the speedup
qsm is preempted by
shows the speedup of
is preempted by other
the speedup of one
preempted by other processes
speedup of one of
by other processes or
of one of three
other processes or by
one of three cache
processes or by its
the authors make the
of three cache manager
authors make the distinction
three cache manager configurations
make the distinction between
or by its own
the distinction between thin
by its own garbage
its own garbage collector
relative to the time
to the time taken
clouds that provide a
the time taken by
that provide a low
such delays are typically
time taken by uniform
delays are typically shorter
taken by uniform priorities
are typically shorter than
by uniform priorities with
typically shorter than the
uniform priorities with synchronous
shorter than the i
priorities with synchronous rpcs
level api and thick
with synchronous rpcs at
clouds that are designed
that are designed for
are designed for a
yet longer than the
designed for a specific
longer than the alarm
for a specific application
than the alarm quantum
thick clouds for a
thus causing the alarm
clouds for a variety
for a variety of
as well as uniform
a variety of purposes
well as uniform priorities
second set of rsized
as uniform priorities and
set of rsized xors
uniform priorities and synchronous
of rsized xors staggered
priorities and synchronous rpcs
rsized xors staggered start
but not the i
including backup and source
xors staggered start xors
backup and source code
and source code repository
source code repository hosting
the graphs also show
graphs also show curves
the maximum alarm firing
also show curves for
with sourceforge and google
show curves for differentiated
sourceforge and google code
curves for differentiated priorities
and google code being
maximum alarm firing delays
google code being examples
for differentiated priorities and
alarm firing delays taken
differentiated priorities and synchronous
firing delays taken from
priorities and synchronous rpcs
delays taken from samples
code being examples of
taken from samples in
being examples of the
examples of the latter
s intervals are indeed
intervals are indeed much
the authors of cumulus
are indeed much larger
authors of cumulus and
indeed much larger in
of cumulus and we
much larger in the
cumulus and we show
larger in the perturbed
and we show that
in the perturbed experiments
we show that thin
and differentiated priorities and
differentiated priorities and asynchronous
priorities and asynchronous rpcs
both on the sender
cloud solutions can be
on the sender and
solutions can be a
the sender and on
can be a cost
sender and on the
and on the receiver
on the receiver side
the values plotted for
another example of moving
values plotted for bandwidth
example of moving a
plotted for bandwidth of
of moving a service
moving a service to
a service to the
service to the cloud
to the cloud is
the cloud is metacdn
large delays are also
delays are also more
s are the same
a content distribution network
are the same as
are also more frequent
the same as shown
same as shown in
as shown in table
the work evaluates the
work evaluates the latency
evaluates the latency of
the latency of various
latency of various cloud
due to the overhead
of various cloud storage
the maximum delay measured
to the overhead of
maximum delay measured on
various cloud storage services
delay measured on receivers
the overhead of priorities
cloud storage services from
overhead of priorities for
measured on receivers in
of priorities for small
on receivers in the
priorities for small rpcs
receivers in the perturbed
for small rpcs mentioned
in the perturbed runs
small rpcs mentioned in
the perturbed runs is
rpcs mentioned in section
storage services from several
services from several locations
from several locations and
several locations and provides
locations and provides an
and provides an abstraction
provides an abstraction to
an abstraction to integrate
abstraction to integrate the
to integrate the different
integrate the different offerings
the different offerings into
different offerings into a
offerings into a single
into a single system
comparing the execution time
the execution time of
execution time of the
time of the foreground
of the foreground workloads
the foreground workloads with
foreground workloads with synchronous
workloads with synchronous writes
update logging and asynchronous
logging and asynchronous writeback
and asynchronous writeback reveals
asynchronous writeback reveals that
writeback reveals that the
like transactional data store
reveals that the latter
transactional data store backed
that the latter two
data store backed by
the latter two options
store backed by s
latter two options generally
two options generally perform
options generally perform comparably
generally perform comparably to
perform comparably to or
ms in the unperturbed
comparably to or better
in the unperturbed experiments
to or better than
or better than synchronous
and faced similar issues
better than synchronous writes
faced similar issues as
similar issues as s
logging and asynchronous writeback
vn due to its
the value grows from
and asynchronous writeback greatly
due to its need
asynchronous writeback greatly improve
to its need for
writeback greatly improve the
its need for high
greatly improve the performance
need for high consistency
improve the performance of
the performance of the
performance of the background
of the background workloads
elastras assigns update priviledges
assigns update priviledges for
update priviledges for different
as has been noted
priviledges for different areas
has been noted previously
for different areas of
different areas of the
areas of the data
of the data store
the data store to
data store to individual
store to individual front
the problem could be
using the lock service
problem could be alleviated
the lock service to
could be alleviated by
lock service to elect
be alleviated by making
service to elect an
alleviated by making our
to elect an owner
by making our priority
elect an owner for
making our priority scheduling
an owner for each
our priority scheduling more
owner for each partition
priority scheduling more fine
we focus on mfs
much in the style
focus on mfs with
in the style described
on mfs with asynchronous
the style described by
mfs with asynchronous writeback
style described by google
with asynchronous writeback in
described by google s
asynchronous writeback in the
by google s chubby
writeback in the rest
in the rest of
varying priorities for control
the rest of this
priorities for control packets
rest of this paper
of this paper because
this paper because it
paper because it provides
because it provides comparable
or by assigning priorities
it provides comparable performance
by assigning priorities to
provides comparable performance to
assigning priorities to feeds
comparable performance to logged
priorities to feeds in
performance to logged updates
to feeds in the
feeds in the sending
in the sending stack
allows straightforward modeless adaptation
a lock service based
straightforward modeless adaptation to
lock service based on
modeless adaptation to bandwidth
service based on paxos
adaptation to bandwidth variation
and is easily extensible
is easily extensible to
easily extensible to more
extensible to more than
to more than one
number of messages awaiting
more than one level
of messages awaiting acknowledgement
than one level of
messages awaiting acknowledgement in
one level of priority
awaiting acknowledgement in experiments
acknowledgement in experiments with
in experiments with perturbances
defers finegrained locking to
finegrained locking to the
which is required for
locking to the application
is required for our
to the application in
required for our cache
the application in order
for our cache consistency
application in order not
our cache consistency algorithm
in order not to
order not to burden
not to burden the
to burden the global
since reducing available bandwidth
burden the global lock
reducing available bandwidth increases
token roundtrip time and
available bandwidth increases the
roundtrip time and the
the global lock service
time and the time
global lock service with
and the time to
lock service with high
bandwidth increases the contention
the time to recover
increases the contention between
time to recover in
the contention between rpcs
to recover in the
contention between rpcs of
service with high traffic
between rpcs of different
rpcs of different types
the benefits of rpc
benefits of rpc priorities
of rpc priorities should
vn we opted to
rpc priorities should be
we opted to use
priorities should be more
opted to use the
should be more apparent
to use the lock
be more apparent at
use the lock service
more apparent at lower
apparent at lower priorities
token roundtrip time and
roundtrip time and the
time and the time
shows the experiments of
and the time to
the experiments of table
grained locking instead of
the time to recover
locking instead of just
time to recover in
instead of just leader
to recover in the
of just leader election
extended to a wider
to a wider range
a wider range of
wider range of bandwidth
since the latter would
range of bandwidth values
the latter would have
latter would have required
would have required duplicating
have required duplicating much
in these and later
required duplicating much of
it is worth noting
duplicating much of zookeeper
is worth noting that
these and later experiments
worth noting that the
much of zookeeper s
noting that the doubled
of zookeeper s functionality
that the doubled token
zookeeper s functionality to
the doubled token roundtrip
s functionality to replicate
doubled token roundtrip time
we evaluate mfs performance
functionality to replicate the
evaluate mfs performance with
to replicate the leader
mfs performance with bandwidths
replicate the leader s
performance with bandwidths from
the leader s state
as compared to unperturbed
compared to unperturbed experiments
scalability is not an
can t be accounted
is not an obstacle
t be accounted for
not an obstacle because
be accounted for by
an obstacle because there
accounted for by the
obstacle because there is
for by the increase
because there is no
by the increase in
there is no need
the increase in memory
is no need for
increase in memory overhead
no need for global
in memory overhead or
need for global locking
memory overhead or cpu
for global locking across
overhead or cpu activity
global locking across multiple
or cpu activity on
locking across multiple repositories
cpu activity on the
activity on the receivers
the load can be
load can be partitioned
as was the case
can be partitioned across
was the case in
be partitioned across as
the case in experiments
partitioned across as many
case in experiments where
across as many zookeeper
in experiments where we
as many zookeeper instances
experiments where we varied
many zookeeper instances as
where we varied the
zookeeper instances as necessary
we varied the replication
varied the replication factor
s is not low
replication is not without
is not low in
is not without its
not low in the
not without its dangers
low in the sense
the problem can be
in the sense of
problem can be traced
the sense of prior
can be traced to
sense of prior work
be traced to a
traced to a priority
to a priority inversion
it is low enough
is low enough to
because of repeated losses
low enough to cause
enough to cause significant
to cause significant contention
cause significant contention for
and it has been
the system maintains a
significant contention for the
system maintains a high
it has been shown
maintains a high volume
contention for the workloads
a high volume of
has been shown that
high volume of forwarding
for the workloads we
been shown that replicating
the workloads we have
volume of forwarding traffic
workloads we have considered
shown that replicating too
that replicating too eagerly
replicating too eagerly leads
too eagerly leads quickly
eagerly leads quickly to
the forwarded messages tend
leads quickly to degraded
forwarded messages tend to
quickly to degraded performance
messages tend to get
and we believe that
tend to get ahead
we believe that our
to get ahead of
believe that our results
the solution proposed is
that our results will
solution proposed is to
our results will hold
proposed is to use
get ahead of the
is to use master
ahead of the token
to use master copy
results will hold if
use master copy replication
will hold if available
hold if available bandwidth
if available bandwidth and
both on the send
available bandwidth and grep
on the send path
where a transaction does
bandwidth and grep write
a transaction does not
transaction does not immediately
does not immediately update
not immediately update all
where in the sinks
immediately update all replicas
we use a simple
use a simple round
robin policy of multiplexing
policy of multiplexing between
of multiplexing between data
as the master copy
multiplexing between data feeds
and only the lock
and on the receive
only the lock service
afs mfs afs mfs
on the receive path
mfs afs mfs elapsed
afs mfs elapsed time
which deals with simple
where forwarded packets are
forwarded packets are treated
packets are treated as
are treated as control
treated as control traffic
bandwidth operations that may
and while they re
operations that may be
while they re prioritized
that may be concentrated
they re prioritized over
may be concentrated on
re prioritized over data
be concentrated on a
concentrated on a small
on a small number
a small number of
small number of servers
they are treated as
are treated as equally
treated as equally important
as equally important as
equally important as tokens
must be eagerly replicated
they also increase the
also relevant is sundr
also increase the overall
increase the overall volume
the overall volume of
overall volume of i
the secure untrusted data
secure untrusted data repository
o that the nodes
that the nodes process
tokens are processed with
are processed with higher
processed with higher latency
this file system allows
file system allows clients
system allows clients to
allows clients to detect
clients to detect against
to detect against malicious
detect against malicious or
against malicious or compromised
malicious or compromised storage
or compromised storage servers
compromised storage servers or
storage servers or hosting
servers or hosting platforms
or hosting platforms by
hosting platforms by providing
platforms by providing fork
by providing fork consistency
a property which ensures
histogram of maximum alarm
property which ensures that
of maximum alarm delays
maximum alarm delays in
which ensures that clients
ensures that clients can
that clients can detect
clients can detect integrity
can detect integrity failures
detect integrity failures as
integrity failures as long
failures as long as
as long as they
long as they see
as they see each
they see each other
see each other s
each other s file
other s file modifications
similar techniques could be
techniques could be used
could be used to
histogram of maximum alarm
be used to recover
of maximum alarm delays
used to recover data
maximum alarm delays in
to recover data from
recover data from client
data from client working
from client working copies
client working copies in
working copies in the
copies in the event
in the event of
the event of a
event of a catastrophic
of a catastrophic cloud
a catastrophic cloud failure
once code repositories are
code repositories are stored
repositories are stored in
are stored in the
stored in the cloud
overheads in a lightly
one might imagine enabling
might imagine enabling mashups
imagine enabling mashups in
enabling mashups in ways
mashups in ways not
in ways not previously
loaded system so far
ways not previously possible
system so far the
so far the evaluation
far the evaluation has
the evaluation has focused
evaluation has focused on
has focused on scenarios
focused on scenarios where
on scenarios where the
web based code viewers
scenarios where the system
where the system was
the system was heavily
system was heavily loaded
with unbounded multicast rates
and cross reference viewers
unbounded multicast rates and
cross reference viewers might
multicast rates and occasional
reference viewers might be
rates and occasional perturbations
viewers might be built
might be built by
be built by third
we traced degraded performance
traced degraded performance or
pulling data from the
degraded performance or scheduling
data from the repositories
performance or scheduling delays
from the repositories of
or scheduling delays to
the repositories of several
scheduling delays to memory
repositories of several distinct
of several distinct communities
but how does the
how does the system
comparison of mfs and
does the system behave
of mfs and afs
the system behave when
mfs and afs performance
system behave when lightly
behave when lightly loaded
mfs with synchronous rpcs
do similar phenomena occur
with synchronous rpcs and
seeks to enable such
synchronous rpcs and priorities
to enable such applications
rpcs and priorities is
enable such applications by
and priorities is compared
such applications by granting
priorities is compared to
here we ll see
is compared to a
we ll see that
compared to a version
ll see that load
to a version of
see that load has
a version of the
applications by granting direct
version of the andrew
that load has a
of the andrew file
load has a super
the andrew file system
by granting direct access
granting direct access of
direct access of cloud
access of cloud storage
of cloud storage to
linear impact on performance
speedups for the two
cloud storage to third
for the two workloads
storage to third parties
the two workloads of
two workloads of the
workloads of the gw
of the gw test
the gw test are
gw test are shown
subject to the data
to the data owner
the growth in memory
the data owner s
growth in memory consumption
data owner s security
in memory consumption causes
relative to the performance
owner s security requirements
memory consumption causes slowdowns
to the performance of
consumption causes slowdowns that
the performance of afs
causes slowdowns that amplify
performance of afs at
a question that may
slowdowns that amplify the
question that may naturally
that amplify the increased
that may naturally arise
amplify the increased latencies
may naturally arise is
the increased latencies associated
increased latencies associated with
latencies associated with the
associated with the growth
with the growth in
the growth in traffic
why not use a
not use a general
use a general purpose
a general purpose file
general purpose file system
purpose file system interface
to show this we
traffic are scaled down
show this we designed
are scaled down further
file system interface to
this we designed experiments
system interface to s
scaled down further in
we designed experiments that
down further in parallel
designed experiments that vary
experiments that vary the
that vary the multicast
vary the multicast rate
the graphs in figure
validate the incorporation of
the incorporation of rpc
incorporation of rpc priorities
and store a repository
store a repository on
showed that the load
a repository on that
that the load on
since all the foreground
the load on receivers
all the foreground workloads
load on receivers grows
the foreground workloads improve
on receivers grows roughly
this is indeed possible
receivers grows roughly linearly
comparison of packet recovery
is indeed possible to
of packet recovery probability
indeed possible to do
foreground workloads improve their
workloads improve their performance
as expected given the
improve their performance substantially
expected given the linearly
their performance substantially at
but would entail pushing
performance substantially at lower
would entail pushing temporary
substantially at lower bandwidths
entail pushing temporary files
given the linearly increasing
pushing temporary files such
the linearly increasing load
temporary files such as
files such as transactions
relative to mfs with
to mfs with no
mfs with no priorities
negligible loss rates and
loss rates and the
rates and the nearly
and the nearly flat
the nearly flat curve
nearly flat curve of
and incurring additional monetary
flat curve of memory
incurring additional monetary costs
curve of memory consumption
the decrease in throughput
additional monetary costs due
decrease in throughput for
monetary costs due to
in throughput for the
costs due to the
due to the increased
to the increased number
the increased number of
increased number of s
parameter trace mostly writes
staggered start first i
start first i data
first i data packets
i data packets added
data packets added to
there would also likely
packets added to a
would also likely be
added to a layer
also likely be performance
to a layer with
likely be performance problems
the latter reflecting our
a layer with interleave
latter reflecting our cooperative
layer with interleave i
reflecting our cooperative caching
our cooperative caching policy
since file append and
file append and rename
append and rename operations
and rename operations do
load on the sender
rename operations do not
operations do not map
do not map efficiently
r fire immediately with
not map efficiently to
fire immediately with just
map efficiently to s
immediately with just one
with just one packet
just one packet in
one packet in them
because the linear growth
for the next i
the linear growth of
the next i data
linear growth of traffic
next i data packets
i data packets added
combined with our fixed
with our fixed rate
our fixed rate of
fs that is aware
fixed rate of state
rate of state aggregation
that is aware of
r fire immediately with
is aware of subversion
fire immediately with two
aware of subversion s
increases the amount of
immediately with two data
the amount of unacknowledged
of subversion s file
amount of unacknowledged data
with two data packets
subversion s file naming
two data packets in
data packets in them
s file naming and
file naming and use
naming and use scenario
and use scenario could
and so on until
use scenario could of
so on until r
scenario could of course
on until r i
could of course overcome
until r i data
of course overcome these
r i data packets
course overcome these limitations
i data packets have
overcome these limitations by
data packets have been
these limitations by pushing
packets have been added
limitations by pushing only
have been added to
by pushing only what
been added to the
pushing only what is
added to the layer
only what is actually
to the layer and
this triggers higher overheads
the layer and all
what is actually required
layer and all bins
is actually required into
and all bins have
actually required into s
all bins have fired
bins have fired exactly
have fired exactly once
the time spent in
time spent in the
spent in the garbage
in the garbage collector
the garbage collector grows
garbage collector grows from
but we believe that
we believe that such
all bins fire at
believe that such specialized
bins fire at size
that such specialized tools
fire at size r
such specialized tools are
specialized tools are better
tools are better built
are better built on
better built on top
built on top of
on top of a
top of a file
now that they have
of a file system
that they have been
a file system abstraction
they have been staggered
file system abstraction than
have been staggered at
system abstraction than pushed
been staggered at the
abstraction than pushed underneath
staggered at the start
than pushed underneath it
r fire for any
fire for any i
c onclusion we have
for any i data
combined with a linear
onclusion we have shown
with a linear growth
any i data packets
a linear growth of
we have shown that
linear growth of cpu
have shown that the
growth of cpu usage
shown that the cost
of cpu usage due
the outlined scheme works
cpu usage due to
that the cost of
usage due to the
outlined scheme works when
due to the increasing
the cost of using
to the increasing volume
scheme works when i
the increasing volume of
cost of using a
increasing volume of traffic
works when i is
of using a cloud
when i is greater
using a cloud computing
i is greater than
a cloud computing storage
is greater than or
cloud computing storage service
greater than or equal
these overheads cause the
computing storage service for
overheads cause the super
than or equal to
storage service for source
or equal to r
service for source code
for source code repository
source code repository hosting
linear growth of cpu
code repository hosting is
growth of cpu overhead
repository hosting is low
of cpu overhead shown
as is usually the
cpu overhead shown on
is usually the case
overhead shown on figure
both for individual projects
for individual projects and
individual projects and moderately
projects and moderately sized
and moderately sized communities
if i is smaller
i is smaller than
is smaller than r
considering the costs of
the costs of a
the bin with index
costs of a resilient
bin with index x
of a resilient local
the increasing number of
with index x fires
a resilient local storage
index x fires at
increasing number of unacknowledged
resilient local storage system
number of unacknowledged requests
local storage system of
of unacknowledged requests and
storage system of scsi
unacknowledged requests and the
system of scsi disks
requests and the resulting
of scsi disks and
scsi disks and tape
and the resulting overheads
disks and tape backup
the resulting overheads rise
these traces are representative
resulting overheads rise sharply
traces are representative periods
overheads rise sharply at
are representative periods of
cloud computing is a
representative periods of mixed
computing is a very
periods of mixed read
rise sharply at the
of mixed read and
is a very attractive
mixed read and write
sharply at the highest
read and write activity
a very attractive solution
at the highest rates
very attractive solution for
the highest rates because
attractive solution for this
highest rates because of
solution for this application
rates because of the
the durations are from
because of the increasing
durations are from the
of the increasing token
are from the original
the increasing token roundtrip
from the original ntfs
increasing token roundtrip time
the original ntfs traces
our implementation of s
the issue here is
note that the total
vn brings this concept
that the total file
brings this concept a
issue here is that
this concept a step
here is that the
concept a step closer
is that the amount
the initial firing sizes
that the amount of
initial firing sizes would
a step closer to
the total file sizes
step closer to becoming
the amount of i
closer to becoming reality
total file sizes represent
firing sizes would be
file sizes represent the
sizes represent the amount
represent the amount fetched
o to be processed
the amount fetched by
to be processed increases
amount fetched by mfs
and provides evidence that
for the first bin
provides evidence that performance
the first bin and
evidence that performance will
fetched by mfs during
that performance will be
by mfs during the
performance will be acceptable
mfs during the trace
much as in some
will be acceptable for
as in some of
for the second bin
in some of the
be acceptable for typical
some of the earlier
acceptable for typical use
of the earlier scenarios
for typical use scenarios
where this is exceed
if r and i
this is exceed by
r and i are
is exceed by the
and i are not
exceed by the write
i are not integral
this delays tokens as
are not integral multiples
by the write traffic
not integral multiples of
delays tokens as a
integral multiples of each
tokens as a function
multiples of each other
as a function of
a function of the
the additional traffic is
function of the growing
additional traffic is due
of the growing volume
traffic is due to
the growing volume of
is due to new
growing volume of multicast
due to new files
limiting still works but
to new files being
volume of multicast traffic
new files being created
still works but is
files being created or
works but is slightly
being created or existing
but is slightly less
created or existing ones
is slightly less effective
we confirm the hypothesis
or existing ones extended
confirm the hypothesis by
slightly less effective due
the hypothesis by looking
less effective due to
hypothesis by looking at
effective due to rounding
by looking at the
due to rounding errors
looking at the end
technological impact of magnetic
time spent on rpcs
impact of magnetic hard
of magnetic hard disk
magnetic hard disk drives
delaying xors in the
hard disk drives on
xors in the straightforward
disk drives on storage
in the straightforward implementation
drives on storage systems
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
as soon as they
soon as they are
as they are generated
this results in the
results in the repair
in the repair packet
the repair packet leaving
repair packet leaving immediately
packet leaving immediately after
leaving immediately after the
we would expect latency
immediately after the last
would expect latency to
after the last data
expect latency to decrease
the last data packet
latency to decrease as
last data packet that
to decrease as the
data packet that was
decrease as the sending
packet that was added
as the sending rate
that was added to
the sending rate increases
was added to it
sending rate increases because
rate increases because the
increases because the system
because the system operates
the system operates more
system operates more smoothly
which lowers burst tolerance
lowers burst tolerance if
burst tolerance if the
tolerance if the repair
if the repair packet
the repair packet was
avoiding context switching overheads
repair packet was generated
context switching overheads and
packet was generated at
switching overheads and the
was generated at interleave
overheads and the extra
generated at interleave i
and the extra latencies
the extra latencies caused
extra latencies caused by
latencies caused by the
caused by the small
the resulting protocol can
by the small amount
resulting protocol can tolerate
the small amount of
protocol can tolerate a
small amount of buffering
can tolerate a burst
amount of buffering in
tolerate a burst of
of buffering in our
a burst of i
buffering in our protocol
burst of i lost
in our protocol stack
of i lost data
i lost data packets
lost data packets excluding
data packets excluding the
packets excluding the repair
with larger packets once
larger packets once the
packets once the rate
once the rate exceeds
but the burst could
the burst could swallow
burst could swallow both
could swallow both the
swallow both the repair
both the repair and
the repair and the
repair and the last
and the last data
the last data packet
last data packet in
data packet in it
packet in it as
in it as they
it as they are
as they are not
they are not separated
are not separated by
not separated by the
separated by the requisite
by the requisite interleave
the latency starts increasing
latency starts increasing again
the solution to this
due to the longer
solution to this is
to the longer pipeline
to this is simple
the longer pipeline at
this is simple delay
longer pipeline at the
is simple delay sending
pipeline at the receive
simple delay sending the
at the receive side
delay sending the repair
the receive side and
sending the repair packet
ntfs workloads in addition
receive side and other
workloads in addition to
side and other phenomena
the repair packet generated
and other phenomena just
in addition to measuring
repair packet generated by
other phenomena just mentioned
addition to measuring the
packet generated by a
to measuring the performance
generated by a repair
measuring the performance of
by a repair bin
the performance of mfs
this is not the
performance of mfs with
a repair bin until
of mfs with synthetic
is not the case
mfs with synthetic workloads
not the case for
repair bin until the
the case for small
bin until the next
case for small packets
until the next time
the next time a
we have also conducted
next time a data
have also conducted experiments
time a data packet
also conducted experiments with
a data packet is
conducted experiments with traces
data packet is added
experiments with traces gathered
packet is added to
with traces gathered from
is added to the
traces gathered from the
added to the now
gathered from the windows
to the now empty
from the windows nt
the now empty bin
the windows nt file
windows nt file system
here the load on
the load on the
load on the system
which happens i packets
on the system is
happens i packets later
the system is much
system is much smaller
i packets later and
packets later and introduces
later and introduces the
and introduces the required
introduces the required interleave
the required interleave between
required interleave between the
interleave between the repair
the above observations are
between the repair packet
above observations are consistent
the repair packet and
observations are consistent with
repair packet and the
are consistent with the
packet and the last
consistent with the sharp
and the last data
with the sharp rise
the last data packet
the sharp rise of
last data packet included
sharp rise of the
although mfs is implemented
rise of the average
mfs is implemented on
of the average delay
is implemented on a
the average delay for
implemented on a variant
average delay for timer
on a variant of
delay for timer events
data packet included in
a variant of unix
packet included in it
and ntfs has a
notice that although transmitting
ntfs has a somewhat
that although transmitting the
has a somewhat different
although transmitting the xor
a somewhat different interface
transmitting the xor immediately
somewhat different interface to
the xor immediately results
different interface to the
xor immediately results in
interface to the file
immediately results in faster
to the file system
results in faster recovery
as the rate changes
the rate changes from
the traces were converted
doing so also reduces
traces were converted to
so also reduces the
were converted to run
also reduces the probability
converted to run on
reduces the probability of
to run on top
the probability of a
run on top of
probability of a lost
on top of mfs
of a lost packet
top of mfs with
a lost packet being
of mfs with little
lost packet being recovered
mfs with little difficulty
the original traces recorded
original traces recorded file
traces recorded file accesses
brewer s conjecture and
off results in a
s conjecture and the
recorded file accesses on
results in a minor
conjecture and the feasibility
file accesses on a
in a minor control
and the feasibility of
a minor control knob
the feasibility of consistent
minor control knob permitting
feasibility of consistent available
accesses on a set
of consistent available partition
control knob permitting us
on a set of
knob permitting us to
a set of machines
permitting us to balance
set of machines in
timer delays at the
of machines in a
us to balance speed
delays at the receiver
to balance speed against
at the receiver increase
balance speed against burst
in in acm sigact
speed against burst tolerance
in acm sigact news
the receiver increase from
machines in a lan
our default configuration is
default configuration is to
configuration is to transmit
a majority of the
is to transmit the
majority of the accesses
to transmit the xor
of the accesses were
transmit the xor immediately
the accesses were local
accesses were local but
were local but some
local but some were
but some were to
some were to remote
were to remote machines
and on the sender
we extracted subintervals from
extracted subintervals from the
subintervals from the traces
from the traces which
the traces which featured
traces which featured interesting
which featured interesting file
envelope analysis to start
featured interesting file system
analysis to start with
interesting file system behaviour
file system behaviour and
system behaviour and processed
behaviour and processed them
and processed them to
we note that no
processed them to remove
note that no two
them to remove accesses
that no two repair
to remove accesses to
no two repair packets
remove accesses to files
two repair packets generated
accesses to files over
repair packets generated at
packets generated at different
generated at different interleaves
at different interleaves i
number of unacknowledged messages
of unacknowledged messages and
this preprocessing was necessary
unacknowledged messages and average
preprocessing was necessary to
messages and average token
was necessary to eliminate
and average token roundtrip
necessary to eliminate the
average token roundtrip time
to eliminate the influence
token roundtrip time as
eliminate the influence of
roundtrip time as a
the influence of extremely
time as a function
influence of extremely large
as a function of
of extremely large nt
a function of the
extremely large nt system
function of the sending
large nt system files
of the sending rate
will have more than
have more than one
more than one data
than one data packet
one data packet in
data packet in common
packet in common as
in common as long
common as long as
linearly growing memory use
as long as the
of the file system
long as the least
growing memory use on
filesystem backup to the
the file system traffic
as the least common
file system traffic in
the least common multiple
system traffic in some
backup to the cloud
traffic in some portions
memory use on sender
in some portions of
use on sender and
some portions of the
on sender and the
portions of the original
sender and the nearly
of the original traces
and the nearly flat
of the interleaves is
the nearly flat usage
the interleaves is greater
nearly flat usage on
interleaves is greater than
flat usage on the
is greater than r
given that mfs retrieves
greater than r i
usage on the receiver
that mfs retrieves and
on the receiver as
mfs retrieves and writes
the receiver as a
retrieves and writes back
receiver as a function
and writes back whole
as a function of
writes back whole files
a function of the
function of the sending
of the sending rate
pairings of repair bins
of repair bins in
repair bins in two
including these system files
bins in two different
these system files would
in two different layers
system files would have
two different layers with
files would have distorted
different layers with interleaves
layers with interleaves i
would have distorted the
have distorted the experiments
distorted the experiments at
the experiments at low
experiments at low bandwidths
gives statistics for the
statistics for the three
receive latency for varying
for the three traces
latency for varying rate
a trace in which
with various message sizes
trace in which reads
in which reads predominate
a trace in which
trace in which writes
in which writes predominate
and one containing exceptionally
a good rule of
one containing exceptionally heavy
good rule of thumb
containing exceptionally heavy file
alarm firing delays on
exceptionally heavy file system
rule of thumb is
heavy file system traffic
firing delays on sender
of thumb is to
delays on sender and
thumb is to select
on sender and receiver
is to select interleaves
sender and receiver as
to select interleaves that
each trace was run
and receiver as a
select interleaves that are
receiver as a function
trace was run over
as a function of
interleaves that are relatively
a function of sending
was run over mfs
that are relatively prime
run over mfs with
function of sending rate
over mfs with the
are relatively prime to
mfs with the combinations
relatively prime to maximize
with the combinations of
prime to maximize their
the combinations of synchronous
to maximize their lcm
combinations of synchronous and
of synchronous and asynchronous
synchronous and asynchronous writes
and asynchronous writes and
asynchronous writes and differentiated
and also ensure that
writes and differentiated and
also ensure that the
and differentiated and uniform
ensure that the larger
differentiated and uniform priorities
that the larger interleave
and uniform priorities in
the larger interleave is
uniform priorities in previous
larger interleave is greater
priorities in previous experiments
interleave is greater than
harnessing storage clouds for
is greater than r
storage clouds for high
clouds for high performance
for high performance content
high performance content delivery
and the results are
the results are given
let us assume that
results are given in
us assume that packets
are given in figure
assume that packets are
that packets are dropped
packets are dropped with
are dropped with uniform
group memory consumption in
memory consumption in a
consumption in a final
to interpret these graphs
in a final set
a final set of
final set of experiments
given a lost data
a lost data packet
look for instance at
for instance at the
th international conference on
we focus on scalability
what is the probability
instance at the heavy
is the probability that
at the heavy load
the probability that we
the heavy load bar
probability that we can
heavy load bar mostly
that we can recover
load bar mostly reads
we can recover it
focus on scalability with
international conference on service
on scalability with the
scalability with the number
with the number of
the number of groups
we can recover a
can recover a data
recover a data packet
a data packet if
a single sender multicasts
data packet if at
single sender multicasts to
packet if at least
sender multicasts to a
if at least one
multicasts to a varying
at least one of
to a varying number
least one of the
a varying number of
one of the c
varying number of groups
of the c xors
number of groups in
the c xors containing
of groups in a
c xors containing it
groups in a roundrobin
xors containing it is
in a roundrobin fashion
containing it is received
it is received correctly
is received correctly and
received correctly and usable
all receivers join all
receivers join all groups
and since the groups
since the groups are
the groups are perfectly
groups are perfectly overlapped
all the other data
the other data packets
other data packets in
the system contains a
data packets in it
system contains a single
packets in it have
contains a single region
in it have also
it have also been
have also been received
also been received correctly
qsm s regional recovery
s regional recovery protocol
regional recovery protocol is
recovery protocol is oblivious
the probability of which
protocol is oblivious to
probability of which is
is oblivious to the
of which is simply
oblivious to the groups
hence the receivers behave
the receivers behave identically
receivers behave identically no
behave identically no matter
identically no matter how
no matter how many
matter how many groups
how many groups we
many groups we use
on the other hand
the probability of a
probability of a received
of a received xor
the sender maintains a
a received xor being
sender maintains a number
received xor being unusable
maintains a number of
xor being unusable is
a number of per
being unusable is the
unusable is the complement
this affects the sender
affects the sender s
the sender s memory
sender s memory footprint
applications unique files total
unique files total file
files total file sizes
so changes to throughput
changes to throughput or
to throughput or protocol
throughput or protocol behavior
or protocol behavior must
protocol behavior must be
behavior must be directly
must be directly or
be directly or indirectly
directly or indirectly linked
or indirectly linked to
indirectly linked to memory
linked to memory usage
an elastic transactional data
elastic transactional data store
transactional data store in
data store in the
we do not expect
store in the cloud
do not expect the
not expect the token
expect the token roundtrip
the token roundtrip time
token roundtrip time or
roundtrip time or the
time or the amount
the probability x of
or the amount of
probability x of a
the amount of messages
grep in the gw
amount of messages pending
x of a sent
of messages pending acknowledgement
in the gw workload
messages pending acknowledgement to
the gw workload even
pending acknowledgement to vary
of a sent xor
acknowledgement to vary with
gw workload even is
to vary with the
a sent xor being
vary with the number
workload even is less
with the number of
sent xor being dropped
even is less than
the number of groups
is less than would
xor being dropped or
less than would be
being dropped or unusable
than would be expected
dropped or unusable is
would be expected with
or unusable is the
be expected with reduced
unusable is the sum
expected with reduced bandwidth
is the sum of
the sum of the
sum of the probability
of the probability that
here uniform priorities result
the probability that it
uniform priorities result in
probability that it was
priorities result in throughput
that it was dropped
result in throughput linear
it was dropped and
in throughput linear in
groups this is the
throughput linear in the
this is the case
linear in the bandwidth
was dropped and the
dropped and the probability
the chubby lock service
and the probability that
chubby lock service for
the probability that it
lock service for loosely
while differentiated priorities are
probability that it was
differentiated priorities are less
that it was received
priorities are less sensitive
it was received and
was received and unusable
the rc and gc
rc and gc tests
and gc tests show
gc tests show the
tests show the benefit
show the benefit of
the benefit of asynchronous
benefit of asynchronous writeback
in this range memory
this range memory consumption
range memory consumption on
since the updates from
memory consumption on the
the updates from the
consumption on the sender
updates from the compile
on the sender grows
th conference on usenix
from the compile workload
conference on usenix symposium
the compile workload are
on usenix symposium on
compile workload are committed
usenix symposium on operating
workload are committed sooner
symposium on operating systems
are committed sooner to
on operating systems design
committed sooner to the
operating systems design and
sooner to the server
systems design and implementation
to the server than
the server than with
server than with synchronous
than with synchronous writes
due to the overlap
and so does the
to the overlap of
so does the time
the overlap of think
does the time spent
overlap of think time
the time spent in
of think time with
time spent in the
think time with asynchronous
spent in the clr
time with asynchronous writes
though uniform priorities provide
uniform priorities provide better
priorities provide better performance
provide better performance for
better performance for the
performance for the write
for the write component
the write component of
write component of the
component of the rw
of the rw test
the rw test at
since it is easy
it is easy to
is easy to ensure
easy to ensure that
to ensure that no
inspection of the managed
ensure that no two
of the managed heap
that no two xors
the managed heap in
no two xors share
managed heap in a
two xors share more
as is to be
xors share more than
is to be expected
share more than one
heap in a debugger
more than one data
in a debugger shows
than one data packet
a debugger shows that
since we are prioritising
debugger shows that the
we are prioritising reads
shows that the growth
that the growth in
the growth in memory
the usability probabilities of
growth in memory used
usability probabilities of different
in memory used is
probabilities of different xors
memory used is caused
of different xors are
used is caused not
different xors are independent
is caused not by
this benefit largely vanishes
caused not by messages
benefit largely vanishes at
largely vanishes at lower
vanishes at lower bandwidths
the probability of all
probability of all the
of all the c
but by the per
all the c xors
the c xors being
c xors being dropped
though we have concentrated
xors being dropped or
we have concentrated on
group elements of the
being dropped or unusable
elements of the protocol
have concentrated on determining
dropped or unusable is
concentrated on determining the
or unusable is xc
of the protocol stack
on determining the benefit
determining the benefit of
the benefit of rpc
benefit of rpc priorities
each maintains a queue
of rpc priorities by
rpc priorities by a
priorities by a comparison
the probability of correctly
by a comparison of
probability of correctly receiving
a comparison of different
of correctly receiving at
comparison of different configurations
correctly receiving at least
of different configurations of
receiving at least one
different configurations of mfs
at least one usable
configurations of mfs to
least one usable xor
of mfs to one
one usable xor is
small structures for profiling
mfs to one another
structures for profiling etc
with thousands of groups
we have also performed
have also performed a
also performed a few
performed a few experiments
these add up to
a few experiments to
the probability of recovering
add up to tens
probability of recovering the
up to tens of
of recovering the lost
to tens of megabytes
few experiments to compare
recovering the lost data
experiments to compare the
the lost data packet
to compare the performance
lost data packet is
compare the performance of
we can confirm the
the performance of mfs
can confirm the theory
performance of mfs to
confirm the theory by
of mfs to a
the theory by turning
mfs to a standard
theory by turning on
to a standard distributed
by turning on additional
a standard distributed file
turning on additional tracing
standard distributed file system
on additional tracing in
additional tracing in the
tracing in the per
illustrates the result of
the result of running
this tracing is lightweight
result of running the
tracing is lightweight and
of running the gw
is lightweight and has
running the gw test
lightweight and has little
the gw test over
and has little effect
gw test over mfs
has little effect on
test over mfs and
little effect on cpu
over mfs and an
effect on cpu consumption
mfs and an andrew
and an andrew file
an andrew file system
but it increases the
it increases the memory
increases the memory footprint
the memory footprint by
memory footprint by adding
footprint by adding additional
by adding additional data
adding additional data structures
additional data structures that
form formula only gives
we used the arla
data structures that are
used the arla implementation
structures that are updated
the arla implementation of
that are updated once
formula only gives us
arla implementation of the
only gives us a
implementation of the afs
gives us a lower
of the afs cache
us a lower bound
the afs cache manager
a lower bound on
are updated once per
lower bound on the
updated once per second
bound on the recovery
on the recovery probability
which burdens the gc
since the xor usability
the xor usability formula
xor usability formula does
usability formula does not
formula does not factor
does not factor in
and the openafs server
not factor in the
factor in the probability
in the probability of
the probability of the
afs uses a udp
probability of the other
of the other data
the other data packets
other data packets in
data packets in the
based rpc library without
packets in the xor
rpc library without priorities
in the xor being
the xor being dropped
xor being dropped and
being dropped and recovered
the results largely correspond
results largely correspond to
largely correspond to those
correspond to those in
to those in figure
it is worth noting
we extend the analysis
is worth noting that
extend the analysis to
worth noting that the
the analysis to bursty
noting that the memory
analysis to bursty losses
that the memory usages
mfs significantly outperforms afs
the memory usages reported
significantly outperforms afs for
memory usages reported here
outperforms afs for the
usages reported here are
afs for the foreground
reported here are averages
if the lost data
for the foreground grep
the lost data packet
the foreground grep workload
lost data packet was
data packet was part
packet was part of
was part of a
part of a loss
of a loss burst
since afs effectively uses
a loss burst of
afs effectively uses synchronous
loss burst of size
effectively uses synchronous rpcs
burst of size b
uses synchronous rpcs with
synchronous rpcs with uniform
and the peak values
rpcs with uniform priorities
the peak values are
peak values are typically
repair packets generated at
packets generated at interleaves
in the background write
generated at interleaves less
the background write workload
at interleaves less than
interleaves less than b
less than b are
than b are dropped
b are dropped or
afs slightly outperforms mfs
are dropped or useless
dropped or useless with
or useless with high
useless with high probability
but it is both
it is both a
is both a more
both a more mature
and we can discount
a more mature system
we can discount them
and more optimised than
more optimised than mfs
optimised than mfs for
than mfs for this
mfs for this sort
of recovering the data
for this sort of
the nodes on our
this sort of communication
nodes on our cluster
recovering the data packet
on our cluster only
the data packet is
the dangers of replication
data packet is then
our cluster only have
dangers of replication and
since the results of
of replication and a
the results of running
replication and a solution
results of running the
of running the other
running the other tests
the other tests are
other tests are similar
we omit them for
omit them for brevity
is the number of
the number of xors
number of xors generated
of xors generated at
xors generated at interleaves
generated at interleaves greater
at interleaves greater than
interleaves greater than b
mostly reads mostly writes
reads mostly writes heavy
mostly writes heavy load
the formulae derived for
writes heavy load store
formulae derived for xor
heavy load store overhead
derived for xor usability
load store overhead priorities
for xor usability still
store overhead priorities uniform
xor usability still hold
overhead priorities uniform priorities
priorities uniform priorities uniform
acm sigmod international conference
uniform priorities uniform synchronous
sigmod international conference on
priorities uniform synchronous asynchronous
international conference on management
uniform synchronous asynchronous time
conference on management of
synchronous asynchronous time spent
on management of data
asynchronous time spent on
since packet losses with
time spent on rpcs
packet losses with more
losses with more than
with more than b
more than b intervening
memory footprint is significant
than b intervening packets
b intervening packets between
intervening packets between them
packets between them have
between them have independent
them have independent probability
there is only correlation
is only correlation within
only correlation within the
correlation within the bursts
how does this compare
does this compare to
the peak footprint approaches
this compare to traditional
codes such as reed
and the system is
the system is close
system is close to
is close to swapping
c repair packets are
repair packets are generated
packets are generated and
are generated and sent
generated and sent for
and sent for every
sent for every r
for every r data
every r data packets
groups are enough to
and the correct delivery
are enough to trigger
the correct delivery of
enough to trigger signs
correct delivery of any
to trigger signs of
delivery of any r
trigger signs of instability
of any r of
any r of the
r of the r
token roundtrip times start
roundtrip times start to
times start to grow
c packets transmitted is
packets transmitted is sufficient
transmitted is sufficient to
is sufficient to reconstruct
thus delaying message cleanup
sufficient to reconstruct the
to reconstruct the original
reconstruct the original r
the original r data
original r data packets
given a lost data
a lost data packet
and increasing memory overhead
we can recover it
can recover it if
recover it if at
it if at least
if at least r
at least r packets
least r packets are
r packets are received
packets are received correctly
are received correctly in
received correctly in the
correctly in the encoding
in the encoding set
the encoding set of
encoding set of r
although the process is
the process is fairly
process is fairly unpredictable
c data and repair
data and repair packets
and repair packets that
repair packets that the
we see spikes and
packets that the lost
see spikes and anomalies
that the lost packet
the lost packet belongs
lost packet belongs to
we can easily recognize
can easily recognize a
easily recognize a super
the probability of recovering
probability of recovering a
of recovering a lost
linear trend starting at
recovering a lost packet
trend starting at around
a lost packet is
lost packet is equivalent
packet is equivalent to
is equivalent to the
equivalent to the probability
to the probability of
the probability of losing
probability of losing c
or less packets from
less packets from the
packets from the total
from the total r
at around this point
since the number of
we also start to
the number of other
also start to see
number of other lost
start to see occasional
of other lost packets
to see occasional bursts
other lost packets in
see occasional bursts of
lost packets in the
occasional bursts of packet
packets in the xor
bursts of packet losses
in the xor is
the xor is a
xor is a random
is a random variable
a random variable y
random variable y and
variable y and has
y and has a
and has a binomial
has a binomial distribution
a binomial distribution with
binomial distribution with parameters
often roughly correlated across
roughly correlated across receivers
such events trigger bursty
events trigger bursty recovery
trigger bursty recovery overloads
number of messages pending
of messages pending ack
messages pending ack and
is the summation p
pending ack and token
the summation p z
ack and token roundtrip
summation p z c
and token roundtrip time
token roundtrip time as
roundtrip time as a
secure untrusted data repository
time as a function
as a function of
a function of the
function of the number
of the number of
the number of groups
memory usage grows with
usage grows with the
grows with the number
with the number of
the number of groups
th conference on symposium
we plot the recovery
conference on symposium on
beyond a certain threshold
on symposium on opearting
plot the recovery probability
symposium on opearting systems
the recovery probability curves
on opearting systems design
recovery probability curves for
probability curves for layered
the system is increasingly
curves for layered interleaving
system is increasingly unstable
for layered interleaving and
layered interleaving and reed
solomon against uniformly random
against uniformly random loss
uniformly random loss rate
time spent in the
spent in the clr
in the clr code
throughput decreases with the
decreases with the number
with the number of
the number of groups
note that the curves
that the curves are
the curves are very
curves are very close
are very close to
very close to each
close to each other
especially in the loss
in the loss range
the loss range of
loss range of interest
range of interest between
all groups have the
groups have the same
have the same subscribers
local recovery for receiver
recovery for receiver loss
for receiver loss in
receiver loss in the
loss in the absence
in the absence of
the absence of intelligent
absence of intelligent flow
of intelligent flow control
intelligent flow control mechanisms
flow control mechanisms like
control mechanisms like tcp
the key insight is
key insight is that
insight is that all
is that all these
that all these effects
all these effects originate
these effects originate at
effects originate at the
originate at the sender
at the sender node
communal data sharing in
data sharing in public
sharing in public clouds
inexpensive data center end
which is more loaded
is more loaded and
more loaded and less
loaded and less responsive
hosts can be easily
can be easily overwhelmed
be easily overwhelmed and
easily overwhelmed and drop
overwhelmed and drop packets
and drop packets during
drop packets during traffic
packets during traffic spikes
detailed analysis of the
during traffic spikes or
analysis of the captured
traffic spikes or cpu
of the captured network
the captured network traffic
captured network traffic shows
network traffic shows that
intensive maintenance tasks like
traffic shows that the
maintenance tasks like garbage
shows that the multicast
tasks like garbage collection
that the multicast stream
the multicast stream in
multicast stream in all
stream in all cases
in all cases looks
all cases looks basically
cases looks basically identical
level protocols layered over
protocols layered over udp
layered over udp for
and hence we cannot
over udp for reliable
hence we cannot attribute
udp for reliable multicast
we cannot attribute token
cannot attribute token latency
attribute token latency or
token latency or losses
latency or losses to
or losses to the
losses to the increased
to the increased volume
the increased volume of
increased volume of traffic
throughput spikes or longer
spikes or longer bursts
or high speed data
or longer bursts of
high speed data transfer
longer bursts of data
the sender spends more
sender spends more time
spends more time transmitting
more time transmitting at
time transmitting at lower
transmitting at lower rates
but doesn t produce
doesn t produce any
for example would ordinarily
t produce any faster
example would ordinarily go
produce any faster data
would ordinarily go back
any faster data bursts
ordinarily go back to
faster data bursts than
go back to the
data bursts than those
back to the sender
bursts than those we
to the sender to
than those we observe
the sender to retrieve
those we observe with
sender to retrieve the
we observe with smaller
to retrieve the lost
observe with smaller numbers
retrieve the lost packet
with smaller numbers of
smaller numbers of groups
even though it was
though it was dropped
it was dropped at
was dropped at the
dropped at the receiver
at the receiver after
the receiver after covering
receiver after covering the
after covering the entire
covering the entire geographical
the entire geographical distance
the maelstrom proxy acts
maelstrom proxy acts as
receiver performance indicators such
proxy acts as a
performance indicators such as
acts as a local
indicators such as delays
as a local packet
such as delays in
a local packet cache
as delays in firing
delays in firing timer
in firing timer event
firing timer event or
timer event or cpu
event or cpu utilization
storing incoming packets for
or cpu utilization don
cpu utilization don t
incoming packets for a
utilization don t show
don t show any
packets for a short
t show any noticeable
show any noticeable trend
for a short period
a short period of
short period of time
period of time and
of time and providing
time and providing hooks
all roads lead back
roads lead back to
and providing hooks that
lead back to the
back to the sender
providing hooks that allow
hooks that allow protocols
that allow protocols to
and the main thing
allow protocols to first
the main thing going
protocols to first query
main thing going on
to first query the
thing going on in
first query the cache
going on in the
query the cache to
on in the sender
the cache to locate
in the sender is
cache to locate missing
the sender is that
to locate missing packets
sender is that it
locate missing packets before
is that it has
missing packets before sending
that it has a
packets before sending retransmission
it has a steadily
before sending retransmission requests
has a steadily growing
sending retransmission requests back
a steadily growing memory
retransmission requests back to
steadily growing memory footprint
requests back to the
back to the sender
we also looked at
also looked at token
looked at token round
future versions of maelstrom
versions of maelstrom could
of maelstrom could potentially
maelstrom could potentially use
could potentially use knowledge
potentially use knowledge of
use knowledge of protocol
knowledge of protocol internals
of protocol internals to
the distribution of token
protocol internals to transparently
distribution of token roundtrip
internals to transparently intervene
of token roundtrip times
token roundtrip times for
roundtrip times for different
times for different numbers
for different numbers of
different numbers of groups
numbers of groups shows
of groups shows an
by intercepting and satisfying
groups shows an increase
intercepting and satisfying retransmission
shows an increase of
and satisfying retransmission requests
an increase of the
satisfying retransmission requests sent
increase of the token
retransmission requests sent by
of the token roundtrip
requests sent by the
the token roundtrip time
sent by the receiver
by the receiver in
the receiver in a
receiver in a nak
caused almost entirely by
or by resending packets
by resending packets when
resending packets when acknowledgments
packets when acknowledgments are
when acknowledgments are not
of the tokens that
acknowledgments are not observed
the tokens that are
are not observed within
tokens that are delayed
not observed within a
that are delayed the
observed within a certain
are delayed the most
within a certain time
a certain time period
certain time period in
time period in an
period in an ack
implementation details we initially
details we initially implemented
we initially implemented and
which points to disruptive
initially implemented and evaluated
points to disruptive events
implemented and evaluated maelstrom
to disruptive events as
and evaluated maelstrom as
disruptive events as the
evaluated maelstrom as a
events as the culprit
maelstrom as a user
rather than a uniform
than a uniform increase
a uniform increase of
uniform increase of the
increase of the token
performance turned out to
of the token processing
turned out to be
the token processing overhead
out to be limited
to be limited by
be limited by copying
limited by copying and
by copying and context
we find that these
and we subsequently reimplemented
find that these tokens
we subsequently reimplemented the
that these tokens were
subsequently reimplemented the system
these tokens were most
reimplemented the system as
tokens were most commonly
the system as a
were most commonly delayed
system as a module
most commonly delayed on
as a module that
commonly delayed on the
a module that runs
delayed on the sender
module that runs within
that runs within the
runs within the linux
with many thousands of
many thousands of groups
the average time to
average time to travel
time to travel by
to travel by one
travel by one hop
by one hop from
one hop from sender
hop from sender to
from sender to receiver
sender to receiver or
to receiver or receiver
receiver or receiver to
or receiver to sender
receiver to sender can
to sender can grow
sender can grow to
can grow to nearly
at an encoding rate
an encoding rate of
as compared to an
compared to an average
the experimental prototype of
experimental prototype of the
the miner s dilemma
ms per hop from
prototype of the kernel
per hop from receiver
miner s dilemma ittay
hop from receiver to
of the kernel version
from receiver to receiver
the kernel version reaches
s dilemma ittay eyal
kernel version reaches output
version reaches output speeds
dilemma ittay eyal cornell
reaches output speeds close
output speeds close to
ittay eyal cornell university
eyal cornell university abstract
cornell university abstract an
gigabit per second of
university abstract an open
per second of combined
second of combined data
abstract an open distributed
of combined data and
combined data and fec
an open distributed system
data and fec traffic
the overloaded sender occasionally
open distributed system can
overloaded sender occasionally releases
distributed system can be
sender occasionally releases the
system can be secured
occasionally releases the tokens
limited only by the
releases the tokens with
can be secured by
the tokens with a
only by the capacity
be secured by requiring
by the capacity of
tokens with a delay
the capacity of the
secured by requiring participants
capacity of the outbound
by requiring participants to
of the outbound network
requiring participants to present
the outbound network card
participants to present proof
to present proof of
present proof of work
proof of work and
of work and rewarding
work and rewarding them
and rewarding them for
rewarding them for participation
lambda networks are already
networks are already reaching
are already reaching speeds
already reaching speeds of
the bitcoin digital currency
bitcoin digital currency introduced
digital currency introduced this
currency introduced this mechanism
the value of the
value of the delay
of the delay grows
which is adopted by
the delay grows with
is adopted by almost
delay grows with the
adopted by almost all
grows with the number
by almost all contemporary
with the number of
almost all contemporary digital
the number of groups
all contemporary digital currencies
contemporary digital currencies and
digital currencies and related
currencies and related services
and higher speeds are
a natural process leads
higher speeds are a
natural process leads participants
speeds are a certainty
process leads participants of
are a certainty down
leads participants of such
a certainty down the
participants of such systems
certainty down the road
of such systems to
such systems to form
systems to form pools
our old culprit is
old culprit is back
where members aggregate their
members aggregate their power
aggregate their power and
their power and share
power and share the
and share the rewards
we envision maelstrom as
related costs at the
envision maelstrom as a
costs at the sender
maelstrom as a small
as a small rack
experience with bitcoin shows
with bitcoin shows that
bitcoin shows that the
shows that the largest
style cluster of servers
that the largest pools
the largest pools are
largest pools are often
increasing the number of
pools are often open
the number of groups
each acting as an
number of groups slows
acting as an individual
of groups slows the
as an individual proxy
groups slows the sender
allowing anyone to join
and this cascades to
traffic would be distributed
this cascades to create
it has long been
would be distributed over
has long been known
cascades to create all
be distributed over such
to create all sorts
long been known that
distributed over such a
create all sorts of
been known that a
over such a rack
all sorts of downstream
known that a member
sorts of downstream problems
such a rack by
of downstream problems that
that a member can
a rack by partitioning
downstream problems that can
a member can sabotage
problems that can destabilize
rack by partitioning the
that can destabilize the
member can sabotage an
by partitioning the address
can destabilize the system
can sabotage an open
destabilize the system as
partitioning the address space
the system as a
sabotage an open pool
the address space of
system as a whole
an open pool by
address space of the
open pool by seemingly
space of the remote
pool by seemingly joining
of the remote data
by seemingly joining it
the remote data center
seemingly joining it but
remote data center and
joining it but never
discussion the experiments just
it but never sharing
data center and routing
but never sharing its
the experiments just reported
never sharing its proofs
center and routing different
sharing its proofs of
experiments just reported make
its proofs of work
and routing different segments
just reported make it
routing different segments of
reported make it clear
different segments of the
make it clear that
segments of the space
it clear that the
the pool shares its
clear that the performance
of the space through
pool shares its revenue
the space through distinct
shares its revenue with
space through distinct maelstrom
its revenue with the
through distinct maelstrom appliance
revenue with the attacker
distinct maelstrom appliance pairs
limiting factor in the
factor in the qsm
in the qsm system
the qsm system is
qsm system is latency
and so each of
so each of its
each of its participants
of its participants earns
its participants earns less
and that in addition
we plan to experiment
that in addition to
plan to experiment with
in addition to protocol
to experiment with such
addition to protocol factors
we define and analyze
to protocol factors such
experiment with such configurations
protocol factors such as
define and analyze a
factors such as the
such as the length
and analyze a game
as the length of
analyze a game where
which would also permit
the length of token
would also permit us
length of token rings
also permit us to
a game where pools
permit us to explore
game where pools use
us to explore fault
where pools use some
latency is strongly influenced
pools use some of
is strongly influenced by
use some of their
strongly influenced by the
some of their participants
influenced by the memory
of their participants to
by the memory footprint
their participants to infiltrate
the memory footprint of
if a maelstrom blade
memory footprint of the
a maelstrom blade fails
footprint of the system
participants to infiltrate other
to infiltrate other pools
infiltrate other pools and
other pools and perform
pools and perform such
and perform such an
perform such an attack
when we built the
we built the system
with any number of
built the system it
any number of pools
and to support load
the system it was
system it was obvious
it was obvious that
was obvious that minimizing
obvious that minimizing latency
that minimizing latency would
balancing schemes that might
minimizing latency would be
schemes that might vary
latency would be important
that might vary the
might vary the ip
vary the ip address
attacks is not a
this motivated several of
the ip address space
motivated several of the
is not a nash
several of the design
not a nash equilibrium
of the design decisions
ip address space partitioning
the design decisions discussed
address space partitioning dynamically
design decisions discussed in
space partitioning dynamically to
decisions discussed in section
partitioning dynamically to spread
we study the special
dynamically to spread the
study the special cases
to spread the encoding
the special cases where
spread the encoding load
special cases where either
the encoding load over
cases where either two
encoding load over multiple
but the repeated linkage
where either two pools
load over multiple machines
the repeated linkage of
either two pools or
repeated linkage of latency
two pools or any
linkage of latency and
pools or any number
of latency and oscillatory
or any number of
latency and oscillatory throughputs
any number of identical
and oscillatory throughputs to
number of identical pools
oscillatory throughputs to memory
of identical pools play
throughputs to memory was
identical pools play the
to memory was a
pools play the game
memory was a surprise
play the game and
we present the implementation
the game and the
present the implementation and
game and the rest
the implementation and performance
and the rest of
implementation and performance of
the rest of the
and performance of a
rest of the participants
performance of a single
of the participants are
we expected a much
the participants are uninvolved
expected a much smaller
a much smaller impact
we can summarize our
in both of these
can summarize our design
the kernel implementation is
summarize our design insights
kernel implementation is a
our design insights as
implementation is a module
design insights as follows
is a module for
both of these cases
a module for linux
of these cases there
these cases there exists
cases there exists an
there exists an equilibrium
exists an equilibrium that
an equilibrium that constitutes
minimize the memory footprint
equilibrium that constitutes a
that constitutes a tragedy
constitutes a tragedy of
a tragedy of the
we expected that the
tragedy of the commons
expected that the primary
of the commons where
that the primary cost
the commons where the
the primary cost of
commons where the participating
primary cost of managed
where the participating pools
with hooks into the
the participating pools attack
cost of managed memory
participating pools attack one
of managed memory would
hooks into the kernel
managed memory would be
into the kernel packet
memory would be associated
the kernel packet filter
would be associated with
pools attack one another
be associated with garbage
attack one another and
associated with garbage collection
one another and earn
another and earn less
and earn less than
earn less than they
less than they would
than they would have
they would have if
would have if none
have if none had
if none had attacked
all costs associated with
costs associated with managed
associated with managed memory
with managed memory rise
managed memory rise in
memory rise in the
rise in the amount
in the amount of
maelstrom proxies work in
the amount of allocated
proxies work in pairs
amount of allocated memory
the decision whether or
mostly reads mostly writes
decision whether or not
reads mostly writes heavy
whether or not to
one on each side
or not to attack
on each side of
not to attack is
each side of the
to attack is the
mostly writes heavy load
attack is the miner
side of the long
at least in the
writes heavy load store
is the miner s
heavy load store overhead
the miner s dilemma
least in the windows
load store overhead priorities
in the windows clr
store overhead priorities uniform
of the long haul
overhead priorities uniform priorities
the long haul link
priorities uniform priorities uniform
an instance of the
uniform priorities uniform synchronous
instance of the iterative
priorities uniform synchronous asynchronous
of the iterative prisoner
uniform synchronous asynchronous figure
the iterative prisoner s
each proxy acts both
iterative prisoner s dilemma
proxy acts both as
acts both as an
both as an ingress
as an ingress and
the game is played
an ingress and egress
game is played daily
ingress and egress router
is played daily by
graphs of ntfs traces
and egress router at
played daily by the
egress router at the
daily by the active
router at the same
by the active bitcoin
at the same time
the active bitcoin pools
the same time since
whereas traditional multicast systems
same time since they
each trace ran with
time since they handle
traditional multicast systems accept
since they handle duplex
trace ran with synchronous
they handle duplex traffic
multicast systems accept messages
handle duplex traffic in
ran with synchronous or
which apparently choose not
systems accept messages whenever
duplex traffic in the
accept messages whenever the
traffic in the following
with synchronous or asynchronous
apparently choose not to
messages whenever the application
in the following manner
whenever the application layer
choose not to attack
the application layer or
synchronous or asynchronous writes
application layer or the
or asynchronous writes and
layer or the multicast
asynchronous writes and uniform
the egress router captures
writes and uniform or
if this balance breaks
egress router captures ip
or the multicast protocols
and uniform or differentiated
router captures ip packets
uniform or differentiated priorities
captures ip packets and
the multicast protocols produce
ip packets and creates
multicast protocols produce it
the revenue of open
packets and creates redundant
revenue of open pools
and creates redundant fec
the total height of
creates redundant fec packets
qsm uses an upcall
total height of each
of open pools might
height of each bar
open pools might diminish
of each bar denotes
each bar denotes the
the original ip packets
bar denotes the time
original ip packets are
denotes the time from
making them unattractive to
the time from the
them unattractive to participants
time from the first
often we can delay
from the first to
ip packets are routed
we can delay generating
packets are routed through
can delay generating a
are routed through unaltered
delay generating a message
the first to last
generating a message until
first to last write
a message until the
routed through unaltered as
message until the last
through unaltered as they
until the last minute
unaltered as they would
as they would have
and the shaded portion
they would have been
the shaded portion denotes
would have been originally
shaded portion denotes the
and we can also
portion denotes the time
we can also avoid
denotes the time from
can also avoid situations
the time from the
also avoid situations in
is a digital currency
avoid situations in which
time from the first
situations in which data
from the first to
in which data piles
a digital currency that
which data piles up
digital currency that is
data piles up on
currency that is gaining
piles up on behalf
that is gaining acceptance
up on behalf of
the first to last
the redundant packets are
on behalf of an
redundant packets are then
first to last read
packets are then forwarded
behalf of an aggressive
are then forwarded to
of an aggressive sender
then forwarded to the
forwarded to the remote
the white portions denote
to the remote ingress
white portions denote the
the remote ingress router
portions denote the extra
remote ingress router via
denote the extra time
ingress router via a
the extra time required
router via a udp
extra time required to
via a udp channel
time required to complete
required to complete all
to complete all writes
complete all writes after
all writes after the
limit buffering and caching
writes after the last
the ingress router captures
after the last read
ingress router captures and
the last read has
router captures and stores
last read has finished
most existing multicast protocols
with an estimated market
captures and stores ip
an estimated market capitalization
existing multicast protocols buffer
and stores ip packets
estimated market capitalization of
multicast protocols buffer data
stores ip packets coming
protocols buffer data at
for asynchronous writeback with
ip packets coming from
asynchronous writeback with priorities
buffer data at many
writeback with priorities in
market capitalization of over
data at many layers
with priorities in the
at many layers and
packets coming from the
many layers and cache
coming from the direction
layers and cache data
from the direction of
and cache data rather
the direction of the
cache data rather casually
direction of the egress
data rather casually for
of the egress router
rather casually for recovery
casually for recovery purposes
upon receipt of a
receipt of a redundant
this turns out to
of a redundant packet
turns out to be
out to be extremely
this shows that the
to be extremely costly
shows that the total
be extremely costly in
that the total duration
extremely costly in a
an ip packet is
costly in a managed
the total duration of
in a managed setting
ip packet is recovered
a managed setting and
total duration of the
managed setting and must
duration of the trace
setting and must be
packet is recovered if
and must be avoided
of the trace with
must be avoided whenever
is recovered if there
be avoided whenever possible
the trace with this
recovered if there is
trace with this mfs
if there is an
with this mfs configuration
there is an opportunity
this mfs configuration is
is an opportunity to
an opportunity to do
opportunity to do so
redundant packets that can
packets that can be
that can be used
can be used at
be used at a
used at a later
cumulative distribution of the
at a later time
distribution of the multicast
a later time are
of the multicast rates
bitcoin s security stems
the multicast rates for
later time are stored
s security stems from
security stems from a
stems from a robust
but all the fetch
from a robust incentive
all the fetch traffic
a robust incentive system
the fetch traffic is
if the redundant packet
fetch traffic is completed
the redundant packet is
traffic is completed within
redundant packet is useless
packet is useless it
participants are required to
is useless it is
are required to provide
useless it is immediately
required to provide expensive
it is immediately discarded
to provide expensive proofs
provide expensive proofs of
expensive proofs of work
upon recovery the ip
recovery the ip packet
and they are rewarded
the ip packet is
they are rewarded according
ip packet is sent
seconds of the start
are rewarded according to
token roundtrip times for
packet is sent through
rewarded according to their
is sent through a
according to their efforts
this is a significant
sent through a raw
is a significant improvement
through a raw socket
a significant improvement over
a raw socket to
significant improvement over the
raw socket to its
this architecture has proved
socket to its intended
architecture has proved both
to its intended destination
has proved both stable
improvement over the alternative
proved both stable and
over the alternative configurations
both stable and scalable
the alternative configurations measured
using fec requires that
fec requires that each
and it is used
it is used by
requires that each data
is used by most
used by most contemporary
that each data packet
by most contemporary digital
most contemporary digital currencies
each data packet have
contemporary digital currencies and
digital currencies and related
data packet have a
currencies and related services
packet have a unique
have a unique identifier
seconds of the trace
intervals between the subsequent
of the trace are
between the subsequent tokens
the trace are taken
a unique identifier that
trace are taken up
are taken up by
unique identifier that the
taken up by asynchronously
identifier that the receiver
up by asynchronously writing
that the receiver can
by asynchronously writing back
the receiver can use
asynchronously writing back file
receiver can use to
writing back file updates
can use to keep
use to keep track
to keep track of
keep track of received
track of received data
in all cases the
of received data packets
all cases the traces
received data packets and
cases the traces take
data packets and to
the traces take significantly
packets and to identify
traces take significantly longer
and to identify missing
take significantly longer than
to identify missing data
significantly longer than they
identify missing data packets
longer than they originally
missing data packets in
than they originally did
data packets in a
they originally did in
packets in a repair
originally did in ntfs
in a repair packet
where they were mostly
if we had access
they were mostly accessing
we had access to
were mostly accessing the
had access to end
clear messages out of
mostly accessing the local
messages out of the
accessing the local file
out of the system
the local file system
of the system quickly
local file system and
file system and therefore
we could have added
system and therefore had
could have added a
and therefore had no
have added a header
therefore had no bandwidth
data paths should have
added a header to
paths should have rapid
had no bandwidth constraints
should have rapid data
a header to each
have rapid data movement
header to each packet
rapid data movement as
to each packet with
data movement as a
each packet with a
movement as a key
packet with a unique
as a key goal
with a unique sequence
the results largely repeat
a unique sequence number
results largely repeat those
largely repeat those seen
repeat those seen in
those seen in the
seen in the microbenchmarks
to the extent that
the extent that the
extent that the greatest
that the greatest performance
the greatest performance improvements
we ve already mentioned
greatest performance improvements are
ve already mentioned that
performance improvements are seen
already mentioned that data
improvements are seen at
mentioned that data paths
are seen at low
that data paths should
seen at low bandwidth
data paths should clear
at low bandwidth when
paths should clear messages
low bandwidth when there
should clear messages quickly
bandwidth when there is
our results apply to
we intercept traffic transparently
results apply to all
when there is high
apply to all such
there is high read
to all such incentive
intercept traffic transparently and
all such incentive systems
but there are other
traffic transparently and need
there are other important
transparently and need to
are other important forms
other important forms of
important forms of delay
but we use bitcoin
we use bitcoin terminology
such as in the
route it without modification
use bitcoin terminology and
it without modification or
as in the mostly
without modification or addition
bitcoin terminology and examples
terminology and examples since
and examples since it
most situations in which
examples since it serves
situations in which qsm
since it serves as
in which qsm developed
writes trace where there
which qsm developed convoy
trace where there is
it serves as an
where there is an
serves as an active
as an active and
an active and archetypal
active and archetypal example
we identify ip packets
like behavior or oscillatory
identify ip packets by
behavior or oscillatory throughput
ip packets by a
or oscillatory throughput can
packets by a tuple
bitcoin implements its incentive
oscillatory throughput can be
by a tuple consisting
decrease in the time
a tuple consisting of
in the time spent
implements its incentive systems
tuple consisting of the
the time spent to
consisting of the source
time spent to read
of the source and
spent to read all
the source and destination
to read all the
source and destination ip
its incentive systems with
throughput can be traced
incentive systems with a
and destination ip address
read all the files
can be traced to
systems with a data
be traced to design
with a data structure
traced to design decisions
a data structure called
to design decisions that
data structure called the
design decisions that caused
structure called the blockchain
decisions that caused scheduling
even at the higher
that caused scheduling jitter
at the higher bandwidth
size of the ip
caused scheduling jitter or
of the ip header
the higher bandwidth of
the blockchain is a
the ip header plus
scheduling jitter or allowed
blockchain is a serialization
jitter or allowed some
is a serialization of
or allowed some form
a serialization of all
allowed some form of
serialization of all bitcoin
some form of priority
of all bitcoin transactions
form of priority inversion
ip header plus data
of priority inversion to
priority inversion to occur
it is a single
and a checksum over
is a single global
a checksum over the
a single global ledger
checksum over the ip
delaying a crucial message
single global ledger maintained
a crucial message behind
over the ip data
there is a decrease
the ip data payload
is a decrease of
crucial message behind a
global ledger maintained by
message behind a less
ledger maintained by an
behind a less important
maintained by an open
a less important one
by an open distributed
the checksum over the
an open distributed system
checksum over the payload
over the payload is
the payload is necessary
implications included the following
payload is necessary since
is necessary since the
since anyone can join
necessary since the ip
anyone can join the
since the ip identification
can join the open
the ip identification field
join the open system
ip identification field is
the open system and
the mostlyreads trace is
open system and participate
mostlyreads trace is not
system and participate in
trace is not much
and participate in maintaining
is not much affected
participate in maintaining the
not much affected by
in maintaining the blockchain
much affected by changes
identification field is only
affected by changes in
event handlers should be
by changes in the
handlers should be short
changes in the configuration
bitcoin uses a proof
uses a proof of
a proof of work
proof of work mechanism
although there is a
of work mechanism to
there is a slight
work mechanism to deter
bits long and a
is a slight decrease
mechanism to deter attacks
a slight decrease in
long and a single
slight decrease in both
and a single pair
decrease in both read
a single pair of
we struggled to make
participation requires exerting significant
single pair of end
requires exerting significant compute
struggled to make the
exerting significant compute resources
in both read and
to make the overall
both read and write
read and write times
make the overall behavior
and write times for
hosts communicating at high
the overall behavior of
a participant that proves
write times for prioritised
overall behavior of the
participant that proves she
times for prioritised asynchronous
communicating at high speeds
for prioritised asynchronous writeback
that proves she has
at high speeds will
behavior of the system
proves she has exerted
high speeds will use
of the system as
she has exerted enough
speeds will use the
the system as predictable
has exerted enough resources
will use the same
system as predictable as
exerted enough resources with
use the same identifier
as predictable as possible
enough resources with a
the same identifier for
predictable as possible not
resources with a proof
same identifier for different
as possible not a
with a proof of
identifier for different data
a proof of work
possible not a trivial
for different data packets
proof of work is
not a trivial task
different data packets within
of work is allowed
a trivial task in
data packets within a
work is allowed to
trivial task in configurations
packets within a fairly
is allowed to take
task in configurations where
allowed to take a
within a fairly short
to take a step
in configurations where hundreds
take a step in
a fairly short interval
a step in the
configurations where hundreds of
load trace performs best
where hundreds of processes
trace performs best with
hundreds of processes might
performs best with uniform
of processes might be
best with uniform asynchronous
processes might be multicasting
with uniform asynchronous writeback
fairly short interval unless
step in the protocol
short interval unless the
in the protocol by
interval unless the checksum
the protocol by generating
unless the checksum is
protocol by generating a
we once again attribute
might be multicasting in
once again attribute this
be multicasting in thousands
again attribute this to
multicasting in thousands of
attribute this to inefficiency
in thousands of overlapping
this to inefficiency in
by generating a block
to inefficiency in the
thousands of overlapping groups
the checksum is added
inefficiency in the rpc
checksum is added to
in the rpc protocol
is added to differentiate
added to differentiate between
participants are compensated for
to differentiate between them
by keeping event handlers
are compensated for their
keeping event handlers short
compensated for their efforts
event handlers short and
for their efforts with
handlers short and predictable
since under extremely heavy
short and predictable and
their efforts with newly
and predictable and eliminating
efforts with newly minted
predictable and eliminating the
with newly minted bitcoins
and eliminating the need
unique identifiers result in
under extremely heavy load
identifiers result in garbled
eliminating the need for
result in garbled recovery
the need for locking
in garbled recovery by
extremely heavy load and
garbled recovery by maelstrom
the process of creating
heavy load and high
process of creating a
load and high bandwidth
we obtained a more
and high bandwidth it
an event which will
obtained a more predictable
of creating a block
a more predictable system
creating a block is
more predictable system and
event which will be
predictable system and were
a block is called
system and were able
block is called mining
and were able to
which will be caught
high bandwidth it performs
were able to eliminate
bandwidth it performs better
able to eliminate multithreading
it performs better when
and the participants miners
will be caught by
performs better when all
be caught by higher
better when all messages
with the associated context
caught by higher level
the associated context switching
in order to win
associated context switching and
order to win the
context switching and locking
to win the reward
switching and locking overheads
by higher level checksums
when all messages have
all messages have the
higher level checksums designed
messages have the same
many miners try to
have the same priority
miners try to generate
level checksums designed to
try to generate blocks
checksums designed to deal
designed to deal with
to deal with tranmission
the system automatically adjusts
deal with tranmission errors
system automatically adjusts the
with tranmission errors on
automatically adjusts the difficulty
a file group is
adjusts the difficulty of
tranmission errors on commodity
the difficulty of block
file group is implemented
errors on commodity networks
group is implemented as
here we encounter a
on commodity networks and
is implemented as a
difficulty of block generation
we encounter a tension
commodity networks and hence
encounter a tension between
implemented as a special
networks and hence does
as a special type
a tension between two
a special type of
tension between two goals
special type of file
such that one block
type of file within
that one block is
of file within the
one block is added
file within the mfs
block is added every
within the mfs file
and hence does not
from a memory footprint
hence does not have
a memory footprint perspective
does not have significant
the mfs file system
not have significant consequences
have significant consequences unless
significant consequences unless it
consequences unless it occurs
one might prefer not
unless it occurs frequently
with its own file
might prefer not to
minutes to the blockchain
prefer not to pull
its own file identifier
not to pull in
to pull in a
the kernel version of
pull in a message
kernel version of maelstrom
this means that each
version of maelstrom can
means that each miner
in a message until
that each miner seldom
of maelstrom can generate
each miner seldom generates
a message until qsm
but not attached to
message until qsm can
maelstrom can generate up
until qsm can process
not attached to any
miner seldom generates a
can generate up to
qsm can process it
generate up to a
seldom generates a block
up to a gigabit
attached to any specific
to a gigabit per
to any specific directory
a gigabit per second
but in a datacenter
gigabit per second of
in a datacenter or
although its revenue may
per second of data
a datacenter or cluster
second of data and
the file group a
its revenue may be
of data and fec
revenue may be positive
data and fec traffic
may be positive in
most message loss occurs
be positive in expectation
message loss occurs in
file group a file
loss occurs in the
group a file belongs
occurs in the operating
a file belongs to
in the operating system
with the input data
the input data rate
a miner may have
input data rate depending
miner may have to
data rate depending on
may have to wait
rate depending on the
not on the network
have to wait for
is one of its
to wait for an
depending on the encoding
wait for an extended
on the encoding rate
one of its attributes
hence message loss rates
for an extended period
message loss rates soar
an extended period to
loss rates soar if
extended period to create
rates soar if we
period to create a
the mfs prefetching subsystem
to create a block
soar if we leave
create a block and
mfs prefetching subsystem derives
a block and earn
we were able to
if we leave messages
were able to saturate
we leave messages on
able to saturate the
leave messages on input
prefetching subsystem derives much
block and earn the
subsystem derives much of
and earn the actual
derives much of its
messages on input sockets
much of its effectiveness
on input sockets for
of its effectiveness from
input sockets for long
to saturate the outgoing
earn the actual bitcoins
saturate the outgoing card
its effectiveness from being
the outgoing card at
effectiveness from being combined
outgoing card at rates
from being combined with
card at rates as
being combined with prioritised
at rates as high
combined with prioritised rpcs
rates as high as
miners form mining pools
while the prefetching algorithm
the prefetching algorithm in
control the event processing
where all members mine
the event processing order
prefetching algorithm in mfs
all members mine concurrently
algorithm in mfs is
members mine concurrently and
in mfs is straightforward
mine concurrently and they
concurrently and they share
and they share their
they share their revenue
share their revenue whenever
it can still make
their revenue whenever one
can still make bad
revenue whenever one of
still make bad decisions
whenever one of them
with cpu overload occurring
make bad decisions without
cpu overload occurring at
one of them creates
bad decisions without a
of them creates a
them creates a block
decisions without a large
without a large overall
a large overall performance
and the imposition of
large overall performance penalty
the imposition of an
pools are typically implemented
overall performance penalty because
are typically implemented as
performance penalty because the
typically implemented as a
imposition of an internal
implemented as a pool
penalty because the interference
as a pool manager
of an internal event
a pool manager and
because the interference of
pool manager and a
an internal event processing
manager and a cohort
the interference of prefetching
internal event processing prioritization
where each incoming data
interference of prefetching with
each incoming data packet
of prefetching with other
incoming data packet had
and a cohort of
data packet had to
a cohort of miners
packet had to be
small delays add up
prefetching with other file
delays add up in
had to be xored
add up in large
with other file system
up in large systems
other file system activity
the pool manager joins
file system activity is
pool manager joins the
system activity is minimised
manager joins the bitcoin
joins the bitcoin system
tight control over event
the bitcoin system as
control over event processing
bitcoin system as a
over event processing largely
in the same way
system as a single
event processing largely eliminated
as a single miner
buffering requirements at the
the same way that
processing largely eliminated convoy
requirements at the receive
largely eliminated convoy effects
same way that some
eliminated convoy effects and
instead of generating proof
convoy effects and oscillatory
of generating proof of
effects and oscillatory throughput
generating proof of work
and oscillatory throughput problems
way that some local
that some local file
some local file systems
incoming data packets are
local file systems execute
it outsources the work
file systems execute speculative
outsources the work to
data packets are buffered
the work to the
systems execute speculative operations
work to the miners
execute speculative operations to
packets are buffered so
speculative operations to improve
are buffered so that
operations to improve performance
buffered so that they
in order to evaluate
so that they can
order to evaluate the
act on fresh state
to evaluate the miners
that they can be
evaluate the miners efforts
they can be used
can be used in
be used in conjunction
used in conjunction with
many inefficiencies can be
in conjunction with xors
inefficiencies can be traced
conjunction with xors to
can be traced to
the pool manager accepts
be traced to situations
with xors to recover
pool manager accepts partial
traced to situations in
mfs makes use of
xors to recover missing
to situations in which
makes use of the
to recover missing data
manager accepts partial proof
situations in which one
use of the speculative
recover missing data packets
accepts partial proof of
in which one node
of the speculative communication
which one node takes
partial proof of work
one node takes action
the speculative communication of
node takes action on
proof of work and
takes action on the
speculative communication of prioritised
action on the basis
of work and estimates
on the basis of
communication of prioritised rpcs
the basis of stale
work and estimates each
basis of stale state
of prioritised rpcs in
and estimates each miner
of stale state information
estimates each miner s
stale state information from
any received xor that
prioritised rpcs in the
received xor that is
state information from some
xor that is missing
information from some other
each miner s power
rpcs in the hope
miner s power according
in the hope of
that is missing more
the hope of achieving
s power according to
hope of achieving a
is missing more than
from some other node
missing more than one
of achieving a benefit
more than one data
achieving a benefit through
power according to the
than one data packet
triggering redundant retransmissions or
one data packet is
a benefit through prefetching
according to the rate
benefit through prefetching files
redundant retransmissions or other
data packet is stored
to the rate with
retransmissions or other overheads
the rate with which
packet is stored temporarily
rate with which it
with which it submits
which it submits such
it submits such partial
submits such partial proof
the pull architecture has
such partial proof of
in case all but
pull architecture has the
case all but one
partial proof of work
all but one of
architecture has the secondary
but one of the
has the secondary benefit
one of the missing
mfs prefetching implementation the
of the missing packets
when a miner generates
the missing packets are
a miner generates a
the secondary benefit of
miner generates a full
missing packets are received
generates a full proof
secondary benefit of letting
a full proof of
packets are received later
benefit of letting us
full proof of work
of letting us delay
are received later or
letting us delay the
received later or recovered
prefetching implementation the mfs
later or recovered through
us delay the preparation
or recovered through other
it sends it to
recovered through other xors
delay the preparation of
implementation the mfs cache
the preparation of status
the mfs cache manager
preparation of status packets
mfs cache manager incorporates
sends it to the
cache manager incorporates a
allowing the recovery of
manager incorporates a small
it to the pool
incorporates a small prefetching
the recovery of the
a small prefetching module
to the pool manager
of status packets until
the pool manager which
status packets until they
recovery of the remaining
packets until they are
pool manager which publishes
until they are about
of the remaining missing
manager which publishes this
the remaining missing packet
which publishes this proof
remaining missing packet from
publishes this proof of
missing packet from this
this proof of work
packet from this xor
proof of work to
they are about to
of work to the
which can be optionally
work to the bitcoin
can be optionally enabled
to the bitcoin system
be optionally enabled at
are about to be
in practice we stored
optionally enabled at start
practice we stored data
about to be transmitted
we stored data and
the pool manager thus
stored data and xor
pool manager thus receives
data and xor packets
manager thus receives the
and xor packets in
thus receives the full
xor packets in double
receives the full revenue
when it is initialised
the full revenue of
conclusions the premise of
packets in double buffered
full revenue of the
in double buffered red
the premise of our
double buffered red black
revenue of the block
buffered red black trees
premise of our work
red black trees for
of the block and
of our work is
a prefetching thread starts
the block and distributes
our work is that
block and distributes it
prefetching thread starts and
and distributes it fairly
work is that developers
distributes it fairly according
thread starts and initiates
is that developers of
it fairly according to
starts and initiates prefetch
fairly according to its
that developers of services
according to its members
and initiates prefetch requests
to its members power
developers of services intended
initiates prefetch requests in
of services intended to
prefetch requests in parallel
services intended to run
requests in parallel with
intended to run on
in parallel with the
many of the pools
parallel with the main
to run on clustered
with the main activity
of the pools are
the main activity of
run on clustered platforms
main activity of the
the pools are open
activity of the cache
on clustered platforms desire
of the cache manager
pools are open they
clustered platforms desire the
are open they allow
platforms desire the productivity
open they allow any
desire the productivity and
they allow any miner
the productivity and robustness
the core component of
productivity and robustness benefits
entries this occupies around
core component of the
and robustness benefits of
allow any miner to
robustness benefits of managed
component of the cache
benefits of managed environments
any miner to join
of the cache manager
miner to join them
the cache manager alerts
to join them using
cache manager alerts the
join them using a
and need replication tools
them using a public
manager alerts the prefetching
using a public internet
need replication tools integrated
a public internet interface
alerts the prefetching module
replication tools integrated with
the prefetching module every
tools integrated with those
prefetching module every time
integrated with those environments
the repair bins in
module every time an
such open pools are
every time an application
repair bins in the
time an application reads
open pools are susceptible
building such tools so
an application reads or
such tools so posed
application reads or writes
tools so posed challenges
reads or writes a
bins in the layered
pools are susceptible to
so posed challenges to
are susceptible to the
posed challenges to us
susceptible to the classical
challenges to us as
to the classical block
to us as protocol
the classical block withholding
us as protocol and
classical block withholding attack
as protocol and system
or writes a file
in the layered interleaving
protocol and system designers
the layered interleaving scheme
layered interleaving scheme store
by calling the file
interleaving scheme store incrementally
calling the file access
scheme store incrementally computed
which were the primary
store incrementally computed xors
were the primary focus
incrementally computed xors and
the primary focus of
the file access routine
computed xors and lists
primary focus of our
xors and lists of
focus of our paper
and lists of data
lists of data packet
this routine checks whether
of data packet headers
routine checks whether the
checks whether the file
a central insight is
whether the file belongs
central insight is that
the file belongs to
where a miner sends
file belongs to a
insight is that high
a miner sends only
belongs to a file
without the data packet
to a file group
the data packet payloads
a file group if
miner sends only partial
file group if not
performance protocols running in
sends only partial proof
protocols running in managed
only partial proof of
running in managed settings
partial proof of work
in managed settings need
the access is ignored
proof of work to
resulting in low storage
of work to the
managed settings need to
work to the pool
in low storage overheads
to the pool manager
settings need to maintain
the pool manager and
low storage overheads for
pool manager and discards
need to maintain the
manager and discards full
prefetching it is a
and discards full proof
it is a member
storage overheads for each
is a member of
discards full proof of
a member of a
full proof of work
member of a file
overheads for each layer
to maintain the smallest
for each layer that
maintain the smallest possible
each layer that rise
the smallest possible memory
layer that rise linearly
smallest possible memory footprint
that rise linearly with
of a file group
rise linearly with the
due to the partial
linearly with the value
to the partial proof
with the value of
the partial proof of
the value of the
partial proof of work
value of the interleave
proof of work it
the group is put
of work it sends
group is put at
work it sends to
is put at the
it sends to the
put at the head
the memory footprint for
at the head of
memory footprint for a
the head of the
sends to the pool
footprint for a longrunning
head of the prefetch
for a longrunning proxy
of the prefetch list
a longrunning proxy was
longrunning proxy was around
the miner is considered
miner is considered a
the prefetch thread periodically
is considered a regular
prefetch thread periodically examines
considered a regular pool
plication of this principle
a regular pool member
thread periodically examines the
regular pool member and
mb in our experiments
pool member and the
periodically examines the prefetching
member and the pool
examines the prefetching is
and the pool can
the prefetching is commonly
qsm achieves scalability and
the pool can estimate
achieves scalability and stability
pool can estimate its
scalability and stability even
can estimate its power
other performance enhancing roles
prefetching is commonly used
and stability even at
is commonly used to
performance enhancing roles maelstrom
commonly used to improve
stability even at very
enhancing roles maelstrom appliances
even at very high
used to improve the
roles maelstrom appliances can
at very high loads
to improve the performance
maelstrom appliances can optionally
improve the performance of
the attacker shares the
appliances can optionally aggregate
attacker shares the revenue
the performance of lo
can optionally aggregate small
shares the revenue obtained
an unexpected side effect
the revenue obtained by
optionally aggregate small subkilobyte
revenue obtained by the
unexpected side effect of
aggregate small subkilobyte packets
group at the head
side effect of building
at the head of
small subkilobyte packets from
the head of the
effect of building qsm
subkilobyte packets from different
head of the list
packets from different flows
of building qsm in
from different flows into
building qsm in windows
different flows into larger
qsm in windows was
flows into larger ones
if the group file
in windows was that
the group file for
into larger ones for
group file for the
larger ones for better
file for the group
ones for better communication
for the group is
windows was that by
obtained by the other
was that by integrating
by the other pool
that by integrating our
the other pool members
the group is cal
by integrating our system
group is cal file
integrating our system tightly
is cal file systems
our system tightly with
for better communication efficiency
system tightly with the
better communication efficiency over
but does not contribute
communication efficiency over the
tightly with the platform
as well as distributed
efficiency over the long
well as distributed file
as distributed file systems
it reduces the revenue
reduces the revenue of
we created a new
the revenue of the
created a new kind
revenue of the other
a new kind of
of the other members
new kind of live
kind of live distributed
of live distributed objects
not in the cache
but also its own
in split flow control
abstract data types that
split flow control mode
data types that form
flow control mode they
types that form groups
we provide necessary background
control mode they can
provide necessary background on
mode they can perform
necessary background on the
they can perform send
background on the bitcoin
it retrieves it from
on the bitcoin protocol
retrieves it from the
it from the server
side buffering of in
and that are updated
that are updated using
are updated using qsm
pools and the classical
updated using qsm multicasts
and the classical block
flight data for multi
then it scans the
the classical block withholding
it scans the in
these look natural to
scans the in a
gigabyte flows that exceed
the in a file
flows that exceed the
in a file system
that exceed the sending
a file system with
exceed the sending end
file system with whole
classical block withholding attack
look natural to the
block withholding attack in
natural to the windows
withholding attack in section
to the windows user
attack in section ii
host s buffering capacity
such an object changes
and specify our model
an object changes faster
specify our model in
a mechanism is required
object changes faster than
our model in section
mechanism is required files
model in section iii
maelstrom appliances can act
is required files in
changes faster than the
appliances can act as
faster than the average
can act as multicast
than the average windows
act as multicast forwarding
the average windows object
as multicast forwarding nodes
for a broader view
required files in the
a broader view of
files in the group
broader view of the
in the group in
view of the protocol
appliances send multicast packets
of the protocol and
send multicast packets to
but the same basic
the group in order
the protocol and ecosystem
multicast packets to each
protocol and ecosystem the
packets to each other
the same basic mechanisms
group in order until
same basic mechanisms can
to each other across
basic mechanisms can support
each other across the
mechanisms can support them
other across the long
and ecosystem the reader
in order until it
ecosystem the reader may
order until it finds
the reader may refer
until it finds the
reader may refer to
it finds the first
may refer to the
finds the first one
and the component integration
the first one which
the component integration environment
first one which is
refer to the survey
one which is not
to the survey by
which is not to
the survey by bonneau
is not to determine
survey by bonneau et
not to determine appropriate
by bonneau et al
and use ip multicast
to determine appropriate prefetching
determine appropriate prefetching hints
earlier work in file
work in file in
in file in the
file in the cache
extends seamlessly to encompass
seamlessly to encompass them
although a great deal
to spread them within
a great deal of
spread them within their
great deal of additional
and issues a prefetch
deal of additional work
them within their data
issues a prefetch request
within their data centers
of additional work is
in this work we
additional work is needed
this work we analyze
a prefetch request or
work we analyze block
prefetch request or system
we analyze block withholding
request or system prefetching
analyze block withholding attacks
or system prefetching has
qsm should eventually enable
block withholding attacks among
system prefetching has used
appliances can take on
prefetching has used clustering
can take on other
has used clustering to
take on other existing
should eventually enable casual
on other existing roles
used clustering to derive
other existing roles in
eventually enable casual use
existing roles in the
clustering to derive file
enable casual use of
roles in the data
casual use of live
in the data center
withholding attacks among pools
to derive file groups
use of live objects
derive file groups from
of live objects not
file groups from validation
live objects not just
groups from validation request
objects not just in
a pool that employs
from validation request for
acting as security and
validation request for it
pool that employs the
not just in datacenters
that employs the pool
just in datacenters but
as security and vpn
in datacenters but also
employs the pool block
datacenters but also on
if all the files
but also on desktops
security and vpn gateways
also on desktops in
all the files are
the pool block withholding
the files are valid
pool block withholding attack
files are valid and
on desktops in wan
are valid and are
desktops in wan settings
valid and are in
block withholding attack registers
and are in the
and vpn gateways and
withholding attack registers with
vpn gateways and as
attack registers with the
gateways and as conventional
are in the cache
and as conventional performance
in the cache access
as conventional performance enhancing
the cache access statistics
registers with the victim
opening the door to
conventional performance enhancing proxies
the door to a
with the victim pool
door to a new
the victim pool as
to a new style
victim pool as a
a new style of
pool as a regular
new style of distributed
as a regular miner
style of distributed programming
it receives tasks from
the current version of
receives tasks from the
current version of qsm
tasks from the victim
version of qsm is
from the victim pool
of qsm is stable
the victim pool and
predicted future file accesses
victim pool and transfers
future file accesses from
pool and transfers them
file accesses from cache
qsm is stable in
and transfers them to
is stable in cluster
transfers them to some
stable in cluster settings
them to some of
in cluster settings and
to some of its
the group is moved
some of its own
group is moved to
of its own miners
is moved to the
moved to the end
to the end of
the end of the
e valuation we evaluated
end of the prefetch
we call these infiltrating
of the prefetch list
has a growing community
valuation we evaluated maelstrom
a growing community of
call these infiltrating miners
we evaluated maelstrom on
growing community of users
evaluated maelstrom on the
maelstrom on the emulab
on the emulab testbed
and the mining power
looking to the future
the mining power spent
the emulab testbed at
mining power spent by
emulab testbed at utah
power spent by a
spent by a pool
by a pool the
we plan to scale
a pool the infiltration
plan to scale qsm
pool the infiltration rate
to scale qsm into
scale qsm into wan
qsm into wan settings
or allowed applications to
allowed applications to specify
when the attacking pool
applications to specify prefetch
to support a wider
the attacking pool s
support a wider range
attacking pool s infiltrating
a wider range of
pool s infiltrating miners
wider range of multicast
s infiltrating miners deliver
range of multicast reliability
infiltrating miners deliver partial
of multicast reliability properties
miners deliver partial proofs
deliver partial proofs of
for all the experiments
partial proofs of work
the thread rechecks the
thread rechecks the head
and to introduce a
rechecks the head of
to introduce a gossip
the head of the
the attacker transfers them
head of the list
attacker transfers them to
of the list ing
transfers them to the
the list ing hints
them to the victim
list ing hints explicitly
to the victim pool
introduce a gossip infrastructure
we used a dumbbell
a gossip infrastructure that
used a dumbbell topology
gossip infrastructure that would
a dumbbell topology of
letting the attacked pool
dumbbell topology of two
the attacked pool estimate
infrastructure that would support
attacked pool estimate their
topology of two clusters
pool estimate their power
that would support configuration
of two clusters of
would support configuration discovery
two clusters of nodes
support configuration discovery and
clusters of nodes connected
configuration discovery and other
of nodes connected via
when the infiltrating miners
nodes connected via routing
discovery and other self
connected via routing nodes
the infiltrating miners deliver
via routing nodes with
infiltrating miners deliver a
routing nodes with a
miners deliver a full
nodes with a high
deliver a full proof
a full proof of
full proof of work
latency link in between
link in between them
the attacking pool discards
live objects pose a
attacking pool discards it
objects pose a protocol
to find the next
pose a protocol design
designed to emulate the
a protocol design challenge
find the next file
to emulate the setup
the next file to
this attack affects the
next file to prefetch
emulate the setup in
attack affects the revenues
the setup in figure
they give rise to
affects the revenues of
give rise to irregular
the revenues of the
rise to irregular patterns
a new group may
revenues of the pools
to irregular patterns of
of the pools in
new group may now
the pools in several
irregular patterns of overlapping
pools in several ways
group may now be
and ran the proxy
patterns of overlapping multicast
may now be at
ran the proxy code
the victim pool s
the proxy code on
victim pool s effective
proxy code on the
pool s effective mining
code on the routers
of overlapping multicast groups
now be at the
s effective mining rate
be at the inter
effective mining rate is
mining rate is unchanged
file dependencies can also
dependencies can also be
oriented state aggregation mechanisms
can also be used
but its total revenue
also be used as
state aggregation mechanisms will
be used as a
its total revenue is
aggregation mechanisms will need
total revenue is divided
mechanisms will need to
revenue is divided among
will need to be
is divided among more
need to be redesigned
divided among more miners
used as a source
show the performance of
as a source of
the performance of the
a source of hints
performance of the kernel
we have an idea
of the kernel version
have an idea for
the attacker s mining
the kernel version at
attacker s mining power
kernel version at gigabit
an idea for solving
version at gigabit speeds
idea for solving this
s mining power is
head of the list
mining power is reduced
of the list as
the list as a
list as a result
the remainder of the
as a result of
remainder of the graphs
a result of further
of the graphs show
result of further application
the graphs show the
of further application accesses
graphs show the performance
further application accesses to
show the performance of
recovery would be performed
the performance of the
application accesses to files
since some of its
would be performed by
some of its miners
performance of the user
of its miners are
be performed by selecting
its miners are used
performed by selecting a
miners are used for
by selecting a subset
are used for block
selecting a subset of
used for block withholding
it may be known
a subset of nodes
space version at slower
subset of nodes that
may be known that
of nodes that form
version at slower speeds
nodes that form a
be known that a
that form a clean
but it earns additional
form a clean overlay
it earns additional revenue
a clean overlay structure
known that a certain
to emulate the mtu
earns additional revenue through
emulate the mtu difference
that a certain shared
the mtu difference between
additional revenue through its
mtu difference between the
rather than just treating
difference between the long
than just treating every
a certain shared library
just treating every single
revenue through its infiltration
treating every single receiver
certain shared library is
through its infiltration of
shared library is reprefetch
its infiltration of the
every single receiver as
infiltration of the other
library is reprefetch requests
haul link and the
is reprefetch requests are
link and the data
reprefetch requests are similar
of the other pool
single receiver as a
and the data center
requests are similar to
receiver as a member
are similar to regular
as a member of
similar to regular fetch
a member of a
to regular fetch requests
member of a recovery
regular fetch requests for
of a recovery region
the data center network
the total effective mining
fetch requests for files
total effective mining power
effective mining power in
mining power in the
power in the system
in the system is
the system is reduced
quired to run a
to run a text
whether this can really
run a text editor
this can really scale
can really scale remains
causing the bitcoin protocol
really scale remains to
the bitcoin protocol to
scale remains to be
bitcoin protocol to reduce
remains to be seen
we set an mtu
protocol to reduce the
in this case it
set an mtu of
to reduce the difficulty
this case it would
case it would be
it would be advantageous
would be advantageous with
taking all these factors
all these factors into
be advantageous with the
these factors into account
advantageous with the exception
with the exception that
the exception that they
exception that they are
we observe that a
that they are issued
bytes on the network
observe that a pool
on the network connecting
they are issued at
the network connecting the
that a pool might
are issued at the
a pool might be
network connecting the end
pool might be able
issued at the lowest
might be able to
at the lowest level
be able to increase
the lowest level of
able to increase its
lowest level of prito
hosts to the proxy
level of prito retrieve
to the proxy and
to increase its revenue
the proxy and an
of prito retrieve the
increase its revenue by
proxy and an mtu
its revenue by attacking
and an mtu of
revenue by attacking other
prito retrieve the shared
by attacking other pools
retrieve the shared library
the shared library from
shared library from the
library from the server
from the server as
the server as well
each pool therefore makes
server as well as
pool therefore makes a
as well as retriev
therefore makes a choice
makes a choice of
a choice of whether
choice of whether to
of whether to attack
whether to attack each
bytes on the long
to attack each of
attack each of the
each of the other
of the other pools
all other rpc traffic
haul link between proxies
the other pools in
other rpc traffic takes
other pools in the
rpc traffic takes precedence
pools in the system
traffic takes precedence over
the only exception is
takes precedence over a
only exception is figure
precedence over a prefetch
over a prefetch rpc
and with what infiltration
with what infiltration rate
ing the text editor
the text editor executable
this gives rise to
gives rise to the
rise to the pool
to the pool game
where we maintained equal
we maintained equal mtus
maintained equal mtus of
we specify this game
specify this game and
this game and provide
game and provide initial
as shown in table
and provide initial analysis
provide initial analysis in
initial analysis in section
analysis in section iv
in section v we
section v we analyze
bytes on both links
v we analyze the
we analyze the scenario
and only one tion
analyze the scenario where
only one tion such
the scenario where exactly
one tion such as
scenario where exactly two
tion such as the
where exactly two of
design and implementation of
all the experiments are
exactly two of the
the experiments are done
and implementation of a
experiments are done with
two of the pools
are done with maelstrom
implementation of a reliable
done with maelstrom using
of the pools take
such as the operating
the pools take part
with maelstrom using end
pools take part in
as the operating system
take part in the
of a reliable group
part in the game
the operating system s
in the game and
a reliable group communication
operating system s database
reliable group communication toolkit
the game and only
group communication toolkit for
system s database of
communication toolkit for java
game and only one
s database of installed
and only one can
database of installed software
only one can attack
of installed software prefetch
one can attack the
installed software prefetch is
can attack the other
software prefetch is made
prefetch is made at
is made at a
made at a time
this is more a
is more a matter
the attacker can always
more a matter of
attacker can always increase
a matter of implementapackages
can always increase its
always increase its revenue
increase its revenue by
its revenue by attacking
which illustrates the performance
illustrates the performance of
we conclude that in
the performance of split
conclude that in the
performance of split mode
that in the general
of split mode flow
in the general case
split mode flow control
specified dependency information tion
dependency information tion convenience
information tion convenience than
tion convenience than a
convenience than a design
with any number of
than a design decision
any number of pools
other work has shown
work has shown can
has shown can be
shown can be used
the benefits initiating multiple
attacks is not a
is not a nash
benefits initiating multiple concurrent
not a nash equilibrium
initiating multiple concurrent prefetches
multiple concurrent prefetches from
show that commodity tcp
concurrent prefetches from differany
prefetches from differany of
from differany of these
differany of these techniques
ip throughput collapses in
of these techniques could
throughput collapses in the
these techniques could be
collapses in the presence
section vi deals with
in the presence of
techniques could be used
the presence of non
vi deals with the
could be used to
deals with the case
be used to derive
with the case of
used to derive hints
the case of two
design and evaluation of
case of two pools
and evaluation of a
to derive hints for
evaluation of a wide
derive hints for use
and that maelstrom successfully
hints for use ent
that maelstrom successfully masks
for use ent servers
maelstrom successfully masks loss
area event notification service
successfully masks loss and
where each can attack
masks loss and prevents
each can attack the
loss and prevents this
can attack the other
and prevents this collapse
acm transactions on computer
prevents this collapse from
transactions on computer systems
this collapse from occurring
analysis becomes more complicated
becomes more complicated in
more complicated in two
complicated in two ways
mfs does not currently
shows the performance of
does not currently make
the performance of the
not currently make use
performance of the userspace
currently make use of
of the userspace version
make use of timeouts
the revenue of each
use of timeouts by
the userspace version on
revenue of each pool
userspace version on a
of timeouts by the
of each pool affects
timeouts by the mfs
each pool affects the
by the mfs prefetching
pool affects the revenue
the mfs prefetching subsystem
affects the revenue of
the revenue of the
revenue of the other
of the other through
the other through the
other through the infiltrating
our evaluation uses hand
through the infiltrating miners
mbps link and figure
we prove that for
prove that for a
that for a static
as we have noted
for a static choice
we have noted earlier
a static choice of
shows the kernel version
static choice of infiltration
the kernel version on
choice of infiltration rates
kernel version on a
of infiltration rates the
but it could easily
infiltration rates the pool
it could easily to
rates the pool revenues
could easily to exspecified
the pool revenues converge
easily to exspecified dependency
to exspecified dependency information
the experiment in each
experiment in each case
in each case involves
which is inaccurate in
each case involves running
is inaccurate in some
case involves running iperf
once one pool changes
inaccurate in some tended
one pool changes its
in some tended to
pool changes its infiltration
some tended to abandon
changes its infiltration rate
tended to abandon a
its infiltration rate of
to abandon a prefetching
infiltration rate of the
abandon a prefetching attempt
rate of the other
a prefetching attempt that
prefetching attempt that does
attempt that does not
that does not complete
does not complete cases
the latter may prefer
latter may prefer to
may prefer to change
flows from one node
prefer to change its
rather than reimplementing an
to change its infiltration
than reimplementing an existing
change its infiltration rate
reimplementing an existing hint
from one node to
its infiltration rate of
one node to another
infiltration rate of the
node to another across
rate of the former
to another across the
another across the long
generation in a timely
in a timely manner
therefore the game itself
the game itself takes
distance link with and
game itself takes multiple
link with and without
itself takes multiple rounds
with and without intermediary
takes multiple rounds to
and without intermediary maelstrom
we focus on the
multiple rounds to converge
without intermediary maelstrom proxies
focus on the performance
intermediary maelstrom proxies and
on the performance of
maelstrom proxies and measuring
the performance of mfs
proxies and measuring obtained
performance of mfs with
and measuring obtained throughput
of mfs with prefetchthe
measuring obtained throughput while
mfs with prefetchthe main
obtained throughput while varying
we show analytically that
throughput while varying loss
with prefetchthe main complexity
while varying loss rate
show analytically that the
prefetchthe main complexity in
analytically that the game
main complexity in implementing
that the game has
complexity in implementing the
left graph on each
in implementing the prefetching
graph on each figure
implementing the prefetching subing
the game has a
game has a single
has a single nash
weight process groups in
a single nash equilibrium
process groups in the
single nash equilibrium and
using a deliberately simple
groups in the isis
a deliberately simple hint
in the isis system
nash equilibrium and numerically
deliberately simple hint mechanism
equilibrium and numerically study
simple hint mechanism for
and numerically study the
hint mechanism for the
numerically study the equilibrium
mechanism for the purposes
study the equilibrium points
for the purposes system
the equilibrium points for
the purposes system lies
equilibrium points for different
purposes system lies in
points for different pool
system lies in handling
for different pool sizes
lies in handling a
the error bars on
in handling a demand
error bars on the
handling a demand fetch
bars on the graphs
for pools smaller than
on the graphs to
the graphs to the
graphs to the left
a compulsory fetch to
to the left are
compulsory fetch to of
the left are standard
fetch to of evaluation
left are standard errors
are standard errors of
standard errors of the
errors of the throughput
of the throughput over
the throughput over ten
dependencies between files are
throughput over ten runs
between files are conveyed
files are conveyed using
are conveyed using a
conveyed using a service
using a service a
at the equilibrium point
a service a cache
service a cache miss
the equilibrium point both
equilibrium point both pools
point both pools earn
both pools earn less
pools earn less than
for a file which
earn less than they
a file which is
less than they would
ip s cache of
than they would have
file which is already
they would have in
which is already being
would have in the
is already being prefetched
have in the nonequilibrium
s cache of tuning
in the nonequilibrium no
cache of tuning parameters
of tuning parameters to
tuning parameters to allow
parameters to allow for
to allow for repeatable
allow for repeatable results
which is a list
is a list of
a list of file
the clients in the
list of file identifiers
clients in the experiment
of file identifiers for
in the experiment are
file identifiers for the
the experiment are running
identifiers for the related
experiment are running tcp
for the related files
since pools can decide
pools can decide to
can decide to start
decide to start or
ip reno on a
to start or stop
reno on a linux
this conflict arises very
start or stop attacking
conflict arises very frequently
or stop attacking at
stop attacking at any
attacking at any point
particularly when an appliit
when an appliit is
an appliit is assumed
this can be modeled
appliit is assumed that
can be modeled as
is assumed that after
constructing reliable distributed communication
assumed that after one
be modeled as the
that after one file
reliable distributed communication systems
after one file in
modeled as the miner
one file in the
distributed communication systems with
file in the group
communication systems with corba
in the group has
as the miner s
the group has been
the miner s dilemma
group has been accessed
miner s dilemma an
s dilemma an instance
ieee communications magazine feature
dilemma an instance of
communications magazine feature topic
an instance of the
magazine feature topic issue
instance of the iterative
cation performs a fast
feature topic issue on
performs a fast linear
topic issue on distributed
a fast linear scan
issue on distributed object
fast linear scan of
on distributed object computing
linear scan of files
of the iterative prisoner
the maelstrom parameters used
scan of files in
the iterative prisoner s
maelstrom parameters used are
of files in a
iterative prisoner s dilemma
parameters used are r
files in a file
in a file group
attacking is the dominant
is the dominant strategy
the dominant strategy in
an it becomes advantageous
dominant strategy in each
it becomes advantageous to
strategy in each iteration
becomes advantageous to prefetch
advantageous to prefetch the
to prefetch the remainder
prefetch the remainder of
but if the pools
the remainder of the
if the pools can
remainder of the files
the pools can agree
of the files in
pools can agree not
the files in efficient
can agree not to
files in efficient implementation
agree not to attack
in efficient implementation of
efficient implementation of prefetching
implementation of prefetching requires
of prefetching requires that
prefetching requires that the
both benefit in the
requires that the demand
benefit in the long
in the long run
we address in section
address in section vii
in section vii the
section vii the case
vii the case where
the case where the
case where the participants
where the participants are
the participants are an
participants are an arbitrary
are an arbitrary number
an arbitrary number of
arbitrary number of identical
number of identical pools
there exists a symmetric
exists a symmetric equilibrium
a symmetric equilibrium in
symmetric equilibrium in which
equilibrium in which each
in which each participating
which each participating pool
each participating pool attacks
participating pool attacks each
space version involved running
pool attacks each of
version involved running a
attacks each of the
involved running a single
each of the other
of the other participating
the other participating pools
as in the minority
in the minority two
hierarchical clustering of message
second iperf flow from
clustering of message flows
of message flows in
iperf flow from one
message flows in a
flows in a multicast
flow from one node
in a multicast data
a multicast data dissemination
from one node to
multicast data dissemination system
here too at equilibrium
one node to another
too at equilibrium all
at equilibrium all pools
node to another with
equilibrium all pools earn
all pools earn less
to another with and
pools earn less than
earn less than with
another with and without
less than with the
than with the no
with and without maelstrom
and without maelstrom running
without maelstrom running on
maelstrom running on the
running on the routers
on the routers and
the routers and measuring
routers and measuring throughput
and measuring throughput while
measuring throughput while varying
throughput while varying the
our results imply that
while varying the random
results imply that block
varying the random loss
imply that block withholding
the random loss rate
that block withholding by
random loss rate on
block withholding by pools
loss rate on the
withholding by pools leads
rate on the link
by pools leads to
on the link and
pools leads to an
the link and the
leads to an unfavorable
link and the oneway
to an unfavorable equilibrium
and the oneway latency
to test the kernel
test the kernel version
the kernel version at
kernel version at gigabit
due to the anonymity
version at gigabit speeds
to the anonymity of
the anonymity of miners
optimizing buffer management for
we ran eight parallel
a single pool might
buffer management for reliable
single pool might be
ran eight parallel iperf
pool might be tempted
management for reliable multicast
might be tempted to
eight parallel iperf flows
be tempted to attack
parallel iperf flows from
iperf flows from one
flows from one node
proceedings of the international
leading the other pools
from one node to
the other pools to
of the international conference
other pools to attack
one node to another
pools to attack as
the international conference on
to attack as well
node to another for
international conference on dependable
conference on dependable systems
on dependable systems and
dependable systems and networks
the implications might be
implications might be devastating
might be devastating for
be devastating for open
devastating for open pools
if their revenues are
their revenues are reduced
the curves obtained from
curves obtained from the
obtained from the two
miners will prefer to
from the two versions
will prefer to form
the two versions are
prefer to form closed
two versions are almost
to form closed pools
versions are almost identical
form closed pools that
closed pools that cannot
pools that cannot be
that cannot be attacked
cannot be attacked in
be attacked in this
attacked in this manner
we present both to
present both to show
both to show that
to show that the
though this may be
this may be conceived
show that the kernel
may be conceived as
that the kernel version
be conceived as bad
the kernel version successfully
conceived as bad news
as bad news for
kernel version successfully scales
bad news for public
news for public mining
version successfully scales up
for public mining pools
successfully scales up the
scales up the performance
up the performance of
the performance of the
performance of the userspace
on the whole it
of the userspace version
the whole it may
the userspace version to
whole it may be
userspace version to hundreds
it may be good
version to hundreds of
may be good news
to hundreds of megabits
be good news to
hundreds of megabits of
good news to the
of megabits of traffic
news to the bitcoin
megabits of traffic per
to the bitcoin system
of traffic per second
which prefers small pools
we examine the practicality
examine the practicality of
the practicality of the
practicality of the attack
of the attack in
the attack in section
attack in section viii
in section viii and
section viii and discuss
viii and discuss implications
and discuss implications and
a group membership service
discuss implications and model
group membership service for
implications and model extensions
membership service for wans
and model extensions in
model extensions in section
extensions in section ix
acm transactions on computer
transactions on computer systems
our contributions are the
contributions are the following
we show how tcp
ip performance degrades on
performance degrades on a
definition of the pool
of the pool game
the pool game where
pool game where pools
ms link as the
game where pools in
link as the loss
where pools in a
as the loss rate
pools in a proof
the loss rate is
loss rate is increased
rate is increased from
ofwork secured system attack
secured system attack one
system attack one another
attack one another with
one another with a
another with a pool
with a pool block
a pool block withholding
pool block withholding attack
in the general case
maelstrom masks loss up
masks loss up to
attacks is not an
is not an equilibrium
without significant throughput degradation
with the kernel version
with two minority pools
the kernel version achieving
two minority pools participating
kernel version achieving two
version achieving two orders
achieving two orders of
two orders of magnitude
orders of magnitude higher
the only nash equilibrium
of magnitude higher throughput
only nash equilibrium is
magnitude higher throughput that
nash equilibrium is when
higher throughput that conventional
equilibrium is when the
throughput that conventional tcp
is when the pools
when the pools attack
the pools attack one
pools attack one another
and both earn less
both earn less than
earn less than if
less than if none
than if none had
if none had attacked
the graphs on the
miners therefore face the
graphs on the right
therefore face the miner
on the right side
face the miner s
the right side of
the miner s dilemma
right side of figures
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
repeatedly choosing between attack
choosing between attack and
between attack and no
ip throughput declining on
throughput declining on a
declining on a link
on a link of
a link of increasing
link of increasing length
of increasing length when
increasing length when subjected
length when subjected to
when subjected to uniform
subjected to uniform loss
to uniform loss rates
with multiple pools of
uniform loss rates of
multiple pools of equal
pools of equal size
of equal size there
equal size there is
size there is a
there is a symmetric
is a symmetric nash
a symmetric nash equilibrium
where all pools earn
all pools earn less
pools earn less than
earn less than if
less than if none
than if none had
if none had attacked
the top line in
top line in the
line in the graphs
in the graphs is
the graphs is the
graphs is the performance
is the performance of
the performance of tcp
inefficient equilibria for open
equilibria for open pools
for open pools may
ip without loss and
open pools may serve
without loss and provides
pools may serve the
loss and provides an
may serve the system
and provides an upper
serve the system by
provides an upper bound
the system by reducing
an upper bound for
system by reducing their
upper bound for performance
by reducing their attraction
bound for performance on
reducing their attraction and
for performance on the
their attraction and pushing
performance on the link
attraction and pushing miners
and pushing miners towards
pushing miners towards smaller
miners towards smaller closed
towards smaller closed pools
space and kernel versions
the classical block withholding
classical block withholding attack
block withholding attack is
withholding attack is old
attack is old as
maelstrom masks packet loss
is old as pools
masks packet loss and
old as pools themselves
packet loss and tracks
loss and tracks the
and tracks the lossless
tracks the lossless line
the lossless line closely
but its use by
its use by pools
use by pools has
by pools has not
lagging only when the
pools has not been
only when the link
has not been suggested
when the link latency
not been suggested until
the link latency is
been suggested until recently
link latency is low
latency is low and
is low and tcp
we overview related attacks
overview related attacks and
ip s throughput is
related attacks and prior
s throughput is very
attacks and prior work
throughput is very high
and prior work in
prior work in section
work in section x
and conclude with final
conclude with final remarks
with final remarks in
final remarks in section
remarks in section xi
p reliminaries b itcoin
reliminaries b itcoin and
b itcoin and p
itcoin and p ooled
and p ooled m
p ooled m ining
ooled m ining bitcoin
m ining bitcoin is
ining bitcoin is a
bitcoin is a distributed
prefetch no prefetch prefetch
no prefetch prefetch no
prefetch prefetch no prefetch
prefetch no prefetch relative
no prefetch relative speedup
prefetch relative speedup relative
relative speedup relative speedup
clients use the system
use the system by
the system by issuing
system by issuing transactions
and the system s
the system s only
system s only task
s only task is
only task is to
task is to serialize
is to serialize transactions
to serialize transactions in
serialize transactions in a
transactions in a single
in a single ledger
a single ledger and
single ledger and reject
ledger and reject transactions
and reject transactions that
reject transactions that cannot
transactions that cannot be
prefetch no prefetch relative
that cannot be serialized
no prefetch relative speedup
cannot be serialized due
prefetch relative speedup relative
be serialized due to
relative speedup relative speedup
ip no loss maelstrom
serialized due to conflicts
no loss maelstrom no
due to conflicts with
loss maelstrom no loss
to conflicts with previous
maelstrom no loss maelstrom
conflicts with previous transactions
bitcoin transactions are protected
transactions are protected with
prefetch no prefetch relative
are protected with cryptographic
no prefetch relative speedup
protected with cryptographic techniques
with cryptographic techniques that
cryptographic techniques that ensure
techniques that ensure that
that ensure that only
ensure that only the
that only the rightful
only the rightful owner
the rightful owner of
rightful owner of a
owner of a bitcoin
of a bitcoin can
a bitcoin can transfer
bitcoin can transfer it
the transaction ledger is
prefetch no prefetch relative
transaction ledger is stored
no prefetch relative speedup
ledger is stored by
prefetch relative speedup bad
is stored by a
relative speedup bad groups
stored by a network
by a network of
a network of miners
network of miners in
of miners in a
miners in a data
in a data structure
a data structure caller
data structure caller the
structure caller the blockchain
revenue for proof of
for proof of work
proof of work the
of work the blockchain
work the blockchain records
the blockchain records the
blockchain records the transactions
records the transactions in
the transactions in units
transactions in units of
in units of blocks
dubbed the genesis block
is defined as part
defined as part of
as part of the
part of the protocol
a valid block contains
valid block contains the
block contains the hash
contains the hash of
the hash of the
hash of the previous
of the previous block
the hash of the
hash of the transactions
of the transactions in
the transactions in the
transactions in the current
in the current block
and a bitcoin address
a bitcoin address which
bitcoin address which is
address which is to
which is to be
is to be credited
to be credited with
be credited with a
credited with a reward
with a reward for
a reward for generating
reward for generating the
for generating the block
any miner may add
miner may add a
may add a valid
add a valid block
a valid block to
valid block to the
block to the chain
to the chain by
proving that it has
that it has spent
it has spent a
has spent a certain
spent a certain amount
a certain amount of
certain amount of work
amount of work and
of work and publishing
work and publishing the
and publishing the block
publishing the block with
the block with the
block with the proof
with the proof over
the proof over an
proof over an overlay
over an overlay network
an overlay network to
overlay network to all
network to all other
to all other miners
when a miner creates
a miner creates a
miner creates a block
it is compensated for
is compensated for its
compensated for its efforts
for its efforts with
its efforts with bitcoins
this compensation includes a
compensation includes a per
transaction fee paid by
fee paid by the
paid by the users
by the users whose
the users whose transactions
users whose transactions are
whose transactions are included
and an amount of
an amount of minted
amount of minted bitcoins
of minted bitcoins that
minted bitcoins that are
bitcoins that are thus
that are thus introduced
are thus introduced into
thus introduced into the
introduced into the system
the work which a
work which a miner
which a miner is
a miner is required
miner is required to
is required to do
required to do is
to do is to
do is to repeatedly
is to repeatedly calculate
to repeatedly calculate a
repeatedly calculate a a
calculate a a hash
a a hash function
a hash function specifically
hash function specifically the
function specifically the sha
aware adaptation techniques for
adaptation techniques for mobile
techniques for mobile file
of a block header
for mobile file systems
mobile file systems benjamin
file systems benjamin atkin
systems benjamin atkin kenneth
benjamin atkin kenneth p
to indicate that he
indicate that he has
that he has performed
he has performed this
has performed this work
birman nec laboratories america
nec laboratories america cornell
laboratories america cornell university
america cornell university atkin
the miner provides a
miner provides a probabilistic
provides a probabilistic proof
a probabilistic proof as
probabilistic proof as follows
the generated block has
generated block has a
block has a nonce
has a nonce field
which can contain any
can contain any value
the miner places different
miner places different values
edu abstract therefore react
places different values in
abstract therefore react to
different values in this
therefore react to bandwidth
values in this field
react to bandwidth variations
in this field and
to bandwidth variations in
this field and calculates
bandwidth variations in a
field and calculates the
variations in a fine
and calculates the hash
relative speedup of workloads
calculates the hash for
speedup of workloads with
the hash for each
of workloads with prefetching
hash for each value
these graphs show the
if the result of
graphs show the speedup
the result of the
show the speedup gained
result of the hash
the speedup gained by
life file system traffic
of the hash is
file system traffic featuring
the hash is smaller
system traffic featuring high
hash is smaller than
traffic featuring high read
is smaller than a
speedup gained by adding
smaller than a target
gained by adding prefetching
than a target value
by adding prefetching for
adding prefetching for a
write wireless networks present
prefetching for a range
wireless networks present unusual
for a range of
networks present unusual challenges
a range of bandwidth
the nonce is considered
range of bandwidth values
nonce is considered a
present unusual challenges for
is considered a solution
unusual challenges for mobile
challenges for mobile file
for mobile file contention
relative to the time
to the time taken
and the block is
the time taken with
the block is valid
time taken with a
mafs is able to
taken with a bandwidth
is able to achieve
with a bandwidth of
able to achieve improvements
to achieve improvements in
achieve improvements in execusystem
the number of attempts
improvements in execusystem clients
number of attempts to
of attempts to find
attempts to find a
to find a single
find a single hash
since they are characterised
a single hash is
they are characterised by
single hash is therefore
are characterised by unpredictable
hash is therefore random
characterised by unpredictable tion
is therefore random with
by unpredictable tion time
therefore random with a
unpredictable tion time of
random with a geometric
tion time of up
with a geometric distribution
time of up to
s and no prefetching
as each attempt is
where a test comprises
each attempt is a
a test comprises two
attempt is a bernoulli
test comprises two separate
is a bernoulli trial
comprises two separate processes
a bernoulli trial with
bernoulli trial with a
trial with a success
with a success probability
a success probability determined
only the speedup for
success probability determined by
the speedup for the
probability determined by the
speedup for the foreground
determined by the target
for the foreground process
by the target value
the foreground process is
foreground process is shown
at both low and
both low and high
at the existing huge
low and high bandwidths
fetch wait for the
the existing huge hashing
wait for the prefetch
existing huge hashing rates
for the prefetch to
huge hashing rates and
the prefetch to complete
hashing rates and small
rates and small target
and small target values
or that the prefetch
that the prefetch be
the prefetch be aborted
the time to find
time to find a
the traditional approach to
to find a single
traditional approach to adapting
issuing a fetch rpc
find a single hash
a fetch rpc at
a single hash can
fetch rpc at the
single hash can be
approach to adapting network
hash can be approximated
rpc at the same
to adapting network communication
at the same time
can be approximated by
the same time as
adapting network communication to
same time as a
be approximated by an
time as a prefetch
network communication to these
as a prefetch is
approximated by an exponential
a prefetch is in
communication to these conditions
prefetch is in progress
by an exponential distribution
is in progress needlessly
to these conditions is
in progress needlessly wastes
these conditions is to
progress needlessly wastes bandwidth
conditions is to write
is to write back
to write back file
the average time for
write back file updates
average time for a
since it retrieves the
back file updates asynchronously
it retrieves the same
file updates asynchronously when
retrieves the same file
time for a miner
the same file from
updates asynchronously when bandwidth
same file from the
for a miner to
file from the server
asynchronously when bandwidth is
from the server twice
a miner to find
miner to find a
to find a solution
find a solution is
a solution is therefore
the same could be
solution is therefore proportional
same could be true
is therefore proportional to
could be true if
therefore proportional to its
be true if we
proportional to its hashing
true if we opt
to its hashing rate
if we opt for
its hashing rate or
we opt for aborting
hashing rate or mining
opt for aborting prefetches
rate or mining power
this can lead to
can lead to underutilisation
lead to underutilisation of
to underutilisation of bandwidth
since an aborted prefetch
underutilisation of bandwidth and
an aborted prefetch could
of bandwidth and inconsistencies
aborted prefetch could be
bandwidth and inconsistencies between
prefetch could be very
and inconsistencies between clients
could be very close
to maintain a constant
be very close to
maintain a constant rate
very close to completion
a constant rate of
constant rate of bitcoin
rate of bitcoin generation
we describe a new
describe a new mobile
a new mobile access
mfs therefore makes the
new mobile access to
therefore makes the demand
mobile access to shared
and as part of
access to shared data
as part of its
to shared data is
part of its defense
shared data is complicated
of its defense against
data is complicated by
its defense against denial
makes the demand fetch
defense against denial of
is complicated by an
the demand fetch wait
complicated by an unpredictable
demand fetch wait for
by an unpredictable mobile
fetch wait for the
an unpredictable mobile file
wait for the prefetch
unpredictable mobile file system
tcp no loss maelstrom
against denial of service
no loss maelstrom no
denial of service and
loss maelstrom no loss
of service and other
maelstrom no loss maelstrom
service and other attacks
but also raises the
also raises the priority
that supports graceful degradation
raises the priority of
supports graceful degradation computing
the priority of the
graceful degradation computing environment
the system normalizes the
priority of the prefetch
system normalizes the rate
of the prefetch rpc
normalizes the rate of
the prefetch rpc to
the rate of block
prefetch rpc to that
the network or a
rpc to that of
network or a particular
to that of a
rate of block generation
or a particular destination
that of a regular
a particular destination of
of a regular fetch
particular destination of file
a regular fetch operation
destination of file system
of file system performance
file system performance as
system performance as bandwidth
performance as bandwidth is
as bandwidth is reduced
to prevent a priority
the protocol deterministically defines
prevent a priority inversion
protocol deterministically defines the
deterministically defines the target
as well as may
defines the target value
well as may be
this requires an additional
as may be unavailable
the target value for
requires an additional raise
target value for each
value for each block
for each block according
or the throughput may
each block according to
priority rpc to the
the throughput may be
block according to the
throughput may be substandard
rpc to the server
according to the time
to the time required
the time required to
time required to generate
required to generate recent
as rapid propagation of
to generate recent blocks
which results in more
rapid propagation of essential
results in more overhead
propagation of essential file
in more overhead than
of essential file updates
more overhead than the
overhead than the case
than the case where
the case where a
case where a demand
mafs is able to
where a demand fetch
is able to shown
a demand fetch occurs
able to shown in
demand fetch occurs without
to shown in figure
fetch occurs without a
is updated once every
occurs without a fetch
this graph shows results
graph shows results from
shows results from packet
on the other hand
the fetch can frequently
fetch can frequently make
blocks such that the
can frequently make use
such that the average
frequently make use of
that the average time
make use of the
the average time for
use of the data
average time for each
of the data already
time for each block
the data already transferred
for each block to
data already transferred and
each block to be
already transferred and so
block to be found
transferred and so still
to be found is
and so still results
so still results in
still results in a
results in a faster
in a faster response
improvements in execution time
a faster response to
in execution time for
faster response to the
execution time for real
response to the application
note that the exponential
life measurements of available
that the exponential distribution
as we have explained
the exponential distribution is
measurements of available bandwidth
exponential distribution is memoryless
of available bandwidth between
available bandwidth between a
bandwidth between a mobile
between a mobile host
the implementation of the
a mobile host on
if all miners mine
mobile host on a
all miners mine for
host on a wireless
implementation of the prefetching
on a wireless network
miners mine for block
of the prefetching subsystem
mine for block number
the prefetching subsystem is
for block number b
prefetching subsystem is not
subsystem is not sophisticated
and a wired host
a wired host near
wired host near the
host near the base
once the block is
near the base station
the block is found
while it will reach
block is found at
it will reach an
is found at time
found at time t
will reach an equilibrium
one way link latency
file system traces featuring
reach an equilibrium if
system traces featuring read
an equilibrium if the
all miners switch to
equilibrium if the total
miners switch to mine
if the total size
switch to mine for
the total size of
to mine for the
total size of the
mine for the subsequent
size of the file
as the mobile host
for the subsequent block
the mobile host moves
of the file groups
the subsequent block b
the file groups in
file groups in the
groups in the prefetch
in the prefetch list
factors such as the
the prefetch list is
such as the distance
prefetch list is less
as the distance to
list is less than
the distance to the
at t without changing
is less than the
t without changing their
less than the cache
distance to the base
without changing their probability
to the base station
than the cache size
changing their probability distribution
the base station and
their probability distribution of
base station and local
probability distribution of finding
station and local interference
distribution of finding a
and local interference cause
there is no mechanism
local interference cause the
of finding a block
interference cause the host
is no mechanism to
cause the host s
finding a block after
the host s network
a block after t
host s network card
no mechanism to prevent
s network card to
network card to switch
mechanism to prevent the
card to switch to
to switch to higher
to prevent the prefetching
prevent the prefetching subsystem
the prefetching subsystem running
prefetching subsystem running ahead
the probability that a
subsystem running ahead of
probability that a miner
running ahead of actual
way latency throughput as
ahead of actual file
that a miner i
of actual file accesses
latency throughput as a
actual file accesses and
throughput as a function
file accesses and evicting
as a function of
a miner i with
a function of latency
accesses and evicting useful
miner i with mining
and evicting useful files
i with mining power
evicting useful files from
with mining power mi
useful files from the
mining power mi finds
such switching causes available
files from the cache
power mi finds the
switching causes available bandwidth
mi finds the next
causes available bandwidth to
finds the next block
available bandwidth to oscillate
the next block is
bandwidth to oscillate distributed
or evicting files which
next block is its
evicting files which it
block is its ratio
files which it has
is its ratio out
to oscillate distributed file
its ratio out of
which it has prefetched
ratio out of the
oscillate distributed file systems
out of the total
it has prefetched but
of the total mining
distributed file systems are
the total mining power
has prefetched but have
file systems are a
prefetched but have not
total mining power m
but have not yet
mining power m in
have not yet been
power m in the
not yet been referenced
m in the system
yet been referenced by
systems are a common
been referenced by the
are a common feature
referenced by the user
a common feature of
common feature of large
feature of large com
ip to attain very
to attain very high
attain very high speeds
very high speeds on
techniques for preventing this
high speeds on the
for preventing this behaviour
speeds on the gigabit
miner miner miner pool
on the gigabit link
preventing this behaviour have
this behaviour have been
behaviour have been discussed
even when the mobile
have been discussed elsewhere
when the mobile host
miner miner miner pool
the mobile host is
we had to set
mobile host is stationary
had to set the
to set the mtu
set the mtu of
the mtu of the
mtu of the entire
if it is to
of the entire path
it is to enputing
the entire path to
is to enputing environments
entire path to be
path to be the
to be the maximum
since they simplify sharing
they simplify sharing data
simplify sharing data between
sharing data between sure
data between sure that
between sure that clients
sure that clients file
in order to characterise
that clients file operations
order to characterise the
clients file operations are
to characterise the effect
file operations are executed
characterise the effect of
operations are executed in
the effect of adding
are executed in a
effect of adding prefetching
executed in a timely
in a timely way
which meant that the
meant that the long
we ran a set
ran a set of
a set of eight
set of eight microbenchmarks
haul link had the
link had the same
had the same mtu
and can provide scalable
the same mtu as
can provide scalable and
same mtu as the
the experimental setup was
provide scalable and highly
experimental setup was the
scalable and highly available
setup was the same
and highly available file
was the same as
highly available file ac
the same as in
mtu as the inter
same as in the
as in the priority
in the priority tests
file system must adapt
system must adapt to
and one miner mines
must adapt to this
one miner mines solo
though this time mfs
adapt to this variation
this time mfs was
this resulted in the
time mfs was configured
resulted in the fragmentation
mfs was configured to
in the fragmentation of
was configured to run
the fragmentation of repair
configured to run with
pools datacenters are built
fragmentation of repair packets
datacenters are built around
to run with asynchronous
are built around the
of repair packets sent
built around the world
run with asynchronous writeback
repair packets sent over
packets sent over udp
sent over udp on
over udp on the
udp on the longhaul
and rpc with priorities
on the longhaul link
the longhaul link into
longhaul link into two
link into two ip
into two ip packet
two ip packet fragments
and only prefetching was
only prefetching was either
supporting mobile clients requires
prefetching was either enabled
mobile clients requires coping
was either enabled or
clients requires coping existing
since the loss of
requires coping existing systems
either enabled or disabled
coping existing systems tailored
the loss of a
existing systems tailored to
loss of a single
systems tailored to low
mining is only profitable
of a single fragment
is only profitable using
a single fragment resulted
only profitable using dedicated
single fragment resulted in
profitable using dedicated hardware
fragment resulted in the
bandwidth clients differenwith the
using dedicated hardware in
clients differenwith the atypical
dedicated hardware in cutting
the tests were run
hardware in cutting edge
resulted in the loss
tests were run at
differenwith the atypical patterns
were run at a
in the loss of
in cutting edge mining
the loss of the
cutting edge mining rigs
the atypical patterns of
run at a range
loss of the repair
atypical patterns of connectivity
at a range of
patterns of connectivity that
otherwise the energy costs
of connectivity that characterise
the energy costs exceed
connectivity that characterise them
we observed a higher
energy costs exceed the
observed a higher loss
costs exceed the expected
a higher loss rate
exceed the expected revenue
a range of bandwidth
tiate between types of
range of bandwidth values
between types of file
higher loss rate for
types of file system
loss rate for repairs
of file system communication
rate for repairs than
although expected revenue from
for repairs than for
as in the previous
repairs than for data
expected revenue from mining
than for data packets
in the previous section
so that bandwhile a
revenue from mining is
that bandwhile a desktop
from mining is proportional
bandwhile a desktop client
mining is proportional to
a desktop client is
each microbenchmark consists of
desktop client is well
is proportional to the
microbenchmark consists of one
proportional to the power
consists of one or
to the power of
we expect performance to
the power of the
of one or two
power of the mining
connected to a file
of the mining rigs
to a file server
the mining rigs used
a file server un
expect performance to be
one or two processes
performance to be better
or two processes accessing
to be better on
two processes accessing files
be better on a
a single home miner
better on a network
width can be devoted
on a network where
can be devoted to
a network where the
be devoted to important
network where the mtu
single home miner using
where the mtu of
with some or all
the mtu of the
some or all of
mtu of the long
or all of the
home miner using a
all of the files
miner using a small
of the files forming
using a small rig
the files forming file
a small rig is
files forming file groups
haul link is truly
small rig is unlikely
link is truly larger
rig is unlikely to
is truly larger than
is unlikely to mine
truly larger than the
unlikely to mine a
larger than the mtu
to mine a block
than the mtu within
mine a block for
the mtu within each
a block for years
mtu within each cluster
write test is the
test is the same
is the same as
the same as in
same as in section
even with zero loss
a mobile client frequently
mobile client frequently lacks
client frequently lacks the
with a file group
ip throughput in figure
a file group added
file group added for
group added for the
added for the read
for the read data
the compile mfs test
compile mfs test has
miners often organize themselves
mfs test has six
often organize themselves into
test has six file
organize themselves into mining
has six file groups
themselves into mining pools
six file groups for
file groups for the
declines with link latency
groups for the main
for the main directories
the main directories of
main directories of the
directories of the system
this is due to
is due to the
a pool is a
due to the cap
pool is a group
to the cap on
is a group of
the cap on throughput
a group of miners
cap on throughput placed
mb of data in
on throughput placed by
group of miners that
writes back changes to
throughput placed by the
back changes to files
placed by the buffering
of miners that share
by the buffering available
changes to files asynbandwidth
the buffering available at
miners that share their
buffering available at the
to files asynbandwidth to
available at the receiving
that share their revenues
at the receiving end
files asynbandwidth to perform
share their revenues when
asynbandwidth to perform all
forming a single file
to perform all its
a single file group
their revenues when one
perform all its file
revenues when one of
all its file operations
when one of them
its file operations in
one of them successfully
file operations in a
of them successfully mines
operations in a timely
them successfully mines a
in a timely fashion
successfully mines a block
the preceding experiments were
mb of small files
preceding experiments were done
experiments were done with
were done with maelstrom
done with maelstrom in
for each block found
with maelstrom in endto
the revenue is distributed
end flow control mode
revenue is distributed among
is distributed among the
distributed among the pool
among the pool members
the pool members in
where it is oblivious
pool members in proportion
it is oblivious to
members in proportion to
is oblivious to tcp
in proportion to their
assigns lower priorities to
proportion to their mining
lower priorities to asynmobile
all the files are
priorities to asynmobile file
the files are in
to their mining power
files are in a
to asynmobile file systems
are in a single
ip and does not
in a single file
asynmobile file systems typically
a single file group
and does not split
file systems typically assume
does not split connections
systems typically assume that
typically assume that a
assume that a client
that a client is
the expected revenue of
a client is strongly
expected revenue of a
and is consequently sensitive
revenue of a pool
fetch runs as two
of a pool member
runs as two process
is consequently sensitive to
a pool member is
chronous operations at the
consequently sensitive to the
operations at the ip
sensitive to the size
pool member is therefore
to the size of
at the ip level
the size of the
member is therefore the
size of the receiver
the ip level to
of the receiver buffer
is therefore the same
ip level to reduce
therefore the same as
level to reduce interference
the same as its
to reduce interference with
same as its revenue
reduce interference with connected
as its revenue had
interference with connected like
its revenue had it
with connected like a
revenue had it mined
connected like a desktop
had it mined solo
like a desktop host
shows the performance of
the performance of split
performance of split mode
of split mode flow
which form a file
split mode flow control
form a file group
due to the large
connected and should foreground
to the large power
and should foreground operations
the large power of
where maelstrom breaks a
the other does the
maelstrom breaks a single
other does the same
breaks a single tcp
large power of the
limit its bandwidth consumption
power of the pool
its bandwidth consumption to
bandwidth consumption to a
but without a file
ip connection into three
without a file group
consumption to a minimum
connection into three hops
it finds blocks at
finds blocks at a
blocks at a much
at a much higher
a much higher rate
simultaneous writeback executes in
writeback executes in the
executes in the same
in the same way
and so the frequency
so the frequency of
the frequency of revenue
frequency of revenue collection
but the second process
of revenue collection is
the second process writes
revenue collection is higher
second process writes the
process writes the files
writes the files to
the files to the
files to the server
allowing for a stable
to the server instead
split mode flow control
the server instead of
for a stable daily
server instead of reading
mode flow control eliminates
instead of reading them
a stable daily or
flow control eliminates the
stable daily or weekly
control eliminates the requirement
daily or weekly income
adaptation by deferred transmission
eliminates the requirement for
by deferred transmission of
the remaining tests investigate
deferred transmission of file
the requirement for large
transmission of file upwidth
remaining tests investigate the
of file upwidth lies
requirement for large buffers
file upwidth lies between
tests investigate the overhead
upwidth lies between these
for large buffers at
lies between these extremes
investigate the overhead paid
most pools are controlled
the overhead paid for
pools are controlled by
large buffers at the
overhead paid for weaknesses
buffers at the receiving
assuming weak connectivity dates
at the receiving end
paid for weaknesses in
are controlled by a
for weaknesses in the
weak connectivity dates has
weaknesses in the prefetching
controlled by a centralized
in the prefetching algorithm
connectivity dates has the
by a centralized pool
dates has the disadvantage
a centralized pool manager
throughput is essentially insensitive
has the disadvantage of
is essentially insensitive to
the disadvantage of increasing
essentially insensitive to one
disadvantage of increasing the
of increasing the delay
increasing the delay before
the delay before upcan
delay before upcan be
before upcan be too
miners register with the
upcan be too conservative
register with the pool
with the pool manager
the pool manager and
with a slight drop
pool manager and mine
a slight drop due
manager and mine on
since it delays sending
and mine on its
slight drop due to
mine on its behalf
drop due to buffering
it delays sending updates
due to buffering overhead
delays sending updates to
to buffering overhead on
sending updates to the
buffering overhead on the
updates to the dates
overhead on the maelstrom
the pool manager generates
on the maelstrom boxes
to the dates are
pool manager generates tasks
the dates are applied
manager generates tasks and
dates are applied at
generates tasks and the
are applied at the
tasks and the miners
applied at the file
and the miners search
at the file server
the miners search for
miners search for solutions
search for solutions based
kb files and forming
for solutions based on
files and forming its
solutions based on these
and forming its own
and therefore reduces the
forming its own file
based on these tasks
its own file group
therefore reduces the deserver
compares split mode to
reduces the deserver in
split mode to end
the deserver in order
on these tasks that
deserver in order to
these tasks that can
on its first iteration
in order to aggregate
tasks that can serve
order to aggregate modifications
that can serve as
can serve as proof
the workload accesses the
serve as proof of
workload accesses the first
as proof of work
accesses the first file
gree of consistency between
the first file in
of consistency between clients
first file in each
consistency between clients cached
file in each directory
between clients cached copies
once they find a
they find a solution
for its own this
its own this paper
they send it to
own this paper examines
send it to the
this paper examines the
it to the pool
paper examines the effectiveness
to the pool manager
examines the effectiveness of
the effectiveness of mafs
the pool manager behaves
to provoke a large
pool manager behaves as
provoke a large amount
manager behaves as a
a large amount of
behaves as a single
large amount of useless
as a single miner
amount of useless prefetches
a single miner in
single miner in the
miner in the bitcoin
in the bitcoin system
bandwidth client may decide
good order and bad
client may decide to
order and bad order
may decide to delay
and bad order investigate
once it obtains a
bad order investigate the
it obtains a legitimate
decide to delay sending
obtains a legitimate block
order investigate the effect
a legitimate block from
to delay sending a
legitimate block from one
investigate the effect of
block from one of
delay sending a file
from one of its
the effect of the
sending a file system
one of its miners
effect of the ordered
a file system that
of the ordered list
file system that propagates
the ordered list of
system that propagates file
ordered list of files
that propagates file modifications
list of files in
propagates file modifications asynchronously
of files in a
file modifications asynchronously file
files in a file
modifications asynchronously file s
in a file group
the block transfers the
asynchronously file s update
block transfers the revenue
file s update to
transfers the revenue to
s update to the
the revenue to the
update to the file
revenue to the control
to the file server
to the control of
the control of the
control of the pool
of the pool manager
but this decision may
this decision may also
decision may also affect
may also affect at
the pool manager then
also affect at all
pool manager then distributes
prefetching evaluation having added
manager then distributes the
evaluation having added prefetching
affect at all bandwidth
having added prefetching to
at all bandwidth levels
added prefetching to mfs
then distributes the revenue
distributes the revenue among
the revenue among the
revenue among the miners
among the miners according
rather than delaying writes
we evaluated whether such
the miners according to
evaluated whether such a
miners according to their
whether such a straightforward
according to their mining
such a straightforward algorithm
mafs other clients that
a straightforward algorithm can
other clients that would
to their mining power
clients that would like
straightforward algorithm can have
that would like to
algorithm can have a
would like to read
can have a benefit
like to read the
have a benefit for
to read the file
a benefit for some
the architecture is illustrated
benefit for some repre
architecture is illustrated in
is illustrated in figure
optimistic concuruses rpc priorities
order accesses the files
concuruses rpc priorities to
in order to estimate
accesses the files in
order to estimate the
the files in the
to estimate the mining
files in the group
estimate the mining power
in the group in
the mining power of
rpc priorities to reduce
mining power of a
the group in the
power of a miner
priorities to reduce interference
group in the same
to reduce interference between
in the same order
the same order as
reduce interference between read
the pool manager sets
same order as the
interference between read and
order as the list
pool manager sets a
between read and rency
manager sets a partial
read and rency control
sets a partial target
and rency control and
a partial target for
rency control and reconciliation
partial target for each
bad order accesses them
control and reconciliation of
order accesses them in
and reconciliation of conflicting
accesses them in reverse
target for each member
reconciliation of conflicting updates
them in reverse order
of conflicting updates are
conflicting updates are typwrite
updates are typwrite traffic
are typwrite traffic at
typwrite traffic at low
traffic at low bandwidth
to ensure that file
ensure that file modifications
that file modifications ically
file modifications ically used
modifications ically used to
ically used to resolve
used to resolve inconsistencies
than the target of
the target of the
target of the bitcoin
of the bitcoin system
analysis of prefetching the
of prefetching the graphs
prefetching the graphs in
the graphs in figure
each miner is required
miner is required to
is required to send
required to send the
show the results of
to send the pool
the results of the
send the pool manager
results of the experiments
the pool manager blocks
pool manager blocks that
manager blocks that are
blocks that are correct
that are correct according
where a test such
are correct according to
a test such as
mode buffering flow control
test such as simultaneous
buffering flow control against
such as simultaneous demand
flow control against one
correct according to the
when bandwidth are rapidly
according to the partial
bandwidth are rapidly propagated
to the partial target
are rapidly propagated to
way link latency left
rapidly propagated to the
fetch incorporates more than
propagated to the clients
incorporates more than one
to the clients that
more than one workload
the partial target is
the clients that need
most bar represents maelstrom
partial target is chosen
bar represents maelstrom in
target is chosen to
only the elapsed time
is chosen to be
the elapsed time for
chosen to be large
elapsed time for the
represents maelstrom in end
time for the foreground
clients that need them
for the foreground workload
such that partial solutions
that partial solutions arrive
mafs is very low
the one accessing a
partial solutions arrive frequently
one accessing a file
solutions arrive frequently enough
end mode with manually
accessing a file group
mode with manually configured
arrive frequently enough for
this can be an
with manually configured large
can be an acceptable
manually configured large buffers
frequently enough for the
configured large buffers at
be an acceptable price
enough for the manager
large buffers at end
for the manager to
an acceptable price to
the manager to accurately
in most of the
acceptable price to pay
manager to accurately estimate
price to pay for
to accurately estimate the
to pay for the
most of the microbenchmarks
pay for the abilalso
accurately estimate the power
for the abilalso incorporates
estimate the power of
and the second and
the abilalso incorporates a
the second and third
abilalso incorporates a new
adding prefetching from the
incorporates a new invalidation
the power of the
second and third bar
prefetching from the file
and third bar from
power of the miner
third bar from left
from the file groups
bar from left are
based update propagation ity
from left are split
the file groups specified
left are split mode
update propagation ity to
are split mode and
file groups specified has
propagation ity to continue
groups specified has a
ity to continue accessing
split mode and end
specified has a substantial
to continue accessing a
has a substantial improvement
continue accessing a file
a substantial improvement on
accessing a file server
substantial improvement on the
to reduce management overhead
improvement on the performance
on the performance of
the performance of the
performance of the workload
but if bandwidth is
if bandwidth is less
as the value of
bandwidth is less scheme
the value of bitcoin
value of bitcoin rose
varying with how amenable
with how amenable it
how amenable it is
amenable it is to
with standard buffers at
it is to prefetching
unlike previous mobile file
bitcoin mining has become
standard buffers at end
mining has become a
previous mobile file systems
has become a rapidly
become a rapidly advancing
a rapidly advancing industry
more surplus bandwidth and
split mode performs as
surplus bandwidth and more
technological advancements lead to
bandwidth and more think
mode performs as well
and more think time
advancements lead to ever
more think time result
performs as well with
think time result in
lead to ever more
time result in improved
as well with default
result in improved performance
to ever more efficient
client consistency is achievable
ever more efficient hashing
well with default sized
more efficient hashing asics
with default sized buffers
default sized buffers as
sized buffers as end
this naturally means that
codaniques that are oblivious
naturally means that the
that are oblivious to
means that the greatest
are oblivious to the
that the greatest improvements
oblivious to the exact
the greatest improvements from
to the exact bandwidth
greatest improvements from prefetching
end mode performs with
the exact bandwidth level
mode performs with large
improvements from prefetching are
performs with large end
from prefetching are evident
prefetching are evident at
are evident at higher
evident at higher bandwidths
and can like file
can like file systems
like file systems therefore
file systems therefore switch
systems therefore switch between
therefore switch between a
and much better than
switch between a low
much better than end
six out of eight
this is a simplification
out of eight microbenchmarks
is a simplification that
of eight microbenchmarks run
a simplification that is
eight microbenchmarks run at
simplification that is sufficient
microbenchmarks run at least
that is sufficient for
is sufficient for our
sufficient for our analysis
end mode with default
mode with default sized
with default sized buffers
writes mode and a
the intricacies of reward
mode and a synchronous
intricacies of reward systems
of reward systems are
reward systems are explained
systems are explained in
faster when bandwidth is
acthe authors were supported
authors were supported in
were supported in part
supported in part by
in part by darpa
part by darpa under
by darpa under afrl
darpa under afrl grant
under afrl grant radc
afrl grant radc cording
grant radc cording to
radc cording to the
cording to the available
to the available bandwidth
a notable exception is
notable exception is p
in a wireless f
at low bandwidth most
low bandwidth most workloads
bandwidth most workloads see
most workloads see no
workloads see no benefit
since all the bandwidth
all the bandwidth is
the bandwidth is dedicated
bandwidth is dedicated to
is dedicated to higher
which we discuss in
we discuss in section
discuss in section ix
only two tests perform
two tests perform worse
tests perform worse with
perform worse with prefetching
forks block propagation in
worse with prefetching than
block propagation in the
with prefetching than without
propagation in the overlay
in the overlay network
the overlay network takes
overlay network takes seconds
therefore it is possible
write test performs slightly
it is possible for
test performs slightly worse
is possible for two
performs slightly worse due
possible for two distant
slightly worse due to
for two distant miners
worse due to its
two distant miners to
due to its already
distant miners to generate
to its already heavy
miners to generate competing
its already heavy network
to generate competing blocks
already heavy network contention
both of which name
the bad groups test
of which name the
which name the same
name the same block
the same block as
same block as their
block as their predecessor
which exploits poor prefetching
exploits poor prefetching hints
and by afosr under
by afosr under muri
afosr under muri grant
under muri grant f
performs when prefetching is
when prefetching is used
are rare since the
rare since the average
since the average mining
the average mining interval
average mining interval is
this effect is due
effect is due to
is due to the
due to the useless
to the useless prefetching
the useless prefetching rpcs
useless prefetching rpcs flooding
prefetching rpcs flooding the
rpcs flooding the outgoing
flooding the outgoing link
the outgoing link and
and they occur on
outgoing link and imposing
they occur on average
link and imposing minor
occur on average once
and imposing minor delays
on average once every
imposing minor delays on
minor delays on each
delays on each demand
on each demand fetch
cumulatively these slow down
these slow down the
slow down the overall
down the overall performance
an usual phenomenon is
usual phenomenon is that
phenomenon is that the
is that the bad
that the bad order
the bad order test
bad order test consistently
order test consistently outperforms
test consistently outperforms good
consistently outperforms good order
the system has a
system has a mechanism
even though the latter
has a mechanism to
though the latter triggers
a mechanism to solve
the latter triggers prefetches
mechanism to solve forks
latter triggers prefetches in
to solve forks when
triggers prefetches in the
solve forks when they
prefetches in the correct
forks when they do
in the correct order
when they do occur
variations in bandwidth can
in bandwidth can occur
bandwidth can occur without
can occur without the
the explanation is that
causing one of the
occur without the user
one of the blocks
without the user s
of the blocks to
the user s with
the blocks to be
user s with additional
blocks to be discarded
s with additional support
with additional support from
additional support from microsoft
the good order test
support from microsoft research
good order test suffers
from microsoft research and
we ignore bifurcations for
microsoft research and from
order test suffers from
research and from the
ignore bifurcations for the
and from the intel
bifurcations for the sake
from the intel corporation
for the sake of
test suffers from the
the sake of simplicity
suffers from the fast
from the fast linear
the fast linear scan
fast linear scan phenomenon
linear scan phenomenon described
since the choice of
scan phenomenon described in
the choice of the
phenomenon described in section
so that changing modes
choice of the discarded
that changing modes creates
of the discarded block
changing modes creates unexpected
the discarded block on
modes creates unexpected incon
discarded block on bifurcation
block on bifurcation is
on bifurcation is random
several clients concurrently modify
clients concurrently modify a
concurrently modify a file
one may incorporate this
may incorporate this event
incorporate this event into
this event into the
event into the probability
the final contents depend
all prefetches in this
final contents depend on
into the probability of
contents depend on the
prefetches in this test
the probability of finding
depend on the client
probability of finding a
on the client that
of finding a block
the client that closed
in this test conflict
client that closed it
this test conflict with
that closed it last
test conflict with demand
conflict with demand fetches
and consider instead the
consider instead the probability
instead the probability of
a client can lock
the probability of finding
client can lock a
probability of finding a
can lock a file
of finding a block
lock a file to
finding a block that
a file to synchronise
a block that is
file to synchronise accesses
block that is not
that is not discarded
at the start of
the start of the
start of the bad
the server grants the
of the bad order
pools often charge a
the bad order test
server grants the client
often charge a small
grants the client a
charge a small percentage
the client a lease
a small percentage of
small percentage of the
percentage of the revenue
the prefetching subsystem is
of the revenue as
the revenue as fee
prefetching subsystem is able
subsystem is able to
is able to prefetch
able to prefetch some
to prefetch some files
we discuss in section
prefetch some files accessed
discuss in section ix
some files accessed at
in section ix the
files accessed at the
section ix the implications
accessed at the end
that is renewed each
at the end of
ix the implications of
is renewed each time
the implications of such
renewed each time the
implications of such fees
the end of the
of such fees to
end of the test
such fees to our
each time the client
fees to our analysis
time the client communicates
the client communicates with
client communicates with the
communicates with the file
without conflicting with a
with the file server
conflicting with a demand
many pools are open
with a demand fetch
pools are open and
are open and accept
open and accept any
and accept any interested
accept any interested miner
it can therefore achieve
can therefore achieve a
therefore achieve a greater
achieve a greater speedup
a pool interface is
pool interface is typically
interface is typically comprised
is typically comprised of
typically comprised of a
comprised of a web
of a web interface
a web interface for
web interface for registration
interface for registration and
for registration and a
registration and a miner
and a miner interface
a miner interface for
miner interface for the
interface for the mining
for the mining software
in order to mine
order to mine for
to mine for a
mine for a pool
a miner registers with
miner registers with the
registers with the web
with the web interface
supplies a bitcoin address
a bitcoin address to
bitcoin address to receive
address to receive its
to receive its future
receive its future shares
its future shares of
future shares of the
shares of the revenue
and receives from the
receives from the pool
from the pool credentials
the pool credentials for
pool credentials for mining
then he feeds his
he feeds his credentials
feeds his credentials and
his credentials and the
credentials and the pool
and the pool s
the pool s address
pool s address to
s address to its
address to its mining
to its mining rig
the mining rig obtains
mining rig obtains its
rig obtains its tasks
obtains its tasks from
its tasks from the
tasks from the pool
from the pool and
the pool and sends
pool and sends partial
and sends partial and
sends partial and full
partial and full proof
and full proof of
full proof of work
typically with the stratum
with the stratum protocol
as it finds blocks
the pool manager credits
pool manager credits the
manager credits the miner
way delivery latency against
credits the miner s
delivery latency against loss
the miner s account
latency against loss rate
miner s account according
s account according to
account according to its
according to its share
to its share of
its share of the
share of the work
adaptive remote procedure call
remote procedure call figure
and transfers these funds
transfers these funds either
these funds either on
funds either on request
either on request or
on request or automatically
request or automatically to
time series of wireless
or automatically to the
series of wireless bandwidth
automatically to the aforementioned
to the aforementioned bitcoin
the aforementioned bitcoin address
mafs uses adaptive remote
uses adaptive remote procedure
adaptive remote procedure call
remote procedure call for
too big pools despite
procedure call for client
big pools despite their
pools despite their important
despite their important role
their important role of
important role of enabling
role of enabling small
pools can constitute a
can constitute a threat
constitute a threat to
a threat to the
threat to the bitcoin
to the bitcoin system
adaptation based on low
the bitcoin system if
bitcoin system if their
system if their size
if their size is
their size is too
size is too large
if one pool controls
one pool controls the
pool controls the majority
controls the majority of
adaptive rpc is based
the majority of mining
rpc is based on
majority of mining power
is based on our
based on our earlier
on our earlier work
our earlier work in
earlier work in modes
work in modes can
the system becomes unstable
in modes can be
modes can be ill
suited to situations where
to situations where bandwidth
situations where bandwidth is
where bandwidth is not
bandwidth is not network
number of rpcs by
of rpcs by type
rpcs by type in
by type in bandwidth
type in bandwidth variability
in bandwidth variability test
and differs from severely
differs from severely constrained
the entries under p
entries under p denote
but insufficient for a
under p denote periods
insufficient for a client
p denote periods in
for a client to
denote periods in the
a client to ignore
periods in the test
client to ignore it
to ignore it a
ignore it a typical
it a typical rpc
a typical rpc system
typical rpc system in
rpc system in allowing
system in allowing applications
gives the abbreviations for
in allowing applications to
the abbreviations for rpc
allowing applications to control
warns that the system
applications to control how
abbreviations for rpc types
to control how concurrent
that the system is
control how concurrent rpcs
the system is unstable
how concurrent rpcs are
system is unstable with
concurrent rpcs are transmitted
is unstable with even
are likely to be
unstable with even smaller
likely to be beneficial
with even smaller pools
and special handling for
special handling for failwhen
the first would reduce
handling for failwhen deciding
first would reduce the
for failwhen deciding what
would reduce the aggressiveness
failwhen deciding what to
reduce the aggressiveness of
deciding what to send
the aggressiveness of prefetching
what to send over
to send over the
send over the network
in realistic scenarios of
realistic scenarios of the
scenarios of the bitcoin
ures due to insufficient
of the bitcoin system
due to insufficient bandwidth
the bitcoin system no
setting a byte threshold
bitcoin system no pool
system no pool controls
adaptive rpc requests and
no pool controls a
rpc requests and replies
pool controls a majority
requests and replies can
controls a majority of
from a file group
a majority of the
and replies can contain
a file group if
replies can contain an
majority of the mining
can contain an arbitrary
of the mining power
contain an arbitrary amount
file group if it
an arbitrary amount of
group if it appeared
arbitrary amount of data
if it appeared that
it appeared that a
appeared that a process
that a process was
a process was not
a sender also attaches
process was not using
for one day in
was not using the
one day in june
sender also attaches a
not using the files
also attaches a priority
using the files prefetched
attaches a priority and
the files prefetched based
a priority and timeout
files prefetched based on
priority and timeout to
prefetched based on its
and timeout to the
based on its prior
timeout to the send
on its prior accesses
to the send operation
this would reduce the
would reduce the overhead
reduce the overhead in
the overhead in the
a single pool called
overhead in the bad
single pool called ghash
in the bad groups
file system overview rover
the bad groups case
system overview rover queued
overview rover queued rpc
the second would explicitly
second would explicitly detect
would explicitly detect a
explicitly detect a fast
detect a fast linear
a fast linear scan
fast linear scan by
linear scan by a
scan by a process
of the blocks in
the blocks in the
blocks in the bitcoin
in the bitcoin main
an adaptive rpc can
the bitcoin main chain
adaptive rpc can be
by counting the instances
rpc can be asynchronous
counting the instances of
the instances of prefetch
instances of prefetch and
the bitcoin community backlashed
of prefetch and demand
bitcoin community backlashed at
prefetch and demand fetch
community backlashed at the
and demand fetch conflict
backlashed at the pool
demand fetch conflict for
fetch conflict for a
adaptive mobile file system
conflict for a file
for a file group
which has done nothing
has done nothing worse
is a distributed file
and then disable prefetching
done nothing worse than
then disable prefetching from
a distributed file sys
disable prefetching from the
nothing worse than being
prefetching from the group
worse than being extremely
than being extremely successful
so that an application
that an application need
an application need not
application need not block
need not block waiting
not block waiting for
block waiting for the
waiting for the result
io reduced its relative
intem designed to support
reduced its relative mining
prefetching and bandwidth variability
designed to support efficient
its relative mining power
to support efficient access
and bandwidth variability so
support efficient access to
bandwidth variability so far
efficient access to a
relative mining power and
access to a remote
mining power and publicly
to a remote file
power and publicly committed
a remote file server
and publicly committed to
our experimental results have
remote file server stead
publicly committed to stay
experimental results have demonstrated
committed to stay away
results have demonstrated the
to stay away from
have demonstrated the benefits
stay away from the
the library makes an
demonstrated the benefits of
library makes an upcall
the benefits of mfs
makes an upcall when
benefits of mfs adaptation
an upcall when the
of mfs adaptation mechanisms
upcall when the reply
mfs adaptation mechanisms at
when the reply arrives
adaptation mechanisms at various
mechanisms at various levels
at various levels of
various levels of bandwidth
levels of bandwidth availability
since an application can
an application can perform
application can perform multiple
can perform multiple rpcs
but not when the
perform multiple rpcs concurby
not when the bandwidth
multiple rpcs concurby mobile
when the bandwidth is
block withholding and its
the bandwidth is changing
withholding and its detection
bandwidth is changing over
and its detection classical
is changing over the
its detection classical block
changing over the duration
detection classical block withholding
rpcs concurby mobile clients
over the duration of
concurby mobile clients that
the duration of the
mobile clients that must
duration of the test
clients that must cope
that must cope with
must cope with variations
cope with variations in
with variations in available
variations in available bandwidth
to conclude this section
conclude this section we
this section we will
section we will describe
the mafs design and
we will describe an
is an attack performed
will describe an example
an attack performed by
mafs design and terminology
attack performed by a
design and terminology are
performed by a pool
and terminology are similar
by a pool member
terminology are similar to
describe an example of
are similar to rently
a pool member against
an example of mfs
pool member against the
example of mfs traffic
member against the other
of mfs traffic under
against the other pool
adaptive rpc schedules their
the other pool members
mfs traffic under the
rpc schedules their transmission
traffic under the execution
under the execution of
the execution of the
execution of the simultaneous
the attacking miner registers
this corresponds to allocating
of the simultaneous writeback
corresponds to allocating bandwidth
attacking miner registers with
to allocating bandwidth among
the simultaneous writeback test
miner registers with the
allocating bandwidth among the
simultaneous writeback test described
bandwidth among the competing
registers with the pool
among the competing rpcs
writeback test described in
with the pool and
test described in section
the pool and apparently
pool and apparently starts
and apparently starts mining
the andrew file system
apparently starts mining honestly
starts mining honestly it
mining honestly it regularly
honestly it regularly sends
it regularly sends the
regularly sends the pool
sends the pool partial
the pool partial proof
pool partial proof of
partial proof of work
this test involves two
test involves two simultaneous
involves two simultaneous workloads
the attacking miner sends
attacking miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
kb to the server
if it finds a
attaching priorities to rpcs
to the server and
priorities to rpcs allows
the server and the
it finds a full
server and the other
to rpcs allows applications
and the other reads
finds a full solution
rpcs allows applications to
a full solution that
allows applications to control
full solution that constitutes
applications to control this
solution that constitutes a
to control this scheduling
that constitutes a full
control this scheduling policy
constitutes a full proof
kb files from the
a full proof of
files from the server
full proof of work
proof of work it
of work it discards
a programmer divides rpcs
work it discards the
programmer divides rpcs into
it discards the solution
divides rpcs into classes
but is slightly modified
is slightly modified from
slightly modified from original
modified from original version
reducing the pool s
from original version to
the pool s total
original version to use
pool s total revenue
version to use a
to use a longer
use a longer think
a longer think time
longer think time of
file access model based
access model based on
model based on the
based on the importance
this attack is illustrated
on the importance of
attack is illustrated in
the importance of their
is illustrated in figure
importance of their results
of their results to
their results to the
results to the user
packet delivery latencies throughput
seconds when accessing each
and then mafs clients
the attacker does not
then mafs clients use
when accessing each file
mafs clients use whole
attacker does not change
does not change the
not change the pool
change the pool s
the pool s effective
improving the potential for
pool s effective mining
the potential for rpcs
s effective mining power
potential for rpcs to
for rpcs to overlap
when a file is
a file is accessed
file is accessed assigns
and does not affect
is accessed assigns priorities
does not affect directly
accessed assigns priorities to
not affect directly the
assigns priorities to the
affect directly the revenue
priorities to the classes
directly the revenue of
we enabled asynchronous writeback
the revenue of other
revenue of other pools
enabled asynchronous writeback and
asynchronous writeback and ran
the library schedules rpcs
writeback and ran the
library schedules rpcs for
and ran the test
schedules rpcs for the
ran the test with
rpcs for the first
the test with the
for the first time
test with the synthetic
the attacked pool shares
with the synthetic bandwidth
attacked pool shares its
the synthetic bandwidth trace
pool shares its revenue
synthetic bandwidth trace shown
shares its revenue with
bandwidth trace shown in
its revenue with the
trace shown in figure
revenue with the attacker
a client fetches the
client fetches the entire
fetches the entire file
the entire file from
therefore each miner earns
entire file from the
each miner earns less
file from the file
from the file based
the file based on
file based on priorities
as the same revenue
based on priorities whenever
the same revenue is
on priorities whenever there
same revenue is distributed
priorities whenever there is
revenue is distributed among
which changes the bandwidth
is distributed among more
whenever there is insufficient
distributed among more miners
changes the bandwidth once
there is insufficient bandwidth
the bandwidth once per
is insufficient bandwidth to
bandwidth once per second
insufficient bandwidth to server
bandwidth to server and
recall that the proof
to server and caches
that the proof of
server and caches it
mbps flow alongside on
the proof of work
flow alongside on the
proof of work is
alongside on the same
of work is only
on the same link
work is only valid
the same link to
is only valid for
same link to simulate
only valid for a
link to simulate a
valid for a specific
to simulate a real
mafs only sends the
this has three sections
only sends the server
for a specific block
sends the server the
time stream combined with
the server the contents
a brief period when
stream combined with other
brief period when the
combined with other inter
period when the bandwidth
as it is the
server the contents transmit
it is the nonce
the contents transmit competing
is the nonce with
contents transmit competing rpcs
when the bandwidth is
transmit competing rpcs without
the nonce with which
competing rpcs without a
the bandwidth is at
nonce with which the
rpcs without a noticeable
with which the block
without a noticeable delay
which the block s
the block s hash
block s hash is
s hash is smaller
hash is smaller than
is smaller than its
rpcs of a modified
smaller than its target
of a modified file
a modified file when
modified file when it
file when it is
when it is closed
it is closed by
the attacking miner cannot
is closed by an
attacking miner cannot use
shows the average delivery
miner cannot use it
the average delivery latency
closed by an application
average delivery latency of
a gradual decrease to
this is from higher
although the term block
the term block withholding
level packets in the
term block withholding has
priority classes are performed
block withholding has become
classes are performed first
withholding has become canonical
and rpcs of referred
rpcs of referred to
note that the block
of referred to as
s over the course
referred to as writeback
over the course of
that the block is
the course of ten
the block is discarded
course of ten seconds
block is discarded and
is discarded and never
as loss rates go
discarded and never introduced
loss rates go up
and never introduced into
and then the maintenance
never introduced into the
then the maintenance of
introduced into the system
the maintenance of the
into the system as
the system as the
directory operations cache equal
system as the name
operations cache equal priority
as the name block
cache equal priority are
the name block withholding
equal priority are performed
name block withholding implies
priority are performed in
are performed in parallel
this ensures that the
ensures that the directory
that the directory contents
miners miners miners pool
s rate until the
the directory contents and
rate until the end
directory contents and apply
until the end of
contents and apply changes
the end of the
and apply changes locally
end of the test
shows the same scenario
as well as mak
the same scenario with
classical block withholding attack
same scenario with a
scenario with a constant
with a constant uniformly
a constant uniformly random
application adapts itself to
constant uniformly random loss
a group of miners
uniformly random loss rate
group of miners attack
random loss rate of
of miners attack pool
adapts itself to the
itself to the available
to the available bandwidth
summary of results the
the available bandwidth gracefully
of results the test
results the test was
with a block withholding
the test was executed
a block withholding attack
test was executed once
was executed once with
ing an rpc to
executed once with prefetching
an rpc to apply
once with prefetching enabled
rpc to apply the
to apply the changes
denoted by a dashed
apply the changes to
by a dashed red
the changes to the
a dashed red arrow
changes to the server
and despite the simplicity
to the server s
despite the simplicity of
the server s copy
the simplicity of the
simplicity of the mfs
of the mfs prefetching
the mfs prefetching implementation
whole since lower bandwidth
maelstrom s delivery latency
this attack reduces the
s delivery latency is
since lower bandwidth translates
delivery latency is almost
attack reduces the attacker
lower bandwidth translates into
latency is almost exactly
once with no prefetching
is almost exactly equal
bandwidth translates into longer
almost exactly equal to
reduces the attacker s
translates into longer delays
exactly equal to the
into longer delays for
and the rpcs were
longer delays for lowerfile
the rpcs were then
delays for lowerfile caching
rpcs were then divided
for lowerfile caching is
the attacker s revenue
lowerfile caching is effective
were then divided acwe
caching is effective if
attacker s revenue compared
is effective if a
s revenue compared to
effective if a client
then divided acwe have
if a client s
revenue compared to solo
equal to the one
compared to solo mining
a client s connectivity
to solo mining or
client s connectivity is
solo mining or honest
s connectivity is uncertain
mining or honest pool
divided acwe have shown
way latency on the
acwe have shown that
latency on the link
have shown that workloads
or honest pool participation
shown that workloads which
that workloads which are
workloads which are amenable
which are amenable to
are amenable to file
rpc timeouts allow the
it suffers from the
timeouts allow the application
suffers from the reduced
ip takes more than
from the reduced revenue
takes more than twice
the reduced revenue like
more than twice as
reduced revenue like the
than twice as long
allow the application to
level cording to which
revenue like the other
cording to which period
like the other pool
to which period of
the other pool participants
twice as long once
the application to prevent
which period of the
application to prevent since
period of the trace
as long once one
of the trace they
to prevent since the
the trace they terminated
and its revenue is
prevent since the client
its revenue is less
since the client can
way latencies go past
revenue is less than
trace they terminated in
is less than its
the client can always
less than its share
client can always use
than its share of
can always use cached
its share of the
always use cached copies
share of the total
use cached copies of
of the total mining
cached copies of files
for each prefetching can
the total mining power
each prefetching can achieve
total mining power in
prefetching can achieve speedups
mining power in the
can achieve speedups of
power in the system
copies of files instead
of files instead low
this attack can therefore
attack can therefore only
priority rpcs being silently
can therefore only be
rpcs being silently starved
therefore only be used
only be used for
be used for sabotage
using priorities alof incrementally
priorities alof incrementally fetching
at a cost to
alof incrementally fetching them
a cost to the
incrementally fetching them from
cost to the attacker
fetching them from the
them from the server
four quantities are calculated
the time spent queued
time spent queued for
spent queued for as
even if a pool
queued for as much
lows a programmer to
for as much as
if a pool detects
a programmer to write
a pool detects that
programmer to write an
pool detects that it
to write an adaptive
detects that it is
write an adaptive application
that it is under
an adaptive application without
it is under a
adaptive application without ports
is under a block
application without ports this
under a block withholding
without ports this type
a block withholding attack
ports this type of
at bandwidths as low
this type of disconnected
bandwidths as low as
type of disconnected operation
ip one way link
one way link latency
it might not be
might not be able
not be able to
be able to detect
able to detect which
to detect which of
detect which of its
which of its registered
of its registered miners
its registered miners are
registered miners are the
miners are the perpetrators
prefetching both the rpc
but not to the
both the rpc request
not to the ex
the rpc request and
a pool can estimate
rpc request and reply
pool can estimate its
can estimate its expected
having to take account
estimate its expected mining
to take account of
and the time taken
its expected mining power
the time taken for
take account of the
time taken for each
expected mining power and
taken for each to
account of the actual
for each to be
mining power and its
each to be carries
of the actual bandwidth
to be carries a
power and its actual
be carries a small
the actual bandwidth or
and its actual mining
carries a small performance
actual bandwidth or current
a small performance overhead
its actual mining power
bandwidth or current mix
split with regular buffers
actual mining power by
or current mix tent
mining power by the
current mix tent of
even when performed at
power by the rates
when performed at received
mix tent of automatic
by the rates of
tent of automatic reconciliation
the rates of partial
of automatic reconciliation of
rates of partial proofs
automatic reconciliation of update
of partial proofs of
reconciliation of update conflicts
partial proofs of work
from the first to
proofs of work and
the first to the
of work and full
first to the last
work and full proofs
to the last packet
and full proofs of
full proofs of work
end with large buffers
this ignores the time
ignores the time the
the time the lowest
time the lowest priority
supplied by its miners
which can reduce its
can reduce its effectiveness
reduce its effectiveness for
its effectiveness for fast
on of rpcs at
a difference above a
of rpcs at runtime
effectiveness for fast lin
and outperforms it with
difference above a set
outperforms it with regular
above a set confidence
it with regular buffers
a set confidence interval
set confidence interval indicates
and avoid having to
confidence interval indicates an
spent at the server
interval indicates an attack
avoid having to specify
at the server servicing
having to specify thresholds
the server servicing the
to specify thresholds at
server servicing the rpc
specify thresholds at the
thresholds at the other
to detect whether a
at the other hand
detect whether a single
whether a single miner
a single miner is
single miner is attacking
miner is attacking it
latency metrics to measure
trip time ear scan
metrics to measure the
time ear scan workloads
to measure the latency
measure the latency effects
the pool must use
level caching reduces the
pool must use a
the latency effects of
must use a similar
caching reduces the delay
use a similar technique
it is possible to
latency effects of tcp
reduces the delay incurred
is possible to construct
the delay incurred which
possible to construct combination
delay incurred which it
comparing the estimated mining
incurred which it should
to construct combination of
the estimated mining power
construct combination of file
which it should switch
estimated mining power of
it should switch communication
combination of file between
should switch communication modes
mining power of the
of file between the
power of the attacker
file between the client
of the attacker based
between the client and
the attacker based on
the client and the
an rpc whose results
attacker based on its
client and the server
rpc whose results are
based on its partial
mbps stream between two
whose results are urgently
stream between two nodes
on its partial proof
between two nodes over
results are urgently required
two nodes over a
but these quantities are
its partial proof of
are urgently required should
these quantities are small
partial proof of work
urgently required should be
quantities are small groups
required should be aswhen
proof of work with
should be aswhen an
are small groups and
be aswhen an application
of work with the
aswhen an application opens
small groups and a
an application opens a
work with the fact
application opens a file
groups and a workload
with the fact it
and a workload for
the fact it never
a workload for which
fact it never supplies
workload for which prefetching
it never supplies a
for which prefetching can
never supplies a full
which prefetching can significantly
supplies a full proof
prefetching can significantly compared
as has been shown
can significantly compared to
has been shown in
significantly compared to the
been shown in the
compared to the other
a full proof of
to the other costs
full proof of work
shown in the low
these values are added
if the attacker has
values are added up
the attacker has a
are added up for
attacker has a small
added up for each
plots delivery latency against
has a small mining
delivery latency against message
a small mining power
latency against message identifier
up for each degrade
for each degrade performance
it will send frequent
a key point is
will send frequent partial
key point is that
send frequent partial proofs
of the rpcs within
frequent partial proofs of
the rpcs within a
partial proofs of work
point is that we
rpcs within a particular
is that we are
within a particular period
that we are plotting
we are plotting the
it is possible to
are plotting the delivery
is possible to use
plotting the delivery latency
but the pool will
the delivery latency of
and the results are
delivery latency of all
possible to use a
the results are shown
to use a signed
results are shown within
use a signed the
the pool will only
latency of all packets
are shown within the
a signed the highest
pool will only expect
shown within the constraints
will only expect to
within the constraints imposed
signed the highest priority
the constraints imposed by
only expect to see
constraints imposed by our
not just lost ones
expect to see a
imposed by our file
to see a full
by our file group
see a full proof
particularly if the rpc
a full proof of
if the rpc contains
full proof of work
the rpc contains outcontent
proof of work at
our file group representa
the spikes in latency
of work at very
spikes in latency are
work at very low
based division of files
in latency are triggered
division of files into
at very low frequency
of files into blocks
latency are triggered by
files into blocks as
are triggered by losses
into blocks as the
triggered by losses that
blocks as the basis
by losses that lead
as the basis for
losses that lead to
the basis for re
that lead to packets
lead to packets piling
it cannot obtain statistically
to packets piling up
cannot obtain statistically significant
packets piling up both
obtain statistically significant results
piling up both at
statistically significant results that
up both at the
significant results that would
both at the receiver
results that would indicate
at the receiver and
that would indicate an
the receiver and the
would indicate an attack
receiver and the sender
an attacker can use
attacker can use multiple
but still important rpcs
can use multiple small
still important rpcs can
use multiple small block
important rpcs can ducing
multiple small block withholding
rpcs can ducing client
ip delays correctly received
small block withholding miners
delays correctly received packets
block withholding miners and
correctly received packets at
withholding miners and replace
received packets at the
miners and replace them
packets at the receiver
and replace them frequently
at the receiver while
the receiver while waiting
receiver while waiting for
while waiting for missing
waiting for missing packets
a small miner is
for missing packets sequenced
missing packets sequenced earlier
packets sequenced earlier by
sequenced earlier by the
earlier by the sender
the main conclusion we
while the lowest levels
a miners whose expected
it also delays packets
miners whose expected full
the lowest levels are
whose expected full proof
also delays packets at
expected full proof of
lowest levels are useful
delays packets at the
full proof of work
levels are useful for
packets at the sender
main conclusion we draw
are useful for server
at the sender when
proof of work frequency
useful for server traffic
the sender when it
of work frequency is
conclusion we draw from
work frequency is yearly
sender when it cuts
we draw from the
for server traffic does
draw from the test
server traffic does not
such a miner will
when it cuts down
from the test cases
it cuts down on
a miner will see
the test cases exhibitthe
miner will see a
traffic does not eliminate
cuts down on the
does not eliminate the
test cases exhibitthe graphs
not eliminate the fundamental
down on the sending
eliminate the fundamental problem
on the sending window
the fundamental problem of
the sending window size
fundamental problem of rpcs
sending window size in
problem of rpcs that
window size in response
of rpcs that can
size in response to
rpcs that can be
in response to the
that can be arbitrarily
response to the loss
can be arbitrarily delayed
to the loss events
will see a non
cases exhibitthe graphs show
exhibitthe graphs show how
such as speculative activities
the delays caused by
graphs show how priorities
delays caused by these
negligible average daily revenue
caused by these two
show how priorities affect
by these two mechanisms
as speculative activities like
how priorities affect rpcs
these two mechanisms are
speculative activities like prefetching
two mechanisms are illustrated
priorities affect rpcs and
mechanisms are illustrated in
activities like prefetching and
are illustrated in figure
affect rpcs and how
like prefetching and transferring
rpcs and how prefetching
prefetching and transferring archival
and how prefetching a
and transferring archival data
how prefetching a prefetch
prefetching a prefetch penalty
a prefetch penalty is
prefetch penalty is that
penalty is that the
if the inicontention for
is that the implementation
the inicontention for insufficient
that the implementation could
inicontention for insufficient bandwidth
the implementation could be
where single packet losses
implementation could be im
single packet losses cause
packet losses cause spikes
losses cause spikes in
tial assumption regarding the
cause spikes in delivery
assumption regarding the correct
spikes in delivery latency
ing changes mfs behaviour
in delivery latency that
regarding the correct priority
delivery latency that last
the correct priority level
latency that last for
correct priority level for
that last for hundreds
priority level for an
in all three time
last for hundreds of
all three time periods
level for an rpc
for hundreds of packets
for an rpc proves
an rpc proves incorrect
more time proved to
time proved to incorporate
the maelstrom configuration used
proved to incorporate a
maelstrom configuration used is
to incorporate a mechanism
configuration used is r
a call to the
incorporate a mechanism to
call to the library
a mechanism to inhibit
to the library can
mechanism to inhibit prefetching
the library can be
library can be made
can be made to
be made to assign
made to assign a
if the attacker replaces
the attacker replaces such
the is spent on
attacker replaces such a
replaces such a small
is spent on rpcs
such a small miner
spent on rpcs to
a small miner every
on rpcs to fetch
small miner every month
rpcs to fetch file
to fetch file attributes
fetch file attributes with
file attributes with prefetching
he will collect about
will collect about b
attributes with prefetching enabled
client cache consistency new
with prefetching enabled current
cache consistency new priority
prefetching enabled current prefetching
at the end of
enabled current prefetching algorithm
the end of each
current prefetching algorithm does
end of each month
prefetching algorithm does not
when a client fetches
algorithm does not correlate
a client fetches a
does not correlate file
client fetches a file
not correlate file accesses
the pool must decide
correlate file accesses with
pool must decide within
file accesses with than
must decide within this
accesses with than without
decide within this month
the file server grants
within this month whether
file server grants it
this month whether the
server grants it permission
month whether the miner
grants it permission to
whether the miner is
since the time to
the miner is an
it permission to cache
miner is an attacker
the time to receive
permission to cache the
time to receive a
to cache the file
to receive a fetch
cache the file for
the file for a
and revoke its earnings
file for a limited
for a limited period
attributes request the processes
request the processes which
the processes which make
processes which make them
and adds it to
adds it to a
it to a list
or just an unlucky
just an unlucky honest
but if this were
an unlucky honest miner
if this were done
two changes or reply
since an honest miner
changes or reply is
an honest miner of
or reply is negligible
honest miner of this
implementation of clients that
miner of this power
of clients that cache
of this power is
clients that cache the
this power is unlikely
the increased time is
power is unlikely to
increased time is due
that cache the file
time is due to
is unlikely to find
is due to a
unlikely to find a
due to a greater
to find a full
to a greater queue
find a full proof
if the client modifies
a full proof of
the client modifies and
full proof of work
client modifies and then
proof of work within
modifies and then closes
of work within a
and then closes the
work within a month
then closes the file
rpc times at intermediate
times at intermediate bandwidth
it transmits the new
transmits the new contents
the new contents to
new contents to the
contents to the server
according to the exponential
which mafs is implemented
to the exponential distribution
mafs is implemented in
is implemented in c
implemented in c on
in c on freebsd
a pool that rejects
pool that rejects miners
that rejects miners based
the client is a
rejects miners based on
client is a usermakes
miners based on this
is a usermakes a
based on this criterion
a usermakes a callback
on this criterion would
usermakes a callback rpc
this criterion would reject
a callback rpc to
criterion would reject the
callback rpc to any
would reject the majority
rpc to any other
reject the majority of
to any other clients
the majority of its
any other clients on
majority of its honest
other clients on the
of its honest miners
clients on the list
a client level process
the alternative of rejecting
client level process that
alternative of rejecting small
level process that stores
of rejecting small miners
process that stores cached
rejecting small miners in
that stores cached files
small miners in general
stores cached files in
miners in general or
cached files in a
in general or distributing
files in a local
general or distributing revenue
in a local filesystem
or distributing revenue on
distributing revenue on a
revenue on a yearly
on a yearly basis
a yearly basis contradicts
the that receives a
yearly basis contradicts the
that receives a callback
basis contradicts the goal
receives a callback rpc
contradicts the goal of
a callback rpc discards
the goal of pooled
callback rpc discards its
goal of pooled mining
rpc discards its cached
discards its cached copy
its cached copy of
cached copy of the
copy of the file
server also stores its
m odel and s
also stores its copies
odel and s tandard
stores its copies of
and s tandard o
its copies of files
s tandard o peration
copies of files in
tandard o peration we
of files in a
o peration we specify
files in a local
peration we specify the
in a local filesystem
we specify the basic
specify the basic model
the basic model in
basic model in which
model in which participants
in which participants operate
which participants operate in
participants operate in section
operate in section iii
if an application has
an application has the
application has the file
has the file open
the file open when
file open when its
open when its client
when its client re
proceed to describe how
to describe how honest
describe how honest miners
system operations from applications
how honest miners operate
operations from applications are
honest miners operate in
from applications are redirected
miners operate in this
applications are redirected to
operate in this environment
are redirected to user
in this environment in
redirected to user level
this environment in sections
to user level ceives
environment in sections iii
user level ceives the
level ceives the callback
the file is discarded
file is discarded once
is discarded once it
discarded once it is
once it is closed
and how the classical
how the classical block
when through a kernel
the classical block withholding
through a kernel module
classical block withholding attack
a kernel module at
block withholding attack is
kernel module at the
withholding attack is implemented
module at the client
attack is implemented with
is implemented with our
implemented with our model
with our model in
our model in section
model in section iii
fetch prefetch metadata store
prefetch metadata store fetch
model the system is
metadata store fetch file
the system is comprised
store fetch file attributes
system is comprised of
is comprised of the
comprised of the bitcoin
of the bitcoin network
the bitcoin network and
bitcoin network and nodes
network and nodes with
and nodes with unique
nodes with unique ids
pull file update fetch
file update fetch file
update fetch file data
and progresses in steps
a node i generates
node i generates tasks
i generates tasks which
generates tasks which are
tasks which are associated
which are associated with
prefetch file data lock
are associated with its
file data lock a
associated with its id
data lock a file
with its id i
a node can work
node can work on
can work on a
work on a task
most metadata rpcs store
on a task for
metadata rpcs store file
a task for the
rpcs store file data
task for the duration
for the duration of
the duration of a
duration of a step
unlink file such as
file such as deleting
such as deleting a
as deleting a modified
deleting a modified file
the result of this
result of this work
of this work is
this work is a
work is a set
such optimisations can be
is a set of
optimisations can be effective
a set of partial
can be effective at
u trsu t u
be effective at low
trsu t u trsu
effective at low bandwidth
t u trsu t
set of partial proofs
u trsu t utrsut
of partial proofs of
partial proofs of work
proofs of work and
when there is a
of work and a
there is a natural
work and a set
is a natural delay
and a set of
request queued request send
a set of full
set of full proofs
queued request send reply
percentage of packets recovered
of full proofs of
but at high bandwidth
request send reply queued
full proofs of work
send reply queued reply
reply queued reply send
an artificial delay in
the number of proofs
artificial delay in writing
number of proofs in
delay in writing back
of proofs in each
in writing back updates
proofs in each set
writing back updates introduces
in each set has
back updates introduces inconsistencies
each set has a
updates introduces inconsistencies between
set has a poisson
introduces inconsistencies between the
has a poisson distribution
inconsistencies between the client
between the client and
the client and the
client and the file
and the file server
partial proofs with a
proofs with a large
with a large mean
a large mean and
this can be acceptable
large mean and full
can be acceptable at
mean and full proofs
be acceptable at low
and full proofs with
acceptable at low bandwidths
full proofs with a
proofs with a small
with a small mean
relatively prime interleaves offer
when the user may
prime interleaves offer better
the user may table
interleaves offer better performance
nodes that work on
that work on tasks
work on tasks are
on tasks are called
tasks are called a
are called a miners
priorities for mafs remote
miners have identical power
for mafs remote procedure
mafs remote procedure calls
and hence identical probabilities
hence identical probabilities to
be grateful to be
identical probabilities to generate
grateful to be able
probabilities to generate proofs
to be able to
to generate proofs of
be able to use
generate proofs of work
able to use the
to use the file
use the file system
the file system at
file system at all
the bitcoin network pays
bitcoin network pays for
network pays for full
pays for full proofs
for full proofs of
but should be avoided
full proofs of work
should be avoided when
be avoided when bandwidth
avoided when bandwidth is
when bandwidth is unconstrained
to acquire this payoff
acquire this payoff an
this payoff an entity
payoff an entity publishes
an entity publishes a
entity publishes a task
publishes a task task
a task task and
task task and its
task and its corresponding
and its corresponding proof
its corresponding proof of
corresponding proof of work
proof of work to
of work to the
mafs avoids the need
work to the network
avoids the need for
the need for modes
need for modes by
for modes by using
the payoff goes to
modes by using asynchronous
payoff goes to the
by using asynchronous remote
goes to the id
using asynchronous remote procedure
to the id associated
asynchronous remote procedure calls
the id associated with
remote procedure calls between
id associated with task
procedure calls between a
calls between a client
between a client and
a client and the
client and the file
and the file server
the bitcoin protocol normalizes
the file server writeback
file server writeback at
bitcoin protocol normalizes revenue
server writeback at all
writeback at all bandwidth
protocol normalizes revenue such
at all bandwidth levels
normalizes revenue such that
revenue such that the
such that the average
that the average total
and incorporates a new
the average total revenue
incorporates a new upare
average total revenue distributed
a new upare divided
total revenue distributed in
new upare divided into
revenue distributed in each
upare divided into several
distributed in each step
divided into several types
in each step is
into several types depending
each step is a
several types depending on
step is a constant
types depending on their
is a constant throughout
depending on their function
a constant throughout the
constant throughout the execution
throughout the execution of
the execution of the
execution of the system
rpcs date propagation algorithm
date propagation algorithm to
propagation algorithm to reduce
algorithm to reduce the
any node can transact
to reduce the possibility
node can transact bitcoins
reduce the possibility of
can transact bitcoins to
the possibility of inconsisto
transact bitcoins to another
possibility of inconsisto fetch
bitcoins to another node
of inconsisto fetch and
to another node by
inconsisto fetch and store
another node by issuing
fetch and store data
node by issuing a
and store data are
by issuing a bitcoin
rpc times at high
issuing a bitcoin transaction
store data are self
times at high bandwidth
nodes that generate tasks
that generate tasks but
generate tasks but outsource
tasks but outsource the
but outsource the work
outsource the work are
the work are called
work are called pools
pools send tasks to
send tasks to miners
tasks to miners over
to miners over the
miners over the network
the miners receive the
miners receive the tasks
as new operations are
new operations are added
operations are added to
are added to the
added to the tail
to the tail tions
the tail tions include
tail tions include fetching
tions include fetching and
and send the partial
include fetching and setting
send the partial and
fetching and setting file
the partial and full
and setting file attributes
partial and full proofs
and full proofs of
full proofs of work
proofs of work to
of work to the
work to the pool
and directory of the
directory of the log
apart from working on
from working on tasks
the client flushes operations
client flushes operations serially
flushes operations serially from
operations serially from the
serially from the head
from the head of
the head of operations
head of operations such
of operations such as
operations such as creating
such as creating and
as creating and unlinking
creating and unlinking files
control rpcs the log
and receipt are instantaneous
we assume that the
server traffic consists of
assume that the number
traffic consists of a
that the number of
consists of a variety
the number of miners
of a variety of
number of miners is
a variety of foreground
of miners is large
variety of foreground include
miners is large enough
of foreground include locking
is large enough such
foreground include locking files
large enough such that
include locking files and
enough such that mining
locking files and the
such that mining power
files and the server
that mining power can
and the server s
mining power can be
the server s callback
power can be split
server s callback to
can be split arbitrarily
s callback to invalidate
be split arbitrarily without
callback to invalidate a
split arbitrarily without resolution
to invalidate a rpcs
arbitrarily without resolution constraints
invalidate a rpcs for
a rpcs for control
rpcs for control operations
for control operations and
control operations and fetching
operations and fetching file
denote the number of
and fetching file data
the number of pools
number of pools with
of pools with p
and a stream client
a stream client s
the total number of
stream client s cached
total number of mining
client s cached copy
number of mining power
s cached copy of
of mining power in
cached copy of a
mining power in the
copy of a file
power in the system
in the system with
the system with m
system with m and
with m and the
of background rpcs for
m and the miners
background rpcs for logged
and the miners participating
rpcs for logged operations
the miners participating in
miners participating in pool
participating in pool i
when bandwidth is high
replayed logged operations complete
logged operations complete quickly
with little extra delay
we use a quasistatic
when bandwidth is low
use a quasistatic analysis
a quasistatic analysis where
quasistatic analysis where miner
analysis where miner participation
logged operations are de
where miner participation in
miner participation in a
participation in a pool
in a pool does
a pool does not
pool does not change
communication adaptation layed in
does not change over
adaptation layed in proportion
not change over time
layed in proportion to
in proportion to the
proportion to the foreground
to the foreground rpc
the foreground rpc traffic
foreground rpc traffic and
rpc traffic and the
traffic and the availto
solo mining a solo
and the availto reduce
mining a solo miner
the availto reduce its
a solo miner is
availto reduce its network
solo miner is a
reduce its network communication
miner is a node
its network communication when
is a node that
network communication when bandwidth
a node that generates
communication when bandwidth is
node that generates its
when bandwidth is low
that generates its own
generates its own tasks
in every step it
every step it generates
step it generates a
it generates a task
a mobile file system
mobile file system client
file system client can
system client can automatically
works on it for
client can automatically adapt
on it for the
can automatically adapt its
it for the duration
automatically adapt its communication
for the duration of
adapt its communication strategy
the duration of the
its communication strategy to
duration of the step
communication strategy to the
of the step and
strategy to the available
the step and if
to the available bandwidth
step and if it
and if it finds
if it finds a
it finds a full
finds a full proof
a full proof of
full proof of work
it publishes this proof
publishes this proof of
this proof of work
proof of work to
of work to earn
work to earn the
to earn the payoff
rpc priorities cations transfer
priorities cations transfer a
cations transfer a large
transfer a large volume
a large volume of
large volume of data
volume of data that
of data that the
pools a pool is
data that the user
a pool is a
that the user is
pool is a node
the user is unlikely
is a node that
user is unlikely to
a node that serves
is unlikely to require
node that serves as
unlikely to require immediately
that serves as a
serves as a coordinator
as a coordinator and
a coordinator and multiple
coordinator and multiple miners
consuming bandwidth that can
and multiple miners can
bandwidth that can be
multiple miners can register
layered interleaving recovery percentage
miners can register to
that can be used
can register to a
interleaving recovery percentage and
register to a pool
can be used mafs
to a pool and
recovery percentage and latency
a pool and work
be used mafs uses
pool and work for
percentage and latency c
used mafs uses priorities
and work for it
mafs uses priorities to
uses priorities to reduce
priorities to reduce contention
to reduce contention between
layered interleaving and bursty
reduce contention between foreground
interleaving and bursty loss
in every step it
contention between foreground for
and bursty loss thus
between foreground for important
every step it generates
foreground for important tasks
bursty loss thus far
step it generates a
loss thus far we
it generates a task
thus far we have
generates a task for
far we have shown
a task for each
we have shown how
task for each registered
have shown how maelstrom
for each registered miner
shown how maelstrom effectively
each registered miner and
how maelstrom effectively hides
registered miner and sends
maelstrom effectively hides loss
consider an application that
effectively hides loss from
miner and sends it
hides loss from tcp
an application that activities
and sends it over
application that activities and
sends it over the
that activities and deferrable
it over the network
activities and deferrable background
ip for packets dropped
and deferrable background activities
for packets dropped with
packets dropped with uniform
dropped with uniform randomness
each miner receives its
miner receives its task
adaptive rpc fetches images
receives its task and
rpc fetches images from
its task and works
fetches images from a
task and works on
images from a file
and works on it
from a file server
we examine the performance
works on it for
examine the performance of
on it for the
the performance of the
it for the duration
performance of the layered
for the duration of
processes each in turn
the duration of the
of the layered interleaving
duration of the step
the layered interleaving algorithm
at the end of
showing how different parameterizations
the end of the
how different parameterizations handle
preferentially allocates bandwidth to
different parameterizations handle bursty
allocates bandwidth to foreground
parameterizations handle bursty loss
bandwidth to foreground rpcs
handle bursty loss patterns
end of the step
unlike plays the resulting
we use a loss
the miner sends the
plays the resulting image
use a loss model
miner sends the pool
a loss model where
sends the pool the
loss model where packets
and writes it to
model where packets are
writes it to the
the pool the full
it to the server
where packets are dropped
pool the full and
packets are dropped in
the full and the
are dropped in bursts
full and the partial
dropped in bursts of
and the partial proofs
in bursts of fixed
if the user little
bursts of fixed length
the user little work
the partial proofs of
partial proofs of work
proofs of work it
of work it has
work it has found
allowing us to study
us to study the
to study the impact
study the impact of
the impact of burst
the pool receives the
impact of burst length
pool receives the proofs
of burst length on
receives the proofs of
burst length on performance
the proofs of work
proofs of work of
of work of all
work of all its
of all its miners
which assigns a lower
the link has a
assigns a lower priority
link has a one
a lower priority to
lower priority to writeback
registers the partial proofs
priority to writeback in
the partial proofs of
to writeback in wants
partial proofs of work
writeback in wants to
proofs of work and
in wants to see
of work and publishes
wants to see the
work and publishes the
to see the processed
and publishes the full
see the processed images
publishes the full proofs
percentage of packets recovered
it calculates its overall
calculates its overall revenue
one else wants to
else wants to im
and proceeds to distribute
proceeds to distribute it
to distribute it among
distribute it among its
it among its miners
each miner receives revenue
miner receives revenue proportional
mafs has a finer
receives revenue proportional to
reed solomon layered interleaving
revenue proportional to its
proportional to its success
to its success in
its success in the
grained differentiation mediately read
success in the current
differentiation mediately read them
in the current step
writing the output back
namely the ratio of
the output back will
the ratio of its
output back will interfere
ratio of its partial
back will interfere with
of its partial proofs
will interfere with between
its partial proofs of
interfere with between rpcs
partial proofs of work
proofs of work out
of work out of
work out of all
out of all partial
and uses priorities at
of all partial proofs
uses priorities at all
all partial proofs of
priorities at all bandwidths
partial proofs of work
proofs of work the
of work the pool
work the pool received
this alfetching the next
alfetching the next image
we assume that pools
assume that pools do
and slow down the
that pools do not
slow down the application
pools do not collect
do not collect fees
not collect fees of
collect fees of the
fees of the revenue
lows control over bandwidth
control over bandwidth allocation
over bandwidth allocation at
pool fees and their
bandwidth allocation at the
fees and their implications
allocation at the level
and their implications on
at the level of
their implications on our
the level of individinterference
implications on our analysis
level of individinterference due
on our analysis are
of individinterference due to
our analysis are discussed
individinterference due to write
analysis are discussed in
due to write traffic
are discussed in section
to write traffic is
discussed in section ix
write traffic is often
traffic is often solved
is often solved by
often solved by writing
solved by writing ual
by writing ual rpcs
block withholding miner a
without requiring that an
withholding miner a miner
requiring that an mafs
miner a miner registered
that an mafs client
a miner registered at
an mafs client is
miner registered at a
mafs client is aware
registered at a pool
client is aware of
at a pool can
is aware of back
a pool can perform
aware of back updates
pool can perform the
of back updates asynchronously
can perform the classical
perform the classical block
the classical block withholding
classical block withholding attack
the application in our
application in our example
in our example the
our example the precise
example the precise bandwidth
an attacker miner operates
attacker miner operates as
miner operates as if
operates as if it
as if it worked
if it worked for
can start reading another
it worked for the
start reading another image
worked for the pool
reading another image without
another image without waiting
image without waiting for
without waiting for the
waiting for the previwhen
it receives its tasks
for the previwhen choosing
receives its tasks and
the previwhen choosing priorities
its tasks and works
tasks and works on
and works on them
automatic assignment and fine
assignment and fine ous
only at the end
and fine ous output
at the end of
fine ous output to
the end of each
ous output to be
end of each round
output to be sent
of each round it
to be sent to
solomon versus layered interleaving
each round it sends
be sent to the
round it sends only
sent to the file
it sends only its
to the file server
versus layered interleaving latency
sends only its partial
layered interleaving latency of
only its partial proofs
its partial proofs of
partial proofs of work
asynchronous writeback granularity are
writeback granularity are preferable
and omits full proofs
omits full proofs of
ms and a loss
full proofs of work
and a loss rate
proofs of work if
a loss rate of
of work if it
to avoid the need
work if it had
avoid the need for
if it had found
the need for user
it had found any
need for user intervenallows
for user intervenallows i
the pool registers the
o and cpu processing
pool registers the miner
and cpu processing to
registers the miner s
cpu processing to be
the miner s partial
processing to be overlapped
miner s partial proofs
but cannot distinguish between
cannot distinguish between miners
distinguish between miners running
between miners running honestly
tion and provide the
miners running honestly and
and provide the maximum
running honestly and block
provide the maximum degree
honestly and block withholding
the maximum degree of
and block withholding miners
maximum degree of differentiation
where it is varied
degree of differentiation among
of differentiation among ecution
differentiation among ecution time
among ecution time and
the implications are that
ecution time and utilising
implications are that a
time and utilising bandwidth
are that a miner
and utilising bandwidth more
that a miner that
utilising bandwidth more efficiently
a miner that engages
miner that engages in
that engages in block
engages in block withholding
in block withholding does
block withholding does not
mbps flow of udp
withholding does not contribute
flow of udp packets
does not contribute to
of udp packets is
not contribute to the
udp packets is sent
contribute to the pool
packets is sent over
to the pool s
is sent over it
the pool s overall
scheduling rpcs based on
pool s overall mining
rpcs based on priorities
s overall mining power
based on priorities is
on priorities is only
priorities is only ever
but still shares the
if bandwidth is low
still shares the pool
we show that our
shares the pool s
show that our observation
the pool s revenue
that our observation in
pool s revenue according
our observation in section
contention arises when files
observation in section iv
s revenue according to
arises when files are
revenue according to its
when files are being
according to its sent
files are being effective
to its sent partial
e is correct for
its sent partial proofs
is correct for high
sent partial proofs of
are being effective if
partial proofs of work
correct for high loss
being effective if concurrent
for high loss rates
effective if concurrent rpcs
high loss rates if
if concurrent rpcs usually
loss rates if the
to reason about a
rates if the interleaves
concurrent rpcs usually end
if the interleaves are
reason about a pool
the interleaves are relatively
rpcs usually end up
interleaves are relatively prime
about a pool s
usually end up with
a pool s efficiency
end up with different
pool s efficiency we
up with different prifetched
s efficiency we define
with different prifetched at
efficiency we define its
performance improves substantially when
we define its per
different prifetched at the
improves substantially when loss
prifetched at the same
substantially when loss rates
at the same time
when loss rates are
the same time as
loss rates are high
same time as updates
rates are high and
time as updates are
are high and losses
as updates are written
high and losses are
updates are written back
and losses are bursty
miner revenue as follows
the graph plots the
graph plots the percentage
plots the percentage of
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
packets successfully recovered on
but processes are too
successfully recovered on the
processes are too coarse
recovered on the y
grained for this purpose
axis against an xaxis
against an xaxis of
an xaxis of loss
the revenue density of
xaxis of loss rates
of loss rates on
tention can be mitigated
loss rates on a
revenue density of a
can be mitigated by
rates on a log
be mitigated by prioritising
on a log scale
density of a pool
mitigated by prioritising file
of a pool is
by prioritising file fetch
a pool is the
prioritising file fetch rpcs
the maelstrom configuration used
file fetch rpcs above
maelstrom configuration used is
fetch rpcs above file
configuration used is r
pool is the ratio
is the ratio between
the ratio between the
based priorities provide some
ratio between the average
priorities provide some more
between the average revenue
provide some more detail
the average revenue a
average revenue a pool
revenue a pool member
a pool member earns
but the imporwriteback rpcs
pool member earns and
the imporwriteback rpcs to
member earns and the
imporwriteback rpcs to ensure
earns and the average
rpcs to ensure that
and the average revenue
to ensure that they
the average revenue it
ensure that they will
average revenue it would
that they will be
revenue it would have
they will be preferentially
it would have earned
will be preferentially allo
would have earned as
have earned as a
earned as a solo
as a solo miner
tance of a file
of a file can
a file can be
file can be hard
the revenue density of
can be hard to
revenue density of a
be hard to determine
density of a solo
hard to determine automatically
of a solo miner
and that of a
that of a miner
of a miner working
a miner working with
miner working with an
working with an unattacked
with an unattacked pool
an unattacked pool are
unattacked pool are one
if a pool is
a pool is attacked
pool is attacked with
is attacked with block
files can be too
attacked with block withholding
can be too numerous
be too numerous for
too numerous for the
numerous for the user
for the user to
its revenue density decreases
the user to manually
user to manually assign
to manually assign priin
manually assign priin this
assign priin this section
we assess the effectiveness
continuous analysis because our
assess the effectiveness of
analysis because our analysis
the effectiveness of asynchronous
because our analysis will
effectiveness of asynchronous orities
our analysis will be
analysis will be of
will be of the
be of the average
of the average revenue
rpcs are more numerous
we will consider proofs
will consider proofs of
consider proofs of work
but priorities can be
priorities can be autowriteback
can be autowriteback and
both full and partial
be autowriteback and rpc
autowriteback and rpc priorities
and rpc priorities in
as continuous deterministic sizes
rpc priorities in mafs
priorities in mafs under
in mafs under different
mafs under different levels
according to their probability
under different levels matically
we show the ability
different levels matically assigned
show the ability of
levels matically assigned to
the ability of layered
matically assigned to them
ability of layered interleaving
assigned to them according
of layered interleaving to
to them according to
work on a task
them according to the
layered interleaving to provide
according to the operation
on a task therefore
interleaving to provide gracefully
a task therefore results
to provide gracefully degrading
to the operation the
provide gracefully degrading performance
task therefore results in
gracefully degrading performance in
therefore results in a
degrading performance in the
results in a deterministic
performance in the face
the operation the rpc
in the face of
in a deterministic fraction
the face of bursty
operation the rpc of
face of bursty loss
a deterministic fraction of
the rpc of bandwidth
deterministic fraction of proof
rpc of bandwidth availability
fraction of proof of
of proof of work
we plot the percentage
plot the percentage of
we examine the degree
examine the degree corresponds
t he p ool
the degree corresponds to
the percentage of lost
he p ool g
p ool g ame
percentage of lost packets
ool g ame a
of lost packets successfully
as shown in table
lost packets successfully recovered
packets successfully recovered against
successfully recovered against the
the pool block withholding
recovered against the length
pool block withholding attack
against the length of
block withholding attack just
the length of loss
withholding attack just as
length of loss bursts
attack just as a
of loss bursts for
just as a miner
loss bursts for two
as a miner can
bursts for two different
a miner can perform
or rpcs to which
miner can perform block
for two different sets
can perform block withholding
rpcs to which a
perform block withholding on
two different sets of
block withholding on a
different sets of interleaves
withholding on a pool
to which a file
on a pool j
which a file system
a file system client
file system client that
system client that avoids
and in the bottom
client that avoids switching
in the bottom graph
a pool i can
that avoids switching modes
the bottom graph we
avoids switching modes in
pool i can use
switching modes in re
bottom graph we plot
i can use some
graph we plot the
can use some of
we plot the average
use some of its
plot the average latency
that the user has
the average latency at
the user has to
some of its mining
user has to wait
average latency at which
of its mining power
has to wait for
latency at which the
its mining power to
at which the packets
mining power to infiltrate
which the packets were
power to infiltrate a
the packets were recovered
to infiltrate a pool
infiltrate a pool j
a pool j and
pool j and perform
j and perform a
recovery latency is defined
and perform a block
latency is defined as
or sponse to bandwidth
perform a block withholding
is defined as the
a block withholding attack
sponse to bandwidth changes
defined as the difference
block withholding attack on
to bandwidth changes is
withholding attack on j
as the difference between
bandwidth changes is able
the difference between the
changes is able to
difference between the eventual
is able to adapt
between the eventual delivery
able to adapt to
denote the amount of
to adapt to both
the eventual delivery time
adapt to both insufficient
the amount of such
to both insufficient rpcs
eventual delivery time of
both insufficient rpcs whose
amount of such infiltrating
insufficient rpcs whose results
delivery time of the
rpcs whose results can
of such infiltrating mining
whose results can be
time of the recovered
results can be delayed
such infiltrating mining power
of the recovered packet
infiltrating mining power at
request queued request send
mining power at step
the recovered packet and
power at step t
queued request send reply
such as writing back
at step t by
as writing back data
request send reply queued
writing back data bandwidth
step t by xi
recovered packet and the
send reply queued reply
packet and the oneway
reply queued reply send
and the oneway latency
the oneway latency of
and conditions under which
oneway latency of the
conditions under which bandwidth
latency of the link
under which bandwidth is
which bandwidth is plentiful
we confirmed that the
confirmed that the emulab
that the emulab link
the emulab link had
emulab link had almost
miners working for pool
link had almost no
working for pool i
had almost no jitter
e dd e dd
almost no jitter on
prefetching is an example
no jitter on correctly
is an example of
jitter on correctly delivered
an example of speculative
on correctly delivered packets
example of speculative communication
dd e dd f
either mining honestly or
e dd f edd
mining honestly or used
dd f edd f
honestly or used for
f edd f g
or used for infiltrating
edd f g fg
used for infiltrating pool
f g fg e
for infiltrating pool j
g fg e ed
way latency an accurate
fg e ed e
priority rpc whose results
e ed e e
latency an accurate estimate
ed e e d
an accurate estimate of
e e d f
accurate estimate of expected
e d f eed
estimate of expected lossless
d f eed f
of expected lossless delivery
f eed f g
expected lossless delivery time
eed f g fg
rpc whose results can
are loyal to pool
whose results can improve
loyal to pool i
results can improve performance
f g fg e
can improve performance if
g fg e d
improve performance if bandwidth
fg e d e
performance if bandwidth is
at the end of
if bandwidth is high
the end of a
e d e d
end of a round
increasing the interleaves results
d e d f
the interleaves results in
interleaves results in much
results in much higher
in much higher recovery
pool i aggregates its
much higher recovery percentages
i aggregates its revenue
higher recovery percentages at
aggregates its revenue from
recovery percentages at large
its revenue from mining
percentages at large burst
revenue from mining in
at large burst sizes
from mining in the
mining in the current
asynchronous writeback but can
in the current round
writeback but can be
the current round and
but can be safely
current round and from
can be safely omitted
round and from its
be safely omitted if
but comes at the
safely omitted if bandwidth
and from its infiltration
omitted if bandwidth is
from its infiltration in
if bandwidth is low
comes at the cost
its infiltration in the
at the cost of
infiltration in the previous
the cost of higher
in the previous round
cost of higher recovery
of higher recovery latency
it distributes the revenue
mafs asynchronous writeback is
distributes the revenue evenly
asynchronous writeback is based
the revenue evenly among
writeback is based on
revenue evenly among all
is based on similar
evenly among all its
based on similar mechanisms
among all its loyal
on similar mechanisms the
all its loyal miners
similar mechanisms the initial
its loyal miners according
mechanisms the initial priority
loyal miners according to
the initial priority is
miners according to their
initial priority is never
according to their partial
priority is never modified
to their partial proofs
their partial proofs of
partial proofs of work
but the file server
bcq pcb c bq
the file server somefound
pcb c bq pcb
the pool s miners
file server somefound in
c bq pcb cbqpcb
server somefound in many
pool s miners are
somefound in many mobile
bq pcb cbqpcb n
in many mobile file
s miners are oblivious
many mobile file systems
pcb cbqpcb n n
miners are oblivious to
cbqpcb n n on
are oblivious to their
n n on n
oblivious to their role
n on n c
to their role and
on n c bc
their role and they
n c bc bonn
role and they operate
c bc bonn c
and they operate as
bc bonn c bc
they operate as regular
bonn c bc b
operate as regular honest
c bc b cbcb
as regular honest miners
set of interleaves catches
of interleaves catches almost
interleaves catches almost all
catches almost all packets
almost all packets in
all packets in an
packets in an extended
in an extended burst
an extended burst of
rather than making times
revenue convergence note that
than making times requests
convergence note that pool
making times requests an
note that pool j
packets at an average
times requests an increase
at an average latency
that pool j sends
an average latency of
requests an increase in
average latency of around
pool j sends its
an increase in the
c bc b cbcb
j sends its revenue
increase in the priority
sends its revenue to
in the priority of
its revenue to infiltrators
the priority of an
revenue to infiltrators from
priority of an rpc
to infiltrators from pool
of an rpc to
infiltrators from pool i
an rpc to transmit
from pool i at
rpc to transmit an
while repairing all random
pool i at the
repairing all random singleton
i at the end
all random singleton losses
at the end of
random singleton losses within
the end of the
to transmit an rpc
end of the step
transmit an rpc when
an rpc when an
rpc when an application
when an application performs
an application performs a
application performs a metadata
and this revenue is
performs a metadata update
c bc b cbcb
a metadata update or
this revenue is calculated
metadata update or file
revenue is calculated in
update or file data
is calculated in pool
calculated in pool i
in pool i at
pool i at the
the graphs also show
i at the beginning
graphs also show recovery
at the beginning of
also show recovery latency
the beginning of the
show recovery latency rising
beginning of the subsequent
the operation is logged
of the subsequent step
operation is logged and
recovery latency rising gracefully
is logged and replayed
c bc b cbcb
logged and replayed to
latency rising gracefully with
and replayed to the
rising gracefully with the
if there is a
gracefully with the increase
there is a chain
with the increase in
is a chain of
the increase in loss
a chain of pools
increase in loss burst
chain of pools of
in loss burst length
of pools of length
replayed to the file
to the file server
the file server after
file server after a
server after a delay
the longer the burst
where each pool infiltrates
each pool infiltrates the
pool infiltrates the next
this scheme reduces bandwidth
the longer it takes
scheme reduces bandwidth utilisation
the pool revenue will
reduces bandwidth utilisation because
longer it takes to
c b cb a
it takes to recover
b cb a a
takes to recover the
cb a a k
pool revenue will not
a a k k
revenue will not be
a k k j
will not be static
k k j jk
bandwidth utilisation because some
to recover the lost
utilisation because some logged
recover the lost packets
because some logged operations
some logged operations may
since the revenue from
logged operations may be
the revenue from infiltration
operations may be superceded
revenue from infiltration takes
may be superceded by
the maelstrom configuration used
be superceded by later
maelstrom configuration used is
superceded by later ones
configuration used is r
from infiltration takes one
c bc b cbcb
infiltration takes one step
bc b cbcb kk
takes one step to
b cbcb kk j
one step to take
cbcb kk j m
step to take each
kk j m lkjj
to take each hop
j m lkjj ml
m lkjj ml ml
lkjj ml ml c
ml ml c b
ml c b c
c b c b
b c b cb
c b cb kj
b cb kj ih
cb kj ih i
max is the longest
kj ih i h
is the longest chain
ih i h ih
the longest chain in
i h ih j
longest chain in the
chain in the system
the revenue stabilizes after
if there are loops
there are loops in
are loops in the
loops in the infiltration
in the infiltration graph
the system will converge
system will converge to
will converge to a
converge to a certain
to a certain revenue
as stated in the
stated in the following
in the following lemma
c bc b c
bc b c bc
b c bc b
c bc b cbcb
bc b cbcb rpc
b cbcb rpc times
cbcb rpc times at
rpc times at low
times at low bandwidth
if infiltration rates are
infiltration rates are constant
request queued request send
queued request send reply
request send reply queued
send reply queued reply
reply queued reply send
the pool revenues converge
queued reply send total
reply send total time
denote the revenue density
the revenue density of
revenue density of pool
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the end of step
end of step t
of step t by
step t by ri
we show histograms of
show histograms of recovery
histograms of recovery latencies
of recovery latencies for
recovery latencies for the
latencies for the two
for the two interleave
and define the revenue
the two interleave configurations
define the revenue density
two interleave configurations under
the revenue density vector
interleave configurations under different
revenue density vector r
configurations under different burst
under different burst lengths
the histograms confirm the
histograms confirm the trends
confirm the trends described
the trends described above
packet recoveries take longer
recoveries take longer from
take longer from left
longer from left to
from left to right
left to right as
to right as we
right as we increase
as we increase loss
we increase loss burst
increase loss burst length
and from top to
from top to bottom
top to bottom as
to bottom as we
bottom as we increase
as we increase the
we increase the interleave
increase the interleave values
illustrates the difference between
the difference between a
difference between a traditional
between a traditional fec
a traditional fec code
traditional fec code and
fec code and layered
code and layered interleaving
and layered interleaving by
layered interleaving by plotting
interleaving by plotting a
rpc traffic with varying
traffic with varying bandwidth
p in every round
pool i uses its
i uses its mining
uses its mining power
its mining power of
mining power of m
j used for direct
used for direct mining
for direct mining p
show the time spent
the time spent on
time spent on rpcs
spent on rpcs during
and shares it among
on rpcs during an
shares it among its
rpcs during an execution
it among its m
during an execution of
an execution of the
execution of the simultaneous
of the simultaneous writeback
the simultaneous writeback test
simultaneous writeback test from
writeback test from section
with the bandwidth varying
the bandwidth varying according
all sums are over
bandwidth varying according to
sums are over the
varying according to the
are over the range
according to the curve
to the curve in
rpcs are labelled as
are labelled as follows
writes execution time speedup
denote the direct mining
the direct mining revenue
direct mining revenue density
mining revenue density of
revenue density of each
density of each pool
which is a constant
is a constant factor
demand fetch to raise
fetch to raise priority
to raise priority of
raise priority of a
priority of a prefetch
of a prefetch rpc
execution time speedup execution
time speedup execution time
speedup execution time speedup
execution time speedup execution
time speedup execution time
speedup execution time speedup
execution time speedup no
time speedup no priorities
the time spent on
time spent on rpcs
spent on rpcs is
on rpcs is shown
rpcs is shown with
is shown with prefetching
shown with prefetching enabled
note that rpc interactions
that rpc interactions can
rpc interactions can overlap
interactions can overlap so
can overlap so the
overlap so the quantities
so the quantities for
the quantities for different
quantities for different rpc
p the revenue of
for different rpc types
the revenue of pool
different rpc types are
revenue of pool i
rpc types are not
of pool i in
types are not additive
pool i in step
i in step t
in step t taken
step t taken through
for some rpc types
t taken through infiltration
taken through infiltration from
through infiltration from pool
infiltration from pool j
from pool j s
the time spent on
pool j s revenue
time spent on particular
j s revenue in
spent on particular activities
s revenue in step
on particular activities is
revenue in step t
particular activities is negligible
activities is negligible in
is negligible in proportion
negligible in proportion to
in proportion to the
proportion to the overall
to the overall time
attribute requests are small
requests are small and
are small and have
small and have a
and have a very
have a very low
pool i distributes this
a very low transmission
i distributes this revenue
very low transmission time
distributes this revenue among
low transmission time relative
this revenue among its
transmission time relative to
revenue among its mi
time relative to their
relative to their queueing
to their queueing delays
such users happen to
users happen to be
i members loyal and
happen to be working
members loyal and infiltrators
to be working on
be working on the
working on the same
on the same element
the same element of
same element of the
define the p p
element of the design
the p p infiltration
p p infiltration matrix
p infiltration matrix by
infiltration matrix by its
matrix by its i
it is clear that
is clear that satisfying
clear that satisfying a
that satisfying a request
satisfying a request from
a request from stale
request from stale data
whether in from the
in from the cache
or on a server
on a server that
a server that has
server that has yet
that has yet to
has yet to see
yet to see a
to see a delayed
see a delayed writeback
i ij and the
ij and the revenue
and the revenue vector
the revenue vector at
revenue vector at step
would be visible to
vector at step t
be visible to the
at step t is
visible to the user
step t is r
to the user and
the user and costly
strong cache consistency is
cache consistency is certainly
consistency is certainly achievable
is certainly achievable in
certainly achievable in distributed
achievable in distributed file
in distributed file systems
in the pool game
the pool game pools
pool game pools try
but must be implemented
game pools try to
must be implemented with
pools try to optimize
be implemented with synchronous
try to optimize their
implemented with synchronous rpcs
to optimize their infiltration
optimize their infiltration rates
their infiltration rates of
infiltration rates of other
rates of other pools
of other pools to
and requires either readers
other pools to maximize
pools to maximize their
requires either readers or
to maximize their revenue
either readers or writers
readers or writers to
or writers to incur
writers to incur a
to incur a delay
the overall number of
incur a delay to
overall number of miners
a delay to ensure
number of miners and
delay to ensure that
of miners and the
to ensure that only
miners and the number
ensure that only the
and the number of
that only the latest
the number of miners
only the latest version
number of miners loyal
the latest version of
of miners loyal to
latest version of a
miners loyal to each
version of a file
loyal to each pool
of a file is
to each pool remain
a file is accessed
each pool remain constant
pool remain constant throughout
remain constant throughout the
constant throughout the game
time progresses in rounds
as we have noted
we have noted in
have noted in section
let s be a
s be a constant
be a constant integer
a constant integer large
constant integer large enough
integer large enough that
sending file updates to
large enough that revenue
file updates to a
enough that revenue can
updates to a server
that revenue can be
to a server asynchronously
revenue can be approximated
a server asynchronously has
can be approximated as
server asynchronously has two
be approximated as its
asynchronously has two potential
approximated as its convergence
has two potential benefits
as its convergence limit
the process modifying the
in each round the
process modifying the file
each round the system
modifying the file need
round the system takes
the file need not
the system takes s
file need not wait
system takes s steps
need not wait for
takes s steps and
not wait for the
s steps and then
wait for the write
steps and then a
for the write to
and then a single
the write to complete
then a single pool
picked with a round
if the update is
the update is delayed
update is delayed in
is delayed in the
delayed in the log
in the log for
may change its infiltration
the log for some
change its infiltration rates
log for some interval
its infiltration rates of
for some interval before
infiltration rates of all
some interval before being
rates of all other
interval before being written
of all other pools
before being written back
the total revenue of
it may be superseded
total revenue of each
may be superseded by
revenue of each step
be superseded by a
of each step is
superseded by a later
each step is normalized
by a later update
step is normalized to
and therefore can be
therefore can be omitted
can be omitted entirely
so the revenue per
the revenue per round
revenue per round is
per round is one
these benefits come at
benefits come at the
come at the cost
at the cost of
the cost of reduced
cost of reduced cache
the pool taking a
of reduced cache consistency
pool taking a step
taking a step knows
a step knows the
step knows the rate
knows the rate of
the rate of infiltrators
since the version of
rate of infiltrators attacking
the version of the
of infiltrators attacking it
version of the file
workloads with contention between
of the file stored
with contention between priority
the file stored at
contention between priority levels
though not their identity
file stored at the
stored at the server
latency histograms for i
at the server is
the grep workload consists
the server is inconsistent
grep workload consists of
and the revenue rates
workload consists of validating
server is inconsistent during
consists of validating cached
the revenue rates of
of validating cached files
is inconsistent during the
revenue rates of each
inconsistent during the time
rates of each of
during the time that
of each of the
the time that the
each of the other
elapsed time to compile
of the other pools
time to compile mafs
time that the update
that the update remains
the update remains queued
update remains queued for
remains queued for transmission
this knowledge is required
knowledge is required to
is required to optimize
required to optimize a
to optimize a pool
optimize a pool s
even though asynchronous writes
a pool s revenue
though asynchronous writes in
asynchronous writes in mfs
writes in mfs are
in mfs are not
mfs are not delayed
as we see next
are not delayed to
not delayed to aggregate
delayed to aggregate updates
we explain in section
explain in section viii
in section viii how
a burst of updates
section viii how a
viii how a pool
burst of updates to
how a pool can
a pool can technically
of updates to a
pool can technically obtain
updates to a sequence
can technically obtain this
technically obtain this knowledge
to a sequence of
a sequence of files
sequence of files may
of files may flood
files may flood the
may flood the link
general analysis recall that
flood the link to
analysis recall that mi
writes execution time speedup
recall that mi is
the link to the
that mi is the
link to the server
mi is the number
to the server and
is the number of
the server and increase
the number of miners
server and increase the
number of miners loyal
and increase the delay
of miners loyal to
increase the delay before
miners loyal to pool
the delay before updates
loyal to pool i
delay before updates towards
before updates towards the
updates towards the end
towards the end of
the end of the
end of the burst
of the burst are
the burst are committed
any other client accessing
other client accessing the
client accessing the file
is the number of
the number of miners
cache consistency will access
distinct processes distinct files
consistency will access the
number of miners used
will access the stale
processes distinct files total
access the stale version
of miners used by
distinct files total of
miners used by pool
files total of file
used by pool i
total of file sizes
by pool i to
rather than one which
pool i to infiltrate
than one which incorporates
i to infiltrate pool
one which incorporates the
to infiltrate pool j
which incorporates the pending
infiltrate pool j at
incorporates the pending update
pool j at step
j at step t
we therefore refer to
the mining rate of
therefore refer to this
mining rate of pool
refer to this as
rate of pool i
to this as a
of pool i is
this as a hidden
pool i is therefore
as a hidden upstudies
i is therefore the
a hidden upstudies of
is therefore the number
hidden upstudies of distributed
therefore the number of
upstudies of distributed file
the number of its
of distributed file systems
number of its loyal
distributed file systems have
of its loyal miners
file systems have largely
its loyal miners minus
systems have largely concluded
loyal miners minus the
have largely concluded that
miners minus the miners
largely concluded that file
minus the miners it
concluded that file date
the miners it uses
miners it uses for
it uses for infiltration
and the cache consistency
the cache consistency problem
this effective mining rate
cache consistency problem caused
effective mining rate is
consistency problem caused by
mining rate is divided
problem caused by asynchronous
rate is divided by
caused by asynchronous sharing
is divided by the
by asynchronous sharing is
divided by the total
asynchronous sharing is infrequent
by the total mining
sharing is infrequent in
the total mining rate
is infrequent in general
total mining rate in
mining rate in the
rate in the system
namely the number of
the number of all
number of all miners
of all miners that
all miners that do
miners that do not
that do not engage
do not engage in
not engage in block
engage in block withholding
denote the direct mining
the direct mining rate
direct mining rate of
mining rate of pool
rate of pool i
of pool i at
pool i at step
i at step t
writes as the hidden
at step t by
as the hidden update
step t by pp
the hidden update problem
t by pp mi
by pp mi j
we have identified a
have identified a class
identified a class of
a class of cache
class of cache consistency
of cache consistency scenarmobile
cache consistency scenarmobile file
consistency scenarmobile file systems
scenarmobile file systems such
file systems such as
systems such as coda
rely on optimistic conios
on optimistic conios as
optimistic conios as being
conios as being of
as being of high
being of high importance
of high importance and
high importance and inadequately
importance and inadequately served
and inadequately served by
inadequately served by ex
k the revenue density
the revenue density of
currency control to resolve
revenue density of pool
control to resolve the
density of pool i
to resolve the conflicts
of pool i at
resolve the conflicts generated
pool i at the
the conflicts generated by
i at the end
conflicts generated by hidden
at the end of
generated by hidden upisting
the end of step
by hidden upisting mobile
end of step t
hidden upisting mobile file
of step t is
upisting mobile file systems
step t is its
latency histograms for i
t is its revenue
is its revenue from
its revenue from direct
suppose that a complex
revenue from direct mining
that a complex engineering
from direct mining together
a complex engineering dates
direct mining together with
mining together with its
together with its revenue
with its revenue from
its revenue from infiltrated
revenue from infiltrated pools
an alternative approach is
alternative approach is to
approach is to use
is to use a
divided by the number
to use a variant
by the number of
use a variant of
the number of its
a variant of callbacks
number of its loyal
variant of callbacks to
of its loyal miners
of callbacks to design
its loyal miners together
callbacks to design is
loyal miners together with
to design is maintained
miners together with block
design is maintained on
is maintained on a
maintained on a server
on a server and
a server and updated
withholding infiltrators that attack
server and updated by
infiltrators that attack it
and updated by teams
updated by teams of
by teams of de
allow a client to
a client to replay
client to replay writes
to replay writes asynchronously
but retain strong signers
the echo file system
moving average of recovery
average of recovery latencies
of recovery latencies for
recovery latencies for both
latencies for both codes
the channel is configured
channel is configured to
is configured to lose
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
site supervisors work from
singleton packets randomly at
supervisors work from those
packets randomly at a
work from those designs
randomly at a loss
from those designs using
at a loss rate
those designs using mobile
a loss rate of
we thank larry felser
thank larry felser and
larry felser and his
felser and his team
and his team at
his team at autodesk
team at autodesk for
at autodesk for their
autodesk for their help
for their help in
their help in understanddevices
and additionally lose long
additionally lose long bursts
lose long bursts of
these supervisors read from
supervisors read from the
read from the server
from the server and
hereinafter we move to
the server and may
packets at occasional intervals
we move to a
server and may also
move to a static
and may also ing
to a static state
may also ing the
both codes are configured
a static state analysis
also ing the file
codes are configured with
ing the file access
static state analysis and
the file access patterns
are configured with r
file access patterns that
state analysis and omit
access patterns that arise
analysis and omit the
patterns that arise in
and omit the t
that arise in collaborative
omit the t argument
arise in collaborative work
the t argument in
in collaborative work applications
t argument in the
collaborative work applications for
argument in the expressions
work applications for very
applications for very change
for very change the
very change the design
for example to reflect
example to reflect one
and recover all lost
to reflect one of
recover all lost packets
reflect one of the
all lost packets reedsolomon
one of the contingencies
lost packets reedsolomon uses
of the contingencies large
packets reedsolomon uses an
the contingencies large architectural
reedsolomon uses an interleave
contingencies large architectural and
uses an interleave of
since the row sums
large architectural and engineering
the row sums of
architectural and engineering design
row sums of the
and engineering design firms
sums of the infiltration
of the infiltration matrix
the infiltration matrix are
infiltration matrix are smaller
matrix are smaller than
are smaller than one
and layered interleaving uses
layered interleaving uses interleaves
interleaving uses interleaves of
its largest eigenvalue is
largest eigenvalue is smaller
eigenvalue is smaller than
encountered and resolved only
according to the perron
and resolved only as
resolved only as construction
only as construction proceeds
as we have seen
we have seen earlier
the revenues at all
and consequently both have
revenues at all pools
consequently both have a
at all pools converge
both have a maximum
high traffic can cause
have a maximum tolerable
traffic can cause delays
a maximum tolerable burst
can cause delays in
maximum tolerable burst length
cause delays in the
all pools converge as
tolerable burst length of
delays in the round
pools converge as follows
trip time for small
time for small rpcs
we use a publicly
use a publicly available
a publicly available implementation
publicly available implementation of
available implementation of a
implementation of a reed
data rpcs have a
rpcs have a higher
have a higher outgoing
solomon code based on
a higher outgoing queueing
code based on vandermonde
higher outgoing queueing delay
based on vandermonde matrices
outgoing queueing delay in
queueing delay in the
delay in the absence
in the absence of
the absence of prefetching
this is due to
is due to the
due to the majority
to the majority of
the majority of the
majority of the competing
of the competing rpcs
the competing rpcs being
competing rpcs being high
rpcs being high priority
being high priority fetch
the code is plugged
code is plugged into
is plugged into maelstrom
plugged into maelstrom instead
into maelstrom instead of
maelstrom instead of layered
instead of layered interleaving
these rpcs are mostly
rpcs are mostly replaced
are mostly replaced by
mostly replaced by prefetches
showing that we can
that we can use
we can use new
can use new encodings
use new encodings within
which operate at a
new encodings within the
operate at a lower
encodings within the same
at a lower priority
within the same framework
a lower priority than
the same framework seamlessly
lower priority than store
until any point where
solomon code recovers all
any point where a
code recovers all lost
point where a concurrent
recovers all lost packets
where a concurrent demand
a concurrent demand fetch
all lost packets with
concurrent demand fetch rpc
demand fetch rpc raises
lost packets with roughly
fetch rpc raises their
rpc raises their priorities
packets with roughly the
raises their priorities to
the pool game if
their priorities to the
with roughly the same
pool game if no
priorities to the fetch
game if no pool
roughly the same latency
if no pool engages
no pool engages in
the same latency whereas
pool engages in block
engages in block withholding
same latency whereas layered
traffic numbers are for
numbers are for synchronous
latency whereas layered interleaving
are for synchronous writeback
whereas layered interleaving recovers
a comparison of fetch
layered interleaving recovers singleton
interleaving recovers singleton losses
recovers singleton losses almost
singleton losses almost immediately
data and prefetch rpcs
losses almost immediately and
and prefetch rpcs reveals
almost immediately and exhibits
prefetch rpcs reveals the
immediately and exhibits latency
rpcs reveals the effect
and exhibits latency spikes
reveals the effect of
exhibits latency spikes whenever
the effect of the
latency spikes whenever the
effect of the bandwidth
spikes whenever the longer
of the bandwidth decrease
whenever the longer loss
the longer loss burst
longer loss burst occurs
the test run with
and we have i
test run with prefetching
run with prefetching performs
r elated w ork
with prefetching performs a
prefetching performs a fetch
elated w ork maelstrom
w ork maelstrom lies
ork maelstrom lies in
maelstrom lies in the
data rpc to get
lies in the intersection
rpc to get the
in the intersection of
to get the first
the intersection of two
compiling mafs on top
get the first file
mafs on top of
intersection of two research
on top of mafs
of two research areas
two research areas that
research areas that have
which triggers prefetching from
areas that have seen
triggers prefetching from its
that have seen major
prefetching from its file
have seen major innovations
from its file group
seen major innovations in
each miner s revenue
major innovations in the
miner s revenue is
innovations in the last
s revenue is proportional
in the last decade
revenue is proportional to
the last decade high
is proportional to its
because of the large
proportional to its power
of the large delay
the large delay between
large delay between file
delay between file accesses
be it in a
it in a pool
bandwidth is high enough
in a pool or
haul communication and forward
prefetches complete entirely without
communication and forward error
is high enough to
and forward error correction
complete entirely without any
a pool or working
entirely without any overlapping
pool or working solo
without any overlapping demand
high enough to eliminate
any overlapping demand fetches
enough to eliminate differences
to eliminate differences between
eliminate differences between writeback
differences between writeback schemes
ip variants such as
variants such as compound
over the course of
such as compound tcp
recall that difficulty is
the course of the
that difficulty is only
course of the second
difficulty is only adjusted
of the second period
is only adjusted periodically
asynchronous writeback is clearly
the second period of
writeback is clearly beneficial
second period of time
and there are transient
there are transient effects
and priortwo questions are
are transient effects that
bandwidth becomes insufficient for
transient effects that are
priortwo questions are of
effects that are not
becomes insufficient for a
that are not covered
questions are of particular
are not covered by
insufficient for a prefetch
not covered by this
are of particular interest
covered by this stable
for a prefetch to
of particular interest in
a prefetch to complete
particular interest in evaluating
prefetch to complete during
interest in evaluating the
to complete during the
in evaluating the perfor
we discuss this in
use transmission delay to
ities are advantageous in
transmission delay to detect
discuss this in section
delay to detect backed
are advantageous in reducing
to detect backed up
this in section viii
detect backed up routers
advantageous in reducing contention
in reducing contention between
reducing contention between reading
contention between reading mance
miners miners miners a
replacing or supplementing packet
s delay between accesses
between reading mance of
or supplementing packet loss
reading mance of mafs
supplementing packet loss as
mance of mafs communication
packet loss as a
of mafs communication adaptation
loss as a signal
as a signal of
and raisepriority rpcs are
a signal of congestion
raisepriority rpcs are triggered
controls its infiltration rate
rpcs are triggered by
its infiltration rate of
are triggered by the
infiltration rate of pool
triggered by the consequent
while such protocols solve
by the consequent cache
such protocols solve the
the consequent cache misses
which is not possible
protocols solve the congestion
is not possible when
solve the congestion collapse
not possible when synchronous
the congestion collapse experienced
possible when synchronous writeback
congestion collapse experienced by
when synchronous writeback is
collapse experienced by conventional
synchronous writeback is used
experienced by conventional tcp
as the bandwidth decreases
the queueing delays increase
queueing delays increase as
delays increase as a
increase as a proportion
as a proportion of
a proportion of the
proportion of the total
do priorities improve performance
of the total time
and will choose the
the total time spent
priorities improve performance by
total time spent on
will choose the value
time spent on prefetches
improve performance by reducing
they cannot mitigate the
performance by reducing rpc
choose the value that
by reducing rpc conthe
cannot mitigate the longer
the value that maximizes
reducing rpc conthe second
mitigate the longer packet
rpc conthe second microbenchmark
the longer packet delivery
conthe second microbenchmark evaluates
longer packet delivery latencies
second microbenchmark evaluates a
packet delivery latencies caused
microbenchmark evaluates a workload
the modifying client to
delivery latencies caused by
modifying client to flush
latencies caused by packet
value that maximizes the
evaluates a workload that
that maximizes the revenue
a workload that contention
maximizes the revenue density
caused by packet loss
client to flush its
to flush its updates
flush its updates whenever
its updates whenever another
tains explicit contention between
updates whenever another client
explicit contention between different
whenever another client accesses
contention between different types
another client accesses the
between different types of
client accesses the file
and they do not
different types of rpc
they do not eliminate
types of rpc traf
do not eliminate the
not eliminate the need
eliminate the need for
the need for larger
need for larger buffers
for larger buffers at
on the first round
larger buffers at end
the first round of
first round of the
round of the pool
of the pool game
is it possible to
it possible to combine
possible to combine the
to combine the benefit
combine the benefit of
the value of r
separates invalidating a file
fec has seen major
invalidating a file from
has seen major innovations
a file from transmitting
the benefit of asynchronous
file from transmitting its
seen major innovations in
from transmitting its update
is maximized at a
benefit of asynchronous write
maximized at a single
major innovations in the
at a single point
innovations in the last
a single point in
in the last fifteen
single point in the
the last fifteen years
point in the feasible
we have implemented a
in the feasible range
have implemented a similar
implemented a similar scheme
a similar scheme in
similar scheme in mfs
level fec was first
fec was first described
in which an access
was first described for
which an access to
first described for high
an access to a
access to a file
to a file which
a file which has
speed wan networks as
file which has an
wan networks as early
which has an uncommitted
networks as early as
one process performs a
has an uncommitted update
process performs a grep
an uncommitted update at
performs a grep on
uncommitted update at a
a grep on a
update at a different
grep on a set
at a different client
cannot not react to
a different client will
not react to pool
different client will force
on a set of
client will force the
a set of back
will force the writeback
set of back at
of back at low
back at low bandwidth
at low bandwidth with
this point is the
the mfs consistency algorithm
low bandwidth with acceptable
point is the stable
mfs consistency algorithm differs
is the stable state
bandwidth with acceptable performance
the stable state of
consistency algorithm differs in
stable state of the
with acceptable performance at
algorithm differs in its
state of the system
differs in its incorporation
acceptable performance at cached
in its incorporation of
performance at cached files
its incorporation of file
at cached files that
incorporation of file access
and we denote the
of file access information
we denote the value
cached files that need
denote the value of
files that need to
the value of x
that need to be
it was applied by
need to be validated
was applied by researchers
to be validated before
applied by researchers in
be validated before they
by researchers in the
validated before they can
rather than enforce the
before they can be
researchers in the context
they can be opened
than enforce the same
in the context of
enforce the same level
the context of atm
the same level of
context of atm networks
same level of consistency
level of consistency for
of consistency for all
consistency for all files
mfs differentiates between private
differentiates between private files
which have recently only
have recently only been
recently only been accessed
only been accessed by
another process either writes
been accessed by a
process either writes higher
accessed by a single
either writes higher bandwidths
by a single client
level fec for ip
data to files rapidly
fec for ip networks
for ip networks was
ip networks was revived
networks was revived in
which are accessed by
are accessed by multiple
accessed by multiple clients
and the values of
enforcing cache consistency between
the values of the
cache consistency between clients
values of the corresponding
consistency between clients necessarily
of the corresponding revenues
between clients necessarily requires
the corresponding revenues of
clients necessarily requires that
corresponding revenues of the
necessarily requires that shared
revenues of the pools
requires that shared files
of the pools with
grepwe compare mafs to
the pools with r
that shared files are
compare mafs to alternative
shared files are kept
mafs to alternative approaches
files are kept highly
to alternative approaches in
are kept highly consistent
alternative approaches in two
approaches in two sets
in two sets of
two sets of compile
but modifications to private
in the context of
modifications to private files
the context of both
substituting the stable value
to private files can
context of both reliable
private files can be
of both reliable multicast
files can be written
both reliable multicast and
can be written back
reliable multicast and long
the stable value x
be written back to
written back to the
back to the server
to the server less
the server less aggressively
rizzo subsequently provided a
subsequently provided a working
the technique of using
provided a working implementation
technique of using file
one process reads files
we obtain the revenues
a working implementation of
of using file access
working implementation of a
obtain the revenues of
implementation of a software
process reads files at
of a software packet
reads files at the
using file access patterns
files at the same
the revenues of the
file access patterns to
revenues of the two
at the same experiments
access patterns to adjust
of the two pools
patterns to adjust a
to adjust a cache
adjust a cache consistency
microbenchmarks to measure execution
a cache consistency protocol
all are given in
cache consistency protocol has
are given in figure
to measure execution time
consistency protocol has been
measure execution time time
protocol has been used
execution time time as
has been used in
time time as another
been used in the
time as another is
used in the sprite
as another is writing
in the sprite distributed
another is writing files
the sprite distributed operation
sprite distributed operation system
to simplify the expressions
maelstrom represents a natural
represents a natural evolution
a natural evolution of
natural evolution of these
evolution of these ideas
shows that priorispeedup for
that priorispeedup for simple
priorispeedup for simple workloads
the emphasis on applying
emphasis on applying error
though in sprite changes
on applying error correcting
and traces of actual
applying error correcting codes
in sprite changes in
traces of actual windows
error correcting codes at
sprite changes in caching
of actual windows ties
correcting codes at higher
changes in caching policy
actual windows ties are
codes at higher levels
in caching policy were
windows ties are beneficial
at higher levels of
caching policy were made
ties are beneficial for
higher levels of the
policy were made when
levels of the software
were made when a
of the software stack
made when a file
the software stack has
when a file was
software stack has been
a file was opened
are beneficial for the
file was opened simultaneously
stack has been accompanied
was opened simultaneously at
beneficial for the small
opened simultaneously at different
has been accompanied by
simultaneously at different clients
for the small validation
been accompanied by advances
the small validation rpcs
accompanied by advances in
small validation rpcs when
by advances in the
validation rpcs when the
advances in the codes
while mfs uses longer
in the codes themselves
rpcs when the backnt
when the backnt file
the backnt file system
prior to the mid
the remainder of this
remainder of this section
of this section describes
this section describes our
section describes our consistency
describes our consistency algorithm
our consistency algorithm in
the ntfs traces were
consistency algorithm in detail
ntfs traces were gathered
o ne attacker we
traces were gathered ground
ne attacker we begin
were gathered ground traffic
attacker we begin our
gathered ground traffic is
we begin our analysis
ground traffic is heavy
and an evaluation of
the standard encoding used
an evaluation of its
standard encoding used was
evaluation of its effectiveness
encoding used was reed
of its effectiveness in
begin our analysis with
its effectiveness in reducing
with the sporadic background
effectiveness in reducing cache
our analysis with a
in reducing cache inconsistencies
the sporadic background traffic
analysis with a simplified
sporadic background traffic in
with a simplified game
background traffic in the
a simplified game of
traffic in the cornell
an erasure code that
simplified game of two
host reader writer parameter
game of two pools
erasure code that performs
in the cornell university
reader writer parameter delay
the cornell university computer
code that performs excellently
cornell university computer science
writer parameter delay between
university computer science department
that performs excellently at
parameter delay between accessing
performs excellently at small
delay between accessing modules
excellently at small scale
between accessing modules operations
and of compiling mafs
at small scale but
accessing modules operations per
small scale but does
modules operations per module
scale but does not
operations per module delay
but does not scale
improvements are confined to
per module delay between
does not scale to
are confined to low
not scale to large
module delay between operations
scale to large sets
confined to low bandcontain
delay between operations delay
to large sets of
to low bandcontain access
large sets of data
between operations delay between
low bandcontain access to
sets of data and
bandcontain access to local
of data and error
operations delay between accessing
data and error correcting
access to local and
and error correcting symbols
delay between accessing modules
to local and remote
between accessing modules operations
local and remote file
accessing modules operations per
and remote file systems
this scalability barrier resulted
remote file systems by
modules operations per module
file systems by clients
scalability barrier resulted in
systems by clients in
operations per module delay
by clients in a
barrier resulted in the
clients in a width
per module delay between
in a width levels
resulted in the development
module delay between operations
in the development of
delay between operations size
the development of new
between operations size of
development of new variants
operations size of external
of new variants of
size of external files
miners outside both pools
of external files value
new variants of low
outside both pools mine
variants of low density
both pools mine solo
of low density parity
low density parity check
or with closed pools
with closed pools that
demonstrates that priorities can
closed pools that do
that priorities can imlocal
pools that do not
that do not attack
do not attack and
not attack and cannot
attack and cannot be
and cannot be attacked
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the dashed red arrow
dashed red arrow indicates
red arrow indicates that
arrow indicates that x
priority read performance with
read performance with only
performance with only a
with only a small
only a small overhead
a small overhead for
small overhead for writes
these microbenchmarks show that
s mining power infiltrates
microbenchmarks show that asynmicrobenchmarks
mining power infiltrates pool
show that asynmicrobenchmarks chronous
that asynmicrobenchmarks chronous writeback
asynmicrobenchmarks chronous writeback improves
chronous writeback improves performance
with a block withholding
writeback improves performance even
a block withholding attack
improves performance even at
performance even at comparaour
even at comparaour first
at comparaour first microbenchmark
comparaour first microbenchmark compiles
first microbenchmark compiles mafs
microbenchmark compiles mafs from
does not engage in
not engage in block
engage in block withholding
all of its m
which are orders of
are orders of magnitude
orders of magnitude faster
of magnitude faster than
magnitude faster than reed
loyal miners work on
miners work on its
work on its behalf
mb of tively high
of tively high bandwidths
solomon and much more
and much more scalable
much more scalable in
more scalable in input
scalable in input size
and priorities are effective
priorities are effective in
are effective in mitigating
effective in mitigating source
but require slightly more
in mitigating source code
on the other hand
mitigating source code stored
the other hand does
source code stored in
other hand does not
code stored in an
hand does not employ
stored in an mafs
does not employ x
in an mafs filesystem
require slightly more data
slightly more data to
more data to be
data to be received
to be received at
be received at the
received at the decoder
while the layered interleaving
of its loyal miners
the layered interleaving code
layered interleaving code used
interleaving code used by
code used by maelstrom
used by maelstrom is
and its direct mining
by maelstrom is similar
its direct mining power
maelstrom is similar to
direct mining power is
is similar to the
mining power is only
similar to the tornado
power is only m
mb contention between different
contention between different classes
between different classes of
different classes of rpcs
lt and raptor codes
and raptor codes in
raptor codes in its
codes in its use
of output in the
in its use of
output in the same
its use of simple
in the same filesystem
use of simple xor
configuration parameters for the
of simple xor operations
parameters for the cache
for the cache consistency
the cache consistency evaluation
it differs from them
individual instances are uniformally
the bitcoin system normalizes
differs from them in
bitcoin system normalizes these
instances are uniformally distributed
from them in one
system normalizes these rates
compares the execution time
normalizes these rates by
them in one very
these rates by the
the execution time speedup
rates by the total
in one very important
by the total number
execution time speedup for
one very important aspect
the total number of
are uniformally distributed within
total number of miners
uniformally distributed within the
number of miners that
distributed within the listed
time speedup for the
very important aspect it
speedup for the benchmark
within the listed ranges
for the benchmark under
important aspect it seeks
the benchmark under differing
of miners that publish
benchmark under differing asynchronous
miners that publish full
aspect it seeks to
that publish full proofs
under differing asynchronous writeback
it seeks to minimize
differing asynchronous writeback and
seeks to minimize the
asynchronous writeback and priority
to minimize the latency
writeback and priority schemes
minimize the latency between
namely all miners but
the latency between the
all miners but x
latency between the arrival
if the file is
between the arrival of
the file is shared
as bandwidth is var
file is shared and
the arrival of a
is shared and no
arrival of a packet
shared and no other
of a packet at
and no other shared
a packet at the
no other shared update
packet at the send
other shared update is
shared update is being
update is being sent
we evaluated mafs at
evaluated mafs at a
mafs at a larger
side proxy and its
at a larger scale
proxy and its successful
the pools direct revenues
and its successful reception
pools direct revenues are
the thread begins transmitting
direct revenues are therefore
a larger scale using
thread begins transmitting the
revenues are therefore m
begins transmitting the update
larger scale using the
its successful reception at
transmitting the update at
successful reception at the
the update at the
reception at the receive
update at the store
scale using the ntfs
derived the dominant feature
the dominant feature of
dominant feature of figure
if another shared update
another shared update is
shared update is being
update is being written
codes such as tornado
is that asynchronous write
such as tornado encode
is being written back
as tornado encode over
tornado encode over a
encode over a fixed
over a fixed set
traces summarised in table
a fixed set of
fixed set of input
a synchronous forward invalidation
set of input symbols
synchronous forward invalidation rpc
forward invalidation rpc is
invalidation rpc is made
rpc is made to
is made to the
without treating symbols differently
made to the server
treating symbols differently based
to the server at
although the original execution
the server at the
symbols differently based on
the original execution back
differently based on their
original execution back is
based on their sequence
execution back is beneficial
on their sequence in
back is beneficial at
their sequence in the
is beneficial at all
sequence in the data
beneficial at all bandwidths
in the data stream
at all bandwidths until
server at the highest
at the highest priority
and then the update
then the update is
as mentioned in section
the update is queued
mentioned in section iv
update is queued for
is queued for later
queued for later high
there is less times
is less times of
less times of these
times of these traces
of these traces were
these traces were short
traces were short on
layered interleaving is unique
were short on windows
interleaving is unique in
short on windows nt
is unique in allowing
unique in allowing the
in allowing the recovery
a forward invalidation is
allowing the recovery latency
they execute improvement at
forward invalidation is only
the recovery latency of
invalidation is only made
recovery latency of lost
is only made if
latency of lost packets
only made if the
of lost packets to
made if the update
lost packets to depend
if the update cannot
divides its revenue among
the update cannot be
packets to depend on
update cannot be transmitted
its revenue among its
cannot be transmitted immediately
to depend on the
revenue among its loyal
depend on the actual
among its loyal miners
on the actual burst
its loyal miners and
the actual burst size
loyal miners and the
in practice it can
miners and the miners
where throughput is so
and the miners that
throughput is so low
the miners that infiltrated
is so low that
miners that infiltrated it
so low that con
actual burst size experienced
practice it can therefore
it can therefore be
can therefore be omitted
therefore be omitted at
slowly on mafs due
its revenue density is
on mafs due to
revenue density is therefore
mafs due to high
be omitted at high
due to high bandwidth
omitted at high bandwidth
to high bandwidth requirements
at high bandwidth or
density is therefore r
high bandwidth or when
as opposed to the
bandwidth or when traffic
opposed to the maximum
or when traffic is
trol traffic and the
when traffic is low
to the maximum tolerable
traffic and the delay
the maximum tolerable burst
and the delay in
maximum tolerable burst size
the delay in fetching
tolerable burst size as
delay in fetching files
burst size as with
in fetching files become
size as with other
fetching files become dominating
as with other encoding
files become dominating figure
with other encoding schemes
sending a forward invalidation
a forward invalidation rpc
forward invalidation rpc without
invalidation rpc without requiring
shows execution times under
rpc without requiring the
execution times under four
without requiring the modifying
times under four combinations
requiring the modifying process
under four combinations of
c onclusion modern distributed
four combinations of writeback
the modifying process to
combinations of writeback scheme
onclusion modern distributed systems
of writeback scheme and
modifying process to wait
writeback scheme and priorities
modern distributed systems are
process to wait introduces
distributed systems are compelled
systems are compelled by
are compelled by real
world imperatives to coordinate
imperatives to coordinate across
to coordinate across data
coordinate across data centers
across data centers separated
the consistency maintenance algorithm
data centers separated by
consistency maintenance algorithm a
centers separated by thousands
maintenance algorithm a transient
separated by thousands of
algorithm a transient inconsistency
by thousands of miles
packet loss cripples the
when the server receives
loss cripples the performance
the server receives a
cripples the performance of
divides its revenue among
server receives a forward
its revenue among its
the performance of such
receives a forward invalidation
performance of such systems
revenue among its registered
a forward invalidation for
among its registered miners
forward invalidation for a
invalidation for a shared
and reliability and flow
for a shared the
a shared the mfs
the revenue includes both
shared the mfs cache
revenue includes both its
the mfs cache consistency
control protocols designed for
mfs cache consistency algorithm
protocols designed for lans
includes both its direct
cache consistency algorithm is
designed for lans and
consistency algorithm is intended
both its direct mining
algorithm is intended to
its direct mining revenue
is intended to achieve
direct mining revenue and
intended to achieve a
mining revenue and the
to achieve a file
or the commodity internet
revenue and the revenue
the commodity internet fail
and the revenue its
commodity internet fail to
the revenue its infiltrators
internet fail to achieve
revenue its infiltrators obtained
or begins receiving an
its infiltrators obtained from
begins receiving an update
infiltrators obtained from pool
receiving an update for
an update for a
update for a file
optimal performance on the
performance on the high
it records the idenhigh
records the idenhigh degree
the idenhigh degree of
idenhigh degree of consistency
subject to the constraints
haul lambda networks linking
to the constraints imposed
lambda networks linking data
the constraints imposed by
networks linking data centers
constraints imposed by tity
imposed by tity of
by tity of the
tity of the writer
deploying new protocols is
new protocols is not
protocols is not an
marks the file as
is not an option
the revenue per loyal
not an option for
revenue per loyal pool
the file as dirty
an option for commodity
file as dirty and
option for commodity clusters
as dirty and issues
for commodity clusters where
miner is therefore r
commodity clusters where standardization
dirty and issues callbacks
clusters where standardization is
and issues callbacks to
where standardization is critical
issues callbacks to file
standardization is critical for
callbacks to file semantics
is critical for cost
to file semantics and
critical for cost mitigation
file semantics and the
semantics and the desirability
and the desirability of
the desirability of minimising
desirability of minimising overhead
maelstrom is an edge
is an edge appliance
an edge appliance that
edge appliance that uses
we all the clients
appliance that uses forward
all the clients caching
that uses forward error
the clients caching it
uses forward error correction
forward error correction to
error correction to mask
correction to mask packet
to mask packet loss
mask packet loss from
if one of these
packet loss from endto
one of these clients
of these clients fetches
these clients fetches the
clients fetches the file
fetches the file have
the file have opted
file have opted for
have opted for a
opted for a compromise
for a compromise which
ip throughput and latency
a compromise which results
throughput and latency by
compromise which results in
and latency by orders
which results in a
latency by orders of
results in a small
by orders of magnitude
in a small overhead
orders of magnitude when
a small overhead before
of magnitude when loss
small overhead before the
magnitude when loss occurs
overhead before the update
before the update has
the update has been
we obtain the expression
update has been committed
obtain the expression for
the expression for r
maelstrom is easy to
is easy to install
easy to install and
to install and deploy
the server sends highbut
server sends highbut admits
sends highbut admits the
highbut admits the possibility
admits the possibility of
and is completely transparent
the possibility of a
is completely transparent to
possibility of a transient
completely transparent to applications
of a transient inconsistency
transparent to applications and
to applications and protocols
applications and protocols literally
and protocols literally providing
protocols literally providing reliability
priority server pull rpcs
literally providing reliability in
server pull rpcs to
providing reliability in an
pull rpcs to the
reliability in an inexpensive
rpcs to the clients
in an inexpensive box
to the clients with
the clients with outstanding
clients with outstanding upthe
with outstanding upthe algorithm
outstanding upthe algorithm requires
upthe algorithm requires information
algorithm requires information about
requires information about client
information about client accesses
about client accesses in
client accesses in dates
which causes them to
causes them to raise
them to raise the
to raise the priority
raise the priority of
the priority of any
priority of any store
data order to divide
order to divide files
to divide files according
divide files according their
files according their status
either shared or unrpcs
shared or unrpcs to
or unrpcs to expedite
unrpcs to expedite transmission
a fetch rpc for
fetch rpc for an
rpc for an unshared
for an unshared file
optical domain performance monitoring
an unshared file shared
since the file server
the file server always
file server always assumes
server always assumes that
always assumes that an
assumes that an unshared
that an unshared which
an unshared which is
unshared which is already
which is already cached
is already cached by
the optical fiber communication
already cached by a
optical fiber communication conference
cached by a different
by a different client
a different client always
different client always triggers
client always triggers a
always triggers a file
triggers a file has
a file has an
file has an uncommitted
has an uncommitted write
an uncommitted write when
uncommitted write when it
write when it is
when it is accessed
it is accessed by
is accessed by an
accessed by an addiserver
by an addiserver pull
since the server has
the server has no
server has no way
has no way of
no way of knowing
way of knowing if
of knowing if the
knowing if the file
if the file has
the file has tional
file has tional client
incorrect information about the
information about the status
we analyze this game
about the status of
analyze this game numerically
the status of a
this game numerically by
status of a file
game numerically by finding
of a file only
numerically by finding the
a file only outstanding
by finding the x
file only outstanding updates
affects the efficiency of
the efficiency of the
efficiency of the algorithm
detection of such a
of such a misfinally
and substituting this value
substituting this value for
since updates to shared
this value for r
updates to shared and
to shared and unshared
shared and unshared files
and unshared files are
unshared files are writclassification
files are writclassification results
isn t quite enough
are writclassification results in
writclassification results in the
results in the file
in the file being
the file being marked
file being marked as
being marked as shared
we vary the sizes
vary the sizes of
the sizes of the
sizes of the pools
of the pools through
ten back to the
the pools through the
back to the server
pools through the entire
to the server at
through the entire feasible
the server at different
the entire feasible range
server at different priorities
entire feasible range and
feasible range and depict
range and depict the
and depict the optimal
depict the optimal x
the original order of
original order of the
order of the status
of the status of
the status of files
status of files can
of files can be
files can be specified
can be specified by
and the corresponding revenues
be specified by the
the corresponding revenues in
specified by the user
corresponding revenues in figure
by the user or
the user or by
user or by applithe
or by applithe sequence
by applithe sequence of
applithe sequence of updates
sequence of updates is
of updates is no
updates is no longer
is no longer entirely
each point in each
no longer entirely preserved
point in each graph
in each graph represents
each graph represents the
graph represents the equilibrium
represents the equilibrium point
the equilibrium point of
equilibrium point of a
point of a game
or can be inferred
of a game with
can be inferred by
a game with the
be inferred by the
game with the corresponding
inferred by the file
with the corresponding m
by the file server
the file server according
file server according to
server according to how
according to how it
to how it dates
how it dates to
it dates to shared
dates to shared files
to shared files form
shared files form a
files form a subsequence
where we normalize m
form a subsequence of
a subsequence of the
subsequence of the original
of the original updates
where did my performance
did my performance go
the top right half
top right half of
right half of the
half of the range
automatic inference should incorpoas
of the range in
inference should incorpoas do
the range in all
should incorpoas do the
rate limiting rears its
incorpoas do the updates
limiting rears its ugly
do the updates to
rears its ugly head
the updates to unshared
range in all graphs
updates to unshared files
in all graphs is
all graphs is not
graphs is not feasible
as the sum of
the sum of m
implicit dependenrate a heuristic
dependenrate a heuristic for
a heuristic for the
heuristic for the sharing
for the sharing status
the sharing status of
sharing status of new
status of new files
and a mechacies between
a mechacies between file
mechacies between file updates
between file updates are
file updates are preserved
we use this range
use this range as
this range as a
range as a reference
as a reference color
since the combination of
the combination of nism
combination of nism for
and we use a
elapsed time for all
of nism for converting
time for all fetch
we use a dashed
for all fetch rpcs
use a dashed line
nism for converting shared
a dashed line to
dashed line to show
for converting shared files
line to show the
to show the bound
converting shared files to
show the bound between
the bound between this
shared files to be
bound between this value
between this value within
files to be unshared
this value within the
value within the feasible
to be unshared if
within the feasible range
be unshared if they
unshared if they cease
if they cease to
they cease to forward
cease to forward invalidations
to forward invalidations and
forward invalidations and compulsory
a shows the optimal
invalidations and compulsory server
shows the optimal infiltration
mostly writes mostly reads
the optimal infiltration rate
writes mostly reads trace
and compulsory server pull
mostly reads trace mixed
compulsory server pull rpcs
server pull rpcs for
pull rpcs for unbe
in the entire feasible
rpcs for unbe accessed
the entire feasible range
for unbe accessed by
mostly writes mostly reads
unbe accessed by more
writes mostly reads trace
accessed by more than
mostly reads trace mixed
by more than a
entire feasible range we
more than a single
feasible range we see
than a single client
range we see that
we see that pool
mostly writes mostly reads
writes mostly reads trace
mostly reads trace mixed
reads trace mixed figure
the current implemenshared files
chooses a strictly positive
a strictly positive value
current implemenshared files prevents
strictly positive value for
implemenshared files prevents a
positive value for x
files prevents a client
prevents a client from
a client from accessing
client from accessing new
from accessing new versions
accessing new versions of
a cross layer study
new versions of files
cross layer study of
versions of files tation
layer study of packet
trace duration for asynchronous
study of packet loss
of files tation in
of packet loss in
duration for asynchronous writes
packet loss in all
files tation in mfs
for asynchronous writes is
tation in mfs assumes
asynchronous writes is until
in mfs assumes that
writes is until completion
mfs assumes that every
is until completion of
assumes that every new
until completion of the
the revenue of pool
completion of the last
that every new file
of the last read
every new file is
new file is unshared
is depicted in figure
server is beneficial in
is beneficial in the
and monin contravention of
beneficial in the mostly
b and in the
monin contravention of their
and in the entire
contravention of their update
in the entire feasible
of their update order
in the mostly writes
the entire feasible region
the mostly writes trace
entire feasible region it
feasible region it is
region it is strictly
it is strictly larger
itors client accesses to
is strictly larger than
which has high readwrite
client accesses to a
has high readwrite contention
accesses to a file
to a file according
a file according to
file according to an
according to an overlapping
which the pool would
to an overlapping series
the pool would have
an overlapping series of
pool would have gotten
overlapping series of time
would have gotten without
series of time periods
have gotten without attacking
of time periods to
time periods to ensure
periods to ensure that
to ensure that files
ensure that files which
that files which are
files which are regularly
which are regularly accessed
are regularly accessed remain
regularly accessed remain shared
it is less effective
is less effective than
less effective than synchronous
effective than synchronous writeback
since the mfs file
the mfs file monitoring
mfs file monitoring component
file monitoring component op
due to increased contention
but this effect is
this effect is mitigated
effect is mitigated by
is mitigated by using
mitigated by using priorities
this is clearer in
is clearer in the
experimental setup erates on
clearer in the graph
setup erates on a
in the graph for
c depicts the revenue
the graph for time
erates on a larger
graph for time spent
depicts the revenue of
on a larger time
the revenue of pool
for time spent on
a larger time scale
time spent on fetch
spent on fetch rpcs
larger time scale than
time scale than the
scale than the experiments
than the experiments considered
the experiments considered in
which is strictly smaller
experiments considered in at
is strictly smaller than
considered in at the
at the timescales in
in at the start
the timescales in the
in the entire range
timescales in the ntfs
at the start of
in the ntfs traces
the start of this
start of this section
of this section we
this section we identified
section we identified large
the improvements are less
improvements are less dramatic
are less dramatic than
note that the total
less dramatic than in
that the total system
dramatic than in the
the total system mining
than in the microbenchmarks
scale collaborative this paper
total system mining power
system mining power is
mining power is reduced
power is reduced when
is reduced when pool
but they demonstrate that
we omit its details
they demonstrate that mafs
omit its details for
demonstrate that mafs can
its details for brevity
that mafs can improve
chooses to infiltrate pool
mafs can improve the
can improve the performance
improve the performance of
the performance of large
engineering design as an
design as an example
journal of lightwave technology
as an example of
an example of a
example of a scenario
of a scenario which
a scenario which features
scenario which features when
the revenue of third
which features when a
revenue of third parties
store rpc begins to
features when a process
when a process modifies
rpc begins to arrive
a process modifies a
process modifies a file
begins to arrive store
miners not in either
not in either pool
to arrive store rpc
arrive store rpc received
an update is scheduled
store rpc received dat
update is scheduled to
rpc received dat ar
is scheduled to be
received dat ar re
scheduled to be a
dat ar re sto
to be a high
ar re sto reply
be a high degree
re sto reply ata
a high degree of
sto reply ata e
high degree of read
reply ata e d
ata e d stor
e d stor pc
d stor pc time
stor pc time open
pc time open file
time open file for
open file for writing
file for writing close
for writing close file
at present we have
present we have evalappended
we have evalappended to
have evalappended to the
evalappended to the log
replay log log update
log log update store
log update store rpc
and the process continues
update store rpc complete
the process continues executing
store rpc complete writeback
process continues executing withuated
rpc complete writeback window
continues executing withuated the
complete writeback window analysis
executing withuated the mfs
writeback window analysis client
withuated the mfs cache
window analysis client both
the mfs cache consistency
analysis client both experiments
mfs cache consistency algorithm
client both experiments confirm
cache consistency algorithm using
both experiments confirm the
consistency algorithm using a
therefore pays for the
experiments confirm the benefits
algorithm using a synthetic
confirm the benefits of
pays for the increased
the benefits of asynchronous
using a synthetic out
benefits of asynchronous writeback
for the increased revenue
a synthetic out having
the increased revenue of
synthetic out having to
increased revenue of its
out having to wait
revenue of its attacker
even at bandwidths where
having to wait for
of its attacker and
to wait for the
at bandwidths where a
wait for the server
its attacker and everyone
for the server to
bandwidths where a typical
the server to be
attacker and everyone else
where a typical mobile
and everyone else in
server to be contacted
everyone else in the
a typical mobile file
else in the system
typical mobile file system
mobile file system performs
file system performs all
system performs all rpcs
performs all rpcs synchronously
though we are hoping
implications to the general
we are hoping to
to the general case
are hoping to obtain
the general case consider
asynchronous writeback avoids the
hoping to obtain real
writeback avoids the need
general case consider the
avoids the need to
case consider the case
the need to switch
consider the case of
need to switch operation
the case of p
to switch operation into
case of p pools
to obtain real data
switch operation into a
obtain real data from
operation into a distinct
real data from such
into a distinct low
data from such an
for any choice of
from such an thread
any choice of the
such an thread then
choice of the pools
an thread then checks
of the pools sizes
thread then checks the
the pools sizes m
then checks the status
checks the status of
and choosing a bandwidth
the status of the
choosing a bandwidth threshold
status of the file
a bandwidth threshold at
of the file the
bandwidth threshold at which
the file the update
threshold at which to
file the update modifies
the effects of systemic
at which to switch
effects of systemic packet
of systemic packet loss
systemic packet loss on
packet loss on aggregate
loss on aggregate tcp
if the environment in
on aggregate tcp flows
the environment in the
when used by themselves
environment in the future
priorities do not always
do not always result
not always result in
always result in improved
result in improved performance
the update is queued
update is queued for
is queued for transmission
queued for transmission at
at least one pool
for transmission at the
least one pool will
transmission at the reg
since they are only
one pool will choose
they are only effective
pool will choose to
are only effective if
will choose to perform
ieee conference on supercomputing
choose to perform block
only effective if concurrent
to perform block withholding
effective if concurrent rpcs
if concurrent rpcs have
concurrent rpcs have different
rpcs have different priorities
in a system with
they reduce uservisible delay
a system with p
reduce uservisible delay and
system with p pools
uservisible delay and contention
delay and contention that
and contention that is
contention that is introduced
that is introduced by
is introduced by asynchronous
introduced by asynchronous writeback
update propagation using asynchronous
propagation using asynchronous writeback
using asynchronous writeback at
asynchronous writeback at all
writeback at all bandwidths
is not an equilibrium
at all bandwidths delays
all bandwidths delays sending
bandwidths delays sending updates
delays sending updates to
sending updates to the
updates to the file
to the file server
assume towards negation this
towards negation this is
negation this is not
this is not the
is not the case
we evaluate the effectiveness
evaluate the effectiveness of
the effectiveness of an
effectiveness of an update
of an update propagation
an update propagation scheme
update propagation scheme to
propagation scheme to reduce
scheme to reduce this
to reduce this delay
mafs allows a client
allows a client to
a client to delay
client to delay transmitting
to delay transmitting updates
is an equilibrium point
but the file server
now consider a setting
the file server forces
consider a setting with
file server forces file
a setting with only
server forces file updates
setting with only pools
forces file updates to
file updates to be
end performance effects of
updates to be written
performance effects of parallel
to be written back
effects of parallel tcp
be written back when
of parallel tcp sockets
written back when another
parallel tcp sockets on
back when another client
tcp sockets on a
when another client must
sockets on a lossy
another client must read
on a lossy wide
client must read an
and treat the other
must read an up
treat the other pools
the other pools as
other pools as independent
pools as independent miners
this is the setting
date copy of the
is the setting analyzed
copy of the file
the setting analyzed above
setting analyzed above and
analyzed above and we
above and we have
and we have seen
we have seen there
have seen there that
seen there that pool
can increase its revenue
timeline of a file
increase its revenue by
of a file update
its revenue by performing
international parallel and distributed
revenue by performing a
parallel and distributed processing
by performing a block
and distributed processing symposium
performing a block withholding
a block withholding attack
time advances from left
block withholding attack on
advances from left to
withholding attack on pool
from left to right
client will access stale
will access stale data
due to network latency
s infiltration rate by
infiltration rate by x
the writeback window can
writeback window can never
window can never be
can never be eliminated
but adding an additional
adding an additional delay
an additional delay before
additional delay before writing
delay before writing back
before writing back the
writing back the update
back the update increases
the update increases the
update increases the scope
increases the scope for
the scope for inconsistency
take this values p
this values p m
the performance of tcp
illustrates how this inconsistency
how this inconsistency can
this inconsistency can arise
ip for networks with
for networks with high
networks with high bandwidth
delay products and random
like file system such
products and random loss
file system such as
system such as mafs
a different type of
different type of inconsistency
acm transactions on networking
type of inconsistency is
of inconsistency is introduced
inconsistency is introduced between
is introduced between a
introduced between a client
between a client and
a client and the
client and the server
and the server when
the server when a
server when a file
when a file is
a file is modified
number of rpcs average
of rpcs average time
since the change is
the change is hidden
change is hidden from
is hidden from the
hidden from the server
from the server until
the server until the
server until the file
until the file is
the file is closed
for the purposes of
the purposes of this
purposes of this investigation
of this investigation we
this investigation we assume
investigation we assume that
we assume that the
assume that the open
close interval for a
interval for a file
hik j ihkj m
for a file is
j ihkj m l
a file is small
ihkj m l ml
file is small relative
m l ml cb
is small relative to
l ml cb c
small relative to the
ml cb c b
relative to the network
cb c b cbcb
to the network latency
c b cbcb ed
the network latency and
b cbcb ed f
network latency and writeback
cbcb ed f gf
latency and writeback delay
ed f gf cb
f gf cb c
gf cb c b
cb c b yx
c b yx cbcb
the update propagation techniques
update propagation techniques we
propagation techniques we describe
z eded f f
techniques we describe can
eded f f gfgf
we describe can be
f f gfgf cb
describe can be applied
f gfgf cb b
can be applied equally
gfgf cb b on
be applied equally well
cb b on yxyx
applied equally well to
b on yxyx cbb
equally well to individual
well to individual file
to individual file writes
individual file writes as
file writes as to
writes as to writeback
z eded f f
gfgf c c b
c c b on
c b on yx
b on yx ccb
on yx ccb qp
techniques for update propagation
for update propagation although
update propagation although coda
like file systems can
file systems can generate
systems can generate inconsistencies
can generate inconsistencies between
generate inconsistencies between clients
gf cb b c
cb b c onon
b c onon yxxy
c onon yxxy cbbc
onon yxxy cbbc qpqp
they were designed to
were designed to permit
designed to permit a
to permit a client
permit a client to
a client to function
client to function at
to function at low
z eded r f
function at low bandwidth
a simple model and
eded r f f
simple model and its
r f f srs
model and its empirical
and its empirical validation
rather than for rapid
than for rapid update
for rapid update propagation
acm sigcomm computer communication
sigcomm computer communication review
since it is impractical
it is impractical to
is impractical to lock
impractical to lock files
to lock files if
lock files if clients
gfgf c b onon
files if clients are
c b onon yx
if clients are permitted
b onon yx cb
clients are permitted to
onon yx cb qp
are permitted to modify
permitted to modify the
to modify the filesystem
modify the filesystem while
the filesystem while they
filesystem while they are
while they are disconnected
z ed r f
ed r f r
coda supports stronger consistency
supports stronger consistency through
stronger consistency through optimistic
consistency through optimistic replication
gf invalidations and server
invalidations and server pulls
and server pulls mfs
an alternative approach is
diff synchronous average time
alternative approach is to
approach is to allow
is to allow a
to allow a client
allow a client to
a client to use
client to use asynchronous
to use asynchronous writeback
but require that it
require that it alerts
that it alerts the
it alerts the file
alerts the file server
the file server when
file server when a
server when a file
when a file is
a file is modified
by sending an invalidation
sending an invalidation rpc
this informs the server
informs the server that
the server that the
server that the update
that the update exists
the update exists before
update exists before the
exists before the new
before the new file
the new file contents
new file contents ar
origin of inconsistencies since
of inconsistencies since asynchronous
inconsistencies since asynchronous writeback
since asynchronous writeback decouples
asynchronous writeback decouples modifying
writeback decouples modifying a
decouples modifying a file
congestion control for high
modifying a file from
control for high bandwidth
a file from notifying
file from notifying the
from notifying the server
notifying the server that
the server that a
server that a change
that a change has
a change has occurred
it can generate inconsistencies
can generate inconsistencies between
generate inconsistencies between cached
inconsistencies between cached copies
illustrates the potential for
the potential for inconsistency
during the writeback window
another client accessing a
client accessing a cached
accessing a cached copy
or fetching the file
fetching the file from
the file from the
file from the file
from the file server
will not read up
from the server s
effective erasure codes for
the server s perspective
erasure codes for reliable
codes for reliable computer
for reliable computer communication
reliable computer communication protocols
there is no inconsistency
acm sigcomm computer communication
sigcomm computer communication review
since it is unaware
it is unaware of
is unaware of the
unaware of the new
of the new update
stable state where only
state where only pool
from a global perspective
writing client writes a
client writes a closes
writes a closes a
reading client server fetch
client server fetch a
server fetch a fetch
fetch a fetch reply
flushes update store a
update store a callback
store a callback for
a callback for a
callback for a fetch
for a fetch a
a fetch a open
fetch a open a
writes a closes a
two pools where one
pools where one infiltrates
where one infiltrates the
one infiltrates the other
optimal infiltration rate x
flushes update open a
on the feasibility of
the feasibility of software
feasibility of software fec
fetch reply reading client
reply reading client server
universita di pisa deit
di pisa deit technical
reading client server invalidate
pisa deit technical report
deit technical report lr
client server invalidate a
as a function of
a function of pool
function of pool sizes
writing client pull a
and the lines in
callback for a fetch
for a fetch a
show the revenue density
the revenue density of
back to the setting
to the setting at
the case for packet
the setting at hand
case for packet level
setting at hand with
for packet level fec
at hand with p
store a fetch reply
hand with p pools
in fifth international workshop
fifth international workshop on
international workshop on protocols
the revenue of pool
workshop on protocols for
on protocols for high
is better when x
asynchronous writeback with invalidations
writeback with invalidations figure
a client s update
client s update is
s update is logged
update is logged when
is logged when the
logged when the file
when the file is
the file is closed
while it is in
it is in the
is in the log
other clients see the
clients see the server
see the server s
the server s stale
server s stale version
an invalidation rpc allows
invalidation rpc allows the
rpc allows the server
allows the server to
the server to invalidate
server to invalidate other
to invalidate other clients
invalidate other clients cached
other clients cached copies
a client that modifies
client that modifies a
that modifies a file
lateral error correction for
modifies a file could
error correction for time
a file could save
file could save bandwidth
could save bandwidth by
save bandwidth by not
bandwidth by not sending
by not sending it
not sending it to
sending it to the
it to the file
to the file server
the file server at
file server at all
can improve its revenue
improve its revenue by
its revenue by attacking
revenue by attacking pool
unless the server pulls
the server pulls it
server pulls it to
pulls it to supply
it to supply it
to supply it to
supply it to another
it to another client
fourth usenix symposium on
usenix symposium on networked
mafs clients push updates
symposium on networked systems
clients push updates to
on networked systems design
push updates to the
networked systems design and
updates to the server
systems design and implementation
to the server in
attacks is not an
the server in the
is not an equilibrium
server in the background
not an equilibrium point
to reduce the delay
reduce the delay incurred
the delay incurred when
delay incurred when fetching
incurred when fetching an
when fetching an invalidated
fetching an invalidated file
case as a test
as a test case
pushing updates can result
updates can result in
can result in the
result in the server
we take the pool
in the server having
take the pool distribution
the server having received
the pool distribution in
server having received some
pool distribution in january
or all of the
all of the update
of the update by
the update by the
update by the time
by the time another
the time another client
time another client accesses
another client accesses it
selective invalidation with reader
invalidation with reader pull
with reader pull the
reader pull the effect
pull the effect of
the effect of selective
effect of selective invalidation
of selective invalidation and
selective invalidation and reader
invalidation and reader pull
and reader pull is
reader pull is that
pull is that mafs
is that mafs incorporates
that mafs incorporates sirp
a new algorithm for
new algorithm for maintaining
algorithm for maintaining inter
we analyze the cases
sirp behaves similarly to
analyze the cases where
behaves similarly to synchronous
the cases where each
similarly to synchronous writeback
cases where each of
to synchronous writeback if
where each of the
synchronous writeback if a
each of the pools
writeback if a client
of the pools attacks
if a client client
the pools attacks all
a client client consistency
pools attacks all other
attacks all other open
all other open pools
which combines asynchronous writeback
combines asynchronous writeback with
all of which behave
asynchronous writeback with concurrently
of which behave honestly
writeback with concurrently fetches
with concurrently fetches a
concurrently fetches a file
note that attacking all
that attacking all pools
but behaves like asynchronous
attacking all pools with
behaves like asynchronous writeinvalidations
all pools with force
like asynchronous writeinvalidations and
pools with force proportional
asynchronous writeinvalidations and expedited
with force proportional to
writeinvalidations and expedited transmission
force proportional to their
and expedited transmission of
proportional to their size
expedited transmission of updates
an integrated experimental environment
transmission of updates for
to their size yields
of updates for files
integrated experimental environment for
updates for files back
their size yields the
for files back when
experimental environment for distributed
files back when there
size yields the same
back when there are
yields the same results
when there are no
environment for distributed systems
there are no concurrent
the same results as
are no concurrent fetches
for distributed systems and
same results as attacking
distributed systems and networks
results as attacking a
as attacking a single
attacking a single pool
a single pool of
like synchronous that other
single pool of their
synchronous that other clients
pool of their aggregate
that other clients are
of their aggregate size
other clients are attempting
clients are attempting to
are attempting to read
plugging in the numbers
in the numbers into
the numbers into the
sirp sends an rpc
numbers into the analysis
sends an rpc to
into the analysis above
fifth usenix symposium on
an rpc to the
usenix symposium on operating
rpc to the server
symposium on operating systems
to the server as
on operating systems design
the server as soon
operating systems design and
server as soon as
systems design and implementation
the analysis above shows
as soon as an
soon as an application
analysis above shows that
as an application closes
an application closes a
above shows that a
application closes a modified
closes a modified file
shows that a larger
that a larger pool
a larger pool needs
larger pool needs to
but it can defer
it can defer transmitting
pool needs to use
can defer transmitting the
needs to use a
defer transmitting the selective
to use a smaller
transmitting the selective invalidation
use a smaller ratio
a smaller ratio of
smaller ratio of its
ratio of its mining
using an invalidation rpc
of its mining power
an invalidation rpc to
its mining power for
invalidation rpc to alert
mining power for infiltration
rpc to alert the
power for infiltration and
to alert the actual
for infiltration and can
alert the actual contents
infiltration and can increase
the actual contents until
and can increase its
actual contents until they
can increase its revenue
contents until they are
increase its revenue density
until they are needed
its revenue density more
revenue density more than
density more than a
more than a small
than a small pool
file server to the
server to the existence
to the existence of
the existence of a
existence of a new
of a new update
a new update improves
new update improves cache
update improves cache consistency
achieves its optimum attack
but consumes additional bandwidth
its optimum attack rate
optimum attack rate at
if writeback traffic is
writeback traffic is low
traffic is low enough
is low enough for
low enough for the
enough for the server
for the server to
the server to start
server to start receiving
of the pool s
to start receiving an
the pool s mining
start receiving an update
pool s mining power
increasing its revenue by
physical layer impact upon
its revenue by almost
layer impact upon packet
impact upon packet errors
experimental evaluation immediately after
evaluation immediately after it
immediately after it receives
after it receives the
it receives the invalidation
this amounts to a
the invalidation we conclude
amounts to a daily
invalidation we conclude this
to a daily revenue
we conclude this section
a daily revenue increase
conclude this section with
daily revenue increase of
average duration of reader
this section with an
duration of reader fetch
revenue increase of b
section with an experiment
with an experiment that
an experiment that compares
experiment that compares the
passive and active measurement
that compares the is
and active measurement workshop
compares the is superfluous
sirp avoids this overhead
avoids this overhead by
this overhead by performing
overhead by performing selec
effectiveness of sirp to
of sirp to three
sirp to three alternatives
usd at the exchange
when a client adds
at the exchange rate
a client adds an
the exchange rate on
client adds an update
exchange rate on that
adds an update to
rate on that date
an update to the
update to the writeback
to the writeback back
the writeback back transmits
writeback back transmits an
this represents a considerable
back transmits an update
represents a considerable increase
transmits an update as
a considerable increase of
an update as soon
considerable increase of the
update as soon as
increase of the pools
as soon as a
of the pools net
soon as a file
the pools net revenue
as a file is
a file is closed
for the smallest pool
it only sends an
only sends an invalidation
sends an invalidation if
an invalidation if the
invalidation if the queue
if the queue is
the queue is not
queue is not empty
the attack is much
attack is much less
is much less profitable
chronous writeback puts the
writeback puts the update
puts the update in
to reach the optimum
the update in a
reach the optimum it
update in a queue
the optimum it needs
in a queue and
optimum it needs almost
a queue and transmits
it needs almost a
queue and transmits it
needs almost a third
and transmits it if
almost a third of
transmits it if the
a third of its
it if the queue
third of its power
if the queue is
of its power for
the queue is empty
its power for attacking
power for attacking but
for attacking but increases
attacking but increases its
but increases its revenue
increases its revenue density
the invalidation is piggybacked
its revenue density by
invalidation is piggybacked onto
revenue density by merely
is piggybacked onto the
piggybacked onto the as
onto the as soon
the as soon as
as soon as it
soon as it reaches
as it reaches the
it reaches the front
reaches the front of
the front of the
front of the queue
we also compare update
sirp against a policy
against a policy we
a policy we refer
policy we refer to
we refer to as
refer to as sirp
which only differs from
only differs from sirp
differs from sirp in
from sirp in performing
sirp in performing compulsory
in performing compulsory invalidations
when the server receives
name size discusfish antpool
the server receives an
size discusfish antpool ghash
server receives an invalidation
receives an invalidation from
an invalidation from a
invalidation from a date
io btchine btcguild eligius
from a date results
btchine btcguild eligius others
a date results in
date results in an
results in an invalidation
in an invalidation rpc
an invalidation rpc to
invalidation rpc to the
rpc to the server
it makes callbacks to
the university of illinois
makes callbacks to all
university of illinois national
callbacks to all the
of illinois national center
to all the other
illinois national center for
all the other clients
national center for supercomputing
the other clients that
center for supercomputing applications
other clients that cache
clients that cache the
that cache the are
cache the are of
the are of particular
are of particular interest
of particular interest in
particular interest in this
interest in this comparison
to tell them to
tell them to discard
them to discard their
to discard their copies
if several clients modify
several clients modify are
clients modify are the
modify are the files
are the files readers
the files readers read
how is the performance
is the performance of
the performance of the
performance of the same
of the same file
global crossing current network
modifications are serialised in
crossing current network performance
are serialised in the
serialised in the order
in the order of
the order of their
order of their readers
of their readers and
their readers and writers
readers and writers affected
and writers affected by
writers affected by stronger
affected by stronger consistency
the client that made
client that made the
that made the update
made the update only
the update only transmits
update only transmits it
only transmits it when
transmits it when it
it when it reaches
when it reaches the
it reaches the head
reaches the head of
the head of the
head of the writeback
of the writeback queue
if another client attempts
another client attempts to
client attempts to fetch
attempts to fetch the
to fetch the file
fetch the file during
the file during the
file during the update
during the update s
the update s experimental
update s experimental setup
s experimental setup writeback
experimental setup writeback window
the server blocks that
server blocks that client
blocks that client until
that client until the
client until the update
until the update has
the update has arrived
the server also makes
qwest ip network statistics
server also makes a
also makes a pull
makes a pull rpc
a pull rpc to
pull rpc to the
rpc to the client
to the client that
the client that experiments
client that experiments were
that experiments were conducted
experiments were conducted in
were conducted in a
conducted in a network
in a network of
a network of five
network of five hosts
one modified the file
instructing it to expedite
it to expedite sending
to expedite sending the
expedite sending the update
one writer client that
on onon yxyx p
writer client that was
onon yxyx p p
client that was responsible
yxyx p p qpqp
that was responsible for
was responsible for modifying
responsible for modifying when
for modifying when it
modifying when it receives
z onon yxyx p
when it receives the
onon yxyx p p
it receives the pull
yxyx p p qppq
receives the pull rpc
the client begins sending
client begins sending back
begins sending back a
sending back a collection
z on yx p
back a collection of
on yx p qp
a collection of files
z onon yxxy p
and three reader clients
onon yxxy p p
three reader clients that
yxxy p p qpqp
reader clients that only
clients that only read
that only read the
only read the the
read the the update
the the update at
the update at the
update at the same
z on yx p
at the same priority
on yx p qp
vice president of research
the same priority as
president of research and
same priority as an
of research and t
priority as an rpc
as an rpc to
an rpc to fetch
rpc to fetch file
to fetch file data
z time spent on
time spent on invalidations
the bandwidth between the
bandwidth between the writer
between the writer client
the writer client and
writer client and the
client and the server
and the server that
the server that it
server that it will
that it will be
it will be preferentially
will be preferentially allocated
be preferentially allocated bandwidth
if the update was
the update was set
update was set to
average store rpc duration
the six largest open
six largest open pool
largest open pool sizes
open pool sizes as
pool sizes as of
sizes as of january
and the reader client
server was already being
was already being written
already being written back
the client increases its
client increases its priority
bandwidth was always set
was always set to
acm transactions on networking
so that it can
their optimal infiltration rates
that it can prevent
it can prevent inconsistencies
can prevent inconsistencies by
prevent inconsistencies by inhibiting
inconsistencies by inhibiting access
of each pool as
by inhibiting access to
each pool as a
inhibiting access to the
pool as a fraction
access to the file
as a fraction of
to the file by
a fraction of its
the file by other
fraction of its size
file by other clients
if it attacked all
as shown in figure
it attacked all others
attacked all others without
all others without reciprocation
and their revenue density
their revenue density when
revenue density when attacking
invalidations are used in
are used in fluid
used in fluid replication
t wo p ools
wo p ools we
p ools we proceed
ools we proceed to
we proceed to analyze
proceed to analyze the
to analyze the case
to allow clients to
analyze the case where
allow clients to avoid
the case where two
clients to avoid sending
case where two pools
to avoid sending data
where two pools may
avoid sending data across
two pools may attack
sending data across a
pools may attack each
data across a wide
may attack each other
attack each other and
each other and the
other and the other
and the other miners
the other miners mine
other miners mine solo
v v w w
v w w ut
w w ut v
w ut v wv
again we have pool
ut v wv ut
the server only asks
server only asks the
only asks the client
asks the client for
the client for a
client for a file
for a file s
a file s data
file s data if
s data if another
data if another client
if another client requests
another client requests it
controls its infiltration rate
its infiltration rate x
s read staleness at
also controls its infiltration
controls its infiltration rate
its infiltration rate x
a method for improving
method for improving tcp
for improving tcp performance
improving tcp performance over
tcp performance over wireless
this scenario is illustrated
performance over wireless links
scenario is illustrated in
is illustrated in figure
the total mining power
total mining power in
graphs for cache consistency
mining power in the
for cache consistency trace
power in the system
in the system is
the system is m
system is m x
these graphs show various
graphs show various features
show various features of
various features of the
features of the performance
of the performance results
nd ieee wireless communications
async denotes asynchronous invalidations
ieee wireless communications and
wireless communications and networking
communications and networking conference
and none no invalidations
the direct revenues r
diff denotes differentiated writeback
denotes differentiated writeback priorities
differentiated writeback priorities for
writeback priorities for shared
priorities for shared and
for shared and unshared
shared and unshared files
of the pools from
the pools from mining
pools from mining are
from mining are their
mining are their effective
and unif denotes uniform
are their effective mining
unif denotes uniform priorities
their effective mining rates
cc is the mfs
is the mfs cache
the mfs cache consistency
mfs cache consistency algorithm
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
the height of a
height of a bar
of a bar counts
a bar counts the
bar counts the number
counts the number of
the number of invalidations
an adaptive forward error
adaptive forward error correction
forward error correction protocol
the white portion counts
error correction protocol for
white portion counts the
correction protocol for end
portion counts the number
counts the number of
the number of server
end transport of real
staleness of version retrieved
our experimental setup consisting
experimental setup consisting of
setup consisting of three
consisting of three hosts
and a writer client
the bandwidth from the
bandwidth from the reader
from the reader to
the reader to the
reader to the server
two attacking pools system
to the server was
the server was fixed
server was fixed at
th international conference on
international conference on computer
conference on computer communications
on computer communications and
computer communications and networks
and the bandwidth from
the bandwidth from the
bandwidth from the writer
from the writer to
the writer to the
writer to the server
to the server was
the server was varied
server was varied according
was varied according to
varied according to the
as a function of
according to the experiment
a function of pool
function of pool sizes
the writer was configured
writer was configured in
was configured in one
configured in one of
synchronous writeback asynchronous writeback
in one of seven
writeback asynchronous writeback sirp
one of seven different
asynchronous writeback sirp c
of seven different ways
writeback sirp c sirp
synchronous or no invalidations
and differentiated or uniform
differentiated or uniform priorities
cumulative proportion of reads
or uniform priorities for
uniform priorities for writing
priorities for writing back
for writing back shared
writing back shared and
back shared and unshared
shared and unshared files
based loss recovery for
loss recovery for reliable
the mfs concurrency control
recovery for reliable multicast
mfs concurrency control algorithm
for reliable multicast transmission
corresponds to asynchronous invalidations
to asynchronous invalidations with
asynchronous invalidations with differentiated
invalidations with differentiated priority
with differentiated priority for
differentiated priority for shared
priority for shared files
both clients access a
clients access a shared
access a shared repository
a shared repository of
shared repository of files
repository of files stored
of files stored on
files stored on the
stored on the file
on the file server
staleness of version retrieved
of version retrieved read
version retrieved read staleness
retrieved read staleness at
each module has a
module has a descriptor
has a descriptor file
a descriptor file and
descriptor file and a
file and a set
and a set of
end performance evaluation of
module descriptor files are
cumulative proportion of reads
descriptor files are about
proportion of reads cumulative
of reads cumulative proportion
reads cumulative proportion of
cumulative proportion of reads
kb in size and
in size and the
member files take up
files take up an
take up an average
up an average of
two pools infiltrating each
pools infiltrating each other
the total size of
total size of all
th symposium on high
size of all the
symposium on high performance
of all the files
on high performance interconnects
all the files in
the files in the
files in the collection
divided by the total
in the collection is
by the total mining
the total mining rate
the writer workload consists
writer workload consists of
workload consists of the
consists of the writer
of the writer updating
the writer updating modules
writer updating modules in
updating modules in a
modules in a random
in a random order
an update to a
update to a module
to a module consists
a module consists of
module consists of a
consists of a sequence
of a sequence of
a sequence of operations
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
of which are reads
which are reads and
end forward error correction
are writes to a
writes to a file
to a file in
a file in the
file in the module
staleness of version retrieved
consist of writes to
of writes to unshared
writes to unshared external
to unshared external files
international zurich seminar on
zurich seminar on communications
which are each created
are each created with
each created with a
created with a unique
with a unique name
there is a pause
staleness of reader file
is a pause between
of reader file accesses
a pause between each
pause between each operation
between each operation and
each operation and a
operation and a longer
cumulative distributions for the
and a longer pause
distributions for the staleness
a longer pause between
for the staleness of
longer pause between updates
the staleness of all
pause between updates to
staleness of all accesses
between updates to modules
of all accesses to
all accesses to files
the total revenue of
accesses to files by
total revenue of each
to files by the
revenue of each pool
files by the three
the reader workload is
by the three readers
of each pool is
the three readers are
reader workload is similar
three readers are shown
each pool is its
pool is its direct
is its direct mining
its direct mining revenue
but an access to
higher curves represent less
an access to a
curves represent less staleness
access to a module
to a module consists
a module consists of
module consists of a
consists of a series
of a series of
and the infiltration revenue
a series of reads
the infiltration revenue from
total writer execution time
infiltration revenue from the
revenue from the previous
from the previous round
and external files are
external files are never
files are never accessed
which is the attacked
is the attacked pool
the configuration parameters used
the attacked pool s
configuration parameters used to
attacked pool s total
parameters used to generate
pool s total revenue
used to generate the
s total revenue multiplied
to generate the reader
total revenue multiplied by
generate the reader and
revenue multiplied by its
the reader and writer
multiplied by its infiltration
reader and writer workload
by its infiltration rate
and writer workload are
writer workload are listed
workload are listed in
are listed in table
the case for application
the pool s total
pool s total revenue
synchronous writeback asynchronous writeback
s total revenue is
writeback asynchronous writeback sirp
total revenue is divided
level network striping for
revenue is divided among
asynchronous writeback sirp c
is divided among its
writeback sirp c sirp
the writer workload has
network striping for data
writer workload has a
divided among its loyal
workload has a nominal
striping for data intensive
has a nominal duration
among its loyal miners
a nominal duration of
for data intensive applications
nominal duration of two
its loyal miners and
duration of two minutes
data intensive applications using
loyal miners and miners
intensive applications using high
miners and miners that
applications using high speed
and miners that infiltrated
using high speed wide
miners that infiltrated it
while the reader workload
high speed wide area
the reader workload is
speed wide area networks
reader workload is extended
workload is extended to
at stable state this
is extended to terminate
stable state this is
extended to terminate at
state this is r
to terminate at the
terminate at the same
at the same time
the same time as
same time as the
time as the writer
as the writer workload
the writer workload actually
writer workload actually finishes
since low bandwidth could
low bandwidth could extend
ieee conference on supercomputing
bandwidth could extend its
could extend its running
extend its running time
its running time beyond
running time beyond two
time beyond two minutes
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
analysis of the results
of the results figure
shows graphs of some
graphs of some selected
of some selected results
some selected results from
selected results from the
results from the experiments
while synchronous writes provide
synchronous writes provide strong
writes provide strong concurrency
provide strong concurrency control
they resulted in the
resulted in the lowest
tsunami file transfer protocol
in the lowest rate
the lowest rate of
lowest rate of completed
rate of completed writes
of completed writes in
completed writes in all
writes in all the
in all the tests
since the writer had
the writer had no
writer had no possibility
had no possibility of
no possibility of over
first international workshop on
lapping think time with
international workshop on protocols
think time with asynchronous
workshop on protocols for
time with asynchronous writeback
on protocols for fast
protocols for fast long
at all bandwidth levels
all bandwidth levels the
bandwidth levels the mfs
cc algorithm outperformed synchronous
algorithm outperformed synchronous writes
outperformed synchronous writes by
synchronous writes by at
writes by at least
we obtain the following
and was among the
obtain the following closed
was among the options
the following closed expressions
among the options with
following closed expressions for
the options with the
closed expressions for each
options with the highest
with the highest write
the highest write throughput
we express the revenues
express the revenues as
the revenues as functions
this is clear from
revenues as functions of
is clear from graph
as functions of x
which shows the average
shows the average time
the average time to
average time to complete
time to complete store
to complete store rpcs
complete store rpcs initiated
store rpcs initiated by
rpcs initiated by the
initiated by the writer
cc outperforms all of
outperforms all of the
average reader execution time
all of the alternatives
predictable high performance bulk
high performance bulk data
performance bulk data transfer
this is because of
is because of the
because of the reduced
of the reduced number
the reduced number of
reduced number of invalidations
number of invalidations it
of invalidations it generates
in contrast to most
contrast to most of
to most of the
most of the other
of the other schemes
ieee international conference on
international conference on cluster
it is able to
conference on cluster computing
is able to take
able to take advantage
to take advantage of
take advantage of both
advantage of both differentiated
of both differentiated writeback
pull rpcs to raise
rpcs to raise the
to raise the priority
raise the priority of
the priority of its
priority of its writes
shows the performance from
the performance from the
performance from the reader
from the reader s
the reader s perspective
while the writer is
the writer is able
writer is able to
is able to decrease
able to decrease its
to decrease its time
decrease its time spent
its time spent performing
time spent performing store
spent performing store rpcs
the reader s average
reader s average time
s average time spent
average time spent on
time spent on fetches
spent on fetches increases
solomon codes and their
on fetches increases sharply
codes and their applications
fetches increases sharply when
increases sharply when the
sharply when the file
when the file in
the file in question
file in question must
in question must be
question must be pulled
execution times for concurrent
must be pulled from
times for concurrent access
be pulled from the
for concurrent access trace
pulled from the writer
reader execution times are
execution times are averages
times are averages for
are averages for the
averages for the three
for the three readers
this cost must be
cost must be weighed
must be weighed against
be weighed against the
weighed against the benefit
against the benefit of
the benefit of substantially
benefit of substantially increased
of substantially increased writer
higher bandwidth results in
substantially increased writer throughput
bandwidth results in less
results in less staleness
differentiated writeback succeeds in
since writes can be
writeback succeeds in reducing
writes can be sent
succeeds in reducing the
can be sent to
in reducing the time
be sent to the
reducing the time the
sent to the file
the time the reader
to the file server
time the reader has
the file server faster
the reader has to
reader has to wait
has to wait when
to wait when accessing
wait when accessing a
when accessing a shared
accessing a shared file
sirp is most effective
is most effective at
most effective at reducing
effective at reducing staleness
nat and packet mangling
and packet mangling for
packet mangling for linux
show statistics for invalidations
though many reads return
statistics for invalidations and
many reads return out
for invalidations and serverpull
invalidations and serverpull rpcs
and serverpull rpcs for
serverpull rpcs for those
rpcs for those writer
for those writer configurations
those writer configurations which
writer configurations which make
date file contents when
configurations which make use
file contents when compared
which make use of
contents when compared to
make use of them
when compared to the
compared to the optimal
to the optimal version
cc significantly reduces the
significantly reduces the number
reduces the number of
the number of invalidations
more sirp reads are
sirp reads are up
number of invalidations it
of invalidations it must
invalidations it must transmit
it must transmit by
must transmit by putting
transmit by putting off
by putting off invalidating
putting off invalidating a
off invalidating a file
invalidating a file until
a file until it
compared to synchronous or
file until it is
to synchronous or asynchronous
until it is added
synchronous or asynchronous writeback
it is added to
is added to the
added to the log
allowing higher degrees of
higher degrees of staleness
yet the effect of
the effect of this
effect of this policy
of this policy on
this policy on the
policy on the number
on the number of
the number of serverpull
number of serverpull rpcs
of serverpull rpcs is
serverpull rpcs is minor
more reads performed with
reads performed with sirp
performed with sirp are
with sirp are within
versions of the optimal
which differs from mfs
with this bandwidth level
cc in omitting differentiated
in omitting differentiated writeback
synchronous and asynchronous writeback
multicast routing in datagram
and asynchronous writeback coincide
routing in datagram internetworks
asynchronous writeback coincide in
in datagram internetworks and
writeback coincide in performance
datagram internetworks and extended
makes more invalidations and
internetworks and extended lans
more invalidations and incurs
invalidations and incurs more
and incurs more server
since they are constrained
they are constrained by
acm transactions on computers
are constrained by the
transactions on computers systems
constrained by the bandwidth
by the bandwidth bottleneck
the bandwidth bottleneck and
bandwidth bottleneck and send
bottleneck and send updates
because its store rpcs
and send updates in
its store rpcs must
send updates in the
store rpcs must compete
updates in the same
each pool controls only
rpcs must compete with
in the same order
must compete with the
pool controls only its
compete with the rpcs
controls only its own
with the rpcs to
only its own infiltration
the rpcs to write
its own infiltration rate
rpcs to write back
by suppressing unnecessary invalidations
to write back external
write back external files
in each round of
each round of the
sirp reduces its bandwidth
round of the pool
this increases the commit
reduces its bandwidth usage
increases the commit delay
of the pool game
the commit delay for
its bandwidth usage and
commit delay for each
bandwidth usage and achieves
delay for each file
usage and achieves a
for each file and
and achieves a small
each pool will optimize
achieves a small improvement
each file and the
a small improvement over
pool will optimize its
file and the likelihood
small improvement over sirp
will optimize its infiltration
and the likelihood of
optimize its infiltration rate
the likelihood of it
its infiltration rate of
likelihood of it being
infiltration rate of the
of it being accessed
rate of the other
it being accessed by
being accessed by the
accessed by the reader
since devoting less bandwidth
by the reader while
devoting less bandwidth to
the reader while it
less bandwidth to invalidations
reader while it is
bandwidth to invalidations results
while it is being
to invalidations results in
acts at step t
invalidations results in data
it is being written
results in data reaching
is being written back
in data reaching the
data reaching the server
reaching the server faster
it optimizes its revenue
optimizes its revenue with
its revenue with x
these experiments demonstrate that
experiments demonstrate that for
asynchronous writeback performs as
demonstrate that for the
writeback performs as well
that for the trace
performs as well as
for the trace we
as well as sirp
the trace we have
trace we have examined
the mfs algorithm of
synchronous writeback continues to
mfs algorithm of asynchronous
writeback continues to underperform
algorithm of asynchronous invalidations
of asynchronous invalidations and
this is because the
asynchronous invalidations and differentiated
is because the progress
invalidations and differentiated writeback
because the progress of
the progress of writers
and differentiated writeback is
progress of writers using
differentiated writeback is able
of writers using asynchronous
writers using asynchronous writeback
writeback is able to
using asynchronous writeback schemes
is able to maintain
asynchronous writeback schemes is
writeback schemes is less
able to maintain cache
schemes is less constrained
to maintain cache consistency
is less constrained by
less constrained by the
maintain cache consistency between
constrained by the bandwidth
cache consistency between the
consistency between the two
between the two clients
and they can overlap
the two clients and
they can overlap computation
two clients and to
can overlap computation and
clients and to allow
overlap computation and fetching
and to allow the
computation and fetching file
to allow the writer
and fetching file contents
allow the writer to
fetching file contents with
the writer to write
file contents with writeback
writer to write back
to write back changes
write back changes to
back changes to the
changes to the stored
performance enhancing proxies intended
to the stored data
enhancing proxies intended to
rather than simply being
proxies intended to mitigate
the stored data faster
intended to mitigate link
than simply being a
stored data faster than
simply being a selfinterested
data faster than is
being a selfinterested optimisation
faster than is possible
a selfinterested optimisation by
than is possible with
selfinterested optimisation by writers
is possible with the
optimisation by writers to
possible with the alternative
by writers to improve
with the alternative schemes
writers to improve their
to improve their own
improve their own performance
we intend to further
acts at step t
intend to further evaluate
asynchronous writeback therefore benefits
to further evaluate the
writeback therefore benefits both
further evaluate the perfor
therefore benefits both writers
it optimizes its revenue
benefits both writers and
optimizes its revenue with
both writers and readers
its revenue with x
references mance of the
mance of the algorithm
of the algorithm to
the algorithm to determine
the files shared between
algorithm to determine its
files shared between the
to determine its effectiveness
shared between the clients
determine its effectiveness under
between the clients were
its effectiveness under other
the clients were divided
effectiveness under other workloads
clients were divided into
and with more clients
file lengths were randomised
with an average length
an average length of
evaluation of an adaptive
of an adaptive transport
an adaptive transport protocol
to prevent the clients
prevent the clients falling
the clients falling into
clients falling into lockstep
in proceedings of the
falling into lockstep in
into lockstep in the
lockstep in the course
in the course of
the course of fetching
course of fetching and
of fetching and writing
fetching and writing back
and writing back the
nd annual joint conference
writing back the files
annual joint conference of
joint conference of the
conference of the ieee
of the ieee computer
the ieee computer and
ieee computer and communications
computer and communications societies
udp bandwidth measurement tool
consisting of selecting a
of selecting a random
selecting a random file
a random file set
an equilibrium exists where
random file set and
equilibrium exists where neither
file set and performing
exists where neither pool
set and performing a
and performing a sequence
performing a sequence of
a sequence of reads
sequence of reads or
of reads or writes
reads or writes on
or writes on files
writes on files in
on files in it
can improve its revenue
improve its revenue by
its revenue by changing
revenue by changing its
by changing its infiltration
changing its infiltration rate
the writer performed a
writer performed a file
performed a file set
a file set operation
file set operation of
any pair of values
pair of values x
such that arg maxx
conclusion the growing use
the growing use of
growing use of mobile
use of mobile computers
of mobile computers and
mobile computers and wireless
computers and wireless networks
with each access being
and wireless networks has
each access being equally
wireless networks has greatly
access being equally likely
networks has greatly increased
being equally likely to
has greatly increased the
equally likely to open
greatly increased the scope
likely to open a
increased the scope for
to open a file
the scope for adapting
open a file for
scope for adapting data
a file for reading
for adapting data access
file for reading or
adapting data access to
for reading or writing
data access to vary
readers performed a file
performed a file set
a file set operation
file set operation of
a scalable and tcp
friendly congestion control for
congestion control for high
file sets were treated
sets were treated as
were treated as hot
of the file set
the file set operations
this paper has explored
file set operations were
paper has explored applying
set operations were directed
has explored applying and
operations were directed to
explored applying and j
were directed to those
directed to those file
to those file sets
read staleness comparing update
staleness comparing update propagation
comparing update propagation schemes
update propagation schemes requires
propagation schemes requires a
measurements of a distributed
schemes requires a criterion
of a distributed file
requires a criterion for
a distributed file the
a criterion for measuring
distributed file the technique
criterion for measuring the
file the technique of
for measuring the staleness
the technique of modeless
measuring the staleness of
technique of modeless adaptation
the staleness of file
of modeless adaptation to
staleness of file reads
modeless adaptation to a
adaptation to a distributed
to a distributed file
a distributed file system
distributed file system system
we identified updates to
identified updates to files
updates to files by
to files by associating
in proceedings of the
files by associating a
by associating a version
associating a version number
a version number with
version number with each
number with each file
th acm symposium to
acm symposium to improve
and incrementing it every
symposium to improve its
incrementing it every time
to improve its performance
it every time the
every time the file
time the file was
the file was modified
the cache manager for
cache manager for our
manager for our mfs
for our mfs on
reads were labelled with
our mfs on operating
were labelled with the
mfs on operating systems
labelled with the version
on operating systems principles
with the version number
the version number of
version number of the
number of the file
of the file at
the file at the
file at the time
at the time the
third international workshop on
the time the read
international workshop on protocols
time the read occurred
workshop on protocols for
on protocols for fast
protocols for fast long
the staleness of a
staleness of a particular
of a particular read
a particular read was
particular read was determined
read was determined according
was determined according to
determined according to an
according to an ideal
to an ideal version
an ideal version number
pacific file system incorporates
ideal version number derived
file system incorporates features
version number derived from
system incorporates features that
number derived from executing
incorporates features that are
derived from executing the
features that are not
from executing the experiment
that are not present
executing the experiment with
are not present in
the experiment with all
not present in existing
experiment with all participants
present in existing grove
with all participants running
all participants running on
participants running on a
running on a single
on a single host
in a real execution
the difference between the
difference between the version
between the version number
the version number a
version number a read
number a read returns
a read returns and
read returns and the
returns and the optimal
and the optimal version
the optimal version number
optimal version number determines
version number determines how
number determines how stale
determines how stale the
how stale the read
stale the read is
file systems for mobile
packet recovery in high
systems for mobile hosts
speed networks using coding
adaptation to bandwidth variation
networks using coding and
the feasible region for
using coding and buffer
to bandwidth variation through
coding and buffer management
feasible region for the
shows cumulative distributions for
region for the pool
bandwidth variation through the
for the pool sizes
cumulative distributions for the
the pool sizes is
variation through the use
distributions for the staleness
through the use of
pool sizes is m
for the staleness of
the use of prioritised
the staleness of reads
use of prioritised communication
staleness of reads at
of reads at different
reads at different writer
improved consistency results in
consistency results in fewer
results in fewer stale
in fewer stale reads
and this is reflected
this is reflected by
is reflected by a
reflected by a curve
by a curve that
a curve that is
curve that is higher
that is higher on
is higher on the
higher on the left
on the left side
the left side of
left side of the
side of the graph
consistency maintenance cost the
maintenance cost the overhead
cost the overhead of
o hint genercache consistency
the overhead of the
hint genercache consistency protocol
overhead of the update
genercache consistency protocol using
the revenue function for
consistency protocol using file
of the update propagation
protocol using file access
performance evaluation of forward
using file access information
evaluation of forward error
file access information to
of forward error correction
access information to imation
forward error correction in
information to imation through
the update propagation schemes
to imation through speculative
revenue function for ri
imation through speculative execution
error correction in atm
update propagation schemes can
function for ri is
propagation schemes can be
for ri is concave
schemes can be compared
ri is concave in
can be compared by
is concave in xi
correction in atm networks
concave in xi for
be compared by referring
in xi for all
in operating systems prove
xi for all feasible
operating systems prove performance
for all feasible values
compared by referring to
all feasible values of
by referring to the
feasible values of the
referring to the reader
values of the variables
to the reader and
the reader and writer
reader and writer execution
and writer execution times
acknowledgements shown in figure
reader execution time is
execution time is the
time is the average
is the average for
the average for all
average for all three
for all three readers
therefore the solutions for
the solutions for equations
we have evaluated the
have evaluated the effect
the reduced staleness achievable
evaluated the effect of
reduced staleness achievable by
the effect of these
staleness achievable by sirp
effect of these features
achievable by sirp has
of these features on
by sirp has little
these features on performance
sirp has little or
features on performance at
has little or no
on performance at varying
little or no cost
performance at varying bandwidth
are unique and are
at varying bandwidth levels
or no cost compared
varying bandwidth levels and
unique and are either
bandwidth levels and under
no cost compared to
levels and under both
and are either at
and under both synthetic
cost compared to asynchronous
under both synthetic and
are either at the
both synthetic and real
compared to asynchronous writeback
either at the borders
to asynchronous writeback with
at the borders of
asynchronous writeback with no
the borders of the
writeback with no invalidations
borders of the feasible
of the feasible region
the feasible region or
feasible region or where
region or where ri
since the writer is
the writer is up
writer is up to
slower when using sirp
c compared to sirp
from section v we
section v we know
v we know that
we know that no
selective invalidation is clearly
invalidation is clearly beneficial
attack is not an
is not an equilibrium
not an equilibrium point
sirp has the highest
since each pool can
has the highest average
each pool can increase
the highest average execution
pool can increase its
highest average execution time
can increase its revenue
increase its revenue by
its revenue by choosing
including a workload emulating
revenue by choosing a
a workload emulating collaborative
by choosing a strictly
but this is because
workload emulating collaborative data
choosing a strictly positive
this is because it
a strictly positive infiltration
is because it provides
strictly positive infiltration rate
because it provides the
it provides the best
provides the best consistency
the best consistency of
best consistency of all
consistency of all the
of all the schemes
efficient erasure correcting codes
if a reader reads
ieee transactions on information
a reader reads more
transactions on information theory
reader reads more up
performance measurements access with
measurements access with high
access with high read
then it transfers more
it transfers more data
and found that while
found that while the
that while the of
while the of automatic
the of automatic prefetching
the reader execution time
reader execution time for
execution time for each
in proceedings of the
time for each case
proceedings of the isca
for each case is
of the isca interadditional
is not a solution
the isca interadditional costs
not a solution to
each case is proportional
a solution to equations
isca interadditional costs imposed
case is proportional to
interadditional costs imposed are
is proportional to the
costs imposed are mostly
proportional to the amount
imposed are mostly hidden
to the amount of
the amount of data
amount of data transferred
of data transferred between
data transferred between the
transferred between the reader
they can have benenational
between the reader and
can have benenational conference
the reader and server
have benenational conference on
benenational conference on parallel
conference on parallel and
on parallel and distributed
parallel and distributed computfits
though lack of space
and distributed computfits which
lack of space precludes
distributed computfits which are
of space precludes showing
computfits which are very
space precludes showing this
which are very visible
precludes showing this in
nash equilibrium therefore exists
showing this in a
equilibrium therefore exists with
this in a graph
therefore exists with x
we thank robbert van
thank robbert van renesse
modal nature of ing
nature of ing systems
emin gu n sirer
rimon barr and stephen
barr and stephen rago
and stephen rago for
stephen rago for comments
rago for comments regarding
for comments regarding this
comments regarding this work
adaptation in mfs allows
in mfs allows clients
mfs allows clients to
allows clients to adapt
clients to adapt quickly
to adapt quickly to
adapt quickly to a
quickly to a variety
to a variety of
a variety of bandwidth
variety of bandwidth conditions
of bandwidth conditions without
bandwidth conditions without substantial
conditions without substantial changes
without substantial changes in
substantial changes in operation
evaluation of an adaptive
of an adaptive transport
an adaptive transport protocol
in proceedings of the
proceedings of the twenty
rd annual ieee symposium
annual ieee symposium on
second annual joint conference
ieee symposium on foundations
annual joint conference of
symposium on foundations of
joint conference of the
on foundations of computer
conference of the ieee
foundations of computer science
of the ieee computer
the ieee computer and
ieee computer and communications
computer and communications societies
our evaluation has included
evaluation has included comparisons
has included comparisons of
included comparisons of mfs
comparisons of mfs to
of mfs to cache
mfs to cache manm
ieee transactions on information
transactions on information theory
ager configurations corresponding to
configurations corresponding to prior
corresponding to prior work
and confirmed scale and
confirmed scale and performance
using symbolic computation tools
scale and performance in
and performance in a
performance in a distributed
in a distributed file
a distributed file system
we see that there
see that there is
that there is a
there is a single
is a single pair
acm that there are
a single pair of
that there are situations
single pair of values
there are situations in
pair of values for
are situations in which
of values for which
situations in which mfs
values for which equation
in which mfs would
which mfs would outperform
mfs would outperform afs
transactions on computer systems
holds for any feasible
for any feasible choice
any feasible choice of
feasible choice of m
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
analysis confirms these observations
we simulate the pool
simulate the pool game
the pool game for
pool game for a
the importance of translucence
game for a range
importance of translucence in
for a range of
of translucence in mobile
a range of pool
translucence in mobile computing
range of pool sizes
in mobile computing systems
for each choice of
acm transactions on computer
each choice of pool
choice of pool sizes
we start the simulation
start the simulation when
the simulation when both
simulation when both pools
when both pools do
both pools do not
pools do not infiltrate
do not infiltrate each
not infiltrate each other
coda and little work
these earlier systems were
earlier systems were designed
systems were designed for
were designed for a
designed for a mobile
for a mobile environment
a mobile environment which
mobile environment which is
environment which is substantially
which is substantially different
and the revenue densities
the revenue densities are
revenue densities are r
partially connected operafrom that
connected operafrom that available
operafrom that available today
mfs is able to
is able to provide
able to provide tion
at each round one
each round one pool
round one pool chooses
one pool chooses its
pool chooses its optimal
chooses its optimal infiltration
its optimal infiltration rate
optimal infiltration rate based
infiltration rate based on
rate based on the
based on the pool
on the pool sizes
the pool sizes and
tolerant mechanism for distributed
pool sizes and the
mechanism for distributed file
sizes and the rate
for distributed file cache
and the rate with
distributed file cache consistency
the rate with which
rate with which it
with which it is
which it is infiltrated
in proceedings of the
proceedings of the twelth
of the twelth symposium
the twelth symposium on
and we calculate the
twelth symposium on operating
we calculate the revenue
symposium on operating systems
calculate the revenue after
on operating systems principles
the revenue after convergence
revenue after convergence with
after convergence with equation
recall the players in
the players in the
players in the pool
in the pool game
the pool game are
pool game are chosen
game are chosen with
are chosen with the
chosen with the round
with the round robin
the round robin policy
so the pools take
the pools take turns
and we let the
improved performance in periods
we let the game
performance in periods of
let the game run
in periods of high
the game run until
periods of high network
game run until convergence
of high network contention
high network contention by
the results are illustrated
results are illustrated in
are illustrated in figure
this experiment demonstrates that
experiment demonstrates that sirp
demonstrates that sirp is
that sirp is preferable
sirp is preferable to
is preferable to asynchronous
preferable to asynchronous writeback
to asynchronous writeback at
each run with some
asynchronous writeback at low
run with some m
writeback at low bandwidth
and adds little additional
adds little additional overhead
values results in a
results in a single
in a single point
the difference between asynchronous
a single point in
difference between asynchronous schemes
single point in each
between asynchronous schemes is
point in each graph
asynchronous schemes is minimal
in each graph in
each graph in figure
but any scheme improves
any scheme improves over
scheme improves over synchronous
improves over synchronous writeback
we depict the infiltration
depict the infiltration rates
the infiltration rates of
for the same reasons
infiltration rates of both
the same reasons that
rates of both pools
mofavouring cache validation and
same reasons that it
of both pools x
reasons that it improves
cache validation and rpcs
that it improves performance
validation and rpcs to
and rpcs to retrieve
rpcs to retrieve files
to retrieve files over
asynchronous writeback reduces staleness
retrieve files over other
files over other bile
over other bile computing
other bile computing with
bile computing with the
and sirp makes it
computing with the rover
sirp makes it an
with the rover toolkit
makes it an acceptable
it an acceptable choice
an acceptable choice at
acceptable choice at low
choice at low bandwidth
ieee transactypes of traffic
we have not compared
have not compared mfs
not compared mfs with
compared mfs with lbfs
mfs with lbfs since
with lbfs since tions
lbfs since tions on
since tions on computers
special issue on mobile
b and the pools
issue on mobile computing
and the pools revenue
the pools revenue densities
pools revenue densities r
their approaches are orthogonal
for each choice of
each choice of m
the values of x
scale and performance in
and performance in a
performance in a distributed
in a distributed file
a distributed file system
acm transactions on computer
transactions on computer systems
are the points in
not present in the
the points in each
present in the earlier
points in each of
in the earlier systems
in each of the
the earlier systems we
each of the graphs
earlier systems we have
of the graphs with
systems we have compared
the graphs with the
we have compared against
graphs with the respective
with the respective coordinates
we anticipate that implementing
anticipate that implementing lbfs
that implementing lbfs file
implementing lbfs file chunks
lbfs file chunks in
file chunks in mfs
j graphs we draw
chunks in mfs would
graphs we draw a
we draw a border
draw a border around
a border around the
border around the region
around the region where
the region where there
region where there is
where there is no
attack by i in
by i in equilibrium
for the ri graphs
the ri graphs we
ri graphs we draw
graphs we draw a
we draw a line
draw a line around
a line around the
line around the region
around the region where
the region where the
region where the revenue
where the revenue is
the revenue is the
revenue is the same
is the same as
the same as in
same as in the
as in the no
further improve performance its
improve performance its performance
we first observe that
first observe that only
observe that only in
that only in extreme
and performance in a
only in extreme cases
performance in a wide
in extreme cases a
extreme cases a pool
cases a pool does
a pool does not
pool does not attack
does not attack its
not attack its counterpart
in proceedin future work
we plan to investigate
at equilibrium a pool
plan to investigate the
equilibrium a pool will
to investigate the performance
a pool will refrain
investigate the performance of
pool will refrain from
the performance of ings
will refrain from attacking
performance of ings of
refrain from attacking only
of ings of the
from attacking only if
ings of the first
attacking only if the
of the first usenix
only if the other
the first usenix conference
if the other pool
first usenix conference on
the other pool is
usenix conference on file
other pool is larger
conference on file and
pool is larger than
on file and storage
is larger than about
file and storage modeless
and storage modeless adaptation
storage modeless adaptation and
modeless adaptation and mfs
adaptation and mfs in
and mfs in wide
area and more web
of the total mining
the total mining power
we observe that a
observe that a pool
that a pool improves
a pool improves its
pool improves its revenue
improves its revenue compared
its revenue compared to
revenue compared to the
compared to the no
attacks scenario only when
scenario only when it
only when it controls
when it controls a
it controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
as well as further
well as further evaluating
as further evaluating the
further evaluating the performance
evaluating the performance of
these are the small
the performance of the
are the small triangular
performance of the mfs
the small triangular regions
of the mfs cache
small triangular regions in
the mfs cache consistency
triangular regions in figures
mfs cache consistency algorithm
we also intend to
also intend to use
in the rest of
the rest of the
rest of the space
the trapezoids in the
trapezoids in the figures
the revenue of the
revenue of the pool
of the pool is
the pool is inferior
pool is inferior compared
is inferior compared to
inferior compared to the
mobile computing with the
compared to the no
computing with the rover
with the rover toolkit
disconnected operamfs to further
ieee transactions on computers
operamfs to further examine
to further examine the
further examine the benefits
examine the benefits achievable
the benefits achievable from
benefits achievable from the
the prisoner s dilemma
achievable from the autotion
prisoner s dilemma in
from the autotion in
s dilemma in a
the autotion in the
dilemma in a healthy
autotion in the coda
in a healthy bitcoin
in the coda file
a healthy bitcoin environment
the coda file system
where neither pool controls
acm transactions on commatic
neither pool controls a
transactions on commatic generation
pool controls a strict
on commatic generation of
controls a strict majority
commatic generation of caching
a strict majority of
generation of caching policies
strict majority of the
of caching policies for
majority of the mining
caching policies for files
of the mining power
both pools will earn
pools will earn less
will earn less at
earn less at equilibrium
less at equilibrium than
at equilibrium than if
equilibrium than if both
than if both pools
if both pools ran
both pools ran without
pools ran without attacking
we can analyze in
can analyze in this
analyze in this case
in this case a
this case a game
case a game where
a game where each
game where each pool
where each pool chooses
each pool chooses either
pool chooses either to
chooses either to attack
either to attack and
to attack and optimize
attack and optimize its
and optimize its revenue
or to refrain from
to refrain from attacking
without loss of generality
as we have seen
we have seen in
have seen in section
seen in section v
can increase its revenue
increase its revenue above
enforcing fairness in a
fairness in a live
does attack but pool
streaming system maya haridasana
we denote the revenue
denote the revenue of
automated hoarding for mobile
the revenue of pool
hoarding for mobile computers
and performance in a
performance in a wide
portob and robbert van
and robbert van renessea
in proceedings of the
robbert van renessea a
proceedings of the sixteenth
van renessea a dept
of the sixteenth acm
the sixteenth acm symposium
sixteenth acm symposium on
in proceedings of the
acm symposium on operating
proceedings of the first
symposium on operating systems
the exact value of
on operating systems principles
exact value of r
of the first usenix
the first usenix conference
first usenix conference on
usenix conference on file
conference on file and
depends on the values
on file and storage
on the values of
new york b institute
the values of m
york b institute of
file and storage technologies
b institute of informatics
federal university of rio
university of rio grande
of rio grande do
rio grande do sul
grande do sul porto
do sul porto alegre
but it is always
it is always smaller
is always smaller than
always smaller than one
as we have seen
we have seen above
does choose to attack
this paper has described
paper has described mafs
but does not surpass
does not surpass one
a new file system
new file system for
the game is summarized
file system for mobile
game is summarized in
system for mobile clients
is summarized in figure
for mobile clients that
mobile clients that is
acknowledgements we would like
clients that is tailored
we would like to
that is tailored for
would like to thank
is tailored for wireless
like to thank robbert
tailored for wireless networks
to thank robbert van
for wireless networks by
edu abstract we describe
wireless networks by incorporating
thank robbert van renesse
networks by incorporating automatic
this is the classical
by incorporating automatic adaptation
is the classical prisoner
abstract we describe a
the classical prisoner s
incorporating automatic adaptation to
classical prisoner s dilemma
we describe a practical
automatic adaptation to the
describe a practical auditing
adaptation to the available
a practical auditing approach
to the available bandwidth
practical auditing approach designed
attack is the dominant
emin gu n sirer
is the dominant strategy
auditing approach designed to
gu n sirer and
approach designed to encourage
n sirer and paul
designed to encourage fairness
mafs differs from previous
to encourage fairness in
sirer and paul francis
differs from previous designs
encourage fairness in peer
and paul francis for
from previous designs in
paul francis for comments
previous designs in making
chooses to attack or
designs in making use
francis for comments and
in making use of
to attack or not
making use of asynchronous
for comments and suggestions
use of asynchronous writeback
comments and suggestions regarding
of asynchronous writeback at
and suggestions regarding mfs
asynchronous writeback at all
writeback at all bandwidth
the revenue of pool
at all bandwidth levels
auditing is employed to
we also thank rimon
also thank rimon barr
is employed to ensure
is larger when attacking
employed to ensure that
larger when attacking than
rather than switching from
to ensure that correct
when attacking than when
than switching from synchronous
attacking than when refraining
ensure that correct nodes
than when refraining from
switching from synchronous to
that correct nodes are
and kevin walsh for
from synchronous to asynchronous
kevin walsh for helpful
correct nodes are able
walsh for helpful discussions
synchronous to asynchronous writeback
for helpful discussions and
nodes are able to
helpful discussions and corrections
to asynchronous writeback when
when refraining from attack
asynchronous writeback when bandwidth
discussions and corrections to
are able to receive
and corrections to this
writeback when bandwidth is
able to receive streams
when bandwidth is insufficient
and the same for
corrections to this paper
to receive streams even
the same for pool
receive streams even in
streams even in the
rpc priorities and a
even in the presence
priorities and a new
in the presence of
and a new update
the presence of nodes
a new update propagation
presence of nodes that
new update propagation algorithm
of nodes that do
nodes that do not
at equilibrium of this
that do not upload
equilibrium of this attack
do not upload enough
not upload enough data
reduce a client s
a client s contention
client s contention for
s contention for wireless
contention for wireless bandwidth
when both pools attack
and scales well when
and permit a degree
scales well when compared
permit a degree of
well when compared to
the revenue of each
a degree of consistency
when compared to previous
degree of consistency that
compared to previous solutions
revenue of each pool
to previous solutions that
of consistency that is
previous solutions that rely
of each pool is
solutions that rely on
consistency that is equivalent
that rely on tit
that is equivalent to
each pool is smaller
is equivalent to instantaneous
pool is smaller than
equivalent to instantaneous propagation
is smaller than its
to instantaneous propagation of
smaller than its revenue
instantaneous propagation of updates
than its revenue if
its revenue if neither
revenue if neither pool
if neither pool attacked
tat style of data
style of data exchange
experiments demonstrate that these
demonstrate that these techniques
that these techniques allow
these techniques allow mafs
auditing involves two roles
techniques allow mafs to
allow mafs to achieve
the game is not
mafs to achieve performance
game is not played
to achieve performance that
is not played once
achieve performance that is
a coherent distributed file
performance that is at
coherent distributed file cache
that is at least
distributed file cache with
is at least equal
file cache with directory
at least equal to
cache with directory write
untrusted local auditors run
local auditors run on
auditors run on all
run on all nodes
on all nodes in
all nodes in the
and in most cases
nodes in the system
in most cases superior
most cases superior to
acm transactions on computer
cases superior to that
transactions on computer systems
superior to that achievable
and are responsible for
where each pool can
to that achievable by
each pool can change
are responsible for collecting
pool can change its
that achievable by conventional
can change its strategy
responsible for collecting and
change its strategy between
achievable by conventional file
for collecting and maintaining
its strategy between attack
by conventional file system
strategy between attack and
collecting and maintaining accountable
between attack and no
conventional file system designs
and maintaining accountable information
file system designs that
maintaining accountable information regarding
system designs that switch
accountable information regarding data
designs that switch between
information regarding data sent
that switch between lowand
regarding data sent and
switch between lowand high
data sent and received
the pools can agree
sent and received by
and received by each
received by each node
bandwidth modes according to
modes according to thresholds
to refrain from attacking
mafs is therefore able
is therefore able to
one or more trusted
therefore able to make
or more trusted global
able to make efficient
more trusted global auditors
and in each round
to make efficient use
in each round xxx
trusted global auditors periodically
each round xxx xxx
make efficient use of
round xxx xxx pool
global auditors periodically sample
efficient use of the
auditors periodically sample the
use of the network
periodically sample the state
of the network and
sample the state of
the network and provide
no attack xxx pool
the state of participating
network and provide predictable
state of participating nodes
and provide predictable file
provide predictable file system
predictable file system semantics
estimate whether the streaming
whether the streaming quality
the streaming quality is
regardless of the available
streaming quality is satisfactory
of the available bandwidth
and decide whether any
decide whether any actions
whether any actions are
any actions are required
we demonstrate through simulation
demonstrate through simulation that
through simulation that our
simulation that our approach
that our approach can
our approach can successfully
approach can successfully detect
can successfully detect and
successfully detect and react
detect and react to
and react to the
react to the presence
to the presence of
the presence of opportunistic
presence of opportunistic nodes
of opportunistic nodes in
opportunistic nodes in streaming
nodes in streaming sessions
automated hoarding for mobile
hoarding for mobile computers
it incurs low network
in proceedings of the
incurs low network and
proceedings of the sixteenth
low network and computational
of the sixteenth acm
network and computational overheads
the sixteenth acm symposium
sixteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
which remain fixed as
remain fixed as the
fixed as the system
as the system scales
a lowbandwidth network file
lowbandwidth network file system
in proceedings of the
proceedings of the seventeenth
introduction video and audio
of the seventeenth acm
video and audio streaming
the seventeenth acm symposium
and audio streaming account
seventeenth acm symposium on
audio streaming account for
acm symposium on operating
streaming account for a
symposium on operating systems
account for a large
on operating systems principles
for a large percentage
a large percentage of
large percentage of content
percentage of content accessed
of content accessed over
content accessed over the
accessed over the web
one popular style of
popular style of streaming
style of streaming on
of streaming on the
streaming on the web
on the web is
the web is on
web is on demand
in which users access
which users access pre
stored content at will
another style requires streams
style requires streams to
requires streams to be
streams to be generated
to be generated and
be generated and disseminated
generated and disseminated in
and disseminated in real
this may be the
may be the case
be the case with
the case with important
case with important social
an important property of
important property of live
streaming is that data
is that data is
that data is not
data is not available
is not available in
exploiting weak connectivity for
not available in advance
weak connectivity for mobile
connectivity for mobile file
for mobile file access
being generated just before
generated just before transmission
caching in the sprite
in proceedings of the
in the sprite network
just before transmission at
the sprite network file
proceedings of the fifteenth
sprite network file system
before transmission at the
of the fifteenth acm
transmission at the sender
the fifteenth acm symposium
fifteenth acm symposium on
acm symposium on operating
acm transactions on computer
symposium on operating systems
transactions on computer systems
on operating systems principles
prisoner s dilemma for
s dilemma for two
dilemma for two pools
interested users ideally want
users ideally want to
ideally want to receive
the revenue density of
want to receive the
revenue density of each
to receive the stream
density of each pool
receive the stream without
of each pool is
the stream without much
each pool is determined
stream without much delay
pool is determined by
without much delay from
is determined by the
much delay from its
determined by the decision
delay from its original
by the decision of
from its original transmission
the decision of both
decision of both pools
of both pools whether
both pools whether to
pools whether to attack
whether to attack or
to attack or not
streaming systems now allow
the dominant strategy of
systems now allow large
dominant strategy of each
now allow large numbers
strategy of each player
allow large numbers of
of each player is
large numbers of interested
each player is to
numbers of interested users
player is to attack
of interested users to
interested users to receive
users to receive streamed
to receive streamed data
receive streamed data in
however the payoff of
streamed data in near
the payoff of both
data in near real
payoff of both would
in near real time
of both would be
both would be larger
would be larger if
be larger if they
larger if they both
if they both refrain
without requiring extensive amounts
they both refrain from
requiring extensive amounts of
both refrain from attacking
extensive amounts of resources
a pool can detect
these systems are based
pool can detect whether
systems are based on
can detect whether it
are based on the
detect whether it is
based on the peer
whether it is being
it is being attacked
is being attacked and
being attacked and deduce
attacked and deduce that
and deduce that the
deduce that the other
that the other pool
the other pool is
other pool is violating
pool is violating the
is violating the agreement
cooperation where neither pool
where neither pool attacks
neither pool attacks is
pool attacks is a
where nodes interested in
attacks is a possible
nodes interested in receiving
is a possible stable
interested in receiving data
a possible stable state
in receiving data also
receiving data also help
data also help disseminate
also help disseminate it
help disseminate it to
disseminate it to each
it to each other
bandwidth network file system
alleviating the bottleneck at
the bottleneck at the
bottleneck at the source
in proceedings of the
proceedings of the eighteenth
of the eighteenth acm
the eighteenth acm symposium
eighteenth acm symposium on
initial protocols were based
acm symposium on operating
protocols were based on
symposium on operating systems
were based on building
on operating systems principles
based on building a
on building a tree
based overlay of nodes
overlay of nodes through
of nodes through which
nodes through which data
through which data would
which data would be
data would be pushed
despite the fact that
the fact that the
fact that the single
that the single nash
the single nash equilibrium
single nash equilibrium in
nash equilibrium in every
equilibrium in every round
in every round is
every round is to
round is to attack
such as chainsaw and
as chainsaw and coolstreaming
have shown that the
shown that the use
case as an example
that the use of
as an example we
the use of a
an example we take
use of a mesh
example we take again
of a mesh of
we take again the
a mesh of connected
take again the pool
mesh of connected nodes
again the pool sizes
of connected nodes and
the pool sizes shown
connected nodes and a
pool sizes shown in
nodes and a pull
sizes shown in figure
perspectives on optimistically replicated
on optimistically replicated peer
based data dissemination approach
data dissemination approach can
dissemination approach can provide
approach can provide similar
and study the case
can provide similar results
study the case where
provide similar results with
the case where the
similar results with better
case where the two
software practice and experience
results with better resilience
where the two largest
with better resilience to
the two largest pools
better resilience to failures
resilience to failures and
to failures and churn
nodes joining and leaving
joining and leaving the
and leaving the system
the optimal infiltration rates
out of the total
of the total system
the total system mining
total system mining power
nodes notify each other
notify each other of
each other of receipt
other of receipt of
of receipt of data
receipt of data packets
and request packets from
request packets from their
packets from their neighbors
from their neighbors based
their neighbors based on
neighbors based on the
based on the received
on the received notifications
and the pools would
the pools would lose
practical systems based on
systems based on pull
based streaming now exist
streaming now exist in
now exist in china
where they are used
they are used to
are used to disseminate
used to disseminate television
to disseminate television channels
managing update conflicts in
disseminate television channels to
update conflicts in bayou
television channels to thousands
channels to thousands of
to thousands of users
a weakly connected replicated
weakly connected replicated storage
connected replicated storage system
compared to the no
even though the p
in proceedings of the
proceedings of the fifteenth
of the fifteenth acm
the fifteenth acm symposium
fifteenth acm symposium on
p paradigm allows systems
acm symposium on operating
paradigm allows systems to
symposium on operating systems
allows systems to scale
on operating systems principles
systems to scale with
q i dentical p
to scale with the
scale with the number
i dentical p ools
with the number of
the number of users
dentical p ools let
p ools let there
ools let there be
let there be q
it also leaves them
there be q pools
also leaves them vulnerable
be q pools of
leaves them vulnerable to
q pools of identical
them vulnerable to opportunistic
pools of identical size
vulnerable to opportunistic behavior
of identical size that
identical size that engage
size that engage in
that engage in block
engage in block withholding
in block withholding against
opportunistic nodes attempt to
block withholding against one
nodes attempt to receive
withholding against one another
attempt to receive a
to receive a stream
receive a stream without
a stream without uploading
stream without uploading their
other miners neither attack
without uploading their fair
miners neither attack nor
uploading their fair share
neither attack nor are
their fair share of
attack nor are being
fair share of data
nor are being attacked
informed prefetching and caching
reducing the overall upload
in this case there
the overall upload capacity
this case there exists
overall upload capacity of
case there exists a
in proceedings of the
upload capacity of the
proceedings of the fifteenth
capacity of the system
there exists a symmetric
of the fifteenth acm
exists a symmetric equilibrium
the fifteenth acm symposium
fifteenth acm symposium on
acm symposium on operating
despite the damage that
symposium on operating systems
the damage that they
on operating systems principles
damage that they may
that they may cause
without loss of generality
not much work has
a step of pool
much work has been
work has been done
has been done in
been done in studying
done in studying mechanisms
in studying mechanisms to
studying mechanisms to avoid
mechanisms to avoid their
to avoid their presence
it controls its attack
avoid their presence in
controls its attack rates
their presence in live
its attack rates each
attack rates each of
rates each of the
each of the other
of the other pools
and due to symmetry
the goal of this
due to symmetry they
goal of this the
to symmetry they are
file system usage in
symmetry they are all
of this the authors
they are all the
this the authors were
are all the same
the authors were supported
system usage in windows
authors were supported by
usage in windows nt
were supported by afrl
supported by afrl award
by afrl award fa
the attack rate of
attack rate of pool
in proceedings of the
proceedings of the seventeenth
of the seventeenth acm
the seventeenth acm symposium
against any other pool
seventeenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
each of the other
of the other pools
the other pools can
other pools can attack
pools can attack its
can attack its peers
attack its peers as
its peers as well
all attack rates by
attack rates by all
rates by all attackers
by all attackers are
all attackers are identical
the attack rate of
attack rate of any
rate of any pool
of any pool other
any pool other than
against any other pool
design and implementation of
and implementation of the
implementation of the sun
of the sun network
the sun network file
sun network file system
in proceedings of usenix
proceedings of usenix summer
of usenix summer conference
the direct revenue of
direct revenue of each
revenue of each of
of each of the
each of the other
of the other pools
similarly denote by r
the revenue densities of
revenue densities of pool
the evolution of coda
are instantiated to mi
acm transactions on computer
transactions on computer systems
determinism and asynchrony of
and asynchrony of set
asynchrony of set iterators
of set iterators to
set iterators to reduce
iterators to reduce aggregrate
to reduce aggregrate file
reduce aggregrate file i
in proceedings of the
proceedings of the sixteenth
of the sixteenth acm
the sixteenth acm symposium
sixteenth acm symposium on
the views and conclusions
acm symposium on operating
views and conclusions herein
symposium on operating system
and conclusions herein are
on operating system principles
conclusions herein are those
herein are those of
are those of the
those of the authors
symmetric case we have
case we have r
the expression is shown
expression is shown in
is shown in equation
file system usage in
system usage in windows
usage in windows nt
given any value of
any value of q
in proceedings of the
value of q and
proceedings of the seventeenth
of q and mi
of the seventeenth acm
the seventeenth acm symposium
seventeenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
the feasible range of
feasible range of the
range of the infiltration
of the infiltration rates
the infiltration rates is
minimum and average download
and average download rates
average download rates across
download rates across all
rates across all nodes
across all nodes when
within this range ri
all nodes when using
this range ri is
nodes when using the
range ri is continuous
when using the bar
using the bar gossip
the bar gossip and
bar gossip and chainsaw
gossip and chainsaw protocols
and concave in x
paper is to propose
is to propose and
to propose and evaluate
propose and evaluate a
and evaluate a mechanism
evaluate a mechanism that
a mechanism that can
mechanism that can defend
that can defend against
can defend against this
defend against this problem
whithout incurring large overheads
the optimal point for
the approach that most
optimal point for pool
approach that most closely
that most closely relates
most closely relates to
closely relates to our
relates to our work
to our work is
our work is the
work is the bar
is the bar gossip
the bar gossip protocol
arla a free afs
a free afs client
which employs a tit
in proceedings of the
software defined networks and
defined networks and gossip
networks and gossip protocols
tat approach for encouraging
and gossip protocols robert
approach for encouraging nodes
for encouraging nodes to
gossip protocols robert soule
encouraging nodes to contribute
protocols robert soule ken
robert soule ken birman
soule ken birman nate
ken birman nate foster
a node only sends
since the function is
birman nate foster university
the function is concave
node only sends as
function is concave the
nate foster university of
is concave the equation
foster university of lugano
concave the equation yields
only sends as much
the equation yields a
university of lugano cornell
equation yields a single
of lugano cornell university
sends as much data
yields a single feasible
lugano cornell university cornell
as much data to
cornell university cornell university
much data to another
university cornell university the
data to another node
cornell university the performance
to another node as
university the performance of
another node as it
the performance of data
node as it receives
a single feasible solution
as it receives back
center applications are critically
which is a function
it provides an elegant
is a function of
applications are critically dependent
a function of the
provides an elegant solution
function of the attack
are critically dependent on
of the attack rates
an elegant solution shown
the attack rates of
critically dependent on the
attack rates of the
elegant solution shown to
rates of the other
dependent on the underlying
of the other pools
solution shown to tolerate
on the underlying network
shown to tolerate both
to tolerate both opportunistic
tolerate both opportunistic behavior
both opportunistic behavior and
opportunistic behavior and other
behavior and other malicious
and other malicious attacks
given the complexities associated
the complexities associated with
complexities associated with management
networks today typically provide
today typically provide little
typically provide little more
provide little more than
little more than best
tat does present a
does present a few
effort packet delivery between
present a few undesirable
packet delivery between hosts
a few undesirable requirements
to find a symmetric
find a symmetric equilibrium
the emergence of software
the data source should
data source should ensure
source should ensure that
volume leases for consistency
should ensure that packets
leases for consistency in
for consistency in large
ensure that packets are
has created an opportunity
that packets are evenly
created an opportunity to
packets are evenly spread
an opportunity to build
are evenly spread across
opportunity to build more
evenly spread across the
to build more dynamic
spread across the system
ieee transactions on knowledge
across the system by
build more dynamic networks
the system by sending
transactions on knowledge and
system by sending data
on knowledge and data
by sending data to
more dynamic networks that
knowledge and data engineering
dynamic networks that can
sending data to a
networks that can be
data to a fixed
that can be tailored
to a fixed proportion
can be tailored precisely
a fixed proportion of
be tailored precisely to
fixed proportion of nodes
tailored precisely to the
precisely to the needs
to the needs of
the needs of applications
and by sending different
and obtain a single
by sending different packets
obtain a single feasible
sending different packets to
a single feasible solution
different packets to different
packets to different nodes
existing solutions for monitoring
solutions for monitoring within
the equilibrium infiltration rate
for monitoring within sdns
equilibrium infiltration rate and
monitoring within sdns suffer
infiltration rate and the
within sdns suffer from
rate and the matching
sdns suffer from several
and the matching revenues
suffer from several short
the matching revenues are
it requires the source
matching revenues are shown
requires the source and
revenues are shown in
the source and all
are shown in equation
source and all nodes
and all nodes to
all nodes to have
nodes to have full
to have full membership
either they are inaccurate
have full membership knowledge
due to eventual consistency
these restrictions affect scalability
to eventual consistency of
restrictions affect scalability when
eventual consistency of architecture
affect scalability when the
scalability when the data
when the data source
the data source has
data source has bounded
source has bounded upload
has bounded upload bandwidth
to illustrate this problem
as in the two
we fixed the upload
fixed the upload capacity
the upload capacity of
upload capacity of a
capacity of a data
of a data source
a data source at
the revenue at the
due to limitations of
revenue at the symmetric
to limitations of current
at the symmetric equilibrium
limitations of current hardware
the symmetric equilibrium is
mbps and simulated bar
symmetric equilibrium is inferior
and simulated bar gossip
equilibrium is inferior to
simulated bar gossip when
is inferior to the
bar gossip when streaming
inferior to the no
kbps with increasing numbers
with increasing numbers of
increasing numbers of receivers
or too costly to
too costly to be
costly to be practical
to be practical at
be practical at scale
varied between one and
between one and thirty
one and thirty thousand
and thirty thousand nodes
due to reliance on
to reliance on switch
reliance on switch forwarding
on switch forwarding rules
we compare its scalability
switch forwarding rules and
compare its scalability against
up our analysis addresses
its scalability against the
forwarding rules and centralization
scalability against the chainsaw
our analysis addresses the
against the chainsaw protocol
analysis addresses the eventual
addresses the eventual revenue
the eventual revenue of
eventual revenue of the
revenue of the pools
for which we fixed
assuming the mining difficulty
which we fixed the
the mining difficulty is
we fixed the source
mining difficulty is set
fixed the source s
difficulty is set based
the source s upload
is set based on
source s upload bandwidth
set based on the
s upload bandwidth to
based on the effective
on the effective mining
we argue that gossip
the effective mining power
argue that gossip protocols
that gossip protocols offer
gossip protocols offer an
protocols offer an ideal
offer an ideal alternative
not including mining power
an ideal alternative for
including mining power used
ideal alternative for sdn
mining power used for
alternative for sdn monitoring
power used for withholding
due to their scalability
we present the average
to their scalability and
present the average and
their scalability and resiliency
the average and minimum
average and minimum download
difficulty is updated only
and minimum download rates
is updated only periodically
updated only periodically every
ignored the crucial monitoring
the crucial monitoring component
crucial monitoring component that
as ratios of the
monitoring component that aggregates
ratios of the stream
component that aggregates network
of the stream rate
that aggregates network and
aggregates network and application
network and application state
of both protocols when
both protocols when the
protocols when the number
and sends the events
when the number of
sends the events to
the number of nodes
the events to the
number of nodes is
events to the controller
of nodes is increased
when mining power in
mining power in the
a complete system would
power in the system
complete system would have
in the system is
system would have a
the system is regularly
would have a closed
system is regularly increasing
have a closed loop
bar gossip is not
gossip is not able
is not able to
not able to sustain
continuously monitoring applications and
which has been true
monitoring applications and the
able to sustain its
applications and the network
has been true for
to sustain its performance
been true for the
sustain its performance without
true for the majority
its performance without scaling
for the majority of
performance without scaling the
the majority of bitcoin
without scaling the upload
majority of bitcoin s
scaling the upload capacity
then adjusting sdn policies
the upload capacity of
adjusting sdn policies to
of bitcoin s history
sdn policies to optimize
upload capacity of the
policies to optimize the
capacity of the source
to optimize the use
of the source proportionally
optimize the use of
the source proportionally with
the use of resources
source proportionally with the
proportionally with the size
with the size of
the size of the
size of the system
gossip protocols are an
protocols are an ideal
are an ideal choice
an ideal choice for
chainsaw is able to
ideal choice for implementing
no adjustment may be
choice for implementing a
adjustment may be necessary
is able to scale
for implementing a wide
able to scale well
implementing a wide range
to scale well even
a wide range monitoring
scale well even with
wide range monitoring tasks
well even with a
even with a fixed
with a fixed lower
a fixed lower upload
if an attacker purchases
fixed lower upload bandwidth
with a gossip protocol
an attacker purchases new
lower upload bandwidth at
attacker purchases new mining
upload bandwidth at the
purchases new mining hardware
bandwidth at the source
new mining hardware and
each node exchanges information
mining hardware and employs
node exchanges information with
hardware and employs it
exchanges information with a
and employs it directly
information with a randomly
but cannot handle the
with a randomly selected
employs it directly for
a randomly selected peer
it directly for block
randomly selected peer at
directly for block withholding
cannot handle the presence
selected peer at periodic
handle the presence of
peer at periodic intervals
the presence of opportunistic
presence of opportunistic nodes
this mining power is
mining power is never
because it is based
power is never included
it is based on
we propose to use
is based on periodic
is never included in
based on periodic peer
propose to use auditing
never included in the
to use auditing to
included in the difficulty
use auditing to encourage
in the difficulty calculation
auditing to encourage data
the difficulty calculation the
difficulty calculation the system
calculation the system is
the system is never
system is never aware
is never aware of
never aware of it
gossip s network load
s network load tends
streaming systems like chainsaw
network load tends to
load tends to be
the difficulty is therefore
tends to be well
difficulty is therefore already
is therefore already correctly
our auditing approach establishes
therefore already correctly calculated
auditing approach establishes a
already correctly calculated and
approach establishes a minimum
correctly calculated and the
establishes a minimum threshold
calculated and the attack
scaling linearly with system
a minimum threshold for
linearly with system size
and the attack is
with system size and
minimum threshold for the
system size and not
the attack is profitable
size and not prone
attack is profitable immediately
and not prone to
threshold for the amount
not prone to reactive
for the amount of
prone to reactive feedback
the amount of data
amount of data sent
of data sent by
data sent by any
sent by any node
by any node in
any node in the
if the mining power
node in the system
the mining power is
mining power is static
because peers are selected
peers are selected randomly
and removes nodes that
removes nodes that upload
the attack becomes profitable
no single node is
nodes that upload less
single node is indispensable
attack becomes profitable only
that upload less data
becomes profitable only after
upload less data than
profitable only after the
less data than the
only after the bitcoin
data than the threshold
after the bitcoin system
so tools built on
the bitcoin system has
tools built on gossip
bitcoin system has normalized
built on gossip are
system has normalized the
instead of relying on
has normalized the revenues
of relying on a
on gossip are extremely
normalized the revenues by
relying on a tit
gossip are extremely tolerant
the revenues by adjusting
are extremely tolerant to
revenues by adjusting difficulty
extremely tolerant to disruptions
tolerant to disruptions and
to disruptions and able
disruptions and able to
and able to rapidly
able to rapidly recover
to rapidly recover from
rapidly recover from failures
the revenue of an
we focus on encouraging
revenue of an attacking
although individual gossip protocols
focus on encouraging nodes
individual gossip protocols are
of an attacking pool
gossip protocols are typically
on encouraging nodes to
an attacking pool is
encouraging nodes to respect
protocols are typically very
nodes to respect the
attacking pool is reduced
to respect the established
are typically very simple
respect the established protocol
pool is reduced due
is reduced due to
reduced due to the
due to the reduction
composing multiple protocols can
nodes are forced to
to the reduction in
multiple protocols can lead
are forced to provide
protocols can lead to
the reduction in block
can lead to complex
forced to provide accountable
lead to complex interactions
reduction in block generation
to provide accountable information
in block generation of
to complex interactions with
provide accountable information regarding
block generation of both
accountable information regarding packets
generation of both the
complex interactions with unpredictable
of both the attacking
information regarding packets sent
both the attacking and
interactions with unpredictable behavior
the attacking and attacked
regarding packets sent to
attacking and attacked pools
packets sent to and
sent to and received
to and received from
and received from neighbors
we designed the mica
and the auditing system
pool knowledge and r
the auditing system is
auditing system is responsible
system is responsible for
is responsible for detecting
responsible for detecting and
for detecting and removing
detecting and removing misbehaving
framework to address this
and removing misbehaving nodes
to address this problem
notice that identifying the
mica allows programmers to
that identifying the misbehaving
allows programmers to describe
identifying the misbehaving nodes
programmers to describe gossip
the misbehaving nodes is
to describe gossip protocols
misbehaving nodes is not
describe gossip protocols with
nodes is not a
gossip protocols with a
is not a trivial
protocols with a small
not a trivial task
since there is no
there is no fixed
is no fixed minimum
no fixed minimum amount
and compose the protocols
fixed minimum amount of
compose the protocols with
minimum amount of data
the protocols with a
amount of data that
protocols with a rich
of data that nodes
with a rich collection
data that nodes should
a rich collection of
that nodes should contribute
rich collection of operators
nodes should contribute to
collection of operators to
should contribute to the
of operators to create
contribute to the system
operators to create sophisticated
to create sophisticated protocols
create sophisticated protocols in
sophisticated protocols in a
protocols in a modular
in a modular style
if we assume a
we assume a model
assume a model where
a model where misbehaving
model where misbehaving nodes
mica ensures that the
where misbehaving nodes simply
ensures that the composed
misbehaving nodes simply did
that the composed protocols
nodes simply did not
the composed protocols maintain
simply did not upload
composed protocols maintain strong
did not upload any
not upload any data
detecting them would be
them would be an
would be an easier
robustness and convergence guarantees
be an easier task
in our evaluation of
our evaluation of mica
once we assume that
we have built monitoring
we assume that misbehaving
have built monitoring tasks
assume that misbehaving nodes
built monitoring tasks that
that misbehaving nodes may
monitoring tasks that maintain
misbehaving nodes may adjust
tasks that maintain a
nodes may adjust their
that maintain a predictable
may adjust their contribution
maintain a predictable performance
adjust their contribution level
their contribution level based
contribution level based on
level based on the
based on the policy
even when hundreds of
on the policy used
when hundreds of separate
the policy used by
hundreds of separate instances
policy used by an
of separate instances are
used by an auditing
separate instances are deployed
by an auditing system
instances are deployed on
are deployed on the
deployed on the same
on the same machines
a more elaborate approach
more elaborate approach is
elaborate approach is required
this paper presents and
paper presents and evaluates
presents and evaluates an
and evaluates an auditing
evaluates an auditing model
a control program reacts
control program reacts to
an auditing model based
program reacts to network
reacts to network events
auditing model based on
model based on sampling
based on sampling the
on sampling the system
and updates forwarding rules
sampling the system and
updates forwarding rules on
the system and using
forwarding rules on switches
system and using the
rules on switches to
and using the sampled
on switches to manage
using the sampled information
switches to manage packets
the sampled information to
sampled information to build
information to build a
to build a global
building on this interface
build a global view
a global view of
global view of how
view of how the
our work on merlin
of how the system
how the system is
the system is currently
system is currently behaving
is novel among network
auditors employ strategies to
novel among network programming
employ strategies to identify
among network programming languages
strategies to identify the
network programming languages in
to identify the misbehaving
programming languages in that
identify the misbehaving nodes
languages in that it
the misbehaving nodes that
in that it determines
misbehaving nodes that should
that it determines allocations
nodes that should be
it determines allocations of
that should be punished
determines allocations of limited
allocations of limited network
the paper is organized
paper is organized as
wide resources such as
is organized as follows
resources such as bandwidth
such as bandwidth and
as bandwidth and paths
we have used merlin
have used merlin to
used merlin to improve
merlin to improve the
to improve the latency
improve the latency of
we state the exact
the latency of hadoop
state the exact problem
latency of hadoop jobs
the exact problem that
of hadoop jobs running
and solving we obtain
hadoop jobs running in
exact problem that we
jobs running in the
solving we obtain a
running in the presence
problem that we aim
in the presence of
we obtain a single
the presence of udp
that we aim to
presence of udp background
obtain a single expression
we aim to solve
a single expression for
of udp background traffic
single expression for any
aim to solve and
expression for any ri
to solve and the
solve and the assumptions
and the assumptions considered
the assumptions considered in
or prioritize classes of
assumptions considered in this
prioritize classes of traffic
considered in this work
since in the in
classes of traffic used
in the in order
of traffic used for
the in order to
traffic used for state
in order to choose
order to choose its
to choose its optimal
choose its optimal infiltration
its optimal infiltration rate
machine replication in fault
a pool has to
we review the pull
pool has to know
has to know the
to know the rate
know the rate at
the rate at which
rate at which it
based streaming protocol employed
at which it is
streaming protocol employed in
which it is attacked
protocol employed in our
employed in our system
and the revenue density
the revenue density of
followed by a description
revenue density of potential
by a description of
density of potential victim
these experiments demonstrate that
of potential victim pools
a description of our
experiments demonstrate that an
description of our novel
demonstrate that an sdn
of our novel auditing
that an sdn framework
our novel auditing approach
novel auditing approach in
a pool can estimate
auditing approach in section
pool can estimate the
with the correct information
the correct information as
can estimate the rate
correct information as input
estimate the rate with
the rate with which
rate with which it
with which it is
can provide automated network
which it is attacked
provide automated network management
it is attacked by
automated network management customized
is attacked by comparing
network management customized to
attacked by comparing the
management customized to the
we evaluate the proposed
customized to the needs
evaluate the proposed approach
by comparing the rates
to the needs of
comparing the rates of
the needs of resident
the rates of partial
needs of resident distributed
rates of partial and
we then discuss the
of partial and full
then discuss the costs
of resident distributed applications
discuss the costs of
partial and full proofs
the costs of auditing
and full proofs of
full proofs of work
proofs of work it
of work it receives
while the merlin compiler
work it receives from
the merlin compiler generates
and briefly describe how
merlin compiler generates static
it receives from its
compiler generates static network
receives from its miners
generates static network configurations
briefly describe how to
describe how to extend
how to extend our
to extend our model
extend our model for
as explained in section
merlin uses a small
explained in section ii
our model for heterogeneous
model for heterogeneous systems
runtime component to allow
component to allow for
to allow for dynamic
allow for dynamic adaptation
in order to estimate
order to estimate the
to estimate the revenue
estimate the revenue densities
the revenue densities of
revenue densities of the
densities of the other
of the other pools
based approach allows this
approach allows this adaptation
allows this adaptation to
we present related work
this adaptation to happen
present related work in
adaptation to happen safely
a pool can use
related work in section
pool can use one
can use one of
use one of two
one of two methods
by providing policy language
providing policy language constructs
policy language constructs that
language constructs that can
constructs that can be
that can be automatically
and conclude in section
can be automatically verified
implicit in the design
in the design of
the design of this
design of this runtime
of this runtime component
and sdn networks in
sdn networks in general
problem statement our approach
statement our approach focuses
our approach focuses on
approach focuses on a
is the notion that
focuses on a target
the notion that network
on a target streaming
notion that network events
a target streaming system
that network events are
target streaming system consisting
network events are generated
streaming system consisting of
events are generated in
system consisting of one
are generated in response
consisting of one data
generated in response to
of one data source
in response to the
response to the situational
to the situational status
the situational status culled
situational status culled from
status culled from a
culled from a wide
from a wide range
a wide range of
wide range of sources
which disseminates data at
disseminates data at a
data at a fixed
at a fixed rate
a fixed rate to
fixed rate to a
rate to a dynamic
to a dynamic set
a dynamic set of
dynamic set of receivers
the source has limited
source has limited upload
has limited upload bandwidth
and hence can only
hence can only send
can only send data
packet and drop rates
only send data directly
send data directly to
data directly to a
directly to a small
to a small subset
a small subset of
small subset of interested
subset of interested receivers
like it or not
participating nodes are consequently
nodes are consequently required
are consequently required to
consequently required to forward
required to forward packets
web services are distributed
to forward packets to
services are distributed objects
forward packets to their
packets to their neighbors
helping disseminate all packets
disseminate all packets across
all packets across the
packets across the system
cornell university within the
university within the community
within the community developing
the streamed data should
the community developing the
streamed data should be
community developing the web
data should be received
developing the web services
should be received by
the web services architecture
be received by all
web services architecture and
received by all nodes
services architecture and products
by all nodes within
all nodes within a
nodes within a fixed
within a fixed latency
a fixed latency from
an increasingly schizophrenic message
fixed latency from the
increasingly schizophrenic message is
latency from the source
schizophrenic message is emerging
from the source s
the source s original
source s original transmission
marketing materials assure us
materials assure us that
assure us that web
even in the presence
us that web services
in the presence of
that web services are
the presence of opportunistic
web services are a
presence of opportunistic nodes
services are a breakthrough
offering unparalleled interoperability and
user preferences for a
unparalleled interoperability and comprehensive
preferences for a particular
interoperability and comprehensive standards
for a particular network
and comprehensive standards for
we first assume a
comprehensive standards for associated
first assume a system
standards for associated technologies
assume a system in
a system in which
system in which all
in which all nodes
they portray web services
portray web services as
web services as a
have similar upload and
services as a seamless
similar upload and download
as a seamless interconnection
upload and download bandwidths
a seamless interconnection layer
seamless interconnection layer that
interconnection layer that will
layer that will propel
that will propel computer
computer commerce to a
commerce to a previously
to a previously inaccessible
a previously inaccessible level
we briefly discuss how
and they use language
briefly discuss how to
they use language evocative
discuss how to extend
use language evocative of
how to extend our
language evocative of marketing
to extend our model
evocative of marketing for
extend our model to
of marketing for distributed
our model to work
marketing for distributed object
model to work in
for distributed object middleware
to work in heterogeneous
much of this information
work in heterogeneous scenarios
of this information must
this information must be
information must be created
must be created and
technologists are sending a
be created and updated
are sending a somewhat
we assume that malicious
sending a somewhat different
created and updated dynamically
a somewhat different message
assume that malicious nodes
that malicious nodes exhibit
malicious nodes exhibit byzantine
nodes exhibit byzantine behavior
while correct nodes follow
existing sdn frameworks have
correct nodes follow the
in an essay entitled
nodes follow the protocol
sdn frameworks have largely
follow the protocol as
an essay entitled web
the protocol as defined
frameworks have largely closing
essay entitled web services
have largely closing the
entitled web services are
largely closing the loop
web services are not
services are not distributed
requesting data as needed
are not distributed objects
data as needed and
to accommodate the ever
as needed and sending
needed and sending data
and sending data as
sending data as requested
werner vogels argues that
data as requested from
vogels argues that web
as requested from them
growing demands of cloud
argues that web services
demands of cloud and
that web services will
of cloud and data
web services will work
cloud and data center
services will work well
and data center application
altrustic nodes are a
will work well for
nodes are a subgroup
work well for important
are a subgroup of
well for important classes
a subgroup of correct
for important classes of
networks will need to
important classes of applications
subgroup of correct nodes
will need to become
of correct nodes that
need to become more
correct nodes that are
to become more flexible
nodes that are willing
become more flexible and
that are willing to
more flexible and dynamic
but he also cites
are willing to upload
he also cites significant
willing to upload more
also cites significant limits
to upload more data
upload more data than
expression for ri in
as networks continue to
more data than required
for ri in a
data than required from
ri in a system
than required from them
networks continue to grow
as vogels sees it
in a system with
continue to grow in
a system with pools
to grow in complexity
system with pools of
with pools of equal
pools of equal size
the architecture is so
architecture is so centered
is so centered on
so centered on document
it will become increasingly
we employ the term
centered on document exchange
employ the term opportunistic
will become increasingly difficult
the term opportunistic to
become increasingly difficult for
term opportunistic to refer
increasingly difficult for network
and at its core
opportunistic to refer to
at its core is
difficult for network operators
to refer to a
its core is so
for network operators to
core is so simple
refer to a subgroup
network operators to provide
to a subgroup of
operators to provide this
a subgroup of byzantine
to provide this flexibility
that many features taken
provide this flexibility without
many features taken for
this flexibility without the
features taken for granted
subgroup of byzantine nodes
taken for granted in
flexibility without the support
for granted in object
of byzantine nodes that
without the support of
byzantine nodes that attempt
the support of proper
nodes that attempt to
support of proper tools
oriented systems are fundamentally
that attempt to give
systems are fundamentally lacking
of proper tools and
attempt to give less
proper tools and infrastructure
to give less data
give less data than
less data than they
examples include dynamic object
data than they would
include dynamic object creation
than they would if
dynamic object creation and
they would if they
object creation and garbage
would if they behaved
creation and garbage collection
if they behaved as
they behaved as correct
behaved as correct nodes
provide both the control
both the control and
with the intention of
the control and monitoring
dynamically created object references
the intention of obtaining
control and monitoring components
intention of obtaining as
and monitoring components necessary
of obtaining as much
monitoring components necessary to
obtaining as much data
and a variety of
as much data as
components necessary to automatically
much data as possible
a variety of reliability
data as possible at
necessary to automatically adapt
as possible at least
variety of reliability and
possible at least feasible
to automatically adapt the
at least feasible cost
of reliability and transactional
automatically adapt the network
reliability and transactional mechanisms
adapt the network to
the network to the
network to the needs
to the needs of
these may employ a
the needs of the
may employ a simple
needs of the applications
employ a simple strategy
because both systems use
such as refuse to
both systems use a
as refuse to contribute
systems use a language
refuse to contribute any
to contribute any upload
contribute any upload resources
or a more elaborate
both perspectives can t
they have rigorous semantics
perspectives can t be
q mi q mi
a more elaborate strategy
have rigorous semantics that
can t be correct
rigorous semantics that can
more elaborate strategy that
semantics that can be
elaborate strategy that allows
that can be formally
strategy that allows them
can be formally defined
that allows them to
it s easy to
allows them to cheat
s easy to see
them to cheat without
easy to see how
to cheat without being
to see how this
cheat without being easily
see how this situation
without being easily detected
how this situation arose
they provide predictable operational
provide predictable operational behavior
notice that our model
web services are the
that our model diverges
services are the most
our model diverges from
are the most recent
model diverges from the
the most recent in
diverges from the one
most recent in a
from the one used
recent in a long
they allow for the
in a long series
the one used in
a long series of
one used in bar
long series of object
used in bar gossip
allow for the rigorous
series of object oriented
for the rigorous expression
of object oriented interoperability
the rigorous expression of
object oriented interoperability platforms
rigorous expression of algorithms
expression of algorithms for
of algorithms for monitoring
algorithms for monitoring or
for monitoring or managing
in which nodes are
and mixes ideas from
monitoring or managing sdn
which nodes are classified
or managing sdn networks
mixes ideas from corba
nodes are classified as
are classified as byzantine
while exploiting xml and
exploiting xml and other
xml and other web
rational nodes attempt to
nodes attempt to maximize
attempt to maximize their
to maximize their utility
maximize their utility while
their utility while still
utility while still following
while still following the
still following the defined
developers using popular middleware
following the defined protocol
using popular middleware platforms
popular middleware platforms can
middleware platforms can transform
platforms can transform a
can transform a program
our model is actually
transform a program object
model is actually less
a program object into
is actually less lenient
program object into a
object into a web
into a web services
a web services object
nodes employing strategies to
employing strategies to maximize
strategies to maximize their
or access a remote
to maximize their utility
access a remote ws
maximize their utility are
a remote ws object
this work was supported
their utility are classified
utility are classified as
are classified as byzantine
at the touch of
the touch of a
touch of a button
so that we can
that we can build
by a grant from
we can build a
a grant from the
performance leaves something to
grant from the darpa
can build a practical
from the darpa mrc
build a practical punishment
the darpa mrc program
leaves something to be
something to be desired
based system in which
but computers and networks
system in which any
computers and networks have
in which any node
and networks have become
which any node not
networks have become astonishingly
any node not contributing
have become astonishingly fast
node not contributing its
not contributing its fair
contributing its fair share
its fair share of
fair share of data
major application providers are
share of data may
application providers are planning
of data may be
providers are planning to
data may be expelled
are planning to offer
may be expelled from
planning to offer ws
be expelled from the
to offer ws interfaces
expelled from the system
offer ws interfaces to
ws interfaces to their
interfaces to their products
throughout the paper we
q symmetric equilibrium values
the paper we use
symmetric equilibrium values for
so it makes perfect
paper we use the
it makes perfect sense
equilibrium values for a
makes perfect sense that
we use the terms
perfect sense that the
online measurement of large
use the terms upload
values for a system
measurement of large traffic
sense that the marketing
of large traffic aggregates
the terms upload factor
large traffic aggregates on
that the marketing community
traffic aggregates on commodity
for a system of
aggregates on commodity switches
the marketing community would
terms upload factor and
marketing community would feel
a system of q
community would feel that
system of q pools
would feel that finally
of q pools of
upload factor and download
q pools of equal
factor and download factor
pools of equal sizes
and download factor to
they ve reached the
ve reached the promised
download factor to refer
reached the promised land
factor to refer to
often publish this data
to refer to the
publish this data to
refer to the ratio
this data to demonstrate
to the ratio between
data to demonstrate their
the ratio between an
to demonstrate their honesty
ratio between an upload
demonstrate their honesty to
between an upload or
their honesty to their
an upload or download
honesty to their miners
upload or download rate
or download rate and
download rate and the
rate and the original
has an understandable emphasis
and the original stream
the original stream rate
an understandable emphasis on
understandable emphasis on facts
emphasis on facts on
on facts on the
facts on the ground
on the ground and
given a stream rate
the ground and the
a stream rate of
ground and the vogels
and the vogels essay
the vogels essay reflects
vogels essay reflects the
essay reflects the realities
reflects the realities of
the realities of an
realities of an architecture
of an architecture focused
an architecture focused at
architecture focused at its
focused at its core
at its core on
a download rate of
its core on using
core on using document
on using document exchange
using document exchange to
document exchange to access
exchange to access backend
to access backend servers
this core has been
kbps corresponds to a
core has been extended
corresponds to a download
has been extended with
to a download factor
been extended with such
a download factor of
extended with such mechanisms
with such mechanisms as
such mechanisms as rpc
mechanisms as rpc and
as rpc and asynchronous
rpc and asynchronous messaging
a pool can infiltrate
a compositional architecture for
pool can infiltrate each
compositional architecture for gossip
architecture for gossip protocols
can infiltrate each of
infiltrate each of the
each of the other
of the other pools
the other pools with
other pools with some
streaming system model our
a variety of roll
system model our auditing
pools with some nominal
model our auditing approach
with some nominal probing
our auditing approach is
some nominal probing mining
forward and rendezvous options
auditing approach is used
nominal probing mining power
approach is used over
probing mining power and
is used over the
mining power and measure
used over the chainsaw
power and measure the
over the chainsaw protocol
and measure the revenue
measure the revenue density
but the primary usage
the revenue density directly
the primary usage case
revenue density directly by
primary usage case remains
density directly by monitoring
usage case remains that
directly by monitoring the
case remains that of
by monitoring the probe
remains that of a
monitoring the probe s
all nodes participating in
that of a client
the probe s rewards
of a client sending
probe s rewards from
a client sending documents
s rewards from the
nodes participating in the
rewards from the pool
client sending documents to
participating in the system
sending documents to a
in the system are
documents to a back
the system are organized
system are organized into
are organized into a
organized into a fully
into a fully connected
end service in a
a fully connected mesh
service in a client
block withholding recycling we
fully connected mesh overlay
withholding recycling we assume
recycling we assume that
we assume that the
assume that the infiltrating
that the infiltrating miners
where each node has
the infiltrating miners are
each node has the
infiltrating miners are loyal
node has the same
miners are loyal to
has the same number
are loyal to the
the same number of
loyal to the attacker
same number of neighbors
the assumption is that
assumption is that the
is that the application
that the application can
the application can tolerate
the source is randomly
application can tolerate substantial
source is randomly connected
can tolerate substantial delay
is randomly connected to
tolerate substantial delay before
randomly connected to a
substantial delay before a
connected to a small
delay before a response
to a small subset
before a response arrives
a small subset of
some of the pool
small subset of the
of the pool s
subset of the nodes
the pool s members
pool s members may
and mechanisms capable of
s members may be
mechanisms capable of introducing
members may be disloyal
capable of introducing delays
may be disloyal infiltrators
the streaming process starts
of introducing delays are
streaming process starts at
introducing delays are scattered
process starts at the
delays are scattered throughout
starts at the source
are scattered throughout the
when sending disloyal miners
scattered throughout the architecture
sending disloyal miners to
disloyal miners to perform
miners to perform block
to perform block withholding
which breaks the data
perform block withholding at
breaks the data stream
the more basic assumption
block withholding at other
the data stream into
more basic assumption is
withholding at other pools
data stream into packets
basic assumption is that
stream into packets and
assumption is that it
into packets and sends
an attacker takes a
is that it all
attacker takes a significant
packets and sends notifications
takes a significant risk
and sends notifications to
that it all boils
managing the network with
sends notifications to its
the network with merlin
it all boils down
notifications to its neighbors
all boils down to
to its neighbors as
boils down to moving
its neighbors as soon
neighbors as soon as
down to moving documents
as soon as it
soon as it has
to moving documents around
as it has packets
it has packets to
can use a loyal
has packets to disseminate
moving documents around whereas
use a loyal miner
a loyal miner w
documents around whereas the
loyal miner w to
miner w to infiltrate
around whereas the most
w to infiltrate pool
these notifications are small
whereas the most basic
notifications are small messages
the most basic assumption
are small messages used
most basic assumption of
small messages used only
basic assumption of a
messages used only to
assumption of a distributed
used only to inform
of a distributed object
only to inform neighbors
a distributed object system
to inform neighbors of
distributed object system is
inform neighbors of the
object system is that
neighbors of the availability
system is that the
of the availability of
is that the world
the availability of new
that the world consists
availability of new packets
the world consists of
thinking the miner is
world consists of programs
the miner is loyal
consists of programs and
miner is loyal to
of programs and data
is loyal to it
based on the received
on the received notifications
active and passive objects
might use it to
use it to attack
each node requests missing
it to attack pool
node requests missing packets
the gist of vogel
gist of vogel s
of vogel s essay
vogel s essay is
and the source satisfies
s essay is that
the source satisfies as
the miner m can
essay is that even
miner m can perform
source satisfies as many
m can perform honest
is that even with
can perform honest mining
satisfies as many requests
perform honest mining for
that even with all
honest mining for pool
as many requests as
even with all the
many requests as allowed
with all the contemplated
requests as allowed by
all the contemplated extensions
as allowed by its
allowed by its upload
by its upload capacity
web services are deeply
rather than withhold its
services are deeply mismatched
than withhold its blocks
are deeply mismatched with
deeply mismatched with distributed
mismatched with distributed object
with distributed object computing
with chainsaw the upload
and not return any
chainsaw the upload capacity
not return any revenue
the upload capacity of
return any revenue to
upload capacity of the
any revenue to pool
the dilemma underlying the
capacity of the source
dilemma underlying the debate
of the source does
underlying the debate is
the source does not
the debate is that
source does not need
debate is that the
does not need to
is that the platforms
not need to increase
that the platforms one
need to increase with
the platforms one uses
to increase with the
platforms one uses to
increase with the size
it will take its
with the size of
one uses to create
the size of the
will take its share
size of the system
uses to create wscompatible
take its share of
to create wscompatible objects
its share of pool
create wscompatible objects impose
wscompatible objects impose no
objects impose no such
even an upload capacity
impose no such restrictions
an upload capacity of
a language for provisioning
upload capacity of twice
language for provisioning network
capacity of twice the
for provisioning network resources
there is nothing in
which thinks the miner
of twice the stream
thinks the miner is
is nothing in j
the miner is loyal
twice the stream rate
miner is loyal to
the stream rate is
is loyal to it
stream rate is sufficient
rate is sufficient to
is sufficient to ensure
sufficient to ensure that
to ensure that the
and deliver it back
ensure that the system
deliver it back to
net that warns a
that the system performs
that warns a user
the system performs and
it back to pool
system performs and scales
warns a user that
performs and scales well
a user that an
user that an intended
that an intended use
an intended use of
intended use of the
as nodes receive packets
use of the architecture
to avoid such a
of the architecture may
avoid such a risk
the architecture may be
they mimic the role
architecture may be inappropriate
mimic the role of
the role of the
role of the source
a pool needs a
pool needs a sufficient
needs a sufficient number
a sufficient number of
sending notifications to their
sufficient number of verified
notifications to their own
number of verified miners
much of the excitement
of verified miners miners
of the excitement reflects
verified miners miners that
the excitement reflects the
miners miners that it
excitement reflects the realization
miners that it knows
to their own neighbors
that it knows to
reflects the realization that
their own neighbors in
the realization that with
own neighbors in the
realization that with web
neighbors in the mesh
that with web services
it knows to be
knows to be loyal
allowing packets to be
interoperability really is easier
packets to be propagated
to be propagated through
be propagated through the
propagated through the system
developers have long struggled
the optimal infiltration rate
have long struggled with
optimal infiltration rate may
long struggled with program
infiltration rate may be
rate may be as
may be as high
be as high as
based approach to acquisition
software defined traffic measurement
approach to acquisition of
defined traffic measurement with
to acquisition of packets
traffic measurement with opensketch
program interconnection and integration
and it is natural
it is natural to
of the pool size
is natural to applaud
natural to applaud a
to applaud a widely
applaud a widely adopted
a widely adopted advance
but this is only
this is only in
is only in extreme
provides some resilience to
only in extreme cases
some resilience to failure
in extreme cases when
resilience to failure or
extreme cases when pools
like it or not
cases when pools are
to failure or malicious
when pools are large
failure or malicious behavior
web services are becoming
services are becoming a
for practical pool sizes
are becoming a de
since a participant will
a participant will have
participant will have multiple
will have multiple possible
have multiple possible sources
facto standard for everything
multiple possible sources for
possible sources for each
sources for each packet
a pool may need
pool may need up
may need up to
that s not all
the mesh overlay defines
mesh overlay defines a
overlay defines a predetermined
defines a predetermined set
a predetermined set of
predetermined set of neighbors
set of neighbors for
of neighbors for each
neighbors for each peer
based direct sales systems
direct sales systems are
of its mining power
sales systems are turning
its mining power for
systems are turning to
mining power for infiltration
which also makes it
are turning to the
also makes it hard
turning to the ws
makes it hard for
to the ws architecture
it hard for malicious
the ws architecture as
hard for malicious peers
ws architecture as a
for malicious peers to
architecture as a means
pools typically have loyal
as a means of
malicious peers to round
a means of enlarging
typically have loyal mining
means of enlarging their
peers to round up
of enlarging their markets
have loyal mining power
to round up on
loyal mining power either
round up on individual
mining power either run
up on individual peers
power either run directly
on individual peers since
either run directly by
individual peers since attackers
run directly by the
peers since attackers lack
directly by the pool
since attackers lack a
by the pool owners
attackers lack a deterministic
com has developed a
lack a deterministic means
has developed a web
the pool owners or
a deterministic means of
pool owners or sold
deterministic means of acquiring
owners or sold as
means of acquiring control
or sold as a
access library whereby third
sold as a service
of acquiring control of
as a service but
acquiring control of all
a service but run
control of all of
service but run on
of all of its
but run on the
party application developers can
all of its neighbors
application developers can access
run on the pool
developers can access their
on the pool owners
can access their datacenters
the pool owners hardware
all nodes with exception
access their datacenters from
nodes with exception of
their datacenters from a
with exception of the
datacenters from a diversity
exception of the source
from a diversity of
of the source have
a diversity of end
the source have a
source have a fixed
have a fixed upper
a fixed upper limit
fixed upper limit on
upper limit on their
limit on their upload
on their upload contribution
an application could order
application could order thus
could order thus supplies
order thus supplies directly
thus supplies directly from
supplies directly from amazon
query the fulfillment system
the fulfillment system to
fulfillment system to track
system to track order
to track order status
track order status or
order status or billing
status or billing data
times the stream rate
however the size of
the size of this
size of this mining
of this mining power
this mining power is
mining power is considered
both the vendor and
power is considered a
the vendor and the
is considered a trade
vendor and the application
defined by the protocol
and the application developer
considered a trade secret
the application developer benefit
a trade secret and
trade secret and is
secret and is not
and is not published
this upper limit is
upper limit is not
com enlarges its client
limit is not respected
enlarges its client base
is not respected by
not respected by opportunistic
countermeasures as in the
respected by opportunistic nodes
as in the case
in the case of
while the developer avoids
the case of classical
the developer avoids duplicating
case of classical block
developer avoids duplicating an
of classical block withholding
avoids duplicating an enormous
who attempt to reduce
duplicating an enormous technology
classical block withholding explained
an enormous technology investment
block withholding explained in
attempt to reduce it
withholding explained in section
to reduce it with
explained in section ii
reduce it with the
it with the goal
with the goal of
the goal of uploading
goal of uploading less
of uploading less data
web service components will
service components will play
components will play a
a pool might detect
will play a critical
pool might detect that
on the course of
might detect that it
play a critical role
detect that it is
the course of a
that it is being
course of a streaming
it is being attacked
of a streaming session
a critical role in
critical role in tremendous
role in tremendous numbers
in tremendous numbers of
tremendous numbers of end
but cannot detect which
cannot detect which of
each node stores packets
detect which of its
node stores packets and
which of its miners
stores packets and forwards
of its miners is
packets and forwards them
its miners is the
and forwards them to
the challenge is to
miners is the attacker
challenge is to make
forwards them to other
is to make such
them to other peers
to make such systems
to other peers only
make such systems work
other peers only while
therefore a pool cannot
peers only while the
a pool cannot block
only while the packet
pool cannot block or
while the packet is
cannot block or punish
such systems work reliably
the packet is within
block or punish withholding
packet is within its
or punish withholding miners
is within its availability
within its availability window
outages that plague human
that plague human users
plague human users of
human users of web
users of web browsers
usually spanning a few
of web browsers don
spanning a few seconds
web browsers don t
various techniques can be
browsers don t cause
techniques can be used
don t cause much
can be used to
t cause much harm
be used to encourage
the one issue that
used to encourage miners
each node also maintains
one issue that unites
node also maintains an
to encourage miners to
also maintains an interest
encourage miners to submit
maintains an interest window
miners to submit full
issue that unites almost
to submit full blocks
outages could disrupt a
that unites almost all
could disrupt a computer
unites almost all approaches
which represents the set
almost all approaches to
represents the set of
a pool can pay
the set of packets
all approaches to distributed
set of packets in
pool can pay a
approaches to distributed computing
can pay a bonus
of packets in which
to distributed computing is
pay a bonus for
computer pathway buried deep
a bonus for submitting
distributed computing is the
bonus for submitting a
pathway buried deep within
for submitting a full
computing is the need
submitting a full proof
buried deep within an
packets in which the
deep within an application
a full proof of
within an application on
full proof of work
is the need to
in which the peer
the need to know
which the peer is
an application on which
the peer is currently
need to know whether
peer is currently interested
application on which an
this would increase the
on which an enterprise
to know whether certain
would increase the revenue
which an enterprise has
know whether certain components
an enterprise has become
nodes choose packets to
whether certain components in
enterprise has become dependent
certain components in the
choose packets to request
components in the system
increase the revenue of
in the system have
packets to request from
the system have failed
the revenue of the
it is too easy
system have failed or
to request from each
have failed or are
request from each of
failed or are otherwise
revenue of the miner
or are otherwise unavailable
from each of its
is too easy to
of the miner that
each of its neighbors
too easy to dismiss
the miner that found
easy to dismiss these
miner that found a
to dismiss these concerns
when designing and building
dismiss these concerns by
respecting a maximum limit
designing and building systems
a maximum limit l
and building systems that
maximum limit l on
building systems that need
limit l on the
systems that need to
l on the number
that need to function
on the number of
need to function at
that found a block
these concerns by arguing
the number of outstanding
to function at a
number of outstanding requests
function at a global
of outstanding requests to
at a global scale
found a block while
concerns by arguing that
a block while reducing
by arguing that the
block while reducing the
arguing that the web
while reducing the revenue
that the web is
failure management needs to
the web is extremely
reducing the revenue of
web is extremely scalable
management needs to be
is extremely scalable and
the revenue of the
extremely scalable and robust
needs to be considered
outstanding requests to each
to be considered a
revenue of the other
be considered a fundamental
of the other miners
considered a fundamental building
the other miners from
but this ignores the
other miners from this
a fundamental building block
this ignores the way
miners from this block
ignores the way we
the way we use
way we use the
we use the web
this paper describes the
paper describes the development
while the average revenue
describes the development of
the average revenue of
the development of a
a human can deal
development of a system
average revenue of each
human can deal with
revenue of each miner
can deal with the
of each miner would
deal with the many
each miner would stay
independent failure management service
with the many error
miner would stay the
the many error conditions
would stay the same
many error conditions the
error conditions the web
conditions the web exposes
which allows systems and
allows systems and applications
small miners will suffer
systems and applications to
miners will suffer from
and applications to incorporate
handling those conditions in
applications to incorporate accurate
those conditions in a
to incorporate accurate detection
conditions in a seamless
will suffer from higher
incorporate accurate detection of
suffer from higher variance
accurate detection of failed
from higher variance in
detection of failed processes
higher variance in revenue
automated manner is an
manner is an entirely
is an entirely different
an entirely different challenge
another approach is to
approach is to introduce
is to introduce a
without the need for
to introduce a joining
the need for making
introduce a joining fee
need for making compromises
when we take what
a joining fee by
for making compromises in
we take what was
making compromises in their
joining fee by paying
compromises in their particular
take what was once
in their particular design
fee by paying new
what was once a
by paying new miners
was once a batch
paying new miners less
once a batch service
new miners less for
a batch service or
miners less for their
batch service or a
less for their work
service or a web
with the advent of
for their work until
or a web site
their work until they
a web site and
the advent of ubiquitous
web site and transform
work until they have
site and transform it
until they have established
and transform it into
they have established a
transform it into a
have established a reputation
it into a web
established a reputation with
into a web service
a reputation with the
reputation with the pool
there is no way
it is becoming clear
is no way to
is becoming clear that
no way to enforce
becoming clear that the
miners that seek flexibility
way to enforce appropriate
clear that the systems
to enforce appropriate patterns
that the systems that
enforce appropriate patterns of
that seek flexibility may
appropriate patterns of use
the systems that are
seek flexibility may not
systems that are used
flexibility may not accept
that are used today
may not accept this
are used today in
not accept this policy
what s to stop
accept this policy and
used today in local
this policy and choose
s to stop a
policy and choose another
to stop a web
and choose another pool
stop a web client
a web client from
web client from trying
client from trying to
from trying to download
trying to download amazon
can not simply be
not simply be employed
simply be employed in
com s entire catalog
the pool can use
be employed in their
pool can use a
employed in their existing
can use a honeypot
in their existing form
use a honeypot trap
their existing form or
a honeypot trap by
existing form or trivially
the only answer is
honeypot trap by sending
form or trivially converted
trap by sending the
or trivially converted for
by sending the miners
trivially converted for wide
sending the miners tasks
the miners tasks which
miners tasks which it
tasks which it knows
which it knows will
it knows will result
knows will result in
will result in a
result in a full
in a full proof
a full proof of
full proof of work
one might argue that
might argue that none
argue that none of
that none of these
none of these uses
whatever form such systems
of these uses are
form such systems may
these uses are what
such systems may take
uses are what the
systems may take in
are what the architecture
may take in the
what the architecture is
take in the future
the architecture is intended
architecture is intended to
is intended to support
whether they are replicated
if a miner fails
they are replicated databases
upload factor download factor
a miner fails to
are replicated databases of
not so many years
replicated databases of hyper
so many years ago
miner fails to submit
fails to submit the
to submit the full
submit the full proof
the full proof of
full proof of work
proof of work it
of work it is
work it is tagged
it is tagged as
server architectures faltered over
is tagged as an
architectures faltered over precisely
tagged as an attacker
view or virtual synchronous
faltered over precisely this
or virtual synchronous groups
over precisely this type
virtual synchronous groups or
precisely this type of
synchronous groups or agents
this type of situation
groups or agents employing
to prevent the attacker
or agents employing lazy
prevent the attacker from
agents employing lazy consistency
the attacker from learning
employing lazy consistency schemes
attacker from learning them
server technologies of the
one of the key
the honeypot tasks have
of the key problems
honeypot tasks have to
the key problems that
tasks have to be
key problems that needs
have to be regularly
problems that needs to
to be regularly refreshed
that needs to be
needs to be addressed
is that of the
that of the detection
of the detection and
the detection and handling
pools can also incorporate
detection and handling of
s were widely seen
and handling of faulty
can also incorporate out
handling of faulty components
were widely seen as
also incorporate out of
widely seen as a
incorporate out of band
seen as a kind
out of band mechanisms
as a kind of
of band mechanisms to
a kind of panacea
band mechanisms to deter
mechanisms to deter attacks
building distributed systems and
a silver bullet that
distributed systems and applications
silver bullet that would
such as verifying the
bullet that would slay
systems and applications today
that would slay evil
as verifying the identity
would slay evil mainframe
and applications today is
slay evil mainframe architectures
verifying the identity of
applications today is done
the identity of miners
today is done using
identity of miners or
is done using a
of miners or using
done using a variety
miners or using trusted
using a variety of
enterprises fell over themselves
or using trusted computing
fell over themselves in
using trusted computing technologies
over themselves in a
a variety of systems
themselves in a kind
variety of systems ranging
in a kind of
of systems ranging from
a kind of technology
systems ranging from the
kind of technology gold
ranging from the bare
of technology gold rush
from the bare bone
the bare bone protocols
bare bone protocols interfaces
bone protocols interfaces like
protocols interfaces like bsd
only to discover that
interfaces like bsd sockets
to discover that the
like bsd sockets and
discover that the technology
bsd sockets and the
that the technology had
that assure no block
the technology had been
sockets and the tdi
technology had been oversold
assure no block withholding
no block withholding is
block withholding is taking
withholding is taking place
to rpc based systems
rpc based systems such
based systems such as
this would require miners
systems such as dce
would require miners to
such as dce and
require miners to use
the total cost of
as dce and to
total cost of ownership
dce and to more
cost of ownership for
and to more advanced
of ownership for clientserver
to more advanced distributed
ownership for clientserver systems
more advanced distributed support
for clientserver systems remains
advanced distributed support systems
clientserver systems remains excessively
distributed support systems such
systems remains excessively high
support systems such as
miners to use specialized
systems such as isis
to use specialized hardware
use specialized hardware and
specialized hardware and software
the number of system
number of system administrators
of system administrators remains
system administrators remains roughly
an overhead miners may
administrators remains roughly proportional
overhead miners may not
remains roughly proportional to
miners may not accept
roughly proportional to the
proportional to the size
to the size of
the size of the
size of the deployment
there is no known
is no known silver
no known silver bullet
a list like these
list like these comments
like these comments might
all these techniques reduce
these comments might have
these techniques reduce the
comments might have seemed
techniques reduce the pool
might have seemed like
reduce the pool s
have seemed like an
the pool s attractiveness
seemed like an indictment
pool s attractiveness and
like an indictment of
s attractiveness and deter
an indictment of the
attractiveness and deter miners
indictment of the technology
because we lacked solutions
block withholding in practice
withholding in practice long
in practice long term
practice long term block
long term block withholding
term block withholding attacks
block withholding attacks are
withholding attacks are difficult
attacks are difficult to
are difficult to hide
we know how to
know how to implement
how to implement management
to implement management tools
since miners using an
implement management tools and
miners using an attacked
management tools and fault
maximum upload factor figure
using an attacked pool
an attacked pool would
attacked pool would notice
pool would notice the
would notice the reduced
notice the reduced revenue
the reduced revenue density
how to replicate data
after years of experience
download and upload factors
years of experience with
to replicate data and
of experience with building
replicate data and functionality
experience with building these
and upload factors of
with building these systems
upload factors of nodes
building these systems and
factors of nodes in
these systems and applications
and how to achieve
such attacks are rarely
how to achieve high
attacks are rarely reported
to achieve high ava
of nodes in an
achieve high ava ilability
nodes in an ideal
it is clear that
in an ideal system
is clear that failure
and we can therefore
an ideal system where
we can therefore conclude
ideal system where all
can therefore conclude that
system where all nodes
therefore conclude that they
where all nodes behave
conclude that they are
we ve had decades
clear that failure management
ve had decades of
that they are indeed
had decades of experience
all nodes behave correctly
decades of experience with
they are indeed rare
of experience with large
that failure management is
failure management is not
management is not just
is not just a
not just a essential
scale system monitoring and
just a essential tool
system monitoring and control
a essential tool for
a recent exception is
this limit not only
recent exception is an
limit not only improves
exception is an attack
not only improves the
and are beginning to
only improves the general
are beginning to understand
improves the general flow
is an attack on
the general flow of
beginning to understand how
essential tool for group
to understand how to
tool for group oriented
understand how to build
for group oriented systems
how to build solutions
general flow of packets
to build solutions on
an attack on the
build solutions on an
attack on the eligius
solutions on an internet
on the eligius pool
on an internet scale
all which have built
the eligius pool performed
but also makes it
eligius pool performed in
also makes it harder
pool performed in may
makes it harder for
performed in may and
it harder for malicious
in may and june
harder for malicious peers
for malicious peers to
malicious peers to overrequest
but that it is
peers to overrequest packets
that it is a
to overrequest packets from
peer file sharing turns
overrequest packets from their
it is a fundamental
file sharing turns out
packets from their neighbors
sharing turns out to
is a fundamental service
turns out to be
a fundamental service that
out to be illegal
fundamental service that should
service that should be
peers maintain a queue
that should be placed
maintain a queue of
and it doesn t
should be placed among
it doesn t work
a queue of non
doesn t work all
be placed among such
t work all that
placed among such established
work all that well
among such established basic
such established basic services
satisfied requests from its
established basic services as
requests from its neighbors
basic services as naming
keeping only the l
only the l most
the l most recent
l most recent ones
but spawned a new
spawned a new generation
a new generation of
new generation of technologies
service brokerage and ipc
generation of technologies based
of technologies based on
technologies based on distributed
based on distributed hash
on distributed hash tables
distributed hash tables and
bitcoin before detecting the
hash tables and epidemic
before detecting the attack
tables and epidemic communication
this paper reports on
and epidemic communication protocols
expected behavior our first
behavior our first goal
paper reports on an
our first goal is
at which point payouts
reports on an ongoing
which point payouts to
these offer remarkably stable
first goal is to
on an ongoing research
goal is to explore
point payouts to the
is to explore the
payouts to the attackers
to explore the typical
an ongoing research effort
scalable tools for dealing
explore the typical signature
to the attackers were
the typical signature of
the attackers were blocked
typical signature of the
ongoing research effort to
tools for dealing with
signature of the system
for dealing with enormous
research effort to abstract
dealing with enormous numbers
the attackers continued the
with enormous numbers of
attackers continued the attack
effort to abstract the
enormous numbers of components
since an understanding of
numbers of components scattered
to abstract the failure
of components scattered over
an understanding of the
components scattered over a
abstract the failure handling
scattered over a network
understanding of the behavior
the failure handling strategies
of the behavior of
failure handling strategies from
the behavior of pullbased
not all the stories
handling strategies from a
all the stories are
behavior of pullbased dissemination
the stories are positive
strategies from a variety
of pullbased dissemination in
from a variety of
more bitcoin before realizing
pullbased dissemination in the
bitcoin before realizing they
a variety of popular
before realizing they were
dissemination in the absence
realizing they were not
variety of popular distributed
they were not receiving
in the absence of
of popular distributed systems
the absence of opportunistic
the web services community
absence of opportunistic nodes
web services community decided
were not receiving their
services community decided not
of opportunistic nodes will
community decided not to
not receiving their payout
popular distributed systems and
opportunistic nodes will turn
decided not to adapt
distributed systems and to
not to adapt the
nodes will turn out
to adapt the corba
systems and to develop
the reasons the attack
adapt the corba fault
and to develop a
will turn out to
reasons the attack was
turn out to be
the attack was so
out to be important
attack was so easily
to be important when
tolerance standard for their
to develop a basic
standard for their setting
was so easily subverted
be important when we
so easily subverted is
important when we set
develop a basic failure
when we set out
easily subverted is the
a basic failure management
this is a specification
we set out to
is a specification i
set out to introduce
a specification i know
out to introduce auditing
specification i know well
basic failure management service
subverted is the limited
failure management service that
is the limited efforts
management service that can
the limited efforts of
it was based on
we conducted experiments using
service that can be
conducted experiments using an
was based on the
that can be used
experiments using an event
based on the virtual
can be used by
limited efforts of the
on the virtual synchrony
be used by any
efforts of the attackers
used by any distributed
of the attackers to
the virtual synchrony model
the attackers to hide
by any distributed system
attackers to hide themselves
virtual synchrony model colleagues
any distributed system regardless
synchrony model colleagues of
distributed system regardless of
model colleagues of mine
system regardless of the
colleagues of mine and
which is described in
of mine and i
they have only used
mine and i developed
is described in more
and i developed in
described in more detail
i developed in work
in more detail in
developed in work on
more detail in section
in work on the
have only used two
regardless of the purpose
only used two payout
work on the isis
used two payout addresses
on the isis toolkit
two payout addresses to
of the purpose of
payout addresses to collect
the purpose of that
addresses to collect their
purpose of that system
to collect their payouts
of that system or
the standard hasn t
that system or the
standard hasn t been
system or the techniques
hasn t been a
or the techniques used
t been a commercial
and so it was
been a commercial success
so it was possible
we evaluate the performance
it was possible for
evaluate the performance of
the strategies employed by
was possible for the
strategies employed by this
but the corba standard
employed by this basic
possible for the alert
by this basic service
the corba standard limits
for the alert pool
corba standard limits itself
this basic service are
standard limits itself to
the alert pool manager
basic service are specifically
limits itself to lock
service are specifically targeted
alert pool manager to
are specifically targeted towards
pool manager to cluster
specifically targeted towards applications
nodes during an ideal
manager to cluster the
state replication of a
during an ideal execution
to cluster the attacking
replication of a deterministic
cluster the attacking miners
of a deterministic server
targeted towards applications that
an ideal execution of
towards applications that need
ideal execution of chainsaw
applications that need to
the attacking miners and
that need to operate
perhaps the issue is
need to operate on
attacking miners and obtain
to operate on a
the issue is the
where all the nodes
operate on a global
all the nodes behave
on a global scale
the nodes behave correctly
issue is the way
miners and obtain a
is the way the
and obtain a statistically
the way the technology
obtain a statistically significant
way the technology was
a statistically significant proof
the technology was used
statistically significant proof of
we fixed the upload
significant proof of their
fixed the upload factor
to build a successful
the upload factor of
build a successful service
upload factor of the
proof of their wrongdoing
a successful service the
factor of the source
not the technology itself
successful service the following
of the source at
service the following goals
the following goals were
it is unknown whether
following goals were set
is unknown whether this
unknown whether this was
whether this was a
this was a classical
was a classical block
used in other ways
a classical block withholding
design a failure management
classical block withholding attack
a failure management system
failure management system that
has been quite successful
management system that is
with the goal of
system that is independent
the goal of sabotage
that is independent of
is independent of the
independent of the distributed
of the distributed systems
or a more elaborate
the distributed systems packages
a more elaborate scheme
isis runs the new
distributed systems packages in
runs the new york
systems packages in use
the new york stock
packages in use and
new york stock exchange
in use and provide
and the stream rate
use and provide failure
the stream rate to
and provide failure detection
york stock exchange quote
provide failure detection of
to verify the effectiveness
failure detection of processes
stock exchange quote and
verify the effectiveness of
exchange quote and trade
the effectiveness of block
quote and trade reporting
effectiveness of block withholding
and trade reporting system
of block withholding for
block withholding for profit
a role it has
improve the accuracy of
role it has played
the accuracy of detection
it has played since
accuracy of detection of
of detection of process
we varied the maximum
detection of process and
varied the maximum upload
of process and node
the maximum upload factor
process and node failure
maximum upload factor of
and node failure through
upload factor of nodes
node failure through systems
factor of nodes to
failure through systems support
of nodes to see
nodes to see how
to see how it
see how it affected
design support for failure
how it affected both
support for failure detectors
implemented an experimental bitcoin
for failure detectors to
it affected both the
failure detectors to work
an experimental bitcoin test
detectors to work in
affected both the download
to work in large
experimental bitcoin test network
work in large scale
both the download and
in large scale systems
bitcoin test network and
the download and upload
and the french air
download and upload factors
the french air traffic
test network and demonstrated
french air traffic control
and upload factors of
while maintaining a high
air traffic control system
maintaining a high level
upload factors of nodes
a high level of
network and demonstrated the
factors of nodes across
and demonstrated the practicality
of nodes across the
and the us naval
nodes across the system
the us naval aegis
demonstrated the practicality of
high level of accuracy
the practicality of the
us naval aegis warship
practicality of the attack
naval aegis warship communication
aegis warship communication system
the maximum upload factor
provide support for the
maximum upload factor is
support for the detection
for the detection of
upload factor is a
the detection of partitions
to name just a
detection of partitions in
name just a few
of partitions in networks
factor is a fixed
is a fixed parameter
a fixed parameter which
fixed parameter which defines
leslie lamport s paxos
bitcoin s health large
build a comprehensive software
parameter which defines the
lamport s paxos protocol
which defines the maximum
s paxos protocol has
defines the maximum rate
paxos protocol has been
s health large pools
protocol has been used
the maximum rate at
health large pools hinder
has been used to
a comprehensive software package
been used to build
large pools hinder bitcoin
used to build file
maximum rate at which
comprehensive software package that
rate at which a
software package that can
at which a node
pools hinder bitcoin s
which a node will
package that can be
a node will upload
hinder bitcoin s distributed
node will upload data
that can be easily
will upload data to
bitcoin s distributed nature
upload data to all
can be easily integrated
s distributed nature as
data to all its
distributed nature as they
to all its neighbors
to build file systems
be easily integrated into
build file systems and
nature as they put
file systems and scalable
easily integrated into various
as they put a
integrated into various distributed
systems and scalable clusters
into various distributed systems
they put a lot
various distributed systems packages
put a lot of
distributed systems packages and
for fairness in nodes
systems packages and applications
a lot of mining
fairness in nodes bandwidth
lot of mining power
in nodes bandwidth consumption
of mining power in
none of these examples
mining power in the
the resulting system is
of these examples uses
power in the hands
resulting system is implemented
these examples uses lock
system is implemented and
in the hands of
is implemented and is
the hands of a
implemented and is under
hands of a few
and is under test
of a few pool
step replication of the
a few pool managers
replication of the type
is under test in
we would like all
of the type mandated
would like all nodes
the type mandated by
like all nodes to
type mandated by corba
under test in a
this has been mostly
all nodes to upload
has been mostly addressed
nodes to upload data
been mostly addressed by
to upload data at
test in a wide
every technology has its
mostly addressed by community
upload data at a
addressed by community pressure
data at a factor
by community pressure on
at a factor as
technology has its successes
a factor as close
has its successes and
factor as close as
its successes and failures
as close as possible
in a local setting
close as possible to
a local setting of
community pressure on miners
local setting of a
pressure on miners to
setting of a mix
on miners to avoid
of a mix of
miners to avoid forming
a mix of high
to avoid forming large
avoid forming large pools
speed and traditional networks
and traditional networks and
traditional networks and in
networks and in the
and in the internet
these technologies could take
technologies could take the
we varied the maximum
could take the web
varied the maximum upload
take the web services
the maximum upload factor
a first software release
maximum upload factor of
the web services architecture
first software release is
web services architecture to
software release is planned
services architecture to a
release is planned for
architecture to a new
is planned for the
to a new level
however such recommendations had
upload factor of nodes
such recommendations had only
factor of nodes from
recommendations had only had
planned for the autumn
had only had limited
for the autumn of
only had limited success
doing so could greatly
so could greatly enlarge
could greatly enlarge the
and mining is still
greatly enlarge the web
mining is still dominated
enlarge the web services
is still dominated by
the web services market
still dominated by a
dominated by a small
by a small number
a small number of
small number of large
so what s the
number of large pools
what s the bottom
s the bottom line
as a characteristic example
are web services distributed
web services distributed objects
external failure detector modules
the left graph shows
in the period of
left graph shows the
the period of november
graph shows the minimum
of course they are
failure detector modules originate
detector modules originate in
modules originate in asynchronous
originate in asynchronous distributed
in asynchronous distributed systems
average and maximum download
the marketing people are
and maximum download factors
marketing people are listening
maximum download factors across
people are listening to
where they were introduced
are listening to customers
they were introduced to
download factors across the
were introduced to de
factors across the nodes
across the nodes when
the nodes when the
and they want distributed
nodes when the maximum
they want distributed objects
when the maximum upload
couple the mechanism by
the maximum upload factor
the mechanism by which
maximum upload factor of
mechanism by which failures
but vogels is right
upload factor of nodes
by which failures are
factor of nodes is
which failures are detected
of nodes is increased
failures are detected from
are detected from the
detected from the protocols
from the protocols used
three pools generated over
the protocols used to
protocols used to tolerate
used to tolerate those
to tolerate those failures
by increasing the maximum
increasing the maximum upload
the maximum upload factor
maximum upload factor of
upload factor of nodes
of the proofs of
it s time for
we increase the global
the proofs of work
increase the global upload
s time for the
the global upload capacity
time for the web
global upload capacity of
for the web services
upload capacity of the
chandra and toueg successfully
capacity of the system
the web services community
and toueg successfully show
web services community to
toueg successfully show that
services community to come
successfully show that it
community to come to
leading to a better
to come to grips
to a better flow
show that it is
a better flow of
come to grips with
better flow of packets
that it is possible
to grips with the
it is possible to
grips with the needs
is possible to develop
with the needs of
possible to develop consensus
the needs of their
to develop consensus algorithms
needs of their customer
the fact that block
of their customer base
develop consensus algorithms using
fact that block withholding
the discrepancy among the
consensus algorithms using failure
discrepancy among the upload
that block withholding attacks
algorithms using failure detectors
one can justify solutions
among the upload factors
can justify solutions that
block withholding attacks are
justify solutions that make
the upload factors of
withholding attacks are rarely
upload factors of individual
even if these failure
factors of individual nodes
if these failure detectors
of individual nodes also
these failure detectors make
attacks are rarely observed
failure detectors make frequent
individual nodes also increases
are rarely observed may
detectors make frequent mistakes
rarely observed may indicate
make frequent mistakes in
observed may indicate that
frequent mistakes in their
of the customers happy
may indicate that the
as seen in the
the customers happy but
indicate that the active
customers happy but leave
seen in the graph
mistakes in their observations
in the graph to
that the active pools
the graph to the
the active pools have
graph to the right
active pools have reached
pools have reached an
have reached an implicit
reached an implicit or
an implicit or explicit
when the maximum upload
implicit or explicit agreement
the maximum upload factor
or explicit agreement not
maximum upload factor is
explicit agreement not to
upload factor is increased
agreement not to attack
not to attack one
to attack one another
some nodes participate more
a solution that tries
nodes participate more actively
solution that tries to
participate more actively in
that tries to do
more actively in dissemination
tries to do better
actively in dissemination while
an attacked pool cannot
to do better will
attacked pool cannot detect
do better will probably
in dissemination while others
better will probably overreach
pool cannot detect which
dissemination while others end
cannot detect which of
while others end up
detect which of its
others end up contributing
the failure detector work
end up contributing less
which of its miners
but you can t
failure detector work is
of its miners are
detector work is extended
you can t get
even though all of
work is extended to
though all of them
its miners are attacking
all of them are
miners are attacking it
of them are behaving
is extended to systems
can t get there
extended to systems that
them are behaving correctly
to systems that also
t get there if
systems that also take
let alone which pool
get there if you
alone which pool controls
that also take network
which pool controls the
this is an important
pool controls the miners
also take network failure
there if you close
take network failure into
is an important consideration
if you close your
network failure into account
you close your eyes
at some point a
close your eyes to
some point a pool
your eyes to the
point a pool might
eyes to the way
when we introduce auditing
to the way the
a pool might miscalculate
the way the customers
pool might miscalculate and
way the customers are
might miscalculate and decide
the customers are likely
off in designing practical
customers are likely to
we do not want
miscalculate and decide to
are likely to use
and decide to try
likely to use the
decide to try and
to use the technology
to try and increase
do not want to
in designing practical distributed
try and increase its
not want to punish
and increase its revenue
designing practical distributed systems
want to punish nodes
will the web services
practical distributed systems based
to punish nodes that
the web services community
distributed systems based on
web services community have
one pool might be
services community have the
pool might be enough
community have the wisdom
might be enough to
punish nodes that are
be enough to break
have the wisdom to
enough to break the
nodes that are willing
systems based on the
the wisdom to tackle
to break the agreement
that are willing to
based on the theory
wisdom to tackle the
are willing to contribute
to tackle the tough
on the theory developed
tackle the tough issues
possibly leading to a
the tough issues before
the theory developed for
tough issues before circumstances
leading to a constant
issues before circumstances force
theory developed for asynchronous
before circumstances force it
developed for asynchronous systems
circumstances force it upon
to a constant rate
willing to contribute but
a constant rate of
force it upon them
constant rate of attacks
to contribute but cannot
rate of attacks among
for asynchronous systems is
of attacks among pools
contribute but cannot do
attacks among pools and
asynchronous systems is where
among pools and a
but cannot do so
systems is where and
cannot do so because
is where and how
pools and a reduced
where and how to
and a reduced revenue
and how to introduce
do so because of
how to introduce the
a fellow of the
to introduce the notion
fellow of the acm
introduce the notion of
so because of factors
the notion of time
because of factors such
if open pools reach
of factors such as
open pools reach a
factors such as their
pools reach a state
such as their physical
reach a state where
as their physical positioning
traditionally failure detectors have
their physical positioning in
a state where their
physical positioning in the
failure detectors have been
state where their revenue
detectors have been implemented
positioning in the system
have been implemented using
where their revenue density
been implemented using time
their revenue density is
revenue density is reduced
density is reduced due
is reduced due to
reduced due to attacks
in all our future
out mechanisms in the
all our future experiments
mechanisms in the transport
our future experiments we
in the transport layer
future experiments we set
the transport layer that
miners will leave them
transport layer that implements
will leave them in
layer that implements inter
leave them in favor
experiments we set the
them in favor of
we set the maximum
in favor of other
set the maximum upload
favor of other available
the maximum upload factor
of other available options
maximum upload factor to
miners of sufficient size
and has worked on
of sufficient size can
has worked on reliability
sufficient size can mine
outs remain an important
worked on reliability and
remain an important tool
size can mine solo
an important tool in
on reliability and scalability
important tool in the
reliability and scalability issues
tool in the failure
and scalability issues in
in the failure manager
scalability issues in distributed
the failure manager described
issues in distributed systems
failure manager described in
in distributed systems since
manager described in this
smaller miners can form
distributed systems since starting
miners can form private
described in this paper
can form private pools
systems since starting his
form private pools with
since starting his research
private pools with closed
starting his research career
pools with closed access
effect of opportunistic behavior
the mechanism is integrated
of opportunistic behavior our
mechanism is integrated into
opportunistic behavior our next
is integrated into a
limited to trusted participants
behavior our next goal
he is the author
integrated into a more
is the author of
our next goal was
into a more comprehensive
the author of many
next goal was to
a more comprehensive approach
such a change may
author of many articles
a change may be
of many articles on
change may be in
many articles on the
may be in favor
articles on the subject
be in favor of
more comprehensive approach that
in favor of bitcoin
goal was to understand
comprehensive approach that treats
favor of bitcoin as
approach that treats failure
of bitcoin as a
was to understand the
that treats failure detection
bitcoin as a whole
treats failure detection using
to understand the expected
failure detection using methods
understand the expected behavior
detection using methods based
the expected behavior of
using methods based on
since they require such
methods based on an
expected behavior of correct
based on an analogy
they require such intimate
on an analogy with
behavior of correct nodes
an analogy with fault
require such intimate trust
of correct nodes under
correct nodes under different
and applications will be
nodes under different scenarios
applications will be published
under different scenarios where
will be published by
detection techniques used in
different scenarios where opportunistic
techniques used in daily
scenarios where opportunistic nodes
used in daily life
be published by springer
private pools are likely
where opportunistic nodes compromise
pools are likely to
opportunistic nodes compromise the
published by springer verlag
nodes compromise the system
are likely to be
by springer verlag in
likely to be smaller
when trying to contact
springer verlag in fall
trying to contact a
to contact a person
we therefore studied how
and form a fine
contact a person who
form a fine grained
therefore studied how the
a fine grained distribution
studied how the download
a person who has
how the download and
fine grained distribution of
the download and contribution
person who has allegedly
download and contribution rates
grained distribution of mining
who has allegedly disappeared
and contribution rates of
distribution of mining power
has allegedly disappeared one
of mining power with
contribution rates of correct
allegedly disappeared one would
rates of correct nodes
mining power with many
disappeared one would never
power with many small
of correct nodes are
with many small pools
correct nodes are affected
many small pools and
nodes are affected under
one would never be
small pools and solo
would never be satisfied
are affected under these
pools and solo miners
never be satisfied with
affected under these conditions
be satisfied with making
satisfied with making repeated
with making repeated phone
making repeated phone calls
opportunistic nodes may contribute
repeated phone calls to
web services are not
phone calls to the
services are not distributed
nodes may contribute with
are not distributed objects
calls to the same
may contribute with some
to the same location
contribute with some data
the same location for
with some data in
same location for half
some data in an
location for half an
data in an attempt
for half an hour
in an attempt to
half an hour and
an attempt to disguise
an hour and then
attempt to disguise their
hour and then declaring
to disguise their opportunistic
and then declaring the
disguise their opportunistic behavior
then declaring the disappearance
a pool may engage
declaring the disappearance a
pool may engage in
the disappearance a fact
may engage in an
engage in an attack
in an attack against
an attack against another
attack against another pool
no matter whether the
we considered different rates
matter whether the phone
against another pool not
whether the phone was
considered different rates of
the phone was not
another pool not to
phone was not picked
different rates of contribution
was not picked up
pool not to increase
rates of contribution for
not to increase its
of contribution for opportunistic
to increase its absolute
contribution for opportunistic nodes
increase its absolute revenue
a busy tone was
busy tone was heard
tone was heard or
was heard or the
heard or the phone
but rather to attract
or the phone was
rather to attract miners
the phone was disconnected
to attract miners by
attract miners by temporarily
miners by temporarily increasing
by temporarily increasing its
temporarily increasing its revenue
in practice one would
increasing its revenue relative
practice one would work
its revenue relative to
one would work to
revenue relative to a
would work to gain
relative to a competing
work to gain more
to a competing pool
to gain more confidence
gain more confidence in
more confidence in such
confidence in such a
in such a decision
such a decision by
recent work has investigated
a decision by talking
work has investigated the
decision by talking to
has investigated the motivation
by talking to the
investigated the motivation of
talking to the landlord
the motivation of pools
motivation of pools to
of pools to utilize
pools to utilize part
to utilize part of
the neighbors or others
utilize part of their
neighbors or others that
part of their resources
or others that may
of their resources towards
others that may have
their resources towards sabotage
that may have a
resources towards sabotage attacks
may have a more
towards sabotage attacks against
have a more informed
sabotage attacks against each
a more informed idea
attacks against each other
more informed idea about
informed idea about the
idea about the situation
about the situation of
the situation of the
situation of the person
of the person in
the person in question
the failure management described
failure management described in
management described in this
described in this paper
in this paper is
this paper is capable
paper is capable of
is capable of following
capable of following a
of following a similar
following a similar strategy
if a process under
a process under investigation
process under investigation is
presents the average and
under investigation is not
the average and minimum
investigation is not responding
average and minimum download
is not responding it
and minimum download factors
not responding it will
minimum download factors among
responding it will contact
download factors among all
it will contact the
factors among all correct
will contact the operating
the model of those
contact the operating system
among all correct nodes
the operating system under
model of those works
operating system under which
all correct nodes under
system under which the
correct nodes under different
under which the process
nodes under different configurations
which the process is
of those works is
the process is running
those works is different
works is different from
the stream rate was
is different from the
stream rate was fixed
or other nodes on
different from the pool
rate was fixed at
other nodes on the
from the pool game
nodes on the same
the pool game model
on the same sub
pool game model in
game model in two
model in two major
in two major ways
net to help reach
two major ways a
to help reach a
major ways a sabotage
help reach a decision
ways a sabotage attack
reach a decision in
a sabotage attack does
a decision in which
sabotage attack does not
decision in which one
and all correct nodes
in which one can
attack does not transfer
which one can have
all correct nodes had
one can have greater
does not transfer revenue
can have greater confidence
correct nodes had a
not transfer revenue from
nodes had a maximum
transfer revenue from victim
had a maximum upload
revenue from victim to
a maximum upload factor
from victim to attacker
maximum upload factor of
most distributed systems in
and migrating miners switch
distributed systems in use
migrating miners switch to
systems in use today
miners switch to less
in use today deal
switch to less attacked
use today deal with
to less attacked pools
today deal with failure
deal with failure of
with failure of nodes
failure of nodes or
of nodes or networks
nodes or networks in
changing pool sizes and
or networks in some
pool sizes and hence
networks in some way
sizes and hence revenues
and hence revenues until
hence revenues until convergence
in general the problem
the model is parametrized
general the problem is
model is parametrized by
the problem is detected
is parametrized by the
parametrized by the cost
problem is detected in
by the cost of
is detected in the
the cost of the
detected in the communication
cost of the attack
we ran experiments with
of the attack and
in the communication subsystem
the attack and by
attack and by the
the communication subsystem where
and by the mobility
by the mobility of
communication subsystem where session
the mobility of the
mobility of the miners
subsystem where session or
where session or transport
session or transport protocols
or transport protocols are
and the analysis demonstrates
transport protocols are unable
the analysis demonstrates that
protocols are unable to
analysis demonstrates that when
are unable to make
nodes and increasing percentages
unable to make progress
demonstrates that when considering
to make progress because
and increasing percentages of
make progress because of
that when considering only
progress because of the
increasing percentages of opportunistic
because of the lack
when considering only sabotage
of the lack of
percentages of opportunistic nodes
the lack of response
considering only sabotage attacks
lack of response from
of opportunistic nodes in
of response from remote
only sabotage attacks there
response from remote nodes
opportunistic nodes in the
sabotage attacks there are
nodes in the system
attacks there are regions
there are regions where
are regions where no
traditionally packets are being
packets are being retransmitted
are being retransmitted after
being retransmitted after a
attack is the best
retransmitted after a time
is the best strategy
out period and after
the miner s dilemma
period and after a
miner s dilemma is
and after a retry
s dilemma is therefore
after a retry threshold
dilemma is therefore not
a retry threshold is
is therefore not manifested
retry threshold is reached
therefore not manifested in
threshold is reached the
not manifested in that
is reached the remote
manifested in that model
reached the remote destination
optimizing power consumption in
the remote destination is
power consumption in large
remote destination is marked
consumption in large scale
destination is marked as
in large scale storage
is marked as unreachable
pool competition for miners
large scale storage systems
competition for miners is
scale storage systems lakshmi
for miners is an
storage systems lakshmi ganesh
miners is an incentive
we vary the percentage
is an incentive in
vary the percentage of
some systems inject additional
the percentage of opportunistic
an incentive in and
percentage of opportunistic nodes
incentive in and of
systems inject additional packets
in and of its
and of its own
inject additional packets into
of its own for
its own for mutual
additional packets into the
own for mutual attacks
packets into the data
into the data stream
we can observe that
the data stream to
ken birman computer science
can observe that the
birman computer science department
data stream to ensure
observe that the download
and a pool may
stream to ensure timely
that the download factors
a pool may therefore
to ensure timely detection
the download factors of
pool may therefore choose
ensure timely detection of
download factors of correct
may therefore choose to
timely detection of failures
factors of correct nodes
detection of failures at
therefore choose to perform
of failures at moments
of correct nodes decreases
failures at moments when
choose to perform block
at moments when the
correct nodes decreases since
moments when the traffic
to perform block withholding
when the traffic is
nodes decreases since the
perform block withholding even
the traffic is low
decreases since the aggregated
traffic is low or
block withholding even if
is low or unidirectional
since the aggregated upload
withholding even if its
the aggregated upload capacity
even if its revenue
aggregated upload capacity in
if its revenue would
upload capacity in the
its revenue would increase
capacity in the system
revenue would increase only
in the system becomes
would increase only after
increase only after the
only after the next
after the next difficult
the next difficult adjustment
edu abstract data centers
the two models are
abstract data centers are
two models are therefore
data centers are the
models are therefore complimentary
centers are the backend
are the backend for
the backend for a
backend for a large
for a large number
the analysis of their
a large number of
analysis of their combination
large number of services
of their combination is
number of services that
their combination is left
of services that we
combination is left for
services that we take
is left for future
that we take for
left for future work
we take for granted
expect the application to
take for granted today
avg download factor min
the application to handle
download factor min download
application to handle the
factor min download factor
to handle the failure
handle the failure management
a significant fraction of
the failure management as
significant fraction of the
failure management as the
fraction of the total
management as the support
of the total cost
as the support system
the total cost of
the support system does
total cost of ownership
support system does not
cost of ownership of
system does not contain
of ownership of these
does not contain any
ownership of these large
not contain any fault
we assumed in our
contain any fault management
assumed in our analysis
in our analysis that
our analysis that pools
scale storage systems is
analysis that pools do
storage systems is the
often these systems cannot
systems is the cost
these systems cannot distinguish
is the cost of
systems cannot distinguish between
the cost of keeping
cannot distinguish between process
that pools do not
cost of keeping hundreds
pools do not charge
of keeping hundreds of
do not charge fees
keeping hundreds of thousands
not charge fees from
node or network failure
hundreds of thousands of
charge fees from their
of thousands of disks
fees from their members
thousands of disks spinning
from their members since
their members since such
the mechanisms used to
members since such fees
mechanisms used to detect
since such fees are
used to detect failure
such fees are typically
we present a simple
fees are typically nominal
to detect failure do
present a simple idea
detect failure do not
a simple idea that
failure do not adapt
simple idea that allows
do not adapt to
idea that allows the
not adapt to changing
that allows the storage
adapt to changing network
allows the storage system
to changing network conditions
the storage system to
storage system to turn
system to turn off
to turn off a
turn off a large
off a large fraction
a large fraction of
making it almost impossible
large fraction of its
of a pool s
it almost impossible to
a pool s revenue
fraction of its disks
almost impossible to use
impossible to use these
to use these systems
without incurring unacceptable performance
use these systems unmodified
incurring unacceptable performance penalties
these systems unmodified in
systems unmodified in wide
unmodified in wide area
of particular appeal is
in wide area systems
particular appeal is the
wide area systems without
appeal is the fact
area systems without resorting
is the fact that
systems without resorting to
the fact that our
without resorting to heavy
fact that our solution
resorting to heavy weight
the model can be
that our solution is
to heavy weight solutions
our solution is not
model can be extended
solution is not application
can be extended to
heavy weight solutions like
be extended to include
weight solutions like using
extended to include pools
solutions like using a
to include pools fees
like using a tcp
using a tcp connection
a tcp connection as
tcp connection as the
connection as the preferred
fees would add a
as the preferred transport
would add a friction
the preferred transport method
savings for a very
preferred transport method for
for a very generic
transport method for each
a very generic data
method for each rpc
very generic data center
for each rpc call
generic data center model
add a friction element
a friction element to
friction element to the
element to the flow
to the flow of
the flow of revenue
flow of revenue among
of revenue among infiltrated
revenue among infiltrated and
especially those designed to
among infiltrated and infiltrating
we describe our solution
infiltrated and infiltrating pools
those designed to support
designed to support high
identify the parameters that
the parameters that determine
parameters that determine its
that determine its cost
would change to take
management in a more
change to take into
in a more integrated
to take into account
and present a simulator
a more integrated way
present a simulator that
take into account a
a simulator that allows
into account a pool
simulator that allows us
account a pool fee
that allows us to
a pool fee of
allows us to explore
pool fee of f
many of these systems
us to explore this
fee of f pp
to explore this parameter
of f pp ri
explore this parameter space
of these systems are
these systems are structured
systems are structured as
are structured as groups
structured as groups of
we also present some
as groups of cooperating
also present some initial
groups of cooperating processes
present some initial simulation
of cooperating processes using
some initial simulation results
cooperating processes using some
initial simulation results that
processes using some form
simulation results that add
using some form of
results that add weight
some form of group
that add weight to
form of group membership
add weight to our
weight to our claim
to our claim that
our claim that our
claim that our solution
that our solution represents
our solution represents a
solution represents a new
detection to be able
represents a new powersaving
to be able to
a new powersaving opportunity
be able to reach
new powersaving opportunity for
able to reach consensus
powersaving opportunity for large
various methods are used
of which fault monitors
introduction the declining costs
the declining costs of
declining costs of commodity
costs of commodity disk
of commodity disk drives
commodity disk drives has
disk drives has made
drives has made online
has made online data
made online data storage
online data storage a
data storage a way
storage a way of
a way of life
so much so that
much so that companies
so that companies like
that companies like google
companies like google and
like google and yahoo
google and yahoo host
and yahoo host hundreds
yahoo host hundreds of
host hundreds of thousands
hundreds of thousands of
of thousands of servers
thousands of servers for
of servers for storage
there is a catch
are the most popular
a hundred thousand servers
hundred thousand servers consume
thousand servers consume a
servers consume a lot
consume a lot of
a lot of power
however in each of
in each of these
each of these systems
a pool with a
not only does this
of these systems the
pool with a fee
only does this translate
with a fee of
these systems the failure
a fee of f
does this translate to
systems the failure management
fee of f is
this translate to many
of f is a
the failure management is
f is a less
translate to many millions
failure management is an
is a less attractive
to many millions of
a less attractive target
many millions of dollars
less attractive target for
millions of dollars annually
attractive target for block
management is an integral
target for block withholding
is an integral part
of dollars annually on
an integral part of
dollars annually on electricity
integral part of the
annually on electricity bills
since the attacker s
part of the particular
the attacker s revenue
of the particular membership
attacker s revenue is
the particular membership or
s revenue is reduced
the heat produced by
particular membership or transport
heat produced by so
revenue is reduced by
produced by so much
is reduced by f
by so much computing
membership or transport system
so much computing power
or transport system and
much computing power can
transport system and not
computing power can be
system and not available
power can be searing
and not available for
however it is also
not available for general
it is also less
available for general use
is also less attractive
also less attractive for
an article in the
less attractive for miners
article in the new
attractive for miners in
in the new york
for miners in general
the new york times
although some research groups
new york times describes
york times describes one
times describes one of
describes one of google
trading off the two
one of google s
off the two for
of google s data
the two for best
google s data centers
two for best protection
for best protection is
best protection is left
protection is left for
is left for future
left for future work
as part of the
part of the treatment
of the treatment of
the treatment of the
treatment of the miner
a computing center as
computing center as big
center as big as
as big as two
big as two football
as two football fields
with twin cooling plants
twin cooling plants protruding
cooling plants protruding four
r elated w ork
plants protruding four stories
elated w ork a
protruding four stories into
are focusing on wide
four stories into the
focusing on wide area
stories into the sky
on wide area systems
the block withholding attack
block withholding attack the
of opportunistic nodes figure
withholding attack the danger
the majority of the
attack the danger of
majority of the existing
the danger of a
of the existing failure
danger of a block
the existing failure detectors
of a block withholding
existing failure detectors are
a block withholding attack
failure detectors are not
block withholding attack is
detectors are not suitable
withholding attack is as
are not suitable for
attack is as old
minimum and average download
is as old as
not suitable for use
as old as bitcoin
suitable for use in
old as bitcoin pools
and average download factors
power conservation is an
for use in large
average download factors across
conservation is an important
download factors across all
is an important concern
factors across all correct
an important concern for
across all correct nodes
important concern for big
all correct nodes when
concern for big server
the attack was described
use in large scale
attack was described by
in large scale systems
was described by rosenfeld
for big server clusters
correct nodes when opportunistic
nodes when opportunistic nodes
when opportunistic nodes are
opportunistic nodes are present
because of their inflexibility
of their inflexibility or
since disks account for
their inflexibility or the
disks account for a
inflexibility or the simplicity
account for a significant
or the simplicity of
for a significant fraction
the simplicity of their
each curve corresponds to
simplicity of their assumptions
a significant fraction of
curve corresponds to a
significant fraction of the
corresponds to a different
fraction of the energy
to a different contribution
of the energy consumed
a different contribution rate
different contribution rate used
contribution rate used by
rate used by opportunistic
used by opportunistic nodes
building a failure detector
a failure detector that
failure detector that is
detector that is not
that is not an
several approaches for disk
is not an integral
as pools were becoming
approaches for disk power
pools were becoming a
for disk power management
not an integral part
disk power management have
were becoming a dominant
power management have been
an integral part of
management have been proposed
becoming a dominant player
have been proposed and
integral part of the
been proposed and studied
a dominant player in
dominant player in the
part of the communication
player in the bitcoin
in the bitcoin world
of the communication architecture
we will examine some
will examine some of
the communication architecture permits
examine some of these
some of these here
the paper described the
communication architecture permits the
paper described the standard
described the standard attack
architecture permits the implementation
but first let us
permits the implementation of
first let us lay
let us lay out
the implementation of a
us lay out some
used by a miner
lay out some of
implementation of a collection
out some of the
by a miner to
some of the groundwork
of a collection of
a miner to sabotage
miner to sabotage a
a collection of failure
to sabotage a pool
sabotage a pool at
collection of failure detection
a pool at the
any disk power management
pool at the cost
of failure detection techniques
at the cost of
disk power management scheme
the cost of reducing
failure detection techniques and
cost of reducing its
power management scheme essentially
detection techniques and support
of reducing its own
management scheme essentially attempts
reducing its own revenue
scheme essentially attempts to
techniques and support for
essentially attempts to exploit
attempts to exploit one
and support for failure
to exploit one fact
support for failure detection
a more general view
for failure detection methods
more general view of
failure detection methods of
disks can be run
general view of fairness
can be run in
detection methods of varying
be run in highpower
view of fairness in
run in highpower mode
of fairness in proof
methods of varying levels
fairness in proof of
of varying levels of
in proof of work
varying levels of complexity
proof of work schemes
levels of complexity from
of work schemes was
of complexity from which
work schemes was discussed
complexity from which the
schemes was discussed in
from which the system
which the system designer
the system designer can
with a corresponding performance
system designer can choose
a corresponding performance tradeoff
designer can choose to
can choose to match
choose to match the
to match the system
match the system requirements
avg upload factor min
upload factor min upload
factor min upload factor
a disk can be
the failure management service
disk can be shut
failure management service consists
can be shut off
management service consists of
be shut off so
service consists of three
shut off so that
consists of three functional
off so that it
of three functional modules
so that it consumes
that it consumes no
it consumes no power
given a large cluster
a large cluster of
large cluster of disks
in the context of
the context of the
context of the hashcash
of the hashcash system
only a fraction of
a fraction of them
fraction of them is
of them is accessed
them is accessed at
is accessed at any
accessed at any time
so that the rest
that the rest could
the rest could potentially
rest could potentially be
a library that implements
could potentially be switched
library that implements simple
potentially be switched to
that implements simple failure
be switched to a
implements simple failure management
switched to a low
early work did not
simple failure management functionality
work did not address
failure management functionality and
did not address the
management functionality and provide
not address the possibility
functionality and provide the
address the possibility of
and provide the api
the possibility of pools
provide the api to
possibility of pools infiltrating
the api to the
of pools infiltrating other
api to the complete
pools infiltrating other pools
since mode transitions consume
to the complete service
mode transitions consume time
infiltrating other pools for
transitions consume time and
other pools for block
consume time and power
pools for block withholding
a service implementing per
service implementing per node
implementing per node failure
per node failure management
disk management schemes have
management schemes have to
schemes have to walk
have to walk the
combining fault management with
to walk the tightrope
fault management with other
walk the tightrope of
management with other local
the tightrope of finding
with other local nodes
tightrope of finding the
other local nodes to
of finding the right
local nodes to exploit
finding the right balance
nodes to exploit locality
the right balance between
to exploit locality of
right balance between power
exploit locality of communication
balance between power consumption
locality of communication and
between power consumption and
of communication and failure
power consumption and performance
communication and failure patterns
experimentally demonstrate that block
an inquiry service closely
the solution space explored
inquiry service closely coupled
demonstrate that block withholding
service closely coupled with
solution space explored thus
closely coupled with the
that block withholding can
coupled with the operating
space explored thus far
with the operating system
block withholding can increase
the operating system which
explored thus far in
withholding can increase the
thus far in the
can increase the attacker
far in the literature
increase the attacker s
in the literature can
the attacker s revenue
the literature can be
literature can be divided
can be divided as
be divided as follows
provides information about the
information about the state
they do not address
about the state of
do not address the
the state of local
not address the question
state of local participating
address the question of
of local participating processes
the question of mutual
question of mutual attacks
the most fundamental operation
most fundamental operation offered
fundamental operation offered by
operation offered by a
offered by a failure
by a failure detection
a failure detection service
failure detection service is
detection service is that
service is that of
is that of the
have recently noted that
that of the investigation
recently noted that a
of the investigation of
noted that a pool
the investigation of a
that a pool can
investigation of a suspected
a pool can increase
of a suspected process
pool can increase its
can increase its overall
increase its overall revenue
its overall revenue with
overall revenue with block
to make use of
revenue with block withholding
make use of this
with block withholding if
use of this operation
block withholding if all
of this operation it
withholding if all other
this operation it is
if all other mining
operation it is not
all other mining is
it is not necessary
other mining is performed
is not necessary for
mining is performed by
each of these solutions
is performed by honest
not necessary for either
performed by honest pools
of these solutions proposes
necessary for either the
these solutions proposes a
for either the local
solutions proposes a new
either the local or
proposes a new system
the local or remote
we consider the general
a new system of
local or remote process
new system of some
consider the general case
or remote process to
the general case where
remote process to run
general case where not
process to run any
system of some kind
to run any of
case where not all
run any of the
where not all mining
any of the heartbeat
not all mining is
of the heartbeat or
all mining is performed
the heartbeat or polling
mining is performed through
heartbeat or polling patterns
is performed through public
performed through public pools
based solutions propose novel
solutions propose novel storage
propose novel storage hierarchies
the reasons that the
and analyze situations where
novel storage hierarchies to
analyze situations where pools
reasons that the local
situations where pools can
storage hierarchies to strike
where pools can attack
that the local process
hierarchies to strike the
pools can attack one
to strike the right
can attack one another
the local process began
strike the right balance
local process began to
the right balance between
process began to suspect
right balance between performance
began to suspect the
balance between performance and
the discrepancy between the
between performance and power
to suspect the remote
performance and power consumption
discrepancy between the calculations
suspect the remote process
between the calculations of
the remote process are
remote process are not
process are not of
are not of any
disk management solutions interject
not of any importance
management solutions interject a
of any importance to
solutions interject a new
any importance to the
interject a new disk
importance to the failure
a new disk management
to the failure management
new disk management layer
disk management layer on
management layer on top
layer on top of
on top of the
top of the file
of the file system
and our results for
our results for the
results for the special
for the special case
which controls disk configuration
the special case analyzed
controls disk configuration and
special case analyzed there
disk configuration and data
case analyzed there can
configuration and data layout
analyzed there can be
and data layout to
there can be explained
data layout to achieve
can be explained by
layout to achieve power
be explained by the
explained by the strong
by the strong approximations
the strong approximations in
strong approximations in that
optimal disk access patterns
approximations in that work
caching solutions devise new
solutions devise new power
the process at address
we calculate exactly how
process at address is
calculate exactly how infiltrating
at address is investigated
aware caching algorithms that
exactly how infiltrating miners
address is investigated and
caching algorithms that allow
how infiltrating miners reduce
is investigated and a
infiltrating miners reduce the
algorithms that allow large
miners reduce the revenue
investigated and a report
reduce the revenue density
that allow large fractions
the revenue density of
and a report is
revenue density of the
allow large fractions of
density of the infiltrated
a report is returned
of the infiltrated pool
large fractions of the
report is returned within
fractions of the storage
is returned within the
of the storage system
returned within the deadline
the storage system to
within the deadline set
storage system to remain
the deadline set by
system to remain idle
deadline set by the
to remain idle for
set by the local
remain idle for longer
temporary block withholding in
by the local process
idle for longer periods
block withholding in the
for longer periods of
withholding in the block
longer periods of time
in the block withholding
the block withholding attack
the local process does
block withholding attack discussed
withholding attack discussed in
local process does not
attack discussed in this
allowing them to be
process does not have
them to be switched
discussed in this work
does not have to
in this work the
to be switched to
this work the withheld
be switched to lower
work the withheld blocks
switched to lower power
of opportunistic nodes figure
the withheld blocks are
not have to wait
withheld blocks are never
to lower power modes
have to wait for
blocks are never published
to wait for the
wait for the investigation
for the investigation to
the principal contribution of
minimum and average upload
the investigation to finish
principal contribution of this
investigation to finish but
contribution of this paper
blocks can be withheld
and average upload factors
can be withheld temporarily
of this paper is
to finish but can
this paper is to
average upload factors across
paper is to argue
finish but can make
is to argue that
upload factors across all
to argue that there
but can make use
not following the bitcoin
factors across all correct
argue that there is
across all correct nodes
that there is a
all correct nodes when
there is a fourth
correct nodes when opportunistic
is a fourth niche
nodes when opportunistic nodes
a fourth niche as
when opportunistic nodes are
fourth niche as yet
opportunistic nodes are present
niche as yet unexplored
can make use of
following the bitcoin protocol
make use of the
use of the asynch
of the asynch interface
each curve corresponds to
the asynch interface to
to improve an attacker
asynch interface to collect
improve an attacker s
curve corresponds to a
interface to collect the
corresponds to a different
to collect the result
to a different contribution
collect the result at
an attacker s revenue
a different contribution rate
the result at a
different contribution rate used
result at a later
contribution rate used by
at a later moment
rate used by opportunistic
used by opportunistic nodes
a miner or a
miner or a pool
we do not present
or a pool can
do not present a
a pool can perform
the report contains information
insufficient to provide all
pool can perform a
to provide all nodes
can perform a selfish
provide all nodes with
perform a selfish mining
all nodes with all
a selfish mining attack
not present a new
report contains information on
nodes with all data
present a new system
contains information on whether
information on whether the
on whether the remote
whether the remote node
the remote node was
remote node was reachable
the extent of the
we take an idea
extent of the impact
node was reachable within
of the impact may
take an idea that
the impact may be
an idea that has
impact may be surprising
was reachable within the
idea that has been
reachable within the deadline
that has been around
with selfish mining the
has been around for
within the deadline and
been around for well
selfish mining the attacker
around for well over
the deadline and whether
mining the attacker increases
for well over a
deadline and whether the
the attacker increases its
well over a decade
and whether the process
over a decade now
attacker increases its revenue
whether the process under
increases its revenue by
the process under investigation
its revenue by temporarily
process under investigation was
revenue by temporarily withholding
under investigation was still
by temporarily withholding its
investigation was still present
performance drops by as
was still present at
drops by as much
temporarily withholding its blocks
still present at the
withholding its blocks and
by as much as
its blocks and publishing
present at the host
blocks and publishing them
and publishing them in
publishing them in response
them in response to
in response to block
if the mode parameter
response to block publication
the mode parameter was
to block publication by
mode parameter was used
block publication by other
parameter was used to
publication by other pools
was used to request
by other pools and
used to request a
other pools and miners
to request a more
request a more detailed
a more detailed remote
and argue that technological
more detailed remote reporting
argue that technological evolution
that technological evolution has
presents the average and
technological evolution has given
the average and minimum
evolution has given it
average and minimum upload
process checkpoint information is
has given it a
this attack is independent
given it a new
checkpoint information is returned
and minimum upload factors
information is returned or
minimum upload factors among
attack is independent of
upload factors among all
is returned or the
factors among all correct
is independent of the
it a new relevance
independent of the block
a new relevance today
returned or the remote
new relevance today as
of the block withholding
relevance today as a
or the remote process
the block withholding attack
among all correct nodes
the remote process is
block withholding attack we
today as a natural
withholding attack we discuss
as a natural power
remote process is interrupted
attack we discuss here
process is interrupted to
we discuss here and
is interrupted to provide
discuss here and the
interrupted to provide status
here and the two
to provide status information
and the two can
saving opportunity for large
the two can be
two can be performed
can be performed in
be performed in concert
axis we vary the
see the section on
we vary the percentage
the section on os
vary the percentage of
section on os integration
the percentage of opportunistic
percentage of opportunistic nodes
an attacker can also
the key insight is
attacker can also perform
key insight is that
can also perform a
also perform a double
and on the y
perform a double spending
a double spending attack
double spending attack as
if the node was
spending attack as follows
the node was not
where other solutions attempt
node was not reachable
axis we present the
was not reachable and
we present the upload
other solutions attempt to
present the upload factors
not reachable and the
the upload factors of
solutions attempt to predict
reachable and the local
attempt to predict disk
upload factors of nodes
and the local process
to predict disk access
the local process has
predict disk access to
local process has requested
disk access to determine
process has requested extensive
access to determine which
has requested extensive investigation
which can vary up
to determine which disks
can vary up to
determine which disks to
he intentionally generates two
which disks to power
intentionally generates two conflicting
disks to power down
generates two conflicting transactions
the failure investigator will
failure investigator will try
investigator will try to
will try to contact
try to contact a
places one in a
to contact a failure
one in a block
the lfs automatically provides
contact a failure manager
lfs automatically provides a
a failure manager at
automatically provides a perfect
failure manager at the
in a block it
manager at the node
provides a perfect prediction
a block it withholds
a perfect prediction mechanism
it is interesting to
is interesting to note
interesting to note that
to note that the
and publishes the other
note that the average
publishes the other transaction
simply by virtue of
that the average upload
by virtue of the
the average upload factor
virtue of the fact
net or within its
of the fact that
average upload factor among
or within its administrative
the fact that all
after the recipient sees
fact that all write
within its administrative domain
upload factor among correct
the recipient sees the
factor among correct nodes
its administrative domain which
among correct nodes initially
recipient sees the published
correct nodes initially increases
sees the published transaction
administrative domain which should
accesses go to the
domain which should be
go to the log
which should be able
to the log head
should be able to
and then starts falling
be able to give
then starts falling when
able to give a
the attacker publishes the
to give a more
starts falling when the
give a more conclusive
attacker publishes the withheld
a more conclusive answer
falling when the percentage
more conclusive answer about
publishes the withheld block
conclusive answer about the
explains and expands on
when the percentage of
and expands on this
answer about the node
the withheld block to
the percentage of opportunistic
withheld block to revoke
percentage of opportunistic nodes
block to revoke the
expands on this idea
to revoke the former
of opportunistic nodes increases
s failure to respond
opportunistic nodes increases significantly
revoke the former transaction
if network failure is
this behavior can be
this attack is performed
behavior can be explained
network failure is the
can be explained by
attack is performed by
failure is the cause
be explained by the
is the cause of
explained by the fact
the cause of the
is performed by miners
cause of the loss
by the fact that
of the loss of
performed by miners or
idea overview to see
by miners or pools
the loss of connectivity
miners or pools against
overview to see why
or pools against service
to see why lfs
pools against service providers
see why lfs is
against service providers that
why lfs is a
service providers that accept
lfs is a natural
the report will indicate
is a natural solution
providers that accept bitcoin
a natural solution to
report will indicate which
natural solution to the
correct nodes start contributing
solution to the problem
will indicate which part
to the problem of
indicate which part of
nodes start contributing more
and it not directly
start contributing more to
it not directly related
the problem of disk
not directly related to
contributing more to compensate
directly related to this
problem of disk power
which part of the
of disk power management
related to this work
part of the path
more to compensate for
of the path is
to compensate for the
the path is reachable
compensate for the lack
path is reachable and
for the lack of
is reachable and where
consider some of the
reachable and where the
some of the challenges
and where the suspected
of the challenges involved
the lack of data
block withholding defense most
lack of data provided
withholding defense most crypto
of data provided by
data provided by a
provided by a small
by a small percentage
a small percentage of
currencies use a proof
small percentage of opportunistic
percentage of opportunistic nodes
server systems typically are
systems typically are not
typically are not idle
if the failure investigator
are not idle long
the failure investigator is
not idle long enough
failure investigator is configured
idle long enough to
investigator is configured with
long enough to make
is configured with alternative
enough to make it
work architecture similar to
to make it worthwhile
architecture similar to bitcoin
make it worthwhile to
configured with alternative outgoing
it worthwhile to incur
once the effect of
worthwhile to incur the
with alternative outgoing paths
the effect of opportunistic
to incur the time
effect of opportunistic nodes
where finding proof of
of opportunistic nodes becomes
finding proof of work
opportunistic nodes becomes significant
proof of work is
these paths are probed
of work is the
power expense of switching
work is the result
paths are probed to
is the result of
expense of switching the
the result of solution
are probed to see
result of solution guessing
of switching the disk
probed to see if
switching the disk to
the system collapses and
of solution guessing and
system collapses and correct
solution guessing and checking
collapses and correct nodes
the disk to a
and correct nodes are
disk to a lowpower
correct nodes are not
to a lowpower mode
to see if it
nodes are not able
see if it is
all of the algorithms
are not able to
if it is possible
of the algorithms we
and switching it back
the algorithms we are
it is possible to
algorithms we are aware
switching it back when
we are aware of
is possible to circumvent
are aware of are
it back when it
aware of are susceptible
back when it is
of are susceptible to
when it is accessed
not able to keep
possible to circumvent the
are susceptible to the
able to keep contributing
susceptible to the block
to circumvent the network
to the block withholding
this is a notable
circumvent the network failure
the block withholding attack
the network failure and
is a notable point
network failure and in
another important point to
failure and in such
a notable point of
important point to note
as in all of
point to note is
in all of them
to note is that
and in such a
note is that the
in such a way
is that the minimum
all of them the
that the minimum upload
such a way collect
the minimum upload factor
a way collect information
minimum upload factor does
way collect information about
upload factor does not
collect information about the
notable point of difference
information about the remote
factor does not follow
of them the miner
does not follow a
about the remote process
not follow a clearly
them the miner can
follow a clearly defined
point of difference between
a clearly defined pattern
the miner can check
of difference between server
miner can check whether
difference between server systems
can check whether she
between server systems and
check whether she found
server systems and typical
making it hard to
systems and typical mobile
the report contains information
and typical mobile device
it hard to estimate
typical mobile device scenarios
report contains information about
whether she found a
contains information about the
she found a full
information about the results
found a full or
about the results of
a full or a
the results of these
full or a partial
results of these probes
hard to estimate the
or a partial proof
to estimate the minimum
a partial proof of
estimate the minimum contribution
partial proof of work
the minimum contribution of
early triggers many systems
minimum contribution of correct
which makes it hard
contribution of correct nodes
triggers many systems find
of correct nodes under
makes it hard to
correct nodes under compromised
many systems find it
nodes under compromised scenarios
it hard to translate
systems find it desirable
prominent examples are litecoin
hard to translate the
find it desirable to
to translate the solutions
it desirable to detect
translate the solutions devised
desirable to detect failure
the solutions devised for
to detect failure of
solutions devised for mobile
by applying thresholds to
devised for mobile devices
detect failure of remote
for mobile devices to
applying thresholds to punish
mobile devices to server
failure of remote processes
devices to server systems
thresholds to punish opportunistic
of remote processes even
to punish opportunistic nodes
remote processes even if
processes even if there
even if there is
as we shall see
if there is no
there is no data
correct nodes may also
is no data exchange
nodes may also be
no data exchange actually
may also be unfairly
data exchange actually under
also be unfairly penalized
exchange actually under way
access to a small
to a small subset
a small subset of
small subset of disks
systems are free to
are free to implement
free to implement whatever
to implement whatever scheme
implement whatever scheme they
auditing protocol our idea
whatever scheme they find
protocol our idea for
when combined with a
scheme they find appropriate
our idea for auditing
they find appropriate and
idea for auditing the
combined with a cache
for auditing the described
it is possible to
auditing the described live
with a cache that
is possible to use
a cache that absorbs
find appropriate and use
possible to use an
cache that absorbs read
appropriate and use the
to use an alternative
streaming system against opportunistic
and use the failure
use an alternative proof
system against opportunistic behavior
use the failure investigator
an alternative proof of
the failure investigator from
against opportunistic behavior is
failure investigator from the
alternative proof of work
opportunistic behavior is motivated
investigator from the previous
behavior is motivated by
from the previous section
is motivated by the
the previous section to
motivated by the graphs
previous section to handle
by the graphs presented
section to handle the
proof of work mechanism
results in long disk
the graphs presented in
to handle the suspicions
graphs presented in the
in long disk idle
of work mechanism in
presented in the previous
long disk idle periods
in the previous section
work mechanism in which
or they can make
mechanism in which miners
they can make use
in which miners would
can make use of
low predictability of idle
make use of two
which miners would not
use of two standardized
miners would not be
predictability of idle periods
would not be able
of two standardized schemes
not be able to
we propose to employ
be able to distinguish
two standardized schemes implemented
able to distinguish partial
propose to employ auditing
to distinguish partial from
standardized schemes implemented by
distinguish partial from full
to employ auditing to
schemes implemented by the
partial from full proofs
implemented by the failure
employ auditing to ensure
by the failure manager
from full proofs of
auditing to ensure that
full proofs of work
the failure manager library
to ensure that all
ensure that all nodes
that all nodes in
have shown that there
all nodes in the
shown that there exists
the first scheme uses
nodes in the system
first scheme uses a
that there exists low
in the system contribute
scheme uses a heartbeat
the system contribute more
uses a heartbeat mechanism
there exists low correlation
system contribute more than
exists low correlation between
contribute more than a
low correlation between a
more than a particular
which sends out i
correlation between a given
than a particular specified
between a given idle
a particular specified threshold
a given idle period
given idle period s
idle period s duration
period s duration and
s duration and the
duration and the duration
alive messages to a
and the duration of
messages to a group
the duration of previous
to a group of
duration of previous idle
a group of processes
of previous idle periods
group of processes using
we illustrate the potential
of processes using multiple
illustrate the potential benefit
processes using multiple point
the potential benefit from
potential benefit from using
this variability makes it
benefit from using auditing
variability makes it difficult
from using auditing in
makes it difficult to
using auditing in a
it difficult to devise
auditing in a system
difficult to devise effective
in a system where
to devise effective predictive
point messages or a
devise effective predictive mechanisms
messages or a single
effective predictive mechanisms for
or a single ip
predictive mechanisms for disk
mechanisms for disk idle
for disk idle times
the lfs neatly circumvents
lfs neatly circumvents this
of the nodes are
such a solution could
the nodes are correct
neatly circumvents this problem
nodes are correct and
a solution could reduce
each process keeps track
solution could reduce or
circumvents this problem by
process keeps track of
this problem by predetermining
could reduce or remove
problem by predetermining which
reduce or remove the
by predetermining which disk
or remove the danger
keeps track of the
remove the danger of
predetermining which disk is
the danger of block
which disk is written
danger of block withholding
track of the reception
disk is written to
of the reception times
is written to at
the reception times of
written to at all
the latter do not
to at all times
latter do not upload
reception times of messages
do not upload any
not upload any data
making such a change
times of messages and
such a change may
of messages and if
a change may not
messages and if a
change may not be
and if a number
may not be in
if a number of
server systems are often
not be in the
a number of consecutive
be in the interest
systems are often constrained
in the interest of
number of consecutive heartbeats
the interest of the
are often constrained by
interest of the community
of consecutive heartbeats from
often constrained by service
consecutive heartbeats from a
constrained by service level
heartbeats from a destination
by service level agreements
from a destination is
service level agreements to
a destination is missed
level agreements to guarantee
destination is missed a
agreements to guarantee a
is missed a suspicion
to guarantee a certain
missed a suspicion is
guarantee a certain level
no punishment was applied
a certain level of
a suspicion is raised
certain level of performance
punishment was applied in
or even its potential
was applied in an
applied in an attempt
in an attempt to
an attempt to simulate
so that finding a
could lead to a
attempt to simulate a
that finding a solution
to simulate a system
lead to a reduction
finding a solution that
to a reduction of
simulate a system with
a solution that provides
a system with no
a reduction of pool
fixed period or an
solution that provides acceptable
system with no auditing
that provides acceptable performance
period or an exponential
provides acceptable performance to
or an exponential back
reduction of pool sizes
acceptable performance to only
performance to only a
to only a fraction
only a fraction of
a fraction of the
as explained in section
fraction of the incoming
explained in section ix
of the incoming requests
albeit a large fraction
fixed or estimated by
or estimated by the
estimated by the system
may often not be
often not be sufficient
decentralized pools although most
auditing is enabled and
pools although most pools
is enabled and opportunistic
although most pools use
enabled and opportunistic nodes
most pools use a
as we shall show
pools use a centralized
and multiple suspicion levels
and opportunistic nodes start
multiple suspicion levels are
use a centralized manager
suspicion levels are configurable
opportunistic nodes start to
levels are configurable by
the lfs provides an
are configurable by the
nodes start to be
configurable by the application
lfs provides an applicationindependent
a prominent exception is
start to be expelled
prominent exception is p
to be expelled from
provides an applicationindependent solution
be expelled from the
an applicationindependent solution that
expelled from the system
the application can provide
from the system for
pool a distributed pool
application can provide application
applicationindependent solution that allows
can provide application specific
a distributed pool architecture
provide application specific data
distributed pool architecture with
application specific data to
pool architecture with no
specific data to be
solution that allows the
the system for low
that allows the system
system for low contribution
architecture with no central
data to be piggybacked
with no central manager
to be piggybacked on
allows the system to
be piggybacked on the
the system to perform
piggybacked on the heartbeats
system to perform consistently
to perform consistently across
perform consistently across a
consistently across a wide
the minimum upload factor
across a wide range
minimum upload factor for
a wide range of
upload factor for nodes
wide range of datasets
the second scheme uses
factor for nodes to
second scheme uses a
for nodes to stay
scheme uses a polling
nodes to stay in
uses a polling method
to stay in the
a polling method to
stay in the system
the law of large
in the system was
law of large numbers
the system was set
polling method to collect
but the question of
system was set to
method to collect acknowledgments
the question of whether
to collect acknowledgments from
question of whether a
large scale server systems
collect acknowledgments from the
scale server systems process
acknowledgments from the peer
server systems process incredibly
of whether a pool
systems process incredibly large
from the peer processes
process incredibly large request
whether a pool is
incredibly large request loads
a pool is run
pool is run by
if no acknowledgments are
is run by a
no acknowledgments are received
run by a centralized
directing these to a
acknowledgments are received after
by a centralized manager
are received after a
these to a small
a centralized manager or
received after a number
centralized manager or with
after a number of
to a small fraction
a number of retries
manager or with a
number of retries a
a small fraction of
of retries a suspicion
or with a decentralized
retries a suspicion is
small fraction of the
a suspicion is raised
with a decentralized architecture
fraction of the total
a decentralized architecture is
of the total number
decentralized architecture is almost
the total number of
architecture is almost immaterial
total number of disks
is almost immaterial for
almost immaterial for the
immaterial for the attack
for the attack we
the attack we describe
the fraction that is
fraction that is in
that is in high
and retransmission limits are
retransmission limits are configurable
pool group can be
limits are configurable by
group can be infiltrated
are configurable by the
can significantly raise the
can be infiltrated and
significantly raise the probability
be infiltrated and attacked
raise the probability of
configurable by the application
the probability of error
by the application or
probability of error and
the application or can
of error and failure
application or can be
or can be adapted
can be adapted by
be adapted by the
pool code can be
adapted by the failure
code can be changed
the fact that the
can be changed to
without auditing with auditing
by the failure manager
fact that the disks
the failure manager to
be changed to support
failure manager to the
that the disks used
manager to the network
changed to support attacks
the disks used in
to support attacks against
disks used in these
support attacks against other
used in these contexts
attacks against other pools
in these contexts are
instrumenting the operating system
these contexts are typically
contexts are typically low
on the other hand
to achieve greater failure
achieve greater failure detection
end with relatively weak
greater failure detection accuracy
with relatively weak reliability
relatively weak reliability guarantees
it is necessary to
pool can be used
is necessary to instrument
can be used by
necessary to instrument the
be used by groups
to instrument the operating
used by groups of
as we shall see
by groups of miners
instrument the operating environment
groups of miners to
the operating environment with
of miners to easily
operating environment with support
miners to easily form
environment with support for
our solution alleviates this
with support for process
solution alleviates this problem
to easily form closed
alleviates this problem by
support for process investigation
easily form closed pools
this problem by making
problem by making sure
by making sure that
making sure that the
sure that the live
it has always been
that the live subset
these do not accept
the live subset of
do not accept untrusted
live subset of disks
not accept untrusted miners
subset of disks is
has always been argued
of disks is not
disks is not constant
always been argued that
been argued that in
and are therefore protected
argued that in a
are therefore protected against
that in a distributed
the rest of this
therefore protected against block
rest of this paper
in a distributed system
of this paper is
protected against block withholding
this paper is organized
a distributed system it
paper is organized as
distributed system it is
is organized as follows
system it is impossible
it is impossible to
download factor of correct
is impossible to distinguish
factor of correct nodes
impossible to distinguish a
of correct nodes during
to distinguish a crashed
correct nodes during a
c onclusion we explored
distinguish a crashed process
a crashed process from
onclusion we explored a
crashed process from one
describes some of the
we explored a block
process from one that
some of the solutions
from one that is
explored a block withholding
one that is slow
of the solutions explored
a block withholding attack
the solutions explored in
block withholding attack among
solutions explored in the
second streaming session with
withholding attack among bitcoin
explored in the first
attack among bitcoin mining
in the first three
among bitcoin mining pools
the first three quadrants
bitcoin mining pools an
first three quadrants mentioned
mining pools an attack
three quadrants mentioned above
pools an attack that
an attack that is
attack that is possible
but with the proper
that is possible in
with the proper system
is possible in any
the proper system support
possible in any similar
proper system support this
in any similar system
auditing is enabled in
presents and analyzes our
any similar system that
and analyzes our solution
similar system that rewards
system support this is
system that rewards for
support this is no
that rewards for proof
is enabled in the
this is no longer
rewards for proof of
is no longer true
enabled in the last
for proof of work
discusses our evaluation methodology
our evaluation methodology and
if the node is
evaluation methodology and results
the node is reachable
such systems are gaining
node is reachable and
systems are gaining popularity
is reachable and operating
reachable and operating correctly
we conclude in section
running most digital currencies
most digital currencies and
the operating system can
digital currencies and related
operating system can determine
we present the minimum
currencies and related services
system can determine whether
can determine whether or
determine whether or not
whether or not the
or not the process
we observe that no
not the process has
average and maximum download
the process has crashed
and maximum download factors
maximum download factors across
download factors across correct
based solutions the concept
factors across correct nodes
solutions the concept of
across correct nodes varying
the failure management integrated
correct nodes varying along
attacks is not a
failure management integrated into
is not a nash
the concept of a
not a nash equilibrium
management integrated into the
concept of a memory
integrated into the os
of a memory hierarchy
into the os offers
a memory hierarchy arose
the os offers processes
memory hierarchy arose as
if none of the
os offers processes a
none of the other
hierarchy arose as a
of the other pools
offers processes a mechanism
the other pools attack
arose as a result
processes a mechanism to
as a result of
a mechanism to register
a result of the
mechanism to register and
as observed in this
to register and request
observed in this particular
register and request a
in this particular example
and request a certain
result of the natural
request a certain level
a pool can increase
of the natural tradeoff
pool can increase its
a certain level of
can increase its revenue
certain level of service
increase its revenue by
auditing has the potential
its revenue by attacking
the natural tradeoff between
revenue by attacking the
has the potential to
by attacking the others
natural tradeoff between memory
the potential to improve
tradeoff between memory speed
potential to improve the
between memory speed and
to improve the quality
memory speed and memory
improve the quality of
when two pools can
speed and memory cost
two pools can attack
the quality of streamed
pools can attack each
quality of streamed sessions
is a simple binary
of streamed sessions significantly
can attack each other
a simple binary test
simple binary test performed
binary test performed by
test performed by the
and at low cost
performed by the os
they face a version
by the os upon
face a version of
the os upon receipt
a version of the
os upon receipt of
version of the prisoner
upon receipt of an
of the prisoner s
one important concern is
the prisoner s dilemma
receipt of an inquiry
important concern is that
concern is that if
is that if the
that if the specified
if one pool chooses
if the specified threshold
one pool chooses to
the specified threshold is
pool chooses to attack
specified threshold is too
indicating whether the process
threshold is too high
that there exists a
whether the process is
there exists a similar
the process is still
the victim s revenue
exists a similar tradeoff
victim s revenue is
process is still present
s revenue is reduced
more opportunistic nodes may
a similar tradeoff between
opportunistic nodes may be
is still present in
nodes may be caught
similar tradeoff between performance
still present in the
tradeoff between performance and
present in the process
between performance and power
and it can retaliate
in the process table
it can retaliate by
the process table and
can retaliate by attacking
but correct nodes may
process table and thus
retaliate by attacking and
correct nodes may also
by attacking and increase
performance disks and low
attacking and increase its
nodes may also be
table and thus not
may also be unfairly
and thus not has
also be unfairly punished
thus not has crashed
performance disks such as
and increase its revenue
disks such as laptop
not has crashed or
such as laptop disks
has crashed or voluntary
crashed or voluntary exited
they explore the possibility
no correct nodes were
explore the possibility of
correct nodes were mistakenly
the two other levels
nodes were mistakenly expelled
two other levels that
the possibility of setting
other levels that are
at nash equilibrium both
levels that are currently
possibility of setting up
were mistakenly expelled from
of setting up a
mistakenly expelled from the
setting up a disk
expelled from the system
up a disk hierarchy
that are currently implemented
a disk hierarchy by
nash equilibrium both earn
disk hierarchy by using
equilibrium both earn less
hierarchy by using high
both earn less than
earn less than they
less than they would
provide a remote process
than they would have
a remote process with
they would have if
remote process with information
would have if neither
process with information about
performance disks in conjunction
have if neither attacked
with information about the
disks in conjunction with
information about the progress
in conjunction with each
auditing components we now
conjunction with each other
about the progress the
with multiple pools of
components we now give
multiple pools of equal
we now give some
the progress the local
now give some additional
pools of equal size
give some additional details
progress the local process
some additional details of
of equal size a
additional details of the
the local process is
details of the auditing
equal size a similar
of the auditing architecture
local process is making
in a related vein
process is making which
size a similar situation
is making which is
a similar situation arises
focusing upon two aspects
similar situation arises with
making which is useful
situation arises with a
which is useful in
arises with a symmetric
is useful in the
with a symmetric equilibrium
useful in the investigation
in the investigation of
the investigation of processes
investigation of processes that
of processes that are
processes that are alive
the fact that block
fact that block withholding
that block withholding is
block withholding is not
but that appear slow
withholding is not common
that appear slow or
collecting accountable information about
is not common may
accountable information about the
appear slow or unresponsive
information about the download
propose dynamic rotations per
not common may be
dynamic rotations per minute
about the download and
common may be explained
the download and upload
may be explained by
download and upload factors
be explained by modeling
and upload factors of
at certain intervals the
upload factors of individual
explained by modeling the
factors of individual nodes
certain intervals the process
by modeling the attack
intervals the process logs
of individual nodes in
the process logs checkpoint
individual nodes in the
process logs checkpoint timestamps
modeling the attack decisions
logs checkpoint timestamps with
nodes in the system
checkpoint timestamps with the
the attack decisions as
whereby disks can be
attack decisions as an
timestamps with the failure
decisions as an iterative
with the failure service
as an iterative prisoner
disks can be run
an iterative prisoner s
can be run at
iterative prisoner s dilemma
be run at multiple
run at multiple speeds
which simultaneously logs the
at multiple speeds depending
simultaneously logs the process
multiple speeds depending on
speeds depending on whether
depending on whether power
on whether power or
whether power or performance
establishing and applying the
power or performance takes
and applying the best
or performance takes precedence
we argue that the
applying the best threshold
the response to an
the best threshold at
argue that the situation
best threshold at any
response to an inquiry
threshold at any given
that the situation is
at any given time
to an inquiry request
any given time during
the situation is unstable
given time during execution
an inquiry request holds
situation is unstable since
inquiry request holds the
is unstable since the
request holds the last
poses a significant engineering
holds the last checkpoint
unstable since the attack
the last checkpoint timestamp
since the attack can
we employ two types
the attack can be
a significant engineering challenge
attack can be done
employ two types of
significant engineering challenge whose
two types of components
the current local time
types of components to
engineering challenge whose feasibility
of components to perform
challenge whose feasibility is
components to perform these
whose feasibility is far
can be done anonymously
whether the process has
feasibility is far from
the process has been
is far from obvious
process has been allocated
to perform these two
has been allocated cpu
perform these two roles
been allocated cpu time
allocated cpu time since
cpu time since the
another approach is proposed
time since the last
approach is proposed by
since the last checkpoint
local and global auditors
is proposed by colarelli
one pool may decide
proposed by colarelli et
pool may decide to
may decide to increase
decide to increase its
and whether the process
to increase its revenue
local auditors are executed
increase its revenue and
whether the process has
its revenue and drag
the process has consumed
revenue and drag the
auditors are executed on
and drag the others
process has consumed any
drag the others to
are executed on the
the others to attack
has consumed any messages
executed on the nodes
consumed any messages since
on the nodes participating
others to attack as
any messages since the
the nodes participating in
to attack as well
messages since the last
nodes participating in the
since the last checkpoint
participating in the system
using massive arrays of
ending with a reduced
massive arrays of inexpensive
with a reduced revenue
arrays of inexpensive disks
a reduced revenue for
reduced revenue for all
and therefore cannot be
therefore cannot be trusted
upon receipt of an
receipt of an inquiry
the inferior revenue would
if a node is
inferior revenue would push
a node is malicious
revenue would push miners
of an inquiry the
would push miners to
an inquiry the operating
push miners to join
inquiry the operating system
miners to join private
it might report false
to join private pools
might report false data
the operating system uses
they propose the use
operating system uses an
propose the use of
system uses an upcall
the use of a
which can verify that
use of a small
can verify that their
of a small number
verify that their registered
a small number of
that their registered miners
global auditors are trusted
their registered miners do
auditors are trusted components
registered miners do not
small number of cache
miners do not withhold
are trusted components that
do not withhold blocks
number of cache disks
to interrupt the process
of cache disks in
trusted components that run
cache disks in addition
components that run on
disks in addition to
this would lead to
in addition to the
would lead to smaller
addition to the maid
lead to smaller pools
to the maid disks
interrupt the process and
that run on dedicated
the process and requests
run on dedicated external
process and requests that
on dedicated external nodes
and requests that the
and so ultimately to
requests that the process
so ultimately to a
that the process prepares
ultimately to a better
the process prepares a
to a better environment
process prepares a special
there can be just
prepares a special response
a better environment for
the data in these
better environment for bitcoin
can be just one
environment for bitcoin as
be just one or
for bitcoin as a
just one or a
bitcoin as a whole
one or a few
this response is returned
data in these cache
response is returned to
or a few global
in these cache disks
a few global auditors
is returned to the
these cache disks is
returned to the caller
cache disks is updated
disks is updated to
for their valuable advice
is updated to reflect
we describe their roles
updated to reflect the
describe their roles and
to reflect the workload
their roles and interactions
reflect the workload that
roles and interactions in
the previous sections all
the author is grateful
the workload that is
and interactions in detail
workload that is currently
author is grateful to
previous sections all deal
interactions in detail below
that is currently being
is grateful to ken
is currently being accessed
sections all deal with
grateful to ken birman
all deal with provisions
deal with provisions targeted
with provisions targeted towards
the maid disks can
provisions targeted towards the
maid disks can then
targeted towards the failure
disks can then be
towards the failure management
can then be powered
the failure management of
then be powered down
failure management of processes
emin gu n sirer
and need only be
exploiting the close coupled
need only be spun
the close coupled nature
only be spun up
close coupled nature of
be spun up when
coupled nature of a
spun up when a
nature of a process
local auditors each node
and the paper shepherd
auditors each node n
the paper shepherd joseph
each node n runs
paper shepherd joseph bonneau
node n runs a
up when a cache
n runs a local
when a cache miss
runs a local auditor
a cache miss occurs
of a process and
a process and the
process and the operating
and the operating system
the operating system it
which interacts with other
operating system it runs
interacts with other local
system it runs under
upon which their contents
with other local auditors
which their contents are
other local auditors and
their contents are copied
local auditors and has
contents are copied onto
auditors and has two
are copied onto the
and has two main
to aid accurate detection
has two main roles
copied onto the cache
aid accurate detection in
onto the cache disks
accurate detection in the
detection in the case
publish n s data
in the case of
n s data exchange
the case of node
s data exchange history
this approach has several
case of node failure
approach has several of
of node failure the
has several of the
node failure the fault
several of the weaknesses
failure the fault management
n s local auditor
the fault management system
of the weaknesses that
fault management system implements
the weaknesses that memory
management system implements a
weaknesses that memory caches
system implements a node
that memory caches suffer
implements a node management
peer electronic cash system
s local auditor periodically
a node management service
local auditor periodically compiles
only on a larger
auditor periodically compiles and
on a larger scale
periodically compiles and distributes
compiles and distributes the
which is based on
and distributes the history
is based on the
distributes the history of
based on the experience
if the cache disks
the history of packets
the cache disks are
history of packets exchanged
on the experience that
cache disks are insufficient
the experience that local
disks are insufficient to
experience that local failure
are insufficient to store
of packets exchanged by
insufficient to store the
packets exchanged by n
to store the entire
that local failure investigation
store the entire working
local failure investigation on
the entire working set
failure investigation on a
entire working set of
investigation on a subnet
working set of the
on a subnet is
set of the current
a subnet is more
of the current workload
subnet is more accurate
is more accurate than
more accurate than investigation
accurate than investigation over
than investigation over the
it queries the local
investigation over the internet
queries the local streaming
the local streaming application
with considerable latency penalties
local streaming application running
on a participating subnet
streaming application running on
a participating subnet one
application running on n
participating subnet one or
running on n for
ebay s paypal unit
subnet one or more
s paypal unit to
one or more node
paypal unit to start
or more node failure
unit to start accepting
more node failure monitors
to start accepting bitcoin
the cache disks represent
on n for the
cache disks represent a
start accepting bitcoin payments
n for the set
disks represent a significant
for the set of
represent a significant added
the set of packets
a significant added cost
set of packets it
significant added cost in
of packets it sent
added cost in themselves
packets it sent and
these are simple services
it sent and received
are simple services capable
sent and received using
simple services capable of
and received using the
disk management solutions pinheiro
received using the streaming
management solutions pinheiro and
services capable of performing
solutions pinheiro and bianchini
using the streaming protocol
capable of performing local
the streaming protocol in
of performing local failure
streaming protocol in the
performing local failure investigations
protocol in the most
local failure investigations upon
in the most recent
failure investigations upon requests
the most recent time
investigations upon requests from
most recent time interval
upon requests from remote
requests from remote nodes
suggest that if data
that if data is
if data is laid
data is laid out
is laid out on
laid out on disks
out on disks according
multicast to announce their
on disks according to
to announce their availability
disks according to frequency
the local auditor signs
according to frequency of
announce their availability within
local auditor signs and
to frequency of access
their availability within the
auditor signs and publishes
google adds bitcoin currency
signs and publishes the
availability within the organization
and publishes the collected
within the organization where
with the most popular
publishes the collected history
the most popular files
the organization where their
most popular files being
the collected history to
popular files being located
organization where their presence
files being located in
collected history to an
being located in one
where their presence is
adds bitcoin currency conversion
their presence is being
located in one set
presence is being tracked
in one set of
is being tracked by
one set of disks
being tracked by the
bitcoin currency conversion to
history to an assigned
tracked by the other
currency conversion to search
to an assigned subset
and the least popular
an assigned subset of
the least popular ones
assigned subset of its
least popular ones in
subset of its neighboring
popular ones in another
of its neighboring nodes
by the other nfm
then the latter set
from whom other auditors
the latter set of
whom other auditors may
latter set of disks
other auditors may obtain
set of disks could
auditors may obtain it
of disks could be
an nfm accepts queries
disks could be powered
nfm accepts queries from
could be powered down
accepts queries from remote
be powered down to
queries from remote nodes
this level of indirection
powered down to conserve
from remote nodes about
level of indirection is
remote nodes about the
down to conserve energy
of indirection is used
nodes about the availability
indirection is used to
about the availability of
is used to prevent
the availability of a
their scheme is called
used to prevent nodes
scheme is called popular
availability of a node
to prevent nodes from
of a node within
is called popular data
prevent nodes from masking
called popular data concentration
a node within its
nodes from masking their
node within its organization
from masking their real
masking their real upload
their real upload and
real upload and download
upload and download factors
it will forward this
and download factors by
and they implement and
will forward this request
they implement and evaluate
download factors by presenting
implement and evaluate a
forward this request to
and evaluate a prototype
factors by presenting different
this request to an
by presenting different information
evaluate a prototype file
presenting different information to
a prototype file server
different information to different
request to an nfm
information to different auditors
prototype file server called
to an nfm on
file server called nomad
an nfm on the
server called nomad fs
nfm on the particular
audit n s neighbors
on the particular subnet
n s neighbors histories
the particular subnet which
which runs on top
particular subnet which will
runs on top of
subnet which will investigate
on top of the
which will investigate the
n s local auditor
top of the file
will investigate the availability
of the file system
s local auditor periodically
the file system and
investigate the availability of
file system and monitors
local auditor periodically audits
system and monitors data
the availability of the
and monitors data layout
auditor periodically audits the
monitors data layout on
availability of the node
data layout on disks
periodically audits the published
of the node by
audits the published histories
the node by launching
the published histories of
node by launching a
published histories of the
their findings are that
by launching a number
histories of the nodes
launching a number of
findings are that if
a number of fault
of the nodes with
number of fault test
are that if the
of fault test requests
that if the low
the nodes with whom
nodes with whom n
with whom n exchanges
whom n exchanges packets
access disks are powered
if this is support
disks are powered down
this is support by
is support by the
support by the host
by the host under
this results in a
the host under investigation
results in a considerable
if node n exchanges
in a considerable performance
host under investigation or
a considerable performance hit
node n exchanges packets
under investigation or by
n exchanges packets with
investigation or by icmp
exchanges packets with nodes
or by icmp echo
packets with nodes p
by icmp echo requests
they suggest instead that
icmp echo requests if
suggest instead that they
echo requests if not
instead that they be
that they be run
q and r in
they be run at
and r in the
be run at low
r in the livestreaming
run at low speed
in the livestreaming protocol
the result of the
result of the query
of the query is
the query is then
while their idea is
query is then returned
n s local auditor
their idea is sound
is then returned to
s local auditor compares
then returned to the
local auditor compares these
returned to the requesting
auditor compares these three
to the requesting node
compares these three nodes
it is not clear
these three nodes histories
is not clear whether
three nodes histories with
not clear whether this
nodes histories with n
clear whether this scheme
histories with n s
whether this scheme would
with n s own
this scheme would adapt
n s own history
scheme would adapt to
the nfm also functions
would adapt to different
adapt to different workloads
nfm also functions as
also functions as proxy
this involves ensuring that
functions as proxy for
as proxy for process
proxy for process availability
for process availability queries
process availability queries in
availability queries in the
queries in the case
in the case where
propose another data layout
the case where a
another data layout management
case where a firewall
data layout management scheme
where a firewall obstructs
layout management scheme to
a firewall obstructs the
management scheme to optimize
the amount of data
scheme to optimize disk
firewall obstructs the free
to optimize disk access
amount of data sent
optimize disk access patterns
obstructs the free querying
of data sent by
the free querying of
data sent by these
free querying of the
sent by these nodes
querying of the nodes
by these nodes satisfies
of the nodes by
these nodes satisfies the
the nodes by their
nodes satisfies the defined
nodes by their peers
satisfies the defined minimum
the defined minimum threshold
defined minimum threshold for
minimum threshold for the
threshold for the system
s are configured with
their approach uses finer
are configured with domain
configured with domain and
with domain and acl
domain and acl mechanisms
and acl mechanisms to
grained control over data
acl mechanisms to control
control over data layout
mechanisms to control access
over data layout on
to control access to
data layout on disk
control access to the
access to the information
the set of packets
set of packets they
tuning it on a
of packets they claim
it on a per
an extension which is
packets they claim to
extension which is under
they claim to have
which is under investigation
claim to have sent
is under investigation is
to have sent to
under investigation is to
have sent to and
investigation is to have
applications are instrumented and
sent to and received
are instrumented and then
is to have nodes
to and received from
instrumented and then profiled
to have nodes multicast
and then profiled to
and received from node
then profiled to obtain
have nodes multicast heartbeats
received from node n
profiled to obtain array
nodes multicast heartbeats with
to obtain array access
from node n corresponds
obtain array access sequences
multicast heartbeats with local
node n corresponds to
heartbeats with local node
n corresponds to the
with local node information
corresponds to the set
local node information periodically
to the set of
which their system then
the set of packets
their system then uses
set of packets n
system then uses to
of packets n claims
then uses to determine
packets n claims to
this information can be
n claims to have
information can be collected
claims to have respectively
can be collected by
uses to determine optimal
be collected by the
to have respectively received
collected by the local
to determine optimal disk
by the local nfm
have respectively received from
determine optimal disk layouts
respectively received from and
optimal disk layouts by
received from and sent
disk layouts by computing
from and sent to
layouts by computing optimal
and sent to them
by computing optimal stripe
s and shared in
computing optimal stripe factor
and shared in compressed
shared in compressed form
in compressed form among
compressed form among the
if the first check
form among the other
the first check comparison
among the other nfm
first check comparison fails
s in the organization
the local auditor issues
local auditor issues an
auditor issues an accusation
local system management tools
issues an accusation against
the wisdom of marrying
an accusation against the
system management tools can
accusation against the node
wisdom of marrying the
against the node to
management tools can connect
the node to a
of marrying the disk
node to a global
tools can connect to
to a global auditor
marrying the disk layout
can connect to an
the disk layout to
connect to an nfm
disk layout to the
to an nfm to
layout to the application
an nfm to retrieve
to the application seems
in the second case
the application seems questionable
nfm to retrieve the
to retrieve the information
retrieve the information and
the information and set
information and set trap
the local auditor is
and set trap conditions
local auditor is not
repurposing bitcoin work for
auditor is not able
bitcoin work for data
is not able to
proposed by zhu et
not able to prove
work for data preservation
able to prove the
to prove the neighbor
prove the neighbor s
the neighbor s misbehavior
in distributed systems build
in proceedings of the
distributed systems build on
proceedings of the ieee
systems build on top
of the ieee symposium
build on top of
the ieee symposium on
on top of a
ieee symposium on security
top of a web
symposium on security and
of a web of
on security and privacy
a web of interconnected
it instructs its local
web of interconnected networks
instructs its local streaming
its local streaming application
local streaming application to
streaming application to not
combines a number of
application to not further
a number of ideas
to not further exchange
not further exchange packets
we have to take
further exchange packets with
have to take network
exchange packets with the
it assumes multispeed disks
to take network failure
packets with the misbehaving
take network failure into
with the misbehaving neighbor
network failure into account
and computes online the
computes online the optimal
online the optimal speed
more complex types of
failures at network level
the optimal speed that
complex types of checks
optimal speed that each
at network level are
speed that each disk
types of checks may
network level are in
that each disk should
of checks may also
each disk should run
level are in general
checks may also be
are in general related
may also be performed
in general related to
also be performed to
general related to crash
be performed to address
related to crash failures
disk should run at
to crash failures of
performed to address other
crash failures of routers
to address other types
failures of routers and
address other types of
namecoin dns dotbit project
other types of byzantine
to minimize speed transition
types of byzantine behavior
minimize speed transition overheads
of routers and gateways
disks maintain their speeds
maintain their speeds for
or to severe degradation
their speeds for a
to severe degradation of
speeds for a fixed
severe degradation of the
degradation of the service
of the service level
the service level due
service level due to
level due to network
due to network congestion
causing minimum performance requirements
minimum performance requirements to
they call this the
performance requirements to be
call this the coarse
requirements to be violated
the failure investigator will
when not able to
not able to reach
able to reach the
hibernator includes a file
to reach the node
includes a file server
reach the node under
a file server that
the node under investigation
file server that sits
node under investigation or
server that sits on
under investigation or a
that sits on top
investigation or a relevant
sits on top of
or a relevant nfm
on top of the
top of the file
of the file system
the file system and
file system and manipulates
perform a path search
system and manipulates data
a path search to
and manipulates data layout
path search to find
manipulates data layout to
search to find the
data layout to put
to find the trouble
layout to put the
find the trouble spot
to put the most
the trouble spot in
trouble spot in the
spot in the network
accessed data on the
data on the highest
on the highest speed
it uses the traceroute
a next generation smart
the highest speed disks
next generation smart contract
uses the traceroute technique
the traceroute technique of
traceroute technique of emitting
technique of emitting small
of emitting small messages
the authors address the
emitting small messages with
authors address the issue
small messages with limited
address the issue of
messages with limited ttl
the issue of performance
issue of performance guarantees
of performance guarantees by
performance guarantees by stipulating
guarantees by stipulating that
by stipulating that if
stipulating that if performance
that if performance drops
triggering icmp responses from
if performance drops below
icmp responses from routers
performance drops below some
responses from routers among
drops below some threshold
from routers among the
routers among the path
then all disks are
all disks are spun
if an obstruction is
disks are spun up
an obstruction is found
are spun up to
obstruction is found it
spun up to their
is found it is
up to their highest
found it is reported
to their highest speed
it is reported to
is reported to the
reported to the caller
caching solutions zhu et
the failure management library
failure management library offers
management library offers functionality
library offers functionality to
offers functionality to keep
functionality to keep the
to keep the obstruction
keep the obstruction under
the obstruction under investigation
obstruction under investigation and
under investigation and to
observe that the storage
investigation and to notify
that the storage cache
and to notify the
the storage cache management
to notify the application
storage cache management policy
notify the application once
cache management policy is
the application once the
management policy is pivotal
application once the obstruction
policy is pivotal in
once the obstruction seems
is pivotal in determining
the obstruction seems to
pivotal in determining the
obstruction seems to be
in determining the sequence
seems to be removed
determining the sequence of
the sequence of requests
sequence of requests that
of requests that access
requests that access disks
this way the process
way the process does
the process does not
process does not need
does not need to
not need to keep
cache management policies could
need to keep the
management policies could be
to keep the partitioned
policies could be tailored
keep the partitioned processes
could be tailored to
the partitioned processes under
be tailored to change
partitioned processes under investigation
tailored to change the
processes under investigation but
to change the average
under investigation but can
change the average idle
investigation but can wait
the average idle time
but can wait until
average idle time between
can wait until the
idle time between disk
wait until the connectivity
time between disk requests
until the connectivity is
the connectivity is restored
connectivity is restored by
is restored by simply
restored by simply monitoring
thus providing more opportunities
analysis of bitcoin pooled
by simply monitoring the
of bitcoin pooled mining
providing more opportunities for
bitcoin pooled mining reward
simply monitoring the trouble
pooled mining reward systems
more opportunities for reducing
monitoring the trouble spot
opportunities for reducing disk
for reducing disk energy
reducing disk energy consumption
in case the network
case the network topology
the network topology permits
network topology permits it
cache policies that are
the investigator can be
policies that are aware
investigator can be configured
that are aware of
can be configured to
are aware of the
be configured to use
aware of the underlying
configured to use alternate
of the underlying disk
to use alternate paths
the underlying disk management
underlying disk management schemes
which disks are running
disks are running at
are running at which
running at which speeds
to reach one of
reach one of the
one of the destination
of the destination nfm
can make more intelligent
make more intelligent replacement
more intelligent replacement decisions
from cornell for example
cornell for example it
for example it is
example it is possible
it is possible to
the authors present both
is possible to construct
authors present both offline
present both offline and
both offline and online
offline and online power
alternative routes to anywhere
routes to anywhere in
to anywhere in california
aware cache replacement algorithms
cache replacement algorithms to
replacement algorithms to optimize
global auditing there are
algorithms to optimize read
to optimize read accesses
auditing there are two
there are two ways
are two ways in
the request contains sufficient
two ways in which
they also show through
request contains sufficient information
also show through experiments
ways in which a
contains sufficient information for
show through experiments the
sufficient information for the
through experiments the somewhat
information for the nfm
in which a node
for the nfm to
experiments the somewhat obvious
the nfm to construct
which a node could
nfm to construct a
the somewhat obvious fact
to construct a symmetric
a node could pretend
construct a symmetric return
somewhat obvious fact that
a symmetric return path
node could pretend to
obvious fact that for
could pretend to be
fact that for write
pretend to be sending
that for write accesses
protocols that can exploit
to be sending more
that can exploit this
be sending more or
can exploit this type
sending more or receiving
exploit this type of
more or receiving less
this type of information
or receiving less data
type of information are
receiving less data than
of information are under
less data than it
information are under development
back policies offer more
data than it actually
policies offer more opportunities
than it actually does
offer more opportunities to
more opportunities to save
opportunities to save power
to save power than
save power than write
it could send different
could send different histories
send different histories to
different histories to each
histories to each neighbor
always lying about its
lying about its interactions
about its interactions with
in the context of
its interactions with other
the context of write
interactions with other neighbors
a very natural candidate
n could send a
very natural candidate is
could send a history
natural candidate is the
send a history to
failure investigation of a
candidate is the log
investigation of a process
a history to p
of a process at
research perspectives on bitcoin
history to p pretending
perspectives on bitcoin and
a process at the
on bitcoin and secondgeneration
process at the same
bitcoin and secondgeneration cryptocurrencies
at the same sub
to p pretending to
p pretending to send
pretending to send more
to send more data
send more data to
in ieee symposium on
more data to q
net has always been
data to q than
ieee symposium on security
to q than it
has always been viewed
q than it actually
symposium on security and
than it actually did
always been viewed as
on security and privacy
been viewed as a
viewed as a reasonably
as a reasonably accurate
while it sends a
we now give a
it sends a different
now give a brief
reasons for false suspicions
give a brief overview
sends a different history
a brief overview of
for false suspicions were
a different history to
false suspicions were overload
brief overview of the
suspicions were overload in
overview of the log
different history to q
were overload in the
history to q where
overload in the receiver
to q where it
in the receiver os
structured file system before
q where it pretends
file system before describing
where it pretends to
system before describing the
it pretends to send
before describing the power
pretends to send more
to send more data
send more data to
more data to p
data to p than
to p than it
saving opportunity it represents
p than it actually
than it actually did
n s goal would
s goal would be
goal would be to
which could cause high
would be to send
could cause high message
be to send less
cause high message loss
to send less data
send less data while
less data while not
data while not being
while not being caught
or unresponsiveness due to
not being caught by
unresponsiveness due to application
being caught by any
due to application overload
caught by any of
structured file system the
by any of its
file system the log
any of its neighbors
although that could be
that could be seen
could be seen as
be seen as a
seen as a design
the process of publishing
as a design error
process of publishing a
of publishing a node
publishing a node s
was motivated by a
a node s history
motivated by a need
node s history to
by a need to
s history to a
although confident about the
history to a predefined
confident about the result
a need to optimize
to a predefined set
need to optimize the
a predefined set of
to optimize the latency
predefined set of neighbors
optimize the latency of
one was never guaranteed
the latency of write
set of neighbors ensures
was never guaranteed that
of neighbors ensures that
never guaranteed that the
neighbors ensures that the
guaranteed that the process
ensures that the node
that the process had
that the node cannot
the process had truly
the node cannot send
process had truly crashed
node cannot send conflicting
writing a block of
cannot send conflicting histories
a block of data
send conflicting histories to
block of data to
conflicting histories to different
of data to a
histories to different neighbors
using the os failure
to different neighbors undetected
the os failure management
data to a seagate
os failure management extensions
to a seagate barracuda
a seagate barracuda disk
seagate barracuda disk costs
barracuda disk costs about
therefore avoiding this problem
this assurance is now
assurance is now available
a node could also
node could also lie
the time needed by
could also lie about
time needed by the
also lie about the
needed by the failure
lie about the set
by the failure detector
about the set of
the failure detector to
the set of packets
failure detector to come
set of packets sent
detector to come to
ms in seek time
to come to a
in seek time and
of packets sent to
come to a result
packets sent to or
to a result has
sent to or received
a result has been
to or received from
result has been greatly
or received from a
has been greatly reduced
received from a particular
been greatly reduced in
from a particular neighbor
greatly reduced in the
a particular neighbor p
reduced in the optimistic
common case that the
case that the node
that the node on
the node on which
p will be able
node on which the
will be able to
kb in transmission time
on which the process
be able to identify
which the process was
able to identify that
the process was running
to identify that the
process was running is
the key observation here
identify that the node
was running is reachable
that the node has
key observation here is
the node has lied
observation here is that
node has lied and
here is that seek
has lied and will
is that seek time
regardless if the process
that seek time is
if the process has
seek time is a
the process has failed
lied and will therefore
process has failed or
time is a large
has failed or not
and will therefore stop
is a large and
will therefore stop exchanging
a large and constant
therefore stop exchanging packets
large and constant term
stop exchanging packets with
and constant term in
the node is able
constant term in latency
exchanging packets with n
term in latency computation
node is able to
is able to indicate
able to indicate whether
to indicate whether or
indicate whether or not
given that an opportunistic
to eliminate this term
that an opportunistic node
whether or not the
an opportunistic node s
or not the process
opportunistic node s goal
not the process has
node s goal is
the process has crashed
s goal is to
the lfs replaces write
goal is to maximize
lfs replaces write operations
is to maximize its
replaces write operations by
to maximize its utility
write operations by append
in general a single
operations by append operations
general a single round
it should have no
should have no interest
secondary storage is treated
have no interest in
storage is treated as
trip time is sufficient
is treated as a
no interest in losing
treated as a large
time is sufficient at
interest in losing data
is sufficient at the
in losing data exchange
sufficient at the local
as a large append
at the local network
losing data exchange partners
the local network to
local network to get
network to get a
to get a result
only log and writes
log and writes always
and writes always go
writes always go to
always go to the
opportunistic nodes have no
go to the log
nodes have no incentive
area case this time
have no incentive to
to the log head
no incentive to publish
case this time is
incentive to publish incorrect
this time is a
to publish incorrect histories
time is a function
is a function of
seek time is thus
a function of the
time is thus eliminated
function of the level
of the level of
the level of congestion
level of congestion in
of congestion in the
congestion in the network
and write latency becomes
in the network path
write latency becomes purely
local auditing ensures that
latency becomes purely a
auditing ensures that correct
becomes purely a function
ensures that correct information
purely a function of
the os extensions also
that correct information is
a function of the
os extensions also improve
function of the disk
correct information is available
of the disk bandwidth
extensions also improve the
information is available regarding
also improve the confidence
is available regarding the
improve the confidence in
available regarding the set
the confidence in the
regarding the set of
confidence in the failure
how do reads in
in the failure investigation
do reads in the
the set of data
reads in the lfs
the failure investigation process
set of data sent
failure investigation process in
of data sent and
investigation process in the
data sent and received
process in the wide
in the lfs work
sent and received by
and received by any
received by any node
in the same way
the same way as
same way as in
and allows nodes to
way as in conventional
allows nodes to monitor
as in conventional file
nodes to monitor each
in conventional file systems
to monitor each other
using the old strategy
monitor each other s
the old strategy of
each other s contribution
old strategy of simply
other s contribution rates
strategy of simply polling
of simply polling a
simply polling a process
polling a process until
a process until a
process until a time
and hence do not
hence do not avoid
information propagation in the
do not avoid seek
propagation in the bitcoin
out occurs gives much
in the bitcoin network
occurs gives much less
gives much less confidence
much less confidence in
less confidence in the
confidence in the result
in the result of
the result of the
result of the failure
of the failure investigation
the assumption is that
th ieee international conference
assumption is that with
global auditors global auditors
if no response was
auditors global auditors are
no response was received
global auditors are trusted
response was received after
auditors are trusted components
was received after the
are trusted components with
received after the maximum
trusted components with global
after the maximum number
components with global membership
the maximum number of
with global membership knowledge
maximum number of retransmission
ieee international conference on
is that with good
international conference on peer
number of retransmission is
that with good caching
of retransmission is reached
with good caching mechanisms
who interact with one
interact with one another
with one another and
one another and with
another and with the
it was not certain
and with the local
was not certain whether
with the local auditors
not certain whether this
reads will be a
certain whether this was
will be a small
whether this was because
be a small fraction
this was because of
a small fraction of
was because of network
small fraction of disk
because of network failure
fraction of disk accesses
as shown in figure
host failure or process
as can be imagined
failure or process failure
global auditors execute on
space reclamation is a
auditors execute on nodes
reclamation is a tricky
execute on nodes external
is a tricky problem
on nodes external to
with the new scheme
nodes external to the
a tricky problem in
the new scheme it
tricky problem in log
external to the system
problem in log structured
new scheme it is
in log structured file
scheme it is possible
log structured file systems
it is possible to
is possible to distinguish
their main roles are
possible to distinguish among
to distinguish among these
distinguish among these different
among these different failures
define the minimum upload
the minimum upload threshold
excellent solutions have been
solutions have been proposed
have been proposed to
additional information the full
been proposed to solve
proposed to solve it
global auditors periodically sample
information the full report
auditors periodically sample the
the full report contains
periodically sample the state
full report contains the
sample the state of
and one such is
the state of the
one such is of
state of the system
such is of interest
of the system by
is of interest to
report contains the detailed
of interest to us
bitcoin and the age
contains the detailed results
the system by querying
the detailed results of
and the age of
detailed results of the
the age of bespoke
the disk is divided
system by querying local
results of the trace
by querying local auditors
disk is divided into
age of bespoke silicon
is divided into large
of the trace study
divided into large log
the trace study on
into large log segments
trace study on the
they then cooperate to
study on the accuracy
then cooperate to analyze
on the accuracy and
cooperate to analyze the
in proceedings of the
once a log segment
to analyze the collected
a log segment gets
analyze the collected samples
log segment gets filled
the accuracy and performance
accuracy and performance of
and performance of the
performance of the failure
of the failure detector
and on this basis
the failure detector in
a new log segment
on this basis compute
failure detector in the
this basis compute the
detector in the internet
new log segment is
basis compute the minimum
log segment is allocated
compute the minimum upload
segment is allocated and
the minimum upload contribution
is allocated and the
minimum upload contribution threshold
allocated and the log
the effectiveness of its
and the log head
effectiveness of its partition
the log head moves
of its partition detection
log head moves to
its partition detection mechanism
head moves to the
international conference on compilers
different strategies may be
moves to the new
strategies may be employed
to the new segment
may be employed for
be employed for choosing
architectures and synthesis for
employed for choosing the
and synthesis for embedded
for choosing the best
synthesis for embedded systems
choosing the best possible
when some threshold of
the best possible threshold
host failure measurements and
some threshold of a
failure measurements and measurements
threshold of a segment
measurements and measurements of
of a segment gets
and measurements of failure
a segment gets invalidated
measurements of failure detection
of failure detection for
failure detection for server
detection for server fail
once thresholds are varied
its valid data is
valid data is moved
data is moved to
is moved to another
moved to another segment
they are gossiped to
are gossiped to all
gossiped to all local
to all local auditors
replacing that segment s
that segment s invalid
segment s invalid data
who then enforce the
it will be available
then enforce the determined
will be available later
enforce the determined threshold
be available later this
available later this year
later this year through
this year through the
and it is then
expurge nodes from the
year through the cornell
nodes from the system
it is then added
through the cornell university
is then added to
the cornell university technical
then added to the
cornell university technical report
added to the pool
university technical report server
to the pool of
global auditors are also
the pool of free
pool of free log
auditors are also responsible
of free log segments
are also responsible for
also responsible for verifying
responsible for verifying accusations
for verifying accusations issued
verifying accusations issued by
accusations issued by local
issued by local auditors
into the bitcoin mines
by local auditors against
local auditors against particular
this process results in
auditors against particular nodes
process results in a
results in a natural
in a natural division
a natural division of
natural division of allocated
and after validating the
division of allocated segments
after validating the accusation
of allocated segments into
allocated segments into stable
expurging misbehaving nodes from
misbehaving nodes from the
nodes from the system
validation involves verifying that
relevant url s the
involves verifying that the
url s the horus
consisting almost entirely of
verifying that the accused
almost entirely of data
s the horus project
entirely of data that
that the accused node
of data that is
the horus project the
data that is rarely
the accused node s
that is rarely invalidated
horus project the cornell
accused node s history
project the cornell cluster
node s history indeed
the cornell cluster computing
s history indeed indicates
cornell cluster computing project
history indeed indicates that
cluster computing project werner
indeed indicates that the
computing project werner vogels
indicates that the node
project werner vogels personal
that the node is
werner vogels personal home
the node is sending
vogels personal home page
node is sending less
personal home page papers
is sending less data
home page papers on
sending less data than
page papers on failure
less data than the
papers on failure detection
data than the current
on failure detection http
than the current threshold
which need to be
need to be constantly
to be constantly cleaned
expurging a node involves
a node involves informing
node involves informing the
involves informing the nodes
we will see how
informing the nodes immediate
will see how this
the nodes immediate neighbors
see how this feature
nodes immediate neighbors of
how this feature can
immediate neighbors of its
this feature can be
neighbors of its status
feature can be used
of its status and
can be used to
its status and forcing
be used to save
status and forcing the
used to save power
and forcing the removal
forcing the removal of
the removal of the
removal of the node
of the node from
the node from the
node from the overlay
from the overlay mesh
the number of global
number of global auditors
of global auditors may
global auditors may vary
auditors may vary according
may vary according to
vary according to different
according to different parameters
such as the size
as the size of
the size of the
size of the system
saving opportunity we shall
opportunity we shall now
we shall now argue
shall now argue that
the use of more
now argue that there
use of more global
argue that there remains
of more global auditors
that there remains an
more global auditors distributes
there remains an unexplored
global auditors distributes the
remains an unexplored quadrant
auditors distributes the load
an unexplored quadrant in
distributes the load of
unexplored quadrant in this
the load of sampling
quadrant in this solution
load of sampling and
in this solution space
of sampling and improves
sampling and improves efficiency
and improves efficiency in
improves efficiency in reacting
efficiency in reacting to
caches are used to
in reacting to accusations
are used to minimize
reacting to accusations against
used to minimize accesses
to accusations against nodes
to minimize accesses to
minimize accesses to disk
global auditors are also
good caching algorithms practically
auditors are also perfect
caching algorithms practically eliminate
are also perfect candidates
algorithms practically eliminate read
also perfect candidates to
practically eliminate read accesses
perfect candidates to perform
eliminate read accesses to
candidates to perform membership
read accesses to disk
to perform membership tasks
perform membership tasks such
membership tasks such as
tasks such as acting
such as acting as
as acting as entry
acting as entry points
as entry points to
entry points to the
points to the p
whether synchronous or not
must still eventually access
since they are required
still eventually access the
they are required to
eventually access the disk
are required to have
required to have full
to have full membership
have full membership knowledge
full membership knowledge of
membership knowledge of the
knowledge of the system
of the system for
the system for performing
system for performing their
for performing their auditing
performing their auditing roles
disk access will be
access will be write
global auditing monitors the
putting a disk management
auditing monitors the global
a disk management layer
monitors the global health
disk management layer on
the global health of
management layer on top
global health of the
layer on top of
health of the system
on top of the
top of the file
of the system to
the system to identify
system to identify the
to identify the best
system to optimize data
identify the best value
to optimize data layout
the best value for
optimize data layout for
best value for the
data layout for writes
value for the minimum
layout for writes is
for the minimum upload
for writes is only
the minimum upload threshold
writes is only halfway
minimum upload threshold at
is only halfway to
upload threshold at any
only halfway to the
threshold at any time
halfway to the solution
at any time during
any time during a
time during a streaming
during a streaming session
to take this idea
take this idea to
this idea to its
idea to its logical
to its logical conclusion
and makes final decisions
makes final decisions regarding
final decisions regarding punishment
decisions regarding punishment of
regarding punishment of nodes
it is necessary to
is necessary to rethink
necessary to rethink the
to rethink the file
rethink the file the
the file the disk
management policies described in
policies described in the
described in the related
in the related works
adaptive threshold strategies choosing
transis a communication subsystem
the related works section
a communication subsystem for
threshold strategies choosing an
communication subsystem for high
related works section essentially
subsystem for high availability
strategies choosing an upload
works section essentially attack
choosing an upload threshold
section essentially attack the
an upload threshold requires
essentially attack the problem
idigest of papers of
upload threshold requires care
attack the problem by
the problem by trying
problem by trying to
by trying to predict
trying to predict in
a low threshold may
to predict in advance
low threshold may not
predict in advance which
threshold may not be
in advance which disk
may not be sufficient
advance which disk any
not be sufficient to
which disk any given
be sufficient to identify
disk any given access
sufficient to identify opportunistic
any given access will
to identify opportunistic nodes
given access will go
access will go to
while high thresholds may
high thresholds may incorrectly
thresholds may incorrectly punish
they optimize the data
may incorrectly punish correct
optimize the data layout
incorrectly punish correct nodes
the data layout on
data layout on disks
layout on disks to
on disks to ensure
we considered different strategies
disks to ensure that
considered different strategies for
to ensure that accesses
different strategies for the
ensure that accesses are
strategies for the choice
that accesses are localized
for the choice of
accesses are localized to
the choice of the
are localized to some
choice of the minimum
localized to some fraction
of the minimum contribution
to some fraction of
the minimum contribution t
some fraction of the
minimum contribution t hreshold
fraction of the disks
contribution t hreshold used
t hreshold used for
hreshold used for identifying
used for identifying misbehaving
for identifying misbehaving nodes
so that only these
that only these need
only these need be
these need be powered
need be powered up
the simplest strategy sets
fast message ordering and
simplest strategy sets a
message ordering and membership
strategy sets a fixed
ordering and membership using
sets a fixed threshold
and membership using a
membership using a logical
using a logical token
these are all probabilistic
are all probabilistic models
a new access has
new access has some
access has some probability
has some probability of
some probability of not
probability of not fitting
of not fitting this
not fitting this model
fitting this model and
this model and needing
model and needing to
and needing to access
needing to access a
to access a powered
independent of the current
disk layout becomes tied
of the current state
layout becomes tied to
the current state of
becomes tied to particular
current state of the
tied to particular applications
state of the system
two applications that have
applications that have completely
that have completely different
any node contributing at
have completely different access
node contributing at a
completely different access patterns
contributing at a rate
different access patterns might
at a rate of
access patterns might require
a rate of less
patterns might require completely
rate of less than
might require completely different
require completely different data
completely different data layouts
different data layouts on
data layouts on disk
layouts on disk leading
on disk leading to
disk leading to conflicts
leading to conflicts that
to conflicts that reduce
conflicts that reduce possible
that reduce possible powersavings
reliable communication in the
of the stream rate
communication in the presence
the stream rate would
in the presence of
stream rate would be
the presence of failure
rate would be removed
since all writes in
all writes in an
writes in an lfs
in an lfs are
an lfs are to
acm transaction on computer
lfs are to the
transaction on computer systems
are to the log
one downside of using
to the log head
downside of using a
of using a fixed
using a fixed threshold
we know in advance
a fixed threshold is
know in advance which
fixed threshold is that
in advance which disk
threshold is that opportunistic
advance which disk they
is that opportunistic nodes
which disk they will
disk they will access
that opportunistic nodes that
opportunistic nodes that learn
nodes that learn the
that learn the threshold
this gives us the
learn the threshold can
gives us the perfect
the threshold can simply
us the perfect prediction
threshold can simply contribute
the perfect prediction mechanism
can simply contribute at
simply contribute at the
contribute at the lowest
at the lowest possible
the lowest possible upload
at least for writeaccesses
lowest possible upload factor
this prediction mechanism is
from the graphs in
prediction mechanism is also
the graphs in section
mechanism is also entirely
is also entirely application
it is clear that
is clear that such
clear that such a
that such a stretagy
such a stretagy may
a stretagy may disrupt
if most accesses to
stretagy may disrupt the
most accesses to disks
may disrupt the streaming
accesses to disks were
disrupt the streaming session
to disks were writes
we could power down
could power down every
power down every disk
group membership and viewsynchronous
down every disk but
membership and viewsynchronous communication
every disk but the
choosing a high threshold
disk but the one
a high threshold is
but the one that
high threshold is not
and viewsynchronous communication in
threshold is not a
the one that the
is not a practical
viewsynchronous communication in partitionable
not a practical option
one that the log
communication in partitionable asynchronous
that the log head
in partitionable asynchronous systems
the log head resides
log head resides on
since correct nodes would
correct nodes would get
nodes would get unfairly
would get unfairly punished
to avoid this problem
is an ideal case
we have explored adaptive
an ideal case scenario
have explored adaptive strategies
our view is that
one simple strategy starts
simple strategy starts with
strategy starts with a
starts with a minimum
with a minimum threshold
with a good caching
a good caching algorithm
aware caching algorithms described
caching algorithms described in
algorithms described in the
described in the related
in the related works
the related works section
related works section are
works section are good
section are good candidates
reads to disk can
to disk can be
how a mining monopoly
disk can be minimized
a mining monopoly can
mining monopoly can attack
monopoly can attack bitcoin
and only a small
only a small fraction
a small fraction of
small fraction of the
increasing it only if
fraction of the disks
it only if the
of the disks need
only if the system
the disks need be
if the system is
disks need be powered
the system is compromised
need be powered on
be powered on in
powered on in order
on in order to
in order to serve
global auditors sample the
order to serve all
auditors sample the system
to serve all writes
sample the system to
serve all writes as
unreliable failure detectors for
all writes as well
the system to identify
writes as well as
failure detectors for reliable
as well as reads
system to identify the
detectors for reliable distributed
to identify the average
for reliable distributed systems
identify the average download
the average download factor
to appear in journal
appear in journal of
and if this factor
in journal of the
if this factor is
journal of the acm
this factor is lower
what about the performance
factor is lower than
about the performance and
the performance and power
performance and power costs
and power costs of
power costs of log
costs of log cleaning
al present some optimizations
present some optimizations in
once the download factor
the download factor reaches
download factor reaches a
factor reaches a satisfactory
to hide the performance
reaches a satisfactory level
hide the performance penalty
a satisfactory level again
the performance penalty of
performance penalty of log
penalty of log cleaning
of log cleaning even
log cleaning even when
the threshold may be
cleaning even when the
threshold may be reduced
even when the workload
may be reduced back
when the workload allows
be reduced back to
the workload allows little
reduced back to its
workload allows little idle
back to its initial
allows little idle time
to its initial value
impossibility of distributed consensus
of distributed consensus with
distributed consensus with one
consensus with one faulty
the power costs of
with one faulty process
power costs of log
this stepwise approach allows
costs of log cleaning
stepwise approach allows the
of log cleaning are
approach allows the system
journal of the acm
log cleaning are a
allows the system to
cleaning are a little
the system to catch
are a little more
system to catch opportunistic
a little more tricky
to catch opportunistic nodes
little more tricky to
catch opportunistic nodes in
more tricky to justify
opportunistic nodes in case
nodes in case their
in case their presence
case their presence starts
their presence starts affecting
presence starts affecting the
starts affecting the performance
affecting the performance of
the performance of the
performance of the system
this is where the
is where the natural
where the natural division
the natural division of
while avoiding incorrect accusations
natural division of segments
avoiding incorrect accusations of
division of segments into
incorrect accusations of correct
of segments into stable
accusations of correct nodes
segments into stable and
into stable and volatile
stable and volatile ones
and volatile ones that
volatile ones that the
we also considered a
ones that the log
also considered a second
that the log cleaning
considered a second adaptive
the log cleaning process
a second adaptive strategy
log cleaning process results
cleaning process results in
majority is not enough
bitcoin mining is vulnerable
for computing the threshold
r van and vogels
computing the threshold based
after a significant fraction
the threshold based on
a significant fraction of
threshold based on periodically
in financial cryptography and
based on periodically sampled
financial cryptography and data
significant fraction of segments
cryptography and data security
on periodically sampled download
fraction of segments on
periodically sampled download and
of segments on a
sampled download and upload
segments on a disk
download and upload factors
on a disk have
a disk have been
disk have been classified
have been classified as
been classified as stable
support for highly reliable
the average download factors
average download factors once
download factors once again
factors once again are
once again are used
again are used for
are used for detecting
used for detecting whether
for detecting whether the
detecting whether the threshold
we power the disk
whether the threshold should
power the disk on
the threshold should be
the disk on and
threshold should be varied
disk on and copy
should be varied or
on and copy the
be varied or not
and copy the stable
copy the stable segments
the stable segments to
stable segments to a
segments to a stable
to a stable disk
acm sigops european workshop
our initial threshold is
volatile segments to a
initial threshold is set
segments to a volatile
threshold is set to
to a volatile disk
is set to null
disk is kept on
and the threshold is
the threshold is chosen
threshold is chosen from
is chosen from sampled
chosen from sampled upload
from sampled upload factors
and the entire disk
the entire disk is
entire disk is freed
disk is freed for
is freed for reuse
if the system seems
the system seems to
system seems to be
this is similar to
seems to be in
is similar to the
to be in a
similar to the log
be in a compromised
to the log cleaning
in a compromised state
the log cleaning scheme
log cleaning scheme described
cleaning scheme described in
the collected upload factors
collected upload factors are
upload factors are ordered
factors are ordered and
are ordered and the
ordered and the value
and the value dividing
the value dividing the
value dividing the lowest
percent is used as
is used as the
which uses a hidden
used as the new
uses a hidden structure
as the new threshold
a hidden structure embedded
hidden structure embedded in
structure embedded in the
embedded in the log
in the log to
this approach relies on
the log to track
approach relies on efficiently
log to track segment
relies on efficiently sampling
to track segment utilization
on efficiently sampling the
reliable multicast for distributed
efficiently sampling the system
multicast for distributed interactive
for distributed interactive simulation
cleaning an entire disk
an entire disk amortizes
and on fact that
entire disk amortizes the
on fact that if
disk amortizes the cost
fact that if the
amortizes the cost of
that if the system
the cost of powering
proceedings of acm sigcomm
cost of powering the
if the system s
of powering the disk
the system s performance
powering the disk on
system s performance is
s performance is not
performance is not satisfactory
number of accesses number
of accesses number of
cooperative equilibrium for supergames
accesses number of files
number of files touched
of files touched number
files touched number of
the review of economic
touched number of bytes
review of economic studies
number of bytes touched
percent of the nodes
of bytes touched average
of the nodes are
bytes touched average number
the nodes are opportunistic
touched average number of
average number of bytes
evaluation in this section
we evaluate the performance
evaluate the performance of
the performance of our
performance of our proposed
of our proposed auditing
our proposed auditing strategy
proposed auditing strategy over
auditing strategy over the
strategy over the original
over the original streaming
the original streaming protocol
we built an event
driven simulator and used
simulator and used it
and used it to
used it to simulate
it to simulate streaming
to simulate streaming sessions
simulate streaming sessions on
view synchronous communication in
streaming sessions on networks
synchronous communication in large
sessions on networks with
communication in large scale
nd open broadcast workshop
nodes and an average
and an average of
term competition a game
the target streaming rate
target streaming rate in
streaming rate in the
rate in the experiments
in the experiments was
the experiments was fixed
experiments was fixed to
based simulator of a
simulator of a log
given a trace of
a trace of read
trace of read and
of read and write
increasing reliability of communication
read and write requests
reliability of communication in
of communication in large
communication in large scale
in large scale distributed
and all our experiments
logsim returns the observed
all our experiments were
returns the observed access
our experiments were repeated
the observed access latencies
confidence intervals were small
and for simplicity are
for simplicity are omitted
simplicity are omitted from
are omitted from the
omitted from the graphs
for the chosen set
the chosen set of
chosen set of configuration
set of configuration parameters
the source of the
source of the stream
of the stream has
the stream has an
stream has an upload
has an upload capacity
world traces for our
an upload capacity of
traces for our simulations
upload capacity of four
for our simulations from
capacity of four times
our simulations from a
of four times the
simulations from a web
four times the stream
times the stream rate
server that serves images
that serves images from
serves images from a
images from a database
and is connected to
a generic architecture for
other nodes have enough
generic architecture for dependable
nodes have enough download
architecture for dependable distributed
have enough download capacity
for dependable distributed computing
enough download capacity to
download capacity to receive
capacity to receive the
to receive the stream
describes the characteristics of
the characteristics of a
characteristics of a sample
and upload factor of
of a sample trace
while a true evaluation
a true evaluation of
true evaluation of the
evaluation of the feasibility
of the feasibility and
the feasibility and efficacy
feasibility and efficacy of
and efficacy of our
efficacy of our solution
we defined an availability
of our solution can
defined an availability window
our solution can only
an availability window of
solution can only be
can only be achieved
only be achieved through
be achieved through an
achieved through an actual
through an actual implementation
seconds and an interest
and an interest window
simulation provides an elegant
an interest window of
provides an elegant way
an elegant way to
elegant way to identify
way to identify and
to identify and explore
identify and explore some
and explore some of
explore some of the
some of the cost
to evaluate the quality
evaluate the quality of
the quality of each
quality of each auditing
of each auditing strategy
benefit tradeoffs in a
tradeoffs in a scaled
we evaluate the average
down version of our
evaluate the average download
version of our system
the average download factors
average download factors of
download factors of correct
factors of correct nodes
of correct nodes during
correct nodes during a
the mechanism we simulate
mechanism we simulate is
we simulate is as
simulate is as follows
a flexible group communications
flexible group communications system
cornell university technical report
second time interval after
time interval after auditing
interval after auditing is
after auditing is first
disks are assumed to
auditing is first applied
are assumed to begin
is first applied to
assumed to begin in
first applied to the
to begin in the
applied to the system
begin in the on
in the on state
and an access count
we considered that global
considered that global auditors
is maintained for each
that global auditors collected
maintained for each disk
global auditors collected information
auditors collected information from
io bitcoin mining pool
the user specifies the
user specifies the maximum
specifies the maximum percentage
nodes between each interval
between each interval of
of disks that are
disks that are kept
that are kept powered
are kept powered on
notice that the sample
that the sample size
the sample size does
sample size does not
size does not increase
does not increase with
not increase with the
increase with the size
with the size of
the size of the
size of the system
which is a positive
is a positive aspect
a positive aspect of
positive aspect of the
aspect of the auditing
of the auditing approach
a disk check process
disk check process scans
check process scans the
process scans the access
scans the access count
the access count for
access count for each
count for each disk
for each disk and
each disk and powers
disk and powers down
and powers down all
we discuss the costs
powers down all but
discuss the costs involved
down all but the
the costs involved in
all but the most
costs involved in collecting
involved in collecting these
in collecting these samples
as well as any
well as any disk
as any disk which
any disk which does
disk which does not
which does not have
does not have at
not have at least
have at least t
at least t access
least t access count
miss results in an
results in an access
in an access to
an access to a
access to a powered
then this disk is
this disk is spun
disk is spun up
to remain powered on
remain powered on until
powered on until the
on until the next
until the next disk
the next disk check
and there is a
there is a corresponding
is a corresponding latency
a corresponding latency penalty
number of false positives
of false positives download
false positives download factor
judicious choice of the
choice of the parameters
of the parameters m
the parameters m and
parameters m and t
m and t minimizes
and t minimizes the
t minimizes the probability
minimizes the probability of
the probability of this
probability of this occurrence
methodology we have proposed
we have proposed the
have proposed the use
proposed the use of
the use of lfs
use of lfs in
of lfs in lieu
lfs in lieu of
in lieu of ffs
or other conventional file
other conventional file systems
center scenarios to achieve
scenarios to achieve power
to achieve power conservation
for this idea to
this idea to be
idea to be accepted
two questions need to
questions need to be
need to be answered
to be answered in
be answered in the
answered in the affirmative
a private framework for
private framework for distributed
framework for distributed computation
for distributed computation edward
distributed computation edward tremel
does this new scheme
this new scheme result
new scheme result in
scheme result in significant
result in significant power
in significant power savings
and ma rk jelasity
ma rk jelasity there
rk jelasity there is
jelasity there is a
there is a growing
is a growing class
a growing class of
does this new scheme
this new scheme provide
growing class of distributed
new scheme provide comparable
class of distributed systems
scheme provide comparable performance
provide comparable performance to
of distributed systems applications
comparable performance to existing
performance to existing schemes
distributed systems applications in
systems applications in which
applications in which data
in which data stored
which data stored on
data stored on client
stored on client platforms
the answers to these
on client platforms must
answers to these questions
client platforms must be
to these questions must
platforms must be aggregated
these questions must be
must be aggregated or
questions must be largely
be aggregated or analyzed
must be largely applicationindependent
aggregated or analyzed without
or analyzed without revealing
analyzed without revealing private
kncminer bitcoin mining cloud
without revealing private information
bitcoin mining cloud mining
and must apply to
revealing private information to
must apply to a
private information to the
apply to a generic
information to the operator
to a generic data
a generic data center
generic data center model
systems such as the
such as the smart
as the smart power
to address these questions
the smart power grid
we present a simulator
control systems for energy
logsim consists of less
and traffic analysis in
consists of less than
traffic analysis in large
of less than a
analysis in large cities
less than a thousand
in large cities all
than a thousand lines
large cities all depend
a thousand lines of
cities all depend on
thousand lines of java
all depend on the
lines of java code
depend on the analysis
of java code and
on the analysis of
java code and is
the analysis of data
code and is a
analysis of data supplied
and is a single
of data supplied by
data supplied by measurement
supplied by measurement devices
yet the clients being
the clients being tracked
clients being tracked are
being tracked are unwilling
tracked are unwilling to
are unwilling to reveal
unwilling to reveal such
to reveal such measurement
reveal such measurement data
we must turn off
such measurement data directly
must turn off some
measurement data directly to
turn off some percentage
data directly to the
off some percentage of
directly to the system
some percentage of disks
to the system owner
percentage of disks in
of disks in the
disks in the storage
in the storage system
who might be curious
might be curious about
be curious about private
curious about private client
about private client information
there are two opposing
are two opposing forces
two opposing forces at
these systems thus may
opposing forces at play
systems thus may elicit
forces at play here
thus may elicit public
may elicit public opposition
elicit public opposition despite
public opposition despite their
a large number of
opposition despite their useful
large number of powered
despite their useful features
their useful features because
useful features because of
features because of a
because of a perceived
on disks results in
of a perceived privacy
disks results in good
a perceived privacy risk
results in good performance
there are ways to
are ways to upload
ways to upload sensitive
to upload sensitive data
upload sensitive data to
sensitive data to an
data to an aggregator
to an aggregator without
but also low power
an aggregator without compromising
also low power savings
aggregator without compromising privacy
on the other hand
but existing options have
existing options have limitations
decreasing the number of
the number of powered
one possibility is to
possibility is to keep
is to keep the
to keep the data
on disks incurs two
keep the data encrypted
disks incurs two possible
the data encrypted with
incurs two possible penalties
data encrypted with keys
encrypted with keys known
with keys known only
keys known only to
known only to the
only to the clients
but this requires expensive
this requires expensive homomorphic
requires expensive homomorphic encryption
expensive homomorphic encryption if
an authorization architecture for
homomorphic encryption if the
authorization architecture for trustworthy
encryption if the aggregator
architecture for trustworthy computing
if the aggregator is
the aggregator is to
aggregator is to compute
is to compute directly
transitions consume power and
to compute directly on
consume power and thus
compute directly on it
power and thus counter
in proceedings of the
and thus counter the
proceedings of the twenty
thus counter the potential
counter the potential savings
another is to employ
the potential savings achieved
is to employ a
potential savings achieved by
third acm symposium on
savings achieved by powered
to employ a mechanism
acm symposium on operating
employ a mechanism to
symposium on operating systems
a mechanism to de
on operating systems principles
correlate client identifiers from
to find the optimal
client identifiers from their
find the optimal percentage
identifiers from their data
the optimal percentage of
optimal percentage of disks
percentage of disks to
of disks to be
disks to be powered
to be powered down
quality of streaming when
as chen et al
of streaming when applying
streaming when applying the
when applying the fixed
applying the fixed threshold
the fixed threshold strategy
we ran a set
ran a set of
a set of simulations
set of simulations on
threshold is varied from
of simulations on logsim
simulations on logsim and
on logsim and varied
logsim and varied the
and varied the number
varied the number of
the number of disks
number of disks that
of disks that we
disks that we kept
but this imposes restrictions
that we kept powered
this imposes restrictions on
we kept powered up
imposes restrictions on the
kept powered up from
restrictions on the kind
powered up from none
on the kind of
the kind of aggregation
kind of aggregation that
of aggregation that can
aggregation that can be
that can be done
and the contribution rate
it would be beneficial
the contribution rate of
would be beneficial to
contribution rate of opportunistic
be beneficial to execute
rate of opportunistic nodes
beneficial to execute needed
of opportunistic nodes is
to execute needed computation
opportunistic nodes is varied
execute needed computation directly
nodes is varied from
needed computation directly on
computation directly on the
directly on the client
on the client platforms
so that the system
that the system operator
the system operator or
system operator or analyst
operator or analyst only
or analyst only sees
analyst only sees aggregate
only sees aggregate results
out of a total
of a total of
this approach would provide
approach would provide a
would provide a better
provide a better alternative
a better alternative to
better alternative to central
alternative to central aggregation
to central aggregation provided
presents the average download
central aggregation provided it
the average download factors
aggregation provided it is
average download factors across
provided it is privacy
download factors across all
factors across all correct
across all correct nodes
presents the number of
the number of correct
a data aggregation system
number of correct nodes
data aggregation system based
of correct nodes incorrectly
aggregation system based on
correct nodes incorrectly punished
system based on client
side computation suggests a
computation suggests a purely
suggests a purely peer
we consider the use
consider the use of
the use of fixed
use of fixed thresholds
we studied the effects
studied the effects of
the effects of using
effects of using different
of using different values
using different values for
different values for t
which many systems have
many systems have used
disks were kept powered
systems have used to
were kept powered up
have used to avoid
used to avoid centralized
to avoid centralized control
and increasing it until
of the stream rate
and present a detailed
peer systems have problems
present a detailed set
systems have problems of
a detailed set of
have problems of their
detailed set of results
problems of their own
set of results on
of results on applying
results on applying different
on applying different thresholds
even if we set
applying different thresholds to
if we set privacy
different thresholds to different
we set privacy concerns
thresholds to different scenarios
set privacy concerns aside
by eschewing centralization entirely
the ratio of opportunistic
ratio of opportunistic nodes
they can no longer
of opportunistic nodes is
can no longer take
opportunistic nodes is fixed
no longer take advantage
nodes is fixed to
longer take advantage of
take advantage of the
advantage of the powerful
of the powerful management
the powerful management tools
powerful management tools developed
management tools developed for
tools developed for today
developed for today s
for today s cloud
today s cloud computing
s cloud computing model
but their contribution factor
on power splitting games
power splitting games in
splitting games in distributed
games in distributed computation
the case of bitcoin
clients are isolated network
case of bitcoin pooled
are isolated network hosts
of bitcoin pooled mining
isolated network hosts rather
network hosts rather than
hosts rather than devices
rather than devices within
than devices within a
devices within a single
within a single administrative
a single administrative domain
and often have difficulty
often have difficulty maintaining
have difficulty maintaining connections
difficulty maintaining connections to
maintaining connections to each
connections to each other
to each other through
each other through firewalls
other through firewalls and
through firewalls and address
firewalls and address translation
and address translation barriers
determining the membership of
the membership of a
membership of a peer
peer network is a
network is a surprisingly
is a surprisingly difficult
a surprisingly difficult problem
since there is no
there is no one
is no one entity
no one entity that
one entity that knows
entity that knows the
that knows the identities
knows the identities of
the identities of all
identities of all the
of all the clients
nodes follow the protocol
and changes in membership
changes in membership may
with a maximum contribution
in membership may not
a maximum contribution rate
membership may not be
maximum contribution rate set
may not be detected
contribution rate set to
not be detected and
be detected and propagated
detected and propagated in
and propagated in a
propagated in a timely
cdf number of accesses
in a timely fashion
without a centralized service
a centralized service to
centralized service to assign
service to assign and
to assign and manage
assign and manage node
and manage node identities
we present the average
present the average download
the average download rates
and the number of
the number of correct
number of correct nodes
of correct nodes mistakenly
correct nodes mistakenly removed
nodes mistakenly removed from
mistakenly removed from the
peer system is extremely
removed from the system
weekly bitcoin network statistics
system is extremely vulnerable
is extremely vulnerable to
extremely vulnerable to a
vulnerable to a few
to a few malicious
a few malicious peers
few malicious peers becoming
malicious peers becoming a
peers becoming a majority
becoming a majority of
a majority of the
majority of the apparent
of the apparent nodes
the apparent nodes in
for each of these
apparent nodes in the
each of these configurations
nodes in the system
the threshold applied is
even choosing peers fairly
threshold applied is presented
choosing peers fairly becomes
applied is presented on
peers fairly becomes difficult
is presented on the
presented on the x
because peers usually do
peers usually do not
usually do not store
do not store the
not store the entire
in the left graph
store the entire membership
the entire membership list
entire membership list locally
as the threshold increases
and it is fairly
it is fairly easy
higher download averages are
is fairly easy for
download averages are observed
fairly easy for malicious
easy for malicious peers
for malicious peers to
since more opportunistic nodes
malicious peers to poison
more opportunistic nodes are
peers to poison local
opportunistic nodes are detected
to poison local mem
nodes are detected and
poison local mem cornell
are detected and punished
local mem cornell bership
mem cornell bership views
cornell bership views so
bership views so that
views so that they
so that they will
that they will be
they will be preferred
will be preferred as
the number of nodes
be preferred as neighbors
number of nodes incorrectly
preferred as neighbors by
of nodes incorrectly accused
as neighbors by honest
nodes incorrectly accused also
neighbors by honest nodes
incorrectly accused also increases
accused also increases with
also increases with higher
increases with higher thresholds
as observed in the
observed in the right
in the right graph
scenarios where opportunistic nodes
where opportunistic nodes contribute
opportunistic nodes contribute at
nodes contribute at higher
contribute at higher rates
since neither completely centralized
neither completely centralized aggregation
completely centralized aggregation nor
centralized aggregation nor a
aggregation nor a completely
nor a completely peer
are less disruptive to
less disruptive to the
disruptive to the system
peer system is adequate
system is adequate for
but they also require
is adequate for our
they also require higher
adequate for our purposes
also require higher thresholds
require higher thresholds to
higher thresholds to be
thresholds to be applied
we explore a new
explore a new approach
a new approach that
different thresholds yield best
new approach that combines
thresholds yield best results
approach that combines the
yield best results under
that combines the features
best results under different
combines the features of
results under different scenarios
the features of these
features of these two
of these two extremes
although the idea of
the idea of a
from the results presented
idea of a communication
the results presented in
of a communication system
results presented in figure
a communication system that
communication system that combines
system that combines some
that combines some centralized
combines some centralized control
some centralized control with
centralized control with a
control with a peer
we concluded that the
concluded that the best
that the best fixed
the best fixed threshold
best fixed threshold is
fixed threshold is t
peer overlay is not
overlay is not new
we are the first
are the first to
the first to use
theoretic analysis of ddos
first to use such
analysis of ddos attacks
to use such a
of ddos attacks against
use such a system
ddos attacks against bitcoin
such a system to
attacks against bitcoin mining
a system to preserve
against bitcoin mining pools
system to preserve privacy
to preserve privacy while
providing the best compromise
preserve privacy while computing
the best compromise in
privacy while computing on
in workshop on bitcoin
while computing on sensitive
workshop on bitcoin research
computing on sensitive data
best compromise in terms
compromise in terms of
in terms of performance
terms of performance and
of performance and false
this combination is a
performance and false positives
combination is a sensible
and false positives across
is a sensible tradeoff
false positives across all
a sensible tradeoff for
positives across all scenarios
sensible tradeoff for the
tradeoff for the kinds
for the kinds of
the kinds of systems
kinds of systems we
of systems we target
effect of increasing percentage
of increasing percentage of
increasing percentage of powered
in which there is
up disks on performance
which there is an
we compare all three
there is an owner
compare all three strategies
is an owner or
all three strategies proposed
an owner or operator
three strategies proposed in
owner or operator who
strategies proposed in subsection
or operator who can
operator who can be
who can be trusted
effect of increasing percentage
can be trusted to
of increasing percentage of
be trusted to provide
increasing percentage of powered
trusted to provide basic
to provide basic services
provide basic services such
basic services such as
against each other and
services such as node
up disks on power
such as node identification
disks on power consumption
each other and against
on power consumption both
as node identification and
power consumption both its
other and against a
consumption both its performance
node identification and membership
and against a configuration
identification and membership tracking
against a configuration with
and membership tracking but
a configuration with no
membership tracking but not
configuration with no auditing
as well as its
tracking but not to
well as its power
but not to see
not to see non
when bitcoin mining pools
bitcoin mining pools run
mining pools run dry
aggregated raw client data
the former is measured
former is measured using
in workshop on bitcoin
is measured using the
workshop on bitcoin research
measured using the observed
using the observed access
the observed access latencies
we treat the system
treat the system operator
the system operator as
system operator as an
operator as an honest
while the latter is
the latter is measured
latter is measured by
for the fixed threshold
is measured by comparing
the fixed threshold strategy
measured by comparing the
fixed threshold strategy and
by comparing the cumulative
threshold strategy and as
comparing the cumulative percentage
strategy and as the
the cumulative percentage of
and as the initial
cumulative percentage of time
as the initial threshold
percentage of time the
the initial threshold in
of time the disks
initial threshold in the
time the disks are
who will keep the
the disks are kept
threshold in the stepwise
disks are kept powered
in the stepwise adaptive
are kept powered on
will keep the system
the stepwise adaptive strategy
keep the system running
the system running correctly
system running correctly but
as well as the
running correctly but cannot
we summarize the three
well as the number
summarize the three strategies
as the number of
the three strategies in
the number of mode
three strategies in table
correctly but cannot be
but cannot be allowed
cannot be allowed to
be allowed to see
allowed to see more
to see more information
comparison of mining pools
see more information than
we simulated sessions where
more information than he
information than he or
than he or she
he or she needs
or she needs to
she needs to know
of the nodes were
the nodes were opportunistic
nodes were opportunistic and
were opportunistic and with
opportunistic and with varying
show the results of
and with varying ratios
the results of these
with varying ratios of
results of these simulations
varying ratios of contribution
comparison of mining pools
we introduce a method
introduce a method for
a method for constructing
the contribution rate of
method for constructing a
contribution rate of opportunistic
for constructing a communication
of the disks powered
rate of opportunistic nodes
the disks powered on
of opportunistic nodes is
constructing a communication overlay
opportunistic nodes is varied
nodes is varied from
a communication overlay among
communication overlay among the
overlay among the client
among the client nodes
the client nodes that
client nodes that can
nodes that can safely
that can safely be
can safely be used
safely be used to
be used to perform
used to perform aggregation
to perform aggregation and
perform aggregation and computation
aggregation and computation on
of the disks can
and computation on private
the disks can be
all other nodes are
computation on private data
other nodes are correct
disks can be spun
can be spun down
be spun down while
spun down while still
contributing at a maximum
although this overlay is
down while still maintaining
this overlay is set
at a maximum rate
overlay is set up
a maximum rate of
is set up and
while still maintaining performance
set up and operated
still maintaining performance comparable
up and operated by
maintaining performance comparable to
and operated by the
performance comparable to that
hashcash amortizable publicly auditable
comparable to that of
operated by the system
to that of a
by the system owner
that of a conventional
amortizable publicly auditable cost
of a conventional file
a conventional file system
it provides minimal opportunity
provides minimal opportunity for
we present both the
the performance of our
minimal opportunity for the
present both the average
performance of our system
opportunity for the owner
of our system depends
both the average and
our system depends very
for the owner to
system depends very heavily
the average and the
depends very heavily on
the owner to learn
very heavily on its
average and the minimum
heavily on its cache
owner to learn any
on its cache configuration
and the minimum download
to learn any information
the minimum download factors
learn any information about
minimum download factors across
any information about the
download factors across all
information about the data
since cache optimization is
factors across all correct
about the data being
across all correct nodes
cache optimization is an
all correct nodes in
the data being aggregated
correct nodes in the
optimization is an orthogonal
data being aggregated other
nodes in the system
is an orthogonal issue
being aggregated other than
an orthogonal issue that
aggregated other than the
orthogonal issue that comprises
other than the final
issue that comprises an
than the final result
as the contribution rate
the final result of
that comprises an entire
the contribution rate of
final result of the
contribution rate of opportunistic
result of the computation
rate of opportunistic nodes
comprises an entire field
of opportunistic nodes increases
an entire field of
entire field of research
field of research in
of research in itself
when combined with differential
combined with differential privacy
the download factors are
with differential privacy techniques
download factors are expected
factors are expected to
are expected to increase
it is important to
is important to isolate
important to isolate its
to protect the aggregation
to isolate its effect
which is clear from
protect the aggregation results
is clear from the
isolate its effect on
clear from the curves
its effect on performance
from the curves presented
the aggregation results themselves
strategy no auditing fixed
it can be used
no auditing fixed threshold
can be used to
auditing fixed threshold stepwise
we implemented an ideal
be used to ensure
implemented an ideal cache
fixed threshold stepwise adaptive
an ideal cache algorithm
used to ensure that
threshold stepwise adaptive percentile
to ensure that no
ensure that no query
that no query made
which we term the
no query made to
we term the oracle
based adaptive description fixed
query made to the
adaptive description fixed t
made to the system
to the system reveals
the system reveals the
system reveals the contribution
this data point represents
reveals the contribution of
the contribution of any
data point represents the
contribution of any particular
of any particular node
point represents the best
represents the best performance
the best performance we
best performance we could
our overlay network looks
performance we could achieve
overlay network looks a
we could achieve since
network looks a bit
could achieve since an
looks a bit like
achieve since an oracle
a bit like a
since an oracle has
bit like a gossip
an oracle has future
like a gossip infrastructure
hashcash a denial of
oracle has future knowledge
a denial of service
has future knowledge and
denial of service counter
future knowledge and is
knowledge and is able
and is able to
is able to replace
able to replace items
to replace items accessed
replace items accessed furthest
items accessed furthest in
accessed furthest in the
furthest in the future
and can be used
can be used to
be used to run
used to run gossip
if avg sampled download
avg sampled download factor
with the key difference
the key difference that
key difference that the
difference that the random
that the random peer
we also wish to
the random peer selection
also wish to provide
random peer selection of
wish to provide a
peer selection of gossip
to provide a performance
selection of gossip is
provide a performance comparison
of gossip is replaced
a performance comparison of
gossip is replaced with
performance comparison of our
is replaced with a
comparison of our system
replaced with a completely
of our system against
with a completely deterministic
our system against conventional
a completely deterministic function
nodes are assigned virtual
are assigned virtual ids
assigned virtual ids that
virtual ids that are
ids that are either
that are either integers
are either integers or
either integers or finite
as an approximation of
integers or finite field
an approximation of such
or finite field elements
approximation of such a
of such a system
decrease t back to
and each node uses
we implemented a random
each node uses a
implemented a random placement
node uses a function
a random placement algorithm
uses a function based
a function based on
function based on either
which maps each block
based on either modular
maps each block to
when avg download is
each block to a
avg download is satisfactory
block to a random
download is satisfactory again
to a random disk
on either modular arithmetic
either modular arithmetic or
modular arithmetic or finite
arithmetic or finite fields
all disks are kept
or finite fields to
disks are kept powered
finite fields to compute
are kept powered up
fields to compute the
to compute the order
compute the order in
the order in which
order in which it
in which it should
which it should communicate
it should communicate with
should communicate with the
communicate with the other
with the other nodes
if avg sampled download
we construct this function
avg sampled download factor
construct this function to
having set the context
this function to ensure
function to ensure that
to ensure that the
ensure that the network
that the network is
let us examine fig
the network is optimally
network is optimally robust
is optimally robust and
optimally robust and efficient
on subversive miner strategies
subversive miner strategies and
miner strategies and block
strategies and block withholding
converging in logarithmic time
and block withholding attack
in logarithmic time and
block withholding attack in
logarithmic time and tolerating
withholding attack in bitcoin
time and tolerating message
attack in bitcoin digital
and tolerating message failures
in bitcoin digital currency
tolerating message failures with
message failures with minimal
t is chosen based
failures with minimal delay
is chosen based on
chosen based on sampled
based on sampled upload
on sampled upload factors
the additional two data
key cryptography to encrypt
cryptography to encrypt messages
points described above are
described above are represented
above are represented in
are represented in fig
ensuring that the the
that the the system
the the system operator
the system operator cannot
system operator cannot infer
operator cannot infer anything
cannot infer anything about
infer anything about the
anything about the data
about the data being
the data being aggregated
data being aggregated by
being aggregated by observing
aggregated by observing network
by observing network traffic
even the communication pattern
the communication pattern is
communication pattern is completely
pattern is completely predictable
strategies used for defining
is completely predictable and
used for defining the
completely predictable and hence
for defining the minimum
predictable and hence reveals
defining the minimum upload
and hence reveals nothing
the minimum upload threshold
minimum upload threshold t
upload threshold t figure
shows that all strategies
that all strategies yield
malicious nodes cannot significantly
all strategies yield significantly
nodes cannot significantly deviate
strategies yield significantly better
cannot significantly deviate from
yield significantly better results
significantly deviate from correct
significantly better results compared
deviate from correct behavior
better results compared to
from correct behavior without
results compared to an
correct behavior without being
compared to an approach
behavior without being detected
to an approach with
an approach with no
approach with no auditing
so the network encourages
the network encourages the
network encourages the operator
while both adaptive strategies
encourages the operator to
both adaptive strategies yield
the operator to behave
adaptive strategies yield excellent
operator to behave correctly
strategies yield excellent download
yield excellent download rates
excellent download rates to
download rates to correct
rates to correct nodes
and it even tolerates
it even tolerates byzantine
even tolerates byzantine failure
if we imagine a
the fixed threshold strategy
we imagine a line
tolerates byzantine failure by
fixed threshold strategy s
imagine a line at
byzantine failure by a
a line at y
failure by a small
threshold strategy s performance
by a small minority
strategy s performance is
a small minority of
s performance is not
how incentivize large bitcoin
performance is not as
incentivize large bitcoin mining
small minority of clients
large bitcoin mining http
is not as good
not as good when
as good when opportunistic
good when opportunistic nodes
when opportunistic nodes are
this ensures that important
opportunistic nodes are contributing
ensures that important queries
nodes are contributing with
that important queries will
important queries will not
queries will not be
will not be corrupted
not be corrupted or
be corrupted or blocked
corrupted or blocked by
or blocked by compromised
blocked by compromised devices
or slightly more kbps
and that an adversary
that an adversary cannot
an adversary cannot compromise
adversary cannot compromise the
cannot compromise the privacy
compromise the privacy of
the privacy of client
privacy of client data
of client data by
client data by gaining
data by gaining control
by gaining control of
gaining control of a
control of a few
of a few devices
a few devices in
few devices in the
devices in the system
of the accesses live
the accesses live above
accesses live above this
at those rates opportunistic
live above this line
those rates opportunistic nodes
rates opportunistic nodes are
opportunistic nodes are harmful
nodes are harmful to
are harmful to the
harmful to the system
yet the fixed threshold
the fixed threshold of
disks on is the
on is the third
is the third best
the third best configuration
ro bert orma ndi
is not able to
next only to the
not able to detect
only to the oracle
able to detect them
to the oracle and
istva n hegedu s
and ma rk jelasity
gossip learning with linear
learning with linear models
with linear models on
linear models on fully
models on fully distributed
on fully distributed this
fully distributed this work
distributed this work was
this work was supported
we consider a scenario
consider a scenario where
a scenario where opportunistic
scenario where opportunistic nodes
the performance degradation in
where opportunistic nodes contribute
performance degradation in going
opportunistic nodes contribute with
degradation in going from
nodes contribute with different
by a grant from
contribute with different rates
a grant from the
grant from the nsf
from the nsf data
we varied the percentage
varied the percentage of
the percentage of opportunistic
percentage of opportunistic nodes
of opportunistic nodes in
opportunistic nodes in the
practice and exsmart grids
nodes in the system
and exsmart grids program
in the system from
disks on is negligibly
on is negligibly small
and evenly assigned them
evenly assigned them different
assigned them different contribution
them different contribution rates
for the system under
the system under test
the graphs present the
graphs present the average
present the average and
the optimal configuration is
the average and minimum
optimal configuration is to
average and minimum download
configuration is to fig
and minimum download rates
minimum download rates for
download rates for these
rates for these scenarios
shows an estimate of
an estimate of the
estimate of the actual
no auditing performs significantly
of the actual power
auditing performs significantly worse
the actual power savings
performs significantly worse than
actual power savings achieved
significantly worse than any
power savings achieved by
worse than any of
savings achieved by our
than any of the
achieved by our solution
any of the proposed
of the proposed strategies
we assume the following
assume the following disk
the following disk specifications
the stepwise adaptive approach
stepwise adaptive approach yields
adaptive approach yields the
approach yields the best
yields the best results
the best results when
best results when large
results when large percentages
when large percentages of
large percentages of opportunistic
percentages of opportunistic nodes
of opportunistic nodes are
opportunistic nodes are present
nodes are present in
are present in the
present in the system
it is also simpler
is also simpler than
also simpler than the
simpler than the percentile
antony rowstron and peter
rowstron and peter druschel
since it is based
it is based only
is based only on
based only on samples
only on samples of
on samples of the
samples of the download
of the download rates
the download rates of
download rates of nodes
and routing for large
in both sets of
both sets of experiments
the number of false
number of false positives
of false positives was
false positives was practically
positives was practically null
was practically null under
practically null under all
null under all three
under all three strategies
all three strategies considered
at most one in
most one in some
one in some cases
avg time for transition
we see that turning
see that turning off
auditing costs the overheads
costs the overheads imposed
the overheads imposed by
overheads imposed by auditing
imposed by auditing are
by auditing are an
auditing are an important
of the disks results
are an important consideration
the disks results in
which we address in
we address in this
address in this subsection
most of the work
of the work of
the work of auditing
work of auditing is
of auditing is performed
auditing is performed by
is performed by local
performed by local auditors
which are executed on
are executed on the
executed on the user
on the user nodes
with all the disks
all the disks off
the overhead is constant
independent of the size
of the size of
the size of the
while maintaining acceptable performance
size of the system
and is not significant
since nodes only exchange
correctness of a gossip
nodes only exchange a
of a gossip based
only exchange a small
a gossip based membership
exchange a small amount
gossip based membership protocol
a small amount of
shows some of the
small amount of accounting
some of the tradeoffs
amount of accounting data
of the tradeoffs involved
of accounting data at
accounting data at pre
in proceedings of the
proceedings of the twenty
note that the y
defined intervals of time
fourth annual acm sympo
axis represents three different
represents three different quantities
the cumulative percentage of
cumulative percentage of time
percentage of time the
of time the disks
time the disks are
the disks are powered
disks are powered on
the total duration of
total duration of the
duration of the simulation
if we consider a
we consider a packet
consider a packet rate
a packet rate of
and ma rk jelasity
and the cumulative number
the cumulative number of
cumulative number of mode
a private framework for
private framework for distributed
framework for distributed comsium
transitions that the disks
for distributed comsium on
that the disks undergo
distributed comsium on principles
comsium on principles of
on principles of distributed
principles of distributed computing
seconds the maximum number
the maximum number of
maximum number of packets
number of packets received
both the total duration
of packets received and
the total duration of
packets received and sent
total duration of the
received and sent by
duration of the experiment
and sent by each
sent by each node
by each node is
as well as the
well as the number
as the number of
the number of mode
increase as the percentage
as the percentage of
the percentage of disks
percentage of disks that
of disks that is
disks that is powered
that is powered on
for each packet sent
is powered on is
each packet sent or
powered on is decreased
packet sent or received
the history needs to
history needs to indicate
needs to indicate which
to indicate which neighbor
indicate which neighbor sent
which neighbor sent or
neighbor sent or received
sent or received the
or received the packet
we see that keeping
bits to identify each
to identify each neighbor
the history s size
history s size adds
s size adds up
size adds up to
disks on strikes an
on strikes an acceptable
strikes an acceptable balance
conclusion in this paper
we point out a
point out a new
out a new opportunity
a new opportunity for
new opportunity for saving
opportunity for saving power
for saving power in
saving power in large
the idea is elegant
idea is elegant in
is elegant in its
elegant in its simplicity
this is not significant
is not significant compared
not significant compared to
significant compared to the
compared to the amount
log structured file systems
to the amount of
structured file systems write
the amount of regular
file systems write only
amount of regular data
systems write only to
of regular data exchanged
write only to the
regular data exchanged in
only to the log
data exchanged in a
to the log head
exchanged in a streaming
in a streaming session
we also analyzed the
also analyzed the costs
analyzed the costs of
if read accesses are
the costs of the
read accesses are served
costs of the global
accesses are served by
of the global auditors
are served by the
uniform node sampling service
served by the cache
node sampling service robust
sampling service robust against
service robust against collusions
since they are dedicated
robust against collusions of
they are dedicated and
then write accesses touch
are dedicated and external
against collusions of malicious
dedicated and external to
collusions of malicious nodes
and external to the
write accesses touch only
external to the system
accesses touch only the
touch only the log
only the log head
the log head disk
the overhead imposed by
overhead imposed by them
imposed by them is
by them is of
potentially allowing us to
them is of higher
allowing us to power
is of higher concern
us to power down
to power down all
power down all the
down all the other
all the other disks
global auditors main tasks
auditors main tasks consist
main tasks consist of
existing solutions like disk
tasks consist of sampling
solutions like disk management
consist of sampling the
like disk management solutions
of sampling the system
sampling the system to
the system to collect
system to collect download
to collect download and
collect download and upload
download and upload rates
and upload rates of
ifip international conference on
upload rates of nodes
international conference on dependable
conference on dependable systems
on dependable systems and
dependable systems and networks
and of occasionally disseminating
of occasionally disseminating updates
occasionally disseminating updates to
disseminating updates to the
updates to the threshold
to the threshold value
the sample size remains
sample size remains fixed
size remains fixed independent
remains fixed independent of
fixed independent of the
independent of the size
of the size of
the size of the
size of the population
the working set model
working set model for
set model for program
model for program behavior
we ran simulations to
ran simulations to estimate
simulations to estimate the
to estimate the worst
case standard deviation of
standard deviation of the
deviation of the download
of the download rates
the download rates across
download rates across all
rates across all nodes
we estimate that a
estimate that a sample
that a sample size
a sample size of
nodes is sufficient to
is sufficient to provide
byzantine resilient random membership
resilient random membership sampling
independent of the population
of the population size
in proceedings of the
proceedings of the twenty
seventh acm symposium on
such as the ones
acm symposium on principles
as the ones simulated
symposium on principles of
the ones simulated in
on principles of distributed
ones simulated in this
principles of distributed computing
simulated in this work
even a smaller number
a smaller number of
smaller number of samples
number of samples was
of samples was found
samples was found to
time disks on num
was found to be
found to be sufficient
to be sufficient to
be sufficient to yield
transitions total time of
sufficient to yield satisfactory
total time of run
to yield satisfactory results
centralized costs are fixed
and provide a clear
provide a clear advantage
a clear advantage for
clear advantage for using
advantage for using auditing
for using auditing against
using auditing against tit
tat approaches in large
heterogenous systems so far
systems so far we
so far we considered
improving the performance of
far we considered the
the performance of log
we considered the use
considered the use of
the use of auditing
structured file systems with
use of auditing to
file systems with adaptive
systems with adaptive methods
of auditing to enforce
auditing to enforce node
to enforce node contribution
enforce node contribution in
node contribution in systems
contribution in systems where
in systems where all
systems where all nodes
where all nodes are
all nodes are assumed
nodes are assumed to
are assumed to have
assumed to have homogeneous
to have homogeneous bandwidth
have homogeneous bandwidth resources
enough to upload and
to upload and download
upload and download at
and download at a
download at a rate
at a rate close
a rate close to
rate close to the
close to the stream
to the stream rate
in proceedings of the
proceedings of the acm
of the acm sigcomm
pullbased streaming may be
streaming may be extended
may be extended to
be extended to heterogenous
extended to heterogenous systems
to heterogenous systems by
heterogenous systems by organizing
systems by organizing nodes
by organizing nodes into
organizing nodes into multiple
nodes into multiple groups
managed transactional consistency for
transactional consistency for web
consistency for web caching
for web caching ittay
web caching ittay eyal
caching ittay eyal ken
ittay eyal ken birman
eyal ken birman robbert
ken birman robbert van
birman robbert van renesse
no auditing fixed threshold
robbert van renesse cornell
auditing fixed threshold stepwise
van renesse cornell university
fixed threshold stepwise percentile
renesse cornell university abstract
cornell university abstract in
reducing energy consumption of
energy consumption of disk
consumption of disk storage
of disk storage using
only caches are widely
disk storage using power
caches are widely used
are widely used in
widely used in cloud
avg download factor min
used in cloud infrastructure
download factor min download
in cloud infrastructure to
factor min download factor
cloud infrastructure to reduce
infrastructure to reduce access
to reduce access latency
reduce access latency and
access latency and to
latency and to reduce
and to reduce load
to reduce load on
reduce load on backend
load on backend databases
operators view coherent caches
view coherent caches as
coherent caches as impractical
caches as impractical at
as impractical at genuinely
impractical at genuinely large
at genuinely large scale
genuinely large scale and
large scale and many
scale and many client
facing caches are updated
caches are updated in
are updated in an
updated in an asynchronous
in an asynchronous manner
an asynchronous manner with
asynchronous manner with best
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise percentile
existing solutions that support
solutions that support cache
that support cache consistency
support cache consistency are
cache consistency are inapplicable
consistency are inapplicable to
are inapplicable to this
epidemic algorithms for replicated
inapplicable to this scenario
algorithms for replicated database
to this scenario since
for replicated database maintenance
this scenario since they
scenario since they require
since they require a
they require a round
require a round trip
in proceedings of the
a round trip to
proceedings of the sixth
round trip to the
of the sixth annual
trip to the database
the sixth annual acm
to the database on
sixth annual acm symposium
the database on every
annual acm symposium on
database on every cache
acm symposium on principles
on every cache transaction
symposium on principles of
on principles of distributed
principles of distributed computing
existing incoherent cache technologies
incoherent cache technologies are
cache technologies are oblivious
technologies are oblivious to
are oblivious to transactional
oblivious to transactional data
to transactional data access
even if the backend
if the backend database
the backend database supports
backend database supports transactions
aware cache for read
effect of increasing percentage
of increasing percentage of
increasing percentage of powered
cache improves cache consistency
improves cache consistency despite
cache consistency despite asynchronous
up disks on power
consistency despite asynchronous and
disks on power and
despite asynchronous and unreliable
on power and time
asynchronous and unreliable communication
and unreliable communication between
unreliable communication between the
communication between the cache
between the cache and
and caching solutions are
the cache and the
caching solutions are typically
cache and the database
solutions are typically application
on the other hand
a variant of serializability
variant of serializability that
of serializability that is
serializability that is suitable
is applicable to any
that is suitable for
applicable to any cacheable
is suitable for incoherent
to any cacheable dataset
suitable for incoherent caches
since existing solutions are
and prove that with
existing solutions are typically
prove that with unbounded
upload rate of opportunistic
that with unbounded resources
solutions are typically layered
with unbounded resources t
rate of opportunistic nodes
are typically layered on
typically layered on top
layered on top of
on top of the
top of the file
they could be used
could be used in
be used in conjunction
used in conjunction with
cache allows the system
in conjunction with our
allows the system manager
conjunction with our solution
the system manager to
with our solution to
system manager to choose
our solution to take
manager to choose a
solution to take advantage
to choose a trade
to take advantage of
take advantage of application
off between performance and
between performance and consistency
in lecture notes in
lecture notes in computer
notes in computer science
we also provide some
our evaluation shows that
also provide some initial
evaluation shows that t
provide some initial simulation
some initial simulation results
initial simulation results that
simulation results that validate
results that validate our
cache detects many inconsistencies
that validate our claim
detects many inconsistencies with
validate our claim that
many inconsistencies with only
our claim that power
inconsistencies with only nominal
with only nominal overhead
savings are possible using
are possible using a
we use synthetic workloads
possible using a log
use synthetic workloads to
synthetic workloads to demonstrate
workloads to demonstrate the
to demonstrate the efficacy
demonstrate the efficacy of
the efficacy of t
while simulations can never
cache when data accesses
simulations can never provide
when data accesses are
can never provide conclusive
data accesses are clustered
never provide conclusive evidence
accesses are clustered and
provide conclusive evidence for
are clustered and its
conclusive evidence for the
clustered and its adaptive
evidence for the feasibility
and its adaptive reaction
for the feasibility of
its adaptive reaction to
the feasibility of a
adaptive reaction to workload
feasibility of a system
reaction to workload changes
they are an effective
with workloads based on
are an effective means
workloads based on the
an effective means to
based on the real
effective means to identify
means to identify promising
to identify promising solutions
our principal contribution in
principal contribution in this
contribution in this paper
in this paper is
this paper is in
paper is in having
is in having shown
in having shown a
having shown a new
shown a new fit
a new fit for
new fit for an
fit for an old
for an old idea
upload rate of opportunistic
rate of opportunistic nodes
we believe that the
believe that the log
structured file system shows
file system shows promise
of the inconsistencies and
system shows promise as
the inconsistencies and increases
shows promise as a
inconsistencies and increases the
promise as a powersaving
and increases the rate
as a powersaving opportunity
increases the rate of
a powersaving opportunity for
the rate of consistent
powersaving opportunity for large
rate of consistent transactions
of consistent transactions by
minimum and average download
and average download factors
average download factors across
download factors across all
factors across all correct
across all correct nodes
all correct nodes when
acknowledgments this work was
correct nodes when using
this work was partially
nodes when using different
work was partially funded
when using different strategies
was partially funded by
using different strategies for
partially funded by intel
different strategies for choosing
funded by intel corporation
strategies for choosing the
by intel corporation and
for choosing the threshold
intel corporation and the
corporation and the national
and the national science
the national science foundation
the upload contribution rate
upload contribution rate of
contribution rate of opportunistic
rate of opportunistic nodes
special thanks to saikat
of opportunistic nodes is
thanks to saikat guha
opportunistic nodes is varied
to saikat guha for
nodes is varied in
saikat guha for his
is varied in the
guha for his input
varied in the x
i ntroduction internet services
for his input in
ntroduction internet services like
his input in the
internet services like online
input in the simulator
services like online retailers
in the simulator design
like online retailers and
online retailers and social
and the number of
retailers and social networks
the number of opportunistic
and social networks store
number of opportunistic nodes
social networks store important
we also wish to
networks store important data
of opportunistic nodes is
store important data sets
opportunistic nodes is fixed
important data sets in
nodes is fixed at
also wish to thank
data sets in large
wish to thank our
sets in large distributed
to thank our anonymous
in large distributed databases
thank our anonymous reviewers
our anonymous reviewers for
anonymous reviewers for their
reviewers for their valuable
for their valuable feedback
technical challenges have forced
challenges have forced such
have forced such large
avg download factor min
system operators to forgo
download factor min download
operators to forgo transactional
factor min download factor
to forgo transactional consistency
providing perobject consistency instead
often with some form
with some form of
some form of eventual
form of eventual consistency
conserving disk energy in
disk energy in network
energy in network servers
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise percentile
th international conference on
international conference on supercomputing
based fast overlay topology
fast overlay topology construction
support transactions with guarantees
transactions with guarantees such
with guarantees such as
guarantees such as snapshot
such as snapshot isolation
as snapshot isolation and
snapshot isolation and even
isolation and even full
and even full transactional
even full transactional atomicity
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise percentile
our work begins with
work begins with the
begins with the observation
with the observation that
it can be difficult
the case for massive
can be difficult for
case for massive arrays
be difficult for client
for massive arrays of
massive arrays of idle
arrays of idle disks
tier applications to leverage
applications to leverage the
to leverage the transactions
leverage the transactions that
the transactions that the
transactions that the databases
that the databases provide
their reads are satisfied
reads are satisfied primarily
are satisfied primarily from
satisfied primarily from incoherent
primarily from incoherent cache
the benefits of caching
benefits of caching are
of caching are twofold
conference on file and
on file and storage
file and storage technologies
it reduces database load
thereby enabling higher throughput
the caches are typically
caches are typically placed
are typically placed close
typically placed close to
placed close to the
close to the clients
and maarten van steen
the problem centers on
problem centers on the
centers on the asynchronous
on the asynchronous style
the asynchronous style of
asynchronous style of communication
style of communication used
of communication used between
communication used between the
used between the database
between the database and
the database and the
database and the geo
helping disk arrays sleep
disk arrays sleep through
arrays sleep through the
sleep through the winter
a cache should not
cache should not access
should not access the
not access the database
access the database on
the database on every
database on every transaction
any approach requiring a
approach requiring a high
requiring a high rate
a high rate of
high rate of round
proceedings of the twentieth
of the twentieth acm
the twentieth acm symposium
twentieth acm symposium on
acm symposium on operating
trips to an authoritative
symposium on operating systems
to an authoritative backend
on operating systems principles
an authoritative backend database
authoritative backend database would
backend database would cause
database would cause unacceptable
would cause unacceptable latency
a cache must respond
cache must respond instantly
and asynchronous updates rule
asynchronous updates rule out
updates rule out cache
rule out cache coherency
out cache coherency schemes
cache coherency schemes that
coherency schemes that would
schemes that would require
that would require the
would require the backend
require the backend database
the backend database to
backend database to promptly
database to promptly invalidate
to promptly invalidate or
promptly invalidate or update
invalidate or update cached
or update cached this
update cached this work
cached this work is
this work is supported
interplay of energy and
of energy and performance
energy and performance for
and performance for disk
performance for disk arrays
for disk arrays running
disk arrays running transaction
by a grant from
arrays running transaction processing
a grant from the
running transaction processing workloads
grant from the darpa
from the darpa mrc
the darpa mrc program
in ieee international symposium
ieee international symposium on
international symposium on performance
symposium on performance analysis
on performance analysis of
performance analysis of systems
or even to track
analysis of systems and
even to track the
of systems and software
to track the locations
track the locations at
the locations at which
locations at which cached
at which cached objects
which cached objects reside
we define a variant
define a variant of
a variant of serializability
variant of serializability called
of serializability called cacheserializability
serializability called cacheserializability that
called cacheserializability that is
cacheserializability that is suitable
that is suitable for
is suitable for incoherent
suitable for incoherent caches
a wide range of
wide range of web
range of web applications
from social networks to
social networks to online
networks to online retailers
ratio of freeloaders figure
settle for caches that
for caches that are
caches that are oblivious
that are oblivious to
are oblivious to transactions
despite the fact that
the fact that an
fact that an inconsistent
minimum and average download
that an inconsistent read
and average download factors
an inconsistent read access
average download factors across
inconsistent read access can
download factors across all
read access can deter
factors across all correct
access can deter a
across all correct nodes
can deter a client
all correct nodes when
deter a client and
correct nodes when using
a client and reduce
nodes when using different
client and reduce their
when using different strategies
and reduce their income
reducing disk power consumption
using different strategies for
disk power consumption in
different strategies for choosing
power consumption in servers
strategies for choosing the
consumption in servers with
for choosing the threshold
in servers with drpm
they cannot afford consistent
cannot afford consistent cache
afford consistent cache techniques
consistent cache techniques that
each session has mixed
cache techniques that require
session has mixed set
techniques that require backend
has mixed set of
that require backend accesses
mixed set of opportunistic
require backend accesses on
set of opportunistic nodes
backend accesses on every
accesses on every transaction
contributing at different rates
and percentage of opportunistic
percentage of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is varied
nodes is varied on
is varied on the
a novel caching scheme
varied on the x
novel caching scheme that
caching scheme that improves
scheme that improves consistency
that improves consistency at
improves consistency at the
consistency at the cache
at the cache level
the cache level with
to their upload bandwidths
cache level with a
level with a nominal
with a nominal storage
a nominal storage and
nominal storage and communication
storage and communication tradeoff
nodes able to upload
able to upload at
to upload at a
upload at a rate
at a rate higher
a rate higher than
rate higher than the
higher than the stream
than the stream rate
hiding in plain sight
the stream rate are
cache significantly improves consistency
stream rate are placed
significantly improves consistency for
rate are placed in
improves consistency for workloads
are placed in higher
google seeks more power
consistency for workloads where
for workloads where data
workloads where data accesses
where data accesses are
data accesses are clustered
in the new york
the new york times
which are closer to
which is common in
are closer to the
is common in today
closer to the source
common in today s
in today s large
the source sends data
source sends data to
sends data to the
data to the highest
to the highest level
this is achieved while
the highest level group
is achieved while retaining
highest level group only
achieved while retaining the
while retaining the global
retaining the global scalability
the global scalability afforded
global scalability afforded by
who uses the basic
scalability afforded by executing
uses the basic protocol
afforded by executing read
the basic protocol to
basic protocol to disseminate
protocol to disseminate data
to disseminate data among
disseminate data among each
data among each other
only transactions on the
transactions on the edge
nodes in lower levels
in lower levels may
directly from the cache
lower levels may receive
levels may receive data
may receive data at
receive data at smaller
data at smaller rates
we do this by
do this by storing
this by storing dependency
by storing dependency information
after some filtering is
storing dependency information with
some filtering is applied
dependency information with the
information with the cached
with the cached objects
level nodes may be
nodes may be used
berkeley db java edition
may be used to
db java edition architecture
be used to act
used to act as
to act as sources
act as sources to
to identify possible inconsistencies
as sources to the
an oracle white paper
sources to the lower
identify possible inconsistencies without
possible inconsistencies without contacting
inconsistencies without contacting the
without contacting the database
the user can improve
alleviating the burden at
user can improve the
the burden at the
can improve the level
burden at the source
improve the level of
the level of consistency
level of consistency by
of consistency by adjusting
consistency by adjusting the
auditing can be used
by adjusting the size
can be used to
adjusting the size of
be used to avoid
the size of this
used to avoid the
size of this dependency
to avoid the presence
of this dependency data
avoid the presence of
the presence of opportunistic
presence of opportunistic and
of opportunistic and lower
opportunistic and lower bandwidth
more dependency data leads
and lower bandwidth nodes
dependency data leads to
lower bandwidth nodes in
data leads to increased
bandwidth nodes in the
leads to increased consistency
nodes in the higher
to demonstrate the efficacy
demonstrate the efficacy of
the efficacy of the
efficacy of the proposed
of the proposed scheme
it can ensure that
can ensure that the
ensure that the hierarchy
that the hierarchy of
the hierarchy of nodes
we created a prototype
hierarchy of nodes is
created a prototype implementation
of nodes is obeyed
a prototype implementation and
nodes is obeyed by
prototype implementation and exposed
is obeyed by all
implementation and exposed it
obeyed by all nodes
and exposed it to
exposed it to workloads
it to workloads based
to workloads based on
workloads based on graphically
while allowing the system
allowing the system to
the system to leverage
system to leverage additional
to leverage additional resources
leverage additional resources from
additional resources from privileged
resources from privileged altruistic
from privileged altruistic nodes
privileged altruistic nodes to
such as those seen
altruistic nodes to forward
as those seen in
nodes to forward data
those seen in social
to forward data to
forward data to lower
data to lower level
eduardo pinheiro and ricardo
to lower level groups
pinheiro and ricardo bianchini
we intend to explore
energy conservation techniques for
intend to explore this
conservation techniques for disk
to explore this further
techniques for disk array
explore this further in
this further in future
further in future work
related work several p
of the inconsistencies and
the inconsistencies and can
inconsistencies and can increase
and can increase the
can increase the ratio
streaming protocols have been
increase the ratio of
protocols have been previously
the ratio of consistent
have been previously proposed
ratio of consistent transactions
of consistent transactions by
th annual international conference
annual international conference on
international conference on supercomputing
the first generation of
first generation of systems
relied on approaches based
both with low overhead
on approaches based on
approaches based on pushing
based on pushing data
on pushing data through
pushing data through a
we construct synthetic workloads
data through a single
construct synthetic workloads and
through a single dissemination
synthetic workloads and observe
a single dissemination tree
workloads and observe how
and observe how t
later approaches focused on
cache reacts to different
approaches focused on improving
reacts to different clustering
focused on improving fairness
to different clustering levels
on improving fairness among
different clustering levels and
improving fairness among peers
clustering levels and how
fairness among peers and
levels and how it
among peers and resilience
and how it adapts
peers and resilience to
how it adapts as
characteristics of file system
it adapts as clusters
of file system workloads
adapts as clusters change
and resilience to churn
resilience to churn by
to churn by breaking
churn by breaking data
by breaking data into
with perfectly clustered workloads
breaking data into multiple
data into multiple substreams
into multiple substreams and
multiple substreams and sending
substreams and sending them
and sending them along
sending them along disjoing
them along disjoing paths
cache implements full cache
to explain this perfect
explain this perfect behavior
this perfect behavior we
perfect behavior we prove
behavior we prove a
we prove a related
prove a related claim
a related claim we
related claim we show
claim we show that
we show that with
show that with unbounded
that with unbounded resources
with unbounded resources t
more recent systems like
recent systems like coolstreaming
mendel rosenblum and john
rosenblum and john k
the design and implementation
based style of data
design and implementation of
style of data dissemination
and implementation of a
the contributions of this
implementation of a log
contributions of this work
of this work are
coolstreaming breaks the data
breaks the data into
the data into packets
acm transactions on computer
and peers organized into
transactions on computer systems
peers organized into a
organized into a mesh
into a mesh request
a mesh request packets
mesh request packets from
request packets from their
packets from their neighbors
from their neighbors using
their neighbors using a
neighbors using a scheduling
using a scheduling algorithm
a variant of serializability
variant of serializability suitable
of serializability suitable for
serializability suitable for incoherent
as we saw earlier
suitable for incoherent caches
chainsaw uses a simpler
uses a simpler policy
a simpler policy for
simpler policy for requesting
policy for requesting packets
randomly fetching them while
fetching them while respecting
them while respecting a
while respecting a maximum
respecting a maximum limit
a maximum limit on
maximum limit on the
which allows trading off
limit on the number
allows trading off efficiency
on the number of
trading off efficiency and
the number of outstanding
off efficiency and transaction
number of outstanding requests
of outstanding requests to
outstanding requests to each
requests to each neighbor
consistency in large scale
in large scale cache
large scale cache deployments
chainsaw presents smaller delays
presents smaller delays for
smaller delays for the
delays for the receipt
for the receipt of
the receipt of packets
receipt of packets compared
of packets compared to
packets compared to the
compared to the coolstreaming
to the coolstreaming protocol
in a more recent
cache with synthetic workloads
a more recent work
demonstrating its adaptivity and
its adaptivity and sensitivity
adaptivity and sensitivity to
and sensitivity to clustering
based approaches are shown
approaches are shown to
are shown to present
shown to present better
to present better performance
present better performance over
better performance over tree
cache with workloads based
with workloads based on
workloads based on graphically
previous papers have considered
papers have considered a
have considered a variety
considered a variety of
a variety of possible
world data demonstrating detection
variety of possible mechanisms
data demonstrating detection rates
of possible mechanisms to
demonstrating detection rates of
possible mechanisms to encourage
disk layout optimization for
mechanisms to encourage node
layout optimization for reducing
to encourage node contribution
optimization for reducing energy
for reducing energy consumption
is a framework proposed
a framework proposed to
framework proposed to enforce
proposed to enforce download
to enforce download rate
enforce download rate limitations
download rate limitations on
and consistency improvements of
rate limitations on p
p media streaming systems
th annual international conference
annual international conference on
international conference on supercomputing
the protocol relies on
protocol relies on a
relies on a set
on a set of
a set of trusted
set of trusted nodes
of trusted nodes that
trusted nodes that store
nodes that store information
that store information on
store information on the
information on the data
on the data downloaded
the data downloaded by
data downloaded by each
downloaded by each node
by each node receiving
each node receiving data
nodes only send an
only send an object
cache with unbounded resources
send an object after
with unbounded resources implements
an object after consulting
unbounded resources implements cache
object after consulting the
after consulting the trusted
consulting the trusted nodes
the trusted nodes to
trusted nodes to verify
nodes to verify if
to verify if the
verify if the nodes
if the nodes requesting
the nodes requesting the
nodes requesting the stream
requesting the stream are
the stream are not
stream are not overrequesting
are not overrequesting data
the complexity of implementing
complexity of implementing geo
it is targeted to
is targeted to systems
targeted to systems where
scale databases with strong
to systems where nodes
databases with strong guarantees
systems where nodes upload
with strong guarantees initially
where nodes upload full
strong guarantees initially led
nodes upload full media
guarantees initially led companies
upload full media objects
initially led companies to
full media objects from
led companies to abandon
media objects from each
companies to abandon cross
objects from each other
object consistency altogether and
and not for live
consistency altogether and make
altogether and make do
and make do with
make do with weak
do with weak guarantees
with weak guarantees such
streaming systems where all
weak guarantees such as
systems where all nodes
guarantees such as per
where all nodes are
all nodes are interested
nodes are interested in
are interested in receiving
object atomicity or eventual
interested in receiving the
atomicity or eventual consistency
in receiving the exact
receiving the exact same
the exact same data
exact same data in
same data in close
data in close to
in close to real
close to real time
such systems do repair
systems do repair any
do repair any problems
repair any problems that
any problems that arise
consider fairness issues in
fairness issues in the
issues in the context
in the context of
user is sometimes exposed
the context of tree
is sometimes exposed to
sometimes exposed to inconsistency
for some applications this
some applications this is
applications this is acceptable
and the approach has
the approach has been
approach has been surprisingly
has been surprisingly successful
the authors present mechanisms
authors present mechanisms that
present mechanisms that rank
mechanisms that rank peers
in today s cloud
that rank peers according
rank peers according to
peers according to their
according to their level
to their level of
relaxed consistency is something
their level of cooperation
consistency is something of
level of cooperation with
is something of a
of cooperation with the
something of a credo
cooperation with the system
one of their techniques
of their techniques involves
their techniques involves the
techniques involves the reconstruction
involves the reconstruction of
the reconstruction of trees
reconstruction of trees as
of trees as a
trees as a way
as a way of
a way of punishing
way of punishing opportunistic
of punishing opportunistic nodes
most of their mechanisms
of their mechanisms require
their mechanisms require peers
mechanisms require peers to
require peers to keep
only transactions by accessing
peers to keep track
transactions by accessing caches
to keep track of
keep track of their
track of their parents
of their parents and
their parents and children
parents and children s
which receive their values
and children s behavior
receive their values by
their values by reading
values by reading from
by reading from the
reading from the database
studied the effect of
the effect of different
effect of different types
of different types of
different types of incentives
types of incentives on
of incentives on the
incentives on the chainsaw
on the chainsaw protocol
update transactions go directly
transactions go directly to
go directly to the
directly to the database
subsequent cache invalidations can
cache invalidations can be
invalidations can be delayed
can be delayed or
be delayed or even
tat and some variations
delayed or even lost
or even lost due
even lost due to
lost due to race
due to race conditions
the authors propose an
authors propose an algorithm
propose an algorithm that
an algorithm that sets
algorithm that sets up
leading to a potentially
that sets up local
to a potentially inconsistent
sets up local markets
a potentially inconsistent view
up local markets at
potentially inconsistent view by
local markets at every
inconsistent view by the
markets at every node
view by the cache
by the cache clients
where neighbors compete for
neighbors compete for the
compete for the node
for the node s
the node s upload
node s upload capacity
nodes favor neighbors who
favor neighbors who contribute
neighbors who contribute more
large internet services store
internet services store vast
services store vast amounts
with nodes classified as
store vast amounts of
nodes classified as fast
vast amounts of data
classified as fast or
as fast or slow
fast or slow nodes
online retailers such as
retailers such as amazon
the results indicate that
such as amazon and
results indicate that the
as amazon and ebay
indicate that the proposed
amazon and ebay maintain
that the proposed algorithm
and ebay maintain product
the proposed algorithm improves
ebay maintain product stocks
proposed algorithm improves the
maintain product stocks and
algorithm improves the performance
product stocks and information
improves the performance of
the performance of the
performance of the system
of the system when
the system when the
and social networking sites
system when the total
social networking sites such
when the total upload
networking sites such as
the total upload capacity
sites such as facebook
total upload capacity is
such as facebook and
upload capacity is not
as facebook and twitter
capacity is not enough
facebook and twitter maintain
is not enough to
and twitter maintain graphical
not enough to supply
twitter maintain graphical databases
enough to supply all
maintain graphical databases representing
to supply all the
graphical databases representing user
supply all the nodes
databases representing user relations
representing user relations and
user relations and group
relations and group structures
streaming system where nodes
system where nodes choose
where nodes choose their
nodes choose their neighbors
such databases are sharded
choose their neighbors based
databases are sharded and
their neighbors based on
are sharded and replicated
neighbors based on their
based on their history
on their history of
their history of interaction
a scalable services architecture
the vast majority of
scalable services architecture tudor
vast majority of accesses
nodes are placed in
services architecture tudor marian
are placed in the
majority of accesses are
placed in the system
of accesses are read
in the system according
architecture tudor marian ken
the system according to
tudor marian ken birman
system according to their
marian ken birman department
according to their current
ken birman department of
to their current trading
birman department of computer
their current trading performances
department of computer science
of computer science cornell
computer science cornell university
encouraging nodes to contribute
nodes to contribute more
to contribute more and
contribute more and therefore
more and therefore be
and therefore be closer
therefore be closer to
be closer to the
closer to the source
is a more recent
a more recent live
streaming approach that tolerates
approach that tolerates the
that tolerates the existence
tolerates the existence of
the existence of opportunistic
existence of opportunistic and
of opportunistic and malicious
opportunistic and malicious nodes
time is divided into
is divided into rounds
in which each peer
which each peer communicates
each peer communicates with
peer communicates with another
communicates with another peer
with another peer selected
another peer selected using
peer selected using a
to reduce database load
selected using a pseudo
reduce database load and
database load and to
load and to reduce
and to reduce access
to reduce access latency
edu abstract data centers
these companies employ a
abstract data centers constructed
companies employ a twotier
data centers constructed as
peers exchange their current
employ a twotier structure
centers constructed as clusters
exchange their current history
constructed as clusters of
their current history containing
as clusters of inexpensive
current history containing the
clusters of inexpensive machines
history containing the identifiers
of inexpensive machines have
containing the identifiers of
inexpensive machines have compelling
placing layers of cache
machines have compelling cost
the identifiers of all
layers of cache servers
identifiers of all the
of cache servers in
of all the current
cache servers in front
all the current data
servers in front of
the current data they
in front of the
current data they hold
front of the database
but developing services to
developing services to run
as basis for the
services to run on
basis for the next
to run on them
for the next exchanges
run on them can
on them can be
them can be challenging
nodes also perform a
also perform a phase
perform a phase of
a phase of optimistic
this paper reports on
phase of optimistic push
paper reports on a
the caches of primary
reports on a new
caches of primary interest
on a new framework
of primary interest to
forwarding useful updates to
primary interest to us
useful updates to pseudo
interest to us are
to us are typically
the scalable services architecture
us are typically situated
are typically situated far
randomly picked peers with
typically situated far from
picked peers with no
situated far from the
peers with no guarantee
far from the backend
with no guarantee of
from the backend database
no guarantee of useful
the backend database systems
guarantee of useful return
backend database systems to
database systems to reduce
systems to reduce latency
which helps developers develop
helps developers develop scalable
developers develop scalable clustered
develop scalable clustered applications
companies place caches close
place caches close to
caches close to clients
the work is focused
conclusion we propose and
work is focused on
timeouts are used to
is focused on nontransactional
we propose and evaluate
focused on nontransactional high
are used to ensure
propose and evaluate a
used to ensure that
and evaluate a scalable
to ensure that stale
evaluate a scalable auditing
ensure that stale cached
that stale cached objects
stale cached objects will
cached objects will eventually
objects will eventually be
based technique for enforcing
these are poorly supported
will eventually be flushed
are poorly supported in
technique for enforcing fairness
poorly supported in existing
for enforcing fairness in
supported in existing platforms
enforcing fairness in a
fairness in a live
but to achieve a
to achieve a high
achieve a high cache
a high cache hit
a primary goal was
high cache hit ratio
primary goal was to
goal was to keep
was to keep the
to keep the ssa
our approach employs local
keep the ssa as
timeout values are generally
the ssa as small
values are generally large
ssa as small and
approach employs local auditors
as small and simple
employs local auditors that
small and simple as
local auditors that execute
and simple as possible
auditors that execute on
to obtain reasonable consistency
that execute on all
execute on all nodes
on all nodes in
all nodes in a
key elements include a
nodes in a streaming
elements include a tcp
the database sends an
in a streaming session
database sends an asynchronous
sends an asynchronous stream
based chain replication mechanism
an asynchronous stream of
chain replication mechanism and
they are responsible for
replication mechanism and a
asynchronous stream of invalidation
are responsible for collecting
stream of invalidation records
mechanism and a gossip
of invalidation records or
responsible for collecting auditable
invalidation records or cache
for collecting auditable information
records or cache updates
collecting auditable information about
auditable information about other
based subsystem for managing
information about other neighbors
subsystem for managing configuration
about other neighbors data
for managing configuration data
often using protocols optimized
managing configuration data and
other neighbors data exchanges
configuration data and repairing
using protocols optimized for
data and repairing inconsistencies
protocols optimized for throughput
and repairing inconsistencies after
optimized for throughput and
repairing inconsistencies after faults
and for verifying that
for throughput and freshness
for verifying that neighbors
throughput and freshness and
verifying that neighbors upload
and freshness and lacking
that neighbors upload more
freshness and lacking absolute
neighbors upload more data
and lacking absolute guarantees
upload more data than
our experimental results confirm
more data than a
lacking absolute guarantees of
data than a specified
experimental results confirm the
than a specified threshold
absolute guarantees of order
results confirm the effectiveness
guarantees of order or
confirm the effectiveness of
of order or reliability
the effectiveness of the
effectiveness of the approach
this threshold is defined
threshold is defined by
is defined by dedicated
defined by dedicated global
by dedicated global auditors
it is difficult to
introduction large computing systems
which periodically sample the
is difficult to make
large computing systems are
difficult to make this
periodically sample the state
to make this invalidation
computing systems are often
make this invalidation mechanism
sample the state of
this invalidation mechanism reliable
systems are often structured
invalidation mechanism reliable without
are often structured as
mechanism reliable without hampering
often structured as service
reliable without hampering database
structured as service oriented
without hampering database efficiency
as service oriented architectures
the state of the
state of the system
of the system to
the system to determine
the issues are many
system to determine if
to determine if the
determine if the overall
if the overall download
the overall download rate
overall download rate is
download rate is compromised
for example using web
rate is compromised by
example using web services
is compromised by the
using web services platforms
compromised by the presence
the databases are large
by the presence of
the presence of opportunistic
presence of opportunistic nodes
residing on many servers
global auditing determines the
clients access services in
auditing determines the minimum
access services in a
determines the minimum threshold
services in a request
the minimum threshold for
minimum threshold for uploads
and works with local
databases use locks prudently
works with local auditing
each service is self
with local auditing to
use locks prudently in
local auditing to punish
locks prudently in order
auditing to punish nodes
prudently in order to
to punish nodes that
in order to maximize
punish nodes that do
order to maximize concurrency
nodes that do not
offers its own api
that do not upload
do not upload enough
not upload enough data
to the extent that
and handles its own
the extent that the
handles its own quality
extent that the database
we study the efficiency
its own quality of
study the efficiency of
own quality of service
the efficiency of our
quality of service or
efficiency of our auditing
of service or availability
of our auditing approach
service or availability guarantees
our auditing approach through
that the database keeps
auditing approach through simulation
the database keeps track
database keeps track of
keeps track of the
for example by arranging
track of the caches
example by arranging to
of the caches that
by arranging to be
and show that it
arranging to be restarted
the caches that hold
to be restarted after
caches that hold a
be restarted after a
that hold a copy
restarted after a failure
hold a copy of
show that it is
a copy of each
copy of each object
that it is able
it is able to
while many services need
is able to maintain
many services need to
able to maintain the
services need to maintain
to maintain the throughput
it may be possible
need to maintain availability
maintain the throughput of
may be possible to
to maintain availability in
be possible to send
the throughput of the
possible to send an
maintain availability in the
throughput of the streaming
to send an invalidation
availability in the face
of the streaming system
in the face of
the streaming system even
the face of challenging
streaming system even in
face of challenging operating
system even in the
but tracking the state
of challenging operating conditions
even in the presence
tracking the state of
in the presence of
the state of caches
the presence of a
state of caches is
presence of a large
of caches is complicated
of a large number
caches is complicated and
a large number of
is complicated and hence
large number of opportunistic
complicated and hence if
number of opportunistic nodes
and hence if they
hence if they are
if they are used
they are used at
are used at all
such systems view invalidations
systems view invalidations as
view invalidations as a
invalidations as a kind
building services with these
as a kind of
services with these properties
a kind of hint
with these properties is
these properties is difficult
they could be delayed
existing web services platforms
web services platforms offer
services platforms offer load
balancing and restart mechanisms
and restart mechanisms for
restart mechanisms for transactional
mechanisms for transactional services
for transactional services implemented
transactional services implemented using
services implemented using a
implemented using a three
due to buffering or
to buffering or retransmissions
buffering or retransmissions after
or retransmissions after message
retransmissions after message loss
but not for services
not for services implemented
for services implemented using
a case for end
services implemented using other
case for end system
implemented using other technologies
for end system multicast
developers of nontransactional web
of nontransactional web services
nontransactional web services must
web services must implement
services must implement their
must implement their own
implement their own mechanisms
their own mechanisms for
own mechanisms for replicating
mechanisms for replicating data
due to an inaccurate
to an inaccurate list
an inaccurate list of
inaccurate list of locations
tracking membership and live
membership and live this
and live this work
live this work was
this work was supported
work was supported by
was supported by darpa
ipto under the srs
under the srs program
the srs program and
srs program and by
program and by the
and by the rome
by the rome air
the rome air force
rome air force research
air force research laboratory
due to a system
to a system configuration
a system configuration change
under the prometheus program
or because of races
because of races between
of races between reads
additional support was provided
support was provided by
was provided by the
provided by the nsf
a missing invalidation obviously
robbert van renesse ness
missing invalidation obviously leaves
invalidation obviously leaves the
obviously leaves the corresponding
leaves the corresponding cache
the corresponding cache entry
redirecting requests during failures
corresponding cache entry stale
requests during failures to
during failures to minimize
failures to minimize client
to minimize client disruption
pitfalls of such invalidation
of such invalidation schemes
such invalidation schemes are
and detecting and repairing
invalidation schemes are described
detecting and repairing inconsistencies
schemes are described in
are described in detail
described in detail by
in detail by nishita
detail by nishita et
by nishita et al
our premise in this
premise in this paper
in this paper is
this paper is that
paper is that for
is that for many
that for many services
the transactional model is
transactional model is a
model is a poor
is a poor fit
a poor fit and
poor fit and hence
fit and hence that
and by bronson et
and hence that tools
by bronson et al
hence that tools aimed
reliable multicasting with an
that tools aimed at
multicasting with an overlay
tools aimed at non
with an overlay network
transactional web services systems
web services systems will
services systems will be
systems will be needed
we recognize that this
th symposium on operating
recognize that this is
symposium on operating systems
that this is debatable
on operating systems design
operating systems design and
but forgoing transactional consistency
systems design and implementation
forgoing transactional consistency can
transactional consistency can result
vendors have generally argued
consistency can result in
have generally argued that
can result in undesired
generally argued that only
result in undesired behavior
argued that only transactional
in undesired behavior of
that only transactional systems
undesired behavior of a
only transactional systems offer
behavior of a service
transactional systems offer the
systems offer the hooks
offer the hooks needed
the hooks needed to
hooks needed to support
needed to support automated
consider a buyer at
to support automated scalability
a buyer at an
buyer at an online
at an online site
an online site who
online site who looks
site who looks for
who looks for a
repair and restart mechanisms
looks for a toy
for a toy train
a toy train with
toy train with its
key to this argument
train with its matching
to this argument is
with its matching tracks
this argument is the
its matching tracks just
argument is the ease
matching tracks just as
is the ease with
tracks just as the
the ease with which
just as the vendor
ease with which interrupted
as the vendor is
with which interrupted transactions
the vendor is adding
which interrupted transactions can
vendor is adding them
interrupted transactions can be
is adding them to
transactions can be rolled
adding them to the
can be rolled back
them to the database
the client may see
client may see only
may see only the
see only the train
only the train in
the train in stock
train in stock but
and the relative simplicity
in stock but not
the relative simplicity of
stock but not the
relative simplicity of cleaning
but not the tracks
simplicity of cleaning up
not the tracks because
of cleaning up a
the tracks because the
cleaning up a database
tracks because the product
up a database after
because the product insertion
a database after a
the product insertion transaction
database after a crash
product insertion transaction would
insertion transaction would often
transaction would often be
would often be broken
often be broken into
yet the transactional programming
be broken into two
the transactional programming model
broken into two or
transactional programming model also
into two or more
programming model also brings
two or more atomic
model also brings constraints
or more atomic but
also brings constraints and
more atomic but independent
brings constraints and overheads
atomic but independent subtransactions
were this not the
in a social network
this not the case
an inconsistency with unexpected
the transactional model would
inconsistency with unexpected results
transactional model would long
with unexpected results can
model would long ago
unexpected results can occur
highbandwidth content distribution in
would long ago have
content distribution in cooperative
long ago have become
distribution in cooperative environments
results can occur if
ago have become universal
can occur if a
occur if a user
if a user x
a user x s
user x s record
x s record says
some of these constraints
s record says it
of these constraints relate
record says it belongs
these constraints relate to
says it belongs to
constraints relate to the
it belongs to a
relate to the challenges
belongs to a certain
to the challenges of
to a certain group
th acm symposium on
the challenges of maintaining
acm symposium on operating
challenges of maintaining a
symposium on operating systems
of maintaining a clean
on operating systems principles
maintaining a clean separation
but that group s
a clean separation of
that group s record
clean separation of code
group s record does
separation of code and
s record does not
of code and data
record does not include
does not include x
not all applications can
all applications can be
web albums maintain picture
applications can be structured
albums maintain picture data
can be structured in
maintain picture data and
be structured in this
picture data and access
structured in this manner
data and access control
and access control lists
transactional rollback and restart
rollback and restart can
and restart can be
restart can be costly
and it is important
it is important that
is important that acl
and restarting a database
important that acl and
restarting a database after
that acl and album
a database after a
acl and album updates
database after a crash
and album updates are
after a crash incurs
album updates are consistent
a crash incurs delays
crash incurs delays while
incurs delays while cleanup
delays while cleanup code
while cleanup code runs
the classical example involves
classical example involves removing
example involves removing one
high availability is difficult
involves removing one s
availability is difficult to
removing one s boss
is difficult to acheive
one s boss from
difficult to acheive in
s boss from the
to acheive in the
boss from the album
acheive in the transactional
from the album acl
in the transactional model
the album acl and
album acl and then
acl and then adding
and then adding unflattering
then adding unflattering pictures
the fastest database replication
fastest database replication schemes
while many of these
many of these systems
of these systems make
suffer from failure scenarios
these systems make do
from failure scenarios that
systems make do with
failure scenarios that can
make do with weak
scenarios that can require
do with weak consistency
that can require intervention
can require intervention by
require intervention by a
intervention by a human
by a human operator
their utility is reduced
utility is reduced when
is reduced when their
reduced when their clients
when their clients observe
yet the higher fidelity
their clients observe inconsistencies
the higher fidelity schemes
higher fidelity schemes require
fidelity schemes require expensive
schemes require expensive multi
there has been a
has been a wave
been a wave of
a wave of recent
phase commit protocols and
wave of recent innovations
commit protocols and hence
of recent innovations within
protocols and hence may
recent innovations within the
and hence may not
innovations within the backend
eliminating trees from overlay
hence may not give
trees from overlay multicast
may not give adequate
not give adequate performance
offering scalable object stores
scalable object stores that
object stores that can
stores that can efficiently
th international workshop on
that can efficiently support
international workshop on peer
clustered threetier database products
can efficiently support transactions
threetier database products are
efficiently support transactions through
database products are powerful
support transactions through snapshot
products are powerful solutions
transactions through snapshot isolation
through snapshot isolation and
snapshot isolation and even
isolation and even full
and even full atomicity
but they negotiate these
they negotiate these potential
negotiate these potential pitfalls
these potential pitfalls in
potential pitfalls in ways
pitfalls in ways that
in ways that preclude
ways that preclude important
that preclude important classes
preclude important classes of
important classes of applications
our motivation is to
motivation is to show
is to show that
to show that a
show that a simple
that a simple and
a simple and remarkably
simple and remarkably inexpensive
and remarkably inexpensive infrastructure
remarkably inexpensive infrastructure can
inexpensive infrastructure can support
infrastructure can support clustered
can support clustered execution
support clustered execution of
clustered execution of a
execution of a significant
of a significant class
a significant class of
significant class of non
the work reported here
work reported here focuses
reported here focuses on
here focuses on services
focuses on services that
on services that don
services that don t
that don t fit
don t fit the
t fit the transactional
fit the transactional paradigm
typically for reasons of
our challenge is to
for reasons of performance
challenge is to improve
is to improve transaction
to improve transaction consistency
improve transaction consistency at
transaction consistency at the
consistency at the cache
ones that operate directly
at the cache layer
that operate directly on
operate directly on in
even when the cache
when the cache cannot
memory data structures or
the cache cannot access
data structures or simple
cache cannot access the
structures or simple non
cannot access the backend
access the backend on
the backend on each
backend on each read
to simplify our task
we assume that these
assume that these services
that these services are
these services are capable
services are capable of
are capable of handling
capable of handling outof
today s consistency solutions
s consistency solutions are
consistency solutions are limited
driven overlay network for
solutions are limited to
overlay network for efficient
are limited to the
network for efficient live
limited to the database
for efficient live media
to the database backend
and that processes implementing
efficient live media streaming
that processes implementing them
processes implementing them experience
implementing them experience only
them experience only crash
even when the database
experience only crash failures
when the database itself
the database itself is
database itself is consistent
as will be shown
will be shown below
the vast majority of
vast majority of operations
majority of operations are
of operations are read
our assumptions hold for
th conference on computer
assumptions hold for a
conference on computer communications
hold for a very
on computer communications and
for a very large
computer communications and networking
only transactions issued by
a very large group
transactions issued by edge
very large group of
issued by edge clients
large group of applications
by edge clients and
edge clients and are
clients and are at
and are at high
are at high risk
the ssa was built
at high risk of
ssa was built using
high risk of observing
was built using epidemic
risk of observing inconsistent
of observing inconsistent state
observing inconsistent state in
inconsistent state in the
state in the cache
the outright loss of
communication protocols in conjunction
outright loss of cache
protocols in conjunction with
loss of cache invalidations
in conjunction with a
of cache invalidations emerges
conjunction with a novel
cache invalidations emerges as
with a novel variant
invalidations emerges as an
a novel variant of
emerges as an especially
novel variant of the
as an especially significant
variant of the chain
an especially significant problem
of the chain replication
especially significant problem if
the chain replication scheme
significant problem if transactional
chain replication scheme which
problem if transactional consistency
replication scheme which has
if transactional consistency is
scheme which has evolved
transactional consistency is required
which has evolved from
has evolved from the
evolved from the mechanism
from the mechanism first
the mechanism first proposed
mechanism first proposed in
an acceptable solution for
acceptable solution for a
solution for a consistent
for a consistent cache
a consistent cache must
consistent cache must maintain
cache must maintain the
must maintain the performance
maintain the performance properties
the performance properties of
performance properties of the
properties of the existing
of the existing caching
the existing caching tier
defense against intrusion in
against intrusion in a
intrusion in a live
in a live streaming
gossip based infrastructures are
a live streaming multicast
based infrastructures are beneficial
live streaming multicast system
infrastructures are beneficial because
are beneficial because they
we need to maintain
beneficial because they are
need to maintain the
to maintain the shielding
maintain the shielding role
the shielding role of
shielding role of the
simple to implement rapidly
role of the cache
to implement rapidly self
th ieee international conference
ieee international conference on
the cache hit ratio
international conference on peer
cache hit ratio should
stabilizing after disruptions analytically
hit ratio should be
ratio should be high
after disruptions analytically appealing
disruptions analytically appealing this
analytically appealing this paper
appealing this paper reports
this paper reports on
paper reports on the
reports on the architecture
on the architecture and
the architecture and performance
architecture and performance of
and performance of the
performance of the platform
only cache access should
cache access should complete
access should complete with
should complete with a
complete with a single
and explores the limitations
with a single client
explores the limitations of
the limitations of its
limitations of its underlying
of its underlying techniques
trip on cache hits
the experiments are designed
experiments are designed to
are designed to help
this prohibits coherent cache
designed to help us
prohibits coherent cache solutions
coherent cache solutions such
to help us fully
cache solutions such as
help us fully understand
us fully understand the
fully understand the fundamental
understand the fundamental properties
the fundamental properties of
fundamental properties of a
properties of a single
of a single partitioned
a single partitioned replicated
single partitioned replicated service
partitioned replicated service and
replicated service and thus
service and thus gain
and thus gain a
thus gain a firm
a rchitecture since the
gain a firm grasp
rchitecture since the cache
a firm grasp on
since the cache is
firm grasp on the
the cache is required
grasp on the behavior
cache is required to
on the behavior of
is required to respond
the behavior of the
required to respond immediately
behavior of the ssa
to respond immediately to
of the ssa s
respond immediately to the
the ssa s building
immediately to the client
ssa s building blocks
to the client on
the client on hits
we defer for future
defer for future work
for future work the
future work the full
cache channel is asynchronous
work the full scale
the full scale evaluation
full scale evaluation of
scale evaluation of multiple
evaluation of multiple services
we decided to employ
of multiple services deployed
decided to employ a
multiple services deployed and
to employ a transactional
services deployed and running
employ a transactional consistency
deployed and running at
a transactional consistency that
and running at the
transactional consistency that is
running at the same
consistency that is weaker
at the same time
that is weaker than
is weaker than the
weaker than the full
than the full acid
the full acid model
the ssa currently runs
th conference on computer
ssa currently runs on
conference on computer communications
currently runs on a
runs on a tightly
on a tightly coupled
a tightly coupled cluster
tightly coupled cluster of
coupled cluster of blade
cluster of blade servers
only transactions and update
transactions and update transactions
we show that developers
and update transactions that
show that developers can
update transactions that access
that developers can tune
transactions that access the
developers can tune parameters
that access the same
can tune parameters to
access the same cache
tune parameters to trade
the same cache are
parameters to trade overhead
same cache are guaranteed
to trade overhead for
cache are guaranteed an
trade overhead for speed
are guaranteed an atomic
overhead for speed of
guaranteed an atomic execution
for speed of repair
speed of repair and
of repair and we
repair and we believe
and we believe that
we believe that our
believe that our results
that our results validate
our results validate the
results validate the approach
only transactions that access
transactions that access different
that access different caches
access different caches may
different caches may observe
caches may observe different
may observe different orderings
observe different orderings for
different orderings for independent
application model our work
orderings for independent update
model our work focuses
for independent update transactions
our work focuses on
work focuses on datacenters
focuses on datacenters supporting
on datacenters supporting one
datacenters supporting one or
supporting one or more
one or more services
or more services deployed
more services deployed within
services deployed within a
deployed within a cluster
within a cluster of
a cluster of compute
cluster of compute nodes
every partial execution that
partial execution that includes
execution that includes all
tailer might implement a
that includes all update
might implement a front
includes all update transactions
all update transactions in
update transactions in and
transactions in and all
in and all read
end service that builds
service that builds web
that builds web pages
only transactions that go
transactions that go through
that go through a
parallelizing the task by
go through a single
the task by dispatching
through a single cache
task by dispatching sub
a single cache server
tasks to services to
to services to rank
services to rank product
to rank product popularity
our solution seeks to
solution seeks to approximate
seeks to approximate cache
to approximate cache serializability
approximate cache serializability with
cache serializability with bounded
serializability with bounded caches
with bounded caches and
bounded caches and asynchronous
caches and asynchronous communication
and asynchronous communication with
asynchronous communication with the
communication with the db
our idea starts with
idea starts with an
starts with an observation
end service would probably
service would probably just
objects form clusters with
would probably just be
form clusters with strong
probably just be cloned
clusters with strong locality
with strong locality properties
with identical replicas that
identical replicas that build
transactions are likely to
replicas that build pages
are likely to access
likely to access objects
to access objects that
access objects that are
end services might be
services might be partitioned
might be partitioned into
close to each other
be partitioned into subservices
partitioned into subservices for
into subservices for scalability
subservices for scalability using
for scalability using some
for retailers this might
scalability using some key
retailers this might involve
this might involve related
th symposium on operating
might involve related products
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
for social networks the
social networks the set
networks the set of
the set of friends
for geographical services physical
geographical services physical proximity
and subservices cloned for
subservices cloned for faulttolerance
cloned for faulttolerance and
for faulttolerance and load
and for web albums
for web albums the
web albums the acl
albums the acl objects
the acl objects and
acl objects and the
objects and the pictures
and the pictures assigned
this is a common
the pictures assigned to
is a common model
pictures assigned to them
jim gray and others
gray and others have
and others have suggested
others have suggested that
in some cases applications
have suggested that such
some cases applications explicitly
suggested that such a
cases applications explicitly cluster
that such a system
applications explicitly cluster their
such a system be
explicitly cluster their data
a system be termed
cluster their data accesses
system be termed a
their data accesses to
be termed a farm
data accesses to benefit
termed a farm consisting
accesses to benefit from
a farm consisting of
to benefit from improved
farm consisting of raps
benefit from improved parallelism
reliable array of partitioned
array of partitioned services
reliable array of cloned
array of cloned server
of cloned server processes
the resulting transactions access
resulting transactions access objects
transactions access objects from
access objects from a
objects from a single
from a single cluster
although there will also
there will also be
will also be some
also be some frequency
be some frequency of
some frequency of transactions
frequency of transactions that
of transactions that access
transactions that access unrelated
that access unrelated objects
access unrelated objects in
unrelated objects in different
objects in different clusters
high bandwidth data dissemination
bandwidth data dissemination using
data dissemination using an
dissemination using an overlay
using an overlay mesh
up to the present
our solution requires minor
solution requires minor changes
requires minor changes to
minor changes to the
changes to the database
to the database object
this structure has arisen
the database object representation
structure has arisen mostly
database object representation format
has arisen mostly in
arisen mostly in very
mostly in very large
in very large datacenters
imposing a small and
very large datacenters and
a small and constant
large datacenters and is
th acm symposium on
datacenters and is supported
acm symposium on operating
and is supported primarily
symposium on operating systems
small and constant memory
on operating systems principles
and constant memory overhead
is supported primarily in
supported primarily in the
primarily in the context
in the context of
the context of three
independent of the database
of the database size
the database size and
database size and the
size and the transaction
and the transaction rate
we believe that similar
believe that similar architectures
that similar architectures will
similar architectures will be
architectures will be needed
will be needed more
this overhead involves tracking
be needed more widely
overhead involves tracking and
involves tracking and caching
tracking and caching what
and caching what we
caching what we refer
because the need to
what we refer to
the need to tolerate
we refer to as
need to tolerate heavy
refer to as dependency
to tolerate heavy loads
to as dependency lists
tolerate heavy loads is
heavy loads is increasingly
loads is increasingly ubiquitous
and economic considerations favor
economic considerations favor clustered
considerations favor clustered solutions
length lists of object
lists of object identifiers
of object identifiers and
object identifiers and the
identifiers and the associated
and the associated version
the associated version numbers
game servers require scalability
servers require scalability for
each representing some recently
require scalability for situations
representing some recently updated
scalability for situations in
some recently updated objects
for situations in which
recently updated objects upon
situations in which there
updated objects upon which
in which there are
objects upon which the
which there are many
upon which the cached
there are many users
which the cached object
the cached object depends
military systems require scalability
systems require scalability to
require scalability to support
scalability to support new
to support new generations
support new generations of
sized list can omit
new generations of integrated
list can omit dependency
generations of integrated applications
can omit dependency information
omit dependency information required
dependency information required to
information required to detect
required to detect inconsistencies
hospital automation is putting
automation is putting new
is putting new demands
a comparative study of
putting new demands on
comparative study of live
hence it is important
study of live p
new demands on medical
it is important to
demands on medical information
is important to use
on medical information subsystems
important to use a
to use a bound
use a bound large
a bound large enough
bound large enough to
in a wide range
large enough to capture
a wide range of
enough to capture most
wide range of everyday
to capture most of
range of everyday settings
capture most of the
most of the relevant
of the relevant dependencies
the rollout of soas
rollout of soas and
at present we lack
of soas and the
present we lack an
th conference on computer
we lack an automated
soas and the ease
lack an automated way
conference on computer communications
an automated way to
and the ease of
automated way to do
way to do this
the ease of application
ease of application integration
of application integration they
application integration they support
integration they support will
we require the developer
they support will place
require the developer to
support will place services
the developer to tune
will place services under
developer to tune the
place services under growing
to tune the length
services under growing load
tune the length so
the length so that
length so that the
so that the frequency
that the frequency of
our goal is to
the frequency of errors
goal is to make
frequency of errors is
is to make it
of errors is reduced
to make it easy
errors is reduced to
make it easy to
is reduced to an
it easy to build
reduced to an acceptable
easy to build raps
to an acceptable level
to build raps and
build raps and racs
raps and racs from
and racs from traditional
reasoning about the trade
web service applications designed
service applications designed for
applications designed for quick
in a manner we
designed for quick responsiveness
a manner we discuss
manner we discuss further
we discuss further below
we also want to
also want to build
want to build the
dependency lists should be
to build the simplest
lists should be roughly
build the simplest platform
should be roughly the
the simplest platform capable
be roughly the same
simplest platform capable of
roughly the same size
platform capable of accomplishing
the same size as
capable of accomplishing this
same size as the
of accomplishing this task
size as the size
as the size of
the size of the
size of the workload
of the workload s
the workload s clusters
preventing dos attacks in
dos attacks in peer
our extensions offer a
extensions offer a transactional
a set of racs
offer a transactional interface
a transactional interface to
transactional interface to the
interface to the cache
peer media streaming systems
to the cache in
the cache in addition
cache in addition to
in addition to the
addition to the standard
to the standard read
th annual multimedia computing
annual multimedia computing and
our algorithm detects and
multimedia computing and networking
algorithm detects and fixes
computing and networking conference
detects and fixes inconsistent
and fixes inconsistent read
only transactions at the
transactions at the cache
at the cache with
the cache with constant
cache with constant complexity
it does so by
does so by either
so by either aborting
by either aborting the
either aborting the transaction
which can then be
can then be retried
or invalidating a cached
invalidating a cached object
a cached object which
cached object which can
object which can then
which can then force
can then force a
then force a read
force a read from
a read from the
read from the database
gossip traffic chain figure
similar to handling cache
to handling cache misses
when the dependency lists
the dependency lists fail
dependency lists fail to
lists fail to document
fail to document a
to document a necessary
document a necessary dependency
an application might be
application might be exposed
might be exposed to
be exposed to stale
exposed to stale values
elements of the model
of the model a
the model a service
model a service is
because we have in
a service is simply
we have in mind
service is simply an
have in mind client
is simply an application
simply an application that
an application that provides
application that provides interfaces
side applications that are
that provides interfaces that
applications that are unlikely
provides interfaces that manipulate
that are unlikely to
interfaces that manipulate objects
are unlikely to validate
that manipulate objects of
unlikely to validate against
manipulate objects of unspecified
to validate against the
objects of unspecified nature
validate against the back
a query operation reads
query operation reads some
operation reads some object
reads some object and
some object and returns
for many of our
object and returns a
many of our intended
and returns a computed
of our intended uses
returns a computed value
our intended uses some
intended uses some level
uses some level of
nd workshop on the
some level of undetected
workshop on the economics
level of undetected inconsistency
an update operation modifies
of undetected inconsistency can
on the economics of
undetected inconsistency can slip
the economics of peer
inconsistency can slip past
update operation modifies one
operation modifies one or
modifies one or more
one or more objects
one unusual assumption made
because the developer would
unusual assumption made in
the developer would often
assumption made in our
developer would often be
made in our work
would often be able
in our work is
often be able to
our work is that
be able to tune
work is that many
able to tune the
is that many services
to tune the mechanism
that many services can
many services can process
services can process updates
can process updates out
process updates out of
updates out of order
state operation of large
operation of large applications
we focus on services
the rate of unnoticed
focus on services that
rate of unnoticed inconsistencies
on services that can
of unnoticed inconsistencies could
services that can respond
unnoticed inconsistencies could be
that can respond correctly
inconsistencies could be extremely
can respond correctly to
could be extremely low
respond correctly to queries
correctly to queries even
to queries even if
queries even if some
even if some updates
if some updates are
with clustered workloads we
some updates are temporarily
clustered workloads we will
updates are temporarily missing
workloads we will demonstrate
we will demonstrate that
will demonstrate that it
demonstrate that it is
converge into a state
that it is sufficient
into a state determined
it is sufficient to
a state determined entirely
is sufficient to store
state determined entirely by
sufficient to store a
determined entirely by the
to store a small
entirely by the set
store a small set
by the set of
a small set of
the set of updates
small set of dependencies
set of dependencies to
of dependencies to detect
improving robustness of peer
dependencies to detect most
to detect most inconsistencies
so that if two
that if two members
if two members of
two members of some
members of some subservice
we also investigate workloads
of some subservice receive
peer streaming with incentives
also investigate workloads where
some subservice receive the
investigate workloads where the
subservice receive the same
workloads where the clustered
receive the same updates
where the clustered access
the same updates they
the clustered access pattern
same updates they will
clustered access pattern is
updates they will be
access pattern is less
they will be in
pattern is less strongly
will be in equivalent
is less strongly evident
be in equivalent states
st workshop on the
workshop on the economics
on the economics of
the economics of networked
even if those updates
economics of networked systems
if those updates were
those updates were delivered
updates were delivered in
our approach is less
were delivered in different
approach is less effective
delivered in different orders
is less effective even
less effective even with
effective even with longer
even with longer dependency
with longer dependency list
longer dependency list lengths
a reissued query or
thus our solution is
reissued query or update
our solution is not
query or update returns
solution is not a
or update returns an
is not a panacea
update returns an equivalent
returns an equivalent result
what this amounts to
this amounts to is
for applications matched to
amounts to is that
applications matched to our
to is that the
matched to our assumptions
is that the ssa
that the ssa should
the ssa should deliver
can be highly effective
ssa should deliver updates
should deliver updates as
deliver updates as soon
updates as soon as
as soon as it
soon as it can
as it can even
it can even if
can even if they
database we assume that
even if they are
we assume that the
if they are not
they are not in
assume that the database
are not in order
that the database tags
the database tags each
database tags each object
tags each object with
each object with a
object with a version
with a version number
a version number specific
one way that an
version number specific to
way that an application
number specific to the
that an application might
specific to the transaction
an application might process
to the transaction that
application might process out
the transaction that most
might process out of
transaction that most recently
process out of order
that most recently updated
out of order updates
most recently updated it
of order updates is
order updates is simply
updates is simply to
is simply to delay
simply to delay processing
and that there is
to delay processing them
that there is a
delay processing them until
there is a total
processing them until it
is a total ordering
them until it can
a total ordering on
until it can sort
total ordering on version
it can sort them
ordering on version numbers
can sort them into
sort them into order
p live streaming system
the version of a
but we believe that
version of a transaction
we believe that for
of a transaction is
believe that for many
a transaction is chosen
that for many uses
transaction is chosen to
of the ninth ieee
is chosen to be
the ninth ieee global
chosen to be larger
ninth ieee global internet
to be larger than
it will be possible
be larger than the
will be possible to
larger than the versions
ieee global internet workshop
than the versions of
be possible to act
the versions of all
possible to act on
versions of all objects
to act on an
of all objects accessed
act on an update
all objects accessed by
on an update or
objects accessed by the
an update or query
accessed by the transaction
update or query immediately
or query immediately upon
query immediately upon receiving
immediately upon receiving it
the database stores for
database stores for each
stores for each object
the ssa can support
for each object o
ssa can support raps
each object o a
object o a list
o a list of
a list of k
list of k dependencies
a raps of racs
a service that can
service that can be
that can be structured
can be structured as
be structured as a
structured as a raps
as a raps must
a raps must have
raps must have a
must have a partitioning
have a partitioning function
a partitioning function that
partitioning function that can
function that can be
that can be used
can be used to
be used to map
used to map each
to map each operation
map each operation to
each operation to the
operation to the subservice
to the subservice that
the subservice that should
subservice that should execute
that should execute it
existing systems typically implement
systems typically implement partitioning
typically implement partitioning functions
implement partitioning functions in
partitioning functions in one
functions in one of
in one of two
one of two ways
the service exports its
service exports its partitioning
exports its partitioning function
so that clients are
that clients are able
clients are able to
are able to locally
able to locally implement
to locally implement the
locally implement the logic
this is a list
implement the logic mapping
is a list of
the logic mapping requests
a list of identifiers
logic mapping requests to
list of identifiers and
mapping requests to subservices
of identifiers and versions
identifiers and versions of
and versions of other
versions of other objects
of other objects that
other objects that the
objects that the current
that the current version
the current version of
the cluster might control
current version of o
cluster might control the
version of o depends
might control the dns
of o depends on
or could influence the
could influence the creation
influence the creation of
the creation of web
creation of web pages
of web pages by
only transaction that sees
web pages by modifying
transaction that sees the
pages by modifying urls
that sees the current
sees the current version
the current version of
current version of o
so that clients will
version of o must
that clients will be
of o must not
clients will be directed
o must not see
will be directed to
must not see object
be directed to an
not see object di
directed to an appropriate
see object di with
to an appropriate subservice
object di with version
di with version smaller
with version smaller than
version smaller than vi
when a transaction t
the servers might export
a transaction t with
servers might export actual
transaction t with version
might export actual code
t with version vt
export actual code that
with version vt touches
actual code that the
version vt touches objects
code that the client
vt touches objects o
that the client runs
the partitioning logic is
partitioning logic is situated
logic is situated on
it updates both their
is situated on a
updates both their versions
situated on a load
both their versions and
on a load balancing
their versions and their
a load balancing component
versions and their dependency
load balancing component resident
and their dependency lists
balancing component resident in
component resident in the
resident in the server
in the server cluster
subsequent accesses to object
accesses to object o
the load balancer sprays
load balancer sprays requests
balancer sprays requests over
must see object o
sprays requests over the
requests over the subservices
over the subservices in
the subservices in accordance
subservices in accordance with
with a version not
in accordance with server
a version not smaller
accordance with server logic
version not smaller than
not smaller than vt
the ssa supports the
ssa supports the latter
supports the latter approach
it inherits all of
inherits all of the
offering a mechanism that
all of the l
a mechanism that assists
of the l dependencies
mechanism that assists the
the l dependencies of
that assists the load
l dependencies of o
balancing component in tracking
component in tracking membership
in tracking membership so
tracking membership so that
where l is the
membership so that it
l is the length
so that it can
is the length of
that it can appropriately
the length of o
it can appropriately route
can appropriately route queries
appropriately route queries and
route queries and updates
we assume that processes
so the dependency list
assume that processes are
the dependency list of
that processes are fail
dependency list of o
should a failure occur
and will eventually be
will eventually be detected
eventually be detected as
be detected as faulty
a failure may be
failure may be transient
a process can become
process can become temporarily
can become temporarily unavailable
but then restart and
then restart and recover
restart and recover any
and recover any missing
recover any missing updates
discussion our model is
our model is not
model is not completely
is not completely general
and for this reason
for this reason some
this reason some discussion
reason some discussion is
some discussion is needed
consider the following example
we wish to support
wish to support a
to support a scalable
support a scalable inventory
a scalable inventory service
scalable inventory service that
inventory service that receives
service that receives updates
that receives updates corresponding
receives updates corresponding to
updates corresponding to inventory
corresponding to inventory consumption
to inventory consumption and
inventory consumption and re
queries against such a
against such a service
such a service would
a service would compute
service would compute and
would compute and return
compute and return an
and return an inventory
return an inventory count
an inventory count as
inventory count as of
count as of the
as of the time
of the time the
the time the query
time the query was
the query was processed
but inventory can change
inventory can change in
can change in real
reissued a moment later
might yield a different
yield a different result
a different result and
different result and yet
result and yet both
and yet both would
yet both would be
both would be correct
responses reflecting a reasonably
reflecting a reasonably current
a reasonably current server
reasonably current server state
current server state are
server state are acceptable
on the other hand
a response reflecting a
response reflecting a very
reflecting a very stale
a very stale state
very stale state would
stale state would be
state would be incorrect
a client should not
client should not be
should not be offered
not be offered a
be offered a promotional
offered a promotional price
a promotional price on
promotional price on a
price on a plasma
on a plasma tv
a plasma tv if
plasma tv if the
tv if the last
if the last unit
the last unit was
last unit was actually
unit was actually sold
was actually sold hours
actually sold hours ago
when a transaction is
the inventory service should
a transaction is committed
inventory service should reflect
service should reflect as
should reflect as many
reflect as many updates
as many updates as
this update is done
many updates as possible
update is done for
updates as possible in
is done for all
as possible in the
done for all objects
possible in the replies
for all objects in
in the replies it
all objects in the
the replies it gives
objects in the transaction
replies it gives to
in the transaction at
it gives to requests
the transaction at once
but any reply is
given a read set
any reply is correct
a read set readset
reply is correct provided
is correct provided that
correct provided that it
provided that it was
that it was based
and a write set
it was based on
a write set writeset
was based on a
based on a recent
on a recent state
containing tuples comprised of
tuples comprised of the
comprised of the keys
of the keys accessed
we shall see that
their versions and their
shall see that the
versions and their dependency
building collaboration applications that
see that the ssa
and their dependency lists
that the ssa allows
collaboration applications that mix
the ssa allows brief
applications that mix web
ssa allows brief inconsistencies
that mix web services
allows brief inconsistencies but
the database aggregates them
mix web services hosted
database aggregates them to
web services hosted content
aggregates them to a
services hosted content with
brief inconsistencies but that
hosted content with p
them to a single
inconsistencies but that they
to a single full
but that they can
a single full dependency
that they can be
single full dependency list
they can be limited
full dependency list as
can be limited to
dependency list as follows
be limited to a
limited to a few
to a few seconds
operations against the inventory
against the inventory service
the inventory service happen
inventory service happen to
service happen to be
happen to be commutative
hence the service can
the service can process
service can process updates
can process updates out
process updates out of
updates out of order
krzysztof ostrowski cornell university
but many kinds of
many kinds of services
kinds of services can
of services can handle
services can handle out
dept of computer science
can handle out of
handle out of order
out of order updates
if for no other
for no other reason
no other reason than
other reason than that
reason than that in
than that in many
that in many settings
each update is uniquely
update is uniquely sequenced
is uniquely sequenced by
uniquely sequenced by its
readset writeset this list
sequenced by its source
writeset this list is
this list is pruned
list is pruned to
is pruned to match
pruned to match the
to match the target
permitting the service to
match the target size
the service to sort
the target size using
service to sort updates
target size using lru
to sort updates and
sort updates and to
updates and to process
and to process queries
to process queries against
and stored with each
process queries against the
stored with each write
queries against the sorted
against the sorted database
our group has held
group has held discussions
has held discussions with
a list entry can
held discussions with operators
list entry can be
discussions with operators of
entry can be discarded
with operators of several
can be discarded if
operators of several large
be discarded if the
of several large datacenters
discarded if the same
if the same entry
the same entry s
same entry s object
entry s object appears
and concluded that many
s object appears in
concluded that many services
object appears in another
that many services have
appears in another entry
many services have the
in another entry with
services have the kinds
another entry with a
have the kinds of
entry with a larger
the kinds of properties
with a larger version
kinds of properties just
of properties just cited
ability to respond based
to respond based on
respond based on a
based on a reasonable
were their lengths not
on a reasonable current
their lengths not bounded
a reasonable current state
dependency lists could quickly
and to handle out
lists could quickly grow
edu abstract the most
could quickly grow to
abstract the most commonly
quickly grow to include
the most commonly deployed
grow to include all
most commonly deployed web
to include all objects
commonly deployed web service
include all objects in
deployed web service applications
all objects in the
web service applications employ
objects in the database
service applications employ client
the ssa is a
ssa is a good
is a good match
a good match for
good match for personalization
match for personalization services
cache in our scheme
with clients running remotely
clients running remotely and
running remotely and services
remotely and services hosted
and services hosted in
the cache interacts with
services hosted in data
cache interacts with the
hosted in data centers
interacts with the database
with the database in
the database in essentially
database in essentially the
in essentially the same
essentially the same manner
the same manner as
same manner as for
manner as for a
as for a consistency
we make the case
make the case for
the case for service
applications that combine service
hosted data with collaboration
data with collaboration features
with collaboration features implemented
collaboration features implemented using
features implemented using peerto
and receiving invalidations as
receiving invalidations as the
invalidations as the database
as the database updates
the database updates objects
collaboration features are awkward
features are awkward to
are awkward to support
awkward to support solely
to support solely based
support solely based on
solely based on the
based on the existing
on the existing web
the caches read from
the existing web services
caches read from the
existing web services technologies
read from the database
from the database not
the database not only
database not only the
not only the object
these deal primarily with
indirection through the data
deal primarily with weakly
only the object s
primarily with weakly consistent
the object s value
with weakly consistent data
through the data center
the data center introduces
data center introduces high
center introduces high latencies
introduces high latencies and
but also its version
high latencies and limits
also its version and
latencies and limits scalability
its version and the
version and the dependency
and the dependency list
and precludes collaboration between
precludes collaboration between clients
and all sorts of
collaboration between clients connected
all sorts of services
between clients connected to
sorts of services in
clients connected to one
of services in which
the extended cache exports
services in which replies
extended cache exports a
in which replies are
cache exports a transactional
which replies are intrinsically
exports a transactional read
replies are intrinsically noisy
another but lacking connectivity
but lacking connectivity to
lacking connectivity to the
connectivity to the data
to the data center
such as services that
as services that report
services that report data
that report data gathered
client read requests are
report data gathered from
cornell s live distributed
data gathered from remote
read requests are extended
gathered from remote sensors
s live distributed objects
requests are extended with
live distributed objects platform
are extended with a
distributed objects platform combines
extended with a transaction
objects platform combines web
with a transaction identifier
platform combines web services
a transaction identifier and
combines web services with
transaction identifier and a
web services with direct
identifier and a last
services with direct peerto
a datacenter would also
datacenter would also host
would also host some
also host some kinds
host some kinds of
some kinds of services
peer communication to eliminate
kinds of services ill
communication to eliminate these
to eliminate these issues
matched to our model
but because we are
because we are working
we are working with
are working with web
working with web services
introduction there is a
there is a growing
is a growing opportunity
a growing opportunity to
growing opportunity to use
opportunity to use service
services running on the
the transaction identifier txnid
running on the ssa
transaction identifier txnid allows
on the ssa can
identifier txnid allows the
the ssa can easily
txnid allows the cache
ssa can easily interact
allows the cache to
can easily interact with
the cache to recognize
easily interact with services
cache to recognize reads
interact with services that
to recognize reads belonging
with services that employ
applications in ways that
services that employ other
in ways that can
that employ other solutions
ways that can slash
recognize reads belonging to
that can slash health
reads belonging to the
belonging to the same
to the same transaction
the cache responds with
cache responds with either
responds with either the
with either the value
either the value of
the value of the
value of the requested
permit more effective search
of the requested object
more effective search and
consistency semantics the ssa
effective search and rescue
semantics the ssa implements
search and rescue after
the ssa implements stochastic
and rescue after a
ssa implements stochastic consistency
or with an abort
implements stochastic consistency semantics
rescue after a disaster
with an abort if
an abort if it
abort if it detects
if it detects an
an application will only
it detects an inconsistency
application will only observe
enable a more nimble
will only observe an
a more nimble information
detects an inconsistency between
only observe an inconsistency
an inconsistency between this
observe an inconsistency if
inconsistency between this read
an inconsistency if a
between this read and
inconsistency if a fault
this read and any
if a fault occurs
read and any of
and any of the
or make possible a
any of the previous
make possible a world
of the previous reads
possible a world of
the previous reads with
and even then only
previous reads with the
a world of professional
reads with the same
even then only for
with the same transaction
world of professional dialog
the same transaction id
then only for a
of professional dialog and
only for a period
professional dialog and collaboration
for a period of
dialog and collaboration without
a period of time
and collaboration without travel
period of time associated
we do not guarantee
of time associated with
do not guarantee that
time associated with our
not guarantee that inconsistencies
associated with our repair
guarantee that inconsistencies will
with our repair protocol
that inconsistencies will be
soc applications will need
inconsistencies will be detected
applications will need to
will need to combine
need to combine two
to combine two types
and only if it
combine two types of
only if it has
two types of content
the lastop allows the
if it has the
lastop allows the cache
it has the bad
allows the cache to
has the bad luck
traditional web service hosted
the cache to garbage
web service hosted content
the bad luck to
bad luck to query
luck to query a
to query a node
query a node impacted
such as data from
a node impacted by
as data from databases
node impacted by the
collect its transaction record
impacted by the failure
its transaction record after
transaction record after responding
record after responding to
after responding to the
this window can be
responding to the last
window can be made
to the last read
can be made small
the last read operation
last read operation of
read operation of the
and weather prediction systems
operation of the transaction
so that applications are
that applications are unlikely
applications are unlikely to
are unlikely to observe
with a variety of
unlikely to observe a
a variety of collaboration
to observe a problem
variety of collaboration features
the cache will treat
cache will treat subsequent
will treat subsequent accesses
treat subsequent accesses with
or permitted to grow
subsequent accesses with the
permitted to grow somewhat
such as chat windows
to grow somewhat larger
accesses with the same
with the same transaction
the same transaction id
same transaction id as
transaction id as new
id as new transactions
depending upon the cost
upon the cost of
the cost of inconsistency
cost of inconsistency and
of inconsistency and the
inconsistency and the relative
to implement this interface
and the relative value
peer video and other
video and other media
and other media streams
the cache maintains a
cache maintains a record
maintains a record of
a record of each
record of each transaction
of each transaction with
each transaction with its
transaction with its read
with its read values
of faster response time
faster response time versus
response time versus lower
time versus lower risk
existing web service technologies
versus lower risk of
web service technologies make
lower risk of an
service technologies make it
risk of an observed
and their dependency lists
of an observed fault
technologies make it easy
make it easy to
it easy to build
easy to build applications
on a read of
to build applications in
a read of keycurr
in the experimental work
build applications in which
the experimental work that
applications in which all
experimental work that follows
in which all data
which all data travels
the cache first obtains
all data travels through
cache first obtains the
data travels through a
first obtains the requested
travels through a data
we measure these windows
through a data center
obtains the requested entry
measure these windows for
the requested entry from
these windows for scenarios
requested entry from memory
windows for scenarios representative
for scenarios representative of
implementing collaboration features using
scenarios representative of conditions
collaboration features using these
representative of conditions that
features using these technologies
of conditions that arise
using these technologies is
conditions that arise in
these technologies is problematic
that arise in realistic
technologies is problematic because
arise in realistic settings
is problematic because collaborative
problematic because collaborative applications
because collaborative applications can
collaborative applications can generate
applications can generate high
the ssa framework the
ssa framework the basic
bursty update rates and
framework the basic operation
update rates and yet
the basic operation of
the entry includes the
rates and yet often
entry includes the value
basic operation of the
and yet often require
operation of the ssa
yet often require low
of the ssa is
often require low latencies
the ssa is as
require low latencies and
ssa is as follows
version vercurr and dependency
low latencies and tight
vercurr and dependency list
latencies and tight synchronization
and dependency list deplistcurr
and tight synchronization between
tight synchronization between collaborating
as queries or updates
synchronization between collaborating users
queries or updates are
or updates are received
the cache checks the
updates are received in
cache checks the currently
are received in the
checks the currently read
received in the cluster
the currently read object
one can often achieve
currently read object against
can often achieve better
read object against each
often achieve better performance
object against each of
achieve better performance using
against each of the
better performance using direct
they are passed through
performance using direct client
each of the previously
are passed through a
of the previously read
passed through a partition
the previously read objects
through a partition mapping
a partition mapping component
if a previously read
which directs the request
a previously read version
directs the request to
previously read version v
the request to an
read version v is
request to an appropriate
version v is older
to an appropriate racs
v is older than
is older than expected
older than expected by
than expected by the
expected by the current
we will use the
by the current read
will use the term
the current read s
use the term subservice
current read s dependencies
the term subservice rather
read s dependencies v
term subservice rather than
s dependencies v k
subservice rather than racs
rather than racs in
than racs in the
racs in the remainder
in the remainder of
but in today s
the remainder of the
in today s soa
remainder of the paper
today s soa plat
to create a subservice
create a subservice the
a subservice the developer
subservice the developer must
the developer must first
developer must first implement
must first implement a
first implement a non
band communication is hard
communication is hard to
is hard to integrate
hard to integrate with
to integrate with hosted
integrate with hosted content
this is then cloned
is then cloned using
then cloned using the
this problem is reflected
cloned using the ssa
using the ssa platform
problem is reflected by
is reflected by a
reflected by a growing
by a growing number
a growing number of
each replica is placed
growing number of publications
replica is placed on
number of publications on
is placed on a
of publications on the
placed on a separate
publications on the integration
on a separate node
on the integration of
the integration of web
integration of web services
of web services with
web services with peer
and the replicas are
the replicas are then
replicas are then linked
are then linked using
then linked using tcp
linked using tcp to
using tcp to create
tcp to create a
or the current read
to create a chain
the current read vcurr
current read vcurr is
read vcurr is older
vcurr is older than
is older than expected
older than expected by
than expected by the
expected by the dependencies
by the dependencies of
the dependencies of a
dependencies of a previous
of a previous read
a previous read v
previous read v v
we therefore have a
mapping between a subservice
between a subservice and
a subservice and a
subservice and a chain
gossip based chain replication
an inconsistency is detected
based chain replication the
chain replication the replication
replication the replication scheme
the replication scheme has
otherwise the cache returns
replication scheme has evolved
the cache returns the
scheme has evolved out
cache returns the read
has evolved out of
returns the read value
evolved out of the
the read value to
out of the chain
read value to the
of the chain replication
value to the client
the chain replication mechanism
chain replication mechanism first
replication mechanism first introduced
mechanism first introduced in
upon detecting an inconsistency
the cache can take
cache can take one
can take one of
take one of three
one of three paths
the original scheme was
original scheme was developed
scheme was developed as
was developed as a
abort the current transaction
developed as a means
as a means of
a means of obtaining
means of obtaining high
compared to the other
of obtaining high throughput
to the other approaches
obtaining high throughput and
high throughput and availability
throughput and availability for
and availability for query
this has the benefit
availability for query and
has the benefit of
for query and update
the benefit of affecting
query and update requests
benefit of affecting only
and update requests without
of affecting only the
update requests without sacrificing
affecting only the running
requests without sacrificing strong
only the running transaction
without sacrificing strong consistency
the running transaction and
sacrificing strong consistency guarantees
running transaction and limiting
transaction and limiting collateral
and limiting collateral damage
the gossip based chain
gossip based chain replication
based chain replication behaves
chain replication behaves in
replication behaves in the
behaves in the following
in the following manner
abort the current transaction
the following manner during
the current transaction and
following manner during normal
current transaction and evict
manner during normal operation
transaction and evict the
during normal operation when
and evict the violating
normal operation when nodes
operation when nodes aren
when nodes aren t
nodes aren t failing
aren t failing or
t failing or restarting
update operations are forwarded
operations are forwarded to
are forwarded to the
object from the cache
forwarded to the head
to the head of
the head of the
head of the chain
this approach guesses that
approach guesses that future
guesses that future transactions
where the request is
that future transactions are
the request is processed
future transactions are likely
request is processed using
transactions are likely to
is processed using the
are likely to abort
processed using the local
likely to abort because
using the local replica
to abort because of
abort because of this
because of this object
the state changes are
state changes are passed
changes are passed along
are passed along down
passed along down the
along down the chain
down the chain to
the chain to the
chain to the next
to the next element
check which is the
which in turn updates
which is the violating
in turn updates it
is the violating object
turn updates it s
yet the issue remains
updates it s state
the issue remains unresolved
it s state and
s state and performs
if it is the
state and performs the
it is the currently
and performs the same
is the currently accessed
performs the same operation
the currently accessed object
the same operation until
same operation until the
operation until the tail
until the tail is
the tail is reached
cornell s live distributed
queries can either be
s live distributed objects
can either be directed
live distributed objects platform
either be directed towards
be directed towards a
directed towards a randomly
towards a randomly selected
treat this access as
a randomly selected process
this access as a
randomly selected process in
access as a miss
selected process in the
as a miss and
process in the group
a miss and respond
in the group or
miss and respond to
the group or to
and respond to it
group or to a
respond to it with
or to a specific
to it with a
to a specific one
it with a value
with a value read
a value read from
value read from the
read from the database
live objects for short
the strongest consistency guarantee
strongest consistency guarantee is
consistency guarantee is acheived
if the violating object
allow even a non
guarantee is acheived if
the violating object was
is acheived if all
violating object was returned
acheived if all query
object was returned to
if all query operations
programmer to construct content
all query operations are
was returned to the
query operations are targeted
returned to the user
operations are targeted at
to the user as
are targeted at the
the user as the
rich solutions that blend
user as the result
solutions that blend traditional
as the result of
that blend traditional web
the result of a
blend traditional web services
result of a read
traditional web services and
of a read earlier
web services and peer
targeted at the tail
a read earlier in
at the tail of
read earlier in the
the tail of the
earlier in the transaction
tail of the chain
of the chain node
which is the case
is the case for
the case for the
case for the vanilla
and to share them
for the vanilla chain
to share them with
the vanilla chain replication
share them with others
vanilla chain replication scheme
evict the stale object
however this eliminates the
the stale object and
this eliminates the opportunity
stale object and abort
eliminates the opportunity to
object and abort the
the opportunity to load
and abort the transaction
this is like creating
is like creating a
like creating a slide
creating a slide show
faults and node restarts
consistency with unbounded resources
and node restarts can
node restarts can disrupt
restarts can disrupt the
can disrupt the primary
disrupt the primary communication
the primary communication pattern
primary communication pattern of
after which the solution
communication pattern of the
which the solution can
pattern of the ssa
cache detects all inconsistencies
the solution can be
solution can be shared
can be shared in
be shared in a
if the head of
shared in a file
as stated in the
in a file or
stated in the following
a file or via
in the following theorem
the head of a
file or via email
head of a chain
or via email and
of a chain fails
via email and opened
email and opened on
and opened on other
opened on other machines
update sources will need
sources will need to
will need to discover
need to discover a
the users are immersed
to discover a new
users are immersed in
discover a new head
are immersed in the
immersed in the resulting
in the resulting collaborative
the resulting collaborative application
cache with unbounded cache
if an inner node
with unbounded cache size
an inner node crashes
unbounded cache size and
inner node crashes the
cache size and unbounded
node crashes the chain
size and unbounded dependency
they can interact with
and unbounded dependency lists
crashes the chain may
unbounded dependency lists implements
the chain may break
dependency lists implements cache
can interact with the
interact with the application
with the application and
the application and peers
and if the tail
application and peers see
if the tail crashes
and peers see the
peers see the results
see the results instantly
acks might not be
might not be sent
not be sent back
deferred to appendix a
updates are applied to
are applied to all
applied to all replicas
to all replicas in
all replicas in a
replicas in a consistent
is by constructing a
in a consistent manner
by constructing a serialization
constructing a serialization of
a serialization of the
serialization of the transactions
of the transactions in
or some of its
the transactions in the
some of its members
transactions in the database
in the database and
in contrast to today
the database and in
contrast to today s
database and in one
to today s web
and in one cache
today s web service
s web service platforms
processes will miss updates
will miss updates and
based on the fact
miss updates and hence
on the fact that
updates and hence queries
the fact that the
and hence queries will
fact that the transactions
hence queries will return
that the transactions in
p communication can coexist
the transactions in the
queries will return outdated
communication can coexist with
will return outdated results
transactions in the database
can coexist with more
in the database are
the database are serializable
coexist with more standard
database are serializable by
to repair these inconsistencies
with more standard solutions
are serializable by definition
more standard solutions that
standard solutions that reach
solutions that reach back
the ssa implements a
that reach back to
ssa implements a secondary
reach back to the
implements a secondary update
the implications of theorem
a secondary update propagation
back to the hosted
secondary update propagation mechanism
to the hosted content
the hosted content and
hosted content and trigger
will be seen in
content and trigger updates
be seen in section
and trigger updates at
seen in section v
trigger updates at the
it uses gossip protocols
updates at the associated
uses gossip protocols to
at the associated data
gossip protocols to rapidly
the associated data centers
protocols to rapidly detect
to rapidly detect and
rapidly detect and repair
detect and repair inconsistencies
while simultaneously orchestrating repair
simultaneously orchestrating repair of
when an application needs
orchestrating repair of the
an application needs high
repair of the chain
application needs high data
cache converges to perfect
needs high data rates
converges to perfect detection
to perfect detection when
the gossip rate can
perfect detection when stable
gossip rate can be
detection when stable clusters
rate can be tuned
when stable clusters are
stable clusters are as
clusters are as large
are as large as
as large as its
large as its dependency
with a higher rate
as its dependency lists
a higher rate overheads
higher rate overheads rise
it can use protocols
rate overheads rise but
can use protocols that
overheads rise but repair
in such a scenario
use protocols that bypass
rise but repair occurs
protocols that bypass the
but repair occurs more
that bypass the data
repair occurs more rapidly
bypass the data center
the dependency lists are
the data center to
dependency lists are large
data center to achieve
lists are large enough
center to achieve the
are large enough to
to achieve the full
large enough to describe
achieve the full performance
enough to describe all
the full performance of
to describe all relevant
full performance of the
describe all relevant dependencies
performance of the network
repair is slower but
is slower but overheads
slower but overheads drop
this paper makes the
paper makes the following
makes the following contributions
the subsections that follow
subsections that follow discuss
e xperimental s etup
that follow discuss the
xperimental s etup to
follow discuss the two
s etup to evaluate
discuss the two core
we describe a new
etup to evaluate the
the two core mechanisms
describe a new class
two core mechanisms in
a new class of
core mechanisms in greater
to evaluate the effectiveness
new class of service
evaluate the effectiveness of
mechanisms in greater detail
the effectiveness of our
effectiveness of our scheme
a second class of
we implemented a prototype
second class of faults
class of faults are
of faults are transient
faults are transient and
to study the properties
applications that integrate service
are transient and relate
that integrate service hosted
study the properties of
integrate service hosted content
transient and relate to
service hosted content with
the properties of the
and relate to the
hosted content with peer
relate to the behavior
properties of the cache
to the behavior of
the behavior of tcp
behavior of tcp when
of tcp when a
tcp when a node
we only need a
when a node is
only need a single
a node is subjected
need a single column
node is subjected to
is subjected to stress
we analyze two important
analyze two important examples
two important examples of
such as a burst
important examples of soc
as a burst of
examples of soc applications
a burst of traffic
namely a single cache
search and rescue mission
a single cache backed
and rescue mission and
single cache backed by
rescue mission and virtual
cache backed by a
mission and virtual worlds
backed by a single
by a single database
the os tends to
a single database server
os tends to lose
tends to lose packets
to lose packets and
lose packets and the
packets and the effect
and the effect is
the effect is that
effect is that tcp
illustrates the structure of
is that tcp will
we list the key
that tcp will impose
the structure of our
tcp will impose congestion
structure of our experimental
will impose congestion control
of our experimental setup
list the key challenges
impose congestion control mechanisms
the key challenges that
congestion control mechanisms and
key challenges that soc
control mechanisms and choke
challenges that soc applications
a single database implements
mechanisms and choke back
single database implements a
that soc applications place
database implements a transactional
soc applications place on
implements a transactional key
applications place on their
place on their runtime
on their runtime environments
updates will cease to
will cease to propagate
cease to propagate down
to propagate down the
propagate down the chain
we describe a new
describe a new class
a new class of
new class of multi
even though most of
though most of the
most of the nodes
of the nodes involved
the nodes involved could
layered mashups and contrast
nodes involved could still
mashups and contrast them
involved could still have
and contrast them with
could still have ample
contrast them with more
still have ample capacity
them with more traditional
update clients access database
which sends invalidations to
sends invalidations to the
invalidations to the cache
we will show that
based approach to building
will show that when
approach to building mashups
show that when such
that when such a
when such a problem
such a problem arises
characteristic of today s
only clients access cache
of today s web
today s web development
gossip will route data
will route data around
route data around the
data around the congested
around the congested nodes
we discuss the relative
discuss the relative advantages
the relative advantages of
relative advantages of these
and will also deliver
advantages of these two
will also deliver missed
of these two approaches
also deliver missed updates
these two approaches for
deliver missed updates to
two approaches for building
missed updates to the
approaches for building soc
updates to the overloaded
for building soc applications
to the overloaded nodes
receives all transactions and
the overloaded nodes when
all transactions and rigorously
overloaded nodes when the
transactions and rigorously detects
nodes when the problem
and rigorously detects inconsistencies
when the problem ends
rigorously detects inconsistencies for
we discuss the advantages
detects inconsistencies for statistics
discuss the advantages of
the advantages of decoupling
in the original chain
advantages of decoupling transport
the original chain replication
of decoupling transport and
original chain replication scheme
decoupling transport and information
chain replication scheme the
transport and information layers
replication scheme the queries
and information layers as
scheme the queries are
information layers as a
the queries are directed
layers as a means
queries are directed to
as a means of
are directed to the
a means of achieving
directed to the tail
means of achieving reusability
to the tail of
a set of cache
the tail of the
set of cache clients
tail of the chain
of cache clients perform
cache clients perform readonly
clients perform readonly transactions
perform readonly transactions through
readonly transactions through a
since there is no
transactions through a single
there is no additional
ability to rapidly deploy
is no additional epidemic
through a single cache
to rapidly deploy soc
a single cache server
no additional epidemic communication
rapidly deploy soc applications
deploy soc applications in
soc applications in new
applications in new environments
the cache serves the
in new environments and
any update known to
new environments and adapt
cache serves the requests
environments and adapt them
update known to the
and adapt them dynamically
serves the requests from
adapt them dynamically this
known to the tail
them dynamically this work
the requests from its
dynamically this work was
to the tail is
requests from its local
this work was supported
from its local storage
the tail is stable
its local storage if
tail is stable because
local storage if possible
is stable because it
stable because it must
because it must first
it must first have
or reads from the
must first have been
reads from the database
first have been seen
from the database otherwise
have been seen by
been seen by all
seen by all the
by all the members
all the members of
the members of the
members of the chain
the cache registers an
qi huang is a
to maintain such an
huang is a visiting
maintain such an invariant
cache registers an upcall
is a visiting scientist
registers an upcall that
a visiting scientist from
an upcall that can
visiting scientist from the
upcall that can be
scientist from the school
that can be used
from the school of
the original paper includes
the school of computer
can be used by
school of computer sci
original paper includes mechanisms
be used by the
paper includes mechanisms to
used by the database
includes mechanisms to ensure
by the database to
mechanisms to ensure that
the database to report
to ensure that a
database to report invalidations
ensure that a request
that a request really
huazhong university of sci
a request really reaches
request really reaches the
really reaches the head
reaches the head of
after each update transaction
the head of the
head of the chain
each update transaction the
update transaction the database
transaction the database asynchronously
supported by the chinese
the database asynchronously sends
by the chinese nsfc
database asynchronously sends invalidations
that updates are passed
asynchronously sends invalidations to
updates are passed down
sends invalidations to the
are passed down the
invalidations to the cache
passed down the chain
to the cache for
down the chain and
the cache for all
the chain and applied
cache for all objects
chain and applied in
for all objects that
and applied in a
all objects that were
applied in a strictly
objects that were modified
in a strictly fifo
a strictly fifo manner
strictly fifo manner even
fifo manner even when
manner even when nodes
even when nodes fail
when nodes fail and
nodes fail and the
fail and the chain
and the chain is
the chain is restructured
and that queries are
that queries are sent
queries are sent to
are sent to the
sent to the tail
to the tail of
the tail of the
chosen uniformly at random
tail of the chain
are dropped by the
dropped by the experiment
strong consistency follows easily
consistency follows easily because
follows easily because query
easily because query requests
this is extreme and
because query requests and
is extreme and would
query requests and update
extreme and would only
requests and update requests
and would only be
and update requests are
would only be seen
update requests are processed
only be seen in
requests are processed serially
be seen in the
are processed serially at
seen in the real
processed serially at the
in the real world
serially at the tail
the real world under
at the tail element
real world under conditions
world under conditions of
under conditions of overload
conditions of overload or
of overload or when
the gossip based chain
overload or when the
gossip based chain replication
or when the system
based chain replication weakens
when the system configuration
chain replication weakens the
the system configuration is
replication weakens the model
system configuration is changed
weakens the model in
layered mashup to the
the model in two
mashup to the changing
model in two key
to the changing needs
in two key respects
both the database and
the database and the
database and the cache
we discuss the resulting
and the cache report
discuss the resulting objectoriented
the cache report all
the resulting objectoriented perspective
cache report all completed
report all completed transactions
our solution might sometimes
all completed transactions to
solution might sometimes use
completed transactions to a
might sometimes use the
transactions to a consistency
sometimes use the wrong
to a consistency monitor
use the wrong head
in which instances of
the wrong head of
wrong head of the
which instances of distributed
head of the chain
instances of distributed communication
created in order to
of distributed communication protocols
in order to gather
distributed communication protocols are
order to gather statistics
communication protocols are modeled
for example if an
protocols are modeled uniformly
example if an update
are modeled uniformly as
to gather statistics for
modeled uniformly as objects
gather statistics for our
uniformly as objects similar
statistics for our evaluation
if an update source
as objects similar to
an update source is
objects similar to those
update source is operating
similar to those in
source is operating with
to those in java
is operating with inaccurate
this server collects both
operating with inaccurate membership
server collects both committed
with inaccurate membership information
collects both committed and
both committed and aborted
committed and aborted transactions
and aborted transactions and
aborted transactions and it
transactions and it maintains
and it maintains the
it maintains the full
updates might sometimes arrive
maintains the full dependency
might sometimes arrive out
the full dependency graph
sometimes arrive out of
arrive out of order
the embedded script is
embedded script is often
script is often tightly
it performs full serialization
is often tightly integrated
performs full serialization graph
often tightly integrated with
full serialization graph testing
tightly integrated with backend
for example if the
integrated with backend services
example if the chain
with backend services in
if the chain is
backend services in the
the chain is disrupted
services in the data
chain is disrupted by
in the data center
is disrupted by a
disrupted by a failure
by a failure and
a failure and some
failure and some updates
and some updates arrive
making it awkward to
and calculates the rate
some updates arrive via
calculates the rate of
updates arrive via the
it awkward to access
arrive via the gossip
the rate of inconsistent
via the gossip protocol
awkward to access the
rate of inconsistent transactions
to access the underlying
of inconsistent transactions that
access the underlying services
inconsistent transactions that committed
the underlying services directly
transactions that committed and
underlying services directly from
these changes substantially simplify
services directly from a
that committed and the
directly from a different
changes substantially simplify the
from a different script
committed and the rate
substantially simplify the algorithm
and the rate of
a different script or
the rate of consistent
different script or a
simplify the algorithm but
script or a standalone
rate of consistent transactions
or a standalone client
the algorithm but they
of consistent transactions that
algorithm but they also
consistent transactions that were
but they also weaken
transactions that were unnecessarily
they also weaken the
that were unnecessarily aborted
also weaken the properties
weaken the properties of
the properties of the
properties of the solution
the only way such
our prototype does not
only way such services
prototype does not address
a less significant change
way such services can
less significant change is
does not address the
such services can be
significant change is that
not address the issue
change is that we
services can be mashed
address the issue of
is that we load
the issue of cache
can be mashed up
issue of cache eviction
be mashed up with
of cache eviction when
mashed up with other
cache eviction when running
balance queries over the
eviction when running out
up with other web
queries over the members
when running out of
with other web content
over the members of
other web content is
the members of the
web content is by
running out of memory
content is by either
members of the chain
is by either having
by either having the
either having the data
having the data center
the data center compute
data center compute the
center compute the mashup
all objects in the
objects in the workload
but in ways that
in the workload fit
in ways that seem
the workload fit in
ways that seem to
workload fit in the
so that it can
that seem to match
that it can be
fit in the cache
seem to match the
it can be accessed
to match the class
can be accessed via
match the class of
be accessed via the
the class of applications
accessed via the minibrowser
class of applications of
and eviction is only
of applications of interest
eviction is only done
is only done if
only done if there
done if there is
if there is a
there is a direct
and has the potential
is a direct reason
has the potential to
or by embedding the
the potential to greatly
by embedding the entire
potential to greatly improve
embedding the entire minibrowser
to greatly improve query
the entire minibrowser window
greatly improve query performance
entire minibrowser window in
minibrowser window in a
window in a web
in a web page
had we modeled them
but an embedded minibrowser
evictions would reduce the
an embedded minibrowser can
would reduce the cache
embedded minibrowser can t
reduce the cache hit
minibrowser can t seamlessly
the cache hit rate
can t seamlessly blend
t seamlessly blend with
seamlessly blend with the
epidemic dissemination as noted
blend with the surrounding
dissemination as noted earlier
but could not cause
with the surrounding content
could not cause new
not cause new inconsistencies
ssa uses gossip to
it is like a
uses gossip to detect
is like a standalone
gossip to detect and
we evaluate the effectiveness
like a standalone browser
to detect and repair
evaluate the effectiveness of
a standalone browser within
detect and repair the
the effectiveness of our
standalone browser within its
and repair the inconsistencies
browser within its own
effectiveness of our transactional
repair the inconsistencies that
within its own frame
the inconsistencies that can
of our transactional cache
inconsistencies that can arise
our transactional cache using
that can arise after
transactional cache using various
can arise after a
and runs independent of
arise after a failure
cache using various workloads
after a failure or
runs independent of the
using various workloads and
independent of the rest
a failure or when
of the rest of
various workloads and varying
the rest of the
failure or when a
workloads and varying the
or when a node
rest of the page
and varying the size
when a node joins
varying the size of
the size of the
size of the dependency
to illustrate this point
of the dependency lists
the basic idea is
the dependency lists maintained
basic idea is simple
dependency lists maintained by
lists maintained by the
maintained by the cache
by the cache and
the cache and the
each process in the
cache and the database
process in the system
in the system runs
the system runs a
system runs a periodic
runs a periodic local
a periodic local timer
for the cases considered
the figures are screenshots
figures are screenshots of
are screenshots of web
screenshots of web applications
without synchronization across processes
short dependency lists suffice
with content from multiple
when a timer expires
content from multiple sources
from multiple sources mashed
a process computes a
process computes a summary
also called a digest
an open question for
was constructed using a
open question for further
constructed using a standard
question for further study
using a standard web
for further study is
a standard web services
further study is whether
standard web services approach
study is whether there
is whether there are
whether there are workloads
a list of things
there are workloads that
list of things that
are workloads that might
pulling content from the
workloads that might require
content from the yahoo
that might require limited
of things that it
might require limited but
things that it knows
require limited but larger
limited but larger values
maps and weather web
and weather web services
this summary is sent
weather web services and
note that dependencies arise
summary is sent to
that dependencies arise from
is sent to a
web services and assembling
sent to a randomly
dependencies arise from the
to a randomly selected
services and assembling it
a randomly selected peer
arise from the topology
and assembling it into
from the topology of
assembling it into a
the topology of the
it into a web
topology of the object
into a web page
or subset of peers
a web page as
of the object graph
web page as a
page as a set
as a set of
a set of tiled
set of tiled frames
and not from the
not from the size
from the size of
quick delivery is more
the size of the
delivery is more important
each frame is a
is more important than
size of the transactions
more important than reliability
of the transactions read
important than reliability for
the transactions read and
frame is a minibrowser
transactions read and write
than reliability for gossip
read and write sets
is a minibrowser with
reliability for gossip messages
a minibrowser with its
minibrowser with its own
with its own interactive
as a baseline for
its own interactive controls
a baseline for comparison
hence we favor udp
we favor udp datagrams
favor udp datagrams over
udp datagrams over tcp
and comes from a
we also implemented a
comes from a single
datagrams over tcp for
from a single content
also implemented a timeout
a single content source
over tcp for this
tcp for this kind
for this kind of
this kind of communication
to illustrate one of
illustrate one of the
one of the many
of the many restrictions
it reduces the probability
the recipient compares the
reduces the probability of
recipient compares the gossiped
the probability of inconsistency
compares the gossiped information
probability of inconsistency by
if the user pans
the gossiped information with
the user pans or
of inconsistency by limiting
user pans or zooms
gossiped information with its
pans or zooms in
information with its own
or zooms in the
with its own state
zooms in the map
inconsistency by limiting the
in the map frame
by limiting the life
limiting the life span
the life span of
life span of cache
identifying information known to
span of cache entries
information known to the
the associated map will
known to the sender
associated map will shift
to the sender but
map will shift or
the sender but unknown
will shift or zoom
sender but unknown to
we compare this method
but unknown to itself
compare this method against
this method against our
method against our transactional
but the other frames
against our transactional cache
the other frames remain
our transactional cache by
or known to it
transactional cache by measuring
known to it but
cache by measuring its
to it but apparently
by measuring its effectiveness
it but apparently unknown
other frames remain as
but apparently unknown to
measuring its effectiveness with
apparently unknown to the
frames remain as they
its effectiveness with a
remain as they were
effectiveness with a varying
unknown to the sender
as they were the
with a varying time
they were the frames
were the frames are
the frames are not
frames are not synchronized
it then sends back
then sends back a
sends back a gossip
back a gossip reply
using an unreliable datagram
an unreliable datagram protocol
here we see a
we see a similar
see a similar application
a similar application constructed
similar application constructed using
application constructed using live
containing information the sender
constructed using live objects
information the sender might
both read and update
the sender might find
read and update transactions
sender might find useful
and update transactions access
might find useful and
find useful and requesting
useful and requesting information
content from different sources
and requesting information it
from different sources is
our experiment satisfies all
requesting information it lacks
experiment satisfies all read
different sources is overlaid
sources is overlaid in
is overlaid in the
overlaid in the same
in the same window
the same window and
only transactions from the
same window and synchronized
transactions from the cache
the originator of the
originator of the exchange
of the exchange will
while passing all update
we used white backgrounds
passing all update transactions
the exchange will send
all update transactions directly
used white backgrounds to
update transactions directly to
exchange will send a
transactions directly to the
white backgrounds to highlight
directly to the backend
will send a final
to the backend database
backgrounds to highlight the
send a final message
to highlight the contributions
a final message containing
highlight the contributions of
final message containing any
the contributions of different
message containing any data
contributions of different sources
containing any data that
each cache server is
any data that was
cache server is unaware
data that was solicited
server is unaware of
that was solicited by
but there are no
was solicited by the
there are no frame
solicited by the receiver
are no frame boundaries
is unaware of the
unaware of the other
of the other servers
the other servers it
gossip messages are bounded
other servers it has
messages are bounded in
elements of this mashup
are bounded in size
servers it has its
it has its own
has its own clients
its own clients and
which can include map
thus during a round
own clients and communicates
during a round each
can include map layers
a round each process
clients and communicates directly
round each process will
and communicates directly with
each process will send
communicates directly with the
process will send a
directly with the backend
will send a message
with the backend database
tables showing buildings or
showing buildings or points
buildings or points of
or points of interest
perhaps eliciting a reply
the percentage of read
icons representing severe weather
representing severe weather reports
and perhaps will respond
only transactions can be
perhaps will respond to
transactions can be arbitrarily
will respond to that
can be arbitrarily high
respond to that reply
be arbitrarily high or
arbitrarily high or low
high or low in
or low in this
low in this situation
in the worst case
a round results in
we can push the
can push the percentage
exist layers within which
push the percentage up
layers within which the
within which the end
which the end user
the end user can
the load imposed on
end user can easily
load imposed on the
our simulation focuses on
user can easily navigate
imposed on the network
simulation focuses on just
on the network will
focuses on just a
the network will thus
on just a single
network will thus be
just a single cache
will thus be linear
data can come from
thus be linear in
a single cache it
be linear in the
can come from many
linear in the number
single cache it would
in the number of
come from many kinds
the number of processes
cache it would behave
from many kinds of
it would behave the
many kinds of we
would behave the same
kinds of we discuss
behave the same had
but any individual process
the same had there
of we discuss our
same had there been
any individual process will
had there been many
individual process will see
there been many cache
process will see a
been many cache servers
will see a constant
we discuss our live
see a constant load
discuss our live distributed
our live distributed objects
live distributed objects platform
distributed objects platform as
independent of system size
objects platform as an
platform as an example
as an example of
an example of a
example of a technology
of a technology that
a technology that fits
cache can be used
technology that fits well
can be used with
that fits well with
be used with any
fits well with the
the ssa gossips about
used with any transactional
ssa gossips about membership
well with the layered
with any transactional backend
any transactional backend and
transactional backend and any
backend and any transactional
and any transactional workload
componentized model we derived
model we derived through
we derived through our
derived through our analysis
recoveries and application state
we compare performance of
using this information to
compare performance of hosted
this information to initiate
only transactions will be
performance of hosted enterprise
information to initiate repairs
transactions will be similar
of hosted enterprise service
will be similar to
hosted enterprise service bus
be similar to non
one form of repair
form of repair involves
of repair involves disruption
repair involves disruption to
involves disruption to a
disruption to a chain
the underlying database is
underlying database is only
if a fault breaks
database is only accessed
a fault breaks a
is only accessed on
fault breaks a chain
only accessed on cache
breaks a chain or
accessed on cache misses
a chain or disables
peer communication protocols as
chain or disables the
communication protocols as an
or disables the head
protocols as an underlying
disables the head of
as an underlying communication
the head of a
an underlying communication substrate
head of a chain
underlying communication substrate for
inconsistencies may be observed
communication substrate for soc
substrate for soc applications
gossip is used to
is used to detect
the relative strengths of
used to detect the
we will use synthetic
to detect the problem
relative strengths of each
will use synthetic workloads
detect the problem and
strengths of each of
use synthetic workloads so
the problem and repair
of each of the
synthetic workloads so we
problem and repair involves
each of the solutions
workloads so we can
and repair involves designating
of the solutions tested
repair involves designating a
so we can evaluate
the solutions tested and
involves designating a new
we can evaluate how
solutions tested and the
designating a new head
can evaluate how much
tested and the lack
a new head for
evaluate how much inconsistency
and the lack of
new head for the
the lack of a
head for the chain
how much inconsistency can
for the chain or
lack of a clear
the chain or establishing
much inconsistency can be
chain or establishing a
of a clear winner
or establishing a new
inconsistency can be observed
establishing a new tcp
a clear winner serve
a new tcp connection
can be observed as
clear winner serve as
new tcp connection bridging
be observed as a
tcp connection bridging the
winner serve as a
connection bridging the gap
observed as a function
serve as a further
as a function of
as a further justification
a function of the
a further justification for
function of the amount
a second form of
of the amount of
further justification for the
the amount of clustering
second form of repair
amount of clustering in
justification for the decoupling
of clustering in the
form of repair involves
clustering in the workload
for the decoupling of
of repair involves lost
the decoupling of information
repair involves lost updates
decoupling of information and
of information and transport
information and transport layers
this also allows us
and transport layers advocated
also allows us to
transport layers advocated above
if subservice a has
allows us to look
subservice a has a
us to look at
a has a member
to look at the
has a member m
look at the dynamic
a member m that
at the dynamic behavior
member m that knows
the dynamic behavior of
dynamic behavior of the
behavior of the system
we assume that all
limitations of the existing
assume that all forms
when the amount of
of the existing model
the amount of clustering
the existing model there
amount of clustering and
existing model there are
of clustering and the
model there are two
clustering and the clustering
there are two important
and the clustering formation
that all forms of
the clustering formation change
are two important reasons
all forms of information
two important reasons why
clustering formation change over
important reasons why integrating
formation change over time
reasons why integrating peerto
forms of information are
of information are uniquely
information are uniquely named
are uniquely named and
peer collaboration with server
uniquely named and that
named and that updates
and that updates are
we will look at
that updates are ordered
will look at workloads
updates are ordered separately
look at workloads based
hosted content is difficult
at workloads based on
are ordered separately by
workloads based on amazon
ordered separately by each
based on amazon s
separately by each update
on amazon s product
by each update source
amazon s product co
the first is not
first is not strictly
is not strictly limited
not strictly limited to
strictly limited to collaboration
of update x and
limited to collaboration and
update x and a
to collaboration and peer
x and a member
purchasing and orkut s
and a member m
and orkut s social
a member m that
orkut s social network
member m that lacks
s social network to
m that lacks x
social network to see
network to see how
to see how much
see how much inconsistency
how much inconsistency t
gossip can be used
can be used to
be used to detect
used to detect this
cache can detect as
to detect this and
can detect as a
detect this and m
detect as a function
it is a general
as a function of
this and m can
a function of dependency
and m can then
function of dependency list
m can then send
of dependency list length
can then send x
is a general weakness
then send x to
send x to m
a general weakness of
x to m directly
general weakness of the
and compare this with
weakness of the current
compare this with a
this with a ttl
of the current web
without waiting for the
the current web mashup
waiting for the chain
current web mashup technologies
for the chain to
web mashup technologies that
the chain to be
mashup technologies that makes
chain to be repaired
technologies that makes it
we are also interested
that makes it hard
are also interested in
makes it hard to
also interested in overhead
it hard to seamlessly
hard to seamlessly integrate
to seamlessly integrate data
seamlessly integrate data from
integrate data from several
gossip is not a
data from several different
is not a particularly
from several different sources
not a particularly fast
particularly the additional load
a particularly fast protocol
the additional load on
additional load on the
load on the backend
the web developers community
on the backend database
web developers community has
the backend database that
developers community has slowly
backend database that could
community has slowly converged
database that could form
has slowly converged towards
that could form if
slowly converged towards service
could form if the
converged towards service platforms
form if the the
towards service platforms that
if the the rate
rounds of the protocol
the the rate of
service platforms that export
the rate of cache
of the protocol to
rate of cache misses
platforms that export autonomous
of cache misses increases
the protocol to reach
that export autonomous interactive
protocol to reach n
export autonomous interactive components
to reach n processes
autonomous interactive components to
interactive components to their
components to their clients
on the other hand
b presented three strategies
presented three strategies for
in the form of
three strategies for responding
the form of what
strategies for responding to
form of what we
if rounds occur frequently
of what we ll
for responding to inconsistency
what we ll call
responding to inconsistency detection
we ll call minibrowser
ll call minibrowser interfaces
the delay before information
delay before information spreads
for both the synthetic
before information spreads to
both the synthetic and
information spreads to all
the synthetic and realistic
spreads to all members
synthetic and realistic workloads
a minibrowser is an
to all members of
minibrowser is an interactive
all members of a
is an interactive web
members of a system
an interactive web page
of a system may
interactive web page with
we compare the efficacy
web page with embedded
a system may still
page with embedded script
compare the efficacy of
system may still be
the efficacy of the
may still be small
efficacy of the three
of the three strategies
even in a large
in a large system
synthetic workloads synthetic workloads
workloads synthetic workloads allow
synthetic workloads allow us
workloads allow us to
allow us to understand
gossip is astonishingly robust
us to understand the
to understand the efficacy
understand the efficacy of
the efficacy of t
optimized for displaying a
for displaying a single
there are exponentially many
displaying a single type
are exponentially many paths
a single type of
cache as a function
exponentially many paths by
as a function of
single type of content
many paths by which
a function of clustering
paths by which information
by which information can
which information can pass
for example interactive maps
for the experiments described
example interactive maps from
the experiments described here
information can pass from
interactive maps from google
can pass from point
maps from google earth
pass from point a
from google earth or
from point a to
google earth or virtual
point a to point
earth or virtual earth
a to point b
cache with a maximum
with a maximum of
hence almost any imaginable
almost any imaginable disruption
any imaginable disruption short
elements per dependency list
imaginable disruption short of
our example actually overlays
disruption short of a
example actually overlays weather
short of a lasting
of a lasting partitioning
actually overlays weather from
a lasting partitioning failure
lasting partitioning failure can
overlays weather from google
partitioning failure can be
weather from google on
failure can be overcome
from google on terrain
google on terrain maps
describes synthetic workload generation
on terrain maps from
terrain maps from microsoft
the gossip protocols implemented
maps from microsoft s
gossip protocols implemented in
from microsoft s virtual
protocols implemented in the
microsoft s virtual earth
implemented in the ssa
s virtual earth platform
in the ssa have
virtual earth platform and
the ssa have been
earth platform and extracts
ssa have been designed
platform and extracts census
measures how many inconsistencies
and extracts census data
have been designed specifically
extracts census data from
how many inconsistencies we
census data from the
been designed specifically for
data from the us
many inconsistencies we can
from the us census
designed specifically for use
the us census bureau
inconsistencies we can detect
specifically for use in
we can detect as
for use in our
can detect as a
use in our modified
detect as a function
in our modified version
as a function of
our modified version of
the lion coexists with
modified version of chain
a function of clustering
version of chain replication
lion coexists with the
function of clustering and
coexists with the lamb
of clustering and section
clustering and section v
and with the goal
with the goal of
the second problem is
the goal of running
second problem is that
goal of running in
problem is that with
of running in large
is that with the
running in large clusters
that with the traditional
in large clusters or
with the traditional style
large clusters or datacenters
the traditional style of
considers clustering changes over
traditional style of web
clustering changes over time
style of web development
let be a group
be a group of
a group of processes
content is assumed to
is assumed to be
assumed to be fetched
and let p be
to be fetched from
let p be a
be fetched from a
p be a process
fetched from a server
be a process in
compares the efficacy of
a process in that
the efficacy of various
process in that group
efficacy of various approaches
in that group p
of various approaches to
either directly over http
various approaches to dealing
approaches to dealing with
to dealing with detected
dealing with detected inconsistencies
or by interacting with
by interacting with a
interacting with a web
with a web service
each process has its
process has its own
has its own view
its own view of
own view of the
view of the group
web pages downloaded by
pages downloaded by clients
downloaded by clients browsers
by clients browsers contain
clients browsers contain embedded
browsers contain embedded addresses
contain embedded addresses of
embedded addresses of specific
our basic synthetic workload
addresses of specific servers
basic synthetic workload is
synthetic workload is constructed
workload is constructed as
is constructed as follows
technologies such as ajax
such as ajax allow
as ajax allow for
ajax allow for asynchronous
these views can lag
views can lag reality
for example if a
example if a process
if a process joins
a process joins or
process joins or leaves
but traffic is still
traffic is still always
is still always routed
still always routed through
always routed through a
and different members might
routed through a data
different members might not
through a data center
members might not have
might not have consistent
not have consistent views
the clients don t
clients don t talk
don t talk to
our work assumes that
t talk to one
work assumes that the
talk to one another
assumes that the network
that the network within
the network within a
network within a cluster
within a cluster does
a cluster does not
cluster does not partition
the objects are divided
objects are divided into
are divided into clusters
divided into clusters of
live objects allow visual
into clusters of size
although there are low
objects allow visual content
allow visual content and
visual content and update
content and update events
and update events to
probability failure patterns that
update events to be
failure patterns that could
events to be communicated
patterns that could temporarily
to be communicated using
that could temporarily partition
be communicated using any
could temporarily partition some
communicated using any sort
temporarily partition some subservice
using any sort of
partition some subservice in
any sort of protocol
some subservice in a
subservice in a logical
in a logical sense
but also overlay multicast
process p chooses a
p chooses a random
chooses a random subset
a random subset of
random subset of a
subset of a particular
of a particular size
a particular size view
even a custom protocol
a custom protocol designed
custom protocol designed by
protocol designed by the
designed by the content
by the content provider
and commences a dialog
commences a dialog with
a dialog with each
dialog with each process
with each process in
this makes it possible
each process in the
makes it possible to
process in the set
it possible to achieve
possible to achieve extremely
to achieve extremely high
achieve extremely high levels
extremely high levels of
and there are two
high levels of throughput
there are two types
levels of throughput and
are two types of
the initial message is
two types of workloads
of throughput and latency
initial message is a
message is a compact
is a compact state
a compact state digest
compact state digest summarizing
it also enhances security
state digest summarizing the
digest summarizing the state
summarizing the state of
clustering is perfect and
the state of the
is perfect and each
state of the sender
perfect and each transaction
the data center server
and each transaction chooses
data center server can
each transaction chooses a
center server can t
transaction chooses a single
server can t see
chooses a single cluster
can t see data
a single cluster and
t see data exchanged
single cluster and chooses
see data exchanged directly
the follow up dialog
data exchanged directly between
follow up dialog consists
exchanged directly between peers
up dialog consists of
dialog consists of an
times with repetitions within
consists of an explicit
with repetitions within this
of an explicit request
repetitions within this cluster
an explicit request of
within this cluster to
explicit request of missing
this cluster to establish
request of missing update
cluster to establish its
of missing update operations
the above discussion motivates
to establish its access
above discussion motivates our
establish its access set
discussion motivates our problem
motivates our problem statement
several details of the
details of the epidemic
in the second type
of the epidemic protocols
allow web applications to
the second type of
the epidemic protocols employed
second type of workloads
web applications to overlay
type of workloads access
epidemic protocols employed in
of workloads access is
applications to overlay content
workloads access is not
protocols employed in the
access is not fully
to overlay content from
is not fully contained
employed in the framework
not fully contained within
overlay content from multiple
fully contained within each
in the framework turned
contained within each cluster
content from multiple sources
the framework turned out
from multiple sources in
framework turned out to
multiple sources in a
turned out to be
sources in a layered
out to be important
in a layered fashion
when a transaction starts
to be important determinants
be important determinants of
important determinants of system
determinants of system performance
of system performance and
such that the distinct
it chooses a cluster
system performance and behavior
chooses a cluster uniformly
that the distinct content
a cluster uniformly at
the distinct content layers
cluster uniformly at random
distinct content layers share
content layers share a
suppose that a process
layers share a single
that a process disseminates
share a single view
a process disseminates information
a single view and
process disseminates information via
single view and remain
disseminates information via epidemics
view and remain well
information via epidemics about
and remain well synchronized
via epidemics about a
epidemics about a subject
about a subject s
each object is chosen
object is chosen using
is chosen using a
chosen using a bounded
using a bounded pareto
process p gossips about
a bounded pareto distribution
p gossips about subject
bounded pareto distribution starting
gossips about subject s
pareto distribution starting at
about subject s a
distribution starting at detected
subject s a finite
or panning should cause
s a finite number
starting at detected inconsistencies
a finite number of
panning should cause all
finite number of times
should cause all layers
cause all layers to
all layers to respond
layers to respond simultaneously
as long as subject
long as subject s
as subject s is
subject s is hot
and an update in
an update in any
update in any of
in any of the
after which subject s
any of the layers
which subject s is
of the layers should
update clients access the
subject s is no
the layers should be
clients access the database
layers should be reflected
access the database at
should be reflected in
the database at a
be reflected in all
database at a rate
reflected in all other
s is no longer
at a rate of
in all other layers
is no longer gossiped
no longer gossiped about
allow updates to be
explicit requests for copies
updates to be carried
requests for copies of
to be carried by
for copies of missed
be carried by the
copies of missed messages
carried by the protocol
of missed messages are
by the protocol best
missed messages are limited
the protocol best matched
messages are limited in
protocol best matched to
are limited in size
best matched to the
matched to the setting
only clients access the
to the setting in
clients access the cache
the setting in which
access the cache at
setting in which the
to prevent a process
in which the application
the cache at a
prevent a process that
cache at a rate
which the application is
a process that lagged
the application is used
at a rate of
process that lagged behind
that lagged behind or
lagged behind or just
behind or just joined
or just joined from
just joined from trying
joined from trying to
from trying to catch
trying to catch up
the solutions discussed here
to catch up all
solutions discussed here are
catch up all at
discussed here are based
up all at once
here are based on
are based on live
based on live objects
which would result in
would result in enormous
result in enormous messages
in enormous messages and
enormous messages and serious
messages and serious fluctuations
and serious fluctuations in
serious fluctuations in system
fluctuations in system load
such a process may
new types of components
a process may need
types of components must
process may need to
of components must be
may need to catch
components must be created
need to catch up
must be created for
to catch up over
be created for each
catch up over many
created for each type
up over many seconds
for each type of
each type of content
explicit message requests are
message requests are honored
but the existing collection
requests are honored if
the existing collection of
are honored if the
existing collection of components
honored if the requested
collection of components provides
if the requested messages
of components provides access
the requested messages are
components provides access to
requested messages are still
provides access to several
messages are still in
access to several different
are still in the
to several different types
still in the bounded
several different types of
in the bounded buffers
different types of web
types of web services
of web services hosted
web services hosted content
once a message has
a message has been
message has been delivered
has been delivered to
including all the examples
been delivered to the
all the examples given
delivered to the upper
the examples given above
to the upper levels
and it has been
it has been expunged
has been expunged from
been expunged from the
expunged from the buffers
from the buffers located
the buffers located at
buffers located at the
the resulting live application
located at the gossiper
resulting live application is
at the gossiper level
live application is stored
application is stored as
is stored as an
stored as an xml
as an xml file
requests are simply ignored
the file can be
file can be moved
the requesting process would
can be moved about
requesting process would have
be moved about and
process would have to
moved about and even
would have to try
about and even embedded
have to try to
and even embedded in
to try to find
even embedded in email
try to find the
to find the missing
find the missing data
the missing data elsewhere
users that open it
that open it find
open it find themselves
it find themselves immersed
find themselves immersed into
themselves immersed into the
immersed into the application
if data cannot be
data cannot be recovered
several transport protocols optimized
we signal this to
transport protocols optimized for
signal this to the
protocols optimized for various
this to the application
optimized for various settings
to the application by
for various settings are
the application by delivering
various settings are or
application by delivering an
settings are or will
by delivering an exception
are or will be
delivering an exception upcall
or will be available
will be available in
be available in a
available in a near
in a near future
including support for wan
and leave it to
support for wan networks
leave it to the
for wan networks with
it to the application
wan networks with nats
to the application to
networks with nats and
the application to decide
with nats and firewalls
application to decide how
to decide how to
decide how to handle
how to handle the
to handle the problem
ratio of inconsistencies as
of inconsistencies as a
inconsistencies as a function
as a function of
the size of the
size of the buffers
of the buffers is
the buffers is configurable
the head of its
head of its cluster
of its cluster i
but this rule implies
this rule implies that
rule implies that certain
implies that certain kinds
that certain kinds of
certain kinds of failures
kinds of failures may
of failures may be
failures may be unrecoverable
may be unrecoverable within
be unrecoverable within the
unrecoverable within the ssa
if the pareto variable
the pareto variable plus
pareto variable plus the
digests are bounded in
variable plus the offset
are bounded in the
plus the offset results
bounded in the number
the offset results in
in the number of
offset results in a
the number of messages
results in a number
number of messages they
in a number outside
of messages they advertise
a number outside the
messages they advertise about
number outside the range
they advertise about in
advertise about in one
about in one single
in one single datagram
one single datagram packet
high throughput and very
throughput and very large
and very large numbers
very large numbers of
large numbers of nodes
and each round only
each round only a
round only a single
only a single digest
a single digest is
single digest is disseminated
even if the subset
if the subset view
the subset view selected
has cardinality greater than
cardinality greater than one
messages that are potentially
that are potentially in
large numbers of irregularly
are potentially in transit
numbers of irregularly overlapping
potentially in transit are
of irregularly overlapping multicast
in transit are not
the count wraps back
transit are not retransmitted
count wraps back to
are not retransmitted to
irregularly overlapping multicast groups
not retransmitted to requesting
retransmitted to requesting processes
for example if a
example if a process
if a process p
a process p makes
process p makes an
p makes an explicit
makes an explicit request
inconsistency detection as a
an explicit request for
detection as a function
as a function of
explicit request for a
request for a message
and strong reliability properties
for a message m
a message m and
we start by exploring
message m and the
start by exploring the
m and the request
by exploring the importance
and the request lands
exploring the importance of
the request lands at
the importance of the
request lands at process
importance of the cluster
lands at process q
of the cluster structure
at process q that
the cluster structure by
process q that has
cluster structure by varying
q that has already
structure by varying the
that has already sent
by varying the parameter
has already sent p
varying the parameter of
already sent p a
the parameter of the
sent p a copy
parameter of the pareto
p a copy of
of the pareto distribution
a copy of m
copy of m in
of m in the
m in the recent
in the recent past
we vary the pareto
the recent past then
vary the pareto parameter
recent past then m
the pareto parameter from
past then m will
then m will not
m will not be
will not be retransmitted
a process creates a
process creates a digest
before saying more about
creates a digest based
saying more about our
a digest based upon
more about our approach
digest based upon all
based upon all the
upon all the messages
all the messages received
the messages received by
messages received by means
we analyze a concrete
received by means of
analyze a concrete example
by means of any
a concrete example of
in this experiment we
means of any communication
this experiment we are
of any communication channels
experiment we are only
concrete example of a
we are only interested
example of a soc
are only interested in
of a soc application
only interested in detection
not just the epidemics
a soc application more
soc application more carefully
application more carefully to
more carefully to expose
so we choose the
carefully to expose the
we choose the abort
to expose the full
choose the abort strategy
expose the full range
the full range of
full range of needs
range of needs and
of needs and issues
needs and issues that
and issues that arise
the messages received by
shows the ratio of
messages received by fifo
the ratio of inconsistencies
consider a rescue mission
received by fifo chained
a rescue mission coordinator
by fifo chained channels
ratio of inconsistencies detected
of inconsistencies detected by
inconsistencies detected by t
a police or fire
police or fire chief
cache compared to the
or fire chief coordinating
compared to the total
the message buffers are
to the total number
message buffers are bounded
the total number of
fire chief coordinating teams
total number of potential
chief coordinating teams who
number of potential inconsistencies
coordinating teams who will
teams who will enter
and once a message
who will enter a
once a message has
will enter a disaster
a message has been
enter a disaster zone
message has been delivered
a disaster zone in
has been delivered by
disaster zone in the
been delivered by means
zone in the wake
delivered by means of
in the wake of
by means of an
the wake of a
means of an upcall
wake of a catastrophe
of an upcall it
of a catastrophe to
an upcall it is
a catastrophe to help
upcall it is prone
catastrophe to help survivors
it is prone to
is prone to be
prone to be replaced
to be replaced by
be replaced by the
replaced by the replacement
by the replacement policy
the distribution is almost
distribution is almost uniform
is almost uniform across
the ssa implements several
almost uniform across the
ssa implements several replacement
uniform across the object
implements several replacement policies
across the object set
and the inconsistency detection
the inconsistency detection ratio
inconsistency detection ratio is
most advertised message in
detection ratio is low
advertised message in digests
ratio is low the
is low the dependency
low the dependency lists
the dependency lists are
dependency lists are too
and move supplies as
lists are too small
move supplies as needed
are too small to
too small to hold
small to hold all
to hold all relevant
hold all relevant information
although the ssa should
the ssa should work
ssa should work well
at the other extreme
should work well on
work well on clusters
well on clusters with
on clusters with as
clusters with as many
with as many as
as many as thousands
many as thousands of
would arrive on the
as thousands of nodes
arrive on the scene
build a new collaboration
companies like google and
a new collaboration tool
like google and amazon
google and amazon reportedly
the distribution is so
and amazon reportedly operate
distribution is so spiked
amazon reportedly operate centers
is so spiked that
reportedly operate centers with
and distribute it to
operate centers with tens
distribute it to his
so spiked that almost
centers with tens of
spiked that almost all
with tens of thousands
that almost all accesses
tens of thousands of
almost all accesses of
of thousands of machines
all accesses of a
thousands of machines in
accesses of a transaction
of machines in them
of a transaction are
a transaction are within
each team member would
transaction are within a
team member would carry
are within a cluster
member would carry a
would carry a tablet
and are said to
are said to deploy
said to deploy some
to deploy some popular
allowing for perfect inconsistency
deploy some popular services
for perfect inconsistency detection
style device with wireless
some popular services on
device with wireless communication
popular services on huge
with wireless communication capabilities
services on huge numbers
on huge numbers of
huge numbers of nodes
we note that the
note that the rate
the application built by
that the rate of
application built by the
were we to use
the rate of detected
we to use the
built by the coordinator
to use the ssa
rate of detected inconsistencies
use the ssa in
by the coordinator would
of detected inconsistencies is
the ssa in such
the coordinator would be
ssa in such settings
detected inconsistencies is so
coordinator would be installed
inconsistencies is so high
would be installed on
is so high at
be installed on each
so high at this
our gossip protocol might
installed on each team
high at this point
on each team member
gossip protocol might need
each team member s
at this point that
team member s mobile
protocol might need to
member s mobile device
this point that much
might need to be
point that much of
need to be revisited
that much of the
to be revisited to
much of the load
be revisited to ensure
of the load goes
and in the offices
the load goes to
in the offices in
load goes to the
the offices in mission
goes to the backend
offices in mission headquarters
revisited to ensure that
to the backend database
to ensure that messages
the backend database and
ensure that messages do
backend database and saturates
that messages do not
database and saturates it
messages do not become
the coordinator would then
do not become excessively
coordinator would then deploy
not become excessively large
would then deploy teams
then deploy teams in
deploy teams in the
reducing the overall throughput
teams in the field
one way to accomplish
way to accomplish this
our rescue workers now
to accomplish this might
rescue workers now use
accomplish this might be
workers now use the
this might be to
now use the solution
might be to modify
use the solution to
be to modify the
the solution to coordinate
to modify the epidemic
solution to coordinate and
modify the epidemic protocol
to coordinate and prioritize
the epidemic protocol using
coordinate and prioritize actions
epidemic protocol using spatial
so far we have
protocol using spatial distributions
far we have considered
using spatial distributions to
we have considered behavior
spatial distributions to improve
have considered behavior with
distributions to improve the
inform each other of
to improve the performance
considered behavior with static
each other of the
behavior with static clusters
other of the evolving
of the evolving situation
steer clear of hazards
over the entire run
the entire run of
entire run of each
run of each experiment
of each experiment accesses
each experiment accesses are
as new events occur
experiment accesses are confined
such an approach would
accesses are confined to
an approach would let
are confined to the
approach would let us
confined to the same
would let us restrict
the situational status would
let us restrict information
situational status would evolve
us restrict information to
restrict information to the
information to the vicinity
to the vicinity of
the vicinity of the
and the team member
vicinity of the nodes
the team member who
of the nodes where
team member who causes
the nodes where it
member who causes or
nodes where it might
who causes or observes
where it might be
causes or observes these
it might be needed
in a real system
or observes these status
observes these status changes
these status changes would
status changes would need
changes would need to
in effect adding an
would need to report
effect adding an additional
need to report them
adding an additional layer
to report them to
and so if t
an additional layer of
report them to the
additional layer of hierarchy
them to the others
layer of hierarchy to
of hierarchy to the
hierarchy to the architecture
cache converges to maintain
converges to maintain the
to maintain the correct
maintain the correct dependency
the correct dependency lists
we believe the required
correct dependency lists as
believe the required changes
dependency lists as clusters
the required changes would
lists as clusters change
required changes would be
removing debris blocking access
changes would be relatively
debris blocking access to
would be relatively minor
blocking access to a
our setup serves as
access to a building
setup serves as a
to a building may
serves as a valid
a building may enable
as a valid quasi
building may enable the
may enable the team
enable the team to
the team to check
team to check it
to check it for
check it for victims
and fire that breaks
fire that breaks out
we investigate the convergence
that breaks out in
investigate the convergence of
breaks out in a
the convergence of t
out in a chemical
in a chemical storage
a chemical storage warehouse
epidemic analytical model one
chemical storage warehouse may
cache when clusters change
analytical model one benefit
when clusters change over
storage warehouse may force
clusters change over time
warehouse may force diversion
model one benefit of
may force diversion of
force diversion of resources
one benefit of using
benefit of using gossip
since the dependency lists
of using gossip in
the dependency lists of
using gossip in the
as rescue workers capture
dependency lists of the
rescue workers capture information
gossip in the ssa
lists of the objects
in the ssa is
of the objects are
the ssa is that
the objects are updated
ssa is that we
objects are updated using
is that we can
their mobile devices send
are updated using lru
that we can use
mobile devices send updates
we can use analytical
devices send updates that
can use analytical methods
send updates that must
use analytical methods to
the dependency list of
analytical methods to predict
dependency list of an
methods to predict the
updates that must be
to predict the behavior
list of an object
predict the behavior of
that must be propagated
of an object o
must be propagated in
the behavior of a
be propagated in real
behavior of a cluster
an object o tends
object o tends to
o tends to include
tends to include those
to include those objects
complementing our experimental work
include those objects that
those objects that are
objects that are frequently
having defined the scenario
that are frequently accessed
are frequently accessed together
frequently accessed together with
a basic result of
accessed together with o
basic result of epidemic
now let s analyze
result of epidemic theory
let s analyze in
of epidemic theory states
s analyze in more
dependencies in a new
analyze in more detail
epidemic theory states that
in a new cluster
in more detail the
a new cluster automatically
more detail the requirements
theory states that simple
detail the requirements it
new cluster automatically push
the requirements it places
states that simple epidemics
requirements it places on
cluster automatically push out
it places on our
that simple epidemics eventually
places on our collaboration
automatically push out dependencies
on our collaboration tool
simple epidemics eventually infect
push out dependencies that
epidemics eventually infect the
out dependencies that are
eventually infect the entire
dependencies that are now
infect the entire population
that are now outside
the entire population with
are now outside the
entire population with probability
now outside the cluster
the collaboration tool pulls
collaboration tool pulls data
tool pulls data from
pulls data from many
data from many kinds
moreover starting with a
from many kinds of
many kinds of sources
starting with a single
with a single infected
we perform an experiment
a single infected site
perform an experiment where
single infected site this
it makes far more
an experiment where accesses
makes far more sense
infected site this is
far more sense to
experiment where accesses suddenly
more sense to imagine
site this is achieved
sense to imagine that
where accesses suddenly become
to imagine that weather
this is achieved in
imagine that weather information
accesses suddenly become clustered
is achieved in expected
achieved in expected time
in expected time proportional
expected time proportional to
time proportional to the
initially accesses are uniformly
proportional to the log
accesses are uniformly at
to the log of
are uniformly at random
the log of the
uniformly at random from
log of the population
at random from the
of the population size
random from the entire
from the entire set
messages and alerts come
and alerts come from
alerts come from a
come from a dozen
the protocol roughly falls
from a dozen providers
protocol roughly falls under
a dozen providers than
roughly falls under the
dozen providers than to
falls under the category
providers than to assume
under the category of
than to assume that
the category of a
then at a single
to assume that one
at a single moment
category of a push
a single moment they
assume that one organization
single moment they become
that one organization would
moment they become perfectly
one organization would be
they become perfectly clustered
organization would be hosting
become perfectly clustered into
would be hosting services
perfectly clustered into clusters
be hosting services with
clustered into clusters of
hosting services with everything
into clusters of size
and the exact formula
services with everything we
the exact formula for
with everything we need
exact formula for it
everything we need in
formula for it can
we need in one
for it can be
need in one place
it can be expressed
can be expressed as
be expressed as log
transactions are aborted on
are aborted on detecting
aborted on detecting an
data from distinct sources
on detecting an inconsistency
from distinct sources could
distinct sources could have
sources could have different
could have different format
we use a transaction
have different format and
use a transaction rate
different format and one
a transaction rate of
format and one will
transaction rate of approximately
and one will often
one will often need
will often need to
often need to interface
need to interface to
to interface to each
interface to each using
to each using its
each using its own
using its own protocols
its own protocols and
own protocols and interfaces
as conditions evolve the
conditions evolve the team
evolve the team might
the team might need
for large values of
team might need to
large values of n
might need to be
need to be modify
to be modify the
be modify the application
where n the number
n the number of
the number of sites
number of sites participating
for example adding new
of sites participating in
example adding new types
sites participating in the
adding new types of
participating in the epidemic
new types of information
in the epidemic spread
shows the percentage of
the percentage of transactions
changing the way it
let pi be the
percentage of transactions that
pi be the probability
the way it is
be the probability that
way it is represented
the probability that a
of transactions that commit
probability that a site
transactions that commit and
that a site remains
that commit and are
a site remains susceptible
commit and are consistent
or even modifying the
even modifying the way
modifying the way team
the way team members
way team members communicate
not touched by the
touched by the epidemic
after the ith round
the ith round of
ith round of the
the percentage of transactions
round of the protocol
percentage of transactions that
of transactions that commit
transactions that commit but
back network links fail
that commit but are
commit but are inconsistent
a site remains susceptible
site remains susceptible after
remains susceptible after the
susceptible after the i
whereas a minibrowser would
a minibrowser would typically
minibrowser would typically be
would typically be prebuilt
typically be prebuilt with
and the percentage of
be prebuilt with all
the percentage of transactions
prebuilt with all the
percentage of transactions that
with all the available
of transactions that abort
all the available features
th round if it
the available features in
available features in place
round if it was
if it was susceptible
it was susceptible after
was susceptible after the
susceptible after the ith
our scenario demands a
after the ith cycle
scenario demands a much
the ith cycle and
demands a much more
ith cycle and it
a much more flexible
cycle and it is
much more flexible kind
and it is not
more flexible kind of
it is not contacted
flexible kind of tool
is not contacted by
kind of tool that
not contacted by any
of tool that can
contacted by any infectious
tool that can be
by any infectious site
that can be redesigned
any infectious site in
can be redesigned while
infectious site in the
be redesigned while in
site in the i
redesigned while in use
depending on the location
on the location and
the location and other
location and other factors
the best networking protocols
best networking protocols and
networking protocols and connectivity
protocols and connectivity options
and connectivity options may
connectivity options may vary
relation that we obtain
that we obtain is
in our rescue scenario
the workers may have
workers may have to
may have to use
have to use wireless
to use wireless p
p protocols much of
protocols much of the
much of the time
reaching back to hosted
back to hosted services
to hosted services only
hosted services only intermittently
services only intermittently when
only intermittently when a
intermittently when a drone
since infection starts with
when a drone aircraft
infection starts with one
a drone aircraft passes
starts with one site
drone aircraft passes within
aircraft passes within radio
passes within radio range
for any randomly chosen
any randomly chosen site
randomly chosen site p
the right choice of
right choice of protocol
choice of protocol should
of protocol should reflect
protocol should reflect the
should reflect the operating
abort evict retry behavior
reflect the operating conditions
evict retry behavior on
retry behavior on inconsistency
behavior on inconsistency detection
and if these change
the platform should be
platform should be capable
should be capable of
as a function of
be capable of swapping
a function of the
capable of swapping in
function of the rate
of swapping in a
of the rate of
swapping in a different
the rate of gossip
in a different protocol
a different protocol without
different protocol without disrupting
protocol without disrupting the
without disrupting the end
disrupting the end user
we can predict the
can predict the delay
predict the delay before
this argues for a
the delay before a
argues for a decoupling
for a decoupling of
delay before a typical
a decoupling of functionality
before a typical process
a typical process that
typical process that has
whereas a minibrowser packages
process that has been
a minibrowser packages it
that has been disrupted
minibrowser packages it all
has been disrupted by
packages it all into
been disrupted by a
it all into one
disrupted by a failure
all into one object
by a failure will
a failure will learn
failure will learn about
will learn about inconsistency
learn about inconsistency introduced
better is a design
about inconsistency introduced by
is a design in
inconsistency introduced by the
a design in which
introduced by the failure
design in which the
by the failure and
in which the presentation
the failure and can
which the presentation object
failure and can initiate
and can initiate repair
the presentation object is
presentation object is distinct
object is distinct from
is distinct from objects
distinct from objects representing
from objects representing information
objects representing information sources
representing information sources and
if the model predicts
information sources and objects
the model predicts that
sources and objects representing
model predicts that for
and objects representing transport
predicts that for a
objects representing transport protocols
that for a given
for a given gossip
a given gossip rate
decoupling makes it possible
makes it possible to
a broken chain should
it possible to dynamically
broken chain should be
possible to dynamically modify
chain should be repaired
to dynamically modify or
should be repaired within
dynamically modify or even
modify or even replace
or even replace a
even replace a component
replace a component with
a component with some
component with some other
option when changing conditions
when changing conditions require
changing conditions require it
one can anticipate that
can anticipate that the
anticipate that the disruption
we have posed what
that the disruption associated
have posed what may
posed what may sound
the disruption associated with
what may sound like
may sound like a
disruption associated with a
sound like a very
like a very specialized
associated with a failure
a very specialized problem
with a failure should
s accesses are uniformly
a failure should be
accesses are uniformly at
failure should be limited
are uniformly at random
but in fact we
should be limited to
in fact we see
be limited to the
fact we see this
limited to the maximum
we see this as
to the maximum number
see this as a
the maximum number of
this as a good
maximum number of updates
as a good example
number of updates that
a good example of
of updates that would
good example of a
updates that would be
example of a more
that would be sent
of a more general
would be sent to
a more general kind
be sent to a
more general kind of
sent to a given
general kind of need
to a given subservice
kind of need that
a given subservice during
of need that could
given subservice during a
need that could arise
that could arise in
the efficacy of t
could arise in many
arise in many kinds
in many kinds of
many kinds of settings
cache as a function
as a function of
a function of the
function of the strategy
of the strategy taken
the strategy taken for
strategy taken for handling
taken for handling detected
consider a physician treating
for handling detected inconsistencies
a physician treating a
physician treating a patient
treating a patient with
a patient with a
patient with a complex
with a complex condition
if we know how
we know how large
know how large the
how large the typical
large the typical update
who needs collaboration help
the typical update is
needs collaboration help from
collaboration help from specialists
of the uncommitable tranasctions
and who might even
who might even be
might even be working
and we know the
even be working in
we know the size
be working in a
and evict and retry
know the size limit
working in a remote
evict and retry reduce
the size limit on
and retry reduce the
size limit on data
retry reduce the rate
limit on data sent
reduce the rate of
on data sent in
the rate of uncommitable
data sent in response
rate of uncommitable transactions
sent in response to
in a remote location
in response to explicit
of uncommitable transactions to
response to explicit requests
a remote location under
uncommitable transactions to about
remote location under conditions
location under conditions demanding
under conditions demanding urgent
conditions demanding urgent action
we can predict the
can predict the amount
predict the amount of
the amount of time
the mixture of patient
amount of time that
mixture of patient data
of time that will
time that will be
that will be needed
will be needed to
be needed to repair
needed to repair the
to repair the resulting
repair the resulting data
the resulting data inconsistency
the middle portion is
middle portion is committed
portion is committed transactions
is committed transactions that
these capabilities should help
committed transactions that are
transactions that are inconsistent
capabilities should help the
should help the developer
help the developer parameterize
may be just as
the developer parameterize the
be just as rich
and the top portion
just as rich and
the top portion is
developer parameterize the cluster
top portion is aborted
as rich and dynamic
portion is aborted transactions
parameterize the cluster to
rich and dynamic as
the cluster to balance
and dynamic as in
cluster to balance overhead
dynamic as in our
to balance overhead for
as in our search
balance overhead for gossip
in our search and
overhead for gossip against
our search and rescue
for gossip against repair
search and rescue scenario
gossip against repair times
against repair times desired
repair times desired by
times desired by the
desired by the application
and the underlying communication
the underlying communication options
underlying communication options equally
communication options equally heterogeneous
options equally heterogeneous and
equally heterogeneous and unpredictable
membership some readers may
some readers may be
readers may be curious
may be curious about
be curious about what
curious about what will
about what will seem
designed for a wired
what will seem to
for a wired environment
will seem to be
a wired environment might
seem to be a
wired environment might perform
to be a chicken
environment might perform poorly
might perform poorly or
perform poorly or fail
poorly or fail under
or fail under such
fail under such conditions
on the one hand
if there is a
there is a way
is a way to
a way to solve
way to solve the
we use gossip epidemics
to solve the problem
use gossip epidemics to
gossip epidemics to propagate
epidemics to propagate information
to propagate information about
propagate information about membership
there is a way
information about membership changes
is a way to
a way to build
way to build the
to build the desired
build the desired mashup
yet the gossip protocol
the gossip protocol uses
gossip protocol uses membership
protocol uses membership information
throughout the above we
uses membership information to
the above we noted
membership information to select
above we noted requirements
information to select gossip
to select gossip peers
we now summarize them
now summarize them below
our solution starts with
solution starts with approximate
starts with approximate membership
with approximate membership information
these needs are seen
extracted from a group
needs are seen in
are seen in many
from a group management
seen in many settings
a group management service
group management service component
management service component that
service component that list
component that list the
that list the nodes
list the nodes in
we believe them to
the nodes in the
believe them to be
nodes in the cluster
them to be typical
in the cluster and
to be typical of
the cluster and the
be typical of most
cluster and the rough
typical of most soc
and the rough mapping
of most soc applications
the rough mapping of
rough mapping of services
mapping of services to
of services to those
services to those nodes
we would like to
would like to enable
like to enable a
to enable a non
and then refines this
then refines this with
refines this with incremental
this with incremental updates
programmer to rapidly develop
to rapidly develop a
rapidly develop a new
develop a new collaborative
a different concern relates
a new collaborative application
different concern relates to
new collaborative application by
concern relates to behavior
collaborative application by composing
relates to behavior when
application by composing together
to behavior when membership
by composing together and
behavior when membership information
composing together and customizing
when membership information is
together and customizing preexisting
membership information is perceived
and customizing preexisting components
information is perceived differently
is perceived differently at
perceived differently at different
differently at different nodes
we would like to
would like to be
like to be able
to be able to
although such a condition
be able to overlay
such a condition may
able to overlay data
a condition may arise
to overlay data from
condition may arise during
overlay data from multiple
may arise during transitional
data from multiple sources
arise during transitional periods
potentially in different formats
these quickly resolve as
quickly resolve as additional
resolve as additional rounds
as additional rounds of
obtained using different protocols
additional rounds of gossip
using different protocols and
rounds of gossip replace
different protocols and inconsistent
of gossip replace stale
protocols and inconsistent interfaces
gossip replace stale data
replace stale data with
stale data with more
data with more accurate
we would like to
would like to be
like to be able
to be able to
be able to dynamically
able to dynamically customize
to dynamically customize the
dynamically customize the application
customize the application at
the application at runtime
we have never observed
have never observed a
never observed a membership
observed a membership inconsistency
a membership inconsistency that
membership inconsistency that persisted
inconsistency that persisted for
that persisted for longer
persisted for longer than
for longer than a
longer than a few
than a few hundred
a few hundred milliseconds
by incorporating new data
incorporating new data sources
new data sources or
the ssa is quite
data sources or changing
ssa is quite tolerant
sources or changing the
is quite tolerant of
or changing the way
quite tolerant of short
changing the way data
the way data is
way data is presented
customuserserviceapp heartbeatmonitor gossiper subserviceprocess
heartbeatmonitor gossiper subserviceprocess chainlink
and without disrupting system
gossiper subserviceprocess chainlink subservicecontrol
without disrupting system operation
subserviceprocess chainlink subservicecontrol nonblockingtransport
perfectly clustered synthetic workload
we would like to
clustered synthetic workload where
would like to be
synthetic workload where the
like to be able
workload where the clusters
to be able to
where the clusters shift
be able to accommodate
the clusters shift by
able to accommodate new
to accommodate new types
accommodate new types of
new types of data
types of data sources
new formats or protocols
the component stack of
formats or protocols that
component stack of one
or protocols that we
marked by vertical lines
stack of one subservice
protocols that we may
of one subservice process
that we may not
we may not have
may not have anticipated
not have anticipated at
have anticipated at the
anticipated at the time
at the time the
the time the system
time the system was
the system was released
failure and recovery process
data might be published
and recovery process failure
might be published by
s access is unclustered
be published by the
recovery process failure detection
published by the individual
process failure detection is
by the individual users
failure detection is accomplished
detection is accomplished by
and as a result
is accomplished by means
as a result the
accomplished by means of
a result the dependency
by means of two
result the dependency lists
and it might be
means of two mechanisms
the dependency lists are
it might be necessary
dependency lists are useless
might be necessary for
be necessary for the
necessary for the users
detecting fifo channels that
for the users to
fifo channels that break
the users to exchange
only few inconsistencies are
users to exchange their
few inconsistencies are detected
to exchange their data
exchange their data without
their data without access
in our case they
data without access to
our case they are
without access to a
case they are tcp
access to a centralized
they are tcp channels
to a centralized repository
are tcp channels with
tcp channels with low
channels with low value
with low value for
low value for the
value for the so
data may be obtained
for the so timeout
may be obtained using
the so timeout property
be obtained using different
obtained using different types
using different types of
different types of network
types of network protocols
of the transactions that
the transactions that commit
transactions that commit have
that commit have witnessed
commit have witnessed inconsistent
and the type of
have witnessed inconsistent data
the type of the
based heartbeat detection mechanism
type of the physical
of the physical network
the physical network or
physical network or protocols
network or protocols may
once a process is
or protocols may not
a process is deceased
protocols may not be
may not be known
not be known in
be known in advance
the information is propagated
information is propagated within
is propagated within the
propagated within the group
it should be possible
within the group in
should be possible to
the group in two
be possible to rapidly
accesses become perfectly clustered
group in two ways
possible to rapidly compose
to rapidly compose the
rapidly compose the application
compose the application using
the application using whatever
application using whatever communication
using whatever communication infrastructure
whatever communication infrastructure is
we see fast improvement
communication infrastructure is currently
see fast improvement of
infrastructure is currently available
the process that has
fast improvement of inconsistency
process that has detected
improvement of inconsistency detection
that has detected the
has detected the membership
users may be mobile
detected the membership change
may be mobile or
the membership change feeds
be mobile or temporarily
the inconsistency rate drops
mobile or temporarily disconnected
membership change feeds the
inconsistency rate drops as
change feeds the event
rate drops as the
feeds the event description
drops as the abort
the event description into
as the abort rate
event description into the
the abort rate rises
description into the chain
abort rate rises this
into the chain itself
rate rises this is
and the topology of
rises this is desired
the topology of the
this is desired as
topology of the network
is desired as well
of the network and
this is delivered in
the network and its
is delivered in chain
network and its characteristics
delivered in chain order
and its characteristics might
in chain order to
its characteristics might change
chain order to every
characteristics might change over
the overall rate of
order to every non
might change over time
overall rate of consistent
rate of consistent committed
of consistent committed transactions
faulty process and where
consistent committed transactions drops
process and where necessary
the system should be
committed transactions drops because
system should be easily
transactions drops because the
should be easily reconfigurable
drops because the probability
because the probability of
chain repair procedure is
the probability of conflicts
repair procedure is undertaken
probability of conflicts in
the requirements outlined above
of conflicts in the
requirements outlined above might
conflicts in the clustered
outlined above might seem
in the clustered scenario
above might seem hard
the clustered scenario is
might seem hard to
the same detector process
seem hard to satisfy
clustered scenario is higher
same detector process starts
detector process starts up
process starts up a
starts up a backup
up a backup gossip
a backup gossip notification
backup gossip notification stream
the solution is surprisingly
solution is surprisingly simple
to illustrate more realistic
illustrate more realistic behavior
this is a fast
is a fast dying
a fast dying epidemic
our analysis motivates a
analysis motivates a component
we use clustered accesses
use clustered accesses that
clustered accesses that slowly
it spreads rapidly but
accesses that slowly drift
spreads rapidly but also
rapidly but also dies
but also dies out
also dies out rapidly
transactions are perfectly clustered
in which the web
which the web services
the fifo channels are
the web services and
as in the previous
web services and hosted
in the previous experiment
fifo channels are rebuilt
services and hosted content
channels are rebuilt appropriately
and hosted content are
are rebuilt appropriately by
hosted content are modeled
rebuilt appropriately by the
content are modeled as
appropriately by the processes
are modeled as reusable
by the processes that
modeled as reusable overlayed
the processes that identify
as reusable overlayed information
minutes the cluster structure
reusable overlayed information layers
the cluster structure shifts
processes that identify themselves
cluster structure shifts by
overlayed information layers backed
that identify themselves to
information layers backed by
identify themselves to be
layers backed by customizable
themselves to be affected
backed by customizable transport
to be affected by
by customizable transport layers
be affected by the
affected by the membership
by the membership change
a graph of components
and the group converges
the group converges to
group converges to a
converges to a stable
a collaborative application is
to a stable configuration
collaborative application is a
application is a forest
a set of such
set of such graphs
update sources can use
sources can use this
our vision demands a
can use this update
vision demands a new
demands a new kind
use this update to
a new kind of
new kind of soc
this update to reconnect
kind of soc standard
update to reconnect to
to reconnect to a
reconnect to a new
to a new head
in order to facilitate
a new head of
order to facilitate the
new head of any
to facilitate the side
head of any chain
of any chain that
any chain that may
chain that may have
that may have lost
may have lost its
have lost its previous
lost its previous head
its previous head as
side coexistence of components
previous head as a
coexistence of components that
head as a consequence
of components that might
as a consequence of
components that might today
a consequence of the
that might today be
consequence of the crash
might today be implemented
today be implemented as
be implemented as proprietary
implemented as proprietary minibrowsers
if we enable components
if a process wants
we enable components to
a process wants to
enable components to talk
process wants to join
components to talk to
to talk to oneanother
it starts by sending
starts by sending a
we need to agree
by sending a request
need to agree on
sending a request to
to agree on the
a request to a
agree on the events
request to a random
on the events and
to a random member
the events and representation
a random member of
events and representation that
random member of the
and representation that the
member of the group
representation that the dialog
that the dialog will
the dialog will employ
and wrapping back to
wrapping back to zero
back to zero after
the decoupling of functionality
decoupling of functionality into
the group member will
of functionality into layers
group member will commence
functionality into layers also
member will commence a
into layers also suggests
will commence a membership
layers also suggests a
commence a membership change
also suggests a need
a membership change protocol
suggests a need for
membership change protocol as
a need for a
change protocol as described
need for a standardized
protocol as described above
for a standardized layering
again once all the
in the examples above
once all the nodes
all the nodes receive
the nodes receive the
nodes receive the membership
receive the membership event
one can identify at
the membership event and
can identify at least
membership event and update
identify at least four
event and update their
and update their view
the objects dependency lists
the linkage layer that
objects dependency lists are
linkage layer that talks
dependency lists are outdated
layer that talks to
that talks to the
talks to the underlying
to the underlying data
implementation details the framework
the underlying data source
details the framework was
this leads to a
the framework was implemented
leads to a sudden
the update generating and
to a sudden increased
update generating and interpreting
framework was implemented using
generating and interpreting layer
a sudden increased inconsistency
was implemented using the
sudden increased inconsistency rate
implemented using the java
increased inconsistency rate that
using the java language
inconsistency rate that converges
the java language and
rate that converges back
java language and its
that converges back to
language and its non
and the transport protocol
converges back to zero
until this convergence is
this convergence is interrupted
convergence is interrupted by
is interrupted by the
we propose that this
interrupted by the next
propose that this decoupling
by the next shift
that this decoupling be
this decoupling be done
the system design was
decoupling be done using
system design was strongly
be done using event
design was strongly influenced
was strongly influenced by
strongly influenced by prior
influenced by prior work
by prior work on
prior work on highperformance
work on highperformance services
on highperformance services platforms
a natural way of
natural way of thinking
way of thinking about
of thinking about components
notably welsh s seda
thinking about components that
welsh s seda architecture
about components that dates
components that dates back
that dates back to
dates back to smalltalk
b presented three possible
presented three possible strategies
three possible strategies for
possible strategies for the
strategies for the cache
for the cache to
rather than having the
the cache to deal
than having the data
cache to deal with
having the data center
to deal with inconsistency
the data center developer
deal with inconsistency detection
data center developer offer
center developer offer content
components are highly autonomous
developer offer content through
offer content through proprietary
content through proprietary minibrowser
through proprietary minibrowser interface
she would define an
would define an event
there are only four
are only four distinct
only four distinct control
four distinct control threads
distinct control threads in
based interface between transport
control threads in the
interface between transport and
threads in the component
between transport and information
in the component stack
transport and information layers
the component stack of
component stack of a
stack of a process
the visual events delivered
visual events delivered by
events delivered by the
delivered by the transport
by the transport could
the transport could then
aborting and evicting value
transport could then be
could then be delivered
then be delivered to
be delivered to an
delivered to an information
to an information layer
namely one for the
an information layer responsible
one for the non
information layer responsible for
for the non blocking
layer responsible for visualizing
the non blocking transport
responsible for visualizing them
the tcp chain and
tcp chain and for
chain and for the
and for the heartbeat
for the heartbeat component
user mouse and keyboard
through when possible as
mouse and keyboard events
when possible as in
and keyboard events and
possible as in cache
keyboard events and pass
as in cache miss
events and pass them
the ssa is roughly
and pass them down
with this type of
this type of event
we will now compare
will now compare their
now compare their efficacies
either layer could easily
layer could easily be
could easily be replaced
easily be replaced with
we use the approximate
be replaced with a
use the approximate clusters
replaced with a different
the approximate clusters workload
with a different one
approximate clusters workload with
peer protocols would also
protocols would also be
would also be encapsulated
also be encapsulated within
a window size of
be encapsulated within their
encapsulated within their respective
within their respective transport
their respective transport layers
a pareto parameter of
one version of a
version of a transport
of a transport layer
a transport layer could
transport layer could fetch
layer could fetch data
could fetch data directly
fetch data directly from
data directly from a
and the maximum dependency
directly from a server
the maximum dependency list
from a server in
maximum dependency list size
a server in a
dependency list size is
server in a data
list size is set
in a data center
size is set to
whereas a different version
a different version might
different version might use
version might use a
might use a peer
a reliable multicast protocol
the lower portion of
lower portion of the
portion of the graph
of the graph is
it could leverage different
the graph is the
could leverage different type
graph is the ratio
leverage different type of
is the ratio of
different type of hardware
the ratio of committed
type of hardware or
ratio of committed transactions
of hardware or be
of committed transactions that
hardware or be optimized
committed transactions that the
or be optimized for
transactions that the abort
be optimized for different
that the abort strategy
optimized for different types
the abort strategy provides
for different types of
abort strategy provides a
different types of workloads
strategy provides a significant
provides a significant improvement
a significant improvement over
significant improvement over a
improvement over a normal
provided that the different
that the different versions
the different versions of
different versions of the
versions of the transport
of the transport layer
the transport layer conform
transport layer conform to
layer conform to the
conform to the same
to the same standardized
the same standardized event
as the strategy detects
the strategy detects and
strategy detects and aborts
detects and aborts over
the application could then
application could then switch
could then switch between
then switch between them
switch between them as
between them as conditions
them as conditions demand
of all inconsistent transactions
all inconsistent transactions that
inconsistent transactions that would
transactions that would have
that would have been
would have been committed
but the other strategies
the other strategies make
other strategies make further
strategies make further improvements
users interact through live
evict reduces uncommittable transactions
interact through live objects
reduces uncommittable transactions to
through live objects that
live objects that transform
objects that transform actions
that transform actions into
transform actions into updates
actions into updates that
into updates that are
updates that are communicated
that are communicated in
are communicated in the
of its value with
communicated in the form
its value with abort
in the form of
the form of events
form of events that
of events that are
events that are shared
this indicates that violating
that are shared via
are shared via the
shared via the transport
via the transport layer
the protocol implemented by
protocol implemented by the
implemented by the transport
by the transport layer
the transport layer might
cache entries are likely
transport layer might replicate
entries are likely to
layer might replicate the
are likely to be
might replicate the event
likely to be repeat
to be repeat offenders
deliver it to the
it to the tablets
they are too old
to the tablets of
are too old for
the tablets of our
too old for objects
tablets of our rescue
old for objects that
of our rescue workers
for objects that are
objects that are likely
that are likely to
are likely to be
and report it through
likely to be accessed
report it through the
to be accessed together
it through the event
be accessed together with
accessed together with them
together with them in
with them in future
them in future transactions
based interface back to
interface back to the
back to the information
to the information layer
and so it is
the information layer at
so it is better
information layer at which
it is better to
layer at which the
is better to evict
at which the event
better to evict them
which the event has
the event has originated
retry reduces uncommittable transactions
reduces uncommittable transactions further
uncommittable transactions further to
transactions further to about
the transport layer with
transport layer with the
layer with the embedded
with the embedded distributed
the embedded distributed protocol
embedded distributed protocol would
distributed protocol would behave
protocol would behave very
would behave very much
behave very much like
of its value with
very much like an
its value with abort
much like an object
like an object in
an object in smalltalk
it would consume events
would consume events and
realistic workloads we now
consume events and respond
workloads we now evaluate
events and respond with
we now evaluate the
and respond with events
now evaluate the efficacy
evaluate the efficacy of
the efficacy of t
this motivates thinking about
motivates thinking about communication
thinking about communication protocols
cache with workloads based
about communication protocols as
with workloads based on
communication protocols as objects
workloads based on two
based on two sampled
on two sampled topologies
two sampled topologies from
sampled topologies from the
and indeed in treating
topologies from the online
indeed in treating them
from the online retailer
in treating them as
the online retailer amazon
treating them as objects
online retailer amazon and
them as objects much
retailer amazon and the
amazon and the social
as objects much as
and the social network
the social network orkut
objects much as we
much as we treat
as we treat any
we treat any other
treat any other kind
any other kind of
other kind of object
kind of object in
of object in a
object in a language
describes how we generated
in a language like
how we generated these
a language like java
we generated these workloads
language like java or
like java or in
java or in a
or in a runtime
in a runtime environment
a runtime environment like
runtime environment like jini
environment like jini or
measures the efficacy of
the efficacy of t
doing so unifies apparently
so unifies apparently distinct
unifies apparently distinct approaches
cache on these workloads
on these workloads as
these workloads as a
workloads as a function
as a function of
just as a remotely
a function of maximum
as a remotely hosted
function of maximum dependency
a remotely hosted form
of maximum dependency list
remotely hosted form of
maximum dependency list size
hosted form of content
form of content such
of content such as
content such as a
and compares this to
such as a map
compares this to a
as a map or
this to a strategy
a map or an
to a strategy based
map or an image
a strategy based on
or an image of
strategy based on ttls
an image of a
image of a raincloud
of a raincloud can
a raincloud can be
raincloud can be modeled
can be modeled as
be modeled as an
modeled as an object
so can network protocols
can network protocols be
compares the efficacy of
network protocols be treated
the efficacy of the
protocols be treated as
efficacy of the three
be treated as objects
of the three strategies
the three strategies of
three strategies of dealing
strategies of dealing with
of dealing with detected
dealing with detected inconsistencies
p systems try to
systems try to make
try to make everything
to make everything a
make everything a p
but in the examples
in the examples we
we generated two workloads
the examples we ve
generated two workloads based
examples we ve seen
two workloads based on
workloads based on real
based on real data
several kinds of content
kinds of content would
of content would more
content would more naturally
would more naturally be
more naturally be hosted
we started from a
started from a snapshot
from a snapshot of
a snapshot of amazon
d images of terrain
snapshot of amazon s
images of terrain and
of amazon s product
of terrain and buildings
amazon s product co
purchasing graph taken early
on the other hand
soc applications are likely
applications are likely to
are likely to embody
likely to embody quite
to embody quite a
embody quite a range
quite a range of
a range of p
each separate video object
each product sold by
product sold by the
sold by the online
by the online retailer
the online retailer is
online retailer is a
retailer is a node
is a node and
a node and each
node and each pair
may have its own
and each pair of
have its own associated
each pair of products
its own associated update
pair of products purchased
own associated update stream
of products purchased in
products purchased in a
purchased in a single
in a single user
a single user session
if one thinks of
single user session is
one thinks of these
user session is an
thinks of these as
session is an edge
of these as topics
these as topics in
as topics in publish
the original graph contains
original graph contains more
graph contains more than
an application could have
application could have many
could have many such
have many such topics
and the application instance
the application instance running
application instance running on
instance running on a
running on a given
on a given user
a given user s
given user s machine
user s machine could
s machine could simultaneously
machine could simultaneously display
could simultaneously display data
simultaneously display data from
display data from several
data from several topics
we have previously said
have previously said that
previously said that we
said that we d
that we d like
we d like to
d like to think
like to think of
to think of protocols
think of protocols as
of protocols as objects
it now becomes clear
now becomes clear that
we used a snapshot
becomes clear that further
used a snapshot of
clear that further precision
a snapshot of the
that further precision is
snapshot of the friendship
further precision is needed
of the friendship relations
the friendship relations graph
friendship relations graph in
relations graph in the
graph in the orkut
the objects aren t
in the orkut social
objects aren t merely
the orkut social network
aren t merely protocols
but in fact are
in fact are individual
fact are individual protocol
are individual protocol instances
our system will need
system will need to
will need to simultaneously
need to simultaneously support
to simultaneously support potentially
simultaneously support potentially large
support potentially large numbers
potentially large numbers of
large numbers of transport
numbers of transport objects
of transport objects running
transport objects running concurrently
objects running concurrently in
running concurrently in the
concurrently in the end
in support of a
support of a variety
of a variety of
a variety of applications
variety of applications and
of applications and uses
each user is a
user is a node
is a node and
a node and each
node and each pair
all of this leads
and each pair of
of this leads to
each pair of users
this leads to new
pair of users with
leads to new challenges
of users with a
users with a friend
with a friend relationship
a friend relationship is
friend relationship is an
the obvious one was
relationship is an edge
obvious one was mentioned
one was mentioned earlier
the original graph contains
today s web services
original graph contains more
s web services don
graph contains more than
web services don t
services don t support
don t support p
contemporary web services solutions
web services solutions presume
services solutions presume a
solutions presume a client
server style of interaction
with data relayed through
data relayed through a
relayed through a message
even if clients are
as seen by the
if clients are connected
seen by the entire
clients are connected to
by the entire chain
are connected to one
because the sampled topologies
the sampled topologies are
sampled topologies are large
topologies are large and
if they lose connectivity
are large and we
they lose connectivity to
lose connectivity to the
large and we only
connectivity to the broker
and we only need
we only need to
only need to simulate
they can t collaborate
need to simulate a
to simulate a single
simulate a single column
a single column of
another serious issue arises
single column of the
serious issue arises if
column of the system
issue arises if the
of the system for
arises if the clients
the system for our
if the clients don
system for our purposes
the clients don t
for our purposes one
clients don t trust
our purposes one database
don t trust the
purposes one database server
t trust the data
one database server and
trust the data center
database server and one
server and one cache
and one cache server
one cache server we
cache server we down
sensitive data will need
data will need to
will need to be
need to be encrypted
sample both graphs to
the problem here is
problem here is that
here is that web
is that web services
that web services security
web services security standards
services security standards tend
security standards tend to
standards tend to trust
tend to trust the
to trust the web
trust the web services
the web services platform
web services platform itself
we use a technique
use a technique based
the standards offer no
a technique based on
standards offer no help
technique based on random
offer no help at
based on random walks
no help at all
on random walks that
help at all if
random walks that maintains
at all if we
walks that maintains important
all if we need
that maintains important properties
if we need to
maintains important properties of
we need to provide
important properties of the
need to provide end
properties of the original
of the original graph
experimental results and validation
end encryption mechanisms while
encryption mechanisms while also
mechanisms while also preventing
while also preventing the
also preventing the hosted
preventing the hosted services
the hosted services from
hosted services from seeing
services from seeing the
from seeing the keys
specifically clustering which is
clustering which is central
which is central to
is central to our
central to our experiment
we encounter debilitating latency
encounter debilitating latency and
debilitating latency and throughput
we start by choosing
latency and throughput issues
start by choosing a
by choosing a node
choosing a node uniformly
a node uniformly and
hosted services will be
node uniformly and random
services will be performance
uniformly and random and
and random and start
random and start a
and start a random
start a random walk
limiting bottlenecks when used
a random walk from
bottlenecks when used in
random walk from that
the tests reported here
walk from that location
when used in settings
tests reported here employ
used in settings with
reported here employ a
in settings with large
here employ a hard
settings with large numbers
with large numbers of
large numbers of clients
as we will see
we will see in
will see in our
see in our experimental
in our experimental section
the ssa is a
ssa is a work
is a work in
a work in progress
we are left with
are left with a
left with a mixture
with a mixture of
a mixture of good
mixture of good and
the walk reverts back
of good and bad
walk reverts back to
good and bad news
reverts back to the
back to the first
fledged system will use
to the first node
system will use a
the first node and
will use a software
first node and start
web services standardize client
node and start again
use a software partitioning
services standardize client access
a software partitioning mechanism
standardize client access to
software partitioning mechanism based
client access to hosted
partitioning mechanism based on
this is repeated until
access to hosted services
is repeated until the
to hosted services and
repeated until the target
hosted services and data
mechanism based on the
until the target number
based on the web
the target number of
on the web services
target number of nodes
the web services request
number of nodes have
web services request invocation
of nodes have been
services request invocation model
nodes have been visited
we can easily build
can easily build some
easily build some form
although extracting the partitioning
build some form of
extracting the partitioning key
some form of multiframed
the partitioning key from
form of multiframed web
partitioning key from incoming
of multiframed web page
key from incoming requests
multiframed web page that
from incoming requests will
web page that could
incoming requests will impose
page that could host
requests will impose some
that could host each
will impose some overhead
could host each kind
host each kind of
each kind of information
kind of information in
of information in its
information in its own
show a further down
in its own minibrowser
we do not expect
do not expect performance
not expect performance of
expect performance of the
performance of the full
when connectivity is adequate
fledged system to deviate
system to deviate significantly
relaying data via a
to deviate significantly from
data via a hosted
deviate significantly from what
via a hosted service
significantly from what is
a hosted service has
nodes to provide some
from what is reported
to provide some perception
what is reported below
provide some perception of
hosted service has many
some perception of the
service has many of
perception of the topologies
has many of the
many of the benefits
of the benefits of
the benefits of a
benefits of a publishsubscribe
of a publishsubscribe architecture
the graphs are visibly
graphs are visibly clustered
such as robustness as
as robustness as the
the amazon topology more
robustness as the set
amazon topology more so
as the set of
topology more so than
the set of clients
more so than the
set of clients changes
so than the orkut
than the orkut one
the natural way to
natural way to think
way to think of
to think of our
think of our application
of our application is
our application is as
application is as an
is as an object
its topology has a
topology has a more
has a more clustered
a more clustered structure
but web services provide
web services provide no
services provide no support
provide no support for
and so the dependency
no support for this
so the dependency lists
support for this kind
the dependency lists hold
for this kind of
dependency lists hold more
this kind of client
lists hold more relevant
kind of client application
hold more relevant information
of client application development
treating nodes of the
our solution may perform
nodes of the graphs
solution may perform very
of the graphs as
may perform very poorly
the graphs as database
graphs as database objects
or fail if the
fail if the hosted
transactions are likely to
if the hosted services
are likely to access
the hosted services are
likely to access objects
hosted services are inaccessible
to access objects that
access objects that are
objects that are topologically
that are topologically close
are topologically close to
topologically close to one
all data will probably
close to one another
data will probably be
will probably be visible
probably be visible to
be visible to the
for the online retailer
visible to the hosted
to the hosted services
the hosted services unless
hosted services unless the
services unless the developer
it is likely that
unless the developer uses
is likely that objects
the developer uses some
likely that objects bought
developer uses some sort
that objects bought together
uses some sort of
objects bought together are
some sort of non
bought together are also
together are also viewed
are also viewed and
also viewed and updated
viewed and updated together
update injection time against
injection time against delivery
time against delivery time
against delivery time at
delivery time at node
viewing and buying a
and buying a toy
buying a toy train
a toy train and
using live objects for
toy train and matching
live objects for soc
train and matching rails
objects for soc applications
for soc applications cornell
soc applications cornell s
applications cornell s live
cornell s live objects
s live objects platform
live objects platform supports
objects platform supports componentized
for the social network
layered mashup creation and
mashup creation and sharing
it is likely that
is likely that data
likely that data of
that data of befriended
data of befriended users
and overcomes limitations of
of befriended users are
overcomes limitations of existing
befriended users are viewed
limitations of existing web
users are viewed and
of existing web technologies
are viewed and updated
viewed and updated together
the major design aspects
major design aspects are
design aspects are as
aspects are as follows
the developer starts by
developer starts by creating
tagging a person in
or gaining access to
a person in a
person in a picture
a collection of components
commenting on a post
on a post by
a post by a
post by a friend
by a friend s
each component is an
a friend s friend
component is an object
is an object that
an object that supports
object that supports live
that supports live functionality
or viewing one s
viewing one s neighborhood
and exposes eventbased interfaces
exposes eventbased interfaces by
eventbased interfaces by which
interfaces by which it
by which it interacts
which it interacts with
we run a set
it interacts with other
run a set of
interacts with other components
a set of experiments
set of experiments similar
of experiments similar to
experiments similar to the
similar to the t
components representing hosted content
representing hosted content sensors
varying cache entry ttl
hosted content sensors and
cache entry ttl to
content sensors and actuators
entry ttl to evaluate
sensors and actuators renderers
ttl to evaluate the
and actuators renderers that
to evaluate the efficacy
actuators renderers that graphically
evaluate the efficacy of
renderers that graphically depict
the efficacy of this
that graphically depict events
efficacy of this method
graphically depict events replication
of this method in
depict events replication protocols
this method in reducing
events replication protocols synchronization
method in reducing inconsistencies
replication protocols synchronization protocols
in reducing inconsistencies and
protocols synchronization protocols folders
reducing inconsistencies and the
synchronization protocols folders containing
inconsistencies and the corresponding
protocols folders containing sets
and the corresponding overhead
folders containing sets of
containing sets of objects
sets of objects display
of objects display interfaces
objects display interfaces that
display interfaces that visualize
interfaces that visualize folders
mashups of components are
of components are represented
limiting ttl has detrimental
components are represented as
ttl has detrimental effects
are represented as a
has detrimental effects on
represented as a kind
detrimental effects on cache
as a kind of
effects on cache hit
a kind of xml
on cache hit ratio
kind of xml web
of xml web pages
quickly increasing the database
increasing the database workload
each describing a recipe
describing a recipe for
a recipe for obtaining
recipe for obtaining and
by increasing database access
for obtaining and parameterizing
increasing database access rate
obtaining and parameterizing components
database access rate to
and parameterizing components that
access rate to more
parameterizing components that will
rate to more than
components that will serve
to more than twice
that will serve as
more than twice its
will serve as layers
update delay as seen
serve as layers of
delay as seen by
as layers of the
than twice its original
layers of the composed
as seen by individual
of the composed mashup
twice its original load
seen by individual processes
its original load we
original load we only
load we only observe
we only observe a
we call such an
only observe a reduction
call such an xml
observe a reduction of
such an xml page
a reduction of inconsistencies
an xml page a
reduction of inconsistencies of
xml page a live
of inconsistencies of about
page a live object
a live object reference
references can be distributed
can be distributed as
be distributed as files
http or other means
this is more than
is more than twice
more than twice the
than twice the rate
twice the rate of
the rate of inconsistencies
an soc application is
rate of inconsistencies achieved
soc application is created
of inconsistencies achieved by
application is created by
inconsistencies achieved by t
is created by building
created by building a
by building a forest
building a forest consisting
a forest consisting of
cache for the retailer
forest consisting of graphs
for the retailer workload
consisting of graphs of
the retailer workload and
of graphs of references
retailer workload and only
graphs of references that
workload and only slightly
of references that are
and only slightly better
references that are mashed
only slightly better than
that are mashed together
slightly better than the
better than the rate
than the rate of
the rate of inconsistencies
rate of inconsistencies achieved
of inconsistencies achieved by
inconsistencies achieved by t
an automated tool lets
cache for the social
automated tool lets the
for the social network
the social network workload
tool lets the developer
lets the developer drag
the developer drag and
developer drag and drop
and with twice the
drag and drop to
with twice the additional
and drop to combine
twice the additional load
drop to combine references
the additional load on
to combine references for
additional load on the
combine references for individual
load on the database
references for individual objects
for individual objects into
individual objects into an
objects into an xml
our experiments were conducted
into an xml mashup
experiments were conducted using
an xml mashup of
were conducted using the
xml mashup of references
we generate a transactional
mashup of references describing
conducted using the ssa
of references describing a
generate a transactional workload
references describing a graph
using the ssa framework
describing a graph of
a transactional workload that
a graph of objects
the ssa framework deployed
transactional workload that accesses
ssa framework deployed on
workload that accesses products
framework deployed on a
that accesses products that
deployed on a tightly
accesses products that are
on a tightly coupled
products that are topologically
a tightly coupled homogeneous
that are topologically close
tightly coupled homogeneous cluster
coupled homogeneous cluster of
checks mashups to verify
mashups to verify that
to verify that they
verify that they compose
that they compose correctly
we use random walks
each transaction starts by
the nodes are connected
transaction starts by picking
nodes are connected by
starts by picking a
are connected by two
by picking a node
connected by two separate
picking a node uniformly
by two separate high
a node uniformly at
two separate high speed
node uniformly at random
separate high speed ethernet
uniformly at random and
d visualization of an
at random and takes
high speed ethernet backbone
visualization of an airplane
speed ethernet backbone planes
of an airplane may
an airplane may need
steps of a random
airplane may need to
of a random walk
we experimented with several
may need to be
experimented with several configurations
need to be connected
to be connected to
be connected to a
the nodes visited by
connected to a source
nodes visited by the
to a source of
some placed the control
a source of gps
visited by the random
source of gps and
by the random walk
of gps and other
placed the control traffic
gps and other orientation
the random walk are
and other orientation data
random walk are the
the control traffic on
walk are the objects
control traffic on a
are the objects the
traffic on a different
the objects the transaction
which in turn needs
on a different switched
objects the transaction accesses
in turn needs to
a different switched ethernet
turn needs to run
different switched ethernet segment
needs to run over
switched ethernet segment while
to run over a
update transactions first read
run over a data
transactions first read all
over a data replication
ethernet segment while others
a data replication protocol
first read all objects
data replication protocol with
read all objects from
replication protocol with specific
all objects from the
protocol with specific reliability
objects from the database
segment while others aggregated
while others aggregated both
others aggregated both the
aggregated both the control
ordering or security properties
both the control traffic
and then update all
the control traffic and
then update all objects
control traffic and the
update all objects at
traffic and the data
all objects at the
and the data traffic
objects at the database
the data traffic on
when activated on a
data traffic on the
activated on a user
traffic on the same
on a user s
on the same segment
a user s machine
read transactions read the
transactions read the objects
read the objects directly
the objects directly from
objects directly from the
no significant differences were
an xml mashup yields
significant differences were observed
directly from the cache
xml mashup yields a
mashup yields a graph
yields a graph of
a graph of interconnected
graph of interconnected proxies
but this may be
this may be because
may be because our
be because our control
because our control traffic
a proxy is a
our control traffic consisted
proxy is a piece
control traffic consisted mainly
is a piece of
traffic consisted mainly of
a piece of running
consisted mainly of fast
piece of running code
of running code that
running code that may
code that may render
in this section we
this section we evaluate
section we evaluate t
which put little stress
cache using the workloads
put little stress on
using the workloads described
little stress on the
the workloads described above
stress on the communication
or transform visual content
on the communication channels
we found that the
encapsulate a protocol stack
found that the abort
in the future we
that the abort rate
the future we hope
the abort rate is
future we hope to
abort rate is negligible
we hope to explore
rate is negligible in
hope to explore scenarios
is negligible in all
to explore scenarios that
negligible in all runs
explore scenarios that generate
scenarios that generate exceptionally
that generate exceptionally heavy
generate exceptionally heavy control
component in the xml
exceptionally heavy control traffic
in the xml mashup
efficacy is therefore defined
the xml mashup produces
is therefore defined to
xml mashup produces an
therefore defined to be
mashup produces an associated
defined to be the
produces an associated proxy
which would allow us
to be the ratio
would allow us to
be the ratio of
allow us to explore
the ratio of inconsistent
us to explore the
ratio of inconsistent transactions
the hierarchy of proxies
of inconsistent transactions out
to explore the benefits
inconsistent transactions out of
hierarchy of proxies reflects
transactions out of all
explore the benefits of
of proxies reflects the
the benefits of isolation
proxies reflects the hierarchical
benefits of isolation of
reflects the hierarchical structure
out of all commits
the hierarchical structure of
of isolation of that
hierarchical structure of the
isolation of that traffic
structure of the xml
of that traffic with
of the xml mashup
that traffic with respect
the overhead of the
traffic with respect to
overhead of the system
with respect to data
of the system is
respect to data traffic
the system is twofold
an object proxy can
object proxy can initialize
in the interest of
proxy can initialize itself
the interest of brevity
can initialize itself by
interest of brevity we
initialize itself by copying
dependency list maintenance implies
itself by copying the
of brevity we did
by copying the state
list maintenance implies storage
copying the state from
brevity we did not
the state from some
maintenance implies storage and
state from some active
we did not perform
from some active proxy
implies storage and bandwidth
did not perform any
storage and bandwidth overhead
not perform any experiments
and bandwidth overhead at
perform any experiments to
bandwidth overhead at both
our platform assists with
any experiments to evaluate
platform assists with this
overhead at both the
assists with this sort
experiments to evaluate the
with this sort of
at both the database
this sort of state
to evaluate the load
sort of state transfer
both the database and
evaluate the load balancing
the database and the
the load balancing component
database and the cache
load balancing component but
balancing component but we
component but we plan
but we plan to
we plan to do
plan to do so
the object proxies then
to do so in
as well as compute
object proxies then become
do so in the
proxies then become active
so in the future
well as compute overhead
as compute overhead for
compute overhead for dependency
overhead for dependency list
for dependency list merging
all the experiments involved
dependency list merging at
the experiments involved a
list merging at the
experiments involved a single
merging at the server
involved a single partitioned
at the server and
a single partitioned and
the server and consistency
single partitioned and replicated
server and consistency checks
partitioned and replicated service
and consistency checks at
for example by relaying
consistency checks at the
example by relaying events
checks at the cache
by relaying events from
relaying events from sensors
for ease of exposition
events from sensors into
from sensors into a
sensors into a replica
this service implements a
service implements a simple
implements a simple wall
the storage required is
storage required is only
required is only for
is only for object
or by receiving events
only for object ids
by receiving events and
for object ids and
receiving events and reacting
object ids and versions
events and reacting to
the service itself maintains
and reacting to them
service itself maintains the
itself maintains the time
with updates coming from
and both updates and
updates coming from client
both updates and checks
coming from client applications
updates and checks are
from client applications that
and checks are o
by redisplaying an aircraft
client applications that read
applications that read a
that read a high
quality clock and send
clock and send the
our approach shares certain
and send the current
approach shares certain similarities
send the current value
shares certain similarities with
in the number of
certain similarities with the
the number of objects
similarities with the existing
number of objects in
with the existing web
of objects in the
the existing web development
objects in the system
as processes forward updates
in the system and
existing web development model
the system and o
processes forward updates along
forward updates along the
updates along the chain
in the sense that
the sense that it
they will track the
sense that it uses
will track the clock
that it uses hierarchical
track the clock themselves
it uses hierarchical xml
uses hierarchical xml documents
in the size of
hierarchical xml documents to
the size of the
xml documents to define
size of the dependency
documents to define the
of the dependency lists
to define the content
all of our partitioning
of our partitioning scenarios
our partitioning scenarios included
partitioning scenarios included at
which is limited to
on the other hand
scenarios included at least
included at least four
at least four subservices
we depart from some
depart from some of
from some of the
and each subservice included
some of the de
each subservice included between
the second and potentially
second and potentially more
and potentially more significant
facto stylistic standards that
potentially more significant overhead
stylistic standards that have
standards that have emerged
more significant overhead is
significant overhead is the
overhead is the effect
is the effect on
for example if one
the effect on cache
example if one pulls
effect on cache hit
if one pulls a
on cache hit ratio
one pulls a minibrowser
cache hit ratio due
we expect these to
pulls a minibrowser from
expect these to be
a minibrowser from google
these to be typical
minibrowser from google earth
hit ratio due to
to be typical cases
ratio due to evictions
be typical cases for
due to evictions and
typical cases for real
to evictions and hence
cases for real deployments
evictions and hence the
for real deployments of
and hence the database
real deployments of the
it expects to interact
hence the database load
deployments of the ssa
expects to interact directly
to interact directly with
interact directly with the
directly with the end
with the end user
since cache load is
it should be noted
cache load is significantly
should be noted that
load is significantly larger
be noted that small
is significantly larger than
noted that small subservice
significantly larger than database
that small subservice sizes
larger than database load
and includes embedded javascript
includes embedded javascript that
embedded javascript that handles
javascript that handles such
that handles such interactions
orders of magnitude for
of magnitude for facebook
can result in degenerate
result in degenerate behavior
the same functionality would
in degenerate behavior and
same functionality would be
degenerate behavior and are
functionality would be represented
behavior and are not
would be represented as
and are not appropriate
be represented as a
are not appropriate configurations
represented as a mashup
not appropriate configurations for
as a mashup of
appropriate configurations for the
a mashup of a
configurations for the ssa
mashup of a component
for the ssa architecture
even a minor deterioration
of a component that
a minor deterioration in
a component that fetches
minor deterioration in hit
component that fetches maps
deterioration in hit ratio
that fetches maps and
in hit ratio can
fetches maps and similar
hit ratio can yield
maps and similar content
ratio can yield a
and similar content with
can yield a prohibitive
similar content with a
yield a prohibitive load
content with a second
a prohibitive load on
with a second component
prohibitive load on the
a second component that
load on the backend
second component that provides
on the backend database
component that provides the
mapping between service processes
that provides the visualization
between service processes and
provides the visualization interface
service processes and physical
processes and physical nodes
although the term mashup
c shows the experiment
in order to avoid
shows the experiment results
the term mashup may
order to avoid os
term mashup may sound
to avoid os resource
mashup may sound static
avoid os resource contention
each data point is
data point is the
point is the result
in the sense of
we experimented with groups
is the result of
the sense of having
experimented with groups of
the result of a
sense of having its
result of a single
of having its components
of a single run
having its components predetermined
this is not necessarily
we vary the dependency
is not necessarily the
not necessarily the case
vary the dependency list
the dependency list size
dependency list size and
list size and for
one kind of live
size and for each
kind of live object
and for each value
of live object could
for each value run
live object could be
each value run the
object could be a
value run the experiment
could be a folder
run the experiment for
be a folder including
the experiment for the
a folder including a
experiment for the two
folder including a set
for the two workloads
including a set of
the two workloads and
a set of objects
two workloads and measure
workloads and measure the
and measure the average
measure the average values
the average values of
average values of these
for example extracted from
values of these metrics
example extracted from a
extracted from a directory
from a directory in
a directory in a
directory in a file
by convention the head
in a file system
convention the head of
a file system or
the head of the
cache is able to
head of the chain
is able to reduce
of the chain for
able to reduce inconsistencies
the chain for each
to reduce inconsistencies significantly
chain for each group
file system or pulled
for each group was
system or pulled from
each group was called
or pulled from a
group was called node
pulled from a database
for the retailer workload
from a database in
a database in response
database in response to
in response to a
response to a query
a single dependency reduces
single dependency reduces inconsistencies
dependency reduces inconsistencies to
and all update requests
all update requests for
when the folder contents
update requests for a
the folder contents change
requests for a partition
for a partition were
a partition were routed
partition were routed towards
were routed towards this
the mashup is dynamically
routed towards this node
mashup is dynamically updated
of their original value
since delivery delays in
as might occur when
delivery delays in the
might occur when a
delays in the chain
occur when a rescue
in the chain were
two dependencies reduce inconsistencies
the chain were measured
when a rescue worker
chain were measured relative
dependencies reduce inconsistencies to
were measured relative to
a rescue worker enters
measured relative to node
rescue worker enters a
worker enters a building
enters a building or
a building or turns
building or turns a
or turns a corner
all the statistics pertaining
the statistics pertaining to
of their original value
statistics pertaining to the
pertaining to the group
to the group disregarded
live objects can easily
the group disregarded node
and three to less
objects can easily support
three to less than
can easily support applications
easily support applications that
support applications that dynamically
applications that dynamically recompute
that dynamically recompute the
dynamically recompute the set
we simulated two classes
recompute the set of
simulated two classes of
the set of visible
two classes of failures
set of visible objects
for the social network
the social network workload
as a function of
a function of location
function of location and
of location and orientation
at some time t
some time t one
time t one process
and dynamically add or
dynamically add or remove
add or remove them
or remove them from
remove them from the
them from the mashup
of the inconsistencies remain
a rescuer would automatically
rescuer would automatically and
would automatically and instantly
the system must detect
automatically and instantly be
system must detect the
in both workloads there
must detect the failure
and instantly be shown
both workloads there is
instantly be shown the
workloads there is no
be shown the avatars
there is no visible
shown the avatars of
repair the broken fifo
is no visible effect
the broken fifo channel
the avatars of others
no visible effect on
avatars of others who
visible effect on cache
of others who are
effect on cache hit
others who are already
on cache hit ratio
who are already working
are already working at
already working at that
working at that site
and hence no increased
hence no increased access
no increased access rate
increased access rate at
and be able to
access rate at the
be able to participate
rate at the database
able to participate in
to participate in conference
the failed process recovers
failed process recovers and
process recovers and rejoins
recovers and rejoins the
and rejoins the chain
the reduction in inconsistency
reduction in inconsistency ratio
in inconsistency ratio is
the join protocol would
inconsistency ratio is significantly
join protocol would run
ratio is significantly better
is significantly better for
point dialog with them
significantly better for the
and the previously failed
better for the next
the previously failed node
for the next we
previously failed node would
the next we compared
through chat objects that
failed node would become
chat objects that run
next we compared our
objects that run over
we compared our technique
node would become the
compared our technique with
would become the new
that run over multicast
our technique with a
run over multicast protocol
become the new tail
over multicast protocol objects
the new tail of
technique with a simple
new tail of the
with a simple approach
tail of the chain
a simple approach in
simple approach in which
this model can support
approach in which we
model can support a
in which we limited
can support a wide
which we limited the
support a wide variety
we limited the life
a wide variety of
limited the life span
the scenario is intended
wide variety of collaboration
scenario is intended to
variety of collaboration and
is intended to model
of collaboration and coordination
intended to model a
collaboration and coordination paradigms
to model a common
model a common case
a common case in
common case in which
case in which the
in which the failure
which the failure detection
the failure detection mechanism
the live objects platform
failure detection mechanism senses
live objects platform makes
here inconsistencies are not
objects platform makes it
inconsistencies are not detected
platform makes it easy
detection mechanism senses a
makes it easy for
mechanism senses a transient
it easy for a
senses a transient problem
easy for a non
but their probability of
their probability of being
programmer to create the
probability of being witnessed
to create the needed
create the needed soc
of being witnessed is
the needed soc application
a node that has
being witnessed is reduced
node that has become
witnessed is reduced by
that has become overloaded
is reduced by having
has become overloaded or
the rescue coordinator pulls
become overloaded or is
reduced by having the
overloaded or is unresponsive
rescue coordinator pulls prebuilt
by having the cache
or is unresponsive for
coordinator pulls prebuilt object
is unresponsive for some
having the cache evict
unresponsive for some other
pulls prebuilt object references
for some other reason
the cache evict entries
prebuilt object references from
cache evict entries after
object references from a
evict entries after a
references from a folder
entries after a certain
such as garbage collection
after a certain period
a certain period even
certain period even if
each corresponding to a
period even if the
corresponding to a desired
even if the database
to a desired kind
if the database did
a desired kind of
the database did not
desired kind of information
database did not indicate
and does not respond
did not indicate they
does not respond to
not indicate they are
not respond to the
indicate they are invalid
respond to the heartbeat
to the heartbeat within
the heartbeat within the
heartbeat within the accepted
within the accepted window
by reconfiguring the chain
would correspond to objects
correspond to objects that
to objects that point
the load on node
objects that point to
load on node drops
that point to a
point to a web
to a web service
a web service over
web service over the
service over the network
compares the efficacy of
and the problem will
the efficacy of the
the problem will eventually
efficacy of the abort
problem will eventually resolve
evict and retry policies
and retry policies with
it then requests a
retry policies with the
then requests a rejoin
policies with the amazon
peer objects would implement
with the amazon and
objects would implement chat
the amazon and orkut
would implement chat windows
amazon and orkut workloads
a node crash that
node crash that results
crash that results in
that results in a
results in a reboot
in these experiments we
in a reboot would
these experiments we use
a reboot would result
experiments we use dependency
reboot would result in
we use dependency lists
would result in similar
use dependency lists of
result in similar behavior
dependency lists of length
event interfaces allow such
interfaces allow such objects
allow such objects to
such objects to coexist
objects to coexist in
to coexist in a
coexist in a shared
in a shared display
just as with the
a shared display window
as with the synthetic
shared display window that
with the synthetic workload
display window that can
window that can pan
all the nodes in
the nodes in the
nodes in the subservice
in the subservice remain
the subservice remain operational
evicting conflicting transactions is
conflicting transactions is an
transactions is an effective
is an effective way
jump to new locations
but one of them
an effective way of
one of them becomes
effective way of invalidating
of them becomes overloaded
way of invalidating stale
of invalidating stale objects
invalidating stale objects that
stale objects that might
the relative advantages and
objects that might cause
causing the tcp link
that might cause problems
relative advantages and disadvantages
might cause problems for
the tcp link to
cause problems for future
advantages and disadvantages of
problems for future transactions
tcp link to the
and disadvantages of our
link to the upstream
disadvantages of our model
to the upstream node
of our model can
the upstream node to
our model can be
the effects are more
model can be summarized
upstream node to become
can be summarized as
effects are more pronounced
be summarized as follows
node to become congested
are more pronounced for
to become congested and
more pronounced for the
become congested and starving
pronounced for the well
congested and starving downstream
like other modern web
and starving downstream nodes
other modern web development
modern web development tools
which begin to miss
begin to miss updates
our platform supports drag
with the amazon workload
this scenario models a
abort is able to
scenario models a behavior
is able to detect
models a behavior common
a behavior common in
drop style of development
behavior common in experiments
common in experiments on
in experiments on our
experiments on our cluster
when a node becomes
easy creation of content
a node becomes very
of the inconsistent transactions
node becomes very busy
becomes very busy or
very busy or the
busy or the communication
or the communication subsystem
whereas with the less
the communication subsystem becomes
communication subsystem becomes heavily
subsystem becomes heavily loaded
the resulting solutions are
resulting solutions are easy
solutions are easy to
clustered orkut workload it
are easy to share
orkut workload it only
workload it only detects
tcp at the node
at the node upstream
the node upstream from
by selecting appropriate transport
node upstream from it
selecting appropriate transport layers
upstream from it will
from it will sense
it will sense congestion
will sense congestion and
sense congestion and reduce
congestion and reduce its
functionality such as coordination
and reduce its window
such as coordination between
reduce its window size
as coordination between searchers
coordination between searchers can
between searchers can remain
in both cases evict
searchers can remain active
both cases evict reduces
if the impacted node
cases evict reduces uncommittable
can remain active even
evict reduces uncommittable transactions
the impacted node is
reduces uncommittable transactions considerably
impacted node is in
remain active even if
node is in the
active even if connectivity
is in the middle
even if connectivity to
in the middle of
relative to their value
if connectivity to the
to their value with
the middle of the
their value with abort
middle of the chain
connectivity to the data
to the data center
the data center is
data center is disrupted
it ceases to relay
ceases to relay updates
streams of video or
of video or sensor
or does so after
with the amazon workload
does so after long
the amazon workload and
so after long delays
video or sensor data
or sensor data can
sensor data can travel
data can travel directly
can travel directly and
travel directly and won
directly and won t
hence downstream nodes fall
and won t be
downstream nodes fall behind
won t be delayed
t be delayed by
be delayed by the
delayed by the need
by the need to
in the amazon workload
the need to ricochet
need to ricochet off
to ricochet off a
the chain replication scheme
ricochet off a remote
chain replication scheme slows
off a remote and
replication scheme slows to
retry further reduces this
scheme slows to a
a remote and potentially
further reduces this value
remote and potentially inaccessible
reduces this value to
and potentially inaccessible server
slows to a crawl
based interoperability standards are
the ssa benefits from
interoperability standards are needed
ssa benefits from its
of its value with
benefits from its gossip
its value with abort
from its gossip repair
its gossip repair mechanisms
which route missing updates
we could lose access
route missing updates around
r elated w ork
could lose access to
missing updates around the
elated w ork a
updates around the slow
lose access to some
around the slow node
access to some of
to some of the
some of the sophisticated
of the sophisticated proprietary
the sophisticated proprietary interactive
sophisticated proprietary interactive functionality
proprietary interactive functionality optimized
recent years have seen
route them to that
interactive functionality optimized for
years have seen a
functionality optimized for proprietary
them to that node
have seen a surge
optimized for proprietary minibrowser
seen a surge of
a surge of progress
surge of progress in
when it recovers and
of progress in the
it recovers and needs
based solutions with an
recovers and needs to
solutions with an embedded
and needs to repair
with an embedded javascript
progress in the development
needs to repair its
in the development of
to repair its state
the development of scalable
development of scalable object
of scalable object stores
scalable object stores that
object stores that support
stores that support transactions
peer communication can be
some systems such as
communication can be much
knowing that gossip will
can be much harder
that gossip will kick
gossip will kick in
be much harder to
much harder to use
harder to use than
to use than relaying
an upstream node can
use than relaying data
upstream node can deliberately
than relaying data through
node can deliberately drop
relaying data through a
can deliberately drop updates
data through a hosted
deliberately drop updates on
through a hosted service
drop updates on congested
a hosted service that
updates on congested tcp
hosted service that uses
on congested tcp connections
service that uses an
that uses an enterprise
uses an enterprise service
an enterprise service bus
we used our wall
clock service to evaluate
service to evaluate the
to evaluate the behavior
evaluate the behavior of
the behavior of the
behavior of the overall
of the overall system
the overall system in
overall system in various
system in various scenarios
in various scenarios and
various scenarios and with
the lack of a
scenarios and with different
lack of a one
and with different parameters
of a one size
a one size fits
one size fits all
size fits all publish
a stream of updates
stream of updates of
of updates of various
updates of various rates
subscribe substrate forces the
of various rates is
substrate forces the developers
various rates is injected
forces the developers to
rates is injected into
the developers to become
is injected into the
developers to become familiar
injected into the head
to become familiar with
into the head of
become familiar with and
the head of the
familiar with and choose
head of the chain
with and choose between
and choose between a
choose between a range
between a range of
a range of different
range of different and
of different and incompatible
different and incompatible options
export novel consistency definitions
novel consistency definitions that
consistency definitions that allow
definitions that allow for
for groups of nodes
that allow for effective
an wrong choice of
allow for effective optimizations
wrong choice of transport
choice of transport could
of transport could result
transport could result in
could result in degraded
result in degraded qos
several recent systems implement
recent systems implement full
established point in time
systems implement full fledged
implement full fledged atomicity
full fledged atomicity while
fledged atomicity while preserving
a victim node receives
atomicity while preserving the
or even data loss
while preserving the system
victim node receives a
preserving the system s
node receives a command
the system s scalability
receives a command that
system s scalability with
a command that forces
s scalability with a
command that forces it
scalability with a wide
that forces it to
with a wide variety
forces it to halt
a wide variety of
wide variety of workloads
second life as a
life as a soc
the node continues to
as a soc application
google s spanner utilizes
a soc application up
node continues to listen
soc application up to
s spanner utilizes accurate
application up to now
continues to listen for
spanner utilizes accurate clock
to listen for commands
utilizes accurate clock synchronization
listen for commands that
for commands that would
commands that would restart
that would restart it
we have focused on
have focused on a
focused on a small
this is accomplished by
is accomplished by having
accomplished by having node
but our longer term
our longer term goal
by balakrishnan et al
longer term goal is
term goal is to
goal is to support
send a crash command
is to support a
a crash command to
to support a large
is constructed on top
crash command to the
constructed on top of
command to the victim
on top of the
to the victim node
top of the scalable
scale nextgeneration collaboration system
the victim node once
nextgeneration collaboration system similar
victim node once a
of the scalable corfu
node once a certain
collaboration system similar to
once a certain number
system similar to second
a certain number of
similar to second life
certain number of updates
number of updates were
of updates were injected
updates were injected into
were injected into the
injected into the chain
a virtual reality immersion
virtual reality immersion system
reality immersion system created
immersion system created by
system created by linden
created by linden labs
the victim node will
second life is implemented
victim node will stop
life is implemented with
node will stop participating
is implemented with a
will stop participating in
implemented with a data
stop participating in the
with a data center
participating in the normal
a data center including
in the normal protocol
data center including a
the normal protocol and
normal protocol and will
center including a large
protocol and will handle
utilize a large set
and will handle only
a large set of
including a large number
large set of independent
will handle only wakeup
set of independent logs
a large number of
handle only wakeup commands
large number of servers
only wakeup commands from
number of servers storing
wakeup commands from this
of servers storing the
commands from this moment
servers storing the state
from this moment onwards
storing the state of
the state of the
state of the virtual
of the virtual world
the chain detects the
chain detects the failure
the locations of all
locations of all users
repairs and announces the
and announces the membership
announces the membership change
after a number of
a number of updates
number of updates have
of updates have been
updates have been injected
have been injected since
been injected since the
injected since the crash
since the crash command
the crash command was
crash command was issued
then move about and
move about and interact
about and interact with
and interact with others
sends a wakeup command
a wakeup command to
wakeup command to the
command to the victim
to the victim node
use lock chains and
one can create a
lock chains and assume
can create a cybercaf
chains and assume transactions
and assume transactions are
assume transactions are known
transactions are known in
are known in advance
these methods all scale
methods all scale well
all scale well and
the victim node rejoins
scale well and in
victim node rejoins the
well and in many
node rejoins the group
and in many cases
in many cases allow
many cases allow databases
cases allow databases to
it has to catch
allow databases to accept
has to catch up
databases to accept loads
as other second life
to accept loads similar
other second life users
accept loads similar to
second life users enter
loads similar to those
life users enter the
similar to those handled
to catch up by
users enter the room
to those handled by
catch up by obtaining
those handled by non
up by obtaining copies
by obtaining copies of
they can interact with
obtaining copies of updates
can interact with the
copies of updates that
interact with the environment
of updates that it
with the environment and
updates that it has
the environment and one
that it has missed
we experimentally determined that
they are not expected
are not expected to
not expected to disrupt
expected to disrupt the
in the second life
repetitions of each experiment
to disrupt the prevailing
the second life architecture
disrupt the prevailing two
of each experiment were
each experiment were enough
experiment were enough to
were enough to yield
whenever an avatar moves
enough to yield accurate
an avatar moves or
to yield accurate measurements
avatar moves or performs
yield accurate measurements with
moves or performs some
accurate measurements with low
or performs some action
measurements with low variance
performs some action in
some action in the
action in the virtual
note that we are
in the virtual world
that we are addressing
we are addressing the
are addressing the problem
addressing the problem of
the problem of read
shows the update delivery
a request describing this
the update delivery delay
update delivery delay for
request describing this event
delivery delay for a
only incoherent caches that
delay for a set
describing this event is
for a set of
incoherent caches that respond
this event is passed
caches that respond to
a set of four
that respond to queries
set of four consecutive
respond to queries without
of four consecutive nodes
to queries without access
four consecutive nodes in
queries without access to
consecutive nodes in a
without access to the
event is passed to
access to the backend
nodes in a chain
to the backend database
is passed to the
passed to the hosting
to the hosting data
the hosting data center
hosting data center and
previous work on coherent
data center and processed
work on coherent caches
center and processed by
starting with the victim
and processed by servers
with the victim node
processed by servers running
by servers running there
clients do perform a
do perform a variety
perform a variety of
a variety of decoding
variety of decoding and
the chain length is
of decoding and rendering
decoding and rendering functions
and rendering functions locally
but the data center
and we report on
the data center must
we report on a
data center must be
report on a gossip
center must be in
on a gossip rate
must be in the
a gossip rate of
be in the loop
in the loop to
the loop to ensure
loop to ensure that
to ensure that all
ensure that all users
that all users observe
all users observe consistent
users observe consistent state
when the number of
the number of users
number of users in
milliseconds at a steady
of users in a
at a steady update
users in a scenario
a steady update injection
in a scenario isn
steady update injection rate
a scenario isn t
update injection rate of
scenario isn t huge
second life can easily
life can easily keep
can easily keep up
easily keep up using
keep up using a
up using a standard
using a standard workload
a standard workload partitioning
standard workload partitioning scheme
there are three anomalies
workload partitioning scheme in
are three anomalies that
supports transactions using locks
partitioning scheme in which
transactions using locks or
three anomalies that can
using locks or communication
anomalies that can be
scheme in which different
that can be seen
locks or communication with
in which different servers
or communication with the
can be seen on
communication with the database
be seen on the
with the database on
seen on the graphs
which different servers handle
the database on each
different servers handle different
database on each transaction
servers handle different portions
handle different portions of
different portions of the
the first one is
portions of the virtual
first one is experienced
of the virtual world
one is experienced by
these techniques are not
is experienced by the
techniques are not applicable
experienced by the victim
are not applicable in
by the victim node
not applicable in our
the victim node for
applicable in our scenario
victim node for updates
node for updates injected
for updates injected between
for example because large
example because large numbers
because large numbers of
large numbers of users
numbers of users want
of users want to
users want to enter
want to enter the
to enter the same
enter the same virtual
the same virtual discotheque
seconds after the start
after the start of
the start of the
start of the experiment
the servers can become
servers can become overwhelmed
can become overwhelmed and
the second is experienced
become overwhelmed and are
second is experienced by
overwhelmed and are forced
is experienced by all
and are forced to
experienced by all the
are forced to reject
by all the other
forced to reject some
all the other nodes
to reject some of
the other nodes for
reject some of the
other nodes for update
some of the users
nodes for update messages
of the users or
for update messages injected
the users or reduce
update messages injected at
users or reduce their
messages injected at around
or reduce their frame
rendering rates and resolution
seconds after the start
after the start of
the start of the
start of the experiment
second life might seem
life might seem jumpy
might seem jumpy and
while the third one
seem jumpy and unrealistic
the third one is
third one is a
one is a smaller
is a smaller mixed
a smaller mixed burst
second life as a
smaller mixed burst for
life as a live
mixed burst for updates
as a live objects
burst for updates injected
a live objects application
for updates injected at
live objects application poses
objects application poses some
application poses some new
poses some new challenges
on the one hand
seconds into the experiment
many aspects of the
note that the y
aspects of the application
of the application can
the application can be
application can be addressed
axes have different scales
can be addressed in
have different scales to
be addressed in the
different scales to observe
addressed in the same
scales to observe how
in the same manner
to observe how the
the same manner we
observe how the system
same manner we ve
how the system handles
manner we ve outlined
the system handles the
we ve outlined for
system handles the transient
ve outlined for the
handles the transient failure
outlined for the search
the transient failure better
for the search and
the search and rescue
search and rescue application
therefore the third anomaly
the third anomaly appears
one could use microsoft
third anomaly appears to
could use microsoft virtual
anomaly appears to grow
use microsoft virtual earth
appears to grow with
to grow with the
grow with the chain
with the chain distance
the chain distance from
chain distance from the
distance from the victim
from the victim node
as a source of
the growth is not
growth is not significant
d textures representing landscapes
since the cause of
the cause of this
cause of this anomaly
of this anomaly is
this anomaly is an
anomaly is an artifact
is an artifact of
an artifact of java
artifact of java s
of java s garbage
java s garbage collection
s garbage collection mechanism
garbage collection mechanism kicking
in standards for creating
collection mechanism kicking in
standards for creating mashups
for creating mashups could
creating mashups could be
mashups could be used
as can be noted
could be used to
be used to identify
used to identify sensors
to identify sensors and
identify sensors and other
sensors and other data
and other data sources
performed recovery for the
recovery for the updates
which could then be
for the updates it
could then be wrapped
the updates it has
then be wrapped as
updates it has missed
be wrapped as live
it has missed during
wrapped as live objects
has missed during the
as live objects and
missed during the period
live objects and incorporated
during the period it
objects and incorporated into
the period it was
and incorporated into live
period it was down
incorporated into live scenes
because the chain delivers
on top of this
the chain delivers new
chain delivers new updates
delivers new updates at
new updates at the
updates at the moment
streaming media sources such
at the moment of
the moment of rejoin
media sources such as
sources such as video
such as video cameras
as video cameras mounted
all past updates were
video cameras mounted at
past updates were solely
cameras mounted at street
updates were solely recovered
mounted at street level
were solely recovered by
at street level in
solely recovered by means
street level in places
recovered by means of
level in places such
by means of epidemics
in places such as
places such as tokyo
such as tokyo s
as tokyo s ginza
tokyo s ginza can
s ginza can be
the second anomaly that
ginza can be added
can be added to
second anomaly that shows
be added to create
added to create realistic
anomaly that shows up
to create realistic experience
that shows up in
shows up in the
up in the update
in the update delivery
the more complex issue
the update delivery delay
more complex issue is
update delivery delay for
complex issue is that
delivery delay for the
issue is that a
delay for the nodes
is that a search
for the nodes downstream
that a search and
the nodes downstream from
a search and rescue
nodes downstream from the
search and rescue application
downstream from the victim
and rescue application can
from the victim node
rescue application can be
the victim node reflects
application can be imagined
victim node reflects the
can be imagined as
node reflects the period
be imagined as a
reflects the period when
imagined as a situational
the period when the
as a situational state
period when the chain
a situational state fully
when the chain is
situational state fully replicated
the chain is broken
state fully replicated across
fully replicated across all
replicated across all of
across all of its
all of its users
during the time it
the time it took
time it took for
it took for the
took for the failure
for the failure detection
the failure detection mechanism
failure detection mechanism to
all machines would see
detection mechanism to declare
machines would see all
mechanism to declare the
would see all the
to declare the node
see all the state
declare the node deceased
all the state updates
to start up the
even if the user
start up the membership
if the user is
up the membership change
the user is zoomed
the membership change protocol
user is zoomed into
is zoomed into some
zoomed into some particular
into some particular spot
some particular spot within
and for the membership
particular spot within the
for the membership information
spot within the overall
the membership information to
within the overall scene
membership information to propagate
the chain is interrupted
chain is interrupted between
is interrupted between node
one can contemplate such
can contemplate such an
contemplate such an approach
such an approach because
an approach because the
approach because the aggregate
because the aggregate amount
the aggregate amount of
aggregate amount of information
amount of information might
of information might not
and hence the updates
information might not be
hence the updates circumvent
might not be that
the updates circumvent the
not be that large
updates circumvent the gap
circumvent the gap by
the gap by means
gap by means of
by means of gossip
second life conceptually is
updates can bypass nodes
life conceptually is a
can bypass nodes in
conceptually is a whole
bypass nodes in the
is a whole universe
nodes in the chain
in the chain using
the chain using the
chain using the gossip
using the gossip as
unbounded in size and
the gossip as it
in size and hence
gossip as it can
size and hence with
as it can be
and hence with different
it can be seen
hence with different users
can be seen in
with different users in
be seen in the
different users in very
seen in the figure
users in very distinct
in very distinct parts
very distinct parts of
distinct parts of the
parts of the space
but this phenomenon is
this phenomenon is less
db access rate normed
phenomenon is less likely
it would make no
is less likely as
would make no sense
less likely as the
make no sense for
likely as the node
no sense for every
as the node receiving
sense for every user
the node receiving the
for every user to
node receiving the update
every user to see
receiving the update is
user to see every
the update is farther
to see every event
update is farther away
is farther away downstream
farther away downstream from
db access rate normed
away downstream from the
downstream from the victim
from the victim node
we would solve this
would solve this problem
solve this problem using
this problem using the
problem using the dynamic
using the dynamic database
contains an aggregated view
the dynamic database querying
an aggregated view of
dynamic database querying approach
aggregated view of the
database querying approach outlined
view of the data
querying approach outlined in
of the data in
approach outlined in section
the data in figure
for the entire chain
each user would see
at gossip rates of
user would see only
would see only the
see only the objects
only the objects within
the objects within some
objects within some range
or within line of
within line of sight
as a user moves
a user moves about
the platform would recompute
platform would recompute the
would recompute the query
recompute the query result
milliseconds showing that the
showing that the behavior
that the behavior of
the behavior of the
behavior of the scheme
and then update the
of the scheme is
then update the display
the scheme is not
update the display accordingly
scheme is not a
is not a fluke
note that the delay
that the delay of
the delay of the
delay of the updates
of the updates delivered
that since some live
the updates delivered at
hit ratio hit ratio
since some live objects
updates delivered at the
some live objects uses
delivered at the victim
live objects uses p
at the victim node
the victim node is
victim node is significantly
node is significantly larger
p protocols that might
is significantly larger than
protocols that might organize
significantly larger than that
that might organize user
larger than that of
might organize user s
than that of the
organize user s machines
that of the nodes
user s machines into
of the nodes downstream
s machines into groups
the nodes downstream of
machines into groups forwarding
nodes downstream of it
into groups forwarding streams
downstream of it in
groups forwarding streams of
of it in the
forwarding streams of data
it in the chain
streams of data to
of data to one
data to one another
we observed that even
observed that even with
that even with sufficiently
we end up in
even with sufficiently high
end up in a
with sufficiently high gossip
up in a situation
sufficiently high gossip rate
in a situation where
a situation where each
situation where each user
where each user belongs
each user belongs to
the only node to
user belongs to a
only node to experience
belongs to a potentially
node to experience any
to a potentially large
to experience any significant
a potentially large number
experience any significant inconsistency
potentially large number of
any significant inconsistency window
large number of such
significant inconsistency window is
number of such groups
inconsistency window is the
window is the node
is the node that
product a nity social
the node that failed
a nity social network
and the groups that
the groups that one
groups that one user
note that when the
that one user is
that when the failed
one user is a
when the failed node
user is a part
the failed node rejoins
is a part of
a part of might
part of might be
of might be very
might be very different
queries are performed against
be very different from
are performed against its
very different from the
performed against its data
different from the groups
against its data before
from the groups that
its data before it
the groups that other
data before it has
groups that other users
before it has time
that other users belong
it has time to
other users belong to
has time to fully
time to fully recover
to support such a
support such a model
once the chain is
the chain is restored
we need to be
all new updates are
need to be able
new updates are received
to be able to
be able to support
able to support very
to support very large
support very large numbers
very large numbers of
there were rare cases
large numbers of publish
were rare cases when
rare cases when gossip
cases when gossip circumvented
when gossip circumvented the
gossip circumvented the chain
circumvented the chain replication
the chain replication even
chain replication even though
and with different users
replication even though the
with different users subscribed
even though the chain
different users subscribed to
though the chain was
users subscribed to very
the chain was not
subscribed to very different
chain was not broken
to very different sets
very different sets of
different sets of topics
but this happened only
this happened only for
happened only for gossip
up to now we
only for gossip rates
for gossip rates close
to now we have
gossip rates close to
rates close to the
now we have been
close to the update
to the update injection
we have been fairly
the update injection rate
have been fairly negative
been fairly negative about
fairly negative about the
later in this section
in this section we
negative about the trend
this section we will
section we will show
about the trend to
we will show that
will show that even
the trend to standardize
show that even with
that even with these
trend to standardize client
even with these rapid
with these rapid repairs
to standardize client access
standardize client access to
client access to hosted
access to hosted content
the gossip overhead is
to hosted content through
gossip overhead is actually
overhead is actually low
hosted content through web
content through web minibrowsers
through web minibrowsers that
web minibrowsers that make
minibrowsers that make the
that make the javascript
make the javascript running
the javascript running on
javascript running on a
running on a user
on a user s
a user s machine
user s machine virtually
s machine virtually inseparable
machine virtually inseparable from
virtually inseparable from the
inseparable from the data
from the data center
our core criticism was
of the messages were
core criticism was that
the messages were delivered
criticism was that for
messages were delivered by
was that for most
were delivered by gossip
that for most soc
delivered by gossip ahead
for most soc applications
by gossip ahead of
gossip ahead of the
ahead of the chain
of the chain for
the chain for gossip
a minibrowser approach would
chain for gossip rate
minibrowser approach would lack
for gossip rate identical
approach would lack the
gossip rate identical to
would lack the flexibility
rate identical to the
lack the flexibility to
identical to the update
the flexibility to seamlessly
to the update injection
flexibility to seamlessly combine
the update injection rate
to seamlessly combine content
seamlessly combine content from
combine content from different
content from different sources
and to customize the
to customize the underlying
customize the underlying communication
the underlying communication substrate
contains a plot of
a plot of update
plot of update injection
of update injection time
update injection time against
injection time against update
time against update delivery
our earlier concerns carry
against update delivery time
earlier concerns carry over
update delivery time for
concerns carry over to
delivery time for the
carry over to the
time for the victim
over to the second
for the victim node
to the second life
the second life scenario
ideally this is a
this is a straight
is a straight line
a straight line because
straight line because of
line because of chain
because of chain replication
d texture representing terrain
texture representing terrain in
note that once the
representing terrain in some
that once the victim
terrain in some region
once the victim node
product a nity social
the victim node recovers
a nity social network
it gracefully catches up
gracefully catches up and
catches up and does
up and does so
in a minibrowser approach
and does so quickly
does so quickly for
so quickly for both
quickly for both gossip
for both gossip rates
the minibrowser generates the
both gossip rates identical
minibrowser generates the texture
gossip rates identical and
generates the texture from
rates identical and half
the texture from hosted
identical and half the
texture from hosted data
and half the update
half the update injection
the update injection rate
now consider the link
consider the link congestion
the link congestion case
this model makes it
model makes it difficult
to superimpose other content
superimpose other content over
other content over the
content over the texture
we would need to
would need to rely
need to rely on
to rely on a
rely on a hosting
on a hosting system
a hosting system s
hosting system s mashup
system s mashup technology
s mashup technology to
mashup technology to do
technology to do this
if we wanted to
we wanted to blend
wanted to blend weather
to blend weather information
blend weather information from
weather information from the
information from the national
from the national hurricane
the national hurricane center
national hurricane center with
hurricane center with a
center with a google
with a google map
the google map service
google map service would
map service would need
service would need to
would need to explicitly
need to explicitly support
to explicitly support this
explicitly support this sort
support this sort of
this sort of embedding
in our second life
our second life scenario
the visible portion of
visible portion of the
portion of the scene
of the scene the
the scene the part
scene the part of
the part of the
part of the texture
of the texture being
the texture being displayed
texture being displayed will
being displayed will often
displayed will often be
will often be controlled
often be controlled by
be controlled by events
controlled by events generated
by events generated by
events generated by other
generated by other live
by other live objects
other live objects that
live objects that share
objects that share the
that share the display
share the display window
perhaps under control of
under control of users
control of users running
of users running on
users running on machines
running on machines elsewhere
on machines elsewhere in
machines elsewhere in the
elsewhere in the network
these remote sources won
remote sources won t
limited cache entry ttl
sources won t fit
cache entry ttl fig
won t fit into
t fit into the
fit into the interaction
into the interaction model
the interaction model expected
interaction model expected by
model expected by the
expected by the minibrowser
experiments with workloads based
with workloads based on
workloads based on a
based on a web
on a web retailer
a web retailer product
web retailer product affinity
retailer product affinity topology
the size and shape
product affinity topology and
size and shape of
affinity topology and a
topology and a social
and shape of the
and a social network
a social network topology
shape of the display
social network topology illustrated
network topology illustrated in
of the display window
the display window and
display window and other
window and other elements
and other elements of
other elements of the
elements of the runtime
of the runtime environment
the runtime environment should
runtime environment should be
environment should be inherited
should be inherited from
be inherited from the
inherited from the hierarchy
from the hierarchy structure
the hierarchy structure of
hierarchy structure of the
structure of the object
of the object mashup
the object mashup used
object mashup used to
mashup used to create
used to create the
to create the application
compared against the alternative
against the alternative of
the alternative of reducing
alternative of reducing cache
of reducing cache entry
reducing cache entry time
thus our texture should
our texture should learn
texture should learn its
should learn its size
learn its size and
its size and orientation
size and orientation and
and orientation and even
orientation and even the
and even the gps
even the gps coordinates
the gps coordinates on
gps coordinates on which
coordinates on which to
on which to center
which to center from
to center from the
data points are medians
center from the parent
points are medians and
from the parent object
are medians and error
the parent object that
medians and error bars
parent object that hosts
and error bars bound
object that hosts it
error bars bound the
and similarly until we
similarly until we reach
until we reach the
we reach the root
reach the root object
the root object hosting
root object hosting the
object hosting the display
hosting the display window
a minibrowser isn t
minibrowser isn t a
isn t a component
it runs the show
despite all of the
all of the above
of the above criticism
this could work well
could work well if
work well if a
well if a system
minibrowsers retain one potential
if a system has
retain one potential advantage
a system has multiple
one potential advantage over
system has multiple classes
potential advantage over the
has multiple classes of
advantage over the layered
multiple classes of objects
over the layered architecture
the layered architecture we
layered architecture we proposed
architecture we proposed earlier
all clustered but with
clustered but with different
but with different associated
with different associated clustering
since all aspects of
different associated clustering properties
all aspects of the
aspects of the view
of the view are
the view are optimized
view are optimized to
are optimized to run
optimized to run together
the interaction controls might
interaction controls might be
controls might be far
might be far more
be far more sophisticated
far more sophisticated and
more sophisticated and perform
sophisticated and perform potentially
and perform potentially much
perform potentially much better
potentially much better than
much better than a
better than a solution
than a solution resulting
a solution resulting from
solution resulting from mashing
resulting from mashing up
from mashing up together
mashing up together multiple
up together multiple layers
together multiple layers developed
multiple layers developed independently
in many realistic examples
many realistic examples event
consistent inconsistent aborted ab
based interfaces could get
inconsistent aborted ab ev
interfaces could get fairly
aborted ab ev re
could get fairly complex
ab ev re ab
ev re ab ev
re ab ev re
ab ev re i
ev re i i
and difficult for most
re i i tr
difficult for most developers
i i tr tr
for most developers to
i tr tr o
most developers to work
tr tr o o
developers to work with
tr o o rt
o o rt ct
o rt ct rt
rt ct rt ct
ct rt ct y
rt ct y y
ct y y amazon
this observation highlights the
y y amazon orkut
y amazon orkut fig
observation highlights the importance
highlights the importance of
the importance of developing
importance of developing component
of developing component interface
developing component interface and
component interface and event
interface and event standards
and event standards for
event standards for the
standards for the layered
the efficacy of t
for the layered architecture
the layered architecture we
layered architecture we ve
architecture we ve outlined
cache as a function
as a function of
a function of the
the task isn t
function of the inconsistency
task isn t really
of the inconsistency handling
isn t really all
the inconsistency handling strategy
t really all that
inconsistency handling strategy for
really all that daunting
handling strategy for realistic
strategy for realistic workloads
the designers of microsoft
designers of microsoft s
of microsoft s object
microsoft s object linking
s object linking and
object linking and embedding
much work has been
work has been done
has been done on
been done on creating
done on creating consistent
standard faced similar challenges
on creating consistent caches
creating consistent caches for
consistent caches for web
caches for web servers
their ole interfaces are
ole interfaces are pervasively
interfaces are pervasively used
are pervasively used to
pervasively used to support
used to support thousands
to support thousands of
support thousands of plugins
thousands of plugins that
of plugins that implement
plugins that implement context
that implement context menus
virtual folders and various
folders and various namespace
and various namespace extensions
and drag and drop
drag and drop technologies
lacking the needed standards
the live objects platform
live objects platform supports
objects platform supports both
platform supports both options
supports both options today
in addition to allowing
addition to allowing hosted
to allowing hosted content
allowing hosted content to
hosted content to be
content to be pulled
to be pulled in
be pulled in and
pulled in and exposed
in and exposed via
and exposed via event
exposed via event interfaces
components developed by some
developed by some of
by some of our
some of our users
of our users also
our users also use
users also use embedded
also use embedded minibrowsers
use embedded minibrowsers to
embedded minibrowsers to gain
minibrowsers to gain access
to gain access to
gain access to a
access to a wide
to a wide range
a wide range of
wide range of platforms
performance evaluation central to
evaluation central to our
central to our argument
to our argument is
our argument is the
argument is the assertion
is the assertion that
the assertion that hosted
assertion that hosted event
that hosted event notification
hosted event notification solutions
event notification solutions scale
notification solutions scale poorly
solutions scale poorly and
scale poorly and stand
poorly and stand as
and stand as a
stand as a barrier
as a barrier to
a barrier to collaboration
barrier to collaboration applications
and that developers will
that developers will want
developers will want to
will want to combine
want to combine hosted
to combine hosted content
combine hosted content with
hosted content with p
p protocols to overcome
protocols to overcome these
to overcome these problems
in this section we
this section we present
section we present data
we present data to
present data to support
data to support our
to support our claims
some of the results
and higher level objects
are drawn from a
drawn from a widely
from a widely cited
a widely cited industry
widely cited industry whitepaper
such systems consider only
systems consider only one
consider only one object
only one object at
and were obtained using
one object at a
were obtained using a
object at a time
obtained using a testing
using a testing methodology
a testing methodology and
testing methodology and setup
methodology and setup developed
and only individual read
and setup developed and
only individual read and
setup developed and published
individual read and write
developed and published by
read and write operations
and published by sonic
published by sonic software
as they do not
they do not support
do not support a
not support a transactional
support a transactional interface
there are few if
are few if any
few if any multi
these systems generally try
the remainder was produced
systems generally try to
remainder was produced in
update delay as seen
generally try to avoid
was produced in our
try to avoid staleness
produced in our own
to avoid staleness through
delay as seen by
avoid staleness through techniques
in our own experiments
staleness through techniques such
as seen by individual
through techniques such as
seen by individual processes
techniques such as time
by individual processes during
individual processes during persistent
processes during persistent link
during persistent link congestion
persistent link congestion node
from the industry white
the industry white paper
updates on upstream and
on upstream and downstream
upstream and downstream fifo
analyzes the performance of
and downstream fifo channels
the performance of several
performance of several commercial
of several commercial enterprise
several commercial enterprise service
our work considers multi
commercial enterprise service bus
object transactional consistency of
transactional consistency of cache
consistency of cache access
shown is the maximum
is the maximum throughput
early work on scalable
work on scalable database
on scalable database caching
scalable database caching mostly
database caching mostly ignored
caching mostly ignored transactional
mostly ignored transactional consistency
the experiment varies the
experiment varies the number
varies the number of
work has been done
the number of subscribers
has been done on
number of subscribers while
been done on creating
of subscribers while using
done on creating consistent
subscribers while using a
on creating consistent caches
while using a single
creating consistent caches for
using a single publisher
consistent caches for databases
a single publisher that
single publisher that communicates
publisher that communicates through
that communicates through a
communicates through a single
through a single hosted
a single hosted message
single hosted message broker
hosted message broker on
message broker on a
broker on a single
on a single topic
extends a centralized database
a centralized database with
centralized database with support
database with support for
with support for caches
figured for message durability
support for caches that
for caches that provide
caches that provide snapshot
that provide snapshot isolation
provide snapshot isolation semantics
even if a subscriber
if a subscriber experiences
a subscriber experiences a
subscriber experiences a transient
experiences a transient loss
albeit the snapshots seen
a transient loss of
the snapshots seen may
transient loss of connectivity
snapshots seen may be
seen may be stale
the publisher retains and
to improve the commit
publisher retains and hence
improve the commit rate
retains and hence can
the commit rate for
and hence can replay
commit rate for read
hence can replay all
can replay all messages
as the number of
the number of subscribers
number of subscribers increases
where the cache holds
the cache holds several
cache holds several versions
holds several versions of
several versions of an
versions of an object
of an object and
latency will also soars
an object and enables
will also soars because
object and enables the
also soars because the
and enables the cache
soars because the amount
enables the cache to
because the amount of
the cache to choose
the amount of time
cache to choose a
amount of time the
to choose a version
of time the broker
choose a version that
time the broker needs
a version that allows
the broker needs to
version that allows a
broker needs to spend
that allows a transaction
needs to spend sending
allows a transaction to
to spend sending a
a transaction to commit
spend sending a single
sending a single message
a single message increases
single message increases linearly
message increases linearly with
this technique could also
increases linearly with the
technique could also be
linearly with the number
could also be used
with the number of
also be used with
the number of subscribers
be used with our
used with our solution
inconsistency window against gossip
window against gossip rate
against gossip rate at
gossip rate at the
durability is often not
rate at the failed
is often not required
at the failed node
shows throughput in an
throughput in an experiment
in an experiment in
an experiment in which
experiment in which the
in which the publisher
which the publisher does
the publisher does not
publisher does not log
does not log data
a disconnected subscriber would
disconnected subscriber would experience
subscriber would experience a
would experience a loss
also support snapshot isolation
we find that while
but can be used
find that while the
can be used with
that while the maximum
be used with any
while the maximum throughput
used with any backend
the maximum throughput is
with any backend database
maximum throughput is much
throughput is much higher
time between node failure
including ones that are
between node failure and
ones that are sharded
the degradation of performance
that are sharded and
node failure and rejoin
degradation of performance is
failure and rejoin as
of performance is even
and rejoin as number
performance is even more
rejoin as number of
is even more dramatic
as number of consecutive
number of consecutive updates
of consecutive updates missed
consecutive updates missed by
updates missed by the
missed by the victim
by the victim node
developers of collaboration applications
of collaboration applications that
collaboration applications that need
applications that need good
that need good scalability
need good scalability might
good scalability might discover
scalability might discover that
provides a transactionally consistent
might discover that hosted
a transactionally consistent cache
discover that hosted esb
transactionally consistent cache for
that hosted esb options
consistent cache for the
hosted esb options won
cache for the jboss
esb options won t
for the jboss middleware
options won t achieve
won t achieve this
t achieve this goal
we report on some
report on some experiments
on some experiments we
some experiments we conducted
experiments we conducted on
we conducted on our
conducted on our own
on our own at
our own at cornell
support transactions on cached
transactions on cached enterprise
on cached enterprise javabeans
focusing on scalability of
on scalability of event
scalability of event notification
of event notification platforms
event notification platforms that
notification platforms that leverage
platforms that leverage peer
peer techniques for dissemination
techniques for dissemination and
for dissemination and recovery
allows update transactions to
update transactions to read
on the first graph
transactions to read stale
to read stale data
read stale data out
stale data out of
data out of caches
out of caches and
of caches and provide
caches and provide bounds
and provide bounds on
provide bounds on how
bounds on how much
on how much staleness
how much staleness is
much staleness is allowed
we compare the maximum
compare the maximum throughput
the maximum throughput of
these techniques require fast
maximum throughput of two
techniques require fast communication
throughput of two decentralized
require fast communication between
of two decentralized reliable
fast communication between the
two decentralized reliable multicast
communication between the cache
decentralized reliable multicast protocols
between the cache and
the cache and the
cache and the database
and the database for
the database for good
database for good performance
in our work caches
our work caches are
work caches are asynchronously
caches are asynchronously updated
a single topic and
single topic and a
topic and a single
which is how caches
and a single publisher
is how caches currently
how caches currently work
caches currently work in
currently work in large
work in large multi
unlike in the previous
in the previous tests
f uture d irections
uture d irections the
d irections the dependency
irections the dependency list
the dependency list sizes
these experiments used a
dependency list sizes for
list sizes for all
sizes for all objects
for all objects in
all objects in t
cache are currently all
are currently all of
currently all of the
all of the same
of the same maximum
the same maximum length
this may not be
may not be optimal
this limits the peak
limits the peak performance
the peak performance to
if the workload accesses
the workload accesses objects
workload accesses objects in
accesses objects in clusters
objects in clusters of
in clusters of different
clusters of different sizes
objects of larger clusters
of larger clusters call
larger clusters call for
clusters call for longer
call for longer dependency
for longer dependency lists
once appropriate real workloads
appropriate real workloads are
real workloads are available
it may be possible
may be possible to
be possible to improve
possible to improve performance
to improve performance by
improve performance by dynamically
performance by dynamically changing
by dynamically changing per
achieves stable high throughput
object dependency list sizes
balancing between objects to
between objects to maintain
objects to maintain the
to maintain the same
maintain the same overall
the same overall space
same overall space overhead
another option is to
option is to explore
is to explore an
runs at about a
to explore an approach
at about a fifth
explore an approach in
about a fifth that
an approach in which
a fifth that speed
approach in which each
in which each type
which each type of
each type of object
type of object would
collapsing as the number
of object would have
as the number of
object would have its
the number of subscribers
would have its own
number of subscribers increases
have its own dependency
its own dependency list
own dependency list bound
at small loss rates
latency in qsm is
in qsm is at
qsm is at the
is at the level
at the level of
agnostic and treats all
and treats all objects
treats all objects and
all objects and object
objects and object relations
and object relations as
object relations as equal
using an lru policy
an lru policy to
lru policy to trim
policy to trim the
to trim the list
trim the list of
the list of dependencies
ms irrespectively of the
irrespectively of the number
gossip chain inconsistency window
of the number of
the number of subscribers
there may be cases
may be cases in
when the number of
be cases in which
the number of topics
cases in which the
number of topics is
in which the application
of topics is varied
which the application could
the application could explicitly
application could explicitly inform
could explicitly inform the
qsm maintains its high
explicitly inform the cache
maintains its high performance
inform the cache of
the cache of relevant
cache of relevant object
of relevant object dependencies
on the second graph
and those could then
those could then be
could then be treated
then be treated as
be treated as more
treated as more important
as more important and
more important and retained
while other less important
we report performance for
other less important ones
less important ones are
important ones are managed
ones are managed by
are managed by some
managed by some other
by some other policy
some other policy such
other policy such as
policy such as lru
but performance for other
performance for other group
for other group sizes
other group sizes is
in a web album
group sizes is similar
a web album the
web album the set
album the set of
jgroups performance was higher
the set of pictures
performance was higher with
set of pictures and
was higher with smaller
higher with smaller group
of pictures and their
with smaller group sizes
pictures and their acl
and their acl is
their acl is an
but erodes as the
acl is an important
erodes as the number
is an important dependency
as the number of
the number of topics
an important dependency whereas
number of topics increases
important dependency whereas occasional
dependency whereas occasional tagging
whereas occasional tagging operations
jgroups failed when we
occasional tagging operations that
failed when we attempted
tagging operations that relate
when we attempted to
operations that relate pictures
we attempted to configure
that relate pictures to
attempted to configure it
relate pictures to users
to configure it with
pictures to users may
configure it with more
to users may be
it with more than
users may be less
may be less important
it may be straightforward
may be straightforward to
be straightforward to extend
straightforward to extend the
to extend the cache
extend the cache api
the cache api to
cache api to allow
api to allow the
to allow the application
allow the application to
we look at two
the application to specify
look at two scalable
application to specify such
at two scalable protocols
to specify such dependencies
two scalable protocols under
specify such dependencies and
scalable protocols under conditions
such dependencies and to
protocols under conditions of
dependencies and to modify
under conditions of stress
and to modify t
with a focus on
cache to respect them
a focus on delivery
focus on delivery latency
c onclusion existing large
as a fixed message
a fixed message rate
fixed message rate is
message rate is spread
scale computing frameworks make
rate is spread over
inconsistency window against gossip
is spread over varying
computing frameworks make heavy
spread over varying numbers
window against gossip rate
over varying numbers of
frameworks make heavy use
varying numbers of topics
against gossip rate for
make heavy use of
gossip rate for the
heavy use of edge
rate for the whole
use of edge caches
for the whole chain
of edge caches to
edge caches to reduce
caches to reduce client
to reduce client latency
subscribers each join some
but this form of
each join some number
this form of caching
join some number of
form of caching has
some number of topics
of caching has not
caching has not been
has not been available
not been available for
a publisher sends data
been available for transactional
publisher sends data at
available for transactional applications
sends data at a
data at a rate
at a rate of
we believe this is
believe this is one
this is one reason
is one reason that
one reason that transactions
reason that transactions are
that transactions are generally
transactions are generally not
are generally not considered
generally not considered to
not considered to be
considered to be a
to be a viable
be a viable option
a viable option in
viable option in extremely
option in extremely large
in extremely large systems
selecting the topic in
the topic in which
topic in which to
in which to send
which to send at
to send at random
time between node failure
between node failure and
node failure and rejoin
failure and rejoin as
and rejoin as number
rejoin as number of
as number of consecutive
a variant of serializability
number of consecutive updates
variant of serializability that
of consecutive updates missed
of serializability that is
consecutive updates missed by
serializability that is suitable
updates missed by the
that is suitable for
missed by the victim
is suitable for incoherent
by the victim node
suitable for incoherent caches
which cannot communicate with
cannot communicate with the
communicate with the backend
with the backend database
the backend database on
backend database on every
database on every read
on every read access
we see that ricochet
we then presented t
an architecture for controlling
architecture for controlling transaction
for controlling transaction consistency
controlling transaction consistency with
a cornelldeveloped protocol for
transaction consistency with caches
cornelldeveloped protocol for low
the system extends the
system extends the edge
extends the edge cache
the edge cache by
edge cache by allowing
cache by allowing it
by allowing it to
allowing it to offer
it to offer a
to offer a transactional
offer a transactional interface
we believe that t
cache is the first
is the first transaction
aware caching architecture in
caching architecture in which
architecture in which caches
in which caches are
which caches are updated
caches are updated asynchronously
inconsistency window against the
as the number of
window against the ratio
the number of topics
against the ratio between
number of topics increases
the ratio between injection
of topics increases to
ratio between injection rate
between injection rate and
injection rate and gossip
rate and gossip rate
a lookup request only
lookup request only requires
request only requires a
only requires a round
trip to the database
to the database in
the database in case
database in case there
in case there is
case there is a
there is a cache
is a cache miss
a cache miss there
cache miss there is
miss there is no
there is no additional
is no additional traffic
different update injection delay
no additional traffic and
additional traffic and delays
traffic and delays to
and delays to ensure
delays to ensure cache
to ensure cache coherence
latency soars when we
soars when we repeat
when we repeat this
we repeat this with
repeat this with the
this with the industrystandard
s overload by dropping
with the industrystandard scalable
cache associates dependency information
the industrystandard scalable reliable
overload by dropping updates
industrystandard scalable reliable multicast
associates dependency information with
by dropping updates on
dependency information with cached
information with cached database
dropping updates on its
with cached database objects
updates on its inbound
on its inbound and
its inbound and outbound
inbound and outbound fifo
while leaving the interaction
and outbound fifo channels
leaving the interaction between
outbound fifo channels according
the interaction between the
widely used for event
fifo channels according to
interaction between the backend
used for event notification
between the backend systems
for event notification in
the backend systems and
event notification in their
channels according to a
backend systems and the
notification in their datacenters
according to a random
systems and the cache
to a random distribution
and the cache otherwise
a random distribution throughout
the cache otherwise unchanged
random distribution throughout the
as can be seen
distribution throughout the first
can be seen in
throughout the first three
be seen in the
the first three quarters
seen in the graph
first three quarters of
this information includes version
three quarters of the
information includes version identifiers
quarters of the experiment
includes version identifiers and
version identifiers and bounded
srm s recovery latency
s recovery latency rises
recovery latency rises linearly
latency rises linearly in
rises linearly in the
linearly in the figure
with this modest amount
this modest amount of
modest amount of additional
amount of additional information
scalability of commercial esbs
of commercial esbs figure
we show that inconsistency
show that inconsistency can
that inconsistency can be
inconsistency can be greatly
can be greatly reduced
be greatly reduced or
greatly reduced or even
scalability of commercial esbs
reduced or even completely
of commercial esbs number
or even completely eliminated
commercial esbs number of
even completely eliminated in
esbs number of topics
completely eliminated in some
eliminated in some cases
cache is intended for
is intended for clustered
intended for clustered workloads
and those arise naturally
those arise naturally in
arise naturally in social
naturally in social networks
our experiments confirm that
mobile applications with spatial
applications with spatial locality
hosted enterprise service bus
enterprise service bus architectures
service bus architectures can
bus architectures can achieve
architectures can achieve high
can achieve high levels
our experiments demonstrate t
achieve high levels of
high levels of publish
cache to be effective
to be effective in
subscribe performance for small
be effective in realistic
performance for small numbers
and we report on
for small numbers of
effective in realistic workloads
small numbers of subscribers
in realistic workloads based
realistic workloads based on
workloads based on datasets
based on datasets from
on datasets from amazon
but performance degrades very
datasets from amazon and
performance degrades very sharply
from amazon and orkut
degrades very sharply as
very sharply as the
sharply as the number
as the number of
the number of subscribers
using dependency lists of
number of subscribers or
dependency lists of size
of subscribers or topics
subscribers or topics grows
updates that were initially
the jgroups and srm
that were initially dropped
jgroups and srm platforms
were initially dropped and
initially dropped and eventually
dropped and eventually made
which don t leverage
don t leverage peer
and eventually made their
eventually made their way
made their way through
their way through gossip
way through gossip could
through gossip could later
gossip could later be
could later be sent
later be sent via
be sent via fifo
scale poorly in the
sent via fifo channels
poorly in the number
via fifo channels as
in the number of
fifo channels as shown
the number of subscribers
channels as shown by
number of subscribers or
as shown by the
of subscribers or topics
shown by the increasingly
by the increasingly large
and was also able
the increasingly large density
was also able to
increasingly large density of
also able to increase
large density of dark
able to increase consistent
to increase consistent transaction
increase consistent transaction rate
consistent transaction rate by
scale well in these
well in these dimensions
plots closer to the
closer to the tail
to the tail of
the tail of the
tail of the chain
ricochet achieved the best
achieved the best recovery
the best recovery latency
best recovery latency when
recovery latency when message
as before note that
latency when message loss
before note that the
when message loss is
note that the yaxes
message loss is an
that the yaxes have
loss is an issue
with only nominal overhead
the yaxes have different
only nominal overhead on
yaxes have different scales
nominal overhead on the
have different scales to
overhead on the database
but at relatively high
different scales to observe
at relatively high overhead
scales to observe the
to observe the delays
observe the delays better
our experiments with synthetic
experiments with synthetic workloads
not shown on these
with synthetic workloads showed
shown on these graphs
synthetic workloads showed that
workloads showed that t
the figures show that
figures show that even
show that even for
that even for a
even for a gossip
cache s efficacy depends
for a gossip rate
s efficacy depends on
a gossip rate half
qsm at small loss
gossip rate half the
efficacy depends on the
rate half the injection
at small loss rates
depends on the clustering
small loss rates achieves
on the clustering level
half the injection rate
the clustering level of
loss rates achieves similar
clustering level of the
rates achieves similar average
level of the workload
achieves similar average latency
similar average latency with
recall that this is
average latency with considerably
that this is the
latency with considerably lower
this is the rate
with considerably lower network
is the rate at
considerably lower network overheads
the rate at which
rate at which digests
cache adapts to dynamically
adapts to dynamically changing
to dynamically changing workloads
but if a packet
dynamically changing workloads where
if a packet is
changing workloads where clusters
a packet is lost
workloads where clusters change
where clusters change over
clusters change over time
are exchanged between two
exchanged between two or
between two or more
it may take several
two or more processes
may take several seconds
take several seconds to
due to resource limitations
several seconds to recover
to resource limitations t
seconds to recover it
the epidemics could deliver
epidemics could deliver messages
could deliver messages with
deliver messages with a
cache maintains only a
making it less appropriate
messages with a delay
it less appropriate for
with a delay of
less appropriate for time
a delay of about
maintains only a short
only a short dependency
a short dependency list
which is naturally imperfect
we don t see
is naturally imperfect and
don t see any
naturally imperfect and does
t see any single
imperfect and does not
see any single winner
and does not include
any single winner here
does not include all
not include all dependencies
each of the solutions
we proved that when
of the solutions tested
proved that when resources
the solutions tested has
that when resources are
solutions tested has some
when resources are unbounded
tested has some advantages
has some advantages that
some advantages that its
advantages that its competitors
that its competitors lack
s for the rest
cache s algorithm implements
for the rest of
s algorithm implements cache
the rest of the
rest of the chain
of the chain during
we re currently developing
the chain during a
re currently developing new
chain during a congestion
currently developing new p
during a congestion that
a congestion that took
the plot also shows
plot also shows that
also shows that delays
shows that delays increased
that delays increased with
delays increased with time
therefore if congestion may
it builds an overlay
if congestion may span
builds an overlay multicast
congestion may span large
an overlay multicast tree
may span large periods
overlay multicast tree within
span large periods of
multicast tree within which
large periods of time
tree within which events
within which events travel
the gossip rate must
and is capable of
gossip rate must be
is capable of selforganizing
rate must be carefully
capable of selforganizing in
must be carefully tuned
of selforganizing in the
be carefully tuned to
selforganizing in the presence
carefully tuned to compensate
in the presence of
tuned to compensate for
the presence of firewalls
to compensate for the
compensate for the losses
for the losses induced
the losses induced by
losses induced by the
induced by the congested
by the congested tcp
the congested tcp channels
the second round of
second round of experiments
round of experiments quantified
of experiments quantified the
a separate project is
experiments quantified the average
separate project is creating
quantified the average and
project is creating a
the average and maximum
is creating a protocol
average and maximum inconsistency
creating a protocol suite
and maximum inconsistency window
a protocol suite that
maximum inconsistency window for
protocol suite that we
inconsistency window for a
suite that we call
window for a service
that we call the
we call the properties
call the properties framework
under various update injection
various update injection rates
update injection rates and
injection rates and gossip
rates and gossip rates
and gossip rates respectively
the goal is to
goal is to offer
is to offer strong
to offer strong forms
we define the inconsistency
offer strong forms of
define the inconsistency window
strong forms of reliability
the inconsistency window as
forms of reliability that
inconsistency window as the
of reliability that can
window as the time
reliability that can be
as the time interval
that can be customized
the time interval during
can be customized for
time interval during which
be customized for special
interval during which queries
customized for special needs
during which queries against
which queries against the
queries against the service
against the service return
the service return a
service return a stale
return a stale value
speed and scalability are
and scalability are only
scalability are only elements
are only elements of
only elements of a
elements of a broader
of a broader story
shows that the inconsistency
that the inconsistency window
the inconsistency window grows
developers will need different
inconsistency window grows slowly
will need different solutions
window grows slowly as
need different solutions for
grows slowly as the
different solutions for different
slowly as the gap
solutions for different purposes
as the gap between
the gap between the
gap between the update
between the update injection
the update injection rate
by offering a flexible
update injection rate and
offering a flexible yet
injection rate and the
a flexible yet structured
rate and the gossip
flexible yet structured component
and the gossip rate
yet structured component mashup
the gossip rate widens
structured component mashup environment
the graph s x
live objects makes it
graph s x axis
objects makes it possible
s x axis represents
makes it possible to
x axis represents the
it possible to create
axis represents the ratio
possible to create applications
represents the ratio between
to create applications that
the ratio between the
create applications that mix
ratio between the update
applications that mix hosted
between the update injection
that mix hosted with
the update injection rate
mix hosted with p
update injection rate and
injection rate and gossip
rate and gossip rate
and that can adapt
that can adapt their
can adapt their behavior
this confirms that epidemics
confirms that epidemics are
that epidemics are a
epidemics are a robust
are a robust tunable
a robust tunable mechanism
robust tunable mechanism providing
tunable mechanism providing graceful
to achieve desired properties
mechanism providing graceful degradation
achieve desired properties in
desired properties in a
properties in a way
in a way matched
a way matched to
way matched to the
matched to the environment
the inconsistency window shifts
inconsistency window shifts in
window shifts in accordance
shifts in accordance with
in accordance with the
accordance with the update
with the update injection
the update injection rate
scalability of qsm and
of qsm and jgroups
throughput for various group
for various group sizes
notice that the difference
that the difference between
the difference between the
difference between the maximum
between the maximum inconsistency
the maximum inconsistency window
maximum inconsistency window and
inconsistency window and the
window and the average
and the average inconsistency
prior work the idea
the average inconsistency window
work the idea of
average inconsistency window is
the idea of integrating
inconsistency window is two
idea of integrating web
window is two orders
of integrating web services
is two orders of
integrating web services with
two orders of magnitude
web services with peer
this reflects the degree
reflects the degree to
the degree to which
peer platforms is certainly
degree to which the
platforms is certainly not
to which the victim
is certainly not new
which the victim node
the victim node lags
victim node lags the
node lags the other
lags the other nodes
the other nodes during
other nodes during the
nodes during the period
during the period before
the period before it
period before it has
before it has fully
it has fully caught
has fully caught up
next we evaluated the
we evaluated the inconsistency
evaluated the inconsistency window
the inconsistency window of
inconsistency window of a
window of a service
of a service running
a service running at
service running at a
running at a particular
at a particular update
a particular update rate
and for three different
for three different intervals
three different intervals in
different intervals in which
intervals in which the
in which the victim
which the victim node
the victim node is
victim node is halted
show average and maximum
average and maximum inconsistency
and maximum inconsistency windows
maximum inconsistency windows for
inconsistency windows for both
windows for both the
for both the victim
both the victim and
the victim and for
victim and for the
and for the other
for the other processes
the other processes of
other processes of one
processes of one subservice
the more messages the
more messages the victim
messages the victim node
the victim node needs
victim node needs to
node needs to recover
the larger the inconsistency
larger the inconsistency window
again the difference between
the difference between the
difference between the average
between the average and
the average and maximum
average and maximum in
the existing work falls
existing work falls roughly
work falls roughly into
falls roughly into two
roughly into two categories
the first line of
first line of research
google s globally distributed
line of research is
s globally distributed database
of research is focused
research is focused on
is focused on the
focused on the use
on the use of
the use of peer
acm transactions on computer
transactions on computer systems
as a basis for
a basis for scalable
basis for scalable web
for scalable web service
scalable web service discovery
the second line of
second line of research
line of research concentrates
of research concentrates on
research concentrates on the
concentrates on the use
on the use of
the use of replication
use of replication protocols
of replication protocols at
replication protocols at the
protocols at the web
at the web service
the web service backend
web service backend to
service backend to achieve
backend to achieve fault
p platforms such as
platforms such as jxta
such as jxta are
as jxta are treated
jxta are treated not
are treated not as
treated not as means
not as means of
as means of collaboration
means of collaboration or
of collaboration or media
collaboration or media carrying
or media carrying live
media carrying live content
but rather as a
rather as a supporting
as a supporting infrastructure
a supporting infrastructure at
supporting infrastructure at the
infrastructure at the data
at the data center
the data center backend
our work is focused
work is focused on
is focused on blending
focused on blending the
on blending the content
blending the content available
the content available through
content available through p
p and web service
and web service protocols
neither technology is subordinate
technology is subordinate with
is subordinate with respect
subordinate with respect to
with respect to the
respect to the other
technologies that use peer
peer protocols to support
protocols to support live
to support live and
support live and interactive
live and interactive content
and interactive content have
interactive content have existed
content have existed earlier
an excellent example of
excellent example of such
example of such technology
of such technology is
such technology is the
technology is the croquet
distributed data structures over
data structures over a
structures over a shared
over a shared log
in proceedings of the
in which the entire
which the entire state
the entire state of
entire state of a
state of a virtual
th acm symposium on
acm symposium on operating
symposium on operating systems
d world is stored
on operating systems principles
world is stored in
is stored in a
stored in a peer
peer fashion and updated
fashion and updated using
and updated using a
updated using a two
other work in this
work in this direction
in this direction includes
none of these systems
delivery distribution for a
of these systems supports
distribution for a chain
these systems supports the
systems supports the sorts
supports the sorts of
the sorts of componentized
layered architectures that we
architectures that we have
that we have advocated
we have advocated here
the types of peer
gossip rate left figure
peer protocols these systems
protocols these systems can
these systems can leverage
and the types of
the types of a
types of a traditional
of a traditional hosted
a traditional hosted content
traditional hosted content they
hosted content they can
content they can blend
they can blend with
ordering transactions with prediction
can blend with their
transactions with prediction in
blend with their p
with prediction in distributed
prediction in distributed object
in distributed object stores
th workshop on large
our platform is designed
platform is designed from
is designed from ground
scale distributed systems and
designed from ground up
distributed systems and middleware
from ground up with
ground up with extensibility
up with extensibility in
with extensibility in mind
every part of it
part of it can
of it can be
it can be replaced
can be replaced and
be replaced and customized
and different components within
on each graph left
different components within a
each graph left bars
components within a single
graph left bars denote
within a single mashup
left bars denote transient
a single mashup application
bars denote transient failure
single mashup application can
mashup application can leverage
application can leverage different
can leverage different transport
leverage different transport protocols
prior work on typed
work on typed component
on typed component architectures
right bars denote a
typed component architectures includes
bars denote a transient
component architectures includes a
denote a transient failure
architectures includes a tremendous
a transient failure corroborated
includes a tremendous variety
transient failure corroborated with
a tremendous variety of
failure corroborated with a
tremendous variety of programming
corroborated with a link
variety of programming languages
with a link congestion
of programming languages and
a link congestion phenomenon
programming languages and platforms
link congestion phenomenon modeled
congestion phenomenon modeled by
including early languages such
early languages such as
languages such as smalltalk
such as smalltalk alongside
as smalltalk alongside modern
smalltalk alongside modern component
message drop on the
based environments such as
drop on the adjacent
environments such as java
on the adjacent fifo
the adjacent fifo channels
adjacent fifo channels of
fifo channels of node
key transactions for key
specialized component architectures such
component architectures such figure
scalability qsm and jgroups
throughput for various numbers
for various numbers of
various numbers of topics
for srm and ricochet
srm and ricochet with
and ricochet with varying
ricochet with varying numbers
with varying numbers of
varying numbers of topics
as mit s argus
mit s argus system
flexible protocol composition stacks
protocol composition stacks such
composition stacks such as
stacks such as bast
oriented architectures such as
architectures such as juni
has been used in
been used in the
used in the context
in the context of
the context of integrating
context of integrating service
discussion of component integration
of component integration systems
component integration systems and
integration systems and their
systems and their relation
and their relation to
their relation to live
relation to live objects
is beyond the scope
beyond the scope of
the scope of this
scope of this paper
more details can be
details can be found
can be found in
much relevant prior work
relevant prior work consists
prior work consists of
work consists of the
consists of the scripting
of the scripting languages
the scripting languages mentioned
scripting languages mentioned in
languages mentioned in the
facebook s distributed data
mentioned in the discussion
s distributed data store
in the discussion above
distributed data store for
data store for the
store for the social
for the social graph
in usenix annual technical
usenix annual technical conference
our belief is that
belief is that even
is that even though
that even though these
even though these languages
though these languages are
these languages are intended
languages are intended for
are intended for fairly
intended for fairly general
for fairly general use
they have evolved to
have evolved to focus
evolved to focus on
to focus on minibrowser
focus on minibrowser situations
on minibrowser situations in
minibrowser situations in which
situations in which the
in which the application
which the application lives
the application lives within
application lives within a
lives within a dedicated
within a dedicated browser
a dedicated browser frame
interacts directly with the
directly with the user
and cannot be mixed
cannot be mixed with
be mixed with content
mixed with content from
with content from other
content from other sources
from other sources in
other sources in a
sources in a layered
in a layered fashion
live objects can support
objects can support minibrowsers
can support minibrowsers as
support minibrowsers as objects
but we ve argued
we ve argued that
ve argued that by
argued that by modeling
that by modeling hosted
by modeling hosted content
modeling hosted content at
hosted content at a
content at a lower
we found that less
at a lower level
found that less than
a lower level as
lower level as components
level as components that
as components that interact
components that interact via
that interact via events
interact via events and
via events and focusing
events and focusing on
and focusing on the
focusing on the multi
layered style of mashups
style of mashups as
of mashups as opposed
mashups as opposed to
as opposed to the
opposed to the standard
of the messages were
to the standard tiled
the messages were delivered
the standard tiled model
messages were delivered by
were delivered by gossip
delivered by gossip for
by gossip for the
gossip for the nodes
for the nodes to
the nodes to the
nodes to the left
to the left of
the left of the
left of the victim
this confirms that gossip
confirms that gossip rarely
conclusions to build ambitious
that gossip rarely is
to build ambitious collaboration
gossip rarely is used
build ambitious collaboration application
rarely is used to
is used to circumvent
used to circumvent chain
to circumvent chain replication
circumvent chain replication in
the web services community
chain replication in the
web services community will
replication in the normal
services community will need
in the normal case
community will need ways
will need ways to
need ways to combine
scaling memcache at facebook
a peculiar effect is
peculiar effect is noticeable
effect is noticeable in
is noticeable in figure
content from multiple sources
these include hosted sources
th usenix symposium on
include hosted sources that
usenix symposium on networked
hosted sources that run
symposium on networked systems
sources that run in
in that more messages
on networked systems design
that more messages are
that run in data
more messages are delivered
networked systems design and
messages are delivered via
systems design and implementation
are delivered via gossip
run in data centers
in data centers and
data centers and support
centers and support web
even in the prefix
and support web services
in the prefix part
support web services interfaces
the prefix part of
prefix part of the
part of the chain
but also direct peer
although the effect is
the effect is also
effect is also evident
is also evident in
also evident in the
evident in the suffix
peer protocols capable of
protocols capable of transporting
capable of transporting audio
it is more significant
is more significant on
more significant on the
significant on the left
on the left hand
the left hand side
left hand side figure
whiteboard data and other
data and other content
and other content at
where the gossip rate
other content at high
the gossip rate is
content at high data
gossip rate is higher
at high data rates
because we observed this
we observed this phenomenon
observed this phenomenon only
this phenomenon only with
phenomenon only with update
a further need is
only with update rates
further need is to
with update rates of
need is to allow
is to allow disconnected
to allow disconnected collaboration
back to data centers
we suspect that the
our review of the
suspect that the network
review of the performance
that the network stack
the network stack is
of the performance of
network stack is more
stack is more efficient
the performance of enterprise
is more efficient in
performance of enterprise service
more efficient in dealing
efficient in dealing with
of enterprise service bus
in dealing with udp
dealing with udp packets
enterprise service bus eventing
with udp packets then
udp packets then with
service bus eventing solutions
packets then with tcp
then with tcp ones
bus eventing solutions in
with tcp ones under
tcp ones under heavy
eventing solutions in the
ones under heavy load
solutions in the standard
in the standard hosted
the standard hosted web
standard hosted web services
hosted web services model
web services model made
services model made it
model made it clear
made it clear that
it clear that hosted
clear that hosted event
that hosted event channels
hosted event channels won
event channels won t
channels won t have
won t have the
t have the scalability
have the scalability and
the scalability and latency
scalability and latency properties
and latency properties needed
latency properties needed by
properties needed by many
needed by many applications
p alternatives often achieve
alternatives often achieve far
often achieve far better
achieve far better scalability
they also have security
also have security advantages
delivery distribution for a
distribution for a chain
the data center doesn
data center doesn t
center doesn t get
doesn t get a
t get a chance
get a chance to
a chance to see
the live objects platform
live objects platform can
objects platform can seamlessly
platform can seamlessly support
can seamlessly support applications
seamlessly support applications that
support applications that require
applications that require a
that require a mixture
require a mixture of
a mixture of data
mixture of data sources
including both hosted and
both hosted and direct
hosted and direct p
transactional consistency and automatic
consistency and automatic management
and automatic management in
automatic management in an
management in an application
in an application data
an application data cache
further benefits include an
benefits include an easy
include an easy to
an easy to use
easy to use drag
th usenix symposium on
usenix symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
drop programming style that
programming style that yields
style that yields applications
that yields applications represented
yields applications represented as
applications represented as xml
represented as xml files
which can be shared
can be shared as
be shared as files
shared as files or
as files or even
files or even via
or even via email
users that open such
that open such files
consistency windows is slightly
open such files find
windows is slightly more
such files find themselves
is slightly more than
files find themselves immersed
slightly more than an
find themselves immersed in
more than an order
themselves immersed in a
than an order of
immersed in a mediarich
an order of magnitude
in a mediarich collaborative
a mediarich collaborative environment
mediarich collaborative environment that
collaborative environment that also
environment that also offers
that also offers strong
and this is attributable
also offers strong reliability
this is attributable to
is attributable to the
attributable to the victim
to the victim node
the victim node observe
victim node observe that
node observe that the
observe that the two
in the near future
that the two graphs
the two graphs denoting
two graphs denoting the
graphs denoting the maximum
denoting the maximum inconsistency
the maximum inconsistency windows
maximum inconsistency windows for
inconsistency windows for the
windows for the victim
for the victim node
the victim node and
most important of all
victim node and for
node and for the
and for the entire
for the entire chain
live objects are real
the entire chain are
entire chain are identical
the platform is available
platform is available for
is available for free
which means that clients
available for free download
means that clients perceiving
for free download from
that clients perceiving significant
free download from cornell
clients perceiving significant inconsistency
perceiving significant inconsistency are
significant inconsistency are the
inconsistency are the ones
are the ones that
the ones that are
ones that are querying
that are querying the
are querying the victim
querying the victim node
the victim node while
victim node while it
node while it is
while it is still
it is still recovering
is still recovering state
finally we performed a
we performed a set
performed a set of
fast iterative graph computation
a set of experiments
iterative graph computation with
set of experiments to
graph computation with block
of experiments to determine
computation with block updates
experiments to determine the
to determine the distribution
determine the distribution of
the distribution of messages
distribution of messages delivered
of messages delivered by
messages delivered by the
delivered by the chain
of the vldb endowment
by the chain vs
the chain vs delivered
chain vs delivered by
vs delivered by gossip
lateral error correction for
error correction for time
one transient failure affects
transient failure affects the
failure affects the wall
the runs are eight
runs are eight times
are eight times longer
eight times longer than
times longer than the
longer than the runs
than the runs before
both in total experiment
in total experiment time
total experiment time and
experiment time and time
time and time the
and time the victim
time the victim node
the victim node is
victim node is halted
show the number of
the number of messages
number of messages delivered
of messages delivered by
messages delivered by the
delivered by the chain
by the chain replication
the chain replication mechanism
chain replication mechanism and
replication mechanism and the
mechanism and the ones
and the ones delivered
the ones delivered by
ones delivered by the
delivered by the epidemics
for each of the
each of the nodes
of the nodes in
the nodes in a
nodes in a chain
again we omitted the
we omitted the head
concurrency control and recovery
omitted the head of
control and recovery in
the head of the
and recovery in database
head of the chain
recovery in database systems
of the chain node
the chain node because
chain node because its
node because its behavior
because its behavior is
its behavior is not
behavior is not representative
and in this experiment
in this experiment we
this experiment we have
experiment we have chains
we have chains of
have chains of length
exploiting gossip for self
management in scalable event
delivered updates by means
in scalable event notification
updates by means of
scalable event notification systems
by means of the
means of the gossip
of the gossip repair
the gossip repair mechanism
as the nodes get
the nodes get further
nodes get further away
get further away from
further away from the
away from the victim
from the victim node
more of the messages
of the messages were
the messages were delivered
messages were delivered by
were delivered by means
delivered by means of
by means of the
means of the chain
because the repair mechanism
the repair mechanism relinked
repair mechanism relinked the
mechanism relinked the chain
relinked the chain and
the chain and chain
chain and chain replication
and chain replication began
chain replication began to
the dynamics of viral
replication began to function
semantic integration of web
began to function normally
dynamics of viral marketing
integration of web services
of web services and
web services and peer
the speed with which
acm transactions on the
speed with which the
transactions on the web
with which the chain
which the chain is
the chain is restored
chain is restored depends
peer networks to achieve
is restored depends on
networks to achieve fault
restored depends on the
depends on the rate
on the rate of
the rate of the
rate of the fast
and on the responsiveness
on the responsiveness of
the responsiveness of the
responsiveness of the failure
of the failure detection
the failure detection mechanism
future development the current
development the current ssa
the current ssa implementation
current ssa implementation uses
ssa implementation uses gossip
implementation uses gossip in
uses gossip in situations
gossip in situations where
in situations where faster
situations where faster notifications
where faster notifications might
faster notifications might be
notifications might be helpful
we believe that when
believe that when a
that when a node
flexible protocol composition in
when a node fails
protocol composition in bast
a node fails or
node fails or joins
it would be useful
would be useful to
be useful to spread
useful to spread the
to spread the news
spread the news as
the news as quickly
news as quickly as
as quickly as possible
we realize that for
realize that for some
that for some particular
for some particular tasks
some particular tasks gossip
particular tasks gossip could
tasks gossip could be
gossip could be done
could be done more
be done more efficiently
we are therefore exploring
are therefore exploring the
therefore exploring the use
exploring the use of
the use of ip
use of ip multicast
of ip multicast for
self organizing live objects
ip multicast for dissemination
multicast for dissemination of
for dissemination of urgent
dissemination of urgent information
of urgent information as
urgent information as long
information as long as
as long as the
long as the physical
measurement and analysis of
as the physical nodes
and analysis of online
the physical nodes are
analysis of online social
physical nodes are not
of online social networks
nodes are not on
are not on a
not on a public
on a public network
a public network segment
in proceedings of the
th acm sigcomm conference
acm sigcomm conference on
sigcomm conference on internet
conference on internet measurement
we plan to include
plan to include support
to include support for
include support for the
support for the partitioning
for the partitioning of
the partitioning of the
partitioning of the services
of the services by
the services by means
services by means of
by means of registering
means of registering partition
of registering partition function
registering partition function handlers
partition function handlers with
function handlers with a
handlers with a global
with a global data
jms performance comparison for
performance comparison for publish
comparison for publish subscribe
for publish subscribe messaging
we have implemented only
have implemented only the
implemented only the server
fiorano software technologies pvt
only the server side
the server side load
server side load balancing
side load balancing scheme
we are considering ways
are considering ways to
considering ways to extend
ways to extend our
to extend our approach
extend our approach for
our approach for use
approach for use in
for use in settings
use in settings where
in settings where partitioning
settings where partitioning is
where partitioning is done
partitioning is done on
is done on the
done on the client
on the client side
side access to subservice
sampling from large graphs
access to subservice membership
to subservice membership information
subservice membership information is
membership information is needed
in proceedings of the
we are also developing
are also developing a
also developing a gui
developing a gui assisted
a gui assisted automated
th acm sigkdd international
gui assisted automated web
acm sigkdd international conference
assisted automated web service
sigkdd international conference on
automated web service deployment
international conference on knowledge
web service deployment tool
conference on knowledge discovery
on knowledge discovery and
knowledge discovery and data
discovery and data mining
focused on web service
leveraging collaboration of peer
on web service applications
developers could simply drop
could simply drop a
simply drop a wsdl
drop a wsdl service
peer and web services
a wsdl service description
and the system will
the system will generate
system will generate a
will generate a xml
generate a xml description
a xml description that
xml description that can
description that can be
that can be used
can be used later
be used later on
used later on to
later on to actually
on to actually deploy
to actually deploy the
actually deploy the service
deploy the service automatically
the service will be
service will be partitioned
and deployed on the
deployed on the fly
on the fly on
the fly on top
fly on top of
on top of the
based web service composition
top of the processing
web service composition with
of the processing nodes
service composition with jade
composition with jade and
with jade and jxta
scaling up to turn
up to turn the
to turn the ssa
turn the ssa into
the ssa into a
ssa into a full
into a full scale
a full scale platform
one of the immediate
of the immediate future
the immediate future challenges
don t settle for
immediate future challenges is
t settle for eventual
future challenges is the
challenges is the necessity
is the necessity of
the necessity of evaluating
necessity of evaluating a
scalable causal consistency for
of evaluating a full
causal consistency for wide
evaluating a full raps
a full raps of
full raps of racs
raps of racs deployment
area storage with cops
multiple partitioned and cloned
partitioned and cloned services
and cloned services running
cloned services running on
services running on our
running on our tightly
on our tightly coupled
our tightly coupled cluster
tightly coupled cluster would
based architecture for semanticweb
coupled cluster would lead
architecture for semanticweb service
rd acm symposium on
for semanticweb service automatic
cluster would lead to
semanticweb service automatic composition
acm symposium on operating
would lead to a
symposium on operating systems
lead to a series
on operating systems principles
to a series of
a series of other
series of other issues
of other issues that
other issues that should
issues that should be
that should be investigated
placement given a set
given a set of
a set of services
how to place the
to place the clones
place the clones on
the clones on physical
clones on physical nodes
on physical nodes in
physical nodes in order
nodes in order to
in order to satisfy
order to satisfy certain
to satisfy certain constraints
caching placement deciding if
placement deciding if some
deciding if some services
if some services would
some services would benefit
services would benefit if
would benefit if they
benefit if they are
if they are fitted
they are fitted with
are fitted with response
fitted with response caches
and ultimately placing the
ultimately placing the cache
placing the cache components
the cache components in
cache components in a
components in a smart
in a smart way
transactional storage for geo
location placing multiple service
placing multiple service clones
multiple service clones on
service clones on the
clones on the same
on the same physical
the same physical node
same physical node to
rd acm symposium on
physical node to exploit
acm symposium on operating
symposium on operating systems
node to exploit fast
on operating systems principles
to exploit fast ipc
and jong hoon ahnn
exploit fast ipc communication
fast ipc communication as
ipc communication as opposed
programming with live distributed
communication as opposed to
with live distributed objects
as opposed to network
opposed to network messages
to network messages if
network messages if the
messages if the benefits
if the benefits overweigh
the benefits overweigh the
benefits overweigh the cost
overweigh the cost incurred
the cost incurred by
cost incurred by resource
incurred by resource contention
by resource contention on
resource contention on the
contention on the shared
on the shared host
management tools developing tools
tools developing tools that
developing tools that monitor
tools that monitor service
that monitor service properties
monitor service properties such
service properties such as
properties such as response
such as response time
by restarting new clones
achieving reliability through distributed
reliability through distributed data
through distributed data flows
distributed data flows and
using vmm tricks virtual
data flows and recursive
flows and recursive delegation
vmm tricks virtual machines
tricks virtual machines can
virtual machines can be
machines can be used
can be used to
be used to migrate
used to migrate transparently
to migrate transparently a
migrate transparently a collection
transparently a collection of
a collection of services
collection of services on
of services on a
services on a different
on a different physical
a different physical processor
or provide isolation guarantees
provide isolation guarantees between
isolation guarantees between co
replicated systems fast as
systems fast as possible
the ssa can be
th usenix symposium on
ssa can be seen
usenix symposium on operating
can be seen as
symposium on operating systems
be seen as a
on operating systems design
seen as a platform
operating systems design and
as a platform that
systems design and implementation
a platform that leverages
platform that leverages tradeoffs
that leverages tradeoffs between
leverages tradeoffs between weaker
tradeoffs between weaker consistency
with a compensating gossip
a compensating gossip repair
compensating gossip repair mechanism
for higher availability and
higher availability and simplicity
this is an old
is an old idea
an old idea first
old idea first explored
idea first explored in
first explored in the
explored in the grapevine
and later in systems
later in systems like
in systems like bayou
which offer a broad
offer a broad operational
a broad operational spectrum
broad operational spectrum between
operational spectrum between strong
acid in the distributed
in the distributed database
the distributed database cases
changtao qu and wolfgang
qu and wolfgang nejdl
several database and distributed
database and distributed systems
and distributed systems take
distributed systems take advantage
systems take advantage of
take advantage of the
advantage of the same
of the same tradeoff
peer network with web
network with web services
for example allowing multiple
example allowing multiple updates
allowing multiple updates to
multiple updates to occur
combining acid and base
updates to occur simultaneously
acid and base in
and base in a
to occur simultaneously at
base in a distributed
in a distributed database
occur simultaneously at distinct
simultaneously at distinct replicas
at distinct replicas by
distinct replicas by specifying
replicas by specifying a
by specifying a maximum
specifying a maximum accepted
a maximum accepted deviation
maximum accepted deviation from
accepted deviation from strong
deviation from strong consistency
th usenix symposium on
usenix symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
a scalable and ontology
p infrastructure for semantic
infrastructure for semantic web
for semantic web services
tolerating a bounded number
a bounded number of
bounded number of consistency
number of consistency violations
of consistency violations to
consistency violations to increase
violations to increase concurrency
to increase concurrency of
increase concurrency of transactions
or replication according to
replication according to the
according to the need
our work on the
work on the ssa
on the ssa is
the ssa is the
ssa is the first
a shared log design
is the first to
shared log design for
the first to apply
log design for flash
first to apply such
design for flash clusters
a collaboration system architecture
to apply such thinking
apply such thinking to
such thinking to a
thinking to a cluster
to a cluster computing
a cluster computing environment
th usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
platform was designed to
was designed to provide
designed to provide a
to provide a cluster
provide a cluster based
a cluster based environment
cluster based environment for
based environment for scalable
environment for scalable internet
for scalable internet services
scalable internet services of
sonic performance test suite
internet services of the
services of the sort
of the sort used
the sort used in
sort used in web
used in web servers
caching proxies and transformation
proxies and transformation proxies
service components are controlled
components are controlled by
are controlled by a
controlled by a front
by a front end
a front end machine
front end machine that
end machine that acts
machine that acts as
that acts as a
acts as a request
as a request dispatcher
a request dispatcher and
request dispatcher and incorporates
dispatcher and incorporates the
and incorporates the load
incorporates the load balancing
the load balancing and
load balancing and restart
balancing and restart logics
end processes are detected
processes are detected to
are detected to have
detected to have failed
new processes are forked
processes are forked to
are forked to take
forked to take over
to take over the
take over the load
tacc workers can be
workers can be composed
can be composed to
be composed to address
composed to address more
to address more complex
address more complex tasks
tacc stands for transformation
ssa can be seen
can be seen as
be seen as revisiting
seen as revisiting these
as revisiting these architectural
revisiting these architectural ideas
these architectural ideas in
architectural ideas in conjunction
ideas in conjunction with
in conjunction with chain
conjunction with chain replication
have long supported clustered
long supported clustered architectures
and were the first
were the first systems
the first systems to
first systems to exploit
systems to exploit the
to exploit the style
exploit the style of
the style of partitioning
style of partitioning that
of partitioning that leads
partitioning that leads to
that leads to a
a demonstration of collaborative
leads to a raps
demonstration of collaborative web
to a raps of
of collaborative web services
a raps of racs
collaborative web services and
raps of racs solution
web services and peer
most database systems adhere
database systems adhere closely
systems adhere closely to
adhere closely to the
closely to the acid
to the acid model
at potentially high cost
potentially high cost in
high cost in terms
cost in terms of
in terms of reduced
terms of reduced availability
of reduced availability during
reduced availability during faults
discuss this problem in
p network based architecture
ultimately arguing for precisely
network based architecture for
arguing for precisely the
based architecture for web
for precisely the weak
architecture for web service
precisely the weak update
the weak update model
weak update model that
update model that we
model that we adopted
that we adopted here
application servers like the
servers like the j
offer persistent state support
persistent state support by
state support by wrapping
support by wrapping soft
by wrapping soft state
wrapping soft state business
soft state business logic
state business logic components
business logic components on
logic components on top
components on top of
on top of a
top of a relational
of a relational or
a relational or object
they also target large
scale highly available services
and hence we believe
hence we believe they
we believe they could
believe they could benefit
they could benefit from
could benefit from ssa
in a similar vein
framework makes it easy
makes it easy to
it easy to create
easy to create robust
to create robust scalable
create robust scalable services
ninja is arguably more
is arguably more flexible
arguably more flexible than
more flexible than application
flexible than application servers
than application servers in
application servers in that
servers in that it
in that it performs
that it performs connection
it performs connection management
performs connection management and
connection management and automatically
management and automatically partitions
and automatically partitions and
automatically partitions and replicates
partitions and replicates persistent
and replicates persistent state
but the framework takes
the framework takes a
framework takes a different
takes a different tiered
a different tiered approach
different tiered approach to
tiered approach to services
approach to services based
to services based on
services based on bases
active proxies and units
and represents shared state
represents shared state by
shared state by means
state by means of
by means of distributed
means of distributed data
of distributed data structures
conclusion our paper presents
our paper presents the
paper presents the scalable
presents the scalable services
the scalable services architecture
a new platform for
new platform for porting
platform for porting a
for porting a large
porting a large class
a large class of
large class of service
achieving serializability with low
oriented applications onto clusters
serializability with low latency
with low latency in
low latency in geodistributed
latency in geodistributed storage
in geodistributed storage systems
the ssa was designed
ssa was designed to
was designed to be
designed to be as
to be as simple
in proceedings of the
be as simple as
as simple as possible
and at the core
at the core uses
the core uses just
th acm symposium on
core uses just two
acm symposium on operating
uses just two primitive
symposium on operating systems
just two primitive mechanisms
on operating systems principles
tcp chains that support
chains that support a
that support a variant
support a variant of
a variant of chain
variant of chain replication
and gossip epidemics which
gossip epidemics which are
epidemics which are used
which are used to
are used to manage
used to manage configuration
to manage configuration data
manage configuration data and
configuration data and initiate
data and initiate repair
and initiate repair after
initiate repair after failures
with appropriate parameter settings
given a gossip rate
a gossip rate that
gossip rate that is
rate that is sufficiently
that is sufficiently fast
is sufficiently fast relative
sufficiently fast relative to
fast relative to the
relative to the update
to the update rates
the update rates seen
update rates seen in
rates seen in the
seen in the cluster
we find that the
find that the ssa
that the ssa can
the ssa can rapidly
ssa can rapidly and
can rapidly and automatically
rapidly and automatically reconfigure
and automatically reconfigure itself
automatically reconfigure itself after
reconfigure itself after a
itself after a failure
after a failure and
a failure and can
failure and can rapidly
and can rapidly repair
can rapidly repair data
rapidly repair data inconsistencies
repair data inconsistencies that
data inconsistencies that arise
inconsistencies that arise during
that arise during the
arise during the period
during the period when
the period when the
period when the cluster
when the cluster configuration
the cluster configuration was
cluster configuration was still
acm transactions on database
configuration was still disrupted
transactions on database systems
our goal is to
goal is to make
is to make the
to make the software
make the software available
the software available to
software available to a
available to a general
to a general user
a general user community
general user community in
acknowledgments the authors are
the authors are grateful
authors are grateful to
are grateful to the
grateful to the research
to the research team
the research team at
research team at afrl
team at afrl in
at afrl in rome
for their help in
their help in understanding
help in understanding the
in understanding the challenges
understanding the challenges of
the challenges of using
challenges of using service
of using service oriented
using service oriented architectures
service oriented architectures in
oriented architectures in large
architectures in large scale
in large scale settings
and to the researchers
to the researchers at
the researchers at amazon
for helping us understand
helping us understand the
us understand the architectures
understand the architectures employed
the architectures employed in
architectures employed in very
employed in very large
in very large data
very large data centers
an exercise in distributed
exercise in distributed computing
communications of the acm
shoring up persistent applications
in proceedings of the
research edition where the
edition where the academic
where the academic knights
the academic knights meet
academic knights meet the
knights meet the evil
meet the evil empire
the evil empire werner
acm sigmod international conference
evil empire werner vogels
sigmod international conference on
empire werner vogels the
international conference on management
werner vogels the rivalry
conference on management of
vogels the rivalry in
on management of data
the rivalry in the
rivalry in the operating
in the operating system
the operating system market
operating system market place
system market place has
market place has a
place has a severe
has a severe impact
a severe impact on
severe impact on the
impact on the academic
on the academic world
where in the old
in the old days
the old days intellection
old days intellection quality
days intellection quality and
intellection quality and careful
quality and careful deliberation
and careful deliberation would
careful deliberation would prevail
nowadays discussions about operating
discussions about operating systems
about operating systems research
operating systems research appear
systems research appear to
research appear to be
an architecture to support
appear to be more
architecture to support scalable
to be more like
to support scalable online
be more like the
support scalable online personalization
more like the battlefield
scalable online personalization in
like the battlefield of
online personalization in the
the battlefield of a
personalization in the web
battlefield of a holy
of a holy war
the international journal on
international journal on very
with objectivity as its
journal on very large
objectivity as its main
on very large data
as its main victim
very large data bases
we have tried to
have tried to side
tried to side step
to side step the
side step the emotional
step the emotional current
and select an operating
select an operating system
an operating system that
operating system that could
system that could bring
that could bring our
could bring our research
bring our research into
our research into the
research into the next
into the next century
based on objective technical
on objective technical and
objective technical and organizational
technical and organizational criteria
this paper describes how
paper describes how this
describes how this evaluation
how this evaluation lead
this evaluation lead to
evaluation lead to the
lead to the insight
to the insight that
the insight that microsoft
insight that microsoft s
that microsoft s windows
microsoft s windows nt
s windows nt is
windows nt is the
nt is the operating
is the operating system
the operating system that
operating system that is
system that is best
that is best prepared
is best prepared for
best prepared for the
prepared for the future
introduction until recently there
until recently there was
recently there was no
there was no doubt
was no doubt in
no doubt in academia
doubt in academia which
in academia which operating
academia which operating system
which operating system to
operating system to use
system to use for
to use for systems
use for systems research
whether it was a
it was a bsd
was a bsd or
a bsd or system
bsd or system v
or system v derivative
was the predominant choice
which had its roots
had its roots in
its roots in research
was used since its
used since its inception
since its inception to
its inception to investigate
inception to investigate fundamental
to investigate fundamental system
investigate fundamental system research
and the accumulated knowledge
the accumulated knowledge in
accumulated knowledge in academia
knowledge in academia about
in academia about its
academia about its internals
about its internals and
its internals and operations
internals and operations was
and operations was significant
other available operating systems
available operating systems such
operating systems such as
systems such as vms
such as vms and
as vms and mvs
epidemic algorithms for replicated
algorithms for replicated database
for replicated database maintenance
had their roots in
their roots in the
roots in the commercial
in the commercial world
in proceedings of the
the commercial world and
proceedings of the sixth
commercial world and knowledge
of the sixth annual
world and knowledge about
the sixth annual acm
and knowledge about these
sixth annual acm symposium
knowledge about these systems
annual acm symposium on
about these systems never
acm symposium on principles
these systems never accumulated
symposium on principles of
systems never accumulated to
on principles of distributed
never accumulated to the
principles of distributed computing
efficient optimistic concurrency control
accumulated to the critical
optimistic concurrency control using
to the critical mass
concurrency control using loosely
the critical mass were
control using loosely synchronized
critical mass were these
using loosely synchronized clocks
mass were these systems
were these systems could
these systems could be
systems could be considered
could be considered for
be considered for widespread
considered for widespread research
for widespread research tasks
although new research operating
new research operating systems
research operating systems have
operating systems have been
systems have been developed
none have found the
have found the following
found the following that
the following that the
following that the established
that the established unix
the established unix s
established unix s received
freebsd and others continue
and others continue to
others continue to dominate
continue to dominate the
to dominate the academic
dominate the academic landscape
but slowly but surely
slowly but surely windows
but surely windows nt
surely windows nt is
windows nt is now
nt is now entering
is now entering the
now entering the academic
entering the academic world
the academic world as
academic world as a
world as a viable
alternative platform for research
although academia looked with
academia looked with fascination
looked with fascination at
with fascination at dave
fascination at dave cutler
at dave cutler s
dave cutler s attempt
cutler s attempt to
s attempt to build
attempt to build a
to build a new
build a new operating
a new operating system
new operating system from
operating system from the
system from the ground
from the ground up
a scalable system for
scalable system for consistently
system for consistently caching
for consistently caching dynamic
consistently caching dynamic web
caching dynamic web data
support for data sharing
for data sharing among
data sharing among mobile
sharing among mobile users
all expected that windows
in ieee workshop on
expected that windows nt
ieee workshop on mobile
workshop on mobile computing
that windows nt would
on mobile computing systems
windows nt would go
nt would go the
would go the same
go the same way
the same way as
same way as the
way as the other
as the other commercially
the other commercially designed
other commercially designed operating
commercially designed operating systems
designed operating systems before
operating systems before it
systems before it and
before it and remain
it and remain in
and remain in the
remain in the dark
in the dark corner
the dark corner from
dark corner from a
corner from a research
from a research use
a research use point
research use point of
use point of view
about four years ago
not long after the
long after the final
after the final major
the final major release
final major release of
major release of academic
release of academic version
of academic version of
academic version of the
version of the unix
of the unix operating
the unix operating system
a scalable web cache
scalable web cache consistency
web cache consistency architecture
sigcomm computer communications review
the farewell of the
farewell of the berkeley
of the berkeley systems
the berkeley systems werner
berkeley systems werner vogels
systems werner vogels is
werner vogels is a
vogels is a research
is a research scientist
a research scientist at
research scientist at the
scientist at the department
at the department of
the department of computer
department of computer science
of computer science of
computer science of cornell
science of cornell university
his research targets high
availability in distributed systems
with a particular focus
a particular focus on
particular focus on enterprise
focus on enterprise cluster
on enterprise cluster systems
president of reliable network
of reliable network solutions
based cache management for
cache management for dynamic
management for dynamic web
for dynamic web content
which specializes in building
specializes in building solutions
in building solutions for
building solutions for very
solutions for very large
scale reliable distributed systems
usenix windows nt symposium
his personal homepage is
personal homepage is at
homepage is at http
alternative architectures and protocols
architectures and protocols for
and protocols for providing
protocols for providing strong
based scalable network services
for providing strong consistency
providing strong consistency in
strong consistency in dynamic
consistency in dynamic web
in dynamic web applications
world wide web journal
proceedings of the sixteenth
of the sixteenth acm
the sixteenth acm symposium
sixteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
group and the early
and the early demise
the early demise of
early demise of mach
demise of mach as
of mach as the
mach as the last
as the last of
the last of the
last of the research
of the research operating
the research operating systems
the operating system research
operating system research world
system research world was
research world was at
world was at a
was at a crossroads
intel based personal computers
based personal computers were
personal computers were becoming
computers were becoming ubiquitous
and a myriad of
a myriad of unix
myriad of unix operating
of unix operating systems
unix operating systems was
operating systems was available
systems was available for
was available for this
available for this platform
eventually many moved to
many moved to use
moved to use linux
a popular architectural clone
popular architectural clone of
architectural clone of the
clone of the traditional
of the traditional unix
at the computer science
the computer science department
computer science department at
science department at cornell
department at cornell university
at cornell university we
cornell university we made
university we made the
we made the decision
made the decision to
the decision to conduct
decision to conduct our
to conduct our research
conduct our research on
our research on windows
research on windows nt
by that time we
that time we had
time we had learned
we had learned enough
had learned enough from
learned enough from the
enough from the early
cache coherence in distributed
from the early design
coherence in distributed systems
the early design of
early design of windows
design of windows nt
of windows nt to
windows nt to realize
nt to realize that
to realize that it
realize that it was
that it was a
it was a major
was a major step
a major step forward
major step forward in
step forward in operating
forward in operating system
in operating system design
it would provide us
would provide us with
provide us with a
us with a platform
with a platform on
a platform on which
platform on which we
on which we could
which we could perform
we could perform research
could perform research more
perform research more effectively
research more effectively and
more effectively and it
effectively and it would
and it would allows
it would allows us
would allows us to
allows us to focus
us to focus on
to focus on the
focus on the future
on the future directions
the future directions without
future directions without having
directions without having to
without having to worry
having to worry whether
to worry whether the
worry whether the operating
whether the operating system
the operating system was
operating system was capable
system was capable of
was capable of supporting
capable of supporting innovation
by now our complete
the ninja architecture for
now our complete educational
a global cache coherent
ninja architecture for robust
global cache coherent file
our complete educational operation
cache coherent file system
architecture for robust internet
complete educational operation and
educational operation and the
operation and the majority
and the majority of
scale systems and services
the majority of our
majority of our research
of our research projects
our research projects have
research projects have switched
projects have switched to
have switched to using
switched to using windows
to using windows nt
as it now officially
it now officially has
now officially has been
officially has been christened
a distributed memory object
distributed memory object caching
memory object caching system
the ride has been
ride has been rocky
has been rocky and
been rocky and fascinating
in this article i
this article i want
article i want to
i want to share
want to share some
to share some of
share some of the
some of the reasoning
of the reasoning behind
the reasoning behind our
reasoning behind our choice
behind our choice for
our choice for windows
choice for windows nt
for windows nt and
windows nt and to
nt and to share
and to share some
to share some our
share some our experiences
some our experiences with
our experiences with windows
experiences with windows nt
with windows nt as
windows nt as a
nt as a research
as a research platform
os research as religion
research as religion the
as religion the biggest
religion the biggest hurdle
the biggest hurdle in
biggest hurdle in starting
hurdle in starting research
in starting research on
starting research on windows
research on windows nt
on windows nt was
windows nt was not
nt was not technical
spatial gossip and resource
gossip and resource location
and resource location protocols
distributed data structures for
data structures for internet
structures for internet service
for internet service construction
it was to overcome
in proceedings of the
was to overcome the
proceedings of the thirty
to overcome the skepticism
in proceedings of the
overcome the skepticism of
the skepticism of our
third annual acm symposium
skepticism of our colleagues
annual acm symposium on
of our colleagues who
th conference on symposium
acm symposium on theory
conference on symposium on
symposium on theory of
on symposium on operating
on theory of computing
our colleagues who were
symposium on operating system
colleagues who were convinced
on operating system design
who were convinced that
were convinced that it
convinced that it would
that it would not
it would not be
would not be possible
not be possible to
be possible to use
possible to use windows
to use windows nt
use windows nt as
windows nt as a
nt as a good
as a good platform
a good platform for
good platform for research
the predictions were fascinating
we would turn into
would turn into a
turn into a bug
microsoft would sue the
would sue the department
sue the department for
the department for every
department for every technical
for every technical publication
microsoft would hide the
would hide the pieces
hide the pieces of
the pieces of buggy
pieces of buggy code
of buggy code from
buggy code from us
code from us or
from us or bill
us or bill gates
or bill gates would
bill gates would personally
gates would personally tell
would personally tell us
personally tell us where
tell us where and
us where and how
where and how we
and how we should
how we should do
we should do our
should do our research
a technique for increasing
technique for increasing concurrency
for increasing concurrency in
increasing concurrency in a
concurrency in a replicated
in a replicated system
the operating systems research
acm transactions on database
transactions on database systems
operating systems research community
systems research community has
research community has not
community has not remained
has not remained untouched
not remained untouched by
remained untouched by the
untouched by the market
by the market place
the market place rivalry
market place rivalry between
place rivalry between microsoft
rivalry between microsoft and
between microsoft and the
microsoft and the group
and the group lead
the group lead by
group lead by sun
lead by sun microsystems
it is even more
is even more unfortunate
even more unfortunate that
more unfortunate that the
unfortunate that the positions
that the positions taken
the positions taken are
positions taken are not
taken are not based
are not based on
not based on intellectual
based on intellectual deliberation
on intellectual deliberation but
intellectual deliberation but purely
deliberation but purely on
but purely on emotional
purely on emotional grounds
many see microsoft operating
see microsoft operating systems
microsoft operating systems as
operating systems as the
systems as the evil
as the evil empire
out to squash every
to squash every attempt
squash every attempt at
every attempt at innovation
and working with them
working with them is
with them is seen
them is seen as
is seen as collaboration
seen as collaboration with
as collaboration with the
collaboration with the enemy
with the enemy of
the enemy of free
enemy of free academic
of free academic speech
the pros and cons
pros and cons are
and cons are often
cons are often discussed
are often discussed with
often discussed with a
discussed with a righteous
with a righteous zeal
a righteous zeal that
righteous zeal that is
zeal that is frightening
our own experiences with
own experiences with microsoft
adaptive distributed data management
experiences with microsoft can
distributed data management with
with microsoft can only
data management with weak
microsoft can only be
management with weak consistent
can only be described
with weak consistent replicated
only be described as
weak consistent replicated data
be described as extremely
described as extremely positive
in proceedings of the
never before have we
before have we had
have we had such
we had such a
had such a positive
such a positive relation
a positive relation with
positive relation with a
relation with a vendor
without any pressure from
any pressure from their
pressure from their side
acm symposium on applied
symposium on applied computing
we can only conclude
can only conclude that
only conclude that the
conclude that the reasons
that the reasons for
the reasons for the
reasons for the controversy
for the controversy must
tier database caching for
the controversy must be
database caching for e
controversy must be found
must be found in
be found in a
found in a sort
in a sort of
a sort of traditional
in international conference on
sort of traditional emotional
international conference on management
conference on management of
of traditional emotional bonding
on management of data
traditional emotional bonding of
emotional bonding of academia
bonding of academia with
of academia with the
academia with the underdog
with the underdog and
the underdog and that
underdog and that no
and that no real
that no real experiences
no real experiences drive
real experiences drive the
experiences drive the discussion
gaining knowledge the foremost
knowledge the foremost reasons
the foremost reasons why
foremost reasons why unix
reasons why unix was
why unix was such
unix was such a
was such a powerhouse
such a powerhouse in
a powerhouse in operating
powerhouse in operating system
in operating system research
operating system research was
system research was the
research was the great
was the great amount
the great amount of
great amount of knowledge
amount of knowledge accumulated
of knowledge accumulated over
knowledge accumulated over the
accumulated over the years
over the years about
the years about the
years about the internal
about the internal operation
the internal operation of
internal operation of the
operation of the operating
of the operating system
aware adaptable web services
in proceedings of the
many of us had
of us had become
us had become gurus
had become gurus about
become gurus about some
gurus about some part
about some part of
some part of the
th international world wide
part of the os
international world wide web
of the os kernel
world wide web conference
the os kernel and
wide web conference on
os kernel and could
web conference on alternate
kernel and could recite
conference on alternate track
and could recite the
on alternate track papers
could recite the fields
alternate track papers and
recite the fields of
track papers and posters
the fields of an
fields of an i
node structure at late
structure at late night
at late night meetings
late night meetings or
night meetings or discuss
meetings or discuss which
or discuss which data
discuss which data structures
which data structures to
data structures to modify
consistent and scalable cache
structures to modify to
and scalable cache replication
to modify to add
scalable cache replication for
modify to add a
cache replication for multi
to add a new
add a new protocol
a new protocol at
new protocol at runtime
protocol at runtime over
at runtime over an
runtime over an early
over an early morning
an early morning cappuccino
many of us were
of us were and
us were and still
were and still are
and still are afraid
still are afraid to
are afraid to leave
afraid to leave this
to leave this bastion
leave this bastion of
this bastion of safety
bastion of safety behind
of safety behind and
safety behind and trade
behind and trade it
and trade it in
trade it in for
it in for working
in for working on
for working on an
working on an operating
on an operating system
an operating system that
operating system that at
system that at first
that at first sight
at first sight had
first sight had nothing
sight had nothing in
had nothing in common
nothing in common with
in common with our
common with our beloved
with our beloved unix
and our annotated version
our annotated version of
annotated version of the
version of the unix
of the unix version
wouldn t be of
t be of much
be of much help
of much help any
much help any more
help any more either
consistent and scalable caching
and scalable caching in
any more either it
scalable caching in multitier
more either it took
caching in multitier architectures
either it took more
it took more then
took more then a
more then a year
the international journal on
then a year of
international journal on very
a year of immersion
journal on very large
year of immersion in
on very large data
of immersion in the
very large data bases
immersion in the technology
in the technology to
the technology to get
technology to get a
to get a level
get a level where
a level where i
level where i felt
where i felt confident
i felt confident again
felt confident again to
confident again to direct
again to direct others
to direct others in
direct others in our
others in our research
in our research group
together with the overall
with the overall organizational
the overall organizational issues
overall organizational issues i
organizational issues i think
issues i think we
i think we lost
think we lost one
we lost one and
profiles for the situated
lost one and a
for the situated web
one and a half
and a half year
a half year worth
half year worth of
in proceedings of the
year worth of research
proceedings of the eleventh
worth of research time
of the eleventh international
of research time to
the eleventh international conference
research time to make
eleventh international conference on
time to make the
international conference on world
to make the switch
conference on world wide
make the switch in
on world wide web
the switch in the
switch in the most
in the most fundamental
the most fundamental way
others are making the
are making the switch
making the switch more
the switch more gradually
switch more gradually and
more gradually and are
gradually and are experiencing
and are experiencing a
are experiencing a more
experiencing a more smooth
a more smooth transition
all operation systems are
operation systems are created
systems are created equal
are created equal our
created equal our experiences
equal our experiences with
our experiences with switching
experiences with switching to
with switching to windows
switching to windows nt
to windows nt have
windows nt have made
nt have made us
have made us somewhat
made us somewhat more
us somewhat more philosophical
somewhat more philosophical about
more philosophical about the
philosophical about the nature
about the nature of
the nature of operation
nature of operation systems
the most fundamental observation
most fundamental observation is
fundamental observation is that
when stripped to their
stripped to their core
all operating systems are
operating systems are equal
the functionality of the
functionality of the windows
of the windows nt
the windows nt kernel
windows nt kernel is
nt kernel is just
kernel is just as
van renesse and f
is just as all
just as all other
as all other kernels
improving application throughput with
application throughput with enterprise
throughput with enterprise javabeans
with enterprise javabeans caching
it abstracts the hardware
abstracts the hardware in
the hardware in the
hardware in the usual
in the usual sense
in international conference on
chain replication for supporting
international conference on distributed
replication for supporting high
conference on distributed computing
for supporting high throughput
on distributed computing systems
supporting high throughput and
high throughput and availability
process and threads hide
and threads hide the
threads hide the cpu
hide the cpu complexity
in sixth symposium on
sixth symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
file systems and files
systems and files hide
and files hide the
files hide the storage
hide the storage devices
protocols hide the network
shared memory and messages
memory and messages are
and messages are used
messages are used to
are used to allow
used to allow sharing
to allow sharing of
allow sharing of resources
what we often call
we often call operating
often call operating systems
call operating systems has
operating systems has nothing
systems has nothing to
has nothing to do
nothing to do with
to do with the
do with the real
with the real core
the real core of
real core of the
core of the system
unix for most of
for most of us
most of us is
of us is a
us is a collection
is a collection of
a collection of shell
collection of shell commands
of shell commands and
shell commands and development
commands and development libraries
david korn s uwin
currency serializability for middle
tier caching and replication
in international conference on
international conference on management
conference on management of
on management of data
and softway s interix
both show that you
show that you can
that you can give
you can give users
can give users and
give users and developers
users and developers a
enabling scalable online personalization
scalable online personalization on
online personalization on the
personalization on the web
in proceedings of the
nd acm conference on
unix experience including x
acm conference on electronic
conference on electronic commerce
while running on an
running on an windows
on an windows nt
an windows nt kernel
a ppendix we now
windows nt for most
ppendix we now prove
nt for most of
we now prove theorem
for most of us
most of us is
of us is the
us is the windows
is the windows explorer
the windows explorer and
windows explorer and point
and according to microsoft
according to microsoft it
cache with unbounded cache
to microsoft it includes
with unbounded cache size
microsoft it includes a
unbounded cache size and
it includes a web
cache size and unbounded
includes a web browser
size and unbounded dependency
and unbounded dependency lists
unbounded dependency lists implements
dependency lists implements cache
although i have not
i have not seen
have not seen a
not seen a complete
seen a complete re
since we assume that
implementation of the explorer
we assume that the
of the explorer for
assume that the transactional
the explorer for unix
that the transactional db
the transactional db is
transactional db is serializable
the operations in an
operations in an execution
in an execution of
an execution of update
execution of update transactions
compatible libraries from mainsoft
of update transactions update
update transactions update can
transactions update can be
update can be serialized
can be serialized as
be serialized as some
serialized as some serial
as some serial execution
used in the port
in the port of
the port of internet
the next claim trivially
port of internet explorer
next claim trivially follows
of internet explorer show
claim trivially follows from
internet explorer show that
trivially follows from the
explorer show that you
follows from the definition
show that you do
from the definition of
that you do not
the definition of the
you do not need
definition of the database
do not need a
of the database dependency
not need a windows
the database dependency list
need a windows nt
database dependency list specification
a windows nt kernel
windows nt kernel to
nt kernel to get
an architecture for well
kernel to get to
to get to the
get to the same
to the same user
the same user experience
many see the rich
see the rich win
if is a serialization
is a serialization of
a serialization of the
in symposium on operating
serialization of the update
symposium on operating systems
of the update transactions
on operating systems principles
the update transactions of
update transactions of an
transactions of an execution
programming interface as the
of an execution update
interface as the native
as the native programming
the native programming model
native programming model for
programming model for windows
model for windows nt
at every step in
and although most windows
although most windows applications
most windows applications are
windows applications are designed
the version dependencies of
applications are designed using
version dependencies of every
are designed using this
dependencies of every object
designed using this interface
of every object match
every object match those
object match those stored
match those stored in
those stored in its
stored in its dependency
it is not the
in its dependency list
is not the windows
not the windows nt
the windows nt kernel
windows nt kernel interface
almost no applications are
no applications are built
applications are built using
are built using the
built using the kernel
using the kernel interface
we first describe a
first describe a routine
describe a routine for
a routine for placing
routine for placing a
for placing a read
and you would have
you would have a
would have a hard
have a hard time
a hard time finding
only transaction from a
hard time finding the
transaction from a cache
time finding the complete
from a cache server
finding the complete documentation
a cache server in
the complete documentation for
cache server in a
complete documentation for all
server in a serialization
documentation for all the
in a serialization of
for all the system
a serialization of a
all the system calls
serialization of a subset
of a subset of
describing windows nt as
windows nt as a
nt as a micro
to form a serialization
form a serialization of
a serialization of both
serialization of both the
of both the update
both the update transaction
the update transaction and
update transaction and the
the costs and limits
transaction and the read
costs and limits of
and limits of availability
limits of availability for
of availability for replicated
as the kernel is
availability for replicated services
the kernel is certainly
kernel is certainly not
is certainly not small
in proceedings of the
proceedings of the eighteenth
of the eighteenth acm
but it is does
the eighteenth acm symposium
eighteenth acm symposium on
it is does describe
acm symposium on operating
symposium on operating systems
is does describe the
on operating systems principles
does describe the abstraction
describe the abstraction correctly
the abstraction correctly in
abstraction correctly in which
correctly in which the
in which the kernel
which the kernel provides
the kernel provides base
kernel provides base services
provides base services and
base services and the
services and the specific
and the specific application
the specific application context
specific application context is
application context is provided
context is provided through
is provided through subsystem
provided through subsystem servers
through subsystem servers or
subsystem servers or personalities
is one of the
one of the personalities
of the personalities running
the personalities running on
personalities running on top
running on top of
on top of windows
top of windows nt
performing this permutation is
this permutation is one
permutation is one step
is one step of
one step of the
step of the routine
and posix are others
posix are others delivered
we repeat this step
are others delivered by
repeat this step forming
others delivered by microsoft
this step forming a
step forming a series
forming a series of
a series of permutations
one can run windows
can run windows nt
run windows nt without
each permutation is a
windows nt without these
permutation is a serialization
nt without these standard
is a serialization of
without these standard personalities
a serialization of update
these standard personalities and
standard personalities and build
personalities and build your
and build your own
and each permutes a
each permutes a range
design and evaluation of
what is an operating
permutes a range of
is an operating system
and evaluation of a
a range of the
evaluation of a conitbased
range of the transactions
of a conitbased continuous
of the transactions with
a conitbased continuous consistency
the transactions with respect
conitbased continuous consistency model
this question seems to
continuous consistency model for
transactions with respect to
consistency model for replicated
question seems to be
model for replicated services
with respect to the
seems to be on
respect to the previous
to be on the
to the previous step
be on the mind
on the mind of
acm transactions on computer
the mind of many
transactions on computer systems
mind of many people
of many people these
many people these days
in each step the
each step the right
step the right end
the right end of
right end of the
infused by the microsoft
end of the range
by the microsoft trial
of the range is
the range is earlier
range is earlier than
is earlier than in
earlier than in the
academics in general have
than in the previous
in the previous step
in general have taken
general have taken a
have taken a very
taken a very narrow
a very narrow view
as one or more
very narrow view of
one or more of
narrow view of what
or more of the
view of what an
more of the objects
of what an operating
of the objects is
what an operating system
the objects is closer
an operating system is
objects is closer to
is closer to the
closer to the value
to the value read
the value read by
value read by t
david faber at microsoft
faber at microsoft trial
at microsoft trial defined
eventually we therefore reach
microsoft trial defined an
we therefore reach a
trial defined an operating
therefore reach a permutation
defined an operating system
reach a permutation where
an operating system as
a permutation where at
operating system as the
permutation where at the
system as the software
where at the chosen
as the software that
at the chosen time
the software that controls
the chosen time all
software that controls the
chosen time all read
that controls the execution
time all read objects
controls the execution of
all read objects are
the execution of programs
read objects are at
execution of programs on
objects are at their
of programs on computer
are at their correct
programs on computer systems
at their correct versions
on computer systems and
computer systems and may
systems and may provide
and may provide low
we place t there
place t there to
t there to obtain
level services such as
there to obtain the
services such as resource
to obtain the desired
such as resource allocation
obtain the desired serialization
the desired serialization of
desired serialization of the
serialization of the update
of the update transactions
the update transactions and
update transactions and t
output control in a
control in a form
in a form which
a form which is
permutation routine let be
form which is sufficiently
routine let be an
which is sufficiently simple
let be an execution
is sufficiently simple and
be an execution of
sufficiently simple and general
an execution of the
simple and general so
execution of the t
and general so that
general so that these
so that these services
that these services are
these services are broadly
services are broadly useful
are broadly useful to
broadly useful to software
useful to software developers
and denote by update
denote by update the
by update the projection
update the projection of
the projection of on
projection of on the
of on the set
on the set of
the set of database
set of database update
of database update transactions
transaction t reads objects
t reads objects o
in research community this
research community this strict
community this strict distinction
this strict distinction serves
strict distinction serves to
distinction serves to distinguish
serves to distinguish the
to distinguish the real
distinguish the real men
the real men from
real men from the
men from the boys
researchers and hackers that
and hackers that work
hackers that work in
that work in the
work in the area
in the area defined
the area defined by
area defined by this
defined by this narrow
on with versions v
by this narrow definition
this narrow definition of
narrow definition of operating
definition of operating systems
consider themselves part of
themselves part of the
part of the select
of the select circle
the select circle of
select circle of people
circle of people working
of people working on
people working on the
working on the core
on the core of
the core of the
core of the systems
of the systems area
the systems area of
systems area of computer
area of computer science
once you are in
you are in this
are in this circle
take any serialization of
in this circle you
any serialization of update
this circle you will
circle you will become
one exists according to
you will become part
exists according to claim
will become part of
become part of the
part of the secret
of the secret society
the secret society that
and consider the first
secret society that practices
consider the first time
society that practices the
the first time when
that practices the black
first time when all
practices the black art
time when all the
the black art of
when all the objects
black art of os
all the objects the
art of os research
the objects the transaction
of os research and
objects the transaction reads
os research and will
the transaction reads are
research and will start
transaction reads are at
and will start to
reads are at a
will start to regard
are at a version
start to regard any
at a version at
to regard any other
a version at least
regard any other activity
version at least as
any other activity of
at least as large
other activity of systems
least as large as
activity of systems development
as large as the
of systems development as
large as the versions
systems development as irrelevant
as the versions that
development as irrelevant to
the versions that t
as irrelevant to the
versions that t reads
irrelevant to the future
to the future of
the future of computer
future of computer science
at this time at
this time at least
time at least one
at least one object
for a long time
least one object read
a long time the
one object read by
long time the line
object read by t
time the line was
the line was drawn
line was drawn at
was drawn at the
drawn at the kernel
the last written according
last written according to
has the correct version
and one could only
one could only consider
but others might not
could only consider himself
only consider himself a
consider himself a true
himself a true os
assume without loss of
a true os researcher
without loss of generality
true os researcher after
loss of generality that
os researcher after having
of generality that the
researcher after having developed
generality that the last
after having developed at
that the last version
having developed at least
the last version written
developed at least two
last version written is
at least two device
version written is vn
least two device drivers
written is vn of
two device drivers and
is vn of object
device drivers and hacked
vn of object on
drivers and hacked on
of object on at
and hacked on the
object on at step
hacked on the terminal
on at step t
on the terminal driver
at step t of
the terminal driver of
terminal driver of the
driver of the bsd
denote by t the
by t the latest
t the latest time
the latest time at
latest time at which
time at which a
at which a wrong
which a wrong version
not the one read
the one read by
one read by t
in modern operating systems
modern operating systems such
operating systems such as
systems such as windows
such as windows nt
and assume wlog it
assume wlog it is
the notion of where
wlog it is version
notion of where exactly
it is version vn
of where exactly operating
where exactly operating systems
exactly operating systems services
operating systems services are
systems services are located
services are located is
are located is not
located is not that
k of object on
is not that simple
not that simple any
that simple any more
fundamental services are split
rather than the desired
services are split between
than the desired version
are split between kernel
the desired version vn
split between kernel and
between kernel and user
kernel and user space
and user space in
user space in attempts
space in attempts to
in attempts to optimise
attempts to optimise their
to optimise their efficiency
optimise their efficiency and
their efficiency and avoid
efficiency and avoid uncontrolled
and avoid uncontrolled growth
avoid uncontrolled growth of
we now describe a
uncontrolled growth of kernel
now describe a single
growth of kernel services
describe a single step
a single step of
single step of the
step of the routine
the pervasiveness of distributed
pervasiveness of distributed services
consider the transactions between
of distributed services in
the transactions between t
distributed services in modern
transactions between t and
services in modern systems
between t and t
in modern systems can
modern systems can be
systems can be considered
can be considered a
be considered a threat
considered a threat to
a threat to the
threat to the traditional
to the traditional notion
the traditional notion of
traditional notion of operating
notion of operating systems
divide these transactions into
these transactions into three
transactions into three sets
many support services are
support services are required
services are required to
are required to make
required to make distributed
transactions dependent on the
to make distributed systems
dependent on the transaction
make distributed systems work
on the transaction at
distributed systems work efficiently
the transaction at t
systems work efficiently and
work efficiently and effectively
efficiently and effectively and
and effectively and these
effectively and these services
such as security and
as security and directory
security and directory services
and directory services or
directory services or distributed
services or distributed object
transactions on which t
or distributed object support
on which t is
distributed object support and
which t is dependent
object support and cluster
support and cluster management
are not part of
not part of a
part of a traditional
of a traditional view
a traditional view of
traditional view of operating
view of operating systems
transactions that do not
but they are essential
that do not belong
they are essential to
do not belong to
are essential to the
not belong to either
essential to the operation
belong to either group
to the operation of
the operation of modern
operation of modern operating
of modern operating systems
the following lemma states
following lemma states that
lemma states that there
states that there is
this results in that
that there is no
results in that an
there is no dependency
in that an operating
is no dependency among
that an operating system
no dependency among objects
an operating system no
dependency among objects in
operating system no longer
among objects in sets
system no longer is
no longer is a
longer is a simple
is a simple division
a simple division between
simple division between kernel
division between kernel and
between kernel and user
kernel and user space
and hence there is
but consist of a
hence there is no
consist of a myriad
there is no intersection
of a myriad of
is no intersection between
a myriad of services
no intersection between the
intersection between the sets
of which some are
which some are kernilized
some are local and
are local and others
local and others are
and others are remote
operating systems that address
systems that address the
that address the needs
address the needs of
the needs of current
needs of current and
of current and future
current and future clients
and future clients and
future clients and informatik
clients and informatik informatique
if they were dependent
then version vn of
version vn of object
vn of object on
of object on depends
object on depends on
on depends on version
depends on version vn
k of object on
and this dependency is
this dependency is reflected
dependency is reflected in
is reflected in their
reflected in their t
operating systems servers no
systems servers no longer
servers no longer span
no longer span a
longer span a single
span a single computer
because they are unbounded
a single computer and
single computer and they
computer and they abstract
and they abstract services
they abstract services away
abstract services away from
services away from physical
away from physical nodes
transaction t has read
from physical nodes allowing
t has read version
physical nodes allowing user
has read version vn
nodes allowing user to
allowing user to be
user to be part
to be part of
be part of a
part of a larger
potential global operating environment
which is older than
is older than vn
will the real dinosaur
the real dinosaur please
real dinosaur please come
dinosaur please come forward
until the spring of
the read of the
read of the stale
of the stale version
the stale version vn
would have been detected
have been detected by
we were deeply committed
been detected by t
were deeply committed to
deeply committed to sunos
cache and the transaction
and the transaction would
and other bsd derivatives
the transaction would have
transaction would have been
would have been aborted
therefore the assumption is
the assumption is wrong
at that moment its
that moment its vendor
moment its vendor was
its vendor was discontinuing
and the sets are
vendor was discontinuing the
the sets are indeed
was discontinuing the operating
sets are indeed independent
discontinuing the operating system
live network streaming with
network streaming with utilities
streaming with utilities and
with utilities and cost
and had designated solaris
utilities and cost ymir
and cost ymir vigfusson
which had its root
had its root in
its root in at
perhaps an empty set
t s system v
is unrelated to sets
s system v as
system v as the
v as the successor
this event forced us
event forced us to
forced us to take
us to take a
we therefore switch sets
to take a step
take a step back
a step back and
step back and evaluate
back and evaluate our
and evaluate our research
evaluate our research directions
our research directions and
research directions and our
directions and our expectations
and our expectations with
our expectations with respect
expectations with respect to
with respect to the
respect to the operating
to the operating systems
the operating systems to
operating systems to use
maintaining a serialization of
freedman school of computer
a serialization of update
school of computer science
if one issue in
one issue in our
issue in our discussions
in our discussions was
our discussions was dominant
consider the following serialization
it was the fact
iceland of computer science
was the fact that
the fact that most
fact that most of
xi denotes a transaction
that most of the
denotes a transaction x
most of the operating
a transaction x in
of the operating systems
transaction x in set
the operating systems we
x in set i
operating systems we were
systems we were looking
we were looking at
were looking at were
looking at were actually
at were actually very
were actually very old
usa school of electronics
actually very old fashioned
school of electronics engineering
of electronics engineering and
electronics engineering and computer
engineering and computer science
cache consistency we proceed
in structure and in
consistency we proceed to
structure and in implementation
we proceed to prove
proceed to prove theorem
most of these operating
of these operating systems
these operating systems had
operating systems had their
systems had their conception
had their conception in
their conception in the
let be an execution
be an execution of
an execution of the
execution of the t
and denote by update
denote by update the
s and did not
by update the projection
and did not change
update the projection of
did not change much
the projection of on
not change much in
projection of on the
change much in structure
of on the set
much in structure since
on the set of
in structure since then
the set of database
set of database update
of database update transactions
linux could be seen
could be seen as
be seen as an
seen as an exception
as an exception since
an exception since it
exception since it was
since it was developed
it was developed in
was developed in the
developed in the second
in the second half
the second half of
second half of the
department abstract the growth
abstract the growth in
the growth in internet
growth in internet traffic
in internet traffic associated
tm a set of
internet traffic associated with
but its structure mirrored
a set of readonly
traffic associated with video
set of readonly transactions
its structure mirrored that
associated with video streaming
structure mirrored that of
of readonly transactions performed
with video streaming and
readonly transactions performed through
mirrored that of the
transactions performed through a
video streaming and sharing
that of the traditional
performed through a single
of the traditional unix
through a single t
streaming and sharing of
the traditional unix systems
and sharing of videos
sharing of videos is
of videos is so
videos is so rapid
and as such it
is so rapid that
as such it could
if the read sets
such it could be
so rapid that it
it could be considered
the read sets of
could be considered one
rapid that it may
be considered one of
read sets of two
considered one of them
that it may soon
sets of two transactions
it may soon dwarf
of two transactions include
may soon dwarf all
two transactions include the
soon dwarf all other
transactions include the same
dwarf all other forms
include the same object
all other forms of
the same object o
other forms of internet
the significant advances made
forms of internet content
significant advances made in
advances made in academic
made in academic computer
in academic computer science
we say the one
say the one that
one reason for this
the one that read
reason for this is
one that read a
for this is that
in os research and
this is that only
os research and in
is that only some
research and in system
that only some forms
and in system software
only some forms of
in system software engineering
some forms of content
that read a larger
forms of content can
read a larger version
of content can be
a larger version of
content can be cached
larger version of o
have had only minimal
version of o depends
had only minimal impact
of o depends on
only minimal impact on
o depends on the
minimal impact on the
depends on the other
impact on the design
on the design and
the design and implementation
design and implementation of
and implementation of commercial
all transactions access the
implementation of commercial operating
transactions access the same
of commercial operating systems
access the same cache
data generated in real
generated in real time
in real time such
real time such as
time such as by
and the cache is
such as by live
the cache is unbounded
as by live video
the design of all
by live video broadcasts
design of all unix
of all unix systems
all unix systems violates
unix systems violates almost
systems violates almost all
values are only replaced
violates almost all of
are only replaced by
almost all of the
only replaced by newer
all of the software
replaced by newer versions
of the software engineering
the software engineering principles
software engineering principles presented
engineering principles presented to
iptv or new episodes
principles presented to first
or new episodes of
so it is easy
presented to first year
it is easy to
to first year s
is easy to see
first year s computer
new episodes of popular
easy to see that
episodes of popular tv
year s computer science
of popular tv shows
to see that there
s computer science students
see that there are
that there are no
there are no cycles
are no cycles such
no cycles such that
the design is monolithic
cycles such that two
design is monolithic with
such that two transactions
is monolithic with almost
that two transactions depend
monolithic with almost no
two transactions depend on
with almost no modular
transactions depend on one
almost no modular structure
immersive virtual reality applications
depend on one another
virtual reality applications and
reality applications and games
applications and games typically
and games typically can
and the internal kernel
games typically can t
the dependency graph therefore
typically can t be
the internal kernel interfaces
can t be cached
dependency graph therefore describes
t be cached at
internal kernel interfaces are
be cached at all
graph therefore describes a
kernel interfaces are not
therefore describes a partial
interfaces are not strictly
describes a partial order
are not strictly enforced
a partial order of
and in today s
not strictly enforced which
in today s systems
partial order of the
strictly enforced which introduces
order of the read
enforced which introduces dependencies
which introduces dependencies on
introduces dependencies on the
each client may pull
dependencies on the actual
client may pull such
on the actual implementation
may pull such information
the actual implementation of
pull such information on
actual implementation of data
such information on its
implementation of data structures
information on its own
and we choose an
on its own point
we choose an arbitrary
choose an arbitrary total
an arbitrary total ordering
arbitrary total ordering that
making it impossible to
total ordering that respects
it impossible to upgrade
ordering that respects this
impossible to upgrade or
that respects this partial
to upgrade or replace
respects this partial order
upgrade or replace modules
or replace modules without
replace modules without also
modules without also redesigning
without also redesigning several
assume wlog the order
also redesigning several other
wlog the order is
redesigning several other modules
the order is t
stream directly from the
directly from the data
from the data center
for example to replace
example to replace the
even if large numbers
to replace the scheduler
if large numbers of
replace the scheduler in
large numbers of clients
the scheduler in any
numbers of clients share
scheduler in any of
of clients share interest
in any of the
clients share interest in
any of the bsd
share interest in at
of the bsd s
interest in at least
the bsd s one
in at least some
bsd s one needs
at least some aspects
s one needs to
least some aspects of
one needs to spend
some aspects of the
needs to spend two
aspects of the data
to spend two weeks
spend two weeks searching
two weeks searching for
weeks searching for all
searching for all dependencies
for all dependencies and
we propose a new
all dependencies and fixing
we take an initial
dependencies and fixing other
propose a new system
and fixing other sources
take an initial arbitrary
a new system called
an initial arbitrary serialization
new system called g
system called g radient
called g radient aimed
at the top of
g radient aimed at
of and permute it
radient aimed at reducing
the top of our
aimed at reducing the
top of our long
and permute it according
of our long wish
permute it according to
our long wish list
at reducing the load
long wish list for
it according to the
wish list for an
according to the route
list for an ideal
to the route above
for an ideal research
the route above to
an ideal research operating
route above to place
ideal research operating system
reducing the load on
above to place t
the load on providers
load on providers of
on providers of such
providers of such and
were three important general
of such and enabling
three important general points
such and enabling scalable
bandwidthsensitive streaming service for
streaming service for heterogeneous
service for heterogeneous consumers
the result is a
result is a permutation
the design and implementation
the core of the
design and implementation of
core of the system
and implementation of the
of the system is
implementation of the operating
the system is an
of the operating system
system is an overlay
the operating system should
is an overlay networking
operating system should comply
an overlay networking architecture
system should comply with
overlay networking architecture intended
should comply with modern
networking architecture intended to
comply with modern software
architecture intended to run
with modern software engineering
intended to run directly
modern software engineering principles
we take all transactions
to run directly on
take all transactions that
run directly on a
all transactions that precede
directly on a content
transactions that precede t
on a content hosting
a content hosting platform
allowing researchers to introduce
researchers to introduce new
to introduce new components
and which optimizes aggregate
which optimizes aggregate bandwidth
optimizes aggregate bandwidth use
and replace core components
aggregate bandwidth use by
replace core components without
bandwidth use by transforming
core components without redesigning
use by transforming in
components without redesigning the
does not depend on
without redesigning the complete
not depend on them
redesigning the complete system
flight data to match
data to match the
and place them after
to match the ideal
place them after t
match the ideal stream
the ideal stream quality
ideal stream quality expressed
stream quality expressed as
quality expressed as an
the overall structure of
expressed as an economic
overall structure of the
as an economic utility
we call this permutation
structure of the operating
an economic utility of
of the operating system
economic utility of the
utility of the consuming
of the consuming client
user and kernel space
and kernel space components
next we place t
should be designed towards
be designed towards the
designed towards the future
introduction recent years have
recent years have seen
years have seen skyrocketing
have seen skyrocketing demand
seen skyrocketing demand for
skyrocketing demand for internet
demand for internet bandwidth
can be placed immediately
be placed immediately after
placed immediately after t
increasingly dominated by real
should be pervasive throughout
be pervasive throughout the
time streaming of short
pervasive throughout the whole
throughout the whole system
we place it there
place it there to
it there to form
but in many forms
the operating system vendor
operating system vendor should
system vendor should be
is independent of t
vendor should be open
should be open to
be open to innovation
then all its preceding
all its preceding transactions
our experiences in the
experiences in the past
according to the dependency
in the past had
to the dependency graph
if trends continue then
the past had been
trends continue then internet
past had been that
continue then internet video
are unrelated to t
had been that vendors
then internet video alone
been that vendors always
internet video alone will
that vendors always ignored
video alone will generate
and are therefore located
alone will generate almost
vendors always ignored important
are therefore located after
always ignored important research
therefore located after it
ignored important research results
important research results and
research results and only
results and only followed
and only followed very
the permutations required are
exabytes per month by
permutations required are therefore
per month by the
required are therefore after
month by the end
are therefore after t
by the end of
only followed very narrow
followed very narrow paths
very narrow paths of
narrow paths of incremental
paths of incremental improvements
windows nt was the
nt was the only
was the only operating
the only operating system
only operating system that
operating system that came
system that came close
that came close to
came close to matching
close to matching most
to matching most of
matching most of our
most of our requirements
all relevant update transactions
relevant update transactions are
update transactions are located
transactions are located after
with a handful of
are located after t
percent of all internet
a handful of operating
of all internet traffic
handful of operating systems
of operating systems such
operating systems such as
systems such as qnx
such as qnx and
as qnx and utah
qnx and utah s
and utah s os
and therefore the permutations
therefore the permutations required
the permutations required are
permutations required are all
required are all after
are all after t
none of the unix
faced with a competitive
of the unix based
with a competitive landscape
the unix based operating
unix based operating systems
based operating systems came
operating systems came close
systems came close to
came close to fulfilling
since in all cases
isps and content providers
in all cases the
close to fulfilling our
all cases the permutations
to fulfilling our requirements
cases the permutations are
and content providers are
the permutations are after
permutations are after t
content providers are exploring
providers are exploring technologies
as noted before the
are exploring technologies to
noted before the core
exploring technologies to help
before the core of
technologies to help satisfy
the core of those
to help satisfy the
core of those operating
help satisfy the growing
of those operating systems
satisfy the growing demand
those operating systems is
the growing demand alongside
operating systems is based
growing demand alongside the
systems is based on
they do not affect
demand alongside the purchase
do not affect the
alongside the purchase of
not affect the correctness
the purchase of expensive
affect the correctness of
purchase of expensive infrastructure
the correctness of t
reducing the bandwidth consumption
the bandwidth consumption of
bandwidth consumption of simultaneous
we take the resulting
consumption of simultaneous replicated
take the resulting permutation
of simultaneous replicated content
the resulting permutation that
simultaneous replicated content is
resulting permutation that we
year old designs and
permutation that we call
replicated content is a
old designs and these
content is a challenge
designs and these operating
is a challenge which
and these operating systems
a challenge which usually
these operating systems still
challenge which usually leverages
operating systems still treat
which usually leverages two
systems still treat computers
and move all transactions
usually leverages two main
move all transactions that
leverages two main tools
all transactions that neither
still treat computers as
transactions that neither t
treat computers as single
computers as single entities
as single entities without
single entities without a
caching of content and
entities without a coherent
of content and multicasting
depend on to right
on to right after
some forms of video
to right after t
forms of video content
such as downloads of
as downloads of unencrypted
the resulting permutation is
downloads of unencrypted movies
of unencrypted movies or
unencrypted movies or films
movies or films where
or films where many
films where many users
where many users will
many users will share
we repeat this process
users will share the
repeat this process until
will share the same
this process until we
share the same encryption
process until we place
the same encryption key
until we place all
we place all read
a wide variety of
this is a serialization
wide variety of caching
is a serialization of
variety of caching options
a serialization of the
of caching options exist
serialization of the update
of the update transactions
the update transactions in
update transactions in and
transactions in and all
in and all read
only transactions that accessed
transactions that accessed the
that accessed the same
accessed the same cache
feet high windows nt
we have therefore shown
high windows nt looked
have therefore shown that
windows nt looked like
therefore shown that in
nt looked like the
shown that in any
looked like the proverbial
that in any execution
like the proverbial dinosaur
in any execution of
of which is the
any execution of t
which is the akamai
is the akamai content
the akamai content distribution
akamai content distribution network
a closer look revealed
closer look revealed a
cache the update transactions
look revealed a truly
the update transactions can
revealed a truly modern
update transactions can be
a truly modern operating
transactions can be serialized
truly modern operating system
can be serialized with
is arguably the most
be serialized with readonly
arguably the most famous
serialized with readonly transactions
with readonly transactions that
object oriented design is
readonly transactions that accessed
oriented design is pervasive
transactions that accessed a
design is pervasive through
that accessed a single
is pervasive through the
accessed a single cache
pervasive through the system
through the system including
the system including the
system including the kernel
which means that t
there is a complete
cache implements cache serializability
is a complete distributed
a complete distributed strategy
multicast techniques can reduce
complete distributed strategy with
techniques can reduce the
distributed strategy with at
can reduce the overall
strategy with at its
reduce the overall network
with at its core
the overall network traffic
at its core a
overall network traffic by
its core a distributed
network traffic by taking
core a distributed object
traffic by taking advantage
a distributed object technology
by taking advantage of
distributed object technology and
taking advantage of the
object technology and includes
advantage of the packet
technology and includes a
of the packet replication
and includes a complete
the packet replication and
includes a complete integration
packet replication and forwarding
a complete integration of
replication and forwarding within
complete integration of distributed
and forwarding within the
integration of distributed services
forwarding within the network
of distributed services such
within the network infrastructure
distributed services such as
services such as security
the deployment of the
deployment of the efficient
of the efficient network
and last no but
last no but least
there is a real
is a real desire
a real desire by
real desire by the
desire by the vendor
by the vendor to
the vendor to continuously
vendor to continuously innovate
to continuously innovate its
continuously innovate its operating
innovate its operating system
its operating system and
operating system and the
area internet has failed
system and the overall
and the overall services
microsoft doesn t hesitate
doesn t hesitate to
t hesitate to incorporate
hesitate to incorporate academic
to incorporate academic results
incorporate academic results into
academic results into operating
results into operating system
and so more expensive
so more expensive application
and is open for
is open for new
open for new directions
level overlays are generally
overlays are generally used
innovation as a life
as a life style
a life style microsoft
life style microsoft is
style microsoft is not
microsoft is not conservative
is not conservative in
not conservative in its
conservative in its os
in its os development
while most vendors only
the devices used by
most vendors only consider
devices used by content
vendors only consider changes
used by content subscribers
only consider changes to
by content subscribers have
consider changes to their
content subscribers have become
changes to their core
subscribers have become increasingly
to their core os
have become increasingly heterogeneous
their core os services
become increasingly heterogeneous mobile
core os services under
increasingly heterogeneous mobile devices
os services under extreme
services under extreme market
under extreme market pressure
the core of windows
are projected to consume
core of windows nt
projected to consume over
of windows nt has
windows nt has changed
nt has changed significantly
has changed significantly over
changed significantly over the
significantly over the past
over the past years
the past years to
past years to accommodate
years to accommodate the
to accommodate the demands
exabytes of video per
accommodate the demands of
of video per month
the demands of modern
video per month in
demands of modern computing
especially the upcoming release
the upcoming release of
upcoming release of windows
formerly known as windows
known as windows nt
implying that a range
that a range of
a range of subscription
range of subscription rates
of subscription rates and
subscription rates and policies
makes that the microsoft
rates and policies must
that the microsoft takes
and policies must be
the microsoft takes the
policies must be applied
microsoft takes the operating
must be applied over
takes the operating system
be applied over the
the operating system functionality
applied over the user
operating system functionality to
over the user base
system functionality to the
functionality to the next
to the next level
the advances in windows
even if multiple users
if multiple users are
multiple users are streaming
users are streaming the
are streaming the same
streaming the same event
are too numerous to
too numerous to enumerate
numerous to enumerate here
such as watching the
as watching the opening
watching the opening ceremony
the opening ceremony of
opening ceremony of the
they range from a
ceremony of the olympics
range from a file
from a file system
a file system cache
file system cache for
system cache for disconnected
cache for disconnected operation
a smartphone user will
smartphone user will need
user will need a
will need a differently
which was originally developed
need a differently transcoded
was originally developed at
a differently transcoded version
originally developed at cmu
differently transcoded version than
developed at cmu in
transcoded version than the
at cmu in the
version than the people
cmu in the coda
than the people watching
in the coda project
the people watching via
people watching via internet
watching via internet television
to a remote storage
a remote storage service
remote storage service that
storage service that automatically
or on their laptops
service that automatically moves
that automatically moves old
automatically moves old data
moves old data from
old data from your
data from your hard
from your hard disk
different consumer groups may
your hard disk to
consumer groups may desire
hard disk to remote
groups may desire different
disk to remote servers
may desire different local
to remote servers if
desire different local ads
remote servers if you
different local ads or
servers if you are
local ads or sub
if you are running
you are running out
are running out of
running out of disk
out of disk space
titles to be embedded
to be embedded into
be embedded into their
embedded into their video
into their video streams
from tight security integration
avatars in a virtual
in a virtual world
a virtual world can
virtual world can be
world can be viewed
as the dominant security
can be viewed as
the dominant security provider
be viewed as subscribers
viewed as subscribers to
as subscribers to updates
subscribers to updates about
to updates about objects
updates about objects in
to a complete integration
about objects in their
objects in their vicinity
a complete integration of
complete integration of network
integration of network quality
of network quality of
and may want more
network quality of services
may want more detailed
quality of services tools
want more detailed updates
of services tools including
more detailed updates for
services tools including data
detailed updates for objects
tools including data transmission
updates for objects that
including data transmission shapers
for objects that are
data transmission shapers and
objects that are closer
transmission shapers and priority
that are closer to
shapers and priority scheduling
are closer to them
and priority scheduling and
closer to them in
priority scheduling and queuing
to them in this
them in this world
and from attributed based
while this growing heterogeneity
from attributed based distributed
this growing heterogeneity of
attributed based distributed component
growing heterogeneity of device
based distributed component programming
heterogeneity of device types
distributed component programming to
component programming to indexing
programming to indexing support
to indexing support integrated
indexing support integrated in
research on cdns has
support integrated in the
on cdns has generally
integrated in the file
cdns has generally assumed
in the file system
has generally assumed a
generally assumed a homogeneous
assumed a homogeneous population
a homogeneous population of
homogeneous population of end
we are witnesses of
are witnesses of a
witnesses of a unique
of a unique process
never before have we
before have we seen
have we seen such
we seen such a
seen such a radical
such a radical overhaul
a radical overhaul of
radical overhaul of an
overhaul of an operating
of an operating system
an operating system targeted
operating system targeted for
system targeted for the
targeted for the enterprise
for the enterprise market
in general this market
general this market is
this market is very
market is very conservative
is very conservative and
very conservative and not
conservative and not interested
and not interested in
thus most current systems
not interested in taking
interested in taking risks
most current systems assume
current systems assume multiple
systems assume multiple video
however the problems of
assume multiple video streams
the problems of scale
multiple video streams to
video streams to be
streams to be sent
management and distribution are
to be sent from
and distribution are asking
be sent from the
distribution are asking for
sent from the source
are asking for radical
from the source at
asking for radical solutions
the source at different
for radical solutions to
source at different resolutions
radical solutions to get
at different resolutions or
solutions to get to
different resolutions or that
to get to a
resolutions or that a
get to a computing
or that a single
to a computing base
that a single highquality
a computing base that
a single highquality stream
computing base that can
single highquality stream is
base that can bring
highquality stream is transcoded
that can bring us
stream is transcoded by
can bring us into
is transcoded by the
bring us into the
transcoded by the receiver
us into the next
by the receiver who
into the next century
the receiver who then
receiver who then incurs
who then incurs cost
then incurs cost for
incurs cost for last
one of the markets
of the markets where
the markets where we
mile traffic owing to
markets where we will
traffic owing to unnecessarily
where we will see
owing to unnecessarily detailed
we will see the
to unnecessarily detailed video
will see the main
see the main competitive
the main competitive battle
main competitive battle between
we pose the following
competitive battle between microsoft
pose the following question
battle between microsoft and
between microsoft and others
microsoft and others will
and others will be
others will be that
how can we deliver
will be that of
can we deliver live
be that of the
we deliver live dynamic
that of the e
deliver live dynamic content
such as video broadcasts
web farms with hundreds
or financial stock data
farms with hundreds of
with hundreds of nodes
over the internet to
with support services for
the internet to large
support services for load
internet to large number
services for load balancing
to large number of
large number of heterogeneous
number of heterogeneous users
of heterogeneous users simultaneously
heterogeneous users simultaneously while
users simultaneously while balancing
simultaneously while balancing bandwidth
while balancing bandwidth costs
traffic rates and end
distributed and single image
and single image management
live content refers to
content refers to content
refers to content streams
to content streams that
content streams that must
streams that must be
that must be transmitted
must be transmitted to
be transmitted to multiple
transmitted to multiple receivers
to multiple receivers simultaneously
are really pushing the
really pushing the envelope
pushing the envelope of
such as a live
the envelope of all
as a live broadcast
envelope of all operating
of all operating systems
all operating systems that
operating systems that are
systems that are currently
that are currently on
are currently on the
currently on the market
ticker updates for financial
updates for financial stocks
for financial stocks or
financial stocks or object
windows nt is still
stocks or object updates
nt is still considered
or object updates in
is still considered to
object updates in a
still considered to be
updates in a virtual
considered to be the
in a virtual world
to be the new
be the new kid
the new kid on
new kid on the
kid on the block
on the block in
the block in the
block in the internet
in the internet services
the internet services world
we are not focused
are not focused on
not focused on streams
focused on streams with
on streams with a
streams with a pause
but it is clear
with a pause or
a pause or rewind
it is clear that
pause or rewind functions
or rewind functions or
is clear that the
rewind functions or the
functions or the video
clear that the risks
that the risks that
the risks that are
risks that are taken
that are taken now
are taken now are
taken now are the
now are the right
are the right moves
the right moves to
right moves to prepare
moves to prepare the
to prepare the operating
prepare the operating system
the operating system for
the gradient cdn to
operating system for operation
gradient cdn to make
system for operation in
cdn to make progress
for operation in these
to make progress towards
operation in these emerging
make progress towards the
in these emerging massive
progress towards the research
these emerging massive computing
towards the research question
emerging massive computing environments
the bugs innovation comes
we propose a novel
ordering transactions with prediction
bugs innovation comes at
transactions with prediction in
innovation comes at a
propose a novel networked
with prediction in distributed
comes at a price
a novel networked content
prediction in distributed object
in distributed object stores
novel networked content delivery
distributed object stores ittay
networked content delivery system
one of the costs
object stores ittay eyal
content delivery system called
of the costs of
delivery system called g
the costs of introducing
system called g radient
costs of introducing a
called g radient to
of introducing a significant
g radient to address
introducing a significant amount
radient to address the
a significant amount of
to address the complex
significant amount of new
address the complex caching
amount of new code
the complex caching and
of new code is
complex caching and multicasting
new code is the
caching and multicasting issues
code is the number
and multicasting issues associated
is the number of
multicasting issues associated with
the number of software
issues associated with live
number of software defects
associated with live streaming
of software defects per
with live streaming of
software defects per lines
live streaming of dynamic
defects per lines of
streaming of dynamic content
per lines of codes
of dynamic content to
lines of codes increases
dynamic content to a
content to a heterogeneous
to a heterogeneous user
a heterogeneous user population
while measurements actually let
department of computer science
measurements actually let us
actually let us believe
the systems architecture consists
let us believe that
systems architecture consists of
us believe that microsoft
architecture consists of one
believe that microsoft products
consists of one or
that microsoft products are
of one or more
microsoft products are quite
one or more content
products are quite reliable
or more content providers
are quite reliable at
more content providers which
quite reliable at operating
content providers which together
reliable at operating systems
providers which together form
which together form a
together form a cooperative
form a cooperative network
department of electrical engineering
a cooperative network of
cooperative network of g
network of g radient
of g radient cdn
g radient cdn nodes
thousand lines of code
the cdn nodes form
cdn nodes form a
nodes form a dynamic
form a dynamic overlay
israel abstract numbers of
a dynamic overlay over
abstract numbers of storage
dynamic overlay over which
numbers of storage nodes
overlay over which the
over which the content
which the content is
the content is delivered
fresh code has a
when client transactions access
code has a disastrous
client transactions access data
has a disastrous effect
and for our initial
a disastrous effect on
for our initial prototypes
disastrous effect on this
transactions access data on
effect on this number
our initial prototypes we
access data on multiple
initial prototypes we will
data on multiple shards
prototypes we will look
we will look at
will look at spanning
look at spanning trees
the outlook becomes even
the issue of consistency
outlook becomes even more
issue of consistency arises
becomes even more worrisome
the concept of cdn
even more worrisome when
concept of cdn nodes
more worrisome when we
of cdn nodes is
worrisome when we realize
cdn nodes is general
when we realize that
we realize that microsoft
realize that microsoft is
we would use a
that microsoft is not
would use a system
microsoft is not only
use a system with
is not only introducing
a system with acid
not only introducing new
system with acid transactions
only introducing new code
an architecture in which
architecture in which cdn
in which cdn servers
which cdn servers are
but is also changing
cdn servers are hosted
is also changing all
servers are hosted by
also changing all of
are hosted by isps
changing all of its
hosted by isps to
all of its old
by isps to reduce
of its old code
isps to reduce redundant
to reduce redundant incoming
reduce redundant incoming bandwidth
redundant incoming bandwidth is
incoming bandwidth is a
bandwidth is a logical
an automated process is
is a logical scenario
automated process is converting
process is converting all
is converting all of
converting all of the
all of the windows
and another example is
of the windows nt
another example is that
the windows nt code
example is that g
windows nt code to
is that g radient
nt code to be
that g radient nodes
g radient nodes may
radient nodes may as
nodes may as well
may as well be
because this model facilitates
as well be integrated
this model facilitates reasoning
well be integrated into
model facilitates reasoning about
be integrated into set
facilitates reasoning about system
reasoning about system properties
about system properties and
system properties and makes
properties and makes possible
and makes possible a
makes possible a variety
possible a variety of
a variety of highassurance
variety of highassurance guarantees
thousand lines of code
lines of code per
of code per day
code per day and
per day and is
day and is believed
and is believed to
is believed to catch
the acid model is
believed to catch all
our approach to the
to catch all pointer
approach to the problem
catch all pointer arithmetic
to the problem resembles
all pointer arithmetic cases
acid model is often
the problem resembles content
model is often avoided
is often avoided in
often avoided in today
avoided in today s
in today s large
an important question is
important question is whether
question is whether the
is whether the introduced
scale systems due to
and in fact the
whether the introduced functionality
systems due to efficiency
in fact the expected
the introduced functionality is
due to efficiency concerns
fact the expected deployment
introduced functionality is worth
the expected deployment model
functionality is worth the
expected deployment model would
is worth the unavoidable
deployment model would employ
worth the unavoidable initial
model would employ a
the unavoidable initial instability
would employ a geographically
unavoidable initial instability that
employ a geographically distributed
initial instability that is
a geographically distributed set
instability that is bound
geographically distributed set of
that is bound to
distributed set of isps
is bound to occur
set of isps or
of isps or small
existing approaches typically run
isps or small data
approaches typically run transactions
or small data centers
whenever taking risks to
typically run transactions speculatively
taking risks to achieve
small data centers of
run transactions speculatively and
data centers of the
risks to achieve major
centers of the kind
to achieve major improvements
of the kind operated
transactions speculatively and perform
the kind operated by
speculatively and perform certification
kind operated by today
and perform certification after
operated by today s
perform certification after they
there is always the
certification after they complete
by today s cdn
after they complete to
today s cdn providers
is always the down
they complete to preserve
complete to preserve consistency
always the down side
the down side that
down side that there
side that there is
either committing or aborting
whereas today s content
committing or aborting each
that there is some
or aborting each transaction
aborting each transaction depending
there is some change
each transaction depending on
hosting sites cache objects
transaction depending on conflicts
is some change of
some change of failure
change of failure and
of failure and it
failure and it is
and it is likely
it is likely that
is likely that we
likely that we will
that we will see
rain an architecture for
we will see a
an architecture for acid
will see a number
architecture for acid transactions
see a number of
for acid transactions in
a number of components
acid transactions in a
number of components of
transactions in a resilient
of components of nt
in a resilient archive
components of nt coming
a resilient archive with
of nt coming under
resilient archive with independent
nt coming under intense
archive with independent nodes
coming under intense scrutiny
our focus is on
under intense scrutiny from
focus is on content
intense scrutiny from industry
is on content that
scrutiny from industry and
on content that cannot
from industry and academia
content that cannot be
the system orders transactions
that cannot be usefully
cannot be usefully cached
system orders transactions before
orders transactions before they
transactions before they begin
before they begin by
the g radient project
they begin by employing
g radient project aims
such as the directory
radient project aims to
as the directory services
begin by employing predictors
project aims to exploit
by employing predictors that
aims to exploit and
employing predictors that estimate
to exploit and develop
predictors that estimate the
may become a performance
exploit and develop two
become a performance bottleneck
that estimate the set
a performance bottleneck in
estimate the set of
performance bottleneck in the
the set of objects
bottleneck in the overall
set of objects each
in the overall distributed
of objects each transaction
the overall distributed operation
and develop two techniques
objects each transaction will
develop two techniques that
each transaction will access
two techniques that improve
techniques that improve on
that improve on existing
or the wide spread
improve on existing cdns
the wide spread security
such predictors can be
wide spread security integration
predictors can be implemented
spread security integration could
can be implemented with
security integration could introduce
be implemented with machine
integration could introduce a
implemented with machine learning
could introduce a critical
with machine learning tools
and algorithms to balance
introduce a critical dependency
algorithms to balance bandwidth
a critical dependency on
to balance bandwidth costs
critical dependency on the
balance bandwidth costs with
dependency on the high
bandwidth costs with end
availability of the security
of the security servers
our design is focused
design is focused on
from a research point
is focused on modularity
a research point of
focused on modularity and
research point of view
on modularity and incremental
modularity and incremental deployment
these problems do not
problems do not really
a transaction reserves a
do not really bother
transaction reserves a version
not really bother us
reserves a version of
a version of each
version of each object
of each object it
each object it will
object it will use
the advantage of performing
advantage of performing research
of performing research on
performing research on a
research on a system
when later accessing the
later accessing the objects
which has distribution at
it will see these
has distribution at its
will see these reserved
distribution at its core
see these reserved versions
at its core greatly
dynamic content has substantial
its core greatly outweighs
content has substantial levels
core greatly outweighs the
has substantial levels of
greatly outweighs the consequences
substantial levels of redundancy
outweighs the consequences of
the consequences of working
consequences of working with
of working with a
working with a cutting
even when user interests
with a cutting edge
when user interests are
a cutting edge operating
user interests are relatively
cutting edge operating system
interests are relatively heterogeneous
leases for future object
for future object versions
widespread use of streaming
however i must admit
use of streaming video
of streaming video occurs
i must admit that
streaming video occurs when
leases are issued for
video occurs when internet
are issued for a
occurs when internet users
issued for a predefined
when internet users watch
for a predefined time
internet users watch major
a predefined time period
users watch major events
must admit that at
watch major events online
admit that at more
that at more then
such as superbowl or
as superbowl or the
at more then one
superbowl or the olympics
not the lease holder
more then one occasion
then one occasion my
may unilaterally decide to
one occasion my students
unilaterally decide to ignore
decide to ignore a
occasion my students had
and like television users
to ignore a reservation
my students had to
students had to control
such clients have little
had to control their
clients have little tolerance
to run effectively at
to control their murderous
have little tolerance for
run effectively at large
control their murderous intentions
little tolerance for lagged
effectively at large scale
their murderous intentions towards
tolerance for lagged data
murderous intentions towards the
intentions towards the iis
towards the iis or
the iis or mts
rain must tolerate performance
iis or mts developers
must tolerate performance hiccups
large numbers of users
or mts developers or
numbers of users have
of users have essentially
mts developers or were
users have essentially the
have essentially the same
developers or were they
essentially the same needs
or were they kept
were they kept their
they kept their good
but since they may
kept their good spirits
since they may access
all of which are
they may access the
their good spirits by
may access the streams
of which are common
access the streams from
good spirits by contemplating
the streams from a
which are common in
spirits by contemplating the
are common in such
streams from a variety
by contemplating the horrible
from a variety of
common in such settings
a variety of devices
contemplating the horrible tortures
the horrible tortures one
horrible tortures one could
tortures one could perform
with different screen sizes
one could perform on
different screen sizes and
could perform on the
screen sizes and resolutions
perform on the person
progress should never depend
on the person that
should never depend on
the person that had
never depend on the
person that had designed
depend on the responsiveness
or different connectivity properties
on the responsiveness of
that had designed the
the responsiveness of any
had designed the com
responsiveness of any single
designed the com security
of any single machine
the com security architecture
the current solution is
current solution is to
windows research there are
solution is to provide
research there are some
is to provide each
there are some properties
to provide each user
are some properties of
provide each user with
some properties of windows
each user with a
rain requires reliable entities
user with a direct
properties of windows nt
with a direct connection
of windows nt that
a direct connection to
requires reliable entities in
direct connection to a
windows nt that make
connection to a content
reliable entities in cloud
nt that make it
that make it particularly
make it particularly suitable
it particularly suitable for
particularly suitable for research
server due to the
suitable for research purposes
due to the lack
to the lack of
the lack of robust
it is common to
lack of robust multicast
is common to shard
of robust multicast technologies
the operating system kernel
operating system kernel for
system kernel for example
kernel for example is
for example is designed
similar issues arise for
example is designed with
issues arise for newscasts
is designed with extensibility
arise for newscasts of
designed with extensibility in
for newscasts of fast
with extensibility in mind
data across large numbers
across large numbers of
large numbers of nodes
to allow developers of
allow developers of hardware
developers of hardware based
atomic transactions are typically
of hardware based services
transmission of financial data
transactions are typically implemented
of financial data and
are typically implemented by
financial data and virtual
typically implemented by running
data and virtual on
implemented by running transactions
new protocols and file
by running transactions speculatively
protocols and file systems
and file systems to
file systems to add
systems to add their
to add their functionality
and then certifying them
add their functionality to
our insight is that
their functionality to the
insight is that a
functionality to the system
is that a data
to the system without
aborting ones that cause
the system without much
ones that cause conflicts
system without much effort
rich channel can be
channel can be transformed
can be transformed on
all kernel code is
kernel code is developed
in high contention scenarios
code is developed following
is developed following a
developed following a strict
network to create the
this approach has drawbacks
following a strict object
to create the dynamic
a strict object oriented
create the dynamic content
strict object oriented paradigm
the dynamic content for
rather than achieving any
object oriented paradigm and
than achieving any substantial
dynamic content for end
achieving any substantial level
oriented paradigm and its
any substantial level of
paradigm and its functionality
substantial level of concurrency
and its functionality can
its functionality can only
functionality can only be
can only be accessed
only be accessed through
be accessed through interfaces
it prevents concurrency by
prevents concurrency by aborting
concurrency by aborting all
by aborting all but
aborting all but one
we could add personalized
all but one of
none of its implementation
but one of the
could add personalized advertisements
one of the contending
of its implementation is
of the contending transactions
its implementation is visible
subtitles or encryption keys
or encryption keys to
our work explores a
encryption keys to iptv
work explores a new
one of the designs
explores a new option
keys to iptv broadcasts
of the designs abstractions
the designs abstractions of
designs abstractions of the
abstractions of the windows
filters or aggregates to
of the windows nt
or aggregates to financial
the windows nt kernel
aggregates to financial stock
windows nt kernel i
ordering transactions in advance
nt kernel i find
transactions in advance based
kernel i find it
in advance based on
to financial stock updates
advance based on the
i find it particularly
based on the objects
find it particularly fascinating
on the objects they
it particularly fascinating to
or reduce the update
the objects they are
particularly fascinating to work
objects they are likely
reduce the update rate
fascinating to work with
they are likely to
to work with is
the update rate for
work with is the
are likely to access
update rate for distant
with is the device
rate for distant objects
is the device object
for distant objects in
distant objects in the
objects in the virtual
providing acid transactions in
in the virtual world
acid transactions in a
the virtual world to
transactions in a resilient
virtual world to which
in a resilient archive
world to which the
a resilient archive with
to which the user
a device object in
which the user has
resilient archive with independent
the user has subscribed
device object in an
archive with independent nodes
object in an instance
in an instance created
an instance created by
instance created by driver
created by driver objects
the same mechanism will
same mechanism will also
mechanism will also allow
will also allow the
also allow the system
which encapsulates a unit
allow the system to
encapsulates a unit of
the system to tailor
a unit of kernel
system to tailor to
unit of kernel based
to tailor to heterogeneous
of kernel based software
tailor to heterogeneous devices
this preliminary ordering decreases
preliminary ordering decreases abort
ordering decreases abort rate
whether this is a
this is a device
is a device driver
and eliminates aborts in
eliminates aborts in error
a network protocol or
network protocol or a
protocol or a file
or a file system
transcoding a high definition
a file system filter
a high definition broadcast
high definition broadcast to
to allow fast recovery
definition broadcast to adapt
these objects have the
allow fast recovery from
broadcast to adapt its
fast recovery from failures
objects have the interesting
to adapt its resolution
recovery from failures our
have the interesting property
adapt its resolution to
from failures our scheme
the interesting property that
its resolution to serve
failures our scheme does
interesting property that they
our scheme does not
resolution to serve a
scheme does not introduce
property that they can
does not introduce any
that they can be
not introduce any locks
to serve a population
they can be attached
serve a population of
can be attached to
a population of heterogeneous
be attached to other
the system consistency and
attached to other device
population of heterogeneous devices
system consistency and durability
to other device objects
consistency and durability rely
of heterogeneous devices from
and durability rely on
heterogeneous devices from cell
durability rely on a
devices from cell phones
rely on a single
and as such can
on a single scalable
from cell phones to
a single scalable tier
as such can intercept
cell phones to tablets
single scalable tier of
such can intercept and
scalable tier of highly
phones to tablets to
can intercept and manipulate
to tablets to iptv
intercept and manipulate all
tablets to iptv lowering
and manipulate all requests
to iptv lowering overall
manipulate all requests flowing
iptv lowering overall bandwidth
all requests flowing to
lowering overall bandwidth costs
requests flowing to and
overall bandwidth costs without
flowing to and from
bandwidth costs without affecting
to and from the
costs without affecting viewing
and from the original
without affecting viewing experience
from the original device
simulations using the transactional
the original device object
ycsb workloads show the
workloads show the scalability
this way it is
show the scalability and
the scalability and benefits
way it is relatively
scalability and benefits of
and benefits of acidrain
it is relatively simple
is relatively simple to
network transformations will be
relatively simple to add
transformations will be applied
simple to add for
will be applied with
to add for example
be applied with pluggable
add for example a
applied with pluggable serverlets
for example a file
with pluggable serverlets designed
example a file system
pluggable serverlets designed to
a file system object
serverlets designed to execute
file system object that
designed to execute within
system object that compresses
to execute within the
center computing systems often
execute within the cdn
object that compresses or
computing systems often maintain
that compresses or encrypts
systems often maintain massive
within the cdn nodes
often maintain massive data
the cdn nodes of
maintain massive data sets
compresses or encrypts data
cdn nodes of g
or encrypts data before
nodes of g radient
encrypts data before the
sharded over large this
data before the data
over large this work
before the data reaches
large this work was
the data reaches the
this work was funded
data reaches the under
the serverlets encapsulate application
reaches the under laying
the under laying file
under laying file system
speci n ac details
n ac details such
ac details such as
by grants from darpa
details such as the
to redirect disk requests
such as the stream
redirect disk requests to
as the stream data
disk requests to a
the stream data format
requests to a replication
to a replication volume
and the elkin research
the elkin research fund
or to trace device
to trace device object
and the ways to
trace device object interaction
the ways to transform
device object interaction during
ways to transform a
object interaction during development
to transform a the
interaction during development phases
transform a the data
only at a single
at a single tier
a single tier of
single tier of the
the strict object oriented
rich objects into more
strict object oriented approach
objects into more specialized
tier of the system
object oriented approach is
of the system a
into more specialized ones
the system a set
oriented approach is very
system a set of
approach is very well
a set of independent
is very well done
set of independent highly
very well done from
open issues include understanding
well done from a
of independent highly available
issues include understanding what
independent highly available logs
done from a design
include understanding what kinds
from a design point
a design point of
understanding what kinds of
design point of view
what kinds of content
used in a novel
kinds of content may
in a novel manner
of content may be
content may be subject
may be subject to
be subject to such
subject to such transformation
all other entities may
to such transformation and
style hacker s heart
such transformation and which
other entities may fail
transformation and which dynamic
entities may fail and
hacker s heart starts
may fail and can
and which dynamic content
fail and can be
which dynamic content is
and can be replaced
dynamic content is not
can be replaced instantly
s heart starts bleeding
be replaced instantly on
heart starts bleeding when
replaced instantly on failure
starts bleeding when he
bleeding when he or
to assess the effect
when he or she
assess the effect of
he or she realizes
the effect of the
or she realizes that
the architecture maintains consistency
she realizes that he
effect of the transformation
realizes that he can
of the transformation on
that he can no
architecture maintains consistency even
he can no longer
the transformation on quality
can no longer do
maintains consistency even in
no longer do a
transformation on quality and
longer do a quick
consistency even in the
on quality and traffic
even in the event
quality and traffic rates
in the event of
do a quick fix
the event of false
event of false suspicion
how transformation should be
transformation should be meaningfully
inspect a few data
should be meaningfully expressed
a few data structures
be meaningfully expressed and
few data structures and
meaningfully expressed and used
data structures and secretly
expressed and used by
reservations serve as suggestions
and used by content
structures and secretly swivel
used by content providers
serve as suggestions a
and secretly swivel some
as suggestions a reservation
secretly swivel some pointers
suggestions a reservation that
swivel some pointers to
a reservation that is
and to learn how
some pointers to make
reservation that is not
pointers to make things
to learn how computationally
to make things work
that is not used
make things work better
learn how computationally intensive
is not used because
things work better or
not used because of
work better or make
how computationally intensive such
better or make more
used because of a
or make more informed
computationally intensive such transformation
make more informed decisions
because of a sluggish
intensive such transformation methods
of a sluggish or
such transformation methods can
a sluggish or dead
transformation methods can be
sluggish or dead owner
methods can be without
or dead owner is
the internal kernel interfaces
dead owner is ignored
can be without overloading
internal kernel interfaces are
be without overloading the
kernel interfaces are elaborate
without overloading the nodes
the independence of system
independence of system elements
of system elements allows
balancing bandwidth costs with
system elements allows for
bandwidth costs with end
but it appears there
elements allows for good
it appears there are
allows for good scalability
appears there are always
there are always some
are always some things
always some things one
some things one cannot
things one cannot do
the g radi ent
one cannot do as
g radi ent content
due to the interdependence
radi ent content delivery
to the interdependence of
cannot do as efficient
the interdependence of the
ent content delivery system
interdependence of the log
do as efficient as
content delivery system is
as efficient as possible
of the log contents
delivery system is currently
system is currently designed
is currently designed to
currently designed to use
designed to use a
to use a spanningtree
use a spanningtree overlay
in four years of
four years of nt
similar to most multicast
years of nt kernel
to most multicast network
has to be carefully
of nt kernel hacking
to be carefully coordinated
most multicast network architectures
be carefully coordinated to
nt kernel hacking only
carefully coordinated to maintain
kernel hacking only on
coordinated to maintain consistency
hacking only on one
only on one occasion
with virtual links connecting
on one occasion we
virtual links connecting g
one occasion we needed
links connecting g radient
we evaluate our architecture
connecting g radient cdn
occasion we needed to
g radient cdn nodes
evaluate our architecture by
we needed to break
our architecture by simulation
needed to break through
architecture by simulation with
to break through the
by simulation with the
break through the standard
the question is to
through the standard kernel
question is to determine
the standard kernel interface
is to determine what
simulation with the transactional
to determine what nodes
determine what nodes the
what nodes the in
we wanted to add
wanted to add a
to add a fast
network processing and connecting
add a fast trap
processing and connecting to
a fast trap into
and connecting to the
fast trap into the
connecting to the diverse
trap into the kernel
to the diverse end
into the kernel for
the kernel for fast
kernel for fast user
users should be done
and the pages which
the pages which hold
pages which hold the
we need to optimize
which hold the trap
need to optimize the
we contrast the effectiveness
hold the trap dispatch
to optimize the overlay
the trap dispatch tables
contrast the effectiveness of
trap dispatch tables were
optimize the overlay to
dispatch tables were protected
the effectiveness of employing
tables were protected after
the overlay to deliver
were protected after the
effectiveness of employing prediction
protected after the system
overlay to deliver the
after the system boot
of employing prediction and
to deliver the exact
employing prediction and the
deliver the exact stream
prediction and the scalability
the exact stream quality
and the scalability of
exact stream quality demanded
another example of what
stream quality demanded by
the scalability of acid
example of what makes
quality demanded by users
of what makes windows
demanded by users while
what makes windows nt
by users while minimizing
rain with other approaches
makes windows nt particular
users while minimizing bandwidth
windows nt particular suitable
while minimizing bandwidth costs
nt particular suitable for
particular suitable for research
suitable for research is
for research is the
research is the fundamental
is the fundamental manner
the fundamental manner in
we propose to apply
fundamental manner in which
propose to apply an
tm m om i
to apply an economics
manner in which advanced
apply an economics framework
in which advanced distributed
which advanced distributed services
advanced distributed services are
distributed services are integrated
services are integrated into
considering two primary inputs
are integrated into windows
two primary inputs in
integrated into windows nt
primary inputs in determining
inputs in determining the
in determining the optimal
determining the optimal network
the optimal network overlay
it allows us to
om n om i
allows us to rely
on the one hand
us to rely on
to rely on ubiquitous
rely on ubiquitous support
on ubiquitous support services
we consider the cost
ubiquitous support services and
consider the cost for
support services and concentrate
the cost for network
services and concentrate on
cost for network edges
and concentrate on advancing
for network edges to
concentrate on advancing the
network edges to carry
on advancing the state
edges to carry traffic
log i log n
advancing the state of
i log n figure
the state of the
state of the art
of the art where
similar to standard bandwidth
the art where it
to standard bandwidth pricing
art where it is
where it is really
it is really needed
schematic structure of acid
windows nt security provides
we leverage the perceived
nt security provides a
leverage the perceived utility
security provides a complete
the perceived utility by
provides a complete set
perceived utility by end
a complete set of
tms access multiple objects
complete set of services
access multiple objects per
set of services integrated
multiple objects per transaction
of services integrated into
users for receiving the
services integrated into all
for receiving the stream
integrated into all sections
receiving the stream at
into all sections of
the stream at a
objects are managed by
stream at a given
are managed by oms
at a given quality
all sections of the
sections of the operating
of the operating system
researchers who are developing
who are developing an
the exact solution for
are developing an advanced
exact solution for this
developing an advanced multi
solution for this optimization
for this optimization problem
this optimization problem is
optimization problem is intractable
is falsely suspected to
problem is intractable it
falsely suspected to have
node replicated transaction server
is intractable it is
replicated transaction server can
intractable it is np
transaction server can use
suspected to have failed
server can use off
and replaced by omi
we have developed algorithms
have developed algorithms that
developed algorithms that give
algorithms that give an
that give an approximate
give an approximate optimal
an approximate optimal solution
causing them to concurrently
them to concurrently serve
to concurrently serve the
concurrently serve the same
and encryption mechanisms into
serve the same objects
encryption mechanisms into their
in the case of
mechanisms into their system
the case of video
into their system without
case of video streams
oms are backed by
their system without much
are backed by highlyavailable
system without much pain
backed by highlyavailable logs
of video streams whose
video streams whose quality
streams whose quality and
whose quality and traffic
quality and traffic rates
the use of the
and traffic rates can
where they store tentative
use of the com
traffic rates can be
they store tentative transaction
rates can be downgraded
of the com object
can be downgraded by
store tentative transaction entries
the com object model
tentative transaction entries for
be downgraded by g
transaction entries for serialization
com object model in
downgraded by g radient
object model in all
by g radient cdn
model in all the
g radient cdn nodes
in all the windows
all the windows nt
the windows nt services
windows nt services allows
we have derived a
nt services allows research
have derived a primaldual
services allows research projects
derived a primaldual approximation
allows research projects to
a primaldual approximation algorithm
research projects to import
primaldual approximation algorithm which
projects to import these
approximation algorithm which produces
to import these services
algorithm which produces a
import these services in
which produces a solution
these services in a
produces a solution whose
services in a very
a solution whose total
in a very simple
solution whose total cost
a very simple manner
system structure the structure
structure the structure of
the structure of the
the difference between total
structure of the system
difference between total network
of the system is
the existence of com
the system is illustrated
between total network traffic
existence of com makes
system is illustrated in
total network traffic costs
is illustrated in figure
of com makes it
network traffic costs and
com makes it trivial
traffic costs and aggregate
makes it trivial for
costs and aggregate end
it trivial for research
trivial for research projects
for research projects to
research projects to export
at the base of
projects to export their
the base of acid
to export their interfaces
export their interfaces in
their interfaces in a
is within a factor
interfaces in a language
within a factor of
rain are a set
in a language independent
are a set of
a language independent manner
a set of independent
set of independent highly
the ensemble project for
available logs that together
ensemble project for example
logs that together describe
project for example has
that together describe the
for example has developed
together describe the state
example has developed a
describe the state of
has developed a protocol
the state of the
developed a protocol environment
state of the entire
a protocol environment for
of the entire system
of the optimal in
protocol environment for distributed
the optimal in the
environment for distributed operations
optimal in the worst
for distributed operations in
in the worst case
distributed operations in the
each log is accessed
operations in the ml
log is accessed through
in the ml programming
is accessed through an
the ml programming language
accessed through an object
through an object manager
and by using a
by using a com
using a com interface
a com interface are
com interface are the
interface are the services
are the services offered
the services offered by
services offered by ensemble
offered by ensemble available
that caches the data
by ensemble available to
caches the data and
ensemble available to c
the data and provides
data and provides the
and provides the data
we see that the
provides the data structure
the data structure abstraction
see that the algorithm
data structure abstraction exporting
that the algorithm has
structure abstraction exporting read
abstraction exporting read and
the algorithm has lower
exporting read and write
read and write operations
algorithm has lower total
java and vb programmers
has lower total cost
lower total cost compared
total cost compared to
this allowed the researchers
cost compared to a
allowed the researchers to
compared to a single
the researchers to side
which are managed by
to a single stream
are managed by transaction
managed by transaction managers
a single stream source
single stream source and
step the time consuming
stream source and a
the time consuming development
source and a minimum
time consuming development of
and a minimum spanning
consuming development of native
a minimum spanning tree
development of native language
minimum spanning tree streaming
of native language interfaces
spanning tree streaming protocol
tree streaming protocol in
tms provide the atomic
streaming protocol in a
provide the atomic transaction
protocol in a simulation
the atomic transaction abstraction
in a simulation based
it helps of course
a simulation based on
helps of course to
simulation based on a
of course to have
based on a collection
course to have all
on a collection of
to have all the
they receive instructions from
have all the tools
a collection of as
receive instructions from clients
instructions from clients to
from clients to start
clients to start and
to start and end
start and end a
and end a transaction
operating system versions and
and operations to perform
system versions and their
operations to perform on
versions and their source
to perform on individual
and their source code
perform on individual objects
their source code available
gradient mst naive broadcast
on individual objects within
mst naive broadcast total
individual objects within the
naive broadcast total cost
objects within the transaction
microsoft is very generous
is very generous to
very generous to academia
generous to academia and
to academia and makes
academia and makes all
and makes all their
the tms predict which
makes all their tools
tms predict which objects
all their tools from
predict which objects it
their tools from operating
which objects it is
tools from operating systems
objects it is likely
from operating systems to
it is likely to
operating systems to compilers
is likely to access
including tons of documentation
and reserve these object
tons of documentation as
reserve these object versions
of documentation as well
documentation as well as
as well as subscriptions
well as subscriptions to
as subscriptions to the
subscriptions to the developer
to the developer network
they speculatively perform each
speculatively perform each operation
available to the departments
perform each operation with
to the departments free
each operation with the
the departments free of
operation with the help
departments free of charge
with the help of
the help of the
help of the appropriate
of the appropriate oms
source code availability turned
the appropriate oms and
code availability turned out
appropriate oms and according
availability turned out to
oms and according to
turned out to be
and according to the
out to be not
according to the order
to be not crucial
to the order set
the order set by
order set by the
set by the reservations
and was only once
was only once used
only once used to
once used to make
used to make actual
to make actual changes
make actual changes to
actual changes to the
they certify the transaction
changes to the operating
certify the transaction by
to the operating systems
the transaction by checking
transaction by checking for
by checking for conflicts
checking for conflicts in
for conflicts in each
von eicken et al
conflicts in each log
membership monitors are in
monitors are in charge
are in charge of
in charge of deciding
charge of deciding and
of deciding and publishing
the source is extremely
deciding and publishing which
source is extremely useful
and publishing which machines
is extremely useful as
publishing which machines perform
extremely useful as additional
which machines perform which
useful as additional documentation
machines perform which roles
to examine unexpected behaviour
namely which machines run
examine unexpected behaviour or
which machines run the
unexpected behaviour or to
machines run the log
behaviour or to provide
run the log and
or to provide templates
the log and model
to provide templates for
log and model and
provide templates for similar
and model and goal
templates for similar projects
model and goal we
and goal we assume
goal we assume unreliable
we assume unreliable servers
assume unreliable servers that
as one can perform
unreliable servers that may
one can perform complete
servers that may crash
can perform complete source
that may crash or
perform complete source code
may crash or hang
complete source code level
source code level debugging
code level debugging of
level debugging of all
debugging of all parts
of all parts of
all parts of the
parts of the operating
of the operating system
the operating system including
operating system including the
system including the kernel
to accommodate reliable storage
source codes helps us
codes helps us to
helps us to develop
us to develop experimental
to develop experimental services
develop experimental services faster
experimental services faster and
services faster and in
faster and in tune
and in tune with
in tune with existing
tune with existing functionality
as explained in section
students are free to
are free to work
free to work with
to work with the
work with the source
with the source code
the source code and
source code and are
code and are not
and are not prohibited
are not prohibited in
not prohibited in any
prohibited in any way
the system exposes a
in any way from
system exposes a transactional
any way from applying
exposes a transactional data
way from applying the
a transactional data store
the g radient optimization
transactional data store supporting
from applying the knowledge
data store supporting serializable
g radient optimization is
store supporting serializable transactions
applying the knowledge they
radient optimization is effective
the knowledge they gained
optimization is effective compared
knowledge they gained in
is effective compared to
they gained in their
effective compared to a
gained in their later
a client invokes a
in their later careers
client invokes a begin
compared to a centralized
to a centralized source
a centralized source and
centralized source and a
source and a minimum
and a minimum spanning
a minimum spanning tree
interactions with the evil
with the evil empire
the evil empire microsoft
evil empire microsoft realizes
empire microsoft realizes the
protocol even as system
even as system sizes
microsoft realizes the potential
as system sizes scale
system sizes scale up
realizes the potential of
the potential of widespread
potential of widespread adoption
error bars represent one
a field from a
of widespread adoption of
field from a table
bars represent one standard
widespread adoption of windows
represent one standard deviation
one standard deviation over
adoption of windows nt
of windows nt for
windows nt for research
nt for research purposes
for research purposes and
research purposes and there
purposes and there is
and there is dedicated
there is dedicated academic
is dedicated academic relations
dedicated academic relations team
academic relations team whose
setting the value of
relations team whose single
the value of a
the details are deferred
team whose single task
details are deferred to
value of a field
are deferred to a
of a field in
deferred to a full
whose single task it
to a full report
a field in a
a full report on
single task it is
full report on g
field in a table
task it is to
report on g radient
it is to facilitate
is to facilitate the
to facilitate the technology
facilitate the technology transfer
the technology transfer between
technology transfer between microsoft
transfer between microsoft and
finally the client invokes
between microsoft and academia
the client invokes the
microsoft and academia and
client invokes the endtransaction
and academia and vice
invokes the endtransaction command
academia and vice versa
conclusion a number of
a number of interesting
number of interesting open
of interesting open questions
and the system responds
interesting open questions remain
the system responds with
open questions remain the
system responds with either
source licensing is very
questions remain the focus
responds with either a
remain the focus of
licensing is very liberal
the focus of our
with either a commit
is very liberal compared
focus of our continued
very liberal compared to
either a commit or
liberal compared to other
of our continued investigation
a commit or an
compared to other os
commit or an abort
to other os vendors
other os vendors and
how diverse are the
os vendors and several
diverse are the classes
committed transactions form a
are the classes of
transactions form a serializable
the classes of content
form a serializable execution
classes of content that
vendors and several institutions
of content that are
and several institutions are
content that are amenable
several institutions are involved
that are amenable to
institutions are involved in
tms are equipped with
are involved in active
are amenable to our
involved in active exchanges
amenable to our in
are equipped with predictors
in active exchanges with
equipped with predictors that
active exchanges with product
with predictors that foresee
exchanges with product and
predictors that foresee which
with product and research
that foresee which objects
product and research groups
foresee which objects a
and research groups within
how do we best
research groups within microsoft
which objects a transaction
do we best assess
objects a transaction is
we best assess the
a transaction is likely
best assess the effect
transaction is likely to
assess the effect of
is likely to access
the effect of such
likely to access on
effect of such transformations
to access on its
joint projects are in
access on its initiation
projects are in progress
of such transformations on
such transformations on stream
transformations on stream quality
joint papers are starting
papers are starting to
how should these transformations
are starting to appear
should these transformations be
starting to appear and
these transformations be expressed
to appear and academics
appear and academics frequently
and academics frequently present
academics frequently present cutting
frequently present cutting edge
in an implementation of
present cutting edge result
an implementation of the
cutting edge result to
implementation of the system
edge result to microsoft
and utilized by the
result to microsoft developers
utilized by the originating
to microsoft developers and
by the originating content
microsoft developers and researchers
of the system one
the originating content providers
the system one may
originating content providers to
system one may use
content providers to best
one may use multiple
providers to best balance
may use multiple oms
to best balance content
use multiple oms per
multiple oms per log
domain specificity with ease
specificity with ease of
dividing the log s
with ease of development
the log s object
log s object set
how can our overlay
or the other way
can our overlay respond
the other way around
our overlay respond to
overlay respond to churn
respond to churn among
to churn among g
have multiple logs report
churn among g radient
multiple logs report to
among g radient nodes
logs report to a
g radient nodes realistically
report to a single
radient nodes realistically low
to a single om
nodes realistically low in
realistically low in many
operating systems there is
low in many common
systems there is a
in many common cases
there is a direct
the choice depends on
is a direct impact
many common cases such
a direct impact of
common cases such as
direct impact of academia
cases such as video
impact of academia on
such as video streaming
choice depends on the
of academia on microsoft
depends on the throughput
academia on microsoft products
on the throughput of
the throughput of the
but higher in alternative
throughput of the specific
higher in alternative deployment
of the specific implementations
in alternative deployment scenarios
the specific implementations chosen
through involvement in the
specific implementations chosen for
involvement in the strategy
implementations chosen for each
in the strategy phases
chosen for each service
the strategy phases of
strategy phases of products
phases of products as
of products as well
in this paper we
products as well as
this paper we use
as well as through
paper we use a
well as through academic
how do we ensure
as through academic knowledge
do we ensure that
through academic knowledge transfer
we ensure that the
academic knowledge transfer into
ensure that the computational
knowledge transfer into products
that the computational intensity
transfer into products and
the computational intensity of
into products and design
computational intensity of our
products and design groups
intensity of our transformations
mapping for simplicity of
of our transformations do
for simplicity of presentation
our transformations do not
transformations do not place
do not place too
microsoft also provides research
not place too much
we now describe the
also provides research funding
now describe the operation
place too much load
describe the operation of
provides research funding for
the operation of acid
too much load on
research funding for some
much load on our
funding for some relevant
load on our g
for some relevant groups
on our g radient
some relevant groups and
our g radient overlay
relevant groups and fellowship
g radient overlay nodes
groups and fellowship and
and fellowship and research
we start with an
fellowship and research internships
start with an overview
and research internships for
with an overview of
research internships for students
an overview of the
overview of the system
of the system s
the system s structure
g radient contributes a
system s structure in
summary four years of
radient contributes a novel
s structure in section
four years of research
contributes a novel platform
years of research on
a novel platform for
of research on windows
novel platform for continued
research on windows nt
platform for continued study
on windows nt have
for continued study and
windows nt have taught
continued study and progress
nt have taught us
study and progress to
have taught us that
and progress to ever
taught us that we
progress to ever more
us that we made
to ever more effective
that we made the
ever more effective delivery
we made the right
more effective delivery mechanisms
made the right choice
and proceed to describe
the right choice in
proceed to describe the
right choice in leaving
to describe the algorithm
choice in leaving the
describe the algorithm in
in leaving the unix
the algorithm in section
leaving the unix behind
windows nt is an
nt is an exiting
years ahead of its
ahead of its competition
om for each shard
and which tms are
which tms are available
in its implementation and
its implementation and in
implementation and in the
any client can access
and in the actual
client can access any
in the actual services
can access any tm
the actual services offered
access any tm for
any tm for any
tm for any given
for any given transaction
it took quite some
took quite some time
other than the logs
quite some time to
some time to reach
time to reach the
to reach the same
server role assignment may
reach the same level
role assignment may be
the same level of
assignment may be inconsistent
same level of knowledge
level of knowledge and
of knowledge and insight
knowledge and insight we
and insight we used
insight we used to
we used to have
used to have of
to have of unix
have of unix systems
is supposed to be
but now that we
supposed to be managed
now that we have
to be managed by
bandwidth multicast in cooperative
be managed by a
that we have arrived
managed by a single
multicast in cooperative environments
we have arrived at
by a single om
have arrived at that
arrived at that same
at that same knowledge
that same knowledge point
is it clear that
it clear that our
clear that our research
that our research is
our research is making
research is making progress
is making progress faster
making progress faster than
progress faster than ever
at a given time
faster than ever before
but this may change
working with windows nt
this may change due
with windows nt requires
may change due to
windows nt requires certain
change due to an
nt requires certain level
due to an unjustified
requires certain level of
to an unjustified crash
certain level of resilience
an unjustified crash suspicion
unjustified crash suspicion whereupon
crash suspicion whereupon an
suspicion whereupon an object
not because of flaws
because of flaws in
of flaws in the
flaws in the operating
in the operating system
but because of the
because of the zealous
of the zealous attacks
the zealous attacks by
zealous attacks by colleagues
attacks by colleagues and
by colleagues and other
may temporarily be managed
colleagues and other researchers
temporarily be managed by
be managed by two
managed by two oms
publishing papers about research
papers about research performed
about research performed on
approaching the zettabyte era
research performed on windows
performed on windows nt
on windows nt is
cisco visual networking index
windows nt is still
nt is still quite
is still quite difficult
that do not know
still quite difficult as
do not know of
quite difficult as many
not know of one
difficult as many of
know of one another
as many of our
many of our peer
of our peer still
our peer still believe
peer still believe that
still believe that no
believe that no good
that no good research
rain uses log servers
no good research can
uses log servers for
good research can be
log servers for reliable
research can be performed
servers for reliable storage
can be performed on
be performed on windows
performed on windows nt
each log server provides
log server provides a
server provides a sequentially
we hope that eventually
provides a sequentially consistent
hope that eventually the
a sequentially consistent log
that eventually the advanced
sequentially consistent log object
eventually the advanced technical
the advanced technical nature
advanced technical nature of
technical nature of the
nature of the operating
of the operating system
the operating system will
operating system will prevail
system will prevail in
will prevail in the
prevail in the discussion
global mobile data traffic
and that we can
mobile data traffic forecast
update operations are linearizable
data traffic forecast update
that we can have
we can have a
can have a community
have a community where
but reads may return
a community where research
reads may return outdated
community where research results
may return outdated results
where research results can
research results can be
results can be shared
can be shared without
be shared without sarcasm
shared without sarcasm or
without sarcasm or the
sarcasm or the risk
multiple machines may append
or the risk of
machines may append entries
the risk of igniting
may append entries to
risk of igniting yet
append entries to a
of igniting yet another
entries to a log
igniting yet another holy
yet another holy war
machines may register to
may register to the
register to the log
the log then sends
log then sends to
then sends to each
sends to each all
to each all entries
from the first one
the first one in
first one in the
one in the log
and then new entries
then new entries as
new entries as they
entries as they arrive
an om may instruct
om may instruct the
may instruct the log
instruct the log to
the log to truncate
log to truncate its
to truncate its prefix
algorithm we now describe
we now describe the
now describe the acid
we explain the reservation
explain the reservation and
the reservation and certification
reservation and certification protocol
multicast routing in datagram
routing in datagram internetworks
in datagram internetworks and
datagram internetworks and extended
internetworks and extended lans
acm transactions on computer
transactions on computer systems
then discuss prediction errors
a transaction begins with
transaction begins with the
begins with the tm
with the tm receiving
the tm receiving a
tm receiving a begin
transaction instruction from the
instruction from the client
the tm assigns it
tm assigns it a
assigns it a unique
it a unique txnid
and predicts which objects
expert testimony of professor
predicts which objects the
testimony of professor david
which objects the transaction
of professor david j
objects the transaction will
the transaction will access
it interrogates the oms
interrogates the oms about
the oms about all
oms about all these
about all these objects
and they respond with
they respond with the
respond with the latest
with the latest unreserved
the latest unreserved timestamp
latest unreserved timestamp of
unreserved timestamp of each
timestamp of each object
the tm chooses a
tm chooses a timestamp
chooses a timestamp larger
a timestamp larger than
timestamp larger than maximum
larger than maximum among
than maximum among the
maximum among the responses
and asks the oms
asks the oms to
the oms to reserve
oms to reserve the
to reserve the objects
reserve the objects with
the objects with this
objects with this timestamp
with this timestamp to
this timestamp to txnid
the oms confirm the
oms confirm the reservation
confirm the reservation if
the reservation if no
reservation if no concurrent
if no concurrent tm
no concurrent tm has
concurrent tm has reserved
tm has reserved a
has reserved a larger
reserved a larger timestamp
a larger timestamp in
larger timestamp in the
timestamp in the meantime
the tm then proceeds
tm then proceeds to
then proceeds to serve
proceeds to serve transaction
to serve transaction operations
serve transaction operations by
transaction operations by routing
operations by routing them
by routing them to
routing them to the
them to the appropriate
to the appropriate oms
each operation is sent
operation is sent to
is sent to the
sent to the om
to the om in
the om in charge
om in charge of
in charge of the
charge of the object
an example flow of
example flow of the
flow of the algorithm
and analysis of a
analysis of a peer
along with the txnid
the oms order accesses
oms order accesses based
order accesses based on
accesses based on timestamp
based on timestamp reservations
and respond only when
respond only when the
only when the correct
when the correct version
the correct version is
correct version is available
each committed transaction is
committed transaction is assigned
transaction is assigned a
is assigned a timestamp
when reading an object
the timestamp of the
timestamp of the latest
of the latest transaction
the latest transaction that
latest transaction that wrote
transaction that wrote this
that wrote this object
wrote this object is
this object is returned
object is returned to
is returned to the
returned to the tm
the transaction s timestamp
transaction s timestamp is
uwin unix for windows
s timestamp is chosen
timestamp is chosen to
is chosen to be
chosen to be larger
to be larger than
the usenix windows nt
be larger than the
usenix windows nt workshop
larger than the largest
than the largest timestamp
the largest timestamp returned
largest timestamp returned by
timestamp returned by its
returned by its operations
and not larger than
not larger than its
larger than its reserved
than its reserved timestamp
once a tm receives
a tm receives an
tm receives an end
transaction instruction from a
instruction from a client
it notifies the transaction
notifies the transaction s
the transaction s oms
scaling virtual worlds with
virtual worlds with a
worlds with a physical
detailing the transaction s
with a physical metaphor
the transaction s timestamp
transaction s timestamp and
s timestamp and log
the logs in charge
logs in charge of
in charge of the
charge of the shards
of the shards it
the shards it touched
when it receives such
it receives such a
receives such a notification
an om appends to
om appends to its
appends to its log
to its log an
its log an entry
log an entry consisting
an entry consisting of
entry consisting of the
consisting of the txnid
such logs may be
logs may be implemented
may be implemented with
be implemented with various
implemented with various techniques
from smr to log
smr to log chains
th edition with source
edition with source code
we abstract this write
set with the read
with the read timestamps
and assume highly available
assume highly available logs
set with written values
action should be either
should be either committed
be either committed or
either committed or aborted
committed or aborted in
or aborted in all
aborted in all its
in all its logs
and therefore cannot be
therefore cannot be removed
cannot be removed from
be removed from any
removed from any of
from any of them
any of them before
of them before the
them before the result
before the result is
the result is published
the committing tm appends
committing tm appends a
tm appends a gc
appends a gc entry
a gc entry to
gc entry to all
entry to all the
to all the transaction
all the transaction s
the transaction s logs
transaction s logs after
s logs after receiving
logs after receiving an
after receiving an acknowledgement
receiving an acknowledgement that
an acknowledgement that they
acknowledgement that they all
that they all registered
they all registered the
all registered the transaction
registered the transaction s
the transaction s result
an om can invoke
om can invoke log
can invoke log prefix
invoke log prefix truncation
log prefix truncation if
prefix truncation if the
truncation if the prefix
if the prefix was
the prefix was summarized
and all its transactions
all its transactions have
its transactions have corresponding
transactions have corresponding gc
have corresponding gc entries
then waits for the
waits for the entry
for the entry to
the entry to appear
entry to appear in
to appear in the
appear in the log
a platform for distributed
platform for distributed service
for distributed service deployment
distributed service deployment in
service deployment in end
a transaction is committed
deployment in end user
transaction is committed if
in end user homes
is committed if and
the design and implementation
committed if and only
design and implementation of
if and only if
and implementation of the
and only if it
only if it is
if it is written
it is written to
is written to all
written to all logs
and it does not
it does not conflict
does not conflict with
not conflict with previous
conflict with previous transactions
with previous transactions on
previous transactions on any
transactions on any of
on any of them
conflicts are violations of
are violations of read
read or writewrite order
each om checks for
om checks for local
checks for local conflicts
for local conflicts by
local conflicts by checking
conflicts by checking timestamps
by checking timestamps in
checking timestamps in the
timestamps in the prefix
in the prefix of
the prefix of the
prefix of the log
of the log up
the log up to
log up to the
up to the transaction
to the transaction entry
and sends its local
sends its local result
to the calling tm
if all return success
then the transaction has
the transaction has committed
otherwise it has aborted
the tm notifies the
what s new in
tm notifies the client
s new in windows
notifies the client of
the client of the
client of the transaction
of the transaction result
the transaction result and
transaction result and instructs
result and instructs the
and instructs the oms
instructs the oms to
the oms to place
oms to place this
to place this result
place this result in
this result in the
result in the logs
the oms notify the
oms notify the tm
notify the tm once
the tm once the
tm once the results
once the results are
the results are logged
robustness in case of
in case of a
case of a tm
of a tm or
a tm or om
tm or om crash
or a missing result
a missing result or
missing result or gc
result or gc entry
due to message loss
another tm may read
tm may read the
may read the transaction
read the transaction entry
the transaction entry in
transaction entry in one
entry in one of
in one of the
one of the logs
and continue the certification
continue the certification and
the certification and gc
certification and gc process
if a tm places
a tm places a
tm places a transaction
places a transaction entry
a transaction entry in
transaction entry in a
entry in a strict
in a strict subset
a strict subset of
strict subset of the
subset of the transaction
of the transaction s
the transaction s log
transaction s log set
when another tm is
another tm is instructed
tm is instructed to
is instructed to fix
instructed to fix this
it cannot tell whether
cannot tell whether the
tell whether the original
whether the original tm
the original tm is
original tm is crashed
tm is crashed or
is crashed or slow
we introduce poison entries
the fixing tm places
fixing tm places a
tm places a poison
places a poison entry
a poison entry in
poison entry in the
entry in the logs
in the logs that
the logs that miss
logs that miss the
that miss the original
miss the original entry
a poison is interpreted
poison is interpreted as
is interpreted as a
interpreted as a transaction
as a transaction entry
a transaction entry with
transaction entry with a
entry with a conflict
the original entry may
original entry may either
entry may either arrive
may either arrive eventually
either arrive eventually or
arrive eventually or not
and the following are
the following are ignored
any tm can therefore
tm can therefore observe
can therefore observe the
therefore observe the log
observe the log and
the log and consistently
log and consistently determine
and consistently determine the
consistently determine the state
determine the state of
the state of the
state of the transaction
without a race hazard
prediction errors if there
errors if there are
nick vasilatos and werner
if there are no
vasilatos and werner vogels
there are no prediction
are no prediction errors
do you need source
you need source with
need source with that
panel at the usenix
at the usenix windows
the usenix windows nt
usenix windows nt workshop
there are no aborts
if the transaction accesses
the transaction accesses an
transaction accesses an object
accesses an object that
an object that was
object that was not
that was not predicted
this object has no
object has no reserved
has no reserved version
no reserved version for
reserved version for it
accessing it can therefore
it can therefore result
can therefore result in
therefore result in a
result in a conflict
in a conflict of
a conflict of the
conflict of the transaction
of the transaction or
the transaction or of
transaction or of the
or of the following
of the following ones
no conflict would occur
but if one does
if one does it
one does it will
does it will be
it will be detected
will be detected at
be detected at certification
detected at certification time
summary in usenix login
and result in an
result in an abort
in an abort of
an abort of a
abort of a transaction
rx for data center
for data center communication
performance may be slightly
data center communication scalability
may be slightly reduced
but consistency is maintained
if a transaction does
a transaction does not
transaction does not access
does not access an
not access an object
access an object that
an object that was
object that was predicted
the tm must still
tm must still release
must still release the
still release the reservation
release the reservation when
the reservation when the
reservation when the transaction
when the transaction ends
this reservation might slow
reservation might slow the
might slow the processing
unix application portability to
slow the processing of
application portability to windows
the processing of other
portability to windows nt
processing of other transactions
to windows nt via
of other transactions that
windows nt via an
other transactions that wait
nt via an alternative
transactions that wait for
via an alternative environment
that wait for its
an alternative environment subsystem
wait for its release
the usenix windows nt
but would not break
usenix windows nt workshop
would not break consistency
if a tm is
a tm is suspected
tm is suspected as
is suspected as failed
its reservations are revoked
this may harm performance
but cannot break consistency
evaluation we evaluate acid
rain by comparing its
by comparing its performance
comparing its performance to
its performance to the
performance to the classical
to the classical approach
the classical approach that
classical approach that does
approach that does not
that does not use
does not use prediction
not use prediction and
use prediction and compare
prediction and compare its
and compare its certification
compare its certification protocol
its certification protocol with
certification protocol with other
protocol with other certification
with other certification schemes
we use a custom
simulating each of the
each of the agents
of the agents in
the agents in the
agents in the system
in the system clients
live streaming with utilities
our workloads are an
workloads are an adaptation
are an adaptation of
an adaptation of the
adaptation of the transactional
of the transactional ycsb
the transactional ycsb specification
protect the future of
the future of computing
future of computing technology
based on the original
each transaction has a
transaction has a set
has a set of
a set of read
update operations spread along
operations spread along its
spread along its execution
object accesses follow one
accesses follow one of
follow one of two
one of two different
of two different random
two different random distributions
an architecture for scalable
architecture for scalable and
for scalable and fault
where each object is
each object is chosen
object is chosen uniformly
is chosen uniformly at
chosen uniformly at random
gc logs are truncated
logs are truncated to
are truncated to conserve
truncated to conserve resources
to conserve resources and
conserve resources and to
resources and to reduce
and to reduce log
to reduce log replay
reduce log replay time
log replay time on
replay time on om
time on om recovery
each om occasionally summarizes
om occasionally summarizes the
occasionally summarizes the log
summarizes the log prefix
and places this summary
places this summary in
this summary in the
summary in the log
the presence of a
presence of a summary
of a summary of
a summary of the
summary of the log
of the log up
the log up to
log up to a
up to a certain
to a certain entry
a certain entry is
certain entry is not
entry is not sufficient
is not sufficient to
not sufficient to allow
sufficient to allow truncation
to allow truncation at
allow truncation at that
truncation at that entry
this reason is that
reason is that truncation
is that truncation must
that truncation must not
truncation must not break
must not break transaction
not break transaction certification
prediction our first test
our first test scenario
first test scenario imposes
test scenario imposes a
scenario imposes a load
imposes a load substantially
a load substantially below
load substantially below the
substantially below the system
below the system s
the system s capacity
system s capacity with
each transaction reads and
transaction reads and writes
the simulation is faithful
simulation is faithful to
is faithful to the
faithful to the algorithm
with the exception of
the exception of a
exception of a small
of a small shortcut
a small shortcut oms
small shortcut oms grant
shortcut oms grant reservations
oms grant reservations by
grant reservations by arrival
reservations by arrival time
by arrival time rather
arrival time rather than
time rather than by
rather than by timestamp
this results in deadlocks
results in deadlocks in
in deadlocks in high
deadlocks in high contention
in high contention scenarios
and these are resolved
these are resolved with
are resolved with timeouts
first we vary prediction
we vary prediction accuracy
the average ratio of
average ratio of objects
ratio of objects the
of objects the predictor
objects the predictor guesses
the predictor guesses out
predictor guesses out of
guesses out of the
out of the set
of the set the
the set the transaction
set the transaction eventually
the transaction eventually accesses
is equivalent to no
equivalent to no prediction
to no prediction and
no prediction and no
prediction and no reservation
and an accuracy of
means predicting all accesses
transparent error correction for
error correction for lambda
correction for lambda networks
for lambda networks mahesh
lambda networks mahesh balakrishnan
process communication primitives for
communication primitives for programming
increasing contention by decreasing
primitives for programming distributed
contention by decreasing the
for programming distributed systems
by decreasing the number
programming distributed systems robbert
decreasing the number of
distributed systems robbert van
the number of objects
systems robbert van renesse
department of computer science
of computer science cornell
computer science cornell university
science cornell university category
representation the following position
the following position paper
following position paper describes
load with a hot
position paper describes a
paper describes a new
describes a new interprocess
a new interprocess communication
primitive that is designed
that is designed to
is designed to make
designed to make it
to make it easier
make it easier to
it easier to program
easier to program distributed
to program distributed algorithms
it is largely based
is largely based on
largely based on my
based on my experience
on my experience in
my experience in implementing
experience in implementing algorithms
in implementing algorithms such
implementing algorithms such as
algorithms such as distributed
such as distributed consensus
abstract the global network
the global network of
global network of datacenters
network of datacenters is
of datacenters is emerging
increasing contention by increasing
datacenters is emerging as
contention by increasing the
is emerging as an
by increasing the hot
emerging as an important
as an important distributed
an important distributed systems
important distributed systems paradigm
subject to your evaluation
distributed systems paradigm commodity
to your evaluation of
systems paradigm commodity clusters
your evaluation of my
paradigm commodity clusters running
evaluation of my proposal
commodity clusters running high
commit rate drops as
rate drops as contention
i would be happy
drops as contention rises
would be happy to
be happy to present
happy to present this
to present this idea
present this idea at
this idea at the
accurate prediction reduces or
idea at the workshop
prediction reduces or even
reduces or even eliminates
speed lambda networks across
or even eliminates this
lambda networks across hundreds
even eliminates this drop
networks across hundreds of
ipc allows processes to
across hundreds of milliseconds
allows processes to share
hundreds of milliseconds of
processes to share information
of milliseconds of network
to share information and
milliseconds of network latency
share information and to
information and to synchronize
and to synchronize actions
in highest contention scenarios
packet loss on long
even with moderate prediction
with moderate prediction accuracy
haul networks can cripple
there are two classes
networks can cripple application
are two classes of
can cripple application performance
two classes of ipc
we obtain significant improvement
cripple application performance a
obtain significant improvement over
application performance a loss
significant improvement over the
performance a loss rate
improvement over the classical
a loss rate of
over the classical approach
is sufficient to reduce
mc has processes communicate
sufficient to reduce tcp
has processes communicate send
processes communicate send and
communicate send and receive
we define slack to
send and receive messages
define slack to be
ip throughput by an
slack to be the
throughput by an order
to be the average
by an order of
be the average ratio
an order of magnitude
while sm allows processes
order of magnitude on
the average ratio between
of magnitude on a
sm allows processes to
average ratio between the
allows processes to share
ratio between the number
processes to share data
between the number of
to share data directly
the number of accesses
share data directly while
number of accesses predicted
data directly while synchronizing
of accesses predicted and
directly while synchronizing using
accesses predicted and the
while synchronizing using such
predicted and the number
synchronizing using such primitives
and the number of
using such primitives as
the number of objects
such primitives as mutexes
number of objects accessed
primitives as mutexes and
of objects accessed by
as mutexes and condition
objects accessed by the
mutexes and condition variables
accessed by the transaction
maelstrom is an edge
is an edge appliance
an edge appliance that
edge appliance that masks
appliance that masks packet
if a transaction accesses
that masks packet loss
masks packet loss transparently
packet loss transparently and
where processes are physically
loss transparently and quickly
processes are physically separated
transparently and quickly from
and quickly from inter
mc is dominant as
is dominant as e
dominant as e orts
then with a slack
as e orts to
with a slack of
e orts to support
aggregating traffic for high
orts to support the
to support the sm
support the sm paradigm
the sm paradigm have
sm paradigm have not
paradigm have not been
speed encoding and using
have not been successful
encoding and using a
and using a new
using a new forward
a new forward error
new forward error correction
examples of sm include
forward error correction scheme
of sm include tcp
error correction scheme to
sm include tcp connections
correction scheme to handle
it would reserve another
scheme to handle bursty
to handle bursty loss
introduction the emergence of
the emergence of commodity
emergence of commodity clusters
the mc and sm
of commodity clusters and
now with uniform random
mc and sm paradigms
with uniform random load
commodity clusters and datacenters
uniform random load and
and sm paradigms are
clusters and datacenters has
random load and a
sm paradigms are duals
load and a variable
and datacenters has enabled
and a variable number
paradigms are duals in
datacenters has enabled a
are duals in that
a variable number of
duals in that one
variable number of objects
in that one can
has enabled a new
that one can be
enabled a new class
one can be implememted
a new class of
can be implememted using
the effect of using
be implememted using the
new class of globally
effect of using a
class of globally distributed
implememted using the other
of globally distributed highperformance
of using a perfect
globally distributed highperformance applications
using a perfect predictor
distributed highperformance applications that
highperformance applications that coordinate
but they also each
applications that coordinate over
they also each have
that coordinate over vast
also each have their
coordinate over vast geographical
each have their advantages
over vast geographical distances
have their advantages and
their advantages and disadvantages
advantages and disadvantages when
and disadvantages when compared
disadvantages when compared with
when compared with one
compared with one another
with predictors that overpredict
predictors that overpredict by
a financial firm s
that overpredict by factors
financial firm s new
it is useful to
firm s new york
is useful to consider
s new york city
overpredict by factors of
new york city datacenter
useful to consider how
york city datacenter may
to consider how distributed
city datacenter may receive
consider how distributed algorithms
datacenter may receive real
how distributed algorithms such
distributed algorithms such as
algorithms such as replication
time updates from a
updates from a stock
from a stock exchange
a stock exchange in
the impact of overprediction
stock exchange in switzerland
impact of overprediction is
of overprediction is surprisingly
overprediction is surprisingly minor
conduct financial transactions with
financial transactions with banks
transactions with banks in
a finding that should
with banks in asia
typically it has much
it has much to
has much to do
much to do with
to do with progress
cache data in london
data in london for
in london for locality
london for locality and
in order for some
for locality and mirror
order for some process
locality and mirror it
for some process to
and mirror it to
some process to be
mirror it to kansas
process to be able
it to kansas for
to be able to
to kansas for disaster
be able to make
able to make a
to make a transition
it needs to know
needs to know that
to interconnect these bandwidth
to know that one
know that one or
that one or more
one or more other
or more other processes
hungry datacenters across the
ordering transactions in advance
datacenters across the globe
more other processes have
transactions in advance reduces
other processes have reached
in advance reduces conflicts
processes have reached a
organizations are increasingly deploying
have reached a particular
advance reduces conflicts and
reached a particular milestone
are increasingly deploying private
reduces conflicts and increases
increasingly deploying private lambda
conflicts and increases commit
deploying private lambda networks
and increases commit ratio
and some data associated
some data associated with
data associated with that
associated with that milestone
high conflict rates occur
conflict rates occur without
rates occur without with
occur without with uniform
without with uniform access
with uniform access to
uniform access to a
access to a small
to a small number
a small number of
a new leader in
small number of objects
new leader in paxos
leader in paxos needs
in paxos needs to
paxos needs to know
needs to know that
to know that a
know that a quorum
that a quorum of
and high probability of
high probability of accessing
a quorum of acceptors
probability of accessing a
of accessing a hotzone
quorum of acceptors have
raw bandwidth is ubiquitous
of acceptors have progressed
bandwidth is ubiquitous and
acceptors have progressed to
is ubiquitous and cheaply
have progressed to its
ubiquitous and cheaply available
progressed to its proposed
and cheaply available in
to its proposed ballot
cheaply available in the
its proposed ballot and
available in the form
proposed ballot and it
in the form of
even inaccurate prediction is
the form of existing
inaccurate prediction is significant
ballot and it needs
prediction is significant in
form of existing dark
is significant in high
and it needs to
significant in high contention
of existing dark fiber
it needs to know
needs to know what
to know what the
know what the highest
compared to the the
what the highest accepted
to the the classical
the highest accepted proposals
the the classical approach
highest accepted proposals from
accepted proposals from those
proposals from those acceptors
running and maintaining high
from those acceptors are
many if not all
if not all distributed
not all distributed algorithms
free networks over this
all distributed algorithms can
networks over this fiber
distributed algorithms can be
over this fiber is
algorithms can be cleanly
this fiber is difficult
can be cleanly expressed
fiber is difficult and
be cleanly expressed this
commit ratio is affected
cleanly expressed this way
is difficult and expensive
ratio is affected if
is affected if the
affected if the predictor
if the predictor reserves
as a collection of
the predictor reserves unnecessary
a collection of transition
predictor reserves unnecessary objects
collection of transition specifications
reserves unnecessary objects by
capacity optical links are
unnecessary objects by a
optical links are almost
objects by a factor
links are almost never
by a factor of
are almost never congested
a factor of slack
of transition specifications that
transition specifications that specify
specifications that specify under
they drop packets for
that specify under which
drop packets for numerous
specify under which conditions
packets for numerous reasons
under which conditions they
for numerous reasons dirty
which conditions they are
conditions they are enabled
they are enabled and
are enabled and what
enabled and what state
and what state they
what state they need
note that when all
state they need from
that when all accesses
they need from other
when all accesses are
need from other processes
all accesses are to
accesses are to the
are to the hot
to the hot zone
note the similarity to
the similarity to knowledge
while the sm paradigm
the sm paradigm seems
sm paradigm seems the
paradigm seems the best
seems the best fit
the best fit for
best fit for this
fit for this model
for this model of
this model of distributed
model of distributed algorithms
the paradigm is hard
commit rates are lower
paradigm is hard to
rates are lower with
is hard to make
are lower with imperfect
hard to make efficient
lower with imperfect prediction
with imperfect prediction than
imperfect prediction than in
prediction than in the
than in the uniform
in the uniform random
the uniform random case
uniform random case with
and scalable in a
scalable in a physically
in a physically distributed
a physically distributed system
it is notoriously errorprone
is notoriously errorprone as
notoriously errorprone as programmers
errorprone as programmers are
as programmers are having
programmers are having difficulty
are having difficulty utilizing
having difficulty utilizing the
difficulty utilizing the synchronization
utilizing the synchronization primitives
for example and in
the synchronization primitives correctly
example and in different
and in different patterns
the mc paradigm can
ranging from singleton drops
mc paradigm can be
from singleton drops to
paradigm can be used
singleton drops to extended
can be used instead
drops to extended bursts
be used instead but
used instead but is
instead but is awkward
but is awkward and
is awkward and error
this is because all
is because all accesses
because all accesses to
prone as well it
all accesses to the
accesses to the hot
as well it requires
well it requires the
it requires the programmer
zone go through a
requires the programmer to
go through a single
the programmer to figure
through a single om
a single om that
programmer to figure out
single om that becomes
om that becomes a
to figure out which
that becomes a bottleneck
figure out which processes
out which processes should
which processes should send
on the bright side
processes should send which
should send which data
send which data to
which data to which
since object access conflicts
data to which destinations
object access conflicts occur
congestion loss has been
to which destinations at
loss has been observed
access conflicts occur only
has been observed on
which destinations at which
been observed on long
conflicts occur only at
destinations at which times
occur only at a
at which times in
only at a single
which times in order
at a single shard
times in order to
haul networks as well
in order to ensure
order to ensure that
to ensure that recipients
ensure that recipients of
the reservations prevent deadlocks
that recipients of this
reservations prevent deadlocks and
recipients of this data
prevent deadlocks and result
of this data can
deadlocks and result in
this data can make
and result in perfect
data can make progress
result in perfect commit
in perfect commit ratio
perfect commit ratio with
commit ratio with perfect
ratio with perfect prediction
sometimes messages are lost
messages are lost if
are lost if the
lost if the receiver
if the receiver starts
the receiver starts execution
receiver starts execution after
starts execution after the
execution after the sender
where some of the
after the sender has
some of the objects
the sender has started
of the objects belong
sender has started sending
the objects belong to
has started sending messages
objects belong to a
started sending messages to
belong to a so
sending messages to it
to a so called
a so called hot
and each access is
each access is either
access is either to
is either to the
either to the hot
pray semantics of connectionless
semantics of connectionless or
of connectionless or non
or outside of it
blocking messaging primitives is
messaging primitives is one
primitives is one example
chosen uniformly within each
uniformly within each zone
often needless information is
needless information is sent
information is sent as
is sent as more
sent as more recent
as more recent information
more recent information makes
we set an average
recent information makes old
set an average transaction
information makes old messages
an average transaction per
makes old messages obsolete
average transaction per unit
using paxos again as
paxos again as an
again as an example
in the stream of
the stream of values
stream of values that
of values that acceptors
values that acceptors accept
and transactions arrivals are
transactions arrivals are governed
arrivals are governed by
only the most recent
are governed by a
the most recent one
governed by a poisson
most recent one is
by a poisson process
recent one is of
a poisson process with
one is of interest
poisson process with the
process with the required
ms w n s
with the required tput
w n s e
n s e figure
but most mc implementations
most mc implementations will
mc implementations will carefully
implementations will carefully deliver
will carefully deliver each
carefully deliver each and
deliver each and every
each and every one
example lambda network tional
lambda network tional lambdarail
we are unaware of
are unaware of work
unaware of work that
delaying delivery of the
of work that uses
delivery of the important
work that uses prediction
of the important information
that uses prediction to
the important information until
uses prediction to order
important information until all
prediction to order distributed
information until all obsoleted
to order distributed transactions
until all obsoleted information
order distributed transactions before
all obsoleted information has
distributed transactions before certification
obsoleted information has been
information has been delivered
has been delivered as
been delivered as well
this leads to wasting
leads to wasting resources
potential deadlock situations due
deadlock situations due to
situations due to flow
uses static analysis to
due to flow control
static analysis to allow
to flow control leading
analysis to allow separate
flow control leading to
to allow separate workers
control leading to deadly
allow separate workers to
leading to deadly embrace
separate workers to process
workers to process independent
to process independent transactions
process independent transactions without
independent transactions without synchronization
and also obfuscates how
also obfuscates how the
obfuscates how the algorithms
how the algorithms work
rain s suggestive prediction
as has its crippling
has its crippling effect
its crippling effect on
crippling effect on commodity
gargamel determines the final
effect on commodity protocols
determines the final transaction
a new class of
the final transaction order
new class of ipc
motivating research into loss
and does not tolerate
that that tries to
does not tolerate false
that tries to combine
not tolerate false positive
tries to combine the
tolerate false positive prediction
to combine the best
false positive prediction errors
resistant data transfer protocols
combine the best features
the best features of
best features of sm
features of sm and
of sm and mc
it targets a different
from sm it inherits
targets a different setting
sm it inherits direct
a different setting than
it inherits direct access
different setting than acid
inherits direct access to
direct access to and
access to and synchro
nization on state rather
on state rather than
it is a fully
state rather than providing
is a fully replicated
rather than providing a
a fully replicated data
than providing a stream
fully replicated data store
providing a stream of
a stream of state
stream of state updates
while from mc it
from mc it inherits
with a centralized scheduler
mc it inherits an
it inherits an efficient
inherits an efficient implementation
an efficient implementation over
efficient implementation over the
implementation over the existing
over the existing physical
the existing physical infrastructure
the concept is that
for an increasing number
concept is that processes
an increasing number of
is that processes publish
increasing number of shards
that processes publish facts
we run multiple simulations
which are information about
run multiple simulations to
are information about milestones
multiple simulations to find
information about milestones they
simulations to find the
about milestones they have
to find the maximal
milestones they have reached
find the maximal tput
the maximal tput the
maximal tput the system
tput the system can
the system can handle
and subscribe to new
subscribe to new facts
conservative flow control mechanisms
a global log forms
global log forms a
flow control mechanisms designed
log forms a bottleneck
the ipc interface is
control mechanisms designed to
ipc interface is similar
interface is similar to
mechanisms designed to deal
is similar to topic
designed to deal with
to deal with the
deal with the systematic
with the systematic congestion
pc with smr tms
the systematic congestion of
with smr tms is
systematic congestion of the
smr tms is blocked
congestion of the commodity
tms is blocked by
of the commodity internet
is blocked by contention
the commodity internet react
blocked by contention much
commodity internet react too
by contention much earlier
internet react too sharply
contention much earlier than
react too sharply to
but there are several
too sharply to ephemeral
much earlier than acid
sharply to ephemeral loss
there are several important
to ephemeral loss on
are several important semantic
ephemeral loss on over
several important semantic differences
rain due to its
due to its longer
to its longer certification
its longer certification time
provisioned links a single
links a single packet
a single packet loss
single packet loss in
we briefly review here
packet loss in ten
briefly review here work
loss in ten thousand
review here work related
interface is as follows
here work related to
in ten thousand is
work related to acidrain
ten thousand is enough
related to acidrain s
thousand is enough to
to acidrain s certification
is enough to reduce
acidrain s certification protocol
enough to reduce tcp
it will be the
one approach for certification
ip throughput to a
will be the publishers
throughput to a third
approach for certification is
to a third over
be the publishers that
for certification is to
the publishers that actively
certification is to use
a third over a
is to use a
publishers that actively try
to use a single
that actively try to
use a single highly
actively try to push
try to push new
to push new facts
push new facts to
new facts to the
facts to the subscribers
available service that orders
service that orders all
that orders all transactions
orders all transactions in
all transactions in the
transactions in the system
and one in a
one in a thousand
in a thousand drops
a thousand drops it
thousand drops it by
paxos leaders publish new
drops it by an
it by an order
leaders publish new ballots
by an order of
publish new ballots and
an order of magnitude
new ballots and push
ballots and push these
and push these to
push these to acceptors
these to acceptors as
to acceptors as acceptors
acceptors as acceptors do
as acceptors do not
acceptors do not necessarily
time applications are impacted
do not necessarily know
applications are impacted by
not necessarily know what
are impacted by the
necessarily know what the
impacted by the reliance
know what the set
by the reliance of
what the set of
the reliance of reliability
the set of leaders
reliance of reliability mechanisms
set of leaders is
of reliability mechanisms on
reliability mechanisms on acknowledgments
mechanisms on acknowledgments and
on acknowledgments and retransmissions
old ballots are automatically
a transaction commits if
ballots are automatically dropped
transaction commits if and
are automatically dropped from
limiting the latency of
automatically dropped from the
commits if and only
the latency of packet
if and only if
latency of packet recovery
dropped from the transmission
of packet recovery to
from the transmission queue
packet recovery to at
and only if it
recovery to at least
only if it has
to at least the
if it has no
at least the round
it has no conflicts
least the round trip
has no conflicts with
the round trip time
no conflicts with previous
it will be the
conflicts with previous committed
will be the subscribers
with previous committed transactions
be the subscribers that
the subscribers that actively
subscribers that actively poll
that actively poll the
actively poll the publishers
if delivery is sequenced
leaders and learners both
and learners both subscribe
each lost packet acts
learners both subscribe to
lost packet acts as
transaction rate is high
packet acts as a
both subscribe to acceptors
acts as a virtual
subscribe to acceptors accepting
as a virtual road
to acceptors accepting pvalues
acceptors accepting pvalues and
such a global service
accepting pvalues and poll
a global service becomes
pvalues and poll for
global service becomes a
and poll for these
service becomes a bottleneck
poll for these facts
block in the fifo
in the fifo channel
the fifo channel until
fifo channel until it
channel until it is
until it is recovered
our system has no
system has no such
has no such bottleneck
resistant protocols is not
protocols is not an
is not an alternative
not an alternative in
an alternative in corporate
alternative in corporate datacenters
as subscribers that su
subscribers that su ered
that su ered communication
where standardization is the
su ered communication loss
standardization is the key
ered communication loss due
is the key to
communication loss due to
the key to low
loss due to a
key to low and
due to a network
to low and predictable
serialized all transactions when
low and predictable maintenance
to a network partition
and predictable maintenance costs
all transactions when they
a network partition or
transactions when they enter
network partition or having
when they enter the
partition or having been
they enter the system
or having been temporarily
enter the system to
having been temporarily subscribe
the system to achieve
nei this work was
system to achieve a
this work was supported
to achieve a deterministic
work was supported in
achieve a deterministic order
was supported in part
supported in part by
in part by grants
part by grants from
by grants from afosr
despite nondeterministic operations the
nondeterministic operations the transactions
operations the transactions take
ther is eliminating loss
is eliminating loss events
they consider only stored
eliminating loss events on
consider only stored procedures
loss events on a
events on a network
on a network that
a network that could
network that could nsf
which enable this approach
that could nsf and
due to a user
could nsf and intel
to a user closing
nsf and intel corporation
a user closing a
user closing a laptop
whereas we address long
we address long running
address long running transactions
span thousands of miles
long running transactions and
running transactions and use
transactions and use prediction
and use prediction to
use prediction to infer
will the interface requires
prediction to infer an
the interface requires that
to infer an order
interface requires that the
requires that the fact
there is a need
that the fact type
is a need to
the fact type for
a need to link
fact type for a
need to link loss
type for a par
continue to poll publishers
to poll publishers to
poll publishers to receive
publishers to receive facts
to receive facts they
receive facts they have
facts they have ticular
they have ticular topic
side appliance locations of
have ticular topic is
appliance locations of packet
ticular topic is totally
locations of packet loss
topic is totally ordered
of packet loss receive
transactions are also serialized
are also serialized by
also serialized by a
serialized by a central
and those facts will
by a central service
side appliance receiver buffer
those facts will missed
appliance receiver buffer overflow
and then scheduled according
then scheduled according to
local recovery receiving end
scheduled according to this
all this is invisible
according to this global
this is invisible to
to this global order
is invisible to the
invisible to the core
to the core application
the core application be
core application be delivered
application be delivered in
be delivered in order
rain avoids a central
avoids a central service
kernel code no dropped
any data can be
code no dropped packets
data can be made
no dropped packets figure
can be made to
maelstrom communication path mask
but can be managed
communication path mask loss
can be managed through
path mask loss on
be managed through the
mask loss on the
managed through the contally
loss on the link
targets a different problem
through the contally ordered
the contally ordered by
contally ordered by tagging
ordered by tagging it
by tagging it with
tagging it with a
it with a sequence
with a sequence number
where it embraces non
because recovery delays for
recovery delays for lost
delays for lost packets
the hope is that
for lost packets translate
hope is that fact
determinism and separates execution
lost packets translate into
and separates execution from
packets translate into dramatic
separates execution from verification
translate into dramatic reductions
into dramatic reductions in
based ipc will simplify
dramatic reductions in application
ipc will simplify disbut
the result is somewhat
will simplify disbut often
result is somewhat analogous
simplify disbut often times
is somewhat analogous to
disbut often times facts
somewhat analogous to our
often times facts such
analogous to our separation
times facts such as
to our separation of
facts such as ballots
our separation of optimistic
such as ballots are
separation of optimistic ordering
as ballots are totally
because applications and os
of optimistic ordering and
ballots are totally ortributed
optimistic ordering and conservative
applications and os networking
ordering and conservative certification
are totally ortributed programming
and os networking stacks
totally ortributed programming and
os networking stacks in
ortributed programming and make
networking stacks in commodity
programming and make it
stacks in commodity datacenters
make it easier to
and make it easier
it easier to create
in commodity datacenters cannot
easier to create a
make it easier to
to create a practical
commodity datacenters cannot be
create a practical predictor
it easier to reason
datacenters cannot be rewritten
easier to reason dered
cannot be rewritten from
to reason dered already
be rewritten from scratch
certification scalability to evaluate
scalability to evaluate the
to evaluate the scalability
evaluate the scalability of
the scalability of acid
given a stream of
a stream of facts
rain s certification mechanism
stream of facts on
of facts on some
facts on some topic
is a promising solution
a promising solution for
we avoid prediction and
promising solution for reliability
avoid prediction and measure
solution for reliability over
about safety and liveness
for reliability over long
prediction and measure the
and measure the maximal
measure the maximal commit
the maximal commit rate
the argument for this
maximal commit rate it
argument for this is
commit rate it can
for this is only
rate it can accommodate
this is only the
it can accommodate with
is only the highest
can accommodate with an
accommodate with an increasing
with an increasing number
an increasing number of
increasing number of shards
most recent fact need
recent fact need be
fact need be delivered
need be delivered that
be delivered that the
delivered that the paradigm
packet recovery latency is
that the paradigm allows
recovery latency is independent
the paradigm allows the
latency is independent of
paradigm allows the programmer
is independent of the
allows the programmer to
independent of the rtt
the programmer to clearly
writes of objects chosen
of the rtt of
of objects chosen uniformly
the rtt of the
programmer to clearly eventually
objects chosen uniformly at
rtt of the link
chosen uniformly at random
uniformly at random from
at random from a
random from a small
while older facts can
from a small set
older facts can be
while fec codes have
facts can be dropped
a small set of
fec codes have been
codes have been used
have been used for
been used for decades
used for decades within
also specify transitions and
for decades within link
specify transitions and under
transitions and under which
and under which conditions
under which conditions they
which conditions they di
conditions they di erent
they di erent from
di erent from pub
faster commodity processors have
commodity processors have enabled
processors have enabled packet
level fec at end
if no more facts
no more facts are
more facts are enabled
facts are enabled without
are enabled without having
acidrain against two approaches
enabled without having to
without having to worry
having to worry much
to worry much about
worry much about how
more details in section
much about how are
about how are published
how are published but
are published but some
published but some process
but some process later
some process later subscribes
it these conditions are
smr tms is two
these conditions are discovered
phase commit with reliable
will eventually receive the
commit with reliable coordinators
eventually receive the most
receive the most recent
the most recent fact
assuming both publisher and
both publisher and subscriber
publisher and subscriber are
and subscriber are correct
global log is an
end fec is very
log is an architecture
fec is very attractive
is an architecture where
is very attractive for
an architecture where tms
very attractive for inter
these semantics are similar
architecture where tms submit
semantics are similar to
where tms submit all
are similar to the
tms submit all transactions
similar to the anti
submit all transactions to
all transactions to a
transactions to a single
to a single global
entropy style of gossip
a single global log
style of gossip protocols
single global log and
global log and check
easy to deploy and
log and check conflicts
to deploy and customize
and check conflicts on
but the underlying implementation
check conflicts on that
the underlying implementation can
conflicts on that single
underlying implementation can be
on that single log
and does not require
implementation can be anything
does not require specialized
not require specialized equipment
require specialized equipment in
specialized equipment in the
equipment in the network
there is also a
in the network linking
is also a control
the network linking the
also a control interface
network linking the datacenters
a control interface that
control interface that controls
interface that controls routing
that controls routing of
controls routing of facts
routing of facts for
of facts for a
facts for a particular
for a particular topic
host fec has two
has lower latency for
fec has two major
lower latency for a
has two major issues
latency for a given
two major issues first
for a given throughput
paxos acceptors subscribe to
acceptors subscribe to ballots
subscribe to ballots and
to ballots and to
ballots and to new
it s not transparent
and to new proposals
to new proposals from
new proposals from leaders
pc since its faster
since its faster certification
requiring modification of the
its faster certification reduces
modification of the end
faster certification reduces contention
when the leader publishes
the leader publishes one
leader publishes one of
publishes one of these
it has no bottleneck
has no bottleneck as
no bottleneck as with
bottleneck as with a
it is transmitted to
as with a global
is transmitted to all
with a global log
transmitted to all subscribers
that has less overhead
it s not necessarily
has less overhead in
s not necessarily rapid
less overhead in small
and the underlying communication
overhead in small scale
the underlying communication layer
underlying communication layer will
fec works best over
communication layer will continue
works best over high
layer will continue retransmission
will continue retransmission until
while the parameters we
continue retransmission until either
the parameters we choose
retransmission until either acknowledged
stable traffic rates and
parameters we choose are
until either acknowledged or
we choose are arbitrary
traffic rates and performs
either acknowledged or another
rates and performs poorly
acknowledged or another fact
and performs poorly if
or another fact renders
the trends are robust
another fact renders it
performs poorly if the
fact renders it obsolete
poorly if the data
if the data rate
the data rate in
choosing other parameters would
data rate in the
other parameters would provide
rate in the channel
parameters would provide similar
in the channel is
would provide similar trends
the channel is low
channel is low and
is low and sporadic
as in a single
in a single end
we present the maelstrom
present the maelstrom error
the maelstrom error correction
maelstrom error correction appliance
error correction appliance a
correction appliance a rack
appliance a rack of
a rack of proxies
rack of proxies residing
of proxies residing between
proxies residing between a
residing between a datacenter
between a datacenter and
a datacenter and its
datacenter and its wan
phase commit for transaction
and its wan link
commit for transaction certification
the downside of these
downside of these approaches
of these approaches compared
these approaches compared to
approaches compared to acid
rain is that they
is that they require
that they require a
they require a coordinator
maelstrom encodes fec packets
require a coordinator that
encodes fec packets over
a coordinator that performs
fec packets over traffic
coordinator that performs transactions
packets over traffic flowing
that performs transactions to
over traffic flowing through
performs transactions to be
traffic flowing through it
transactions to be highly
flowing through it and
to be highly available
through it and routes
it and routes them
and routes them to
routes them to a
them to a corresponding
this requires another consensus
to a corresponding appliance
a corresponding appliance at
corresponding appliance at the
appliance at the destination
at the destination datacenter
in addition to the
addition to the one
to the one at
the one at the
one at the shard
at the shard itself
which decodes them and
decodes them and recovers
them and recovers lost
and recovers lost data
maelstrom is completely transparent
is completely transparent it
completely transparent it does
transparent it does not
it does not require
does not require modification
not require modification of
require modification of end
related work our transaction
work our transaction ordering
our transaction ordering protocol
transaction ordering protocol is
host software and is
ordering protocol is inspired
software and is agnostic
protocol is inspired by
and is agnostic to
is inspired by a
is agnostic to the
inspired by a state
agnostic to the network
to the network connecting
the network connecting the
network connecting the datacenter
machine ordering mechanism suggested
ordering mechanism suggested by
mechanism suggested by lamport
it eliminates the dependence
eliminates the dependence of
the dependence of fec
dependence of fec recovery
swift institute swift institute
of fec recovery latency
institute swift institute working
fec recovery latency on
swift institute working paper
recovery latency on the
institute working paper no
latency on the data
on the data rate
the data rate in
data rate in any
rate in any single
in any single node
but we have generalized
we have generalized the
have generalized the protocol
generalized the protocol to
the protocol to work
protocol to work with
to work with arbitrary
work with arbitrary overlapping
node channel by encoding
with arbitrary overlapping par
channel by encoding over
by encoding over the
encoding over the aggregated
over the aggregated traffic
the aggregated traffic leaving
references the approaches of
aggregated traffic leaving the
the approaches of mdcc
traffic leaving the datacenter
maelstrom uses a new
uses a new encoding
a new encoding scheme
new encoding scheme called
encoding scheme called layered
scheme called layered interleaving
designed especially for time
sensitive packet recovery in
packet recovery in the
recovery in the presence
s dilemma ittay eyal
in the presence of
dilemma ittay eyal publication
the presence of bursty
ittay eyal publication date
presence of bursty loss
are close to acid
the contributions of this
contributions of this paper
of this paper are
this paper are as
paper are as follows
rain s certification mechanism
end fec for long
rain separates the om
separates the om abstraction
the om abstraction from
om abstraction from the
abstraction from the highly
distance communication between datacenters
electronic copy available at
and argue that the
argue that the rate
that the rate sensitivity
the rate sensitivity of
rate sensitivity of fec
leasing mechanism and fast
sensitivity of fec codes
mechanism and fast recovery
of fec codes and
fec codes and the
codes and the opacity
and the opacity of
we also address garbage
the opacity of their
also address garbage collection
opacity of their implementations
of their implementations present
their implementations present major
implementations present major obstacles
present major obstacles to
which cannot be done
major obstacles to their
cannot be done independently
obstacles to their usage
be done independently at
done independently at the
independently at the logs
a gateway appliance that
gateway appliance that transparently
appliance that transparently aggregates
that transparently aggregates traffic
transparently aggregates traffic and
aggregates traffic and encodes
traffic and encodes over
and encodes over the
encodes over the resulting
over the resulting high
we describe layered interleaving
a new fec scheme
new fec scheme used
fec scheme used by
the miner s dilemma
scheme used by maelstrom
miner s dilemma ittay
used by maelstrom where
s dilemma ittay eyal
by maelstrom where for
dilemma ittay eyal cornell
maelstrom where for constant
ittay eyal cornell university
where for constant encoding
eyal cornell university abstract
for constant encoding overhead
constant encoding overhead the
cornell university abstract an
encoding overhead the latency
university abstract an open
overhead the latency of
abstract an open distributed
the latency of packet
an open distributed system
latency of packet recovery
open distributed system can
of packet recovery degrades
distributed system can be
packet recovery degrades gracefully
system can be secured
recovery degrades gracefully as
can be secured by
degrades gracefully as losses
be secured by requiring
gracefully as losses get
secured by requiring participants
as losses get burstier
by requiring participants to
requiring participants to present
participants to present proof
to present proof of
present proof of work
we discuss implementation considerations
proof of work and
of work and rewarding
work and rewarding them
and rewarding them for
a new paradigm for
rewarding them for participation
new paradigm for building
we built two versions
paradigm for building scalable
built two versions of
for building scalable distributed
two versions of maelstrom
building scalable distributed systems
the bitcoin digital currency
bitcoin digital currency introduced
digital currency introduced this
one runs in user
currency introduced this mechanism
runs in user mode
which is adopted by
while the other runs
is adopted by almost
the other runs within
adopted by almost all
other runs within the
by almost all contemporary
runs within the linux
almost all contemporary digital
within the linux kernel
all contemporary digital currencies
contemporary digital currencies and
digital currencies and related
currencies and related services
we evaluate maelstrom on
evaluate maelstrom on emulab
a natural process leads
natural process leads participants
process leads participants of
leads participants of such
participants of such systems
of such systems to
such systems to form
systems to form pools
where members aggregate their
members aggregate their power
aggregate their power and
and show that it
their power and share
show that it provides
power and share the
that it provides near
and share the rewards
it provides near lossless
uses an architecture similar
provides near lossless tcp
an architecture similar to
architecture similar to our
similar to our certification
to our certification mechanism
experience with bitcoin shows
with bitcoin shows that
ip throughput and latency
bitcoin shows that the
throughput and latency over
shows that the largest
and latency over lossy
that the largest pools
but addresses minitransactions that
latency over lossy links
addresses minitransactions that are
the largest pools are
minitransactions that are submitted
largest pools are often
that are submitted as
pools are often open
are submitted as a
submitted as a whole
and recovers packets with
recovers packets with latency
packets with latency independent
allowing anyone to join
with latency independent of
with no attempt to
latency independent of the
no attempt to order
independent of the rtt
attempt to order potentially
of the rtt of
to order potentially conflicting
the rtt of the
it has long been
rtt of the link
order potentially conflicting transactions
has long been known
of the link and
long been known that
the link and the
been known that a
link and the rate
we address full transactions
known that a member
and the rate in
that a member can
the rate in any
a member can sabotage
rate in any single
member can sabotage an
where the clients sequentially
in any single channel
the clients sequentially access
can sabotage an open
clients sequentially access objects
sabotage an open pool
sequentially access objects before
an open pool by
access objects before ending
open pool by seemingly
objects before ending a
pool by seemingly joining
before ending a transaction
by seemingly joining it
seemingly joining it but
model our focus is
joining it but never
our focus is on
it but never sharing
and use prediction to
but never sharing its
focus is on pairs
never sharing its proofs
use prediction to order
sharing its proofs of
is on pairs of
its proofs of work
prediction to order them
on pairs of geographically
to order them in
pairs of geographically distant
order them in advance
of geographically distant datacenters
geographically distant datacenters that
the pool shares its
distant datacenters that coordinate
pool shares its revenue
datacenters that coordinate with
shares its revenue with
we believe our techniques
its revenue with the
that coordinate with each
revenue with the attacker
believe our techniques could
coordinate with each other
our techniques could be
with each other in
techniques could be used
each other in real
and so each of
could be used to
so each of its
be used to reduce
each of its participants
used to reduce abort
of its participants earns
to reduce abort rates
its participants earns less
reduce abort rates of
abort rates of systems
rates of systems using
this has long been
of systems using sinfonia
has long been a
systems using sinfonia or
we define and analyze
using sinfonia or a
long been a critical
sinfonia or a similar
define and analyze a
or a similar certification
been a critical distributed
and analyze a game
a similar certification mechanism
a critical distributed computing
analyze a game where
critical distributed computing paradigm
a game where pools
distributed computing paradigm in
game where pools use
computing paradigm in application
where pools use some
paradigm in application domains
pools use some of
in application domains such
use some of their
application domains such as
some of their participants
domains such as finance
of their participants to
such as finance and
their participants to infiltrate
as finance and aerospace
participants to infiltrate other
to infiltrate other pools
infiltrate other pools and
other pools and perform
pools and perform such
and perform such an
perform such an attack
similar requirements are arising
with any number of
requirements are arising across
any number of pools
are arising across the
arising across the board
across the board as
the board as globalized
board as globalized enterprises
as globalized enterprises rely
globalized enterprises rely on
enterprises rely on networks
rely on networks for
on networks for high
attacks is not a
is not a nash
speed communication and collaboration
not a nash equilibrium
we study the special
study the special cases
the most general case
the special cases where
most general case of
general case of inter
special cases where either
cases where either two
where either two pools
either two pools or
cluster communication is one
two pools or any
communication is one where
pools or any number
is one where any
or any number of
one where any node
any number of identical
where any node in
number of identical pools
any node in one
of identical pools play
node in one cluster
identical pools play the
in one cluster can
pools play the game
one cluster can communicate
play the game and
cluster can communicate with
the game and the
can communicate with any
game and the rest
communicate with any node
and the rest of
with any node in
the rest of the
any node in the
rest of the participants
node in the other
of the participants are
in the other cluster
the participants are uninvolved
we make no assumptions
make no assumptions about
no assumptions about the
in both of these
assumptions about the type
about the type of
both of these cases
the type of traffic
of these cases there
type of traffic flowing
these cases there exists
of traffic flowing through
traffic flowing through the
cases there exists an
flowing through the link
there exists an equilibrium
exists an equilibrium that
an equilibrium that constitutes
equilibrium that constitutes a
that constitutes a tragedy
constitutes a tragedy of
critical applications could send
applications could send dynamically
a tragedy of the
could send dynamically generated
send dynamically generated real
tragedy of the commons
of the commons where
the commons where the
commons where the participating
time data such as
where the participating pools
data such as stock
the participating pools attack
such as stock quotes
participating pools attack one
pools attack one another
attack one another and
one another and earn
another and earn less
financial transactions and battleground
and earn less than
transactions and battleground location
earn less than they
and battleground location updates
less than they would
than they would have
they would have if
would have if none
have if none had
if none had attacked
while enterprise applications could
enterprise applications could send
applications could send voip
could send voip streams
highly available storage for
available storage for interactive
storage for interactive services
ssh sessions and synchronous
sessions and synchronous file
the decision whether or
and synchronous file updates
decision whether or not
synchronous file updates between
whether or not to
file updates between offices
or not to attack
not to attack is
to attack is the
attack is the miner
is the miner s
the miner s dilemma
packet loss typically occurs
an instance of the
loss typically occurs at
instance of the iterative
typically occurs at two
of the iterative prisoner
occurs at two points
the iterative prisoner s
at two points in
iterative prisoner s dilemma
two points in an
points in an end
the game is played
game is played daily
is played daily by
played daily by the
daily by the active
by the active bitcoin
end communication path between
the active bitcoin pools
communication path between two
path between two datacenters
which apparently choose not
as shown in figure
apparently choose not to
choose not to attack
if this balance breaks
area network connecting them
network connecting them and
connecting them and at
the revenue of open
them and at the
revenue of open pools
and at the receiving
of open pools might
at the receiving end
open pools might diminish
making them unattractive to
them unattractive to participants
loss in the lambda
in the lambda link
the lambda link can
lambda link can occur
link can occur for
can occur for many
occur for many reasons
dirty or degraded fiber
is a digital currency
a digital currency that
digital currency that is
a transactional record manager
currency that is gaining
transactional record manager for
malfunctioning or misconfigured equipment
record manager for shared
that is gaining acceptance
manager for shared flash
low receiver power and
receiver power and burst
power and burst switching
and burst switching contention
burst switching contention are
switching contention are some
contention are some reasons
with an estimated market
an estimated market capitalization
estimated market capitalization of
market capitalization of over
a middleware for highperformance
middleware for highperformance transaction
for highperformance transaction processing
loss can also occur
can also occur at
bitcoin s security stems
also occur at receiving
s security stems from
occur at receiving endhosts
security stems from a
at receiving endhosts within
stems from a robust
receiving endhosts within the
from a robust incentive
endhosts within the destination
a robust incentive system
within the destination datacenter
participants are required to
these are usually cheap
are required to provide
are usually cheap commodity
required to provide expensive
usually cheap commodity machines
to provide expensive proofs
cheap commodity machines prone
provide expensive proofs of
commodity machines prone to
expensive proofs of work
machines prone to temporary
prone to temporary overloads
to temporary overloads that
temporary overloads that cause
and they are rewarded
overloads that cause packets
they are rewarded according
that cause packets to
are rewarded according to
cause packets to be
rewarded according to their
packets to be dropped
according to their efforts
to be dropped by
be dropped by the
dropped by the kernel
by the kernel in
the kernel in bursts
this architecture has proved
architecture has proved both
has proved both stable
proved both stable and
both stable and scalable
and it is used
it is used by
is used by most
used by most contemporary
this loss mode occurs
by most contemporary digital
loss mode occurs with
most contemporary digital currencies
mode occurs with udp
contemporary digital currencies and
digital currencies and related
currencies and related services
based traffic but not
traffic but not with
but not with tcp
which advertises receiver windows
advertises receiver windows to
receiver windows to prevent
windows to prevent end
boosting dbms performance by
dbms performance by parallelising
performance by parallelising write
by parallelising write transactions
what are typical loss
are typical loss rates
typical loss rates on
loss rates on long
one source of information
source of information is
of information is teragrid
an optical network interconnecting
optical network interconnecting major
network interconnecting major supercomputing
prediction of transaction behavior
interconnecting major supercomputing sites
of transaction behavior has
major supercomputing sites in
transaction behavior has the
supercomputing sites in the
behavior has the potential
sites in the us
has the potential to
the potential to significantly
potential to significantly decrease
to significantly decrease abort
teragrid has a monitoring
significantly decrease abort rates
has a monitoring framework
decrease abort rates in
a monitoring framework within
abort rates in large
monitoring framework within which
rates in large scale
framework within which ten
in large scale transactional
within which ten sites
large scale transactional systems
which ten sites periodically
scale transactional systems with
ten sites periodically send
transactional systems with high
sites periodically send each
systems with high contention
periodically send each other
gbps streams of udp
streams of udp packets
of udp packets and
udp packets and measure
rain we employ prediction
our results apply to
packets and measure the
results apply to all
and measure the resulting
apply to all such
measure the resulting loss
to all such incentive
we employ prediction to
all such incentive systems
the resulting loss rate
employ prediction to obtain
prediction to obtain soft
to obtain soft reservations
obtain soft reservations and
but we use bitcoin
soft reservations and implement
we use bitcoin terminology
reservations and implement atomic
use bitcoin terminology and
and implement atomic transactions
bitcoin terminology and examples
implement atomic transactions while
terminology and examples since
atomic transactions while requiring
and examples since it
transactions while requiring high
examples since it serves
while requiring high availability
since it serves as
requiring high availability only
it serves as an
high availability only in
serves as an active
availability only in a
as an active and
each site measures the
an active and archetypal
only in a single
active and archetypal example
site measures the loss
in a single tier
measures the loss rate
a single tier of
the loss rate to
single tier of independent
loss rate to every
tier of independent logs
rate to every other
bitcoin implements its incentive
to every other site
implements its incentive systems
every other site once
its incentive systems with
other site once an
incentive systems with a
this allows for low
systems with a data
site once an hour
with a data structure
a data structure called
data structure called the
structure called the blockchain
resulting in a total
in a total of
the blockchain is a
blockchain is a serialization
is a serialization of
a serialization of all
serialization of all bitcoin
of all bitcoin transactions
loss rate measurements collected
rain s operations never
rate measurements collected across
s operations never depend
measurements collected across the
it is a single
collected across the network
operations never depend on
across the network every
is a single global
the network every hour
never depend on a
a single global ledger
depend on a single
single global ledger maintained
on a single machine
global ledger maintained by
a single machine by
ledger maintained by an
single machine by allowing
maintained by an open
machine by allowing fast
by an open distributed
by allowing fast recovery
an open distributed system
allowing fast recovery from
fast recovery from failures
recovery from failures and
from failures and performance
failures and performance hiccups
since anyone can join
anyone can join the
can join the open
join the open system
the open system and
open system and participate
system and participate in
and participate in maintaining
participate in maintaining the
in maintaining the blockchain
bitcoin uses a proof
uses a proof of
a proof of work
proof of work mechanism
of work mechanism to
work mechanism to deter
mechanism to deter attacks
participation requires exerting significant
requires exerting significant computational
exerting significant computational resources
a participant who proves
participant who proves she
who proves she has
proves she has exerted
she has exerted enough
has exerted enough resources
exerted enough resources with
enough resources with a
resources with a proof
with a proof of
a proof of work
proof of work is
of work is allowed
work is allowed to
is allowed to take
allowed to take a
to take a step
take a step in
a step in the
step in the protocol
in the protocol by
of all such measurements
the protocol by generating
all such measurements were
protocol by generating a
such measurements were over
by generating a block
participants are compensated for
are compensated for their
compensated for their efforts
benchmarking cloud serving systems
for their efforts with
cloud serving systems with
their efforts with newly
serving systems with ycsb
efforts with newly minted
with newly minted bitcoins
the process of creating
process of creating a
of creating a block
creating a block is
a block is called
block is called mining
and the participants miners
of them were over
in order to win
order to win the
to win the reward
many miners try to
miners try to generate
try to generate blocks
the system automatically adjusts
system automatically adjusts the
automatically adjusts the difficulty
adjusts the difficulty of
the difficulty of block
difficulty of block generation
after eliminating a single
eliminating a single site
such that one block
that one block is
one block is added
block is added every
that dropped incoming packets
dropped incoming packets steadily
incoming packets steadily at
packets steadily at a
steadily at a rate
at a rate of
minutes to the blockchain
this means that each
means that each miner
that each miner seldom
each miner seldom generates
miner seldom generates a
seldom generates a block
although its revenue may
its revenue may be
revenue may be positive
may be positive in
be positive in expectation
a miner may have
miner may have to
may have to wait
have to wait for
to wait for an
wait for an extended
for an extended period
an extended period to
extended period to create
period to create a
to create a block
of the remainder were
create a block and
the remainder were over
a block and earn
block and earn the
and earn the actual
earn the actual bitcoins
we plan to build
plan to build on
to build on our
build on our simulation
on our simulation results
our simulation results by
simulation results by implementing
results by implementing acid
miners form mining pools
rain and exploring the
and exploring the different
where all members mine
exploring the different aspects
all members mine concurrently
the different aspects of
members mine concurrently and
different aspects of its
mine concurrently and they
aspects of its performance
concurrently and they share
of its performance in
and they share their
its performance in realistic
they share their revenue
performance in realistic settings
share their revenue whenever
their revenue whenever one
revenue whenever one of
whenever one of them
one of them creates
of particular interest are
of them creates a
them creates a block
pools are typically implemented
are typically implemented as
typically implemented as a
implemented as a pool
as a pool manager
a pool manager and
pool manager and a
different network topologies with
manager and a cohort
these numbers reflect the
network topologies with a
numbers reflect the loss
topologies with a single
reflect the loss rate
with a single datacenter
the loss rate experienced
a single datacenter and
loss rate experienced for
single datacenter and with
rate experienced for udp
datacenter and with multiple
experienced for udp traffic
and with multiple datacenters
for udp traffic on
and a cohort of
udp traffic on an
a cohort of miners
traffic on an end
the pool manager joins
pool manager joins the
manager joins the bitcoin
joins the bitcoin system
the bitcoin system as
end path and may
bitcoin system as a
path and may not
system as a single
and may not generalize
as a single miner
may not generalize to
behavior in face of
not generalize to tcp
in face of high
generalize to tcp packets
face of high contention
instead of generating proof
of generating proof of
generating proof of work
rain should prove efficient
it outsources the work
we do not know
outsources the work to
the work to the
do not know if
work to the miners
not know if packets
know if packets were
if packets were dropped
packets were dropped within
where its overhead may
in order to evaluate
its overhead may be
were dropped within the
overhead may be wasteful
order to evaluate the
dropped within the optical
to evaluate the miners
within the optical network
evaluate the miners efforts
the optical network or
optical network or at
network or at intermediate
or at intermediate devices
at intermediate devices within
intermediate devices within either
the pool manager accepts
devices within either datacenter
pool manager accepts partial
manager accepts partial proof
accepts partial proof of
partial proof of work
though it s unlikely
proof of work and
it s unlikely that
of work and estimates
behavior in error prone
work and estimates each
in error prone scenarios
s unlikely that they
and estimates each miner
unlikely that they were
estimates each miner s
that they were dropped
each miner s power
they were dropped at
miner s power according
were dropped at the
dropped at the end
s power according to
power according to the
according to the rate
to the rate with
the rate with which
rate with which it
with which it submits
which it submits such
it submits such partial
performance with predictors of
many of the mea
with predictors of different
submits such partial proof
predictors of different qualities
such partial proof of
partial proof of work
surements lost just one
lost just one or
just one or two
one or two packets
when a miner generates
or two packets whereas
a miner generates a
two packets whereas kernel
miner generates a full
generates a full proof
a full proof of
full proof of work
nic losses are known
losses are known to
are known to be
known to be bursty
it sends it to
sends it to the
it to the pool
to the pool manager
the pool manager which
pool manager which publishes
manager which publishes this
which publishes this proof
publishes this proof of
this proof of work
proof of work to
of work to the
work to the bitcoin
to the bitcoin system
the pool manager thus
pool manager thus receives
loss occurred on paths
manager thus receives the
occurred on paths where
thus receives the full
on paths where levels
receives the full revenue
paths where levels of
the full revenue of
where levels of optical
full revenue of the
levels of optical link
revenue of the block
of optical link utilization
of the block and
the block and distributes
block and distributes it
and distributes it fairly
distributes it fairly according
it fairly according to
fairly according to its
according to its members
to its members power
many of the pools
lightweight elasticity in shared
of the pools are
elasticity in shared storage
the pools are open
in shared storage databases
pools are open they
shared storage databases for
are open they allow
storage databases for the
were consistently lower than
databases for the cloud
open they allow any
for the cloud using
they allow any miner
the cloud using live
allow any miner to
cloud using live data
any miner to join
using live data migration
miner to join them
to join them using
join them using a
them using a public
using a public internet
a public internet interface
such open pools are
ruling out congestion as
open pools are susceptible
out congestion as a
pools are susceptible to
congestion as a possible
are susceptible to the
as a possible cause
susceptible to the classical
to the classical block
the classical block withholding
classical block withholding attack
a conclusion supported by
conclusion supported by dialogue
supported by dialogue with
by dialogue with the
dialogue with the network
with the network administrators
where a miner sends
a miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
proof of work to
of work to the
work to the pool
to the pool manager
points are provided by
the pool manager and
are provided by the
pool manager and discards
provided by the back
manager and discards full
and discards full proof
discards full proof of
full proof of work
bone networks of tier
due to the partial
to the partial proof
the partial proof of
partial proof of work
proof of work it
of work it sends
work it sends to
it sends to the
sends to the pool
global crossing reports average
crossing reports average loss
reports average loss rates
the miner is considered
average loss rates between
miner is considered a
is considered a regular
considered a regular pool
a regular pool member
regular pool member and
pool member and the
member and the pool
and the pool can
the pool can estimate
pool can estimate its
can estimate its power
live migration in shared
migration in shared nothing
in shared nothing databases
shared nothing databases for
nothing databases for elastic
databases for elastic cloud
for elastic cloud platforms
the attacker shares the
attacker shares the revenue
shares the revenue obtained
the revenue obtained by
revenue obtained by the
obtained by the other
by the other pool
the other pool members
but does not contribute
it reduces the revenue
reduces the revenue of
the revenue of the
revenue of the other
of the other members
on four of its
four of its six
of its six inter
but also its own
we provide necessary background
haul links for the
provide necessary background on
links for the month
necessary background on the
for the month of
background on the bitcoin
the month of december
on the bitcoin protocol
pools and the classical
and the classical block
the classical block withholding
classical block withholding attack
block withholding attack in
withholding attack in section
attack in section ii
and specify our model
specify our model in
our model in section
model in section iii
for a broader view
a broader view of
broader view of the
view of the protocol
of the protocol and
the protocol and ecosystem
protocol and ecosystem the
and ecosystem the reader
qwest reports loss rates
ecosystem the reader may
reports loss rates of
the reader may refer
reader may refer to
may refer to the
refer to the survey
to the survey by
the survey by bonneau
survey by bonneau et
by bonneau et al
in this work we
this work we analyze
work we analyze block
we analyze block withholding
analyze block withholding attacks
block withholding attacks among
withholding attacks among pools
in either direction on
either direction on its
direction on its trans
a pool that employs
pool that employs the
that employs the pool
employs the pool block
pacific link for the
the pool block withholding
link for the same
pool block withholding attack
for the same month
block withholding attack registers
withholding attack registers with
attack registers with the
registers with the victim
with the victim pool
the victim pool as
victim pool as a
pool as a regular
as a regular miner
it receives tasks from
receives tasks from the
tasks from the victim
from the victim pool
we expect privately managed
the victim pool and
expect privately managed lambdas
victim pool and transfers
privately managed lambdas to
pool and transfers them
managed lambdas to exhibit
and transfers them to
lambdas to exhibit higher
transfers them to some
to exhibit higher loss
them to some of
exhibit higher loss rates
to some of its
higher loss rates due
some of its own
loss rates due to
of its own miners
rates due to the
due to the inherent
to the inherent trade
we call these infiltrating
call these infiltrating miners
equipment quality and cost
and the mining power
the mining power spent
mining power spent by
power spent by a
spent by a pool
by a pool the
a pool the infiltration
pool the infiltration rate
the dangers of replication
dangers of replication and
of replication and d
when electronic copy available
electronic copy available at
as well as the
well as the difficulty
as the difficulty of
fast distributed transactions a
the difficulty of performing
distributed transactions a solution
difficulty of performing routine
of performing routine maintenance
performing routine maintenance on
routine maintenance on longdistance
maintenance on longdistance links
end paths as dropping
paths as dropping packets
as dropping packets at
dropping packets at rates
packets at rates of
for partitioned database systems
the attacking pool s
attacking pool s infiltrating
pool s infiltrating miners
s infiltrating miners deliver
infiltrating miners deliver partial
miners deliver partial proofs
deliver partial proofs of
partial proofs of work
the attacker transfers them
to capture a wide
attacker transfers them to
capture a wide range
transfers them to the
a wide range of
them to the victim
wide range of deployed
to the victim pool
range of deployed networks
letting the attacked pool
the attacked pool estimate
attacked pool estimate their
pool estimate their power
existing reliability options tcp
when the infiltrating miners
the infiltrating miners deliver
ip is the default
infiltrating miners deliver a
is the default reliable
miners deliver a full
the default reliable communication
deliver a full proof
default reliable communication option
a full proof of
reliable communication option for
full proof of work
communication option for contemporary
option for contemporary networked
for contemporary networked applications
the attacking pool discards
attacking pool discards it
this attack affects the
exclusive embeddings in commodity
attack affects the revenues
embeddings in commodity operating
affects the revenues of
in commodity operating systems
the revenues of the
commodity operating systems and
revenues of the pools
operating systems and networking
of the pools in
systems and networking apis
the pools in several
pools in several ways
distributed main memory transaction
main memory transaction processing
the victim pool s
memory transaction processing system
victim pool s effective
pool s effective mining
most applications requiring reliable
s effective mining rate
applications requiring reliable communication
effective mining rate is
requiring reliable communication over
mining rate is unchanged
reliable communication over any
communication over any form
over any form of
any form of network
form of network use
of network use tcp
but its total revenue
its total revenue is
total revenue is divided
revenue is divided among
is divided among more
divided among more miners
the attacker s mining
attacker s mining power
s mining power is
mining power is reduced
since some of its
some of its miners
of its miners are
its miners are used
the problem with commodity
miners are used for
problem with commodity tcp
are used for block
used for block withholding
but it earns additional
it earns additional revenue
earns additional revenue through
additional revenue through its
revenue through its infiltration
through its infiltration of
its infiltration of the
infiltration of the other
of the other pool
ip uses positive acknowledgments
uses positive acknowledgments and
the total effective mining
positive acknowledgments and retransmissions
total effective mining power
acknowledgments and retransmissions to
effective mining power in
and retransmissions to ensure
mining power in the
retransmissions to ensure reliability
power in the system
to ensure reliability the
in the system is
ensure reliability the sender
the system is reduced
reliability the sender buffers
the sender buffers packets
sender buffers packets until
buffers packets until their
packets until their receipt
causing the bitcoin protocol
until their receipt is
the bitcoin protocol to
their receipt is acknowledged
bitcoin protocol to reduce
receipt is acknowledged by
protocol to reduce the
is acknowledged by the
to reduce the difficulty
acknowledged by the receiver
taking all these factors
and resends if an
all these factors into
resends if an acknowledgment
these factors into account
if an acknowledgment is
an acknowledgment is not
acknowledgment is not received
is not received within
not received within some
received within some time
we observe that a
within some time period
observe that a pool
that a pool might
a pool might be
pool might be able
might be able to
be able to increase
able to increase its
to increase its revenue
increase its revenue by
its revenue by attacking
a lost packet is
revenue by attacking other
lost packet is received
by attacking other pools
packet is received in
is received in the
received in the form
in the form of
the form of a
each pool therefore makes
form of a retransmission
pool therefore makes a
of a retransmission that
therefore makes a choice
a retransmission that arrives
makes a choice of
retransmission that arrives no
a choice of whether
that arrives no earlier
choice of whether to
verify replication for multi
arrives no earlier than
of whether to attack
whether to attack each
to attack each of
attack each of the
each of the other
of the other pools
the other pools in
other pools in the
pools in the system
and with what infiltration
rtts after the original
with what infiltration rate
after the original send
the original send event
this gives rise to
gives rise to the
the sender has to
rise to the pool
sender has to buffer
to the pool game
has to buffer each
to buffer each packet
buffer each packet until
each packet until it
packet until it s
until it s acknowledged
we specify this game
specify this game and
this game and provide
game and provide initial
and provide initial analysis
provide initial analysis in
initial analysis in section
analysis in section iv
rtt in lossless operation
in section v we
section v we analyze
and it has to
v we analyze the
it has to perform
we analyze the scenario
has to perform additional
analyze the scenario where
to perform additional work
the scenario where exactly
perform additional work to
scenario where exactly two
additional work to retransmit
where exactly two of
work to retransmit the
exactly two of the
to retransmit the packet
two of the pools
retransmit the packet if
of the pools take
the packet if it
the pools take part
packet if it does
pools take part in
if it does not
take part in the
it does not receive
part in the game
does not receive the
in the game and
not receive the acknowledgment
the game and only
game and only one
and only one can
only one can attack
one can attack the
can attack the other
any packets that arrive
packets that arrive with
the attacker can always
that arrive with higher
attacker can always increase
can always increase its
arrive with higher sequence
always increase its revenue
increase its revenue by
with higher sequence numbers
its revenue by attacking
higher sequence numbers than
sequence numbers than that
numbers than that of
than that of a
we conclude that in
that of a lost
conclude that in the
of a lost packet
that in the general
a lost packet must
in the general case
lost packet must be
packet must be queued
must be queued while
be queued while the
queued while the receiver
with any number of
while the receiver waits
any number of pools
the receiver waits for
receiver waits for the
waits for the lost
for the lost packet
the lost packet to
lost packet to arrive
attacks is not a
is not a nash
throughput financial banking application
not a nash equilibrium
financial banking application running
banking application running in
application running in a
running in a datacenter
in a datacenter in
a datacenter in new
datacenter in new york
in new york city
section vi deals with
vi deals with the
deals with the case
with the case of
sending updates to a
the case of two
updates to a sister
case of two pools
to a sister site
a sister site in
sister site in switzerland
where each can attack
each can attack the
can attack the other
the rtt value between
rtt value between these
value between these two
between these two centers
these two centers is
two centers is typically
analysis becomes more complicated
becomes more complicated in
more complicated in two
complicated in two ways
the revenue of each
revenue of each pool
of each pool affects
each pool affects the
pool affects the revenue
affects the revenue of
the revenue of the
using time instead of
revenue of the other
time instead of timeout
of the other through
instead of timeout for
the other through the
of timeout for fault
other through the infiltrating
through the infiltrating miners
in the case of
the case of a
case of a lost
of a lost packet
we prove that for
prove that for a
that for a static
all packets received within
for a static choice
packets received within the
a static choice of
static choice of infiltration
choice of infiltration rates
of infiltration rates the
infiltration rates the pool
rates the pool revenues
the pool revenues converge
milliseconds between the original
between the original packet
the original packet send
once one pool changes
original packet send and
one pool changes its
packet send and the
pool changes its infiltration
send and the a
changes its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the other
the latter may prefer
latter may prefer to
may prefer to change
prefer to change its
to change its infiltration
change its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the former
therefore the game itself
the game itself takes
game itself takes multiple
itself takes multiple rounds
takes multiple rounds to
h ets are generated
multiple rounds to converge
ets are generated from
are generated from alternate
generated from alternate disjoint
from alternate disjoint sub
we show analytically that
show analytically that the
analytically that the game
streams of data rather
that the game has
of data rather than
the game has a
data rather than from
game has a single
rather than from consecutive
has a single nash
than from consecutive packets
a single nash equilibrium
single nash equilibrium and
nash equilibrium and numerically
equilibrium and numerically study
and numerically study the
numerically study the equilibrium
study the equilibrium points
the equilibrium points for
equilibrium points for different
with an interleave index
points for different pool
an interleave index of
for different pool sizes
for pools smaller than
the encoder would a
g create correction packets
create correction packets separately
at the equilibrium point
correction packets separately from
the equilibrium point both
packets separately from three
equilibrium point both pools
separately from three disjoint
point both pools earn
from three disjoint sub
both pools earn less
pools earn less than
earn less than they
less than they would
than they would have
they would have in
would have in the
have in the nonequilibrium
in the nonequilibrium no
the first containing data
first containing data packets
containing data packets numbered
data packets numbered a
packets numbered a c
numbered a c e
a c e g
c e g x
e g x x
since pools can decide
pools can decide to
can decide to start
decide to start or
to start or stop
start or stop attacking
or stop attacking at
stop attacking at any
attacking at any point
this can be modeled
can be modeled as
be modeled as the
modeled as the miner
as the miner s
the miner s dilemma
miner s dilemma an
s dilemma an instance
dilemma an instance of
from paxos to corfu
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
attacking is the dominant
is the dominant strategy
the dominant strategy in
dominant strategy in each
strategy in each iteration
but if the pools
if the pools can
the pools can agree
pools can agree not
can agree not to
agree not to attack
both benefit in the
benefit in the long
in the long run
the second with data
second with data packets
with data packets numb
data packets numb d
packets numb d f
numb d f h
d f h x
f h x x
we address in section
h x x bered
address in section vii
in section vii the
section vii the case
vii the case where
the case where the
case where the participants
where the participants are
the participants are an
participants are an arbitrary
are an arbitrary number
an arbitrary number of
arbitrary number of identical
number of identical pools
there exists a symmetric
exists a symmetric equilibrium
a symmetric equilibrium in
symmetric equilibrium in which
equilibrium in which each
in which each participating
which each participating pool
each participating pool attacks
participating pool attacks each
pool attacks each of
attacks each of the
each of the other
of the other participating
the other participating pools
as in the minority
in the minority two
here too at equilibrium
too at equilibrium all
at equilibrium all pools
equilibrium all pools earn
all pools earn less
pools earn less than
earn less than with
less than with the
than with the no
and the third with
our results imply that
the third with data
results imply that block
third with data b
imply that block withholding
that block withholding by
block withholding by pools
concurrency control and availability
withholding by pools leads
control and availability in
by pools leads to
and availability in multi
pools leads to an
leads to an unfavorable
to an unfavorable equilibrium
due to the anonymity
to the anonymity of
the anonymity of miners
a single pool might
single pool might be
pool might be tempted
might be tempted to
be tempted to attack
leading the other pools
the other pools to
other pools to attack
pools to attack as
to attack as well
the implications might be
implications might be devastating
might be devastating for
be devastating for open
devastating for open pools
if their revenues are
their revenues are reduced
miners will prefer to
will prefer to form
prefer to form closed
to form closed pools
form closed pools that
closed pools that cannot
pools that cannot be
that cannot be attacked
cannot be attacked in
be attacked in this
attacked in this manner
though this may be
this may be conceived
may be conceived as
be conceived as bad
conceived as bad news
as bad news for
bad news for public
news for public mining
for public mining pools
interleaving adds burst tolerance
on the whole it
adds burst tolerance to
the whole it may
burst tolerance to fec
whole it may be
tolerance to fec but
it may be good
to fec but exacerbates
may be good news
fec but exacerbates its
be good news to
but exacerbates its sensitivfigure
good news to the
on predictive modeling for
news to the bitcoin
predictive modeling for optimizing
to the bitcoin system
modeling for optimizing transaction
for optimizing transaction execution
optimizing transaction execution in
transaction execution in parallel
execution in parallel oltp
which prefers small pools
in parallel oltp systems
we examine the practicality
examine the practicality of
the practicality of the
separate encoding for ity
practicality of the attack
encoding for ity to
of the attack in
for ity to sending
the attack in section
ity to sending rate
attack in section viii
to sending rate with
in section viii and
sending rate with an
section viii and discuss
rate with an interleave
viii and discuss implications
with an interleave index
and discuss implications and
an interleave index of
discuss implications and model
interleave index of i
implications and model extensions
index of i and
and model extensions in
of i and an
model extensions in section
i and an encoding
extensions in section ix
and an encoding rate
an encoding rate of
our contributions are the
contributions are the following
the sender would have
sender would have to
would have to wait
have to wait for
to wait for odd
wait for odd and
definition of the pool
for odd and even
of the pool game
odd and even packets
the pool game where
and even packets i
pool game where pools
game where pools in
where pools in a
pools in a proof
ofwork secured system attack
secured system attack one
system attack one another
attack one another with
one another with a
another with a pool
with a pool block
a pool block withholding
pool block withholding attack
packets before sending any
scalable deferred update replication
before sending any redundancy
sending any redundancy information
in the general case
receipt of its retransmission
of its retransmission have
its retransmission have to
retransmission have to be
have to be buffered
to be buffered at
be buffered at the
buffered at the rethese
at the rethese two
the rethese two obstacles
rethese two obstacles to
two obstacles to using
attacks is not an
obstacles to using fec
is not an equilibrium
to using fec in
using fec in time
tings rate sensitivity and
rate sensitivity and burst
with two minority pools
sensitivity and burst susceptibility
two minority pools participating
and burst susceptibility are
burst susceptibility are innotice
susceptibility are innotice that
are innotice that for
innotice that for this
the only nash equilibrium
that for this commonplace
only nash equilibrium is
for this commonplace scenario
nash equilibrium is when
equilibrium is when the
is when the pools
when the pools attack
the pools attack one
pools attack one another
the loss of terlinked
loss of terlinked through
of terlinked through the
terlinked through the tuning
through the tuning knobs
and both earn less
both earn less than
earn less than if
less than if none
than if none had
an interleave of i
if none had attacked
interleave of i and
of i and a
i and a single
and a single packet
a single packet stops
miners therefore face the
single packet stops all
therefore face the miner
packet stops all traffic
face the miner s
stops all traffic in
the case for determinism
all traffic in the
case for determinism in
traffic in the channel
for determinism in database
in the channel to
the miner s dilemma
the channel to the
determinism in database systems
channel to the apa
to the apa rate
the apa rate of
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
repeatedly choosing between attack
choosing between attack and
between attack and no
provides tolerance to a
tolerance to a burst
to a burst of
a burst of up
burst of up to
of up to c
up to c i
to c i plication
c i plication for
i plication for a
plication for a seventh
for a seventh of
a seventh of a
seventh of a second
with multiple pools of
a sequence of such
multiple pools of equal
sequence of such consecutive
pools of equal size
of such consecutive packets
of equal size there
equal size there is
size there is a
there is a symmetric
is a symmetric nash
a symmetric nash equilibrium
the burst tolerance of
where all pools earn
burst tolerance of blocks
all pools earn less
tolerance of blocks can
pools earn less than
of blocks can have
earn less than if
blocks can have devastating
less than if none
can have devastating effect
than if none had
have devastating effect on
if none had attacked
devastating effect on a
effect on a high
throughput an fec code
an fec code can
fec code can be
code can be changed
can be changed by
be changed by modulating
changed by modulating either
by modulating either the
modulating either the c
either the c system
the c system where
inefficient equilibria for open
c system where every
system where every spare
equilibria for open pools
where every spare cycle
every spare cycle counts
for open pools may
open pools may serve
pools may serve the
may serve the system
serve the system by
the system by reducing
system by reducing their
by reducing their attraction
in applior the i
reducing their attraction and
applior the i parameters
their attraction and pushing
attraction and pushing miners
and pushing miners towards
pushing miners towards smaller
increasing c enhances burst
miners towards smaller closed
c enhances burst tolercations
towards smaller closed pools
enhances burst tolercations with
burst tolercations with many
tolercations with many fine
the classical block withholding
classical block withholding attack
block withholding attack is
withholding attack is as
attack is as old
is as old as
as old as pools
a lost packet ance
old as pools themselves
lost packet ance at
packet ance at the
ance at the cost
at the cost of
the cost of network
cost of network and
but its use by
of network and encoding
its use by pools
network and encoding overhead
use by pools has
by pools has not
pools has not been
has not been suggested
not been suggested until
been suggested until recently
potencan potentially trigger a
potentially trigger a butterfly
trigger a butterfly effect
we overview related attacks
a butterfly effect of
overview related attacks and
butterfly effect of missed
related attacks and prior
effect of missed deadtially
attacks and prior work
of missed deadtially worsening
and prior work in
missed deadtially worsening the
prior work in section
deadtially worsening the packet
work in section x
worsening the packet loss
the packet loss experienced
packet loss experienced and
loss experienced and reducing
experienced and reducing lines
and conclude with final
and reducing lines along
conclude with final remarks
reducing lines along a
with final remarks in
lines along a distributed
final remarks in section
along a distributed workflow
remarks in section xi
p reliminaries b itcoin
reliminaries b itcoin and
b itcoin and p
itcoin and p ooled
and p ooled m
p ooled m ining
ooled m ining bitcoin
m ining bitcoin is
ining bitcoin is a
increasing i trades off
bitcoin is a distributed
i trades off recovery
trades off recovery periods
off recovery periods market
recovery periods market crashes
periods market crashes at
market crashes at stock
crashes at stock exchanges
christmas latency for better
latency for better burst
for better burst tolerance
better burst tolerance without
burst tolerance without adding
tolerance without adding overhead
without adding overhead sales
adding overhead sales at
overhead sales at online
sales at online stores
winter storms at air
traffic control as mentioned
for higher values of
higher values of i
the encoder has to
encoder has to centers
has to centers overloaded
to centers overloaded networks
centers overloaded networks and
overloaded networks and end
hosts can exhibit wait
can exhibit wait for
exhibit wait for more
wait for more data
for more data packets
more data packets to
data packets to be
packets to be transmitted
to be transmitted before
be transmitted before it
transmitted before it can
before it can continuous
it can continuous packet
can continuous packet loss
with each lost packet
each lost packet driving
lost packet driving the
packet driving the send
driving the send error
the send error correction
send error correction packets
clients use the system
use the system by
the system by issuing
system further and further
system by issuing transactions
further and further out
and further out of
further out of sync
out of sync with
of sync with respect
sync with respect to
and the system s
with respect to its
respect to its importantly
the system s only
system s only task
s only task is
only task is to
once the fec encoding
the fec encoding is
task is to serialize
fec encoding is parameterized
encoding is parameterized real
is to serialize transactions
to serialize transactions in
serialize transactions in a
transactions in a single
in a single ledger
a single ledger and
single ledger and reject
with a rate and
ledger and reject transactions
a rate and an
and reject transactions that
rate and an interleave
reject transactions that cannot
and an interleave to
transactions that cannot be
an interleave to tolerate
that cannot be serialized
interleave to tolerate a
cannot be serialized due
to tolerate a certain
be serialized due to
tolerate a certain burst
serialized due to conflicts
a certain burst sensitive
due to conflicts with
certain burst sensitive flow
to conflicts with previous
burst sensitive flow control
conflicts with previous transactions
bitcoin transactions are protected
transactions are protected with
ip is unable to
are protected with cryptographic
is unable to distinguish
protected with cryptographic techniques
unable to distinguish length
with cryptographic techniques that
to distinguish length b
cryptographic techniques that ensure
techniques that ensure that
that ensure that only
ensure that only the
that only the rightful
only the rightful owner
the rightful owner of
rightful owner of a
owner of a bitcoin
of a bitcoin can
a bitcoin can transfer
bitcoin can transfer it
the transaction ledger is
transaction ledger is stored
ledger is stored by
is stored by a
stored by a network
by a network of
a network of miners
network of miners in
of miners in a
miners in a data
in a data structure
a data structure caller
data structure caller the
structure caller the blockchain
revenue for proof of
for proof of work
to between ephemeral loss
proof of work the
between ephemeral loss modes
of work the blockchain
ephemeral loss modes due
work the blockchain records
loss modes due to
the blockchain records the
modes due to transient
blockchain records the transactions
due to transient contolerate
records the transactions in
to transient contolerate a
the transactions in units
transient contolerate a burst
transactions in units of
contolerate a burst of
in units of blocks
a burst of length
dubbed the genesis block
is defined as part
defined as part of
as part of the
part of the protocol
a valid block contains
valid block contains the
block contains the hash
contains the hash of
the hash of the
hash of the previous
of the previous block
the hash of the
all losses occurring gestion
hash of the transactions
of the transactions in
the transactions in the
transactions in the current
in the current block
and a bitcoin address
or dirty fiber and
a bitcoin address which
dirty fiber and persistent
bitcoin address which is
fiber and persistent in
address which is to
and persistent in bursts
which is to be
persistent in bursts of
is to be credited
in bursts of size
to be credited with
bursts of size less
be credited with a
of size less than
credited with a reward
size less than or
with a reward for
less than or equal
a reward for generating
than or equal to
reward for generating the
or equal to b
for generating the block
equal to b are
to b are recovered
b are recovered with
are recovered with congestion
any miner may add
miner may add a
may add a valid
add a valid block
the loss of one
a valid block to
loss of one packet
valid block to the
of one packet out
block to the chain
one packet out of
to the chain by
packet out of ten
out of ten thousand
of ten thousand is
ten thousand is sufficient
thousand is sufficient to
is sufficient to reduce
sufficient to reduce tcp
proving that it has
ip throughput to a
that it has spent
throughput to a third
it has spent a
to a third of
has spent a certain
a third of its
spent a certain amount
third of its the
a certain amount of
of its the same
certain amount of work
its the same latency
amount of work and
the same latency and
of work and publishing
same latency and this
work and publishing the
latency and this latency
and publishing the block
and this latency depends
publishing the block with
this latency depends on
the block with the
latency depends on the
block with the proof
depends on the i
with the proof over
on the i palossless
the proof over an
the i palossless maximum
proof over an overlay
over an overlay network
an overlay network to
overlay network to all
network to all other
to all other miners
if one packet is
one packet is lost
packet is lost out
is lost out of
lost out of a
out of a thousand
when a miner creates
a miner creates a
miner creates a block
it is compensated for
is compensated for its
compensated for its efforts
for its efforts with
its efforts with bitcoins
we d like to
d like to parameterize
this compensation includes a
like to parameterize the
compensation includes a per
to parameterize the encoding
parameterize the encoding to
the encoding to tolerate
encoding to tolerate a
transaction fee paid by
to tolerate a maximum
fee paid by the
tolerate a maximum burst
paid by the users
a maximum burst length
by the users electronic
maximum burst length and
the users electronic copy
burst length and then
users electronic copy available
length and then have
electronic copy available at
and then have recovthroughput
then have recovthroughput collapses
have recovthroughput collapses to
recovthroughput collapses to a
collapses to a thirtieth
to a thirtieth of
a thirtieth of the
thirtieth of the maximum
ery latency depend on
latency depend on the
depend on the actual
on the actual burstiness
the actual burstiness of
actual burstiness of the
burstiness of the loss
at the same time
we would like the
would like the encoding
like the encoding to
the encoding to have
encoding to have a
fec constant rate for
constant rate for network
rate for network provisioning
for network provisioning and
network provisioning and stability
whose transactions are included
and an amount of
an amount of minted
amount of minted bitcoins
of minted bitcoins that
an fec scheme is
minted bitcoins that are
fec scheme is required
bitcoins that are thus
scheme is required where
that are thus introduced
is required where latency
are thus introduced into
required where latency of
thus introduced into the
where latency of fec
introduced into the system
latency of fec encoders
of fec encoders are
fec encoders are typically
encoders are typically parameterized
are typically parameterized with
typically parameterized with an
the work which a
work which a miner
which a miner is
a miner is required
miner is required to
is required to do
required to do is
to do is to
do is to repeatedly
is to repeatedly calculate
to repeatedly calculate a
repeatedly calculate a a
recovery degrades gracefully as
calculate a a hash
degrades gracefully as losses
a a hash function
gracefully as losses get
a hash function specifically
as losses get burstier
hash function specifically the
function specifically the sha
even tuple for each
tuple for each outgoing
for each outgoing sequence
each outgoing sequence of
outgoing sequence of r
sequence of r data
of r data packets
a as the encoding
as the encoding overhead
the encoding overhead stays
encoding overhead stays constant
c data and error
data and error correction
and error correction packets
error correction packets are
correction packets are sent
of a block header
to indicate that he
indicate that he has
that he has performed
he has performed this
has performed this work
redundancy information cannot be
information cannot be generated
cannot be generated and
the miner provides a
be generated and sent
miner provides a probabilistic
generated and sent until
provides a probabilistic proof
and sent until all
a probabilistic proof as
sent until all r
probabilistic proof as follows
until all r data
all r data packets
r data packets are
data packets are available
packets are available for
are available for sending
the generated block has
generated block has a
block has a nonce
has a nonce field
which can contain any
can contain any value
the latency of packet
latency of packet recovery
of packet recovery is
packet recovery is determined
the miner places different
recovery is determined by
miner places different values
is determined by the
places different values in
determined by the rate
different values in this
by the rate at
values in this field
the rate at which
in this field and
rate at which the
this field and calculates
at which the sender
field and calculates the
which the sender transmits
and calculates the hash
the sender transmits data
calculates the hash for
the hash for each
hash for each value
generating error correction packets
if the result of
the result of the
result of the hash
of the hash is
the hash is smaller
maelstrom design and implemenfrom
hash is smaller than
is smaller than a
design and implemenfrom less
smaller than a target
than a target value
and implemenfrom less than
implemenfrom less than r
less than r data
than r data packets
the nonce is considered
r data packets at
nonce is considered a
data packets at the
is considered a solution
packets at the sender
at the sender is
the sender is not
sender is not a
and the block is
is not a viable
the block is valid
not a viable tation
a viable tation option
viable tation option even
tation option even though
the number of attempts
option even though the
number of attempts to
even though the data
of attempts to find
though the data rate
attempts to find a
the data rate in
to find a single
data rate in this
find a single hash
rate in this channel
a single hash is
in this channel is
single hash is therefore
this channel is low
hash is therefore random
is therefore random with
therefore random with a
random with a geometric
with a geometric distribution
or network could be
as each attempt is
network could be operating
each attempt is a
could be operating at
attempt is a bernoulli
be operating at near
is a bernoulli trial
operating at near full
a bernoulli trial with
at near full capacity
bernoulli trial with a
near full capacity with
trial with a success
full capacity with data
with a success probability
capacity with data from
a success probability determined
with data from other
success probability determined by
data from other senders
probability determined by the
determined by the target
by the target value
we describe the maelstrom
describe the maelstrom appliance
the maelstrom appliance as
at the existing huge
maelstrom appliance as a
the existing huge hashing
appliance as a single
existing huge hashing rates
as a single machine
huge hashing rates and
a single machine fec
hashing rates and small
single machine fec is
rates and small target
and small target values
machine fec is also
fec is also very
is also very susceptible
also very susceptible to
very susceptible to bursty
susceptible to bursty losses
the time to find
time to find a
to find a single
find a single hash
a single hash can
single hash can be
hash can be approximated
can be approximated by
be approximated by an
approximated by an exponential
by an exponential distribution
the average time for
average time for a
time for a miner
for a miner to
a miner to find
miner to find a
to find a solution
find a solution is
a solution is therefore
solution is therefore proportional
is therefore proportional to
we will show how
therefore proportional to its
will show how more
proportional to its hashing
show how more machines
to its hashing rate
how more machines can
its hashing rate or
more machines can be
hashing rate or mining
machines can be added
rate or mining power
can be added to
be added to terleaving
to maintain a constant
maintain a constant rate
a constant rate of
constant rate of bitcoin
rate of bitcoin generation
and as part of
as part of its
part of its defense
of its defense against
its defense against denial
is a standard encoding
defense against denial of
against denial of service
a standard encoding technique
denial of service and
of service and other
standard encoding technique used
service and other attacks
encoding technique used the
technique used the appliance
used the appliance to
the appliance to balance
the system normalizes the
appliance to balance encoding
system normalizes the rate
to balance encoding load
normalizes the rate of
balance encoding load and
the rate of block
encoding load and scale
rate of block generation
load and scale to
and scale to multo
scale to multo combat
to multo combat bursty
multo combat bursty loss
where error correction pack
the protocol deterministically defines
protocol deterministically defines the
deterministically defines the target
defines the target value
tiple gigabits per second
the target value for
gigabits per second of
target value for each
per second of traffic
value for each block
for each block according
each block according to
block according to the
according to the time
a b c d
to the time required
b c d x
the time required to
c d x x
time required to generate
d x x e
required to generate recent
x x e f
to generate recent blocks
x e f g
e f g h
f g h x
g h x x
h x x appliance
is updated once every
blocks such that the
such that the average
that the average time
the average time for
average time for each
time for each block
for each block to
each block to be
block to be found
to be found is
note that the exponential
that the exponential distribution
the exponential distribution is
exponential distribution is memoryless
if all miners mine
all miners mine for
miners mine for block
mine for block number
for block number b
lan mtu lambda jumbo
mtu lambda jumbo mtu
once the block is
lambda jumbo mtu recipe
the block is found
jumbo mtu recipe list
block is found at
is found at time
found at time t
all miners switch to
miners switch to mine
switch to mine for
to mine for the
mine for the subsequent
for the subsequent block
the subsequent block b
at t without changing
t without changing their
without changing their probability
changing their probability distribution
their probability distribution of
probability distribution of finding
distribution of finding a
of finding a block
finding a block after
a block after t
the probability that a
probability that a miner
that a miner i
a miner i with
miner i with mining
i with mining power
with mining power mi
mining power mi finds
power mi finds the
mi finds the next
finds the next block
the next block is
next block is its
block is its ratio
is its ratio out
its ratio out of
ratio out of the
out of the total
of the total mining
the total mining power
total mining power m
mining power m in
power m in the
m in the system
miner miner miner pool
miner miner miner pool
and one miner mines
one miner mines solo
repair packets are injected
packets are injected into
are injected into stream
injected into stream transparently
pools datacenters are built
datacenters are built around
are built around the
built around the world
basic mechanism the basic
mechanism the basic operation
the basic operation of
basic operation of maelstrom
operation of maelstrom is
of maelstrom is shown
maelstrom is shown in
is shown in figure
mining is only profitable
is only profitable using
only profitable using dedicated
profitable using dedicated hardware
using dedicated hardware in
dedicated hardware in cutting
it intercepts outgoing data
hardware in cutting edge
intercepts outgoing data packets
in cutting edge mining
outgoing data packets and
cutting edge mining rigs
data packets and routes
packets and routes them
and routes them to
routes them to the
them to the destination
to the destination datacenter
otherwise the energy costs
the energy costs exceed
energy costs exceed the
costs exceed the expected
exceed the expected revenue
generating and injecting fec
and injecting fec repair
injecting fec repair packets
fec repair packets into
repair packets into the
although expected revenue from
packets into the stream
expected revenue from mining
into the stream in
revenue from mining is
the stream in their
from mining is proportional
stream in their wake
mining is proportional to
is proportional to the
proportional to the power
to the power of
the power of the
power of the mining
of the mining rigs
a repair packet consists
the mining rigs used
repair packet consists of
packet consists of a
consists of a recipe
of a recipe list
a single home miner
a recipe list of
single home miner using
recipe list of data
home miner using a
list of data packet
miner using a small
of data packet identifiers
using a small rig
data packet identifiers and
a small rig is
packet identifiers and fec
small rig is unlikely
identifiers and fec information
rig is unlikely to
and fec information generated
is unlikely to mine
fec information generated from
unlikely to mine a
information generated from these
to mine a block
generated from these packets
mine a block for
a block for years
in the example in
the example in figure
this information is a
information is a simple
is a simple xor
the size of the
size of the xor
of the xor is
the xor is equal
xor is equal to
miners often organize themselves
is equal to the
often organize themselves into
equal to the mtu
organize themselves into mining
to the mtu of
themselves into mining pools
the mtu of the
mtu of the datacenter
of the datacenter network
and to avoid fragmentation
to avoid fragmentation of
a pool is a
avoid fragmentation of repair
pool is a group
fragmentation of repair packets
is a group of
of repair packets we
a group of miners
repair packets we require
group of miners that
packets we require that
of miners that share
we require that the
miners that share their
require that the mtu
that share their revenues
that the mtu of
share their revenues when
the mtu of the
their revenues when one
mtu of the long
revenues when one of
when one of them
one of them successfully
of them successfully mines
them successfully mines a
successfully mines a block
haul network be set
network be set to
be set to a
set to a slightly
to a slightly larger
a slightly larger value
for each block found
this requirement is usually
the revenue is distributed
requirement is usually satisfied
revenue is distributed among
is usually satisfied in
is distributed among the
usually satisfied in practical
distributed among the pool
satisfied in practical deployments
among the pool members
the pool members in
pool members in proportion
members in proportion to
in proportion to their
proportion to their mining
since gigabit links very
to their mining power
gigabit links very often
links very often use
very often use jumbo
often use jumbo frames
use jumbo frames of
jumbo frames of up
frames of up to
the expected revenue of
expected revenue of a
revenue of a pool
of a pool member
a pool member is
pool member is therefore
member is therefore the
is therefore the same
therefore the same as
the same as its
same as its revenue
as its revenue had
its revenue had it
revenue had it mined
had it mined solo
due to the large
to the large power
the large power of
large power of the
power of the pool
while lan networks have
lan networks have standard
networks have standard mtus
it finds blocks at
have standard mtus of
finds blocks at a
blocks at a much
at a much higher
a much higher rate
and so the frequency
so the frequency of
the frequency of revenue
frequency of revenue collection
of revenue collection is
revenue collection is higher
allowing for a stable
for a stable daily
a stable daily or
stable daily or weekly
at the receiving datacenter
daily or weekly income
the appliance examines incoming
appliance examines incoming repair
examines incoming repair packets
incoming repair packets and
most pools are controlled
repair packets and uses
pools are controlled by
packets and uses them
are controlled by a
and uses them to
controlled by a centralized
uses them to recover
by a centralized pool
them to recover missing
a centralized pool manager
to recover missing data
recover missing data packets
miners register with the
register with the pool
the data packet is
with the pool manager
data packet is injected
the pool manager and
packet is injected transparently
pool manager and mine
is injected transparently into
manager and mine on
injected transparently into the
and mine on its
transparently into the stream
mine on its behalf
into the stream to
the stream to the
stream to the receiving
to the receiving end
the pool manager generates
pool manager generates tasks
manager generates tasks and
generates tasks and the
tasks and the miners
recovered data packets will
and the miners search
data packets will typically
the miners search for
packets will typically arrive
miners search for solutions
will typically arrive out
search for solutions based
for solutions based on
solutions based on these
based on these tasks
on these tasks that
these tasks that can
tasks that can serve
that can serve as
can serve as proof
serve as proof of
as proof of work
but this behavior is
this behavior is expected
behavior is expected by
once they find a
is expected by communication
they find a solution
expected by communication stacks
by communication stacks designed
communication stacks designed for
stacks designed for the
designed for the commodity
they send it to
for the commodity internet
send it to the
it to the pool
to the pool manager
flow control while relaying
control while relaying tcp
the pool manager behaves
pool manager behaves as
manager behaves as a
behaves as a single
as a single miner
a single miner in
single miner in the
miner in the bitcoin
in the bitcoin system
maelstrom has two flow
has two flow control
two flow control modes
once it obtains a
it obtains a legitimate
obtains a legitimate block
a legitimate block from
legitimate block from one
block from one of
from one of its
one of its miners
the block transfers the
block transfers the revenue
transfers the revenue to
the revenue to the
revenue to the control
to the control of
the control of the
control of the pool
of the pool manager
the appliance routes packets
appliance routes packets through
routes packets through without
the pool manager then
packets through without modification
pool manager then distributes
manager then distributes the
then distributes the revenue
distributes the revenue among
the revenue among the
revenue among the miners
among the miners according
the miners according to
miners according to their
control between the endhosts
according to their mining
to their mining power
the architecture is illustrated
architecture is illustrated in
is illustrated in figure
the appliance acts as
appliance acts as a
acts as a tcp
in order to estimate
order to estimate the
to estimate the mining
estimate the mining power
the mining power of
mining power of a
power of a miner
terminating connections and sending
connections and sending back
and sending back acks
sending back acks immediately
back acks immediately before
the pool manager sets
acks immediately before relaying
pool manager sets a
immediately before relaying data
manager sets a partial
before relaying data on
sets a partial target
relaying data on appliance
a partial target for
partial target for each
target for each member
this is particularly useful
is particularly useful for
particularly useful for applications
useful for applications with
for applications with short
lived flows that need
flows that need to
that need to ramp
need to ramp up
to ramp up throughput
ramp up throughput quickly
up throughput quickly and
throughput quickly and avoid
quickly and avoid the
than the target of
and avoid the slow
the target of the
target of the bitcoin
of the bitcoin system
start effects of tcp
each miner is required
miner is required to
ip on a long
is required to send
on a long link
required to send the
to send the pool
send the pool manager
the pool manager blocks
pool manager blocks that
the performance advantages of
manager blocks that are
performance advantages of splitting
blocks that are correct
advantages of splitting longdistance
that are correct according
of splitting longdistance connections
are correct according to
splitting longdistance connections into
correct according to the
longdistance connections into multiple
according to the partial
connections into multiple hops
to the partial target
into multiple hops are
multiple hops are well
hops are well known
the partial target is
partial target is chosen
target is chosen to
is chosen to be
chosen to be large
such that partial solutions
and orthogonal to this
that partial solutions arrive
orthogonal to this work
partial solutions arrive frequently
solutions arrive frequently enough
arrive frequently enough for
frequently enough for the
enough for the manager
we are primarily interested
for the manager to
are primarily interested in
the manager to accurately
primarily interested in isolating
manager to accurately estimate
interested in isolating the
to accurately estimate the
in isolating the impact
accurately estimate the power
isolating the impact of
estimate the power of
the impact of rapid
the power of the
impact of rapid and
power of the miner
of rapid and transparent
rapid and transparent recovery
and transparent recovery of
transparent recovery of lost
recovery of lost packets
of lost packets by
lost packets by maelstrom
packets by maelstrom on
by maelstrom on tcp
to reduce management overhead
rather than the buffering
than the buffering and
as the value of
the buffering and slow
the value of bitcoin
value of bitcoin rose
start avoidance benefits of
avoidance benefits of generic
bitcoin mining has become
benefits of generic performance
mining has become a
has become a rapidly
become a rapidly advancing
a rapidly advancing industry
technological advancements lead to
in the remainder of
advancements lead to ever
the remainder of the
lead to ever more
remainder of the paper
to ever more efficient
ever more efficient hashing
more efficient hashing asics
we describe maelstrom with
describe maelstrom with end
while maelstrom respects end
this is a simplification
is a simplification that
a simplification that is
simplification that is sufficient
that is sufficient for
is sufficient for our
sufficient for our analysis
end flow control connections
the intricacies of reward
intricacies of reward systems
of reward systems are
or splits them and
reward systems are explained
splits them and implements
systems are explained in
them and implements its
and implements its own
implements its own proxy
proxy flow control as
flow control as described
control as described above
it is not designed
is not designed for
not designed for routinely
designed for routinely congested
a notable exception is
for routinely congested networks
notable exception is p
the addition of fec
addition of fec under
of fec under tcp
ip flow control allows
flow control allows it
control allows it to
allows it to steal
it to steal bandwidth
to steal bandwidth from
steal bandwidth from other
bandwidth from other competing
from other competing flows
other competing flows running
competing flows running without
flows running without fec
running without fec in
which we discuss in
without fec in the
we discuss in section
fec in the link
discuss in section ix
though maintaining fairness versus
forks block propagation in
maintaining fairness versus similarly
block propagation in the
fairness versus similarly fec
propagation in the overlay
in the overlay network
the overlay network takes
overlay network takes seconds
therefore it is possible
it is possible for
is possible for two
possible for two distant
for two distant miners
two distant miners to
distant miners to generate
miners to generate competing
to generate competing blocks
both of which name
of which name the
which name the same
name the same block
the same block as
same block as their
block as their predecessor
friendliness with conventional tcp
ip flows is not
flows is not a
is not a primary
not a primary protocol
a primary protocol design
primary protocol design goal
protocol design goal on
design goal on over
are rare since the
rare since the average
since the average mining
the average mining interval
average mining interval is
which are often dedicated
are often dedicated to
often dedicated to specific
dedicated to specific highvalue
to specific highvalue applications
and they occur on
we see evidence for
they occur on average
see evidence for this
occur on average once
evidence for this assertion
on average once every
for this assertion in
this assertion in the
assertion in the routine
in the routine use
the routine use of
routine use of parallel
use of parallel flows
and udp blast protocols
the system has a
system has a mechanism
has a mechanism to
a mechanism to solve
mechanism to solve forks
to solve forks when
solve forks when they
forks when they do
when they do occur
causing one of the
one of the blocks
of the blocks to
the blocks to be
blocks to be discarded
both in commercial deployments
we ignore bifurcations for
in commercial deployments and
ignore bifurcations for the
commercial deployments and by
bifurcations for the sake
deployments and by researchers
for the sake of
and by researchers seeking
the sake of simplicity
by researchers seeking to
researchers seeking to transfer
seeking to transfer large
to transfer large amounts
transfer large amounts of
large amounts of data
since the choice of
amounts of data over
the choice of the
of data over high
choice of the discarded
of the discarded block
the discarded block on
discarded block on bifurcation
block on bifurcation is
on bifurcation is random
one may incorporate this
may incorporate this event
incorporate this event into
this event into the
event into the probability
into the probability of
the probability of finding
probability of finding a
of finding a block
layered interleaving in layered
interleaving in layered interleaving
and consider instead the
consider instead the probability
instead the probability of
the probability of finding
an fec protocol with
probability of finding a
fec protocol with rate
of finding a block
finding a block that
a block that is
block that is not
that is not discarded
pools often charge a
often charge a small
charge a small percentage
a small percentage of
is produced by running
small percentage of the
produced by running c
percentage of the revenue
by running c multiple
of the revenue as
running c multiple instances
the revenue as fee
c multiple instances of
multiple instances of an
we discuss in section
discuss in section ix
in section ix the
section ix the implications
ix the implications of
the implications of such
implications of such fees
of such fees to
such fees to our
fees to our analysis
fec protocol simultaneously with
many pools are open
protocol simultaneously with increasing
pools are open and
simultaneously with increasing interleave
are open and accept
with increasing interleave indices
open and accept any
increasing interleave indices i
and accept any interested
accept any interested miner
a pool interface is
pool interface is typically
interface is typically comprised
is typically comprised of
typically comprised of a
comprised of a web
of a web interface
a web interface for
web interface for registration
interface for registration and
for registration and a
registration and a miner
and a miner interface
a miner interface for
miner interface for the
interface for the mining
for the mining software
in order to mine
order to mine for
to mine for a
mine for a pool
a miner registers with
miner registers with the
registers with the web
with the web interface
supplies a bitcoin address
a bitcoin address to
bitcoin address to receive
address to receive its
to receive its future
receive its future shares
its future shares of
future shares of the
shares of the revenue
and receives from the
receives from the pool
from the pool credentials
the pool credentials for
pool credentials for mining
then he feeds his
he feeds his credentials
feeds his credentials and
his credentials and the
credentials and the pool
and the pool s
the pool s address
pool s address to
s address to its
address to its mining
to its mining rig
the mining rig obtains
mining rig obtains its
rig obtains its tasks
obtains its tasks from
its tasks from the
tasks from the pool
from the pool and
the pool and sends
pool and sends partial
and sends partial and
sends partial and full
partial and full proof
and full proof of
full proof of work
typically with the stratum
with the stratum protocol
as it finds blocks
the pool manager credits
pool manager credits the
manager credits the miner
credits the miner s
the miner s account
miner s account according
s account according to
account according to its
according to its share
to its share of
its share of the
share of the work
three instances of an
and transfers these funds
transfers these funds either
these funds either on
funds either on request
either on request or
on request or automatically
request or automatically to
or automatically to the
automatically to the aforementioned
to the aforementioned bitcoin
the aforementioned bitcoin address
too big pools despite
big pools despite their
pools despite their important
despite their important role
their important role of
important role of enabling
role of enabling small
the first instance with
first instance with interleave
instance with interleave i
pools can constitute a
can constitute a threat
constitute a threat to
a threat to the
threat to the bitcoin
to the bitcoin system
the bitcoin system if
bitcoin system if their
system if their size
if their size is
their size is too
size is too large
the second with interleave
second with interleave i
if one pool controls
one pool controls the
pool controls the majority
controls the majority of
the majority of mining
majority of mining power
the system becomes unstable
and the third with
the third with interleave
third with interleave i
fec encoding is simply
encoding is simply an
is simply an xor
simply an xor of
an xor of the
xor of the r
of the r data
the r data packets
r data packets hence
warns that the system
that the system is
the system is unstable
in layered interleaving each
system is unstable with
layered interleaving each data
is unstable with even
interleaving each data packet
unstable with even smaller
each data packet is
with even smaller pools
data packet is included
packet is included in
is included in c
included in c xors
each of which is
of which is generated
which is generated at
is generated at different
generated at different interleaves
in realistic scenarios of
at different interleaves from
realistic scenarios of the
different interleaves from the
scenarios of the bitcoin
interleaves from the original
of the bitcoin system
from the original data
the bitcoin system no
the original data stream
bitcoin system no pool
system no pool controls
no pool controls a
pool controls a majority
controls a majority of
a majority of the
majority of the mining
of the mining power
as we shall describe
we shall describe shortly
ensures that the c
that the c xors
for one day in
the c xors containing
one day in june
c xors containing a
xors containing a data
containing a data packet
a data packet do
data packet do not
packet do not have
do not have any
not have any other
a single pool called
single pool called ghash
of the blocks in
the blocks in the
blocks in the bitcoin
in the bitcoin main
the bitcoin main chain
the bitcoin community backlashed
bitcoin community backlashed at
community backlashed at the
backlashed at the pool
which has done nothing
has done nothing worse
done nothing worse than
nothing worse than being
worse than being extremely
than being extremely successful
io reduced its relative
reduced its relative mining
its relative mining power
relative mining power and
mining power and publicly
power and publicly committed
and publicly committed to
publicly committed to stay
committed to stay away
to stay away from
stay away from the
block withholding and its
withholding and its detection
and its detection classical
its detection classical block
detection classical block withholding
is an attack performed
an attack performed by
attack performed by a
performed by a pool
by a pool member
a pool member against
pool member against the
member against the other
against the other pool
the other pool members
the attacking miner registers
attacking miner registers with
miner registers with the
registers with the pool
with the pool and
the pool and apparently
pool and apparently starts
and apparently starts mining
apparently starts mining honestly
starts mining honestly it
mining honestly it regularly
honestly it regularly sends
it regularly sends the
regularly sends the pool
sends the pool partial
the pool partial proof
pool partial proof of
partial proof of work
data packet in common
the attacking miner sends
attacking miner sends only
the resulting protocol effectively
miner sends only partial
resulting protocol effectively has
sends only partial proof
protocol effectively has a
only partial proof of
effectively has a rate
partial proof of work
has a rate of
if it finds a
it finds a full
finds a full solution
a full solution that
full solution that constitutes
solution that constitutes a
that constitutes a full
constitutes a full proof
a full proof of
full proof of work
proof of work it
of work it discards
work it discards the
with each xor generated
it discards the solution
each xor generated from
xor generated from r
generated from r data
from r data packets
r data packets and
reducing the pool s
data packets and each
the pool s total
packets and each data
pool s total revenue
and each data packet
each data packet included
data packet included in
packet included in c
included in c xors
this attack is illustrated
attack is illustrated in
is illustrated in figure
illustrates layered interleaving for
layered interleaving for a
the attacker does not
attacker does not change
does not change the
not change the pool
change the pool s
the pool s effective
pool s effective mining
s effective mining power
and does not affect
does not affect directly
not affect directly the
affect directly the revenue
directly the revenue of
the revenue of other
revenue of other pools
the attacked pool shares
attacked pool shares its
pool shares its revenue
shares its revenue with
its revenue with the
revenue with the attacker
therefore each miner earns
each miner earns less
as the same revenue
the same revenue is
same revenue is distributed
revenue is distributed among
is distributed among more
distributed among more miners
recall that the proof
that the proof of
the proof of work
proof of work is
of work is only
work is only valid
is only valid for
only valid for a
valid for a specific
for a specific block
as it is the
it is the nonce
is the nonce with
the nonce with which
nonce with which the
with which the block
which the block s
the block s hash
block s hash is
s hash is smaller
standard fec schemes can
hash is smaller than
fec schemes can be
is smaller than its
schemes can be made
smaller than its target
can be made resistant
be made resistant to
made resistant to a
resistant to a certain
the attacking miner cannot
to a certain loss
attacking miner cannot use
a certain loss burst
miner cannot use it
certain loss burst length
loss burst length at
burst length at the
length at the cost
at the cost of
the cost of increased
cost of increased recovery
of increased recovery latency
increased recovery latency for
although the term block
recovery latency for all
the term block withholding
latency for all lost
term block withholding has
for all lost packets
block withholding has become
withholding has become canonical
including smaller bursts and
smaller bursts and singleton
note that the block
bursts and singleton drops
that the block is
the block is discarded
block is discarded and
is discarded and never
discarded and never introduced
and never introduced into
never introduced into the
introduced into the system
into the system as
layered interleaving provides graceful
the system as the
system as the name
interleaving provides graceful degradation
as the name block
the name block withholding
provides graceful degradation in
name block withholding implies
graceful degradation in the
degradation in the face
in the face of
the face of bursty
face of bursty loss
of bursty loss for
miners miners miners pool
bursty loss for constant
loss for constant encoding
for constant encoding overhead
constant encoding overhead singleton
encoding overhead singleton random
overhead singleton random losses
singleton random losses are
random losses are recovered
losses are recovered as
are recovered as quickly
recovered as quickly as
as quickly as possible
classical block withholding attack
by xors generated with
a group of miners
xors generated with an
group of miners attack
generated with an interleave
of miners attack pool
with an interleave of
with a block withholding
a block withholding attack
and each successive layer
denoted by a dashed
each successive layer of
by a dashed red
successive layer of xors
a dashed red arrow
layer of xors generated
of xors generated at
xors generated at a
generated at a higher
at a higher interleave
a higher interleave catches
higher interleave catches larger
interleave catches larger bursts
catches larger bursts missed
this attack reduces the
larger bursts missed by
attack reduces the attacker
bursts missed by the
reduces the attacker s
missed by the previous
the attacker s revenue
by the previous layer
attacker s revenue compared
s revenue compared to
revenue compared to solo
compared to solo mining
to solo mining or
solo mining or honest
the implementation of this
mining or honest pool
implementation of this algorithm
or honest pool participation
of this algorithm is
this algorithm is simple
algorithm is simple and
is simple and shown
simple and shown in
and shown in figure
it suffers from the
suffers from the reduced
from the reduced revenue
the reduced revenue like
reduced revenue like the
revenue like the other
like the other pool
the other pool participants
and its revenue is
a set of repair
its revenue is less
set of repair bins
revenue is less than
of repair bins is
is less than its
repair bins is maintained
less than its share
bins is maintained for
than its share of
is maintained for each
its share of the
maintained for each layer
share of the total
of the total mining
the total mining power
total mining power in
mining power in the
power in the system
with i bins for
i bins for a
bins for a layer
for a layer with
a layer with interleave
layer with interleave i
the classical block withholding
classical block withholding attack
block withholding attack can
withholding attack can therefore
attack can therefore only
a repair bin consists
can therefore only be
repair bin consists of
therefore only be used
bin consists of a
only be used for
consists of a partially
be used for sabotage
of a partially constructed
a partially constructed repair
partially constructed repair packet
at a cost to
a cost to the
cost to the attacker
an xor and the
xor and the recipe
and the recipe list
the recipe list of
recipe list of identifiers
list of identifiers of
of identifiers of data
identifiers of data packets
of data packets that
even if a pool
data packets that compose
if a pool detects
packets that compose the
a pool detects that
that compose the xor
pool detects that it
detects that it is
that it is under
it is under a
is under a block
under a block withholding
a block withholding attack
each intercepted data packet
intercepted data packet is
data packet is added
packet is added to
it might not be
is added to each
might not be able
added to each layer
not be able to
to each layer where
be able to detect
each layer where adding
able to detect which
layer where adding to
to detect which of
where adding to a
detect which of its
adding to a layer
which of its registered
to a layer simply
of its registered miners
a layer simply means
its registered miners are
layer simply means choosing
registered miners are the
simply means choosing a
miners are the perpetrators
means choosing a repair
choosing a repair bin
a repair bin from
repair bin from the
bin from the layer
from the layer s
a pool can estimate
the layer s set
pool can estimate its
can estimate its expected
estimate its expected mining
its expected mining power
incrementally updating the xor
expected mining power and
updating the xor with
mining power and its
the xor with the
power and its actual
xor with the new
and its actual mining
with the new data
its actual mining power
the new data packet
actual mining power by
mining power by the
power by the rates
by the rates of
the rates of partial
and adding the data
rates of partial proofs
adding the data packet
of partial proofs of
the data packet s
partial proofs of work
data packet s header
proofs of work and
packet s header to
of work and full
s header to the
work and full proofs
header to the recipe
and full proofs of
to the recipe list
full proofs of work
a counter is incremented
counter is incremented as
is incremented as each
incremented as each data
as each data packet
supplied by its miners
each data packet arrives
data packet arrives at
packet arrives at the
arrives at the appliance
a difference above a
difference above a set
above a set confidence
a set confidence interval
and choosing the repair
set confidence interval indicates
choosing the repair bin
confidence interval indicates an
the repair bin from
interval indicates an attack
repair bin from the
bin from the layer
from the layer s
the layer s set
to detect whether a
layer s set is
detect whether a single
s set is done
whether a single miner
set is done by
a single miner is
is done by taking
single miner is attacking
done by taking the
miner is attacking it
by taking the modulo
taking the modulo of
the modulo of the
modulo of the counter
of the counter with
the pool must use
the counter with the
pool must use a
counter with the number
must use a similar
with the number of
use a similar technique
the number of bins
number of bins in
of bins in each
bins in each layer
comparing the estimated mining
the estimated mining power
for a layer with
estimated mining power of
a layer with interleave
mining power of the
power of the attacker
of the attacker based
the attacker based on
attacker based on its
based on its partial
on its partial proof
its partial proof of
partial proof of work
proof of work with
the xth intercepted packet
of work with the
xth intercepted packet is
work with the fact
intercepted packet is added
with the fact it
packet is added to
the fact it never
is added to the
fact it never supplies
it never supplies a
never supplies a full
supplies a full proof
a full proof of
full proof of work
if the attacker has
the attacker has a
attacker has a small
has a small mining
a small mining power
it will send frequent
will send frequent partial
send frequent partial proofs
frequent partial proofs of
when a repair bin
partial proofs of work
a repair bin fills
repair bin fills up
bin fills up its
fills up its recipe
up its recipe list
but the pool will
its recipe list contains
the pool will only
recipe list contains r
pool will only expect
list contains r data
will only expect to
contains r data packets
only expect to see
r data packets it
expect to see a
data packets it fires
to see a full
see a full proof
a full proof of
full proof of work
proof of work at
of work at very
work at very low
a repair packet is
at very low frequency
repair packet is generated
packet is generated consisting
is generated consisting of
generated consisting of the
consisting of the xor
of the xor and
the xor and the
xor and the recipe
and the recipe list
it cannot obtain statistically
the recipe list and
cannot obtain statistically significant
recipe list and is
obtain statistically significant results
list and is scheduled
statistically significant results that
and is scheduled for
significant results that would
is scheduled for sending
results that would indicate
that would indicate an
would indicate an attack
while the repair bin
the repair bin is
repair bin is re
an attacker can use
attacker can use multiple
can use multiple small
use multiple small block
initialized with an empty
multiple small block withholding
with an empty recipe
small block withholding miners
an empty recipe list
block withholding miners and
empty recipe list and
withholding miners and replace
recipe list and blank
miners and replace them
list and blank xor
and replace them frequently
a small miner is
incoming repair packets are
repair packets are processed
packets are processed as
a miner whose expected
are processed as follows
miner whose expected full
whose expected full proof
expected full proof of
full proof of work
proof of work frequency
of work frequency is
if all the data
work frequency is yearly
all the data packets
the data packets contained
data packets contained in
packets contained in the
such a miner will
contained in the repair
a miner will see
in the repair s
miner will see a
the repair s recipe
will see a non
repair s recipe list
s recipe list have
recipe list have been
list have been received
have been received successfully
negligible average daily revenue
the repair packet is
repair packet is discarded
if the repair s
the repair s recipe
repair s recipe list
s recipe list contains
recipe list contains a
list contains a single
contains a single missing
a single missing data
single missing data packet
recovery can occur immediately
can occur immediately by
occur immediately by combining
immediately by combining the
by combining the xor
combining the xor in
the xor in the
xor in the repair
in the repair with
the repair with layer
if the attacker replaces
the attacker replaces such
attacker replaces such a
replaces such a small
such a small miner
a small miner every
small miner every month
he will collect about
will collect about b
at the end of
the end of each
end of each month
the pool must decide
pool must decide within
must decide within this
decide within this month
within this month whether
this month whether the
month whether the miner
whether the miner is
the miner is an
miner is an attacker
and revoke its earnings
or just an unlucky
just an unlucky honest
an unlucky honest miner
since an honest miner
an honest miner of
honest miner of this
miner of this power
of this power is
this power is unlikely
power is unlikely to
is unlikely to find
unlikely to find a
to find a full
find a full proof
a full proof of
full proof of work
proof of work within
of work within a
work within a month
according to the exponential
to the exponential distribution
a pool that rejects
pool that rejects miners
that rejects miners based
rejects miners based on
miners based on this
based on this criterion
on this criterion would
this criterion would reject
criterion would reject the
would reject the majority
reject the majority of
the majority of its
majority of its honest
of its honest miners
the alternative of rejecting
alternative of rejecting small
of rejecting small miners
rejecting small miners in
small miners in general
miners in general or
in general or distributing
general or distributing revenue
or distributing revenue on
distributing revenue on a
revenue on a yearly
on a yearly basis
a yearly basis contradicts
yearly basis contradicts the
basis contradicts the goal
contradicts the goal of
the goal of pooled
goal of pooled mining
layer with interleave of
m odel and s
odel and s tandard
and s tandard o
s tandard o peration
tandard o peration we
o peration we specify
peration we specify the
we specify the basic
specify the basic model
the basic model in
basic model in which
model in which participants
in which participants operate
which participants operate in
participants operate in section
operate in section iii
proceed to describe how
to describe how honest
describe how honest miners
how honest miners operate
honest miners operate in
miners operate in this
operate in this environment
in this environment in
this environment in sections
environment in sections iii
and how the classical
how the classical block
the classical block withholding
classical block withholding attack
block withholding attack is
withholding attack is implemented
attack is implemented with
is implemented with our
implemented with our model
with our model in
our model in section
model in section iii
model the system is
the system is comprised
system is comprised of
is comprised of the
comprised of the bitcoin
of the bitcoin network
the bitcoin network and
bitcoin network and nodes
network and nodes with
and nodes with unique
nodes with unique ids
and progresses in steps
a node i generates
node i generates tasks
i generates tasks which
generates tasks which are
tasks which are associated
which are associated with
are associated with its
associated with its id
with its id i
a node can work
node can work on
can work on a
work on a task
on a task for
a task for the
task for the duration
for the duration of
the duration of a
duration of a step
the result of this
result of this work
of this work is
this work is a
work is a set
is a set of
a set of partial
set of partial proofs
of partial proofs of
partial proofs of work
proofs of work and
of work and a
work and a set
and a set of
a set of full
set of full proofs
of full proofs of
full proofs of work
the number of proofs
number of proofs in
of proofs in each
proofs in each set
in each set has
each set has a
set has a poisson
has a poisson distribution
partial proofs with a
proofs with a large
with a large mean
a large mean and
large mean and full
mean and full proofs
and full proofs with
full proofs with a
proofs with a small
with a small mean
nodes that work on
that work on tasks
the other successfully received
work on tasks are
other successfully received data
on tasks are called
successfully received data packets
tasks are called a
are called a miners
if the repair contains
the repair contains multiple
miners have identical power
repair contains multiple missing
contains multiple missing data
multiple missing data packets
and hence identical probabilities
hence identical probabilities to
identical probabilities to generate
it cannot be used
probabilities to generate proofs
to generate proofs of
cannot be used immediately
generate proofs of work
be used immediately for
used immediately for recovery
immediately for recovery it
for recovery it is
the bitcoin network pays
recovery it is instead
bitcoin network pays for
it is instead stored
network pays for full
is instead stored in
pays for full proofs
instead stored in a
for full proofs of
stored in a table
full proofs of work
in a table that
a table that maps
table that maps missing
that maps missing data
maps missing data packets
missing data packets to
to acquire this payoff
data packets to repair
packets to repair packets
acquire this payoff an
this payoff an entity
payoff an entity publishes
an entity publishes a
entity publishes a task
whenever a data packet
publishes a task task
a data packet is
a task task and
data packet is subsequently
task task and its
packet is subsequently received
task and its corresponding
is subsequently received or
and its corresponding proof
subsequently received or recovered
its corresponding proof of
corresponding proof of work
proof of work to
of work to the
work to the network
this table is checked
table is checked to
the payoff goes to
is checked to see
payoff goes to the
goes to the id
checked to see if
to the id associated
the id associated with
to see if any
id associated with task
see if any xors
if any xors now
any xors now have
xors now have singleton
the bitcoin protocol normalizes
now have singleton losses
bitcoin protocol normalizes revenue
have singleton losses due
protocol normalizes revenue such
singleton losses due to
normalizes revenue such that
losses due to the
revenue such that the
due to the presence
such that the average
to the presence of
that the average total
the presence of the
the average total revenue
presence of the new
average total revenue distributed
of the new packet
total revenue distributed in
the new packet and
revenue distributed in each
new packet and can
distributed in each step
packet and can be
in each step is
and can be used
each step is a
can be used for
step is a constant
be used for recovering
is a constant throughout
used for recovering other
a constant throughout the
for recovering other missing
constant throughout the execution
recovering other missing packets
throughout the execution of
the execution of the
execution of the system
any node can transact
node can transact bitcoins
xors received from different
can transact bitcoins to
received from different layers
transact bitcoins to another
from different layers interact
bitcoins to another node
different layers interact to
to another node by
layers interact to recover
another node by issuing
interact to recover missing
node by issuing a
to recover missing data
by issuing a bitcoin
recover missing data packets
issuing a bitcoin transaction
since an xor received
nodes that generate tasks
an xor received at
that generate tasks but
xor received at a
generate tasks but outsource
received at a higher
tasks but outsource the
at a higher interleave
but outsource the work
a higher interleave can
outsource the work are
higher interleave can recover
the work are called
interleave can recover a
work are called pools
can recover a packet
recover a packet that
a packet that makes
packet that makes an
that makes an earlier
pools send tasks to
makes an earlier xor
send tasks to miners
an earlier xor at
tasks to miners over
earlier xor at a
to miners over the
xor at a lower
miners over the network
at a lower interleave
a lower interleave usable
lower interleave usable hence
the miners receive the
miners receive the tasks
though layered interleaving is
layered interleaving is equivalent
interleaving is equivalent to
is equivalent to c
equivalent to c different
and send the partial
send the partial and
the partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work to
of work to the
work to the pool
apart from working on
instances in terms of
from working on tasks
in terms of overhead
terms of overhead and
of overhead and design
its recovery power is
recovery power is much
power is much higher
is much higher and
much higher and comes
higher and comes close
and comes close to
comes close to standard
and receipt are instantaneous
we assume that the
assume that the number
that the number of
the number of miners
number of miners is
of miners is large
miners is large enough
is large enough such
large enough such that
enough such that mining
such that mining power
that mining power can
mining power can be
power can be split
can be split arbitrarily
be split arbitrarily without
split arbitrarily without resolution
arbitrarily without resolution constraints
denote the number of
the number of pools
number of pools with
of pools with p
the total number of
total number of mining
number of mining power
of mining power in
mining power in the
power in the system
in the system with
the system with m
system with m and
with m and the
m and the miners
and the miners participating
the miners participating in
miners participating in pool
participating in pool i
we use a quasistatic
use a quasistatic analysis
a quasistatic analysis where
quasistatic analysis where miner
analysis where miner participation
where miner participation in
miner participation in a
participation in a pool
in a pool does
a pool does not
pool does not change
does not change over
not change over time
solo mining a solo
mining a solo miner
a solo miner is
solo miner is a
miner is a node
is a node that
a node that generates
node that generates its
that generates its own
generates its own tasks
in every step it
every step it generates
step it generates a
it generates a task
works on it for
on it for the
it for the duration
for the duration of
the duration of the
duration of the step
second set of rsized
of the step and
set of rsized xors
the step and if
of rsized xors staggered
step and if it
rsized xors staggered start
and if it finds
xors staggered start xors
if it finds a
it finds a full
finds a full proof
a full proof of
full proof of work
it publishes this proof
publishes this proof of
this proof of work
proof of work to
of work to earn
work to earn the
to earn the payoff
pools a pool is
a pool is a
pool is a node
is a node that
a node that serves
node that serves as
that serves as a
serves as a coordinator
as a coordinator and
a coordinator and multiple
coordinator and multiple miners
and multiple miners can
multiple miners can register
miners can register to
can register to a
register to a pool
to a pool and
a pool and work
pool and work for
and work for it
in every step it
every step it generates
step it generates a
it generates a task
generates a task for
a task for each
task for each registered
for each registered miner
each registered miner and
registered miner and sends
miner and sends it
and sends it over
sends it over the
it over the network
each miner receives its
miner receives its task
receives its task and
its task and works
task and works on
and works on it
works on it for
on it for the
it for the duration
for the duration of
the duration of the
duration of the step
at the end of
the end of the
end of the step
the miner sends the
miner sends the pool
sends the pool the
the pool the full
pool the full and
the full and the
full and the partial
and the partial proofs
the partial proofs of
partial proofs of work
proofs of work it
of work it has
work it has found
the pool receives the
pool receives the proofs
receives the proofs of
the proofs of work
proofs of work of
of work of all
work of all its
of all its miners
registers the partial proofs
the partial proofs of
partial proofs of work
proofs of work and
of work and publishes
work and publishes the
and publishes the full
publishes the full proofs
it calculates its overall
calculates its overall revenue
and proceeds to distribute
proceeds to distribute it
to distribute it among
distribute it among its
it among its miners
each miner receives revenue
miner receives revenue proportional
receives revenue proportional to
revenue proportional to its
proportional to its success
to its success in
its success in the
success in the current
in the current step
namely the ratio of
the ratio of its
ratio of its partial
of its partial proofs
its partial proofs of
partial proofs of work
proofs of work out
of work out of
work out of all
out of all partial
of all partial proofs
all partial proofs of
partial proofs of work
proofs of work the
of work the pool
work the pool received
we assume that pools
assume that pools do
that pools do not
pools do not collect
do not collect fees
not collect fees of
collect fees of the
fees of the revenue
pool fees and their
fees and their implications
and their implications on
their implications on our
implications on our analysis
on our analysis are
our analysis are discussed
analysis are discussed in
are discussed in section
discussed in section ix
block withholding miner a
withholding miner a miner
miner a miner registered
a miner registered at
miner registered at a
registered at a pool
at a pool can
a pool can perform
pool can perform the
can perform the classical
perform the classical block
the classical block withholding
classical block withholding attack
an attacker miner operates
attacker miner operates as
miner operates as if
operates as if it
as if it worked
if it worked for
it worked for the
worked for the pool
it receives its tasks
receives its tasks and
its tasks and works
tasks and works on
and works on them
only at the end
at the end of
the end of each
end of each round
of each round it
each round it sends
round it sends only
it sends only its
sends only its partial
only its partial proofs
its partial proofs of
partial proofs of work
and omits full proofs
omits full proofs of
full proofs of work
proofs of work if
of work if it
work if it had
if it had found
it had found any
the pool registers the
pool registers the miner
registers the miner s
the miner s partial
miner s partial proofs
but cannot distinguish between
cannot distinguish between miners
distinguish between miners running
between miners running honestly
miners running honestly and
running honestly and block
honestly and block withholding
and block withholding miners
the implications are that
implications are that a
are that a miner
that a miner that
a miner that engages
miner that engages in
that engages in block
engages in block withholding
in block withholding does
block withholding does not
withholding does not contribute
does not contribute to
not contribute to the
contribute to the pool
to the pool s
the pool s overall
pool s overall mining
s overall mining power
but still shares the
still shares the pool
shares the pool s
the pool s revenue
pool s revenue according
s revenue according to
revenue according to its
according to its sent
to its sent partial
its sent partial proofs
sent partial proofs of
partial proofs of work
to reason about a
reason about a pool
about a pool s
a pool s efficiency
pool s efficiency we
s efficiency we define
efficiency we define its
we define its per
miner revenue as follows
the revenue density of
revenue density of a
density of a pool
of a pool is
a pool is the
pool is the ratio
is the ratio between
the ratio between the
ratio between the average
between the average revenue
the average revenue a
average revenue a pool
revenue a pool member
a pool member earns
pool member earns and
member earns and the
earns and the average
and the average revenue
the average revenue it
average revenue it would
revenue it would have
it would have earned
would have earned as
have earned as a
earned as a solo
as a solo miner
the revenue density of
revenue density of a
density of a solo
of a solo miner
and that of a
that of a miner
of a miner working
a miner working with
miner working with an
working with an unattacked
with an unattacked pool
an unattacked pool are
unattacked pool are one
if a pool is
a pool is attacked
pool is attacked with
is attacked with block
attacked with block withholding
its revenue density decreases
continuous analysis because our
analysis because our analysis
because our analysis will
our analysis will be
analysis will be of
will be of the
be of the average
of the average revenue
we will consider proofs
will consider proofs of
consider proofs of work
both full and partial
as continuous deterministic sizes
according to their probability
work on a task
on a task therefore
a task therefore results
task therefore results in
therefore results in a
results in a deterministic
in a deterministic fraction
a deterministic fraction of
deterministic fraction of proof
fraction of proof of
of proof of work
t he p ool
he p ool g
p ool g ame
ool g ame a
the pool block withholding
pool block withholding attack
block withholding attack just
withholding attack just as
attack just as a
just as a miner
as a miner can
a miner can perform
miner can perform block
can perform block withholding
perform block withholding on
block withholding on a
withholding on a pool
on a pool j
a pool i can
pool i can use
i can use some
can use some of
use some of its
some of its mining
of its mining power
its mining power to
mining power to infiltrate
power to infiltrate a
to infiltrate a pool
infiltrate a pool j
a pool j and
pool j and perform
j and perform a
and perform a block
perform a block withholding
a block withholding attack
block withholding attack on
withholding attack on j
denote the amount of
the amount of such
amount of such infiltrating
of such infiltrating mining
such infiltrating mining power
infiltrating mining power at
mining power at step
power at step t
at step t by
step t by xi
miners working for pool
working for pool i
either mining honestly or
mining honestly or used
honestly or used for
or used for infiltrating
used for infiltrating pool
for infiltrating pool j
are loyal to pool
loyal to pool i
at the end of
the end of a
end of a round
pool i aggregates its
i aggregates its revenue
aggregates its revenue from
its revenue from mining
revenue from mining in
from mining in the
mining in the current
in the current round
the current round and
current round and from
round and from its
and from its infiltration
from its infiltration in
its infiltration in the
infiltration in the previous
in the previous round
it distributes the revenue
distributes the revenue evenly
the revenue evenly among
revenue evenly among all
evenly among all its
among all its loyal
all its loyal miners
its loyal miners according
loyal miners according to
miners according to their
according to their partial
to their partial proofs
their partial proofs of
partial proofs of work
the pool s miners
pool s miners are
s miners are oblivious
miners are oblivious to
are oblivious to their
oblivious to their role
to their role and
their role and they
role and they operate
and they operate as
they operate as regular
operate as regular honest
as regular honest miners
revenue convergence note that
convergence note that pool
note that pool j
that pool j sends
pool j sends its
j sends its revenue
sends its revenue to
its revenue to infiltrators
revenue to infiltrators from
to infiltrators from pool
infiltrators from pool i
from pool i at
pool i at the
i at the end
at the end of
the end of the
end of the step
and this revenue is
this revenue is calculated
revenue is calculated in
is calculated in pool
calculated in pool i
in pool i at
pool i at the
i at the beginning
at the beginning of
the beginning of the
beginning of the subsequent
of the subsequent step
if there is a
there is a chain
is a chain of
a chain of pools
where each pool infiltrates
each pool infiltrates the
pool infiltrates the previous
infiltrates the previous one
comparison of packet recovery
of packet recovery probability
the pool revenue will
pool revenue will not
revenue will not be
will not be static
since the revenue from
the revenue from infiltration
revenue from infiltration takes
from infiltration takes one
infiltration takes one step
takes one step to
one step to take
step to take each
to take each hop
from the first step
the revenue of pool
since it is only
it is only infiltrated
is only infiltrated and
only infiltrated and loses
infiltrated and loses some
and loses some of
loses some of its
some of its revenue
of its revenue for
its revenue for pool
optimizations staggered start for
starting from the second
staggered start for rate
from the second step
limiting in the naive
the revenue of pool
in the naive implementation
the naive implementation of
naive implementation of the
implementation of the layered
of the layered interleaving
the layered interleaving algorithm
comprised of its own
of its own mining
repair packets are transmitted
its own mining and
packets are transmitted as
own mining and its
are transmitted as soon
mining and its revenue
transmitted as soon as
and its revenue from
as soon as repair
its revenue from the
soon as repair bins
revenue from the infiltration
as repair bins fill
from the infiltration of
repair bins fill and
the infiltration of pool
bins fill and allow
fill and allow them
and allow them to
allow them to be
them to be constructed
with some revenue lost
some revenue lost due
revenue lost due to
lost due to its
due to its infiltration
all the repair bins
to its infiltration by
the repair bins in
its infiltration by pool
repair bins in a
bins in a layer
in a layer fill
a layer fill in
layer fill in quick
fill in quick succession
starting from the third
from the third step
the revenue of pool
the arrival of packets
max is the longest
is the longest chain
the longest chain in
longest chain in the
chain in the system
the revenue stabilizes after
if there are loops
there are loops in
are loops in the
loops in the infiltration
in the infiltration graph
the system will converge
will successively fill the
system will converge to
successively fill the four
will converge to a
fill the four repair
converge to a certain
the four repair bins
to a certain revenue
four repair bins in
repair bins in layer
as stated in the
stated in the following
in the following lemma
this behavior leads to
behavior leads to a
leads to a large
to a large number
a large number of
large number of repair
number of repair packets
of repair packets being
repair packets being generated
packets being generated and
being generated and sent
generated and sent within
and sent within a
sent within a short
within a short period
a short period of
if infiltration rates are
short period of time
infiltration rates are constant
which results in undesirable
the pool revenues converge
results in undesirable overhead
pool revenues converge to
in undesirable overhead and
revenues converge to a
undesirable overhead and traffic
converge to a limit
overhead and traffic spikes
to a limit as
a limit as time
limit as time progresses
we would like to
would like to rate
denote the revenue density
the revenue density of
revenue density of pool
density of pool i
limit transmissions of repair
of pool i at
transmissions of repair packets
pool i at the
of repair packets to
i at the end
repair packets to one
at the end of
packets to one for
the end of step
to one for every
end of step t
one for every r
of step t by
for every r data
step t by ri
every r data packets
this problem is fixed
problem is fixed by
is fixed by staggering
fixed by staggering the
by staggering the starting
staggering the starting sizes
the starting sizes of
starting sizes of the
and define the revenue
sizes of the bins
define the revenue density
the revenue density vector
revenue density vector r
analogous to the starting
to the starting positions
the starting positions of
starting positions of runners
positions of runners in
of runners in a
runners in a sprint
the very first time
very first time bin
first time bin number
time bin number x
bin number x in
number x in a
x in a layer
in a layer of
a layer of interleave
layer of interleave i
of interleave i fires
it does so at
does so at size
so at size x
at size x mod
size x mod r
the first repair bin
first repair bin in
repair bin in the
bin in the second
in the second layer
the second layer with
second layer with interleave
would fire at size
the second would fire
second would fire at
would fire at size
the revenues at all
revenues at all pools
at all pools converge
all pools converge as
pools converge as follows
for the first i
the first i data
first i data packets
i data packets added
data packets added to
packets added to a
added to a layer
to a layer with
a layer with interleave
layer with interleave i
r fire immediately with
fire immediately with just
immediately with just one
with just one packet
just one packet in
one packet in them
for the next i
the next i data
next i data packets
i data packets added
r fire immediately with
fire immediately with two
immediately with two data
with two data packets
two data packets in
data packets in them
and so on until
so on until r
on until r i
until r i data
r i data packets
i data packets have
data packets have been
packets have been added
have been added to
been added to the
added to the layer
to the layer and
the layer and all
layer and all bins
and all bins have
all bins have fired
bins have fired exactly
have fired exactly once
p in every round
pool i uses its
i uses its mining
uses its mining power
its mining power of
mining power of m
all bins fire at
bins fire at size
fire at size r
now that they have
that they have been
they have been staggered
j used for direct
have been staggered at
used for direct mining
been staggered at the
for direct mining p
staggered at the start
r fire for any
fire for any i
for any i data
any i data packets
and shares it among
shares it among its
it among its m
the outlined scheme works
outlined scheme works when
scheme works when i
works when i is
when i is greater
i is greater than
is greater than or
greater than or equal
than or equal to
or equal to r
as is usually the
is usually the case
if i is smaller
i is smaller than
is smaller than r
all sums are over
sums are over the
are over the range
the bin with index
bin with index x
with index x fires
index x fires at
denote the direct mining
the direct mining revenue
direct mining revenue density
mining revenue density of
revenue density of each
density of each pool
which is a constant
is a constant factor
the initial firing sizes
initial firing sizes would
firing sizes would be
for the first bin
the first bin and
for the second bin
if r and i
r and i are
and i are not
i are not integral
are not integral multiples
not integral multiples of
integral multiples of each
multiples of each other
limiting still works but
still works but is
works but is slightly
but is slightly less
is slightly less effective
slightly less effective due
less effective due to
effective due to rounding
due to rounding errors
delaying xors in the
xors in the naive
in the naive implementation
repair packets are transmitted
packets are transmitted as
are transmitted as soon
transmitted as soon as
as soon as they
soon as they are
as they are generated
this results in the
results in the repair
in the repair packet
the repair packet leaving
repair packet leaving immediately
packet leaving immediately after
leaving immediately after the
immediately after the last
after the last data
the last data packet
last data packet that
data packet that was
packet that was added
that was added to
was added to it
the pool game in
pool game in the
game in the pool
in the pool game
which lowers burst tolerance
the pool game pools
lowers burst tolerance if
pool game pools try
burst tolerance if the
game pools try to
tolerance if the repair
pools try to optimize
if the repair packet
try to optimize their
the repair packet was
to optimize their infiltration
repair packet was generated
optimize their infiltration rates
packet was generated at
their infiltration rates of
was generated at interleave
infiltration rates of other
generated at interleave i
rates of other pools
of other pools to
other pools to maximize
pools to maximize their
to maximize their revenue
the resulting protocol can
resulting protocol can tolerate
protocol can tolerate a
can tolerate a burst
the overall number of
tolerate a burst of
overall number of miners
a burst of i
number of miners and
burst of i lost
of miners and the
of i lost data
miners and the number
i lost data packets
and the number of
lost data packets excluding
the number of miners
data packets excluding the
number of miners loyal
packets excluding the repair
of miners loyal to
miners loyal to each
loyal to each pool
to each pool remain
each pool remain constant
pool remain constant throughout
but the burst could
remain constant throughout the
constant throughout the game
the burst could swallow
burst could swallow both
could swallow both the
swallow both the repair
time progresses in rounds
both the repair and
the repair and the
repair and the last
and the last data
the last data packet
let s be a
last data packet in
s be a constant
data packet in it
be a constant integer
packet in it as
a constant integer large
in it as they
constant integer large enough
it as they are
integer large enough that
as they are not
large enough that revenue
they are not separated
enough that revenue can
are not separated by
that revenue can be
not separated by the
revenue can be approximated
separated by the requisite
can be approximated as
by the requisite interleave
be approximated as its
approximated as its convergence
as its convergence limit
the solution to this
in each round the
solution to this is
each round the system
to this is simple
round the system takes
this is simple delay
the system takes s
is simple delay sending
system takes s steps
takes s steps and
simple delay sending the
s steps and then
steps and then a
delay sending the repair
and then a single
then a single pool
sending the repair packet
the repair packet generated
repair packet generated by
packet generated by a
picked with a round
generated by a repair
by a repair bin
a repair bin until
repair bin until the
bin until the next
until the next time
the next time a
next time a data
time a data packet
may change its infiltration
a data packet is
change its infiltration rates
data packet is added
its infiltration rates of
packet is added to
infiltration rates of all
is added to the
rates of all other
added to the now
of all other pools
to the now empty
the now empty bin
the total revenue of
total revenue of each
revenue of each step
which happens i packets
of each step is
each step is normalized
happens i packets later
step is normalized to
i packets later and
packets later and introduces
later and introduces the
and introduces the required
introduces the required interleave
the required interleave between
required interleave between the
interleave between the repair
between the repair packet
the repair packet and
so the revenue per
repair packet and the
the revenue per round
packet and the last
revenue per round is
and the last data
per round is one
the last data packet
last data packet included
data packet included in
packet included in it
the pool taking a
pool taking a step
taking a step knows
notice that although transmitting
a step knows the
that although transmitting the
step knows the rate
although transmitting the xor
knows the rate of
transmitting the xor immediately
the rate of infiltrators
the xor immediately results
rate of infiltrators attacking
xor immediately results in
of infiltrators attacking it
immediately results in faster
results in faster recovery
though not their identity
doing so also reduces
so also reduces the
also reduces the probability
reduces the probability of
and the revenue rates
the probability of a
the revenue rates of
probability of a lost
revenue rates of each
of a lost packet
rates of each of
a lost packet being
of each of the
lost packet being recovered
each of the other
of the other pools
this knowledge is required
knowledge is required to
is required to optimize
required to optimize a
off results in a
to optimize a pool
results in a minor
optimize a pool s
in a minor control
a pool s revenue
a minor control knob
minor control knob permitting
control knob permitting us
knob permitting us to
permitting us to balance
as we see next
us to balance speed
to balance speed against
balance speed against burst
speed against burst tolerance
we explain in section
explain in section viii
in section viii how
section viii how a
our default configuration is
viii how a pool
default configuration is to
how a pool can
configuration is to transmit
a pool can technically
is to transmit the
pool can technically obtain
to transmit the xor
can technically obtain this
transmit the xor immediately
technically obtain this knowledge
general analysis recall that
analysis recall that mi
recall that mi is
that mi is the
mi is the number
is the number of
the number of miners
number of miners loyal
of miners loyal to
miners loyal to pool
loyal to pool i
envelope analysis to start
analysis to start with
we note that no
is the number of
note that no two
the number of miners
that no two repair
number of miners used
no two repair packets
of miners used by
two repair packets generated
miners used by pool
repair packets generated at
used by pool i
packets generated at different
by pool i to
generated at different interleaves
pool i to infiltrate
at different interleaves i
i to infiltrate pool
to infiltrate pool j
infiltrate pool j at
pool j at step
j at step t
the mining rate of
mining rate of pool
rate of pool i
of pool i is
pool i is therefore
i is therefore the
is therefore the number
therefore the number of
the number of its
number of its loyal
of its loyal miners
its loyal miners minus
loyal miners minus the
miners minus the miners
minus the miners it
the miners it uses
miners it uses for
it uses for infiltration
will have more than
have more than one
more than one data
this effective mining rate
than one data packet
effective mining rate is
one data packet in
mining rate is divided
data packet in common
rate is divided by
packet in common as
is divided by the
in common as long
divided by the total
common as long as
by the total mining
as long as the
the total mining rate
long as the least
total mining rate in
as the least common
mining rate in the
the least common multiple
rate in the system
namely the number of
the number of all
number of all miners
of all miners that
of the interleaves is
all miners that do
the interleaves is greater
miners that do not
interleaves is greater than
that do not engage
is greater than r
do not engage in
greater than r i
not engage in block
engage in block withholding
pairings of repair bins
of repair bins in
denote the direct mining
repair bins in two
the direct mining rate
bins in two different
direct mining rate of
in two different layers
mining rate of pool
two different layers with
rate of pool i
different layers with interleaves
of pool i at
layers with interleaves i
pool i at step
i at step t
at step t by
step t by pp
t by pp mi
by pp mi j
a good rule of
good rule of thumb
rule of thumb is
of thumb is to
thumb is to select
is to select interleaves
to select interleaves that
select interleaves that are
interleaves that are relatively
that are relatively prime
are relatively prime to
relatively prime to maximize
prime to maximize their
to maximize their lcm
k the revenue of
the revenue of pool
and also ensure that
revenue of pool i
also ensure that the
of pool i in
ensure that the larger
pool i in step
that the larger interleave
i in step t
the larger interleave is
in step t taken
larger interleave is greater
step t taken through
interleave is greater than
t taken through infiltration
is greater than r
taken through infiltration from
through infiltration from pool
infiltration from pool j
from pool j s
pool j s revenue
let us assume that
j s revenue in
us assume that packets
s revenue in step
assume that packets are
revenue in step t
that packets are dropped
packets are dropped with
are dropped with uniform
given a lost data
a lost data packet
what is the probability
is the probability that
the probability that we
probability that we can
that we can recover
we can recover it
pool i distributes this
we can recover a
i distributes this revenue
can recover a data
distributes this revenue among
recover a data packet
this revenue among its
a data packet if
revenue among its mi
data packet if at
packet if at least
if at least one
at least one of
least one of the
one of the c
of the c xors
the c xors containing
c xors containing it
xors containing it is
i members loyal and
containing it is re
members loyal and infiltrators
define the p p
the p p infiltration
p p infiltration matrix
p infiltration matrix by
infiltration matrix by its
matrix by its i
local recovery for receiver
recovery for receiver loss
for receiver loss ceived
receiver loss ceived correctly
loss ceived correctly and
ceived correctly and usable
all the other data
i ij the revenue
the other data packets
other data packets in
ij the revenue density
data packets in it
packets in it have
the revenue density of
in it have also
it have also been
revenue density of pool
have also been received
also been received correctly
density of pool i
of pool i at
pool i at the
i at the end
at the end of
the probability of in
the end of step
probability of in the
end of step t
of in the absence
of step t is
in the absence of
step t is its
the absence of intelligent
t is its revenue
absence of intelligent flow
is its revenue from
of intelligent flow control
its revenue from direct
intelligent flow control mechanisms
revenue from direct mining
flow control mechanisms like
from direct mining together
control mechanisms like which
direct mining together with
mechanisms like which is
mining together with its
like which is simply
together with its revenue
with its revenue from
its revenue from infiltrated
revenue from infiltrated pools
divided by the number
by the number of
the number of its
number of its loyal
of its loyal miners
its loyal miners together
loyal miners together with
miners together with block
withholding infiltrators that attack
the probability of a
infiltrators that attack it
probability of a received
of a received tcp
inexpensive xor being unusable
xor being unusable is
being unusable is the
unusable is the complement
hosts can be easily
can be easily overwhelmed
be easily overwhelmed and
easily overwhelmed and drop
overwhelmed and drop packets
and drop packets during
drop packets during traffic
packets during traffic spikes
during traffic spikes or
traffic spikes or cpu
the probability x of
probability x of a
x of a sent
of a sent xor
a sent xor being
sent xor being nance
xor being nance tasks
being nance tasks like
nance tasks like garbage
tasks like garbage collection
reliable applicationdropped or unusable
applicationdropped or unusable is
or unusable is the
unusable is the sum
and the revenue vector
is the sum of
the revenue vector at
the sum of the
revenue vector at step
sum of the probability
vector at step t
of the probability that
at step t is
the probability that it
step t is hereinafter
probability that it level
t is hereinafter we
that it level protocols
is hereinafter we move
it level protocols layered
hereinafter we move to
level protocols layered over
we move to a
protocols layered over udp
move to a static
layered over udp for
to a static state
over udp for reliable
a static state analysis
udp for reliable multiwas
static state analysis and
for reliable multiwas dropped
state analysis and omit
reliable multiwas dropped and
analysis and omit the
multiwas dropped and the
and omit the t
dropped and the probability
omit the t argument
and the probability that
the t argument in
the probability that it
t argument in the
probability that it was
argument in the expressions
that it was received
it was received and
was received and cast
or high speed data
high speed data transfer
since the row sums
the row sums of
row sums of the
sums of the infiltration
of the infiltration matrix
the infiltration matrix are
infiltration matrix are smaller
matrix are smaller than
are smaller than one
its largest eigenvalue is
largest eigenvalue is smaller
eigenvalue is smaller than
recall that difficulty is
that difficulty is only
difficulty is only adjusted
is only adjusted periodically
and there are transient
there are transient effects
are transient effects that
transient effects that are
effects that are not
that are not covered
are not covered by
not covered by this
covered by this stable
we discuss this in
discuss this in section
this in section viii
miners miners miners the
miners miners the revenue
miners the revenue its
the revenue its infiltrators
revenue its infiltrators obtained
its infiltrators obtained from
infiltrators obtained from pool
would ordinarily go back
ordinarily go back to
go back to the
back to the sender
to the sender to
the sender to retrieve
sender to retrieve the
to retrieve the lost
retrieve the lost packet
even though it was
though it was dropped
it was dropped at
was dropped at the
the revenue per loyal
dropped at the receiver
revenue per loyal pool
at the receiver after
the receiver after since
receiver after since it
after since it is
miner is therefore r
since it is easy
it is easy to
is easy to ensure
easy to ensure that
to ensure that no
ensure that no two
that no two xors
no two xors share
two xors share covering
xors share covering the
share covering the entire
covering the entire geographical
the entire geographical distance
more than one data
than one data packet
the usability probabilities of
usability probabilities of the
probabilities of the maelstrom
of the maelstrom proxy
the maelstrom proxy acts
maelstrom proxy acts as
proxy acts as a
acts as a local
as a local packet
controls its infiltration rate
a local packet cache
its infiltration rate of
infiltration rate of pool
stordifferent xors are independent
the probability of all
probability of all ing
of all ing incoming
all ing incoming packets
ing incoming packets for
incoming packets for a
packets for a short
for a short period
a short period of
short period of time
period of time and
of time and prothe
time and prothe c
and will choose the
and prothe c xors
will choose the value
prothe c xors being
choose the value that
c xors being dropped
the value that maximizes
xors being dropped or
value that maximizes the
being dropped or unusable
that maximizes the revenue
dropped or unusable is
maximizes the revenue density
or unusable is xc
viding hooks that allow
hooks that allow protocols
that allow protocols to
allow protocols to first
on the first round
protocols to first query
the first round of
first round of the
to first query the
round of the pool
of the pool game
first query the cache
query the cache the
the cache the probability
cache the probability of
the value of r
the probability of correctly
probability of correctly receiving
of correctly receiving at
correctly receiving at least
is maximized at a
receiving at least one
maximized at a single
at least one usable
at a single point
least one usable to
a single point in
one usable to locate
single point in the
usable to locate missing
point in the feasible
to locate missing packets
in the feasible range
locate missing packets before
missing packets before sending
packets before sending retransmission
before sending retransmission xor
sending retransmission xor is
the probability of recovrequests
probability of recovrequests back
of recovrequests back to
recovrequests back to the
back to the sender
future versions of maelstrom
versions of maelstrom ering
of maelstrom ering the
cannot not react to
maelstrom ering the lost
not react to pool
ering the lost data
the lost data packet
lost data packet is
this point is the
point is the stable
is the stable state
which expands to could
the stable state of
expands to could potentially
stable state of the
to could potentially use
state of the system
could potentially use knowledge
potentially use knowledge of
use knowledge of protocol
knowledge of protocol internals
of protocol internals to
and we denote the
we denote the value
denote the value of
the value of x
by intercepting and this
intercepting and this closed
form formula only gives
formula only gives us
only gives us a
gives us a lower
and the values of
us a lower bound
the values of the
a lower bound satisfying
values of the corresponding
lower bound satisfying retransmission
of the corresponding revenues
bound satisfying retransmission requests
the corresponding revenues of
satisfying retransmission requests sent
corresponding revenues of the
retransmission requests sent by
revenues of the pools
requests sent by the
of the pools with
sent by the receiver
the pools with r
by the receiver in
the receiver in on
receiver in on the
in on the recovery
on the recovery probability
since the xor usability
the xor usability for
substituting the stable value
the stable value x
or by resending packets
by resending packets when
we obtain the revenues
resending packets when acmula
obtain the revenues of
the revenues of the
packets when acmula does
revenues of the two
of the two pools
when acmula does not
acmula does not factor
does not factor in
all are given in
not factor in the
are given in figure
factor in the probability
in the probability of
the probability of the
probability of the other
of the other data
the other data knowledgments
other data knowledgments are
data knowledgments are not
knowledgments are not observed
are not observed within
not observed within a
observed within a certain
within a certain time
a certain time period
certain time period in
time period in an
to simplify the expressions
period in an ack
packets in the xor
in the xor being
the xor being dropped
xor being dropped and
being dropped and recovered
we extend the analysis
extend the analysis to
the analysis to bursty
analysis to bursty losses
no attack if no
attack if no pool
if no pool engages
no pool engages in
pool engages in block
engages in block withholding
if the lost data
the lost data packet
lost data packet was
data packet was part
packet was part of
was part of a
part of a loss
of a loss burst
a loss burst of
loss burst of size
burst of size b
repair packets generated at
packets generated at interleaves
generated at interleaves less
at interleaves less than
interleaves less than b
less than b are
than b are dropped
b are dropped or
are dropped or useless
dropped or useless with
or useless with high
useless with high probability
and we have i
and we can discount
we can discount them
probability of recovering the
of recovering the data
recovering the data packet
the data packet is
data packet is then
each miner s revenue
miner s revenue is
s revenue is proportional
revenue is proportional to
is the number of
is proportional to its
the number of xors
proportional to its power
number of xors generated
of xors generated at
xors generated at interleaves
generated at interleaves greater
at interleaves greater than
interleaves greater than b
be it in a
it in a pool
in a pool or
a pool or working
pool or working solo
the formulae derived for
formulae derived for xor
derived for xor usability
for xor usability still
xor usability still hold
o ne attacker we
since packet losses with
ne attacker we begin
packet losses with more
attacker we begin our
losses with more than
we begin our analysis
with more than b
begin our analysis with
more than b intervening
our analysis with a
than b intervening packets
analysis with a simplified
b intervening packets between
with a simplified game
intervening packets between them
a simplified game of
packets between them have
simplified game of two
between them have independent
game of two pools
them have independent probability
there is only correlation
is only correlation within
only correlation within the
correlation within the bursts
how does this compare
does this compare to
this compare to traditional
codes such as reed
miners outside both pools
outside both pools mine
both pools mine solo
or with closed pools
with closed pools that
closed pools that do
pools that do not
that do not attack
do not attack and
not attack and cannot
attack and cannot be
and cannot be attacked
c repair packets are
repair packets are generated
packets are generated and
are generated and sent
generated and sent for
and sent for every
sent for every r
for every r data
every r data packets
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
and the correct delivery
the correct delivery of
correct delivery of any
delivery of any r
of any r of
any r of the
r of the r
the dashed red arrow
dashed red arrow indicates
red arrow indicates that
arrow indicates that x
c packets transmitted is
packets transmitted is sufficient
transmitted is sufficient to
is sufficient to reconstruct
sufficient to reconstruct the
to reconstruct the original
reconstruct the original r
the original r data
original r data packets
s mining power infiltrates
mining power infiltrates pool
given a lost data
a lost data packet
with a block withholding
a block withholding attack
we can recover it
can recover it if
recover it if at
it if at least
if at least r
at least r packets
least r packets are
does not engage in
r packets are received
not engage in block
packets are received correctly
engage in block withholding
are received correctly in
received correctly in the
correctly in the encoding
in the encoding set
the encoding set of
all of its m
encoding set of r
loyal miners work on
miners work on its
c data and repair
work on its behalf
data and repair packets
and repair packets that
repair packets that the
packets that the lost
that the lost packet
the lost packet belongs
lost packet belongs to
on the other hand
the other hand does
other hand does not
the probability of recovering
hand does not employ
probability of recovering a
does not employ x
of recovering a lost
recovering a lost packet
a lost packet is
lost packet is equivalent
packet is equivalent to
is equivalent to the
equivalent to the probability
to the probability of
the probability of losing
probability of losing c
of its loyal miners
or less packets from
less packets from the
packets from the total
from the total r
and its direct mining
its direct mining power
direct mining power is
mining power is only
power is only m
since the number of
the number of other
number of other lost
of other lost packets
other lost packets in
lost packets in the
packets in the xor
in the xor is
the xor is a
xor is a random
is a random variable
a random variable y
random variable y and
variable y and has
the bitcoin system normalizes
y and has a
bitcoin system normalizes these
and has a binomial
system normalizes these rates
has a binomial distribution
normalizes these rates by
a binomial distribution with
these rates by the
binomial distribution with parameters
rates by the total
by the total number
the total number of
total number of miners
number of miners that
of miners that publish
miners that publish full
that publish full proofs
namely all miners but
all miners but x
the pools direct revenues
pools direct revenues are
direct revenues are therefore
revenues are therefore m
is the summation z
the summation z c
we plot the recovery
plot the recovery probability
the recovery probability curves
recovery probability curves for
probability curves for layered
curves for layered interleaving
for layered interleaving and
layered interleaving and reed
solomon against uniformly random
against uniformly random loss
uniformly random loss rate
note that the curves
that the curves are
divides its revenue among
the curves are very
its revenue among its
curves are very close
revenue among its loyal
are very close to
among its loyal miners
very close to each
its loyal miners and
close to each other
loyal miners and the
miners and the miners
and the miners that
the miners that infiltrated
miners that infiltrated it
especially in the loss
in the loss range
the loss range of
loss range of interest
range of interest between
its revenue density is
revenue density is therefore
density is therefore r
implementation details we initially
details we initially implemented
we initially implemented and
initially implemented and evaluated
implemented and evaluated maelstrom
and evaluated maelstrom as
evaluated maelstrom as a
maelstrom as a user
performance turned out to
turned out to be
out to be limited
to be limited by
be limited by copying
limited by copying and
by copying and context
and we subsequently reimplemented
we subsequently reimplemented the
subsequently reimplemented the system
reimplemented the system as
the system as a
system as a module
as a module that
a module that runs
module that runs within
that runs within the
runs within the linux
at an encoding rate
an encoding rate of
the experimental prototype of
experimental prototype of the
prototype of the kernel
of the kernel version
the kernel version reaches
kernel version reaches output
version reaches output speeds
reaches output speeds close
output speeds close to
game progress bitcoin network
progress bitcoin network figure
gigabit per second of
per second of combined
second of combined data
of combined data and
combined data and fec
data and fec traffic
limited only by the
only by the capacity
by the capacity of
the capacity of the
capacity of the outbound
of the outbound network
the outbound network card
we obtain the expression
obtain the expression for
the expression for r
lambda networks are already
networks are already reaching
are already reaching speeds
already reaching speeds of
and higher speeds are
higher speeds are a
speeds are a certainty
are a certainty down
a certainty down the
certainty down the road
we envision maelstrom as
envision maelstrom as a
maelstrom as a small
as a small rack
style cluster of blade
each acting as an
acting as an individual
as an individual proxy
traffic would be distributed
would be distributed over
be distributed over such
distributed over such a
over such a rack
such a rack by
a rack by partitioning
rack by partitioning the
by partitioning the address
partitioning the address space
the address space of
address space of the
space of the remote
of the remote datacenter
the remote datacenter and
remote datacenter and routing
datacenter and routing different
and routing different segments
divides its revenue among
routing different segments of
its revenue among its
different segments of the
revenue among its registered
segments of the space
among its registered miners
of the space through
the space through distinct
space through distinct maelstrom
through distinct maelstrom appliance
distinct maelstrom appliance pairs
the revenue includes both
revenue includes both its
includes both its direct
both its direct mining
its direct mining revenue
direct mining revenue and
mining revenue and b
we plan to experiment
plan to experiment with
to experiment with such
numerical analysis we analyze
experiment with such configurations
analysis we analyze this
we analyze this game
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
which would also permit
by finding the x
would also permit us
also permit us to
permit us to explore
us to explore faulttolerance
to explore faulttolerance issues
if a maelstrom blade
a maelstrom blade fails
and substituting this value
substituting this value for
this value for r
and to support load
balancing schemes that might
schemes that might vary
that might vary the
we vary the sizes
might vary the ip
vary the sizes of
vary the ip address
the sizes of the
the ip address space
sizes of the pools
ip address space partitioning
of the pools through
address space partitioning dynamically
the pools through the
space partitioning dynamically to
pools through the entire
partitioning dynamically to spread
through the entire feasible
dynamically to spread the
the entire feasible range
to spread the encoding
entire feasible range and
spread the encoding load
feasible range and depict
the encoding load over
range and depict the
encoding load over multiple
and depict the optimal
load over multiple machines
depict the optimal x
we present the implementation
and the corresponding revenues
present the implementation and
the corresponding revenues in
the implementation and performance
corresponding revenues in figure
implementation and performance of
and performance of a
performance of a single
each point in each
point in each graph
the kernel implementation is
in each graph represents
kernel implementation is a
each graph represents the
implementation is a module
graph represents the equilibrium
is a module for
represents the equilibrium point
a module for linux
the equilibrium point of
equilibrium point of a
point of a game
of a game with
a game with the
game with the corresponding
with the corresponding m
where we normalize m
with hooks into the
hooks into the kernel
into the kernel packet
the kernel packet filter
the top right half
top right half of
right half of the
half of the range
of the range in
the range in all
range in all graphs
in all graphs is
all graphs is not
graphs is not feasible
maelstrom proxies work in
proxies work in pairs
as the sum of
the sum of m
one on each side
on each side of
each side of the
side of the long
of the long haul
the long haul link
each proxy acts both
proxy acts both as
acts both as an
both as an ingress
as an ingress and
we use this range
an ingress and egress
use this range as
ingress and egress temporarily
this range as a
range as a reference
as a reference color
in case all but
and we use a
case all but one
we use a dashed
all but one of
use a dashed line
but one of the
a dashed line to
one of the missing
dashed line to show
of the missing packets
line to show the
the missing packets are
to show the bound
missing packets are router
show the bound between
packets are router at
the bound between this
are router at the
bound between this value
router at the same
between this value within
at the same time
this value within the
the same time since
value within the feasible
same time since they
within the feasible range
time since they handle
since they handle duplex
they handle duplex traffic
handle duplex traffic in
duplex traffic in received
traffic in received later
in received later or
received later or recovered
later or recovered through
or recovered through other
a shows the optimal
recovered through other xors
shows the optimal infiltration
the optimal infiltration rate
allowing the following manner
in the entire feasible
the entire feasible range
entire feasible range we
feasible range we see
range we see that
the recovery of the
we see that pool
recovery of the remaining
of the remaining missing
the remaining missing packet
remaining missing packet from
missing packet from this
packet from this xor
chooses a strictly positive
a strictly positive value
strictly positive value for
positive value for x
in practice we stored
practice we stored data
we stored data and
stored data and xor
data and xor packets
and xor packets in
xor packets in dou
packets in dou the
in dou the egress
dou the egress router
the egress router captures
egress router captures ip
router captures ip packets
captures ip packets and
ip packets and creates
packets and creates re
the revenue of pool
ble buffered red black
buffered red black trees
is depicted in figure
red black trees for
b and in the
and in the entire
in the entire feasible
the entire feasible region
entire feasible region it
feasible region it is
region it is strictly
it is strictly larger
is strictly larger than
byte packets and dundant
packets and dundant fec
and dundant fec packets
which the pool would
the pool would have
the original ip packets
pool would have gotten
original ip packets are
would have gotten without
have gotten without attacking
entries this occupies around
routed through unaltered as
through unaltered as they
unaltered as they would
as they would have
they would have been
would have been at
have been at the
been at the send
c depicts the revenue
depicts the revenue of
the revenue of pool
the repair bins in
repair bins in the
bins in the layered
in the layered interoriginally
which is strictly smaller
the redundant packets are
is strictly smaller than
redundant packets are then
packets are then forwarded
are then forwarded leaving
then forwarded leaving scheme
in the entire range
forwarded leaving scheme store
leaving scheme store incrementally
scheme store incrementally computed
store incrementally computed xors
incrementally computed xors and
computed xors and to
xors and to the
and to the remote
note that the total
to the remote ingress
that the total system
the remote ingress router
the total system mining
remote ingress router via
total system mining power
ingress router via a
system mining power is
router via a udp
mining power is reduced
via a udp channel
power is reduced when
is reduced when pool
lists of data packet
of data packet headers
chooses to infiltrate pool
without the data packet
the data packet payloads
resulting in low storage
in low storage overheads
the revenue of third
revenue of third parties
low storage overheads for
storage overheads for each
overheads for each layer
for each layer the
miners not in either
each layer the ingress
not in either pool
layer the ingress router
the ingress router captures
ingress router captures and
router captures and stores
captures and stores ip
and stores ip packets
stores ip packets that
ip packets that rise
packets that rise linearly
that rise linearly with
rise linearly with the
linearly with the value
with the value of
the value of the
value of the interleave
the coming from the
coming from the direction
from the direction of
the direction of the
direction of the egress
of the egress router
upon memory footprint for
memory footprint for a
footprint for a long
running proxy was around
proxy was around receipt
was around receipt of
around receipt of a
receipt of a redundant
of a redundant packet
an ip packet is
ip packet is recov
therefore pays for the
pays for the increased
for the increased revenue
the increased revenue of
increased revenue of its
revenue of its attacker
of its attacker and
mb in our experiments
its attacker and everyone
attacker and everyone else
and everyone else in
everyone else in the
else in the system
ered if there is
if there is an
there is an opportunity
is an opportunity to
an opportunity to do
opportunity to do so
implications to the general
to the general case
redundant packets that can
the general case consider
packets that can be
general case consider the
that can be used
case consider the case
can be used at
consider the case of
be used at a
the case of p
used at a later
case of p pools
at a later time
a later time are
later time are stored
for any choice of
any choice of the
choice of the pools
of the pools sizes
if the redundant packet
the pools sizes m
the redundant packet is
redundant packet is useless
packet is useless it
is useless it is
useless it is immediately
it is immediately dis
other performance enhancing roles
performance enhancing roles carded
upon recovery the ip
at least one pool
recovery the ip packet
least one pool will
the ip packet is
one pool will choose
ip packet is sent
pool will choose to
packet is sent through
will choose to perform
is sent through maelstrom
choose to perform block
sent through maelstrom appliances
to perform block withholding
through maelstrom appliances can
maelstrom appliances can optionally
appliances can optionally aggregate
can optionally aggregate small
optionally aggregate small suba
aggregate small suba raw
small suba raw socket
suba raw socket to
raw socket to its
socket to its intended
to its intended destination
kilobyte packets from different
packets from different flows
from different flows into
different flows into larger
flows into larger ones
into larger ones for
larger ones for using
ones for using fec
for using fec requires
using fec requires that
fec requires that each
requires that each data
that each data packet
each data packet have
data packet have a
packet have a unique
have a unique better
a unique better communication
unique better communication efficiency
better communication efficiency over
communication efficiency over the
efficiency over the long
distance identifier that the
identifier that the receiver
that the receiver can
the receiver can use
receiver can use to
can use to keep
use to keep track
to keep track of
keep track of re
in split flow control
split flow control mode
flow control mode they
control mode they can
mode they can ceived
they can ceived data
can ceived data packets
ceived data packets and
data packets and to
packets and to identify
and to identify missing
to identify missing data
identify missing data packets
missing data packets perform
data packets perform send
side buffering of in
flight data for multiin
data for multiin a
for multiin a repair
multiin a repair packet
if we had access
we had access to
had access to end
we gigabyte flows that
gigabyte flows that exceed
flows that exceed the
that exceed the sending
exceed the sending end
host s buffercould have
s buffercould have added
buffercould have added a
have added a header
added a header to
a header to each
header to each packet
to each packet with
each packet with a
packet with a unique
with a unique ing
a unique ing capacity
maelstrom appliances can act
appliances can act as
can act as mulsequence
act as mulsequence number
we intercept traffic trans
appliances send multicast packparently
send multicast packparently and
multicast packparently and need
packparently and need to
and need to route
need to route it
to route it without
route it without modification
it without modification or
without modification or addi
ets to each other
to each other across
each other across the
other across the long
we identify ip multicast
to spread them within
spread them within their
them within their datacenters
ip packets by a
packets by a tuple
by a tuple consisting
a tuple consisting of
tuple consisting of the
consisting of the source
of the source and
the source and des
appliances can take on
can take on other
take on other existing
on other existing roles
other existing roles in
existing roles in the
roles in the tination
in the tination ip
the tination ip address
size of the ip
of the ip datacenter
acting as security and
as security and vpn
security and vpn gateways
and vpn gateways and
vpn gateways and as
gateways and as header
and as header plus
as header plus data
and a checksum over
a checksum over the
checksum over the ip
over the ip data
the ip data pay
conventional performance enhancing proxies
the checksum over the
checksum over the payload
over the payload is
the payload is necessary
payload is necessary since
is necessary since the
necessary since the ip
since the ip identification
the ip identification field
ip identification field is
identification field is only
bits long and a
long and a single
and a single pair
a single pair of
single pair of end
hosts communicating at high
communicating at high speeds
at high speeds will
evaluation use the same
use the same identifier
the same identifier for
same identifier for different
identifier for different data
for different data packets
different data packets within
data packets within a
packets within a fairly
within a fairly short
a fairly short interval
fairly short interval unless
stable state where only
short interval unless the
state where only pool
interval unless the checksum
unless the checksum is
the checksum is added
checksum is added to
is added to we
added to we evaluated
to we evaluated maelstrom
we evaluated maelstrom on
evaluated maelstrom on the
maelstrom on the emulab
on the emulab testbed
the emulab testbed at
emulab testbed at utah
testbed at utah differentiate
at utah differentiate between
utah differentiate between them
for all the experiments
we used a dumbbell
used a dumbbell topoltifiers
a dumbbell topoltifiers result
dumbbell topoltifiers result in
topoltifiers result in garbled
result in garbled recovery
in garbled recovery by
garbled recovery by maelstrom
two pools where one
pools where one infiltrates
where one infiltrates the
one infiltrates the other
an event ogy of
event ogy of two
ogy of two clusters
optimal infiltration rate x
of two clusters of
two clusters of nodes
clusters of nodes connected
of nodes connected via
nodes connected via routing
connected via routing nodes
via routing nodes which
routing nodes which will
nodes which will be
which will be caught
will be caught by
be caught by higher
caught by higher level
by higher level checksums
higher level checksums designed
level checksums designed with
checksums designed with a
designed with a high
latency link in between
link in between them
as a function of
a function of pool
function of pool sizes
designed to emto deal
to emto deal with
emto deal with tranmission
deal with tranmission errors
with tranmission errors on
tranmission errors on commodity
errors on commodity networks
on commodity networks ulate
commodity networks ulate the
networks ulate the setup
ulate the setup in
the setup in figure
and ran the proxy
ran the proxy code
the proxy code on
proxy code on and
code on and hence
on and hence does
and hence does not
hence does not have
does not have significant
not have significant consequences
have significant consequences unless
and the lines in
significant consequences unless the
consequences unless the routers
shows the performance of
the performance of the
performance of the kernel
show the revenue density
of the kernel version
the revenue density of
the kernel version at
kernel version at gigabit
version at gigabit speeds
the remainder of the
remainder of the graphs
of the graphs it
the graphs it occurs
graphs it occurs frequently
the kernel version of
in a system with
kernel version of maelstrom
a system with p
version of maelstrom can
system with p pools
of maelstrom can generate
maelstrom can generate up
can generate up to
generate up to a
up to a show
to a show the
a show the performance
show the performance of
the performance of the
performance of the user
space version at slower
version at slower gigabit
at slower gigabit per
slower gigabit per second
gigabit per second of
per second of data
second of data and
of data and fec
is not an equilibrium
data and fec traffic
assume towards negation this
towards negation this is
negation this is not
this is not the
is not the case
to emulate the mtu
emulate the mtu difference
the mtu difference between
mtu difference between the
difference between the longput
between the longput data
the longput data rate
longput data rate depending
data rate depending on
rate depending on the
depending on the encoding
on the encoding rate
is an equilibrium point
haul link and the
link and the datacenter
and the datacenter network
now consider a setting
consider a setting with
a setting with only
setting with only pools
and treat the other
treat the other pools
the other pools as
other pools as independent
pools as independent miners
we were able to
were able to saturate
this is the setting
able to saturate the
is the setting analyzed
to saturate the outgoing
the setting analyzed above
saturate the outgoing card
setting analyzed above and
the outgoing card at
analyzed above and we
outgoing card at set
above and we have
card at set an
and we have seen
at set an mtu
we have seen there
set an mtu of
have seen there that
seen there that pool
can increase its revenue
increase its revenue by
its revenue by performing
revenue by performing a
by performing a block
performing a block withholding
a block withholding attack
block withholding attack on
withholding attack on pool
bytes on the network
on the network connecting
the network connecting the
network connecting the rates
connecting the rates as
the rates as high
rates as high as
s infiltration rate by
infiltration rate by x
with cpu overload occurring
cpu overload occurring at
overload occurring at end
hosts to the proxy
to the proxy and
the proxy and an
proxy and an mtu
take this values back
and an mtu of
this values back to
values back to the
back to the setting
to the setting at
the setting at hand
setting at hand with
at hand with p
hand with p pools
the revenue of pool
is better when x
where each incoming data
each incoming data packet
incoming data packet had
data packet had to
packet had to be
had to be xored
to be xored long
haul link between proxies
the only exception is
only exception is figure
where we maintained equal
we maintained equal mtus
maintained equal mtus of
name size discusfish antpool
size discusfish antpool ghash
io btchine btcguild eligius
btchine btcguild eligius others
throughput metrics at the
metrics at the receive
incoming data packets are
data packets are buffered
packets are buffered so
are buffered so that
buffered so that they
so that they can
that they can be
they can be used
can be used in
be used in conjunction
used in conjunction with
in conjunction with figures
show that commodity tcp
ip throughxors to recover
throughxors to recover missing
to recover missing data
recover missing data packets
any received put collapses
received put collapses in
put collapses in the
collapses in the presence
in the presence of
the presence of non
and xor that is
xor that is missing
that is missing more
is missing more than
missing more than one
more than one data
than one data packet
one data packet is
data packet is stored
packet is stored that
is stored that maelstrom
stored that maelstrom successfully
that maelstrom successfully masks
maelstrom successfully masks loss
successfully masks loss and
masks loss and prevents
loss and prevents this
ip no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
the six largest open
six largest open pool
largest open pool sizes
open pool sizes as
pool sizes as of
sizes as of january
their optimal infiltration rates
of each pool as
each pool as a
pool as a fraction
as a fraction of
a fraction of its
fraction of its size
if it attacked all
it attacked all others
attacked all others without
all others without reciprocation
and their revenue density
their revenue density when
revenue density when attacking
can improve its revenue
improve its revenue by
its revenue by attacking
revenue by attacking pool
attacks is not an
is not an equilibrium
not an equilibrium point
case as a test
as a test case
we take the pool
take the pool distribution
the pool distribution in
pool distribution in january
we analyze the cases
analyze the cases where
the cases where each
cases where each of
where each of the
each of the pools
of the pools attacks
the pools attacks all
pools attacks all other
attacks all other open
all other open pools
all of which behave
of which behave honestly
note that attacking all
that attacking all pools
attacking all pools with
all pools with force
pools with force proportional
with force proportional to
force proportional to their
proportional to their size
to their size yields
their size yields the
size yields the same
yields the same results
the same results as
same results as attacking
results as attacking a
as attacking a single
attacking a single pool
a single pool of
single pool of their
pool of their aggregate
of their aggregate size
plugging in the numbers
in the numbers into
the numbers into the
numbers into the analysis
into the analysis above
the analysis above shows
analysis above shows that
above shows that a
shows that a larger
that a larger pool
a larger pool needs
larger pool needs to
pool needs to use
needs to use a
to use a smaller
use a smaller ratio
a smaller ratio of
smaller ratio of its
ratio of its mining
of its mining power
its mining power for
mining power for infiltration
power for infiltration and
for infiltration and can
infiltration and can increase
and can increase its
can increase its revenue
increase its revenue density
its revenue density more
revenue density more than
density more than a
more than a small
than a small pool
achieves its optimum attack
its optimum attack rate
optimum attack rate at
of the pool s
the pool s mining
pool s mining power
increasing its revenue by
its revenue by almost
this amounts to a
amounts to a daily
to a daily revenue
a daily revenue increase
daily revenue increase of
revenue increase of b
usd at the exchange
at the exchange rate
the exchange rate on
exchange rate on that
rate on that date
this represents a considerable
represents a considerable increase
a considerable increase of
considerable increase of the
increase of the pools
of the pools net
the pools net revenue
for the smallest pool
the attack is much
attack is much less
is much less profitable
to reach the optimum
reach the optimum it
the optimum it needs
optimum it needs almost
it needs almost a
needs almost a third
almost a third of
a third of its
third of its power
of its power for
its power for attacking
power for attacking but
for attacking but increases
tcp no loss maelstrom
attacking but increases its
no loss maelstrom no
but increases its revenue
loss maelstrom no loss
increases its revenue density
maelstrom no loss maelstrom
its revenue density by
revenue density by merely
two attacking pools system
one way link latency
as a function of
a function of pool
function of pool sizes
way latency collapse from
latency collapse from occurring
shows the performance of
the performance of the
performance of the user
space version on a
mbps link and figure
shows the kernel version
the kernel version on
kernel version on a
the experiment in each
experiment in each case
in each case involves
each case involves running
case involves running iperf
flows from one node
from one node to
one node to another
node to another across
to another across the
another across the long
distance link with and
link with and without
with and without intermediary
and without intermediary maelstrom
without intermediary maelstrom proxies
intermediary maelstrom proxies and
maelstrom proxies and measuring
proxies and measuring obtained
and measuring obtained throughput
measuring obtained throughput while
obtained throughput while varying
t wo p ools
throughput while varying loss
wo p ools we
while varying loss rate
p ools we proceed
ools we proceed to
we proceed to analyze
proceed to analyze the
left graph on each
to analyze the case
graph on each figure
analyze the case where
the case where two
case where two pools
where two pools may
two pools may attack
pools may attack each
may attack each other
attack each other and
each other and the
other and the other
and the other miners
the other miners mine
other miners mine solo
again we have pool
the error bars on
error bars on the
bars on the graphs
on the graphs to
the graphs to the
graphs to the left
to the left are
the left are standard
left are standard errors
are standard errors of
standard errors of the
errors of the throughput
of the throughput over
the throughput over ten
throughput over ten runs
controls its infiltration rate
its infiltration rate x
ip s cache of
s cache of tuning
cache of tuning parameters
of tuning parameters to
tuning parameters to allow
parameters to allow for
to allow for repeatable
allow for repeatable results
the clients in the
clients in the experiment
in the experiment are
the experiment are running
experiment are running tcp
also controls its infiltration
ip reno on a
controls its infiltration rate
reno on a linux
its infiltration rate x
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the total mining power
the maelstrom parameters used
total mining power in
maelstrom parameters used are
mining power in the
parameters used are r
power in the system
in the system is
the system is m
system is m x
the direct revenues r
of the pools from
the pools from mining
pools from mining are
from mining are their
mining are their effective
are their effective mining
their effective mining rates
without infiltrating mining power
divided by the total
by the total mining
the total mining rate
space version involved running
version involved running a
involved running a single
second iperf flow from
iperf flow from one
flow from one node
from one node to
one node to another
node to another with
to another with and
another with and without
with and without maelstrom
and without maelstrom running
without maelstrom running on
maelstrom running on the
running on the routers
on the routers and
the routers and measuring
routers and measuring throughput
and measuring throughput while
measuring throughput while varying
throughput while varying the
while varying the random
varying the random loss
the random loss rate
random loss rate on
loss rate on the
rate on the link
on the link and
the link and the
link and the one
to test the kernel
test the kernel version
the kernel version at
kernel version at gigabit
version at gigabit speeds
we ran eight parallel
ran eight parallel iperf
eight parallel iperf flows
parallel iperf flows from
iperf flows from one
flows from one node
from one node to
one node to another
node to another for
the curves obtained from
curves obtained from the
obtained from the two
from the two versions
the two versions are
two versions are almost
versions are almost identical
we present both to
present both to show
both to show that
to show that the
the total revenue of
show that the kernel
total revenue of each
that the kernel version
revenue of each pool
the kernel version successfully
of each pool is
kernel version successfully scales
each pool is its
version successfully scales up
pool is its direct
successfully scales up the
is its direct mining
scales up the performance
its direct mining revenue
up the performance of
the performance of the
performance of the user
space version to hundreds
version to hundreds of
to hundreds of megabits
hundreds of megabits of
of megabits of traffic
megabits of traffic per
of traffic per second
two pools infiltrating each
pools infiltrating each other
we show how tcp
ip performance degrades on
and the infiltration revenue
performance degrades on a
the infiltration revenue from
infiltration revenue from the
revenue from the previous
from the previous round
which is the attacked
ms link as the
is the attacked pool
link as the loss
the attacked pool s
as the loss rate
attacked pool s total
the loss rate is
pool s total revenue
loss rate is increased
s total revenue multiplied
rate is increased from
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
is divided among its
divided among its loyal
among its loyal miners
its loyal miners and
loyal miners and miners
miners and miners that
and miners that infiltrated
miners that infiltrated it
at stable state this
stable state this is
state this is r
maelstrom masks loss up
masks loss up to
without significant throughput degradation
with the kernel version
the kernel version achieving
kernel version achieving two
version achieving two orders
achieving two orders of
two orders of magnitude
orders of magnitude higher
of magnitude higher throughput
magnitude higher throughput that
higher throughput that conventional
throughput that conventional tcp
the graphs on the
graphs on the right
on the right side
the right side of
right side of figures
ip throughput declining on
throughput declining on a
declining on a link
on a link of
a link of increasing
link of increasing length
of increasing length when
increasing length when subjected
length when subjected to
when subjected to uniform
subjected to uniform loss
to uniform loss rates
uniform loss rates of
the top line in
top line in the
line in the graphs
in the graphs is
the graphs is the
graphs is the performance
is the performance of
the performance of tcp
ip without loss and
without loss and provides
loss and provides an
and provides an upper
provides an upper bound
we obtain the following
an upper bound for
obtain the following closed
upper bound for performance
the following closed expressions
bound for performance on
following closed expressions for
for performance on the
closed expressions for each
performance on the link
we express the revenues
express the revenues as
the revenues as functions
revenues as functions of
as functions of x
space and kernel versions
maelstrom masks packet loss
masks packet loss and
packet loss and tracks
loss and tracks the
and tracks the lossless
tracks the lossless line
the lossless line closely
lagging only when the
only when the link
when the link latency
the link latency is
link latency is low
latency is low and
is low and tcp
ip s throughput is
s throughput is very
throughput is very high
ip to attain very
to attain very high
attain very high speeds
very high speeds on
high speeds on the
speeds on the gi
each pool controls only
pool controls only its
controls only its own
only its own infiltration
its own infiltration rate
in each round of
each round of the
round of the pool
of the pool game
each pool will optimize
pool will optimize its
will optimize its infiltration
optimize its infiltration rate
its infiltration rate of
infiltration rate of the
rate of the other
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with r
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with x
way delivery latency against
delivery latency against loss
latency against loss rate
an equilibrium exists where
equilibrium exists where neither
exists where neither pool
can improve its revenue
improve its revenue by
its revenue by changing
revenue by changing its
by changing its infiltration
changing its infiltration rate
any pair of values
pair of values x
such that arg maxx
the feasible region for
feasible region for the
region for the pool
for the pool sizes
the pool sizes is
pool sizes is m
the revenue function for
revenue function for ri
function for ri is
for ri is concave
ri is concave in
is concave in xi
concave in xi for
in xi for all
xi for all feasible
for all feasible values
all feasible values of
feasible values of the
values of the variables
packet delivery latencies gabit
delivery latencies gabit link
we had to set
had to set the
to set the mtu
set the mtu of
the mtu of the
mtu of the entire
of the entire path
the entire path to
entire path to be
path to be the
to be the maximum
therefore the solutions for
the solutions for equations
which meant that the
meant that the longhaul
that the longhaul link
the longhaul link had
longhaul link had the
link had the same
are unique and are
had the same mtu
unique and are either
the same mtu as
and are either at
same mtu as the
are either at the
mtu as the inter
either at the borders
at the borders of
the borders of the
borders of the feasible
of the feasible region
the feasible region or
feasible region or where
region or where ri
this resulted in the
resulted in the fragmentation
in the fragmentation of
the fragmentation of repair
fragmentation of repair packets
of repair packets sent
repair packets sent over
packets sent over udp
sent over udp on
over udp on the
udp on the long
haul link into two
link into two ip
into two ip packet
two ip packet fragments
from section v we
section v we know
v we know that
we know that no
since the loss of
the loss of a
loss of a single
attack is not an
of a single fragment
is not an equilibrium
a single fragment resulted
not an equilibrium point
single fragment resulted in
fragment resulted in the
resulted in the loss
in the loss of
the loss of the
loss of the repair
since each pool can
each pool can increase
pool can increase its
can increase its revenue
increase its revenue by
we observed a higher
its revenue by choosing
observed a higher loss
revenue by choosing a
a higher loss rate
by choosing a strictly
higher loss rate for
choosing a strictly positive
loss rate for repairs
a strictly positive infiltration
rate for repairs than
strictly positive infiltration rate
for repairs than for
repairs than for data
than for data packets
we expect performance to
expect performance to be
performance to be better
to be better on
be better on a
better on a network
on a network where
a network where the
network where the mtu
where the mtu of
the mtu of the
mtu of the long
haul link is truly
link is truly larger
is truly larger than
truly larger than the
larger than the mtu
than the mtu within
the mtu within each
mtu within each cluster
is not a solution
not a solution to
a solution to equations
latency metrics to measure
metrics to measure the
to measure the latency
measure the latency effects
the latency effects of
latency effects of tcp
nash equilibrium therefore exists
equilibrium therefore exists with
therefore exists with x
mbps stream between two
stream between two nodes
between two nodes over
two nodes over a
and simultaneously ran a
mbps flow alongside on
flow alongside on the
alongside on the same
on the same link
the same link to
same link to simulate
link to simulate a
to simulate a real
time stream combined with
stream combined with other
combined with other intercluster
with other intercluster traffic
shows the average delivery
the average delivery latency
average delivery latency of
level packets in the
as loss rates go
loss rates go up
shows the same scenario
the same scenario with
same scenario with a
scenario with a constant
with a constant uniformly
a constant uniformly random
constant uniformly random loss
uniformly random loss rate
random loss rate of
and varying oneway latency
maelstrom s delivery latency
s delivery latency is
delivery latency is almost
latency is almost exactly
is almost exactly equal
almost exactly equal to
using symbolic computation tools
exactly equal to the
equal to the one
we see that there
way latency on the
see that there is
latency on the link
that there is a
there is a single
is a single pair
a single pair of
single pair of values
pair of values for
of values for which
values for which equation
ip takes more than
takes more than twice
more than twice as
than twice as long
twice as long once
as long once one
holds for any feasible
for any feasible choice
any feasible choice of
feasible choice of m
way latencies go past
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
analysis confirms these observations
plots delivery latency against
delivery latency against message
we simulate the pool
latency against message identifier
simulate the pool game
the pool game for
pool game for a
game for a range
for a range of
a range of pool
the spikes in latency
range of pool sizes
spikes in latency are
in latency are triggered
latency are triggered by
are triggered by losses
triggered by losses that
for each choice of
by losses that lead
each choice of pool
losses that lead to
choice of pool sizes
that lead to packets
lead to packets piling
to packets piling up
packets piling up at
piling up at the
up at the receiver
we start the simulation
start the simulation when
the simulation when both
simulation when both pools
when both pools do
a key point is
both pools do not
key point is that
pools do not infiltrate
point is that we
do not infiltrate each
is that we are
not infiltrate each other
that we are plotting
we are plotting the
are plotting the delivery
plotting the delivery latency
the delivery latency of
delivery latency of all
latency of all packets
not just lost ones
ip delays correctly received
delays correctly received packets
correctly received packets while
received packets while waiting
packets while waiting for
while waiting for missing
waiting for missing packets
for missing packets sequenced
missing packets sequenced earlier
packets sequenced earlier by
sequenced earlier by the
earlier by the sender
by the sender the
the sender the effect
sender the effect of
the effect of this
effect of this is
of this is shown
this is shown in
is shown in figure
and the revenue densities
the revenue densities are
revenue densities are r
where single packet losses
single packet losses cause
packet losses cause spikes
losses cause spikes in
cause spikes in delivery
spikes in delivery latency
in delivery latency that
delivery latency that last
latency that last for
that last for hundreds
last for hundreds of
for hundreds of packets
at each round one
each round one pool
the low data rate
round one pool chooses
low data rate in
one pool chooses its
data rate in the
pool chooses its optimal
rate in the flow
chooses its optimal infiltration
in the flow of
its optimal infiltration rate
the flow of roughly
optimal infiltration rate based
infiltration rate based on
rate based on the
based on the pool
on the pool sizes
the pool sizes and
pool sizes and the
sizes and the rate
and the rate with
the rate with which
rate with which it
with which it is
which it is infiltrated
kb packets per rtt
packets per rtt makes
per rtt makes tcp
and we calculate the
we calculate the revenue
ip flow control delays
calculate the revenue after
flow control delays at
the revenue after convergence
control delays at the
revenue after convergence with
delays at the sender
after convergence with equation
at the sender unlikely
given that the congestion
that the congestion control
the congestion control algorithm
congestion control algorithm is
control algorithm is reno
recall the players in
the players in the
players in the pool
which implements fast recovery
in the pool game
implements fast recovery and
the pool game are
fast recovery and halves
pool game are chosen
recovery and halves the
game are chosen with
and halves the congestion
are chosen with the
halves the congestion window
chosen with the round
the congestion window on
with the round robin
congestion window on packet
the round robin policy
window on packet loss
on packet loss rather
packet loss rather than
loss rather than resetting
rather than resetting it
so the pools take
than resetting it completely
the pools take turns
and we let the
we let the game
let the game run
the game run until
game run until convergence
the results are illustrated
results are illustrated in
are illustrated in figure
the maelstrom configuration used
maelstrom configuration used is
each run with some
run with some m
values results in a
results in a single
in a single point
a single point in
single point in each
point in each graph
in each graph in
each graph in figure
we depict the infiltration
depict the infiltration rates
the infiltration rates of
infiltration rates of both
rates of both pools
of both pools x
b and the pools
and the pools revenue
the pools revenue densities
pools revenue densities r
for each choice of
each choice of m
the values of x
are the points in
the points in each
points in each of
in each of the
each of the graphs
of the graphs with
the graphs with the
graphs with the respective
with the respective coordinates
j graphs we draw
graphs we draw a
we draw a border
draw a border around
a border around the
border around the region
around the region where
the region where there
region where there is
where there is no
attack by i in
by i in equilibrium
for the ri graphs
the ri graphs we
ri graphs we draw
graphs we draw a
we draw a line
draw a line around
a line around the
line around the region
around the region where
the region where the
region where the revenue
where the revenue is
the revenue is the
revenue is the same
is the same as
the same as in
same as in the
as in the no
we first observe that
first observe that only
observe that only in
that only in extreme
only in extreme cases
in extreme cases a
extreme cases a pool
cases a pool does
a pool does not
pool does not attack
does not attack its
not attack its counterpart
at equilibrium a pool
equilibrium a pool will
a pool will refrain
pool will refrain from
will refrain from attacking
refrain from attacking only
from attacking only if
attacking only if the
only if the other
if the other pool
the other pool is
other pool is larger
pool is larger than
is larger than about
relatively prime interleaves offer
prime interleaves offer better
interleaves offer better performance
offer better performance r
of the total mining
the total mining power
we observe that a
observe that a pool
that a pool improves
a pool improves its
pool improves its revenue
improves its revenue compared
its revenue compared to
revenue compared to the
compared to the no
attacks scenario only when
scenario only when it
only when it controls
when it controls a
it controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
these are the small
are the small triangular
the small triangular regions
small triangular regions in
triangular regions in figures
in the rest of
layered interleaving and bursty
the rest of the
interleaving and bursty loss
rest of the space
and bursty loss thus
bursty loss thus far
loss thus far we
thus far we have
the trapezoids in the
far we have shown
trapezoids in the figures
we have shown how
have shown how maelstrom
shown how maelstrom effectively
how maelstrom effectively hides
maelstrom effectively hides loss
the revenue of the
effectively hides loss from
revenue of the pool
hides loss from tcp
of the pool is
the pool is inferior
pool is inferior compared
is inferior compared to
inferior compared to the
compared to the no
ip for packets dropped
for packets dropped with
packets dropped with uniform
dropped with uniform randomness
we examine the performance
the prisoner s dilemma
examine the performance of
prisoner s dilemma in
the performance of the
s dilemma in a
performance of the layered
dilemma in a healthy
of the layered interleaving
in a healthy bitcoin
the layered interleaving algorithm
a healthy bitcoin environment
showing how different parameterizations
where neither pool controls
how different parameterizations handle
neither pool controls a
different parameterizations handle bursty
pool controls a strict
parameterizations handle bursty loss
controls a strict majority
handle bursty loss patterns
a strict majority of
strict majority of the
majority of the mining
of the mining power
we use a loss
use a loss model
a loss model where
both pools will earn
loss model where packets
pools will earn less
model where packets are
will earn less at
where packets are dropped
earn less at equilibrium
packets are dropped in
less at equilibrium than
are dropped in bursts
at equilibrium than if
dropped in bursts of
equilibrium than if both
in bursts of fixed
than if both pools
bursts of fixed length
if both pools ran
both pools ran without
pools ran without attacking
allowing us to study
us to study the
to study the impact
we can analyze in
study the impact of
can analyze in this
the impact of burst
analyze in this case
impact of burst length
in this case a
of burst length on
this case a game
burst length on performance
case a game where
a game where each
game where each pool
where each pool chooses
each pool chooses either
the link has a
pool chooses either to
link has a one
chooses either to attack
either to attack and
to attack and optimize
attack and optimize its
and optimize its revenue
or to refrain from
to refrain from attacking
ms and a loss
and a loss rate
a loss rate of
without loss of generality
as we have seen
we have seen in
have seen in section
seen in section v
can increase its revenue
increase its revenue above
where it is varied
does attack but pool
mbps flow of udp
flow of udp packets
of udp packets is
udp packets is sent
we denote the revenue
packets is sent over
denote the revenue of
is sent over it
the revenue of pool
we show that our
the exact value of
show that our observation
exact value of r
that our observation in
our observation in section
depends on the values
on the values of
the values of m
is correct for high
correct for high loss
for high loss rates
high loss rates if
loss rates if the
but it is always
rates if the interleaves
it is always smaller
if the interleaves are
is always smaller than
the interleaves are relatively
always smaller than one
interleaves are relatively prime
as we have seen
we have seen above
performance improves substantially when
improves substantially when loss
substantially when loss rates
when loss rates are
loss rates are high
rates are high and
are high and losses
high and losses are
does choose to attack
and losses are bursty
the graph plots the
graph plots the percentage
plots the percentage of
but does not surpass
the percentage of lost
does not surpass one
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
packets successfully recovered on
successfully recovered on the
the game is summarized
recovered on the y
game is summarized in
is summarized in figure
axis against an x
axis of loss rates
of loss rates on
loss rates on a
rates on a log
on a log scale
this is the classical
is the classical prisoner
the classical prisoner s
classical prisoner s dilemma
the maelstrom configuration used
maelstrom configuration used is
configuration used is r
attack is the dominant
is the dominant strategy
chooses to attack or
to attack or not
the revenue of pool
is larger when attacking
larger when attacking than
when attacking than when
attacking than when refraining
than when refraining from
when refraining from attack
and the same for
the same for xxx
same for xxx xxx
for xxx xxx pool
no attack xxx pool
we show the ability
show the ability of
the ability of layered
ability of layered interleaving
of layered interleaving to
layered interleaving to provide
interleaving to provide gracefully
to provide gracefully degrading
provide gracefully degrading performance
gracefully degrading performance in
degrading performance in the
performance in the face
in the face of
the face of bursty
face of bursty loss
we plot the percentage
plot the percentage of
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
packets successfully recovered against
successfully recovered against the
recovered against the length
against the length of
the length of loss
length of loss bursts
of loss bursts for
loss bursts for two
bursts for two different
for two different sets
two different sets of
different sets of interleaves
and in the bottom
in the bottom graph
the bottom graph we
bottom graph we plot
graph we plot the
we plot the average
plot the average latency
the average latency at
average latency at which
latency at which the
at which the packets
which the packets were
the packets were recovered
recovery latency is defined
latency is defined as
is defined as the
defined as the difference
as the difference between
the difference between the
difference between the eventual
between the eventual delivery
the eventual delivery time
eventual delivery time of
delivery time of the
time of the recovered
of the recovered packet
the recovered packet and
recovered packet and the
packet and the one
way latency of the
latency of the link
we confirmed that the
confirmed that the emulab
that the emulab link
the emulab link had
emulab link had almost
link had almost no
had almost no jitter
almost no jitter on
no jitter on correctly
jitter on correctly delivered
on correctly delivered packets
way latency an accurate
latency an accurate estimate
prisoner s dilemma for
an accurate estimate of
s dilemma for two
accurate estimate of expected
dilemma for two pools
estimate of expected lossless
of expected lossless delivery
expected lossless delivery time
the revenue density of
revenue density of each
density of each pool
of each pool is
each pool is determined
pool is determined by
is determined by the
determined by the decision
by the decision of
increasing the interleaves results
the decision of both
the interleaves results in
decision of both pools
interleaves results in much
of both pools whether
results in much higher
both pools whether to
in much higher recovery
pools whether to attack
much higher recovery percentages
whether to attack or
higher recovery percentages at
to attack or not
recovery percentages at large
percentages at large burst
at large burst sizes
the dominant strategy of
dominant strategy of each
but percentage of packets
strategy of each player
percentage of packets recovered
of each player is
each player is to
player is to attack
however the payoff of
the payoff of both
payoff of both would
of both would be
both would be larger
would be larger if
be larger if they
larger if they both
if they both refrain
they both refrain from
both refrain from attacking
percentage of packets recovered
at equilibrium of this
equilibrium of this attack
when both pools attack
the revenue of each
revenue of each pool
of each pool is
each pool is smaller
pool is smaller than
is smaller than its
smaller than its revenue
than its revenue if
its revenue if neither
revenue if neither pool
if neither pool attacked
the game is not
game is not played
is not played once
where each pool can
each pool can change
pool can change its
can change its strategy
change its strategy between
its strategy between attack
strategy between attack and
between attack and no
the pools can agree
to refrain from attacking
and in each round
in each round a
each round a pool
round a pool can
a pool can detect
pool can detect whether
can detect whether it
detect whether it is
whether it is being
it is being attacked
is being attacked and
being attacked and deduce
attacked and deduce that
and deduce that the
deduce that the other
that the other pool
the other pool is
other pool is violating
pool is violating the
is violating the agreement
cooperation where neither pool
where neither pool attacks
neither pool attacks is
pool attacks is a
attacks is a possible
is a possible stable
a possible stable state
despite the fact that
the fact that the
fact that the single
that the single nash
the single nash equilibrium
single nash equilibrium in
nash equilibrium in every
equilibrium in every round
in every round is
every round is to
round is to attack
case as an example
as an example we
an example we take
example we take again
we take again the
take again the pool
again the pool sizes
the pool sizes shown
pool sizes shown in
sizes shown in figure
and study the case
study the case where
the case where the
case where the two
where the two largest
the two largest pools
the optimal infiltration rates
out of the total
of the total system
the total system mining
total system mining power
and the pools would
the pools would lose
compared to the no
q i dentical p
i dentical p ools
dentical p ools let
p ools let there
ools let there be
let there be q
there be q pools
be q pools of
q pools of identical
pools of identical size
of identical size that
identical size that engage
size that engage in
that engage in block
engage in block withholding
in block withholding against
block withholding against one
withholding against one another
other miners neither attack
miners neither attack nor
neither attack nor are
attack nor are being
nor are being attacked
in this case there
this case there exists
case there exists a
there exists a symmetric
exists a symmetric equilibrium
without loss of generality
a step of pool
it controls its attack
controls its attack rates
its attack rates each
attack rates each of
rates each of the
each of the other
of the other pools
and due to symmetry
due to symmetry they
to symmetry they are
symmetry they are all
they are all the
are all the same
layered interleaving recovery percentage
interleaving recovery percentage and
recovery percentage and latency
percentage and latency comes
and latency comes at
latency comes at the
comes at the cost
at the cost of
the cost of higher
cost of higher recovery
of higher recovery latency
the attack rate of
attack rate of pool
against any other pool
each of the other
of the other pools
the other pools can
other pools can attack
pools can attack its
can attack its peers
attack its peers as
its peers as well
all attack rates by
attack rates by all
rates by all attackers
by all attackers are
all attackers are identical
set of interleaves catches
of interleaves catches almost
interleaves catches almost all
the attack rate of
catches almost all packets
attack rate of any
almost all packets in
rate of any pool
all packets in an
of any pool other
packets in an extended
any pool other than
in an extended burst
an extended burst of
against any other pool
packets at an average
at an average latency
an average latency of
average latency of around
while repairing all random
repairing all random singleton
all random singleton losses
random singleton losses within
the direct revenue of
direct revenue of each
revenue of each of
of each of the
each of the other
of the other pools
the graphs also show
similarly denote by r
graphs also show recovery
also show recovery latency
show recovery latency rising
recovery latency rising gracefully
latency rising gracefully with
rising gracefully with the
gracefully with the increase
with the increase in
the revenue densities of
the increase in loss
revenue densities of pool
increase in loss burst
in loss burst length
the longer the burst
the longer it takes
longer it takes to
it takes to recover
takes to recover the
to recover the lost
recover the lost packets
are instantiated to mi
the maelstrom configuration used
maelstrom configuration used is
configuration used is r
we show histograms of
show histograms of recovery
histograms of recovery latencies
of recovery latencies for
recovery latencies for the
latencies for the two
for the two interleave
the two interleave configurations
two interleave configurations under
interleave configurations under different
configurations under different burst
under different burst lengths
the histograms confirm the
histograms confirm the trends
confirm the trends described
the trends described above
packet recoveries take longer
recoveries take longer from
take longer from left
longer from left to
from left to right
left to right as
to right as we
right as we increase
as we increase loss
we increase loss burst
increase loss burst length
and from top to
from top to bottom
top to bottom as
to bottom as we
bottom as we increase
as we increase the
we increase the interleave
increase the interleave values
illustrates the difference between
the difference between a
difference between a traditional
between a traditional fec
a traditional fec code
traditional fec code and
fec code and layered
code and layered interleaving
and layered interleaving by
layered interleaving by plotting
interleaving by plotting a
element moving average of
moving average of recovery
average of recovery latencies
of recovery latencies for
recovery latencies for both
latencies for both codes
the channel is configured
channel is configured to
is configured to lose
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
singleton packets randomly at
packets randomly at a
randomly at a loss
at a loss rate
a loss rate of
and additionally lose long
additionally lose long bursts
lose long bursts of
packets at occasional intervals
both codes recovery latency
reed solomon layered interleaving
and solving we obtain
solving we obtain a
we obtain a single
obtain a single expression
a single expression for
single expression for any
expression for any ri
solomon versus layered interleaving
versus layered interleaving are
layered interleaving are configured
interleaving are configured with
since in the symmetric
are configured with r
in the symmetric case
the symmetric case we
symmetric case we have
case we have r
the expression is shown
and recover all lost
expression is shown in
recover all lost packets
is shown in equation
all lost packets reed
solomon uses an interleave
uses an interleave of
and layered interleaving uses
layered interleaving uses interleaves
interleaving uses interleaves of
given any value of
any value of q
value of q and
of q and mi
and consequently both have
consequently both have a
both have a maximum
have a maximum tolerable
a maximum tolerable burst
maximum tolerable burst length
tolerable burst length of
the feasible range of
feasible range of the
range of the infiltration
of the infiltration rates
the infiltration rates is
we use a publicly
use a publicly available
a publicly available implementation
publicly available implementation of
available implementation of a
implementation of a reed
solomon code based on
code based on vandermonde
based on vandermonde matrices
within this range ri
this range ri is
range ri is continuous
and concave in x
the code is plugged
code is plugged into
is plugged into maelstrom
plugged into maelstrom instead
into maelstrom instead of
maelstrom instead of layered
instead of layered interleaving
the optimal point for
optimal point for pool
showing that we can
that we can use
we can use new
can use new encodings
use new encodings within
new encodings within the
encodings within the same
within the same framework
the same framework seamlessly
solomon code recovers all
code recovers all lost
recovers all lost packets
all lost packets with
lost packets with roughly
packets with roughly the
with roughly the same
roughly the same latency
the same latency whereas
same latency whereas layered
latency whereas layered interleaving
since the function is
whereas layered interleaving recovers
the function is concave
layered interleaving recovers singleton
function is concave the
interleaving recovers singleton losses
is concave the equation
recovers singleton losses almost
concave the equation yields
singleton losses almost immediately
the equation yields a
losses almost immediately and
equation yields a single
almost immediately and exhibits
yields a single feasible
immediately and exhibits latency
a single feasible solution
and exhibits latency spikes
exhibits latency spikes whenever
latency spikes whenever the
spikes whenever the longer
whenever the longer loss
which is a function
the longer loss burst
is a function of
longer loss burst occurs
a function of the
function of the attack
of the attack rates
the attack rates of
attack rates of the
rates of the other
of the other pools
related work a significant
work a significant body
a significant body of
significant body of work
body of work on
of work on application
work on application and
on application and tcp
ip performance over high
distance networks exists in
networks exists in the
exists in the context
in the context of
the context of high
to find a symmetric
find a symmetric equilibrium
the use of parallel
use of parallel sockets
of parallel sockets for
parallel sockets for higher
sockets for higher throughput
for higher throughput in
higher throughput in the
throughput in the face
in the face of
the face of non
congestion loss was proposed
loss was proposed in
was proposed in psockets
and obtain a single
obtain a single feasible
a single feasible solution
a number of protocols
the equilibrium infiltration rate
number of protocols have
equilibrium infiltration rate and
of protocols have been
infiltration rate and the
protocols have been suggested
rate and the matching
have been suggested as
and the matching revenues
been suggested as replacements
the matching revenues are
suggested as replacements for
matching revenues are shown
as replacements for tcp
revenues are shown in
are shown in equation
ip in such settings
in such settings xcp
as in the two
the revenue at the
revenue at the symmetric
at the symmetric equilibrium
the symmetric equilibrium is
symmetric equilibrium is inferior
equilibrium is inferior to
is inferior to the
inferior to the no
up our analysis addresses
our analysis addresses the
are a few but
analysis addresses the eventual
a few but all
addresses the eventual revenue
few but all require
the eventual revenue of
but all require modifications
eventual revenue of the
all require modifications to
revenue of the pools
require modifications to end
assuming the mining difficulty
the mining difficulty is
mining difficulty is set
difficulty is set based
or the intervening network
is set based on
set based on the
based on the effective
on the effective mining
the effective mining power
some approaches seek to
approaches seek to differentiate
seek to differentiate between
to differentiate between congestion
not including mining power
differentiate between congestion and
including mining power used
between congestion and non
mining power used for
power used for withholding
difficulty is updated only
is updated only periodically
updated only periodically every
maelstrom is a transparent
is a transparent performance
a transparent performance enhancing
transparent performance enhancing proxy
as defined in rfc
when mining power in
mining power in the
power in the system
in the system is
the system is regularly
system is regularly increasing
which has been true
has been true for
been true for the
true for the majority
for the majority of
the majority of bitcoin
majority of bitcoin s
of bitcoin s history
numerous implementations of peps
implementations of peps exist
of peps exist for
peps exist for improving
exist for improving tcp
for improving tcp performance
improving tcp performance on
tcp performance on satellite
no adjustment may be
adjustment may be necessary
if an attacker purchases
an attacker purchases new
attacker purchases new mining
purchases new mining hardware
new mining hardware and
mining hardware and employs
hardware and employs it
and employs it directly
employs it directly for
it directly for block
directly for block withholding
this mining power is
mining power is never
power is never included
but we are not
is never included in
we are not aware
never included in the
are not aware of
included in the difficulty
not aware of any
in the difficulty calculation
aware of any peps
the difficulty calculation the
of any peps that
difficulty calculation the system
any peps that use
calculation the system is
peps that use fec
the system is never
that use fec to
system is never aware
use fec to mask
is never aware of
fec to mask errors
never aware of it
to mask errors on
mask errors on long
the difficulty is therefore
difficulty is therefore already
is therefore already correctly
therefore already correctly calculated
already correctly calculated and
correctly calculated and the
calculated and the attack
and the attack is
the attack is profitable
attack is profitable immediately
based fec for reliable
fec for reliable communication
for reliable communication was
reliable communication was first
communication was first explored
if the mining power
was first explored by
the mining power is
first explored by rizzo
mining power is static
the attack becomes profitable
attack becomes profitable only
becomes profitable only after
profitable only after the
only after the bitcoin
after the bitcoin system
the bitcoin system has
bitcoin system has normalized
system has normalized the
has normalized the revenues
normalized the revenues by
the revenues by adjusting
revenues by adjusting difficulty
the revenue of an
revenue of an attacking
of an attacking pool
an attacking pool is
attacking pool is reduced
pool is reduced due
is reduced due to
reduced due to the
due to the reduction
to the reduction in
the reduction in block
reduction in block generation
in block generation of
block generation of both
generation of both the
of both the attacking
both the attacking and
suggested the use of
the attacking and attacked
the use of fec
attacking and attacked pools
use of fec for
of fec for tcp
ip retransmissions over aggregated
retransmissions over aggregated traffic
over aggregated traffic within
aggregated traffic within an
traffic within an overlay
within an overlay network
an overlay network in
overlay network in the
network in the commodity
in the commodity internet
uses fec for real
modulating the rate of
the rate of encoding
rate of encoding adaptively
the use of end
host fec under tcp
ip has been explored
has been explored in
a multitude of different
multitude of different fec
of different fec encodings
different fec encodings exist
fec encodings exist in
encodings exist in literature
they can broadly be
can broadly be categorized
broadly be categorized into
be categorized into optimal
categorized into optimal erasure
into optimal erasure codes
optimal erasure codes and
erasure codes and near
known optimal code is
optimal code is reed
which we described previously
we described previously as
described previously as generating
previously as generating c
as generating c repair
generating c repair packets
c repair packets from
repair packets from r
packets from r source
from r source packets
any r of the
r of the resulting
of the resulting r
c packets can be
packets can be used
can be used to
be used to reconstruct
used to reconstruct the
to reconstruct the r
reconstruct the r source
the r source packets
optimal codes such as
codes such as tornado
such as tornado and
as tornado and lt
off encoding speed for
encoding speed for large
speed for large data
for large data sizes
large data sizes against
data sizes against a
sizes against a loss
against a loss of
a loss of optimality
loss of optimality the
of optimality the receiver
optimality the receiver needs
the receiver needs to
receiver needs to receive
needs to receive slightly
to receive slightly more
receive slightly more than
slightly more than r
more than r source
than r source or
r source or repair
source or repair packets
or repair packets to
repair packets to regenerate
packets to regenerate the
to regenerate the original
regenerate the original r
the original r data
original r data packets
optimal codes are extremely
codes are extremely fast
are extremely fast for
extremely fast for encoding
fast for encoding over
for encoding over large
encoding over large sets
over large sets of
large sets of data
sets of data but
of data but not
data but not of
but not of significant
not of significant importance
of significant importance for
significant importance for real
since optimal codes perform
optimal codes perform equally
codes perform equally well
perform equally well with
equally well with small
well with small data
with small data sizes
expression for ri in
of particular relevance are
for ri in a
particular relevance are growth
ri in a system
relevance are growth codes
in a system with
a system with pools
system with pools of
with pools of equal
pools of equal size
which use multiple encoding
use multiple encoding rates
multiple encoding rates for
encoding rates for different
rates for different overhead
for different overhead levels
layered interleaving uses multiple
interleaving uses multiple interleaves
uses multiple interleaves for
multiple interleaves for different
interleaves for different burst
for different burst resilience
different burst resilience levels
burst resilience levels without
resilience levels without modulating
levels without modulating the
without modulating the encoding
modulating the encoding rate
the effect of random
effect of random losses
of random losses on
random losses on tcp
ip has been studied
has been studied in
been studied in depth
studied in depth by
in depth by lakshman
padhye s analytical model
q mi q mi
provides a means to
a means to gauge
means to gauge the
to gauge the impact
gauge the impact of
the impact of packet
impact of packet loss
of packet loss on
packet loss on tcp
while most published studies
most published studies of
published studies of packet
studies of packet loss
of packet loss are
packet loss are based
loss are based on
are based on the
based on the commodity
on the commodity internet
the commodity internet rather
commodity internet rather than
internet rather than highspeed
rather than highspeed lambda
than highspeed lambda links
study the sprint backbone
the sprint backbone and
sprint backbone and make
backbone and make two
and make two observations
make two observations that
two observations that could
observations that could be
that could be explained
could be explained by
be explained by non
links are rarely loaded
are rarely loaded at
rarely loaded at more
loaded at more than
of capacity and b
packet reordering events occur
reordering events occur for
events occur for some
occur for some flows
possibly indicating packet loss
indicating packet loss followed
packet loss followed by
loss followed by retransmissions
future work scaling maelstrom
work scaling maelstrom to
scaling maelstrom to multiple
maelstrom to multiple gigabits
to multiple gigabits per
multiple gigabits per second
gigabits per second of
per second of traffic
second of traffic will
of traffic will require
traffic will require small
will require small rack
style clusters of tens
q symmetric equilibrium values
clusters of tens of
symmetric equilibrium values for
of tens of machines
equilibrium values for a
tens of machines to
values for a system
of machines to distribute
for a system of
machines to distribute encoding
a system of q
to distribute encoding load
system of q pools
distribute encoding load over
of q pools of
q pools of equal
pools of equal sizes
we need to design
need to design intelligent
to design intelligent load
countermeasures in order to
over mechanisms for such
in order to choose
mechanisms for such a
order to choose its
for such a scheme
to choose its optimal
choose its optimal infiltration
its optimal infiltration rate
a pool has to
pool has to know
we have described layered
has to know the
have described layered interleaving
to know the rate
described layered interleaving with
know the rate at
layered interleaving with fixed
the rate at which
rate at which it
at which it is
which it is attacked
and the revenue density
the revenue density of
revenue density of potential
density of potential victim
of potential victim pools
and the next step
the next step in
next step in extending
step in extending this
in extending this protocol
extending this protocol is
a pool can estimate
this protocol is to
protocol is to make
pool can estimate the
is to make it
to make it adaptive
can estimate the rate
estimate the rate with
the rate with which
rate with which it
changing interleaves and rate
with which it is
interleaves and rate as
which it is attacked
and rate as loss
it is attacked by
rate as loss patterns
is attacked by comparing
as loss patterns in
attacked by comparing the
loss patterns in the
by comparing the rates
patterns in the link
comparing the rates of
in the link change
the rates of partial
rates of partial and
of partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work it
of work it receives
work it receives from
conclusion modern distributed systems
it receives from its
modern distributed systems are
receives from its miners
distributed systems are compelled
systems are compelled by
are compelled by real
as explained in section
explained in section ii
world imperatives to coordinate
imperatives to coordinate across
to coordinate across datacenters
coordinate across datacenters separated
across datacenters separated by
in order to estimate
order to estimate the
to estimate the revenue
estimate the revenue densities
the revenue densities of
revenue densities of the
densities of the other
of the other pools
a pool can use
pool can use one
can use one of
use one of two
one of two methods
pools often publish this
often publish this data
publish this data to
this data to demonstrate
data to demonstrate their
to demonstrate their honesty
demonstrate their honesty to
their honesty to their
honesty to their miners
a pool can infiltrate
pool can infiltrate each
can infiltrate each of
infiltrate each of the
each of the other
of the other pools
the other pools with
other pools with some
pools with some nominal
with some nominal probing
some nominal probing mining
nominal probing mining power
probing mining power and
mining power and measure
power and measure the
and measure the revenue
measure the revenue density
the revenue density directly
revenue density directly by
density directly by monitoring
directly by monitoring the
by monitoring the probe
monitoring the probe s
the probe s rewards
probe s rewards from
s rewards from the
rewards from the pool
as in the case
in the case of
the case of classical
case of classical block
of classical block withholding
classical block withholding explained
block withholding explained in
withholding explained in section
explained in section ii
a pool might detect
pool might detect that
might detect that it
detect that it is
that it is being
it is being attacked
but cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners is
its miners is the
miners is the attacker
therefore a pool cannot
a pool cannot block
pool cannot block or
cannot block or punish
block or punish withholding
or punish withholding miners
various techniques can be
techniques can be used
can be used to
be used to encourage
used to encourage miners
to encourage miners to
encourage miners to submit
miners to submit full
to submit full blocks
a pool can pay
pool can pay a
can pay a bonus
pay a bonus for
a bonus for submitting
bonus for submitting a
for submitting a full
submitting a full proof
a full proof of
full proof of work
this would increase the
would increase the revenue
increase the revenue of
the revenue of the
revenue of the miner
of the miner that
the miner that found
miner that found a
that found a block
found a block while
a block while reducing
block while reducing the
while reducing the revenue
reducing the revenue of
the revenue of the
revenue of the other
of the other miners
the other miners from
other miners from this
miners from this block
while the average revenue
the average revenue of
average revenue of each
revenue of each miner
of each miner would
each miner would stay
miner would stay the
would stay the same
small miners will suffer
miners will suffer from
will suffer from higher
suffer from higher variance
from higher variance in
higher variance in revenue
another approach is to
approach is to introduce
is to introduce a
to introduce a joining
introduce a joining fee
a joining fee by
joining fee by paying
fee by paying new
by paying new miners
paying new miners less
new miners less for
miners less for their
less for their work
for their work until
their work until they
work until they have
until they have established
they have established a
have established a reputation
established a reputation with
a reputation with the
reputation with the pool
miners that seek flexibility
that seek flexibility may
seek flexibility may not
flexibility may not accept
may not accept this
not accept this policy
accept this policy and
this policy and choose
policy and choose another
and choose another pool
the pool can use
pool can use a
can use a honeypot
use a honeypot trap
a honeypot trap by
honeypot trap by sending
trap by sending the
by sending the miners
sending the miners tasks
the miners tasks which
miners tasks which it
tasks which it knows
which it knows will
it knows will result
knows will result in
will result in a
result in a full
in a full proof
a full proof of
full proof of work
if a miner fails
a miner fails to
miner fails to submit
fails to submit the
to submit the full
submit the full proof
the full proof of
full proof of work
proof of work it
of work it is
work it is tagged
it is tagged as
is tagged as an
tagged as an attacker
to prevent the attacker
prevent the attacker from
the attacker from learning
attacker from learning them
the honeypot tasks have
honeypot tasks have to
tasks have to be
have to be regularly
to be regularly refreshed
pools can also incorporate
can also incorporate out
also incorporate out of
incorporate out of band
out of band mechanisms
of band mechanisms to
band mechanisms to deter
mechanisms to deter attacks
such as verifying the
as verifying the identity
verifying the identity of
the identity of miners
identity of miners or
of miners or using
miners or using trusted
or using trusted computing
using trusted computing technologies
that assure no block
assure no block withholding
no block withholding is
block withholding is taking
withholding is taking place
this would require miners
would require miners to
require miners to use
miners to use specialized
to use specialized hardware
use specialized hardware and
specialized hardware and software
an overhead miners may
overhead miners may not
miners may not accept
there is no known
is no known silver
no known silver bullet
all these techniques reduce
these techniques reduce the
techniques reduce the pool
reduce the pool s
the pool s attractiveness
pool s attractiveness and
s attractiveness and deter
attractiveness and deter miners
latency histograms for i
block withholding recycling we
withholding recycling we assume
recycling we assume that
we assume that the
assume that the infiltrating
that the infiltrating miners
the infiltrating miners are
infiltrating miners are loyal
miners are loyal to
are loyal to the
loyal to the attacker
some of the pool
of the pool s
the pool s members
pool s members may
s members may be
members may be disloyal
may be disloyal infiltrators
when sending disloyal miners
sending disloyal miners to
disloyal miners to perform
miners to perform block
to perform block withholding
perform block withholding at
block withholding at other
withholding at other pools
an attacker takes a
attacker takes a significant
takes a significant risk
can use a loyal
use a loyal miner
a loyal miner w
loyal miner w to
miner w to infiltrate
w to infiltrate pool
thinking the miner is
the miner is loyal
miner is loyal to
is loyal to it
might use it to
use it to attack
it to attack pool
the miner m can
miner m can perform
m can perform honest
can perform honest mining
perform honest mining for
honest mining for pool
rather than withhold its
than withhold its blocks
and not return any
not return any revenue
return any revenue to
any revenue to pool
it will take its
will take its share
take its share of
its share of pool
which thinks the miner
thinks the miner is
the miner is loyal
miner is loyal to
is loyal to it
and deliver it back
deliver it back to
it back to pool
to avoid such a
avoid such a risk
a pool needs a
pool needs a sufficient
needs a sufficient number
a sufficient number of
sufficient number of verified
number of verified miners
of verified miners miners
verified miners miners that
miners miners that it
miners that it knows
that it knows to
it knows to be
knows to be loyal
the optimal infiltration rate
optimal infiltration rate may
infiltration rate may be
rate may be as
may be as high
be as high as
of the pool size
but this is only
this is only in
is only in extreme
only in extreme cases
in extreme cases when
extreme cases when pools
cases when pools are
when pools are large
for practical pool sizes
a pool may need
pool may need up
may need up to
latency histograms for i
of its mining power
its mining power for
mining power for infiltration
pools typically have loyal
typically have loyal mining
have loyal mining power
loyal mining power either
mining power either run
power either run directly
either run directly by
run directly by the
directly by the pool
by the pool owners
the pool owners or
pool owners or sold
owners or sold as
or sold as a
sold as a service
as a service but
a service but run
service but run on
but run on the
run on the pool
on the pool owners
the pool owners hardware
packet loss cripples the
however the size of
loss cripples the performance
the size of this
cripples the performance notes
size of this mining
the performance notes of
of this mining power
performance notes of such
this mining power is
notes of such systems
mining power is considered
power is considered a
is considered a trade
considered a trade secret
and reliability and flow
a trade secret and
trade secret and is
secret and is not
and is not published
block withholding in practice
withholding in practice long
in practice long term
practice long term block
long term block withholding
term block withholding attacks
block withholding attacks are
withholding attacks are difficult
attacks are difficult to
are difficult to hide
since miners using an
miners using an attacked
using an attacked pool
an attacked pool would
attacked pool would notice
pool would notice the
would notice the reduced
notice the reduced revenue
the reduced revenue density
are increasingly popular and
increasingly popular and designed
popular and designed for
and designed for lans
designed for lans and
such attacks are rarely
attacks are rarely reported
or the commodity internet
the commodity internet fail
and we can therefore
commodity internet fail to
we can therefore conclude
internet fail to used
can therefore conclude that
fail to used for
therefore conclude that they
to used for applications
conclude that they are
used for applications such
that they are indeed
for applications such as
they are indeed rare
applications such as efficiently
such as efficiently distributing
as efficiently distributing bulk
efficiently distributing bulk data
a recent exception is
recent exception is an
exception is an attack
is an attack on
an attack on the
attack on the eligius
on the eligius pool
the eligius pool performed
eligius pool performed in
pool performed in may
performed in may and
in may and june
achieve optimal performance on
optimal performance on the
performance on the high
it is not obvious
is not obvious that
not obvious that these
obvious that these have
that these have utility
these have utility in
have utility in real
time communi lambda networks
communi lambda networks linking
lambda networks linking datacenters
protocols is not an
is not an option
not an option for
an option for commodity
option for commodity clusters
for commodity clusters where
commodity clusters where standardization
clusters where standardization is
bitcoin before detecting the
where standardization is critical
before detecting the attack
standardization is critical for
is critical for cost
critical for cost mitigation
at which point payouts
which point payouts to
point payouts to the
maelstrom is an edge
payouts to the attackers
is an edge appliance
to the attackers were
an edge appliance that
the attackers were blocked
edge appliance that uses
appliance that uses forward
that uses forward error
uses forward error correction
forward error correction references
the attackers continued the
error correction references to
attackers continued the attack
correction references to mask
references to mask packet
to mask packet loss
mask packet loss from
packet loss from end
more bitcoin before realizing
bitcoin before realizing they
before realizing they were
realizing they were not
they were not receiving
were not receiving their
not receiving their payout
the reasons the attack
reasons the attack was
the attack was so
global crossing current network
attack was so easily
crossing current network performance
was so easily subverted
so easily subverted is
easily subverted is the
subverted is the limited
is the limited efforts
the limited efforts of
limited efforts of the
efforts of the attackers
of the attackers to
the attackers to hide
attackers to hide themselves
they have only used
have only used two
only used two payout
used two payout addresses
two payout addresses to
payout addresses to collect
addresses to collect their
to collect their payouts
and so it was
so it was possible
it was possible for
was possible for the
ip throughput and latency
possible for the alert
throughput and latency by
for the alert pool
and latency by orders
the alert pool manager
latency by orders of
alert pool manager to
by orders of magninetwork
pool manager to cluster
manager to cluster the
to cluster the attacking
cluster the attacking miners
the attacking miners and
attacking miners and obtain
miners and obtain a
and obtain a statistically
obtain a statistically significant
a statistically significant proof
statistically significant proof of
significant proof of their
proof of their wrongdoing
last tude when loss
tude when loss occurs
it is unknown whether
is unknown whether this
unknown whether this was
maelstrom is easy to
whether this was a
is easy to install
this was a classical
easy to install and
was a classical block
to install and accessed
a classical block withholding
install and accessed feb
classical block withholding attack
with the goal of
the goal of sabotage
or a more elaborate
a more elaborate scheme
to verify the effectiveness
verify the effectiveness of
the effectiveness of block
effectiveness of block withholding
of block withholding for
block withholding for profit
and is completely transparent
is completely transparent to
completely transparent to applications
transparent to applications and
qwest ip network statistics
implemented an experimental bitcoin
an experimental bitcoin test
experimental bitcoin test network
bitcoin test network and
test network and demonstrated
network and demonstrated the
and demonstrated the practicality
demonstrated the practicality of
the practicality of the
practicality of the attack
protocols literally providing reliability
literally providing reliability in
providing reliability in an
bitcoin s health large
reliability in an inexpennet
s health large pools
health large pools hinder
large pools hinder bitcoin
pools hinder bitcoin s
hinder bitcoin s distributed
bitcoin s distributed nature
s distributed nature as
distributed nature as they
nature as they put
as they put a
they put a lot
put a lot of
a lot of mining
lot of mining power
of mining power in
mining power in the
power in the hands
in the hands of
the hands of a
hands of a few
of a few pool
a few pool managers
this has been mostly
has been mostly addressed
been mostly addressed by
mostly addressed by community
addressed by community pressure
by community pressure on
community pressure on miners
pressure on miners to
on miners to avoid
miners to avoid forming
to avoid forming large
avoid forming large pools
acknowledgments we would like
we would like to
would like to thank
like to thank our
to thank our shepherd
thank our shepherd robert
our shepherd robert morris
shepherd robert morris and
robert morris and the
morris and the other
and the other reviewers
however such recommendations had
the other reviewers for
such recommendations had only
other reviewers for extensive
recommendations had only had
reviewers for extensive comments
had only had limited
for extensive comments that
only had limited success
extensive comments that significantly
comments that significantly shaped
that significantly shaped the
significantly shaped the final
shaped the final version
and mining is still
the final version of
mining is still dominated
final version of the
is still dominated by
version of the paper
still dominated by a
dominated by a small
by a small number
a small number of
small number of large
number of large pools
as a characteristic example
in the period of
the period of november
vidhyashankar venkataraman and vivek
venkataraman and vivek vishnumurthy
and vivek vishnumurthy provided
vivek vishnumurthy provided useful
vishnumurthy provided useful comments
tom boures provided valuable
boures provided valuable insight
provided valuable insight into
valuable insight into the
insight into the quality
into the quality of
the quality of existing
three pools generated over
quality of existing fiber
of existing fiber links
stanislav shalunov provided information
shalunov provided information on
provided information on loss
information on loss rates
on loss rates on
loss rates on internet
of the proofs of
the proofs of work
and paul wefel gave
paul wefel gave us
wefel gave us access
gave us access to
us access to teragrid
access to teragrid loss
to teragrid loss measurements
the fact that block
fact that block withholding
that block withholding attacks
block withholding attacks are
withholding attacks are rarely
attacks are rarely observed
are rarely observed may
rarely observed may indicate
observed may indicate that
may indicate that the
indicate that the active
that the active pools
the active pools have
active pools have reached
pools have reached an
have reached an implicit
reached an implicit or
an implicit or explicit
implicit or explicit agreement
or explicit agreement not
explicit agreement not to
agreement not to attack
not to attack one
to attack one another
an attacked pool cannot
attacked pool cannot detect
pool cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners are
its miners are attacking
miners are attacking it
let alone which pool
alone which pool controls
which pool controls the
pool controls the miners
at some point a
some point a pool
point a pool might
a pool might miscalculate
pool might miscalculate and
might miscalculate and decide
miscalculate and decide to
and decide to try
decide to try to
to try to increase
try to increase its
to increase its revenue
nat and packet mangling
one pool might be
and packet mangling for
pool might be enough
packet mangling for linux
might be enough to
be enough to break
enough to break the
to break the agreement
possibly leading to a
leading to a constant
to a constant rate
a constant rate of
constant rate of attacks
rate of attacks among
of attacks among pools
attacks among pools and
among pools and a
pools and a reduced
and a reduced revenue
if open pools reach
open pools reach a
pools reach a state
reach a state where
a state where their
state where their revenue
where their revenue density
their revenue density is
revenue density is reduced
density is reduced due
is reduced due to
reduced due to attacks
miners will leave them
will leave them in
leave them in favor
them in favor of
in favor of other
favor of other available
of other available options
miners of sufficient size
of sufficient size can
sufficient size can mine
size can mine solo
smaller miners can form
miners can form private
can form private pools
form private pools with
private pools with closed
pools with closed access
limited to trusted participants
such a change may
a change may be
change may be in
may be in favor
be in favor of
in favor of bitcoin
favor of bitcoin as
of bitcoin as a
bitcoin as a whole
since they require such
they require such intimate
require such intimate trust
private pools are likely
pools are likely to
are likely to be
likely to be smaller
and form a fine
form a fine grained
a fine grained distribution
fine grained distribution of
grained distribution of mining
distribution of mining power
of mining power with
mining power with many
power with many small
with many small pools
many small pools and
small pools and solo
pools and solo miners
a pool may engage
pool may engage in
may engage in an
engage in an attack
in an attack against
lateral error correction for
an attack against another
error correction for timecritical
attack against another pool
correction for timecritical multicast
against another pool not
another pool not to
pool not to increase
not to increase its
to increase its absolute
increase its absolute revenue
but rather to attract
rather to attract miners
to attract miners by
attract miners by temporarily
miners by temporarily increasing
by temporarily increasing its
temporarily increasing its revenue
increasing its revenue relative
its revenue relative to
revenue relative to a
relative to a competing
to a competing pool
fourth usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
recent work has investigated
systems design and implementation
work has investigated the
has investigated the motivation
investigated the motivation of
the motivation of pools
motivation of pools to
of pools to utilize
pools to utilize part
to utilize part of
utilize part of their
part of their resources
of their resources towards
their resources towards sabotage
resources towards sabotage attacks
towards sabotage attacks against
sabotage attacks against each
attacks against each other
the model of those
model of those works
of those works is
those works is different
works is different from
is different from the
different from the pool
from the pool game
the pool game model
pool game model in
performance enhancing proxies intended
game model in two
enhancing proxies intended to
model in two major
proxies intended to mitigate
in two major ways
intended to mitigate link
two major ways a
major ways a sabotage
ways a sabotage attack
a sabotage attack does
sabotage attack does not
attack does not transfer
does not transfer revenue
not transfer revenue from
transfer revenue from victim
revenue from victim to
from victim to attacker
and migrating miners switch
migrating miners switch to
miners switch to less
switch to less attacked
to less attacked pools
changing pool sizes and
pool sizes and hence
sizes and hence revenues
and hence revenues until
hence revenues until convergence
the model is parametrized
model is parametrized by
is parametrized by the
parametrized by the cost
by the cost of
the cost of the
cost of the attack
of the attack and
the attack and by
attack and by the
and by the mobility
by the mobility of
the mobility of the
mobility of the miners
and the analysis demonstrates
the analysis demonstrates that
analysis demonstrates that when
demonstrates that when considering
that when considering only
when considering only sabotage
considering only sabotage attacks
only sabotage attacks there
sabotage attacks there are
attacks there are regions
there are regions where
are regions where no
attack is the best
is the best strategy
the miner s dilemma
miner s dilemma is
s dilemma is therefore
dilemma is therefore not
is therefore not manifested
therefore not manifested in
not manifested in that
manifested in that model
enhanced loss differentiation algorithms
loss differentiation algorithms for
differentiation algorithms for use
algorithms for use in
pool competition for miners
for use in tcp
competition for miners is
use in tcp sources
for miners is an
in tcp sources over
miners is an incentive
tcp sources over heterogeneous
is an incentive in
sources over heterogeneous wireless
an incentive in and
over heterogeneous wireless networks
incentive in and of
in and of its
and of its own
of its own for
its own for mutual
own for mutual attacks
and a pool may
a pool may therefore
pool may therefore choose
may therefore choose to
therefore choose to perform
choose to perform block
to perform block withholding
perform block withholding even
block withholding even if
withholding even if its
ieee global telecommunications conference
even if its revenue
if its revenue would
its revenue would increase
revenue would increase only
would increase only after
increase only after the
only after the next
after the next difficult
the next difficult adjustment
the two models are
two models are therefore
models are therefore complementary
the analysis of their
analysis of their combination
of their combination is
their combination is left
combination is left for
is left for future
left for future work
we assumed in our
assumed in our analysis
in our analysis that
our analysis that pools
analysis that pools do
that pools do not
pools do not charge
do not charge fees
not charge fees from
charge fees from their
fees from their members
from their members since
their members since such
members since such fees
since such fees are
such fees are typically
fees are typically nominal
flow aggregation for enhanced
aggregation for enhanced tcp
for enhanced tcp over
enhanced tcp over wide
tcp over wide area
over wide area wireless
of a pool s
a pool s revenue
the model can be
model can be extended
can be extended to
be extended to include
extended to include pools
to include pools fees
fees would add a
would add a friction
add a friction element
a friction element to
friction element to the
element to the flow
to the flow of
vice president of research
the flow of revenue
president of research and
flow of revenue among
of research and t
of revenue among infiltrated
revenue among infiltrated and
among infiltrated and infiltrating
infiltrated and infiltrating pools
would change to take
change to take into
to take into account
take into account a
into account a pool
account a pool fee
a pool fee of
pool fee of f
fee of f pp
of f pp ri
multicast routing in datagram
routing in datagram internetworks
in datagram internetworks and
datagram internetworks and extended
internetworks and extended lans
a pool with a
pool with a fee
with a fee of
a fee of f
fee of f is
of f is a
f is a less
is a less attractive
a less attractive target
less attractive target for
attractive target for block
target for block withholding
since the attacker s
the attacker s revenue
attacker s revenue is
s revenue is reduced
revenue is reduced by
is reduced by f
however it is also
it is also less
is also less attractive
also less attractive for
less attractive for miners
attractive for miners in
for miners in general
trading off the two
off the two for
the two for best
two for best protection
for best protection is
best protection is left
protection is left for
is left for future
left for future work
as part of the
part of the treatment
of the treatment of
the treatment of the
treatment of the miner
r elated w ork
elated w ork a
the block withholding attack
block withholding attack the
withholding attack the danger
attack the danger of
the danger of a
danger of a block
of a block withholding
a block withholding attack
block withholding attack is
withholding attack is as
attack is as old
is as old as
as old as bitcoin
old as bitcoin pools
the attack was described
attack was described by
was described by rosenfeld
level traffic measurements from
traffic measurements from the
measurements from the sprint
from the sprint ip
the sprint ip backbone
as pools were becoming
pools were becoming a
were becoming a dominant
becoming a dominant player
a dominant player in
dominant player in the
player in the bitcoin
in the bitcoin world
the paper described the
paper described the standard
described the standard attack
used by a miner
by a miner to
a miner to sabotage
miner to sabotage a
to sabotage a pool
sabotage a pool at
a pool at the
pool at the cost
at the cost of
the cost of reducing
cost of reducing its
of reducing its own
reducing its own revenue
a more general view
more general view of
general view of fairness
view of fairness in
of fairness in proof
fairness in proof of
in proof of work
proof of work schemes
of work schemes was
work schemes was discussed
schemes was discussed in
in the context of
the context of the
context of the hashcash
of the hashcash system
a transport protocol for
transport protocol for grid
protocol for grid computing
journal of grid computing
early work did not
work did not address
did not address the
not address the possibility
address the possibility of
the possibility of pools
possibility of pools infiltrating
of pools infiltrating other
pools infiltrating other pools
infiltrating other pools for
other pools for block
pools for block withholding
experimentally demonstrate that block
demonstrate that block withholding
that block withholding can
block withholding can increase
withholding can increase the
can increase the attacker
increase the attacker s
the attacker s revenue
they do not address
do not address the
not address the question
address the question of
the question of mutual
question of mutual attacks
have recently noted that
recently noted that a
noted that a pool
that a pool can
a pool can increase
pool can increase its
can increase its overall
increase its overall revenue
its overall revenue with
overall revenue with block
revenue with block withholding
with block withholding if
block withholding if all
withholding if all other
if all other mining
all other mining is
other mining is performed
mining is performed by
is performed by honest
performed by honest pools
we consider the general
consider the general case
the general case where
general case where not
optical domain performance monitoring
case where not all
where not all mining
not all mining is
all mining is performed
mining is performed through
optical fiber communication conference
is performed through public
performed through public pools
and analyze situations where
analyze situations where pools
situations where pools can
where pools can attack
pools can attack one
can attack one another
the discrepancy between the
discrepancy between the calculations
between the calculations of
for the special case
the special case analyzed
special case analyzed there
case analyzed there and
analyzed there and our
there and our results
and our results can
our results can be
results can be explained
can be explained by
be explained by the
explained by the strong
by the strong approximations
the strong approximations in
strong approximations in that
approximations in that work
we calculate exactly how
calculate exactly how infiltrating
exactly how infiltrating miners
how infiltrating miners reduce
infiltrating miners reduce the
miners reduce the revenue
reduce the revenue density
the revenue density of
end performance effects of
revenue density of the
performance effects of parallel
density of the infiltrated
effects of parallel tcp
of the infiltrated pool
of parallel tcp sockets
parallel tcp sockets on
tcp sockets on a
sockets on a lossy
on a lossy wide
temporary block withholding in
block withholding in the
withholding in the block
in the block withholding
the block withholding attack
block withholding attack discussed
withholding attack discussed in
attack discussed in this
discussed in this work
in this work the
this work the withheld
work the withheld blocks
the withheld blocks are
withheld blocks are never
blocks are never published
blocks can be withheld
can be withheld temporarily
not following the bitcoin
following the bitcoin protocol
to improve an attacker
improve an attacker s
an attacker s revenue
a miner or a
miner or a pool
or a pool can
a pool can perform
pool can perform a
can perform a selfish
perform a selfish mining
a selfish mining attack
with selfish mining the
selfish mining the attacker
the effects of systemic
mining the attacker increases
effects of systemic packet
of systemic packet loss
the attacker increases its
systemic packet loss on
packet loss on aggregate
attacker increases its revenue
loss on aggregate tcp
on aggregate tcp flows
increases its revenue by
its revenue by temporarily
revenue by temporarily withholding
by temporarily withholding its
temporarily withholding its blocks
withholding its blocks and
its blocks and publishing
blocks and publishing them
and publishing them in
publishing them in response
them in response to
in response to block
response to block publication
to block publication by
block publication by other
publication by other pools
by other pools and
other pools and miners
this attack is independent
attack is independent of
is independent of the
independent of the block
of the block withholding
the block withholding attack
ieee conference on supercomputing
block withholding attack we
withholding attack we discuss
attack we discuss here
we discuss here and
discuss here and the
here and the two
and the two can
the two can be
two can be performed
can be performed in
be performed in concert
an attacker can also
attacker can also perform
can also perform a
also perform a double
perform a double spending
a double spending attack
double spending attack as
spending attack as follows
he intentionally generates two
intentionally generates two conflicting
generates two conflicting transactions
places one in a
one in a block
in a block it
a block it withholds
and publishes the other
publishes the other transaction
after the recipient sees
the recipient sees the
recipient sees the published
sees the published transaction
the attacker publishes the
predictable high performance bulk
attacker publishes the withheld
high performance bulk data
publishes the withheld block
performance bulk data transfer
the withheld block to
withheld block to revoke
block to revoke the
to revoke the former
revoke the former transaction
ieee international conference on
international conference on cluster
conference on cluster computing
this attack is performed
attack is performed by
is performed by miners
performed by miners or
by miners or pools
miners or pools against
or pools against service
pools against service providers
against service providers that
service providers that accept
providers that accept bitcoin
and it not directly
it not directly related
not directly related to
directly related to this
related to this work
block withholding defense most
withholding defense most crypto
currencies use a proof
the case for packet
case for packet level
work architecture similar to
for packet level fec
architecture similar to bitcoin
where finding proof of
finding proof of work
proof of work is
of work is the
work is the result
is the result of
the result of solution
result of solution guessing
of solution guessing and
solution guessing and checking
proceedings of the tc
all of the algorithms
of the algorithms we
the algorithms we are
algorithms we are aware
we are aware of
are aware of are
aware of are susceptible
of are susceptible to
are susceptible to the
susceptible to the block
to the block withholding
the block withholding attack
as in all of
in all of them
all of them the
of them the miner
them the miner can
the miner can check
miner can check whether
can check whether she
fifth international workshop on
check whether she found
international workshop on protocols
whether she found a
workshop on protocols for
she found a full
on protocols for high
found a full or
a full or a
full or a partial
or a partial proof
a partial proof of
partial proof of work
prominent examples are litecoin
it is possible to
is possible to use
possible to use an
to use an alternative
use an alternative proof
an alternative proof of
alternative proof of work
proof of work mechanism
of work mechanism in
work mechanism in which
mechanism in which miners
in which miners would
which miners would not
miners would not be
would not be able
not be able to
be able to distinguish
able to distinguish partial
to distinguish partial from
distinguish partial from full
partial from full proofs
from full proofs of
full proofs of work
gigabit ethernet on commodity
ethernet on commodity systems
such a solution could
a solution could reduce
solution could reduce or
could reduce or remove
reduce or remove the
or remove the danger
remove the danger of
the danger of block
danger of block withholding
making such a change
such a change may
a change may not
change may not be
may not be in
not be in the
be in the interest
in the interest of
the interest of the
interest of the community
or even its potential
could lead to a
lead to a reduction
to a reduction of
a reduction of pool
reduction of pool sizes
as explained in section
explained in section ix
decentralized pools although most
pools although most pools
although most pools use
most pools use a
pools use a centralized
use a centralized manager
a prominent exception is
prominent exception is p
pool a distributed pool
a distributed pool architecture
distributed pool architecture with
pool architecture with no
architecture with no central
with no central manager
where did my performance
did my performance go
rate limiting rears its
limiting rears its ugly
rears its ugly head
but the question of
the question of whether
question of whether a
of whether a pool
whether a pool is
a pool is run
pool is run by
is run by a
run by a centralized
by a centralized manager
a centralized manager or
centralized manager or with
manager or with a
or with a decentralized
with a decentralized architecture
a decentralized architecture is
decentralized architecture is almost
architecture is almost immaterial
is almost immaterial for
almost immaterial for the
immaterial for the attack
for the attack we
the attack we describe
pool group can be
group can be infiltrated
can be infiltrated and
be infiltrated and attacked
pool code can be
code can be changed
can be changed to
be changed to support
changed to support attacks
to support attacks against
support attacks against other
attacks against other pools
on the other hand
pool can be used
can be used by
be used by groups
used by groups of
by groups of miners
groups of miners to
of miners to easily
miners to easily form
to easily form closed
easily form closed pools
these do not accept
do not accept untrusted
not accept untrusted miners
and are therefore protected
are therefore protected against
therefore protected against block
protected against block withholding
isn t quite enough
c onclusion we explored
onclusion we explored a
we explored a block
explored a block withholding
a block withholding attack
block withholding attack among
withholding attack among bitcoin
attack among bitcoin mining
among bitcoin mining pools
bitcoin mining pools an
mining pools an attack
pools an attack that
an attack that is
attack that is possible
that is possible in
is possible in any
possible in any similar
in any similar system
any similar system that
similar system that rewards
system that rewards for
that rewards for proof
rewards for proof of
for proof of work
such systems are gaining
systems are gaining popularity
running most digital currencies
most digital currencies and
digital currencies and related
currencies and related services
we observe that no
attacks is not a
is not a nash
not a nash equilibrium
if none of the
none of the other
of the other pools
the other pools attack
a pool can increase
pool can increase its
can increase its revenue
increase its revenue by
modified tcp congestion avoidance
its revenue by attacking
tcp congestion avoidance algorithm
revenue by attacking the
by attacking the others
when two pools can
two pools can attack
pools can attack each
can attack each other
they face a version
face a version of
a version of the
version of the prisoner
of the prisoner s
the prisoner s dilemma
if one pool chooses
one pool chooses to
pool chooses to attack
the victim s revenue
victim s revenue is
s revenue is reduced
and it can retaliate
it can retaliate by
can retaliate by attacking
retaliate by attacking and
by attacking and increase
attacking and increase its
and increase its revenue
at nash equilibrium both
nash equilibrium both earn
equilibrium both earn less
both earn less than
earn less than they
less than they would
than they would have
they would have if
would have if neither
have if neither attacked
with multiple pools of
multiple pools of equal
pools of equal size
of equal size a
equal size a similar
size a similar situation
a similar situation arises
similar situation arises with
situation arises with a
arises with a symmetric
with a symmetric equilibrium
physical layer impact upon
layer impact upon packet
impact upon packet errors
the fact that block
fact that block withholding
that block withholding is
passive and active measurement
block withholding is not
and active measurement workshop
withholding is not common
is not common may
not common may be
common may be explained
may be explained by
be explained by modeling
explained by modeling the
by modeling the attack
modeling the attack decisions
the attack decisions as
attack decisions as an
decisions as an iterative
as an iterative prisoner
an iterative prisoner s
iterative prisoner s dilemma
we argue that the
argue that the situation
that the situation is
the situation is unstable
situation is unstable since
is unstable since the
unstable since the attack
since the attack can
the attack can be
attack can be done
can be done anonymously
one pool may decide
pool may decide to
may decide to increase
decide to increase its
to increase its revenue
increase its revenue and
its revenue and drag
revenue and drag the
and drag the others
drag the others to
the others to attack
others to attack as
to attack as well
ending with a reduced
with a reduced revenue
a reduced revenue for
reduced revenue for all
the inferior revenue would
inferior revenue would push
revenue would push miners
would push miners to
push miners to join
miners to join private
to join private pools
which can verify that
can verify that their
verify that their registered
that their registered miners
their registered miners do
registered miners do not
miners do not withhold
do not withhold blocks
this would lead to
would lead to smaller
lead to smaller pools
maximizing sensor network data
sensor network data persistence
and so ultimately to
so ultimately to a
in proceedings of acm
ultimately to a better
proceedings of acm sigcomm
to a better environment
a better environment for
better environment for bitcoin
environment for bitcoin as
for bitcoin as a
bitcoin as a whole
for their valuable advice
the author is grateful
author is grateful to
is grateful to ken
grateful to ken birman
emin gu n sirer
and the paper shepherd
the paper shepherd joseph
paper shepherd joseph bonneau
congestion control for high
control for high bandwidth
peer electronic cash system
and protocols for computer
protocols for computer communications
ebay s paypal unit
s paypal unit to
paypal unit to start
unit to start accepting
to start accepting bitcoin
start accepting bitcoin payments
google adds bitcoin currency
adds bitcoin currency conversion
bitcoin currency conversion to
currency conversion to search
journal of lightwave technology
a cross layer study
cross layer study of
layer study of packet
study of packet loss
of packet loss in
packet loss in all
the performance of tcp
ip for networks with
for networks with high
networks with high bandwidth
delay products and random
products and random loss
acm transactions on networking
repurposing bitcoin work for
bitcoin work for data
work for data preservation
in proceedings of the
proceedings of the ieee
of the ieee symposium
the ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
namecoin dns dotbit project
rd annual ieee symposium
annual ieee symposium on
ieee symposium on foundations
symposium on foundations of
on foundations of computer
foundations of computer science
a next generation smart
next generation smart contract
end forward error correction
international zurich seminar on
zurich seminar on communications
analysis of bitcoin pooled
rateless codes and big
of bitcoin pooled mining
codes and big downloads
bitcoin pooled mining reward
pooled mining reward systems
paritybased loss recovery for
loss recovery for reliable
recovery for reliable multicast
for reliable multicast transmission
in proceedings of the
proceedings of the acm
of the acm sigcomm
research perspectives on bitcoin
perspectives on bitcoin and
on bitcoin and secondgeneration
bitcoin and secondgeneration cryptocurrencies
in ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
a simple model and
simple model and its
model and its empirical
and its empirical validation
an adaptive forward error
adaptive forward error correction
forward error correction protocol
error correction protocol for
correction protocol for end
computer communications and networks
th international conference on
information propagation in the
propagation in the bitcoin
in the bitcoin network
th ieee international conference
ieee international conference on
international conference on peer
businesses see the light
bitcoin and the age
and the age of
the age of bespoke
age of bespoke silicon
in proceedings of the
international conference on compilers
architectures and synthesis for
and synthesis for embedded
synthesis for embedded systems
into the bitcoin mines
effective erasure codes for
erasure codes for reliable
codes for reliable computer
for reliable computer communication
reliable computer communication protocols
on the feasibility of
the feasibility of software
feasibility of software fec
the case for application
level network striping for
network striping for data
striping for data intensive
for data intensive applications
data intensive applications using
intensive applications using high
applications using high speed
using high speed wide
high speed wide area
speed wide area networks
ieee conference on supercomputing
google s secret plans
s secret plans for
secret plans for all
plans for all that
for all that dark
all that dark fiber
how a mining monopoly
a mining monopoly can
mining monopoly can attack
monopoly can attack bitcoin
an overlay based architecture
overlay based architecture for
based architecture for enhancing
architecture for enhancing internet
for enhancing internet qos
first usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
majority is not enough
bitcoin mining is vulnerable
in financial cryptography and
financial cryptography and data
cryptography and data security
udp bandwidth measurement tool
cooperative equilibrium for supergames
the review of economic
review of economic studies
a tcp performance enhancing
tcp performance enhancing proxy
performance enhancing proxy for
enhancing proxy for satellite
proxy for satellite links
proceedings of the second
of the second international
the second international ifip
networking conference on networking
conference on networking technologies
performance of computer and
of computer and communication
computer and communication networks
and mobile and wireless
mobile and wireless communications
term competition a game
tsunami file transfer protocol
workshop on protocols for
on protocols for fast
protocols for fast longdistance
for fast longdistance networks
the university of illinois
university of illinois national
of illinois national center
illinois national center for
national center for supercomputing
center for supercomputing applications
io bitcoin mining pool
an integrated experimental environment
integrated experimental environment for
experimental environment for distributed
environment for distributed systems
for distributed systems and
distributed systems and networks
of the fifth symposium
the fifth symposium on
fifth symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
solomon codes and their
codes and their applications
kncminer bitcoin mining cloud
bitcoin mining cloud mining
an authorization architecture for
authorization architecture for trustworthy
architecture for trustworthy computing
in proceedings of the
proceedings of the twenty
third acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
on power splitting games
power splitting games in
splitting games in distributed
games in distributed computation
the case of bitcoin
case of bitcoin pooled
of bitcoin pooled mining
weekly bitcoin network statistics
theoretic analysis of ddos
analysis of ddos attacks
of ddos attacks against
ddos attacks against bitcoin
attacks against bitcoin mining
against bitcoin mining pools
in workshop on bitcoin
workshop on bitcoin research
when bitcoin mining pools
bitcoin mining pools run
mining pools run dry
in workshop on bitcoin
workshop on bitcoin research
comparison of mining pools
comparison of mining pools
hashcash amortizable publicly auditable
amortizable publicly auditable cost
hashcash a denial of
a denial of service
denial of service counter
on subversive miner strategies
subversive miner strategies and
miner strategies and block
strategies and block withholding
and block withholding attack
block withholding attack in
withholding attack in bitcoin
attack in bitcoin digital
in bitcoin digital currency
how to disincentivize large
to disincentivize large bitcoin
disincentivize large bitcoin mining
large bitcoin mining pools
the: 7744
of: 4121
a: 3489
to: 3267
and: 3193
in: 2417
is: 1914
for: 1353
that: 1296
with: 990
on: 965
are: 940
we: 925
as: 917
it: 771
by: 745
be: 695
this: 681
data: 659
pool: 659
s: 654
an: 631
at: 630
can: 574
system: 559
its: 497
from: 483
not: 466
or: 452
r: 429
which: 418
each: 404
file: 401
all: 377
systems: 372
m: 368
if: 362
figure: 357
x: 343
one: 338
time: 335
nodes: 332
pools: 325
revenue: 325
t: 325
packets: 320
rate: 320
other: 317
cache: 310
but: 309
our: 291
have: 289
work: 287
i: 282
performance: 281
such: 271
when: 268
loss: 258
p: 258
miners: 257
has: 252
bandwidth: 251
packet: 244
c: 243
network: 242
their: 236
will: 232
attack: 230
block: 230
mining: 230
j: 228
these: 223
than: 222
only: 221
end: 220
use: 220
they: 218
more: 216
node: 209
bitcoin: 204
no: 204
high: 203
number: 202
services: 200
latency: 197
b: 196
may: 193
transactions: 192
would: 192
server: 190
two: 188
where: 188
update: 187
power: 182
between: 180
used: 177
based: 174
d: 173
over: 171
any: 170
different: 169
distributed: 166
miner: 164
new: 164
single: 164
also: 162
client: 161
some: 161
large: 159
tcp: 159
was: 157
web: 157
since: 153
objects: 152
application: 150
ip: 150
service: 150
using: 149
updates: 146
e: 144
protocol: 144
them: 144
set: 140
read: 139
access: 138
applications: 137
process: 137
files: 134
transaction: 133
maelstrom: 132
traffic: 132
there: 131
operating: 130
gossip: 129
however: 129
into: 129
section: 129
withholding: 129
rates: 128
example: 127
mfs: 127
so: 127
communication: 124
consistency: 124
both: 122
same: 122
size: 122
object: 121
priorities: 120
repair: 120
even: 119
peer: 119
throughput: 119
chain: 118
g: 116
control: 114
failure: 114
information: 113
while: 113
first: 112
recovery: 112
were: 112
results: 111
database: 110
protocols: 110
case: 109
acm: 106
link: 106
low: 106
therefore: 106
then: 105
without: 105
rpcs: 104
small: 104
clients: 103
writes: 103
networks: 102
could: 101
second: 101
ms: 100
rpc: 99
do: 98
many: 98
asynchronous: 97
writeback: 97
log: 96
model: 96
within: 96
group: 95
send: 95
does: 94
proof: 94
most: 93
up: 93
memory: 92
state: 91
user: 91
average: 90
content: 90
version: 90
level: 89
order: 89
back: 87
been: 87
support: 87
less: 86
through: 85
windows: 85
available: 84
groups: 84
long: 84
out: 84
see: 84
after: 83
another: 83
approach: 83
fec: 83
full: 83
how: 83
against: 82
architecture: 82
infiltration: 82
message: 82
o: 82
disk: 81
k: 81
messages: 81
need: 81
qsm: 81
about: 80
kb: 80
multicast: 80
sender: 80
uses: 80
management: 79
n: 79
q: 79
way: 79
delivery: 78
total: 78
disks: 77
experiments: 77
possible: 77
write: 77
design: 76
higher: 76
delay: 75
increase: 75
layer: 75
local: 75
research: 75
scale: 75
upload: 75
computer: 74
f: 74
implementation: 74
might: 74
source: 74
analysis: 73
burst: 73
live: 73
probability: 73
workloads: 73
accesses: 72
because: 72
every: 72
lost: 72
solution: 71
cost: 70
due: 70
step: 70
v: 70
value: 70
equilibrium: 69
like: 69
multiple: 69
manager: 68
per: 68
priority: 68
well: 68
list: 67
overhead: 67
computing: 66
load: 66
running: 66
cornell: 65
http: 65
mechanism: 65
opportunistic: 65
run: 65
should: 65
under: 65
attacking: 64
cluster: 64
operations: 64
proceedings: 64
servers: 64
show: 64
shown: 64
test: 64
attacks: 63
layered: 63
much: 63
paper: 63
partial: 63
received: 63
stream: 63
attacker: 62
dependency: 62
kernel: 62
point: 62
solutions: 62
event: 61
l: 61
maximum: 61
must: 61
scheme: 61
shows: 61
sizes: 61
code: 60
game: 60
interleave: 60
prefetching: 60
proofs: 60
replication: 60
result: 60
round: 60
storage: 60
us: 60
perform: 59
sending: 59
very: 59
inconsistency: 58
once: 58
provide: 58
threshold: 58
users: 58
workload: 58
flow: 57
scalable: 57
sent: 57
similar: 57
streaming: 57
being: 56
conference: 56
symposium: 56
download: 55
nt: 55
problem: 55
random: 55
receiver: 55
reduce: 55
requests: 55
until: 55
before: 54
correct: 54
factor: 54
global: 54
graph: 54
interleaving: 54
larger: 54
open: 54
processes: 54
range: 54
retrieved: 54
among: 53
auditing: 53
caching: 53
cannot: 53
h: 53
scenario: 53
center: 52
fetch: 52
mode: 52
real: 52
synchronous: 52
take: 52
transactional: 52
according: 51
form: 51
ieee: 51
increasing: 51
internet: 51
make: 51
present: 51
reads: 51
xor: 51
able: 50
algorithm: 50
current: 50
had: 50
inconsistencies: 50
mobile: 50
store: 50
components: 49
contention: 49
either: 49
existing: 49
hence: 49
mechanisms: 49
mi: 49
now: 49
three: 49
whether: 49
encoding: 48
general: 48
host: 48
implemented: 48
own: 48
prefetch: 48
recovered: 48
reliable: 48
values: 48
although: 47
important: 47
pp: 47
side: 47
w: 47
behavior: 46
execution: 46
fixed: 46
function: 46
generated: 46
graphs: 46
operation: 46
platform: 46
request: 46
speed: 46
th: 46
consider: 45
designed: 45
shared: 45
significant: 45
university: 45
victim: 45
window: 45
attacked: 44
blocks: 44
com: 44
community: 44
delays: 44
density: 44
error: 44
future: 44
hosted: 44
kbps: 44
left: 44
pages: 44
smaller: 44
standard: 44
wide: 44
appliance: 43
changes: 43
component: 43
costs: 43
events: 43
fig: 43
here: 43
makes: 43
ratio: 43
required: 43
right: 43
thus: 43
y: 43
allows: 42
amount: 42
change: 42
developers: 42
distribution: 42
experiment: 42
just: 42
often: 42
rather: 42
scalability: 42
seen: 42
start: 42
tasks: 42
uniform: 42
what: 42
cloud: 41
effect: 41
mafs: 41
missing: 41
numbers: 41
optimal: 41
reduced: 41
simple: 41
ssa: 41
strategy: 41
across: 40
address: 40
detection: 40
down: 40
further: 40
given: 40
hosts: 40
lower: 40
next: 40
non: 40
receive: 40
sends: 40
software: 40
token: 40
typically: 40
allow: 39
caches: 39
cases: 39
congestion: 39
directly: 39
entire: 39
increases: 39
independent: 39
interface: 39
length: 39
original: 39
overheads: 39
part: 39
structure: 39
times: 39
compared: 38
described: 38
direct: 38
during: 38
microsoft: 38
region: 38
require: 38
revenues: 38
world: 38
accessed: 37
al: 37
birman: 37
centers: 37
codes: 37
effective: 37
enough: 37
et: 37
improve: 37
losses: 37
membership: 37
provides: 37
xors: 37
better: 36
clusters: 36
consistent: 36
describe: 36
expected: 36
fact: 36
fast: 36
loyal: 36
previous: 36
related: 36
relative: 36
techniques: 36
today: 36
types: 36
adaptation: 35
additional: 35
almost: 35
commodity: 35
environment: 35
https: 35
international: 35
last: 35
links: 35
longer: 35
minimum: 35
needs: 35
org: 35
performed: 35
proxy: 35
reliability: 35
still: 35
though: 35
above: 34
acid: 34
earlier: 34
evaluation: 34
factors: 34
injection: 34
interleaves: 34
ken: 34
levels: 34
managed: 34
percentage: 34
remote: 34
sets: 34
several: 34
virtual: 34
www: 34
constant: 33
denote: 33
limited: 33
note: 33
overall: 33
particular: 33
receiving: 33
top: 33
working: 33
assume: 32
become: 32
clustered: 32
detect: 32
find: 32
including: 32
period: 32
replicated: 32
scenarios: 32
seconds: 32
space: 32
stable: 32
table: 32
technologies: 32
technology: 32
those: 32
trace: 32
versions: 32
added: 31
ensure: 31
evaluate: 31
finally: 31
follows: 31
immediately: 31
invalidations: 31
least: 31
mb: 31
overlay: 31
prediction: 31
principles: 31
receivers: 31
requires: 31
runs: 31
sirp: 31
target: 31
udp: 31
achieve: 30
adaptive: 30
amazon: 30
auditors: 30
collaboration: 30
correction: 30
dropped: 30
good: 30
incoming: 30
lists: 30
members: 30
performs: 30
policy: 30
recent: 30
ri: 30
schemes: 30
security: 30
share: 30
third: 30
usenix: 30
z: 30
associated: 29
availability: 29
close: 29
commit: 29
complete: 29
delivered: 29
edu: 29
head: 29
key: 29
later: 29
platforms: 29
pull: 29
receives: 29
recover: 29
reducing: 29
science: 29
settings: 29
task: 29
varying: 29
xi: 29
best: 28
configuration: 28
core: 28
dilemma: 28
feasible: 28
implements: 28
issues: 28
making: 28
never: 28
obtain: 28
occur: 28
others: 28
repository: 28
resulting: 28
style: 28
tools: 28
transport: 28
type: 28
area: 27
async: 27
build: 27
building: 27
cached: 27
capacity: 27
collection: 27
failures: 27
following: 27
forward: 27
framework: 27
increased: 27
instance: 27
major: 27
mbps: 27
needed: 27
neighbors: 27
nov: 27
participants: 27
reader: 27
resources: 27
solo: 27
speedup: 27
stored: 27
tm: 27
vn: 27
writer: 27
abort: 26
basic: 26
becomes: 26
benefit: 26
bin: 26
bins: 26
certain: 26
channel: 26
classical: 26
common: 26
consumption: 26
controls: 26
discuss: 26
entry: 26
fault: 26
haul: 26
instead: 26
means: 26
mostly: 26
online: 26
os: 26
solomon: 26
sources: 26
tolerance: 26
vol: 26
allowing: 25
backend: 25
bursts: 25
bursty: 25
choice: 25
conditions: 25
considered: 25
contribution: 25
copy: 25
cs: 25
difficulty: 25
distance: 25
estimate: 25
figures: 25
flows: 25
found: 25
goal: 25
hardware: 25
invalidation: 25
machines: 25
observed: 25
properties: 25
queue: 25
rain: 25
reduces: 25
report: 25
spent: 25
split: 25
takes: 25
transmission: 25
abstract: 24
algorithms: 24
around: 24
blockchain: 24
cause: 24
closed: 24
committed: 24
contrast: 24
correctly: 24
corresponding: 24
critical: 24
datacenters: 24
demand: 24
developed: 24
done: 24
equal: 24
experimental: 24
front: 24
having: 24
idea: 24
individual: 24
infiltrating: 24
knowledge: 24
limit: 24
lock: 24
logs: 24
ny: 24
observe: 24
oriented: 24
peers: 24
place: 24
processing: 24
strategies: 24
streams: 24
structured: 24
too: 24
view: 24
again: 23
approaches: 23
called: 23
choose: 23
create: 23
datacenter: 23
detected: 23
duration: 23
include: 23
layers: 23
likely: 23
majority: 23
member: 23
monitoring: 23
ones: 23
powered: 23
product: 23
reed: 23
sufficient: 23
sync: 23
traditional: 23
unix: 23
ways: 23
workshop: 23
york: 23
alternative: 22
always: 22
avoid: 22
built: 22
certification: 22
connected: 22
consequently: 22
context: 22
defined: 22
dependencies: 22
development: 22
efficient: 22
generate: 22
handle: 22
he: 22
made: 22
maintain: 22
mtu: 22
net: 22
occurs: 22
off: 22
optical: 22
parameters: 22
patterns: 22
popular: 22
problems: 22
revision: 22
starts: 22
via: 22
who: 22
wireless: 22
bandwidths: 21
buffers: 21
centralized: 21
configurations: 21
contains: 21
dynamic: 21
easily: 21
easy: 21
equation: 21
etc: 21
garbage: 21
hand: 21
hash: 21
identical: 21
iii: 21
index: 21
let: 21
life: 21
line: 21
mashup: 21
milliseconds: 21
old: 21
path: 21
private: 21
project: 21
proxies: 21
reasons: 21
response: 21
short: 21
significantly: 21
social: 21
staleness: 21
video: 21
vogels: 21
wait: 21
writing: 21
aggregate: 20
analyze: 20
architectures: 20
benefits: 20
buffering: 20
changing: 20
choosing: 20
consists: 20
four: 20
generates: 20
google: 20
grep: 20
honest: 20
inter: 20
interest: 20
interfaces: 20
library: 20
machine: 20
manner: 20
minibrowser: 20
multi: 20
none: 20
potentially: 20
presence: 20
proc: 20
quality: 20
queued: 20
racs: 20
rapidly: 20
references: 20
respectively: 20
simply: 20
site: 20
stale: 20
together: 20
traces: 20
updated: 20
usa: 20
usage: 20
yet: 20
actually: 19
adding: 19
appropriate: 19
clear: 19
convergence: 19
course: 19
currently: 19
digital: 19
expect: 19
explained: 19
extended: 19
extremely: 19
faster: 19
features: 19
inconsistent: 19
investigation: 19
issue: 19
kind: 19
know: 19
mine: 19
month: 19
natural: 19
networking: 19
om: 19
partition: 19
periods: 19
potential: 19
propagation: 19
proposed: 19
query: 19
quickly: 19
re: 19
recipe: 19
reply: 19
sequence: 19
serializability: 19
soc: 19
speeds: 19
subscribers: 19
taken: 19
towards: 19
transfer: 19
transient: 19
upon: 19
whereas: 19
works: 19
active: 18
aggregation: 18
aware: 18
background: 18
bad: 18
chooses: 18
cpu: 18
databases: 18
difficult: 18
divided: 18
drop: 18
earn: 18
effectiveness: 18
employ: 18
eventually: 18
exchange: 18
failed: 18
feb: 18
fiber: 18
foreground: 18
generation: 18
get: 18
gigabit: 18
heavy: 18
history: 18
identify: 18
includes: 18
initial: 18
itself: 18
known: 18
lambda: 18
latencies: 18
logging: 18
moreover: 18
nash: 18
neither: 18
noted: 18
participating: 18
propose: 18
publish: 18
queries: 18
repositories: 18
roundtrip: 18
sigcomm: 18
specific: 18
study: 18
subversion: 18
summary: 18
switching: 18
synthetic: 18
tokens: 18
topics: 18
unique: 18
varied: 18
various: 18
vary: 18
actual: 17
automatically: 17
chosen: 17
coda: 17
communications: 17
developer: 17
device: 17
devices: 17
don: 17
early: 17
enabled: 17
environments: 17
errors: 17
experience: 17
focus: 17
fraction: 17
functionality: 17
grows: 17
highest: 17
highly: 17
hosting: 17
ii: 17
impact: 17
implement: 17
infrastructure: 17
lines: 17
maintains: 17
modified: 17
module: 17
necessary: 17
offer: 17
partitioning: 17
periodically: 17
products: 17
progress: 17
projects: 17
ran: 17
raps: 17
reach: 17
remain: 17
setting: 17
sharing: 17
simultaneous: 17
specifically: 17
standards: 17
subservice: 17
successfully: 17
supported: 17
switch: 17
symmetric: 17
term: 17
transmitted: 17
van: 17
variety: 17
years: 17
acts: 16
already: 16
axis: 16
believe: 16
buffer: 16
bytes: 16
call: 16
chainsaw: 16
clustering: 16
compare: 16
configured: 16
conflicts: 16
connectivity: 16
contents: 16
conventional: 16
created: 16
define: 16
demonstrate: 16
difference: 16
efficacy: 16
examples: 16
fees: 16
few: 16
ghash: 16
go: 16
hard: 16
illustrated: 16
implications: 16
indeed: 16
infiltrate: 16
integration: 16
io: 16
kinds: 16
lead: 16
limiting: 16
linux: 16
little: 16
main: 16
market: 16
measurements: 16
modes: 16
operate: 16
options: 16
page: 16
parallel: 16
physical: 16
points: 16
prisoner: 16
publishes: 16
registered: 16
requirements: 16
serialization: 16
simulation: 16
simultaneously: 16
status: 16
strong: 16
sub: 16
subsystem: 16
themselves: 16
timestamp: 16
topic: 16
transparently: 16
typical: 16
accessing: 15
adapt: 15
applied: 15
arrive: 15
atp: 15
attempt: 15
bar: 15
bc: 15
comparison: 15
containing: 15
contribute: 15
corba: 15
department: 15
describes: 15
diff: 15
edge: 15
effects: 15
exists: 15
fire: 15
gc: 15
greater: 15
idle: 15
included: 15
infiltrated: 15
info: 15
june: 15
latter: 15
linear: 15
maintaining: 15
namely: 15
november: 15
oms: 15
optimize: 15
outgoing: 15
paths: 15
performing: 15
practice: 15
predictable: 15
programming: 15
regions: 15
regular: 15
renesse: 15
represents: 15
respond: 15
sense: 15
sirer: 15
slightly: 15
slow: 15
statistics: 15
stores: 15
supercomputing: 15
teragrid: 15
thousands: 15
tier: 15
underlying: 15
uniformly: 15
whole: 15
accept: 14
addition: 14
arise: 14
balancing: 14
bounded: 14
channels: 14
class: 14
combined: 14
commits: 14
conclusion: 14
concurrency: 14
currency: 14
decrease: 14
deliver: 14
destination: 14
detects: 14
differentiated: 14
directory: 14
dissemination: 14
distinct: 14
drops: 14
engineering: 14
entries: 14
exactly: 14
explore: 14
fail: 14
fifo: 14
financial: 14
finding: 14
growing: 14
guarantees: 14
handling: 14
help: 14
improves: 14
infiltrators: 14
integrated: 14
interested: 14
involves: 14
malicious: 14
modern: 14
option: 14
perfect: 14
policies: 14
prevent: 14
previously: 14
prior: 14
program: 14
providing: 14
published: 14
question: 14
relatively: 14
sabotage: 14
search: 14
singleton: 14
soon: 14
spread: 14
starting: 14
temporarily: 14
thread: 14
tolerate: 14
turn: 14
useful: 14
xj: 14
zookeeper: 14
achieved: 13
add: 13
afs: 13
annual: 13
avg: 13
balance: 13
bound: 13
collaborative: 13
collect: 13
compile: 13
completely: 13
computation: 13
concurrent: 13
consisting: 13
constraints: 13
decreases: 13
depends: 13
determine: 13
determined: 13
did: 13
digests: 13
discarded: 13
dominant: 13
dynamically: 13
embedded: 13
epidemic: 13
exception: 13
eyal: 13
face: 13
far: 13
field: 13
free: 13
frequently: 13
fundamental: 13
generating: 13
gives: 13
grained: 13
growth: 13
his: 13
hit: 13
instances: 13
intended: 13
interactive: 13
interval: 13
intervals: 13
introduction: 13
join: 13
lack: 13
location: 13
magnitude: 13
measure: 13
mentioned: 13
missed: 13
modeless: 13
nfm: 13
normal: 13
notice: 13
ntfs: 13
overview: 13
paradigm: 13
positive: 13
proportional: 13
provided: 13
public: 13
radient: 13
receipt: 13
registers: 13
relevant: 13
remains: 13
researchers: 13
robust: 13
rtt: 13
semantics: 13
setup: 13
shares: 13
situations: 13
special: 13
static: 13
structures: 13
subscribe: 13
thousand: 13
tool: 13
track: 13
trade: 13
tree: 13
unbounded: 13
written: 13
aborted: 12
academic: 12
acceptable: 12
account: 12
accurate: 12
balakrishnan: 12
base: 12
below: 12
ca: 12
capable: 12
caused: 12
challenges: 12
classes: 12
conclude: 12
copies: 12
creating: 12
cumulative: 12
date: 12
decentralized: 12
decide: 12
dedicated: 12
definition: 12
delayed: 12
despite: 12
efficiency: 12
element: 12
enterprise: 12
facts: 12
fairly: 12
footprint: 12
generally: 12
half: 12
hashcash: 12
html: 12
ing: 12
interactions: 12
introduced: 12
iv: 12
ix: 12
jan: 12
java: 12
keep: 12
leads: 12
lfs: 12
li: 12
limitations: 12
locking: 12
maintained: 12
near: 12
obtained: 12
opportunity: 12
oracle: 12
ordering: 12
orders: 12
otherwise: 12
overlap: 12
particularly: 12
past: 12
practical: 12
primary: 12
purposes: 12
push: 12
reason: 12
recently: 12
redundant: 12
rescue: 12
review: 12
roles: 12
roughly: 12
sort: 12
specify: 12
spikes: 12
stack: 12
subset: 12
taking: 12
technique: 12
ten: 12
tms: 12
unif: 12
whenever: 12
you: 12
achieving: 11
acknowledgments: 11
activity: 11
advance: 11
aggregated: 11
argue: 11
authors: 11
automated: 11
basis: 11
begin: 11
callback: 11
complex: 11
converge: 11
crash: 11
deal: 11
deployed: 11
detail: 11
details: 11
detecting: 11
discussion: 11
energy: 11
ensures: 11
equivalent: 11
evict: 11
fa: 11
fee: 11
fetches: 11
fetching: 11
finds: 11
flexible: 11
focused: 11
heterogeneous: 11
hot: 11
hundreds: 11
identifiers: 11
illustrates: 11
implementing: 11
improvements: 11
incorporates: 11
increasingly: 11
indicate: 11
insufficient: 11
interact: 11
introduce: 11
involved: 11
ithaca: 11
largest: 11
layout: 11
linearly: 11
logged: 11
maintenance: 11
measurement: 11
metadata: 11
modal: 11
moving: 11
name: 11
orkut: 11
osdi: 11
pair: 11
parameter: 11
partitioned: 11
prefetches: 11
privacy: 11
processed: 11
prove: 11
providers: 11
randomly: 11
readers: 11
realistic: 11
recovers: 11
replace: 11
replicas: 11
requiring: 11
responsible: 11
retransmission: 11
role: 11
routine: 11
sample: 11
scheduling: 11
sensitive: 11
sep: 11
separate: 11
serve: 11
simplicity: 11
stock: 11
strictly: 11
subsequent: 11
supporting: 11
supports: 11
true: 11
trusted: 11
try: 11
unlikely: 11
unshared: 11
valid: 11
ve: 11
white: 11
whose: 11
xml: 11
accuracy: 10
ack: 10
additionally: 10
along: 10
appear: 10
arg: 10
assumption: 10
asynchronously: 10
becoming: 10
bitcoins: 10
bottleneck: 10
cc: 10
cdn: 10
check: 10
checks: 10
compares: 10
conflict: 10
constructed: 10
continuous: 10
dec: 10
decision: 10
decisions: 10
degenerate: 10
degree: 10
depend: 10
desired: 10
detailed: 10
discussed: 10
distinguish: 10
distributes: 10
effectively: 10
efforts: 10
elements: 10
enable: 10
enhancing: 10
epidemics: 10
especially: 10
evaluated: 10
eventual: 10
examine: 10
expensive: 10
experienced: 10
fairness: 10
false: 10
final: 10
fine: 10
forms: 10
give: 10
gracefully: 10
ideal: 10
improving: 10
infiltrates: 10
injected: 10
ipc: 10
isn: 10
journal: 10
language: 10
leverage: 10
map: 10
maps: 10
mesh: 10
methods: 10
microbenchmarks: 10
minutes: 10
miss: 10
networked: 10
nevertheless: 10
news: 10
novel: 10
overlapping: 10
paxos: 10
pending: 10
possibility: 10
presented: 10
presents: 10
proceed: 10
pushing: 10
rapid: 10
really: 10
recall: 10
remainder: 10
reported: 10
reports: 10
representing: 10
rest: 10
return: 10
rise: 10
robbert: 10
router: 10
routes: 10
routing: 10
runtime: 10
sampling: 10
scales: 10
segment: 10
situation: 10
studies: 10
subject: 10
success: 10
synchrony: 10
tail: 10
team: 10
technical: 10
tests: 10
theorem: 10
think: 10
thresholds: 10
throughout: 10
tion: 10
transparent: 10
unlike: 10
unstable: 10
usually: 10
utility: 10
variant: 10
visible: 10
volume: 10
widely: 10
zone: 10
achieves: 9
advantages: 9
alarm: 9
allowed: 9
appliances: 9
apply: 9
assigned: 9
assigns: 9
assumed: 9
attackers: 9
august: 9
behave: 9
beneficial: 9
break: 9
causing: 9
central: 9
changed: 9
co: 9
commercial: 9
companies: 9
comparing: 9
competing: 9
compute: 9
computers: 9
confidence: 9
connections: 9
continue: 9
curves: 9
daily: 9
default: 9
degradation: 9
depending: 9
deterministic: 9
developing: 9
dirty: 9
discards: 9
disconnected: 9
domain: 9
ec: 9
ee: 9
efficiently: 9
eliminate: 9
en: 9
entirely: 9
execute: 9
explicit: 9
explored: 9
expression: 9
fails: 9
fashion: 9
fd: 9
force: 9
forming: 9
forwarding: 9
frequency: 9
fully: 9
functions: 9
grant: 9
grow: 9
gw: 9
hide: 9
hierarchy: 9
hold: 9
id: 9
ideally: 9
identifier: 9
importance: 9
incentive: 9
inexpensive: 9
infocom: 9
initially: 9
intel: 9
investigate: 9
iperf: 9
iterative: 9
john: 9
kept: 9
knows: 9
leaving: 9
loads: 9
lose: 9
lossless: 9
lowest: 9
maximize: 9
media: 9
merlin: 9
middle: 9
middleware: 9
minor: 9
modifications: 9
modify: 9
modules: 9
nsdi: 9
owner: 9
pattern: 9
permutation: 9
places: 9
plan: 9
profitable: 9
programmer: 9
prone: 9
proportion: 9
quite: 9
reached: 9
reading: 9
records: 9
reflect: 9
respect: 9
retry: 9
ricochet: 9
rings: 9
risk: 9
rounds: 9
rw: 9
sampled: 9
sd: 9
sec: 9
segments: 9
selected: 9
self: 9
session: 9
shall: 9
showing: 9
sigmod: 9
sosp: 9
specialized: 9
steps: 9
susceptible: 9
terms: 9
threads: 9
tolerant: 9
topology: 9
transfers: 9
transformation: 9
transitions: 9
transmitting: 9
trip: 9
ttl: 9
unacknowledged: 9
unless: 9
upcall: 9
vi: 9
viii: 9
want: 9
werner: 9
academia: 8
accordingly: 8
activities: 8
adds: 8
advantage: 8
affect: 8
affects: 8
afrl: 8
aggregates: 8
allocation: 8
amounts: 8
api: 8
arbitrary: 8
arrays: 8
arxiv: 8
aspects: 8
attributes: 8
auditor: 8
automatic: 8
away: 8
backup: 8
behind: 8
beyond: 8
breaks: 8
buffered: 8
byte: 8
cbcb: 8
challenge: 8
charge: 8
checking: 8
clock: 8
collected: 8
combine: 8
come: 8
competition: 8
compromised: 8
concurrently: 8
confirm: 8
congested: 8
connecting: 8
consecutive: 8
contributing: 8
coordinator: 8
corresponds: 8
creates: 8
currencies: 8
dark: 8
david: 8
de: 8
degrades: 8
densities: 8
deploy: 8
deployment: 8
detectors: 8
differs: 8
dogecoin: 8
drag: 8
driven: 8
earns: 8
eligius: 8
employed: 8
engage: 8
equations: 8
equipment: 8
essentially: 8
ever: 8
exact: 8
executed: 8
exist: 8
extensions: 8
external: 8
extreme: 8
favor: 8
filesystem: 8
gib: 8
greatly: 8
header: 8
histograms: 8
honestly: 8
ideas: 8
improvement: 8
input: 8
insight: 8
interaction: 8
jgroups: 8
largely: 8
leader: 8
leading: 8
leave: 8
lemma: 8
light: 8
limits: 8
litecoin: 8
look: 8
mashups: 8
masks: 8
massive: 8
match: 8
max: 8
mc: 8
measuring: 8
method: 8
minimize: 8
misbehaving: 8
mixed: 8
modeled: 8
models: 8
modification: 8
move: 8
neighbor: 8
nominal: 8
nor: 8
notification: 8
notifications: 8
oct: 8
offers: 8
ordered: 8
papers: 8
participation: 8
payoff: 8
perhaps: 8
perturbed: 8
placed: 8
played: 8
plot: 8
portion: 8
prioritised: 8
purpose: 8
put: 8
react: 8
recovering: 8
refer: 8
refrain: 8
replaced: 8
reservation: 8
reservations: 8
retransmissions: 8
returned: 8
reward: 8
robin: 8
sdn: 8
sections: 8
senders: 8
september: 8
series: 8
serves: 8
similarly: 8
simulate: 8
sink: 8
sm: 8
solve: 8
sometimes: 8
span: 8
specification: 8
specified: 8
stacks: 8
staggered: 8
stepwise: 8
strict: 8
subsequently: 8
substituting: 8
suitable: 8
surprisingly: 8
timer: 8
turns: 8
twice: 8
unusable: 8
verify: 8
views: 8
wang: 8
weak: 8
weather: 8
weekly: 8
wiki: 8
ws: 8
xc: 8
aborting: 7
abstraction: 7
acceptors: 7
acknowledged: 7
air: 7
apache: 7
applying: 7
architectural: 7
arises: 7
array: 7
attractive: 7
belongs: 7
big: 7
broadcast: 7
bsd: 7
byzantine: 7
calculate: 7
card: 7
causes: 7
cb: 7
characteristics: 7
cisco: 7
claim: 7
cleaning: 7
cleanup: 7
clearly: 7
closer: 7
collapse: 7
communities: 7
completion: 7
complexity: 7
concept: 7
conflicting: 7
connection: 7
considering: 7
consistently: 7
construct: 7
contemporary: 7
contributions: 7
cooperative: 7
counter: 7
creation: 7
dashed: 7
december: 7
decoupling: 7
degraded: 7
delaying: 7
demers: 7
deploying: 7
dept: 7
derived: 7
designs: 7
deter: 7
determining: 7
display: 7
disrupt: 7
doesn: 7
doing: 7
dolev: 7
downstream: 7
easier: 7
elapsed: 7
electronic: 7
eliminated: 7
eliminates: 7
employs: 7
empty: 7
emulab: 7
enabling: 7
equally: 7
everything: 7
exchanges: 7
experiences: 7
exploit: 7
exponential: 7
extend: 7
feature: 7
feedback: 7
feeds: 7
fires: 7
fit: 7
follow: 7
furthermore: 7
gaining: 7
gray: 7
guarantee: 7
handles: 7
hour: 7
huge: 7
ignored: 7
image: 7
implementations: 7
importantly: 7
incoherent: 7
incorporate: 7
inferior: 7
introduces: 7
inventory: 7
isis: 7
isolation: 7
january: 7
joseph: 7
keys: 7
latest: 7
lbfs: 7
located: 7
locations: 7
ma: 7
mahesh: 7
mapping: 7
mica: 7
mines: 7
ml: 7
mod: 7
modeling: 7
modifying: 7
motivation: 7
multicasts: 7
nature: 7
negligible: 7
nothing: 7
nsf: 7
oblivious: 7
observation: 7
obvious: 7
october: 7
operator: 7
optimistic: 7
overloaded: 7
partitions: 7
percentile: 7
persistent: 7
plus: 7
poorly: 7
population: 7
pre: 7
prefer: 7
press: 7
prime: 7
programs: 7
propagated: 7
prototype: 7
publishing: 7
rack: 7
rarely: 7
rc: 7
reaches: 7
record: 7
reflects: 7
regarding: 7
register: 7
regularly: 7
relaying: 7
rely: 7
repeated: 7
represent: 7
represented: 7
requesting: 7
resistant: 7
restart: 7
retailer: 7
retrieve: 7
rich: 7
route: 7
routers: 7
san: 7
savings: 7
scaling: 7
seamlessly: 7
seek: 7
sharply: 7
she: 7
simplify: 7
simulations: 7
simulator: 7
sites: 7
socket: 7
sockets: 7
springer: 7
stop: 7
storing: 7
subservices: 7
substantially: 7
successful: 7
timeout: 7
tradeoff: 7
trans: 7
transition: 7
transmit: 7
treat: 7
treated: 7
trees: 7
trust: 7
twenty: 7
u: 7
ubiquitous: 7
unaware: 7
unchanged: 7
useless: 7
utilization: 7
validation: 7
variation: 7
vendor: 7
vendors: 7
versus: 7
vii: 7
violating: 7
wan: 7
year: 7
yield: 7
yields: 7
yu: 7
accommodate: 6
achievable: 6
acknowledgement: 6
act: 6
acting: 6
addressed: 6
addresses: 6
adjustment: 6
administrators: 6
affected: 6
afosr: 6
agreement: 6
alternatives: 6
analyzed: 6
apparently: 6
appropriately: 6
argument: 6
arrives: 6
assumptions: 6
atomic: 6
averages: 6
avoids: 6
bars: 6
begins: 6
berkeley: 6
bonneau: 6
bottom: 6
boundaries: 6
broadly: 6
bullet: 6
california: 6
calls: 6
catch: 6
checkpoint: 6
checksum: 6
chen: 6
closely: 6
clouds: 6
clr: 6
coherent: 6
combination: 6
combines: 6
comes: 6
command: 6
comprised: 6
comput: 6
concave: 6
conducted: 6
conjunction: 6
consensus: 6
conservative: 6
considerable: 6
contain: 6
controlled: 6
coordinate: 6
copying: 6
corporation: 6
costly: 6
coupled: 6
crashed: 6
cross: 6
curve: 6
customize: 6
darpa: 6
dates: 6
db: 6
debian: 6
denotes: 6
dependent: 6
deployments: 6
description: 6
detector: 6
determines: 6
develop: 6
digest: 6
discusfish: 6
disjoint: 6
disseminate: 6
divides: 6
document: 6
draw: 6
druschel: 6
durability: 6
earth: 6
ed: 6
effort: 6
egress: 6
eliminating: 6
email: 6
erasure: 6
established: 6
expressions: 6
facebook: 6
feasibility: 6
feed: 6
fifth: 6
fill: 6
focuses: 6
forced: 6
forks: 6
former: 6
foundation: 6
frame: 6
france: 6
gbps: 6
generic: 6
hashing: 6
heartbeat: 6
hidden: 6
histories: 6
hop: 6
huang: 6
imposed: 6
improved: 6
inc: 6
indicates: 6
industry: 6
ingress: 6
intensive: 6
intercepted: 6
intermediate: 6
issued: 6
issuing: 6
kncminer: 6
krzysztof: 6
lacking: 6
lamport: 6
lan: 6
lans: 6
lcm: 6
ledger: 6
loaded: 6
locally: 6
logical: 6
lt: 6
luu: 6
manage: 6
master: 6
matching: 6
maxx: 6
mean: 6
measured: 6
min: 6
mission: 6
modifies: 6
moment: 6
moves: 6
mp: 6
multicasting: 6
my: 6
naturally: 6
nd: 6
nearly: 6
necessarily: 6
noble: 6
nonce: 6
normalizes: 6
notion: 6
numbered: 6
numerical: 6
numerous: 6
occurring: 6
older: 6
operators: 6
optimized: 6
oscillatory: 6
ostrowski: 6
outlined: 6
outperforms: 6
output: 6
overload: 6
pareto: 6
parties: 6
passive: 6
pdf: 6
perfectly: 6
permit: 6
perspective: 6
phase: 6
play: 6
pooled: 6
possibly: 6
powerful: 6
predict: 6
prefix: 6
price: 6
primarily: 6
procedure: 6
produced: 6
publicly: 6
publisher: 6
pulls: 6
punish: 6
questions: 6
queuing: 6
qwest: 6
reachable: 6
red: 6
reduction: 6
redundancy: 6
reject: 6
repeatedly: 6
replay: 6
replicate: 6
resource: 6
resulted: 6
returns: 6
reveals: 6
rewards: 6
rig: 6
ring: 6
rj: 6
rules: 6
samples: 6
satyanarayanan: 6
say: 6
seattle: 6
seems: 6
select: 6
sensitivity: 6
serialized: 6
six: 6
slowly: 6
snapshot: 6
solving: 6
somewhat: 6
sorts: 6
standardized: 6
states: 6
straightforward: 6
stratum: 6
suggested: 6
summarize: 6
sun: 6
super: 6
supplies: 6
switzerland: 6
synchronization: 6
targeted: 6
tat: 6
thank: 6
theory: 6
timeouts: 6
tit: 6
toolkit: 6
tracking: 6
transmits: 6
trigger: 6
trying: 6
txnid: 6
ultimately: 6
understand: 6
unfortunately: 6
unreliable: 6
usability: 6
usable: 6
validate: 6
variability: 6
variations: 6
vast: 6
vector: 6
vldb: 6
welsh: 6
why: 6
withheld: 6
won: 6
workers: 6
worse: 6
xxx: 6
yahoo: 6
zhang: 6
zhu: 6
ability: 5
absence: 5
absolute: 5
acknowledgements: 5
acknowledgment: 5
acl: 5
adapting: 5
adjusting: 5
ago: 5
agree: 5
ahead: 5
allocated: 5
anyone: 5
append: 5
approximate: 5
arbitrarily: 5
arguably: 5
arrival: 5
assuming: 5
atkin: 5
atomicity: 5
attempts: 5
author: 5
avoiding: 5
award: 5
backed: 5
band: 5
behalf: 5
behaves: 5
belong: 5
bit: 5
bits: 5
blocking: 5
brevity: 5
brewer: 5
broken: 5
broker: 5
buildings: 5
bus: 5
calculated: 5
calculates: 5
capture: 5
carry: 5
catches: 5
caught: 5
chains: 5
cheap: 5
cheriton: 5
classified: 5
cloned: 5
collapses: 5
comments: 5
communicate: 5
communicates: 5
compose: 5
concern: 5
concerns: 5
consequence: 5
considerations: 5
constitutes: 5
constrained: 5
consume: 5
consuming: 5
contact: 5
continuously: 5
coolstreaming: 5
cope: 5
count: 5
counts: 5
crashes: 5
credentials: 5
crossing: 5
customers: 5
danny: 5
datagram: 5
day: 5
dealing: 5
defense: 5
demands: 5
demonstrated: 5
denial: 5
denoted: 5
depict: 5
describing: 5
df: 5
dialog: 5
direction: 5
division: 5
dramatic: 5
dsn: 5
edition: 5
eferences: 5
eight: 5
elaborate: 5
elated: 5
embedding: 5
emerging: 5
employing: 5
encourage: 5
encryption: 5
enforce: 5
ephemeral: 5
estimated: 5
ethernet: 5
exceed: 5
except: 5
exhibit: 5
explain: 5
explicitly: 5
exploiting: 5
exploring: 5
expressed: 5
falls: 5
faults: 5
faulty: 5
filtering: 5
firing: 5
flexibility: 5
forces: 5
forwarded: 5
frames: 5
freebsd: 5
frequent: 5
gap: 5
generality: 5
geo: 5
geographical: 5
gigabits: 5
gribble: 5
grid: 5
ground: 5
gu: 5
hacker: 5
health: 5
hierarchical: 5
highperformance: 5
hints: 5
hooks: 5
human: 5
identification: 5
illustrate: 5
imagine: 5
implicit: 5
implies: 5
inaccurate: 5
incorrect: 5
incrementally: 5
incurs: 5
independently: 5
informatik: 5
informatique: 5
innovation: 5
instantly: 5
integrating: 5
interesting: 5
interference: 5
internal: 5
interoperability: 5
invalidate: 5
investigated: 5
investigator: 5
iptv: 5
isps: 5
ittay: 5
johnson: 5
joining: 5
joins: 5
katz: 5
kleinberg: 5
lakshmi: 5
languages: 5
layouts: 5
learn: 5
leases: 5
lengths: 5
lightweight: 5
linking: 5
liu: 5
locality: 5
locks: 5
logic: 5
looking: 5
lossy: 5
mar: 5
marketing: 5
mask: 5
messaging: 5
metrics: 5
minibrowsers: 5
minority: 5
monitors: 5
monthly: 5
moved: 5
mutual: 5
national: 5
normally: 5
ntroduction: 5
observations: 5
obtains: 5
occasional: 5
occurred: 5
offered: 5
omit: 5
omitted: 5
onclusion: 5
onon: 5
optimization: 5
optimizations: 5
optimizes: 5
organization: 5
organizations: 5
organized: 5
originally: 5
orthogonal: 5
outside: 5
overcome: 5
pairs: 5
partially: 5
passed: 5
pause: 5
pay: 5
pays: 5
peerto: 5
people: 5
percentages: 5
permitting: 5
personal: 5
pf: 5
phenomenon: 5
placement: 5
plots: 5
poison: 5
positives: 5
precisely: 5
predictor: 5
predictors: 5
probabilistic: 5
proceeds: 5
progresses: 5
property: 5
proprietary: 5
protected: 5
proved: 5
punished: 5
quick: 5
raise: 5
rare: 5
raw: 5
rd: 5
reaching: 5
regardless: 5
release: 5
reliance: 5
remaining: 5
remove: 5
repairs: 5
repeat: 5
requested: 5
requirement: 5
resilience: 5
resolve: 5
respects: 5
responsiveness: 5
restrictions: 5
reveal: 5
rizzo: 5
road: 5
robustness: 5
satisfactory: 5
satisfied: 5
save: 5
saving: 5
scheduled: 5
schneider: 5
seem: 5
sees: 5
selecting: 5
sensors: 5
separated: 5
separately: 5
sequenced: 5
serializable: 5
sessions: 5
shard: 5
shards: 5
signal: 5
simulated: 5
sized: 5
slack: 5
slower: 5
sophisticated: 5
soule: 5
speculative: 5
sprint: 5
stated: 5
stay: 5
studied: 5
submit: 5
substantial: 5
subsystems: 5
suffer: 5
sum: 5
summarized: 5
suspicion: 5
switched: 5
switches: 5
tech: 5
tell: 5
temporary: 5
texture: 5
thinking: 5
tightly: 5
timely: 5
timestamps: 5
tocs: 5
topologies: 5
tracks: 5
transform: 5
transformations: 5
trap: 5
treating: 5
trend: 5
trends: 5
triggers: 5
tune: 5
tuning: 5
turned: 5
unable: 5
unexpected: 5
unit: 5
unpredictable: 5
untrusted: 5
updating: 5
upper: 5
ut: 5
utilisation: 5
verifying: 5
viewed: 5
volatile: 5
vs: 5
waiting: 5
walk: 5
wall: 5
wants: 5
win: 5
wired: 5
writers: 5
ycsb: 5
yx: 5
ab: 4
abbadi: 4
ac: 4
accepted: 4
acks: 4
action: 4
actions: 4
adopted: 4
advanced: 4
advances: 4
agrawal: 4
alone: 4
alongside: 4
alternate: 4
alvisi: 4
amir: 4
amortizable: 4
analogous: 4
andrew: 4
answer: 4
antpool: 4
applicable: 4
approximated: 4
april: 4
archive: 4
arrow: 4
aspect: 4
assign: 4
assumes: 4
athey: 4
awkward: 4
bahack: 4
ballots: 4
banking: 4
behaviour: 4
benchmark: 4
bernstein: 4
biersack: 4
bifurcations: 4
bitcointalk: 4
blade: 4
blast: 4
blend: 4
blocked: 4
blogspot: 4
border: 4
boxes: 4
brief: 4
briefly: 4
broadcasts: 4
broader: 4
bulk: 4
burstier: 4
calculator: 4
callbacks: 4
caller: 4
capitalization: 4
captures: 4
carefully: 4
certainly: 4
charts: 4
chat: 4
city: 4
clean: 4
clones: 4
closes: 4
cms: 4
collecting: 4
collector: 4
combining: 4
coming: 4
comparable: 4
compensated: 4
compiles: 4
completed: 4
complicated: 4
componentized: 4
composition: 4
comprehensive: 4
compromise: 4
conduct: 4
confirms: 4
consequences: 4
consist: 4
contained: 4
continued: 4
converges: 4
cooperation: 4
correlated: 4
correlation: 4
courtois: 4
crucial: 4
cryptography: 4
cutting: 4
cycle: 4
danger: 4
das: 4
debugging: 4
decades: 4
decided: 4
declining: 4
deep: 4
deferred: 4
defines: 4
demonstrates: 4
desktop: 4
devastating: 4
di: 4
differences: 4
differentiate: 4
differently: 4
directed: 4
directions: 4
directories: 4
disaster: 4
discovery: 4
discussions: 4
disloyal: 4
disrupted: 4
disruption: 4
distant: 4
distribute: 4
distributions: 4
double: 4
ease: 4
ebay: 4
economic: 4
editor: 4
educause: 4
elsewhere: 4
emin: 4
emulate: 4
encoder: 4
encodes: 4
endhosts: 4
enforcing: 4
engages: 4
engineer: 4
enhanced: 4
enormous: 4
enter: 4
envelope: 4
epi: 4
eprint: 4
esb: 4
evenly: 4
evicting: 4
evidence: 4
evil: 4
ex: 4
examines: 4
exchanged: 4
exclusive: 4
executing: 4
existence: 4
export: 4
exposed: 4
extensive: 4
faber: 4
faced: 4
familiar: 4
february: 4
filter: 4
firewalls: 4
five: 4
fixing: 4
flowing: 4
flush: 4
flushes: 4
focusing: 4
followed: 4
formula: 4
foster: 4
fourth: 4
fragmentation: 4
francis: 4
francisco: 4
freedman: 4
friendly: 4
gain: 4
games: 4
gateways: 4
gathered: 4
gets: 4
globally: 4
goes: 4
going: 4
graceful: 4
grants: 4
grateful: 4
grossklags: 4
hackingdistributed: 4
hakim: 4
heartbeats: 4
heavily: 4
helps: 4
hint: 4
holds: 4
home: 4
honeypot: 4
hope: 4
horus: 4
hweather: 4
identified: 4
identifying: 4
identity: 4
ids: 4
ignore: 4
images: 4
impacted: 4
impossible: 4
inaccessible: 4
incorporating: 4
incurred: 4
incurring: 4
inform: 4
initiated: 4
initiative: 4
inquiry: 4
integral: 4
integrate: 4
intelligent: 4
intend: 4
interacts: 4
interrupted: 4
intervening: 4
intrinsically: 4
introducing: 4
invalidated: 4
invalidating: 4
isbn: 4
javascript: 4
jboss: 4
jelasity: 4
joint: 4
jose: 4
july: 4
jumbo: 4
jxta: 4
kaashoek: 4
keeping: 4
keidar: 4
kermarrec: 4
kj: 4
korn: 4
lacks: 4
lakshman: 4
laszka: 4
leaders: 4
learning: 4
leaves: 4
letting: 4
leveraging: 4
libraries: 4
lies: 4
listed: 4
lived: 4
ll: 4
logsim: 4
longdistance: 4
looked: 4
lru: 4
maid: 4
malfunctioning: 4
managing: 4
marked: 4
matched: 4
matrix: 4
maximizes: 4
measures: 4
merely: 4
methodology: 4
miles: 4
military: 4
miller: 4
mind: 4
minimal: 4
minted: 4
minute: 4
misconfigured: 4
misses: 4
mix: 4
mixture: 4
mobility: 4
modulating: 4
monitor: 4
monopoly: 4
moore: 4
msg: 4
mtus: 4
naive: 4
nak: 4
namecoin: 4
narrow: 4
netfilter: 4
normalized: 4
notable: 4
notify: 4
numerically: 4
obstacles: 4
obtaining: 4
offering: 4
ools: 4
operates: 4
optimum: 4
organofcorti: 4
ork: 4
outstanding: 4
owners: 4
ownership: 4
packages: 4
parameterized: 4
participate: 4
parts: 4
patient: 4
paul: 4
payments: 4
payout: 4
payouts: 4
peak: 4
penalty: 4
peps: 4
periodic: 4
permacoin: 4
permutations: 4
person: 4
perspectives: 4
pfldnet: 4
phenomena: 4
php: 4
pi: 4
picked: 4
pictures: 4
placing: 4
player: 4
plotting: 4
podc: 4
poll: 4
polling: 4
positions: 4
practicality: 4
predicted: 4
preferred: 4
preprint: 4
pressure: 4
prevents: 4
pricing: 4
primitives: 4
principle: 4
probabilities: 4
probably: 4
prominent: 4
promising: 4
protect: 4
provisioned: 4
provisioning: 4
pub: 4
publication: 4
pulled: 4
purely: 4
qi: 4
qp: 4
quantities: 4
quantum: 4
querying: 4
readset: 4
reality: 4
realize: 4
reasonable: 4
reference: 4
reflected: 4
regional: 4
rejoin: 4
relation: 4
relations: 4
reliably: 4
removed: 4
reno: 4
repairing: 4
replacement: 4
replicating: 4
repo: 4
reserved: 4
residing: 4
resilient: 4
resolution: 4
resolved: 4
responding: 4
responses: 4
retailers: 4
retransmit: 4
rev: 4
revoke: 4
rigs: 4
rk: 4
robert: 4
root: 4
rosenfeld: 4
routed: 4
rover: 4
rowstron: 4
rule: 4
safety: 4
saturate: 4
saw: 4
scan: 4
secondary: 4
secret: 4
secure: 4
secured: 4
seeks: 4
selective: 4
selfish: 4
separates: 4
sequences: 4
sequentially: 4
sha: 4
shasha: 4
shenker: 4
shift: 4
shut: 4
silver: 4
situational: 4
sixteenth: 4
smalltalk: 4
smart: 4
smr: 4
sold: 4
spanning: 4
spun: 4
srm: 4
standardization: 4
statistically: 4
steadily: 4
steady: 4
stress: 4
stronger: 4
strongly: 4
students: 4
subjected: 4
subsection: 4
successes: 4
suffers: 4
sums: 4
suspected: 4
symmetry: 4
synchronized: 4
tackle: 4
tailored: 4
technological: 4
tens: 4
terminology: 4
terrain: 4
terry: 4
tested: 4
theoretic: 4
things: 4
threaded: 4
took: 4
tornado: 4
touched: 4
towsley: 4
traced: 4
tradeoffs: 4
trading: 4
translate: 4
travel: 4
treats: 4
tremendous: 4
trial: 4
truly: 4
tuple: 4
understanding: 4
undesirable: 4
units: 4
unknown: 4
unusual: 4
upstream: 4
usd: 4
usual: 4
utilities: 4
vahdat: 4
valuable: 4
variable: 4
variants: 4
varies: 4
vfs: 4
viable: 4
vice: 4
visual: 4
von: 4
vulnerable: 4
waits: 4
walsh: 4
washington: 4
weakly: 4
weatherspoon: 4
weight: 4
wish: 4
withhold: 4
worked: 4
worst: 4
worth: 4
writeset: 4
wrong: 4
xk: 4
xkj: 4
yearly: 4
your: 4
abadi: 3
aborts: 3
accepting: 3
accepts: 3
accountable: 3
accumulated: 3
accusations: 3
acidrain: 3
acknowledge: 3
acquire: 3
actively: 3
adapts: 3
adequate: 3
adjust: 3
advancing: 3
advantageous: 3
advertisements: 3
afec: 3
affecting: 3
aggregating: 3
agnostic: 3
aguilera: 3
aimed: 3
aircraft: 3
alan: 3
albeit: 3
alberta: 3
album: 3
alert: 3
alerts: 3
alleviate: 3
amenable: 3
analytical: 3
analytically: 3
anomaly: 3
anything: 3
app: 3
apparent: 3
appears: 3
ar: 3
areas: 3
aren: 3
argued: 3
arising: 3
arla: 3
assertion: 3
assess: 3
assigning: 3
assignment: 3
association: 3
assure: 3
attribute: 3
auditable: 3
aug: 3
authorization: 3
avatars: 3
avoided: 3
backbone: 3
balancer: 3
baltimore: 3
banks: 3
bases: 3
basically: 3
batch: 3
bayou: 3
beginning: 3
bianchini: 3
black: 3
boards: 3
bone: 3
boston: 3
boures: 3
breaking: 3
bring: 3
browser: 3
builds: 3
busy: 3
calling: 3
cambridge: 3
camera: 3
cap: 3
care: 3
carries: 3
categories: 3
chandra: 3
characteristic: 3
checked: 3
children: 3
chronous: 3
chubby: 3
churn: 3
circumvent: 3
claims: 3
clement: 3
closing: 3
colleagues: 3
colorado: 3
column: 3
combinations: 3
commands: 3
commerce: 3
commonly: 3
commun: 3
communicating: 3
company: 3
compatible: 3
compete: 3
competitive: 3
compilers: 3
compiling: 3
completes: 3
composed: 3
compound: 3
comprises: 3
compulsory: 3
computational: 3
computed: 3
con: 3
conceived: 3
concentrate: 3
concluded: 3
conclusions: 3
condition: 3
configurable: 3
confirmed: 3
conservation: 3
conserve: 3
consideration: 3
constructing: 3
construction: 3
consumed: 3
consumes: 3
continues: 3
convinced: 3
convoy: 3
cooperate: 3
coordinates: 3
coordination: 3
copper: 3
corbett: 3
corfu: 3
corporate: 3
correcting: 3
correctness: 3
correlate: 3
criterion: 3
culler: 3
culprit: 3
cumulus: 3
curious: 3
custer: 3
custom: 3
customer: 3
customized: 3
cycles: 3
dahlin: 3
dangers: 3
davis: 3
ddos: 3
deadline: 3
deadlines: 3
deals: 3
decade: 3
deciding: 3
decker: 3
decreasing: 3
deering: 3
degrade: 3
demonstrating: 3
dependable: 3
designers: 3
desire: 3
determinism: 3
deviation: 3
dialogue: 3
differentiation: 3
dis: 3
discover: 3
discrepancy: 3
disruptions: 3
disruptive: 3
disseminated: 3
distributing: 3
dns: 3
documentation: 3
documents: 3
dollars: 3
dominated: 3
dos: 3
drawn: 3
driver: 3
dropping: 3
drpm: 3
dying: 3
economics: 3
eded: 3
edward: 3
eicken: 3
el: 3
elastic: 3
elastras: 3
election: 3
electrical: 3
elegant: 3
else: 3
emergence: 3
emotional: 3
empire: 3
encodings: 3
encouraging: 3
ending: 3
endpoint: 3
endto: 3
enhances: 3
ensuring: 3
enterprises: 3
entities: 3
entity: 3
essay: 3
essential: 3
evaluates: 3
evaluating: 3
eventing: 3
evident: 3
evolution: 3
evolved: 3
exacerbates: 3
excellent: 3
excluding: 3
executes: 3
expands: 3
expelled: 3
experimentally: 3
experimented: 3
expires: 3
explorer: 3
exposes: 3
extends: 3
extension: 3
extent: 3
extra: 3
extracted: 3
fascinating: 3
fewer: 3
fg: 3
fields: 3
fifteenth: 3
finite: 3
firm: 3
flash: 3
flat: 3
fledged: 3
flight: 3
folder: 3
folders: 3
forest: 3
format: 3
formation: 3
franklin: 3
freeloaders: 3
french: 3
friend: 3
fs: 3
ganesh: 3
gargamel: 3
gather: 3
geographically: 3
gf: 3
gfgf: 3
goals: 3
gossiped: 3
government: 3
gps: 3
graphically: 3
great: 3
greatest: 3
grids: 3
grossman: 3
gt: 3
guaranteed: 3
gui: 3
gummadi: 3
guo: 3
gurumurthi: 3
hall: 3
handlers: 3
handley: 3
happen: 3
happy: 3
hauser: 3
haven: 3
heap: 3
helland: 3
helping: 3
hibernator: 3
hierarchically: 3
hierarchies: 3
highspeed: 3
homogeneous: 3
howard: 3
hypothesis: 3
ibm: 3
icdcs: 3
ics: 3
ignores: 3
ignoring: 3
il: 3
immersed: 3
implicitly: 3
impose: 3
imposes: 3
incentives: 3
income: 3
incorporated: 3
incorrectly: 3
incremental: 3
incremented: 3
incur: 3
indiana: 3
indicating: 3
informed: 3
inherits: 3
initiate: 3
innovations: 3
inside: 3
insights: 3
instability: 3
instantaneous: 3
institute: 3
intent: 3
interacting: 3
intercept: 3
intercepting: 3
intercepts: 3
interconnect: 3
interconnected: 3
internals: 3
internetworks: 3
interplay: 3
intervene: 3
inversion: 3
irregular: 3
iteration: 3
jbosscache: 3
jim: 3
jitter: 3
keeps: 3
kenneth: 3
knowing: 3
kuenning: 3
landscape: 3
laptops: 3
larson: 3
late: 3
lateral: 3
lesson: 3
linkage: 3
linked: 3
lions: 3
lloyd: 3
logically: 3
london: 3
looks: 3
loop: 3
losing: 3
lot: 3
luby: 3
mainframe: 3
mainsoft: 3
mainwin: 3
malkhi: 3
malo: 3
managers: 3
marian: 3
markets: 3
marks: 3
mashed: 3
matter: 3
mazie: 3
mckusick: 3
meanwhile: 3
memcached: 3
michael: 3
microbenchmark: 3
mid: 3
migration: 3
minimizing: 3
mirror: 3
mitigate: 3
modular: 3
montresor: 3
motivated: 3
motivates: 3
mountain: 3
movies: 3
multithreaded: 3
nat: 3
native: 3
neighborhood: 3
ninja: 3
nonetheless: 3
noticeable: 3
null: 3
observing: 3
obstruction: 3
occasionally: 3
odel: 3
oneway: 3
onto: 3
opened: 3
operational: 3
opposed: 3
optimizing: 3
optionally: 3
organize: 3
orientation: 3
ousterhout: 3
outbound: 3
outdated: 3
overflows: 3
overlapped: 3
overloads: 3
overwhelmed: 3
pacific: 3
padhye: 3
pai: 3
paid: 3
parameterize: 3
participant: 3
passing: 3
paying: 3
payload: 3
pc: 3
pedone: 3
penalties: 3
perceived: 3
percent: 3
perez: 3
personalities: 3
personalization: 3
pervasive: 3
peter: 3
phone: 3
pinheiro: 3
pisa: 3
players: 3
pleisch: 3
poisson: 3
polls: 3
poor: 3
popek: 3
popularity: 3
portions: 3
pose: 3
posed: 3
positioning: 3
prabhakaran: 3
prebuilt: 3
precedence: 3
predominate: 3
preferentially: 3
prefetched: 3
presentation: 3
preserved: 3
president: 3
preventing: 3
principal: 3
probing: 3
processor: 3
produce: 3
productivity: 3
programmers: 3
promise: 3
propagate: 3
properly: 3
protection: 3
proves: 3
provider: 3
psockets: 3
publishers: 3
punishment: 3
purchases: 3
pushed: 3
putting: 3
qpqp: 3
quanta: 3
queueing: 3
queues: 3
raises: 3
ramp: 3
ranging: 3
rao: 3
raptor: 3
reacting: 3
readonly: 3
realizing: 3
reasoning: 3
recipient: 3
recognize: 3
recommendations: 3
reconstruct: 3
recoveries: 3
reflecting: 3
rejoins: 3
relate: 3
relates: 3
released: 3
releases: 3
remarkably: 3
removing: 3
replaces: 3
replacing: 3
replayed: 3
replica: 3
replies: 3
representation: 3
representative: 3
res: 3
reserve: 3
resort: 3
resp: 3
respective: 3
responds: 3
restarting: 3
restored: 3
restricted: 3
retain: 3
retransmitted: 3
retrieves: 3
revisions: 3
rewarding: 3
rfc: 3
rises: 3
risks: 3
safely: 3
saint: 3
satisfies: 3
satisfy: 3
satisfying: 3
scaled: 3
scene: 3
school: 3
scope: 3
script: 3
semantic: 3
sensor: 3
separation: 3
sequential: 3
served: 3
seventeenth: 3
seventh: 3
severe: 3
sharded: 3
shepherd: 3
showed: 3
sight: 3
simpler: 3
simplest: 3
sinfonia: 3
situated: 3
sixth: 3
sleep: 3
slight: 3
smallest: 3
soft: 3
song: 3
sorrosal: 3
sound: 3
spanner: 3
spare: 3
spatial: 3
specifications: 3
speculatively: 3
splitstream: 3
splitting: 3
sporadic: 3
spot: 3
sprite: 3
sr: 3
ssrn: 3
stability: 3
standardize: 3
started: 3
stays: 3
stems: 3
streamed: 3
struggled: 3
subnet: 3
subscriber: 3
substrate: 3
successive: 3
suddenly: 3
sufficiently: 3
suggests: 3
suite: 3
supplied: 3
surprising: 3
suspicions: 3
symbolic: 3
symbols: 3
synchronously: 3
sys: 3
syst: 3
tables: 3
tacc: 3
tagging: 3
talk: 3
tape: 3
targets: 3
taylor: 3
teams: 3
television: 3
tends: 3
terminating: 3
testing: 3
text: 3
thin: 3
thinks: 3
thirty: 3
thomson: 3
threat: 3
tight: 3
tiled: 3
tolerable: 3
ton: 3
tput: 3
tr: 3
traditionally: 3
train: 3
transferred: 3
transferring: 3
transmissions: 3
triggered: 3
triggering: 3
trivial: 3
trouble: 3
truncation: 3
tsunami: 3
tudor: 3
tudorm: 3
turning: 3
uk: 3
unacceptable: 3
unavailable: 3
unblocks: 3
uncommittable: 3
undetected: 3
unexpectedly: 3
unfairly: 3
unmanaged: 3
unperturbed: 3
unrelated: 3
utah: 3
utilize: 3
uwin: 3
validated: 3
valuation: 3
variables: 3
variance: 3
verified: 3
verlag: 3
viewing: 3
vigfusson: 3
visualization: 3
vt: 3
wake: 3
walli: 3
wanted: 3
warns: 3
watch: 3
wefel: 3
wei: 3
whatever: 3
widespread: 3
winner: 3
wisdom: 3
wobber: 3
worlds: 3
worry: 3
wv: 3
yxyx: 3
zero: 3
zhao: 3
zurich: 3
abandon: 2
abc: 2
abilene: 2
abstractions: 2
academics: 2
acceptance: 2
accessible: 2
accomplished: 2
accordance: 2
accounting: 2
accumulating: 2
accurately: 2
accusation: 2
accused: 2
acquisition: 2
adam: 2
addison: 2
addressing: 2
adjusted: 2
adjusts: 2
administrative: 2
adopt: 2
advancements: 2
advent: 2
adversary: 2
advertises: 2
advice: 2
advocated: 2
aegis: 2
affinity: 2
aforementioned: 2
age: 2
agents: 2
aggregator: 2
aggressive: 2
aict: 2
aim: 2
ajax: 2
akamai: 2
alaska: 2
alberto: 2
albums: 2
alive: 2
alleviating: 2
allocates: 2
allocating: 2
alloscomp: 2
alternatively: 2
altruistic: 2
ame: 2
amortizes: 2
amounting: 2
analyzes: 2
anchorage: 2
anderson: 2
andresen: 2
anomalies: 2
anonymity: 2
anonymously: 2
anti: 2
anticipate: 2
antony: 2
apart: 2
apis: 2
appealing: 2
appeared: 2
appends: 2
applicationindependent: 2
approximately: 2
approximation: 2
approximations: 2
apr: 2
archetypal: 2
argues: 2
arguing: 2
arithmetic: 2
arose: 2
arraystructured: 2
arrived: 2
art: 2
article: 2
articles: 2
asia: 2
asics: 2
asks: 2
asp: 2
aspx: 2
assists: 2
assurance: 2
astonishingly: 2
asynch: 2
atm: 2
attach: 2
attached: 2
attain: 2
attempted: 2
attempting: 2
attestation: 2
attract: 2
attraction: 2
attractiveness: 2
audio: 2
aumann: 2
authentication: 2
automate: 2
autonomous: 2
autotuning: 2
avoidance: 2
ba: 2
baa: 2
babaoglu: 2
bach: 2
backlashed: 2
bailey: 2
baker: 2
ban: 2
barb: 2
barr: 2
barrier: 2
bast: 2
basu: 2
began: 2
behaved: 2
behaving: 2
belonging: 2
benjamin: 2
berlin: 2
bernoulli: 2
besides: 2
bespoke: 2
bhargava: 2
bifurcation: 2
billion: 2
binary: 2
binomial: 2
birrell: 2
bitcoinfoundation: 2
bjornstad: 2
blank: 2
bloomberg: 2
blow: 2
blumenthal: 2
boils: 2
bolton: 2
bonus: 2
borders: 2
box: 2
boycott: 2
bridge: 2
brings: 2
brokerage: 2
bronson: 2
browsers: 2
bruijn: 2
btcguild: 2
btchine: 2
buf: 2
bulpin: 2
burden: 2
burstiness: 2
business: 2
businesses: 2
buterin: 2
butterfly: 2
bypass: 2
caja: 2
calculation: 2
calculations: 2
calvin: 2
came: 2
canada: 2
candidates: 2
canonical: 2
capabilities: 2
carey: 2
carolina: 2
carrera: 2
cash: 2
castro: 2
casual: 2
casually: 2
category: 2
cation: 2
cdns: 2
cease: 2
ceases: 2
ceived: 2
census: 2
centralization: 2
century: 2
certainty: 2
cfm: 2
challenging: 2
chance: 2
characterise: 2
cheaply: 2
checkout: 2
checksums: 2
chemical: 2
chicago: 2
chief: 2
china: 2
chowdhry: 2
cidr: 2
circle: 2
circulate: 2
circulates: 2
circumstances: 2
cited: 2
clark: 2
click: 2
cloudviews: 2
coarse: 2
coexist: 2
coherence: 2
cohort: 2
colarelli: 2
colocated: 2
color: 2
combat: 2
comer: 2
committing: 2
commons: 2
communicated: 2
compelled: 2
compensate: 2
compensation: 2
complement: 2
composing: 2
computes: 2
concentrated: 2
concert: 2
conclusive: 2
confident: 2
confined: 2
connect: 2
cons: 2
considerably: 2
considers: 2
constitute: 2
constraint: 2
contacted: 2
contexts: 2
contract: 2
contradicts: 2
controlling: 2
conversion: 2
converted: 2
converting: 2
cooling: 2
cooper: 2
cording: 2
corner: 2
correspond: 2
countermeasures: 2
counterpart: 2
covered: 2
covering: 2
cox: 2
cpus: 2
credited: 2
credits: 2
cripple: 2
cripples: 2
criticism: 2
croquet: 2
crypto: 2
cryptocurrencies: 2
cryptographic: 2
cryptology: 2
ct: 2
cubic: 2
cypherspace: 2
cz: 2
damage: 2
dan: 2
dangerous: 2
daniel: 2
dast: 2
datasets: 2
datta: 2
days: 2
dbms: 2
dce: 2
dd: 2
deadlocks: 2
dealbook: 2
deceased: 2
decodes: 2
deduce: 2
deeper: 2
deeply: 2
defanti: 2
defects: 2
defer: 2
degradations: 2
degrading: 2
deleting: 2
deliberately: 2
deliberation: 2
delivering: 2
delta: 2
demanding: 2
dentical: 2
dependence: 2
depicted: 2
depicts: 2
deplist: 2
deplistcurr: 2
derive: 2
descriptor: 2
designing: 2
deterministically: 2
deviate: 2
devise: 2
dfreedman: 2
didn: 2
differentiable: 2
diminish: 2
dinosaur: 2
diot: 2
disabled: 2
disadvantage: 2
disadvantages: 2
discount: 2
disincentivize: 2
disrupting: 2
disseminates: 2
dissertation: 2
distances: 2
distinction: 2
diverse: 2
divide: 2
dividing: 2
doi: 2
dok: 2
dominate: 2
dot: 2
dotbit: 2
doubt: 2
downloaded: 2
downloads: 2
downside: 2
drives: 2
driving: 2
dry: 2
ds: 2
dubbed: 2
dugan: 2
dumbbell: 2
duplex: 2
duplicating: 2
dutta: 2
eagerly: 2
earned: 2
earnings: 2
ebling: 2
echo: 2
ecoop: 2
ecosystem: 2
eigenvalue: 2
eighteenth: 2
einar: 2
einstein: 2
elmore: 2
embeddings: 2
emphasis: 2
empirical: 2
enables: 2
encapsulate: 2
encapsulated: 2
encoders: 2
encounter: 2
encountered: 2
encrypted: 2
endhost: 2
ends: 2
ensemble: 2
ent: 2
enters: 2
envision: 2
equate: 2
equilibria: 2
era: 2
ered: 2
esbs: 2
escriva: 2
esign: 2
establishing: 2
estimates: 2
ethereum: 2
ethereumwhitepaper: 2
ets: 2
european: 2
eurosys: 2
ev: 2
eva: 2
eve: 2
eventbased: 2
everyone: 2
eviction: 2
evictions: 2
evolve: 2
exabytes: 2
exceeds: 2
exceptionally: 2
excessively: 2
executions: 2
exerted: 2
exerting: 2
exhibits: 2
expectation: 2
expectations: 2
expedite: 2
explains: 2
explores: 2
exponentially: 2
exports: 2
express: 2
expurging: 2
extensibility: 2
extremes: 2
eyes: 2
facilitate: 2
facto: 2
fair: 2
fall: 2
falling: 2
farms: 2
faulttolerance: 2
featuring: 2
fekete: 2
felser: 2
felten: 2
feng: 2
ferguson: 2
fetched: 2
fills: 2
finer: 2
finished: 2
finishes: 2
fired: 2
firewalling: 2
firoiu: 2
fits: 2
fix: 2
fl: 2
flag: 2
flexibly: 2
fluctuations: 2
fluid: 2
flushed: 2
fold: 2
forbes: 2
forcing: 2
forgo: 2
formats: 2
formulae: 2
forrestv: 2
forth: 2
foundations: 2
fox: 2
fragment: 2
fragments: 2
fraleigh: 2
frameworks: 2
fred: 2
fresh: 2
friction: 2
friedman: 2
friendliness: 2
frobenius: 2
fundamentally: 2
funded: 2
funds: 2
furman: 2
gained: 2
gaps: 2
garbled: 2
gateway: 2
gehrke: 2
generalize: 2
generations: 2
genesis: 2
geometric: 2
ghz: 2
gibbs: 2
gibson: 2
gigabyte: 2
github: 2
glick: 2
globalcrossing: 2
globe: 2
gossiper: 2
gossips: 2
gotten: 2
gr: 2
gradient: 2
gradually: 2
granted: 2
grapevine: 2
grasp: 2
greene: 2
griner: 2
guerraoui: 2
guesses: 2
guessing: 2
gupta: 2
guruprasad: 2
habel: 2
hackers: 2
halfway: 2
halted: 2
handful: 2
hands: 2
happens: 2
harder: 2
harley: 2
harm: 2
hashrate: 2
headers: 2
healthy: 2
heidelberg: 2
height: 2
held: 2
helpful: 2
hereinafter: 2
heterogenous: 2
hey: 2
hibler: 2
hiccups: 2
hides: 2
highlight: 2
highvalue: 2
hinder: 2
histogram: 2
hits: 2
hoarding: 2
hobor: 2
holy: 2
homepage: 2
honesty: 2
honeyman: 2
hops: 2
hotcloud: 2
huitema: 2
hundred: 2
hungry: 2
hurdle: 2
hurwitz: 2
huston: 2
iacr: 2
ic: 2
iciw: 2
icmp: 2
identities: 2
idit: 2
ie: 2
ifip: 2
ih: 2
ij: 2
ill: 2
illinois: 2
im: 2
imagined: 2
immaterial: 2
immediate: 2
immersion: 2
imperatives: 2
imperfect: 2
imply: 2
imposing: 2
impractical: 2
impulse: 2
incorporation: 2
indices: 2
indirection: 2
inefficiency: 2
inefficient: 2
infer: 2
influence: 2
influenced: 2
infrastructures: 2
ingrid: 2
ings: 2
inherent: 2
ining: 2
initialized: 2
initiates: 2
injecting: 2
insertion: 2
inspect: 2
install: 2
installed: 2
instantiated: 2
institutions: 2
instruction: 2
instructs: 2
integer: 2
intentionally: 2
interconnecting: 2
interconnection: 2
interconnects: 2
interix: 2
intermediary: 2
interpret: 2
intersection: 2
intervention: 2
intimate: 2
intricacies: 2
invalid: 2
investment: 2
invoke: 2
invokes: 2
ipdps: 2
iptps: 2
irish: 2
iscussion: 2
island: 2
italy: 2
itcoin: 2
ith: 2
ity: 2
izs: 2
james: 2
javabeans: 2
jimenez: 2
joglekar: 2
jonsson: 2
jsp: 2
juels: 2
justify: 2
kandemir: 2
kansas: 2
kapritsos: 2
karlsson: 2
katabi: 2
kazar: 2
kemme: 2
keycurr: 2
kharif: 2
kiawah: 2
kilper: 2
kim: 2
kimsas: 2
kjkj: 2
knob: 2
knobs: 2
kojo: 2
kroll: 2
krzys: 2
kurose: 2
labelled: 2
labs: 2
lagged: 2
lagging: 2
lake: 2
lambdarail: 2
lambdas: 2
landing: 2
landolsi: 2
laptop: 2
lastly: 2
lastop: 2
launching: 2
laying: 2
le: 2
lease: 2
legitimate: 2
leigh: 2
lepreau: 2
leskovec: 2
leslie: 2
leverages: 2
levy: 2
lightly: 2
lightwave: 2
likewise: 2
lin: 2
liskov: 2
literally: 2
literature: 2
lm: 2
locate: 2
lockstep: 2
longest: 2
longhaul: 2
loops: 2
loosely: 2
louise: 2
lowering: 2
lowers: 2
lows: 2
ltd: 2
luck: 2
lundqvist: 2
lynch: 2
lyon: 2
madden: 2
madhow: 2
magharei: 2
mance: 2
mandatory: 2
mangling: 2
manifested: 2
manipulate: 2
manually: 2
march: 2
marshaling: 2
martinez: 2
matrices: 2
matthews: 2
mature: 2
maximal: 2
maximized: 2
maya: 2
md: 2
mdcc: 2
meant: 2
megabits: 2
memoryless: 2
menees: 2
metacdn: 2
micro: 2
microsystems: 2
migrating: 2
milestone: 2
mined: 2
minimising: 2
minimizes: 2
minus: 2
mirroring: 2
miscalculate: 2
mismatched: 2
mistakenly: 2
mit: 2
mitigated: 2
mitigation: 2
mlml: 2
modem: 2
moderately: 2
modest: 2
modulo: 2
mohr: 2
montenegro: 2
monterey: 2
moshe: 2
mrc: 2
mst: 2
multigrep: 2
multiples: 2
multiplied: 2
multithreading: 2
muri: 2
muthitacharoen: 2
myriad: 2
nakamoto: 2
named: 2
names: 2
naming: 2
nandi: 2
narayanan: 2
naughton: 2
navathe: 2
ncsa: 2
ne: 2
nec: 2
needham: 2
negation: 2
neil: 2
nejdl: 2
newbold: 2
newer: 2
newly: 2
ngan: 2
nic: 2
nichols: 2
nishtala: 2
nity: 2
nlanr: 2
nonequilibrium: 2
nonnenmacher: 2
nontransactional: 2
normalization: 2
normalize: 2
normalizing: 2
normed: 2
notably: 2
notes: 2
notifies: 2
notifying: 2
noting: 2
nutshell: 2
nytimes: 2
obsolete: 2
obviously: 2
occasion: 2
occupies: 2
odd: 2
offices: 2
ofwork: 2
ole: 2
olympics: 2
omi: 2
omits: 2
ool: 2
ooled: 2
op: 2
opacity: 2
opening: 2
operated: 2
opportunities: 2
opt: 2
opted: 2
ordinarily: 2
organizational: 2
organizing: 2
originate: 2
orities: 2
oscillates: 2
ostar: 2
ourselves: 2
outages: 2
outs: 2
outsource: 2
outsources: 2
overcast: 2
overflow: 2
overlays: 2
overqos: 2
pairings: 2
pam: 2
panacea: 2
par: 2
paradigms: 2
parameshwaran: 2
parameterizations: 2
parametrized: 2
parity: 2
park: 2
parno: 2
pass: 2
pathway: 2
patterson: 2
payloads: 2
paypal: 2
pcb: 2
pdcs: 2
pdfs: 2
penalised: 2
pentium: 2
peration: 2
perfor: 2
peris: 2
permits: 2
permitted: 2
perpetrators: 2
perron: 2
petersen: 2
ph: 2
phanishayee: 2
phases: 2
physically: 2
picture: 2
piggybacked: 2
piling: 2
pipeline: 2
pipelines: 2
pitfalls: 2
plague: 2
plays: 2
plication: 2
plugged: 2
plugging: 2
poolattacks: 2
popper: 2
port: 2
porto: 2
ports: 2
poses: 2
position: 2
powersaving: 2
pplive: 2
practically: 2
preceding: 2
precise: 2
precludes: 2
predecessor: 2
predefined: 2
predetermined: 2
predictive: 2
predicts: 2
preferable: 2
prefers: 2
preiss: 2
preliminary: 2
premise: 2
presenting: 2
preservation: 2
preserve: 2
preserving: 2
prevail: 2
prevention: 2
primitive: 2
prioritising: 2
prioritization: 2
prioritize: 2
prioritizing: 2
privately: 2
probabilistically: 2
probe: 2
problematic: 2
processors: 2
produces: 2
professor: 2
profile: 2
profiler: 2
profit: 2
projection: 2
promote: 2
proper: 2
proposals: 2
pros: 2
proving: 2
pseudo: 2
pullbased: 2
pulling: 2
pulse: 2
purchase: 2
purchasing: 2
pure: 2
pursue: 2
pushes: 2
pvldb: 2
qhuang: 2
qin: 2
qmi: 2
qos: 2
quasistatic: 2
quicksilver: 2
quote: 2
race: 2
racticalities: 2
radc: 2
radical: 2
radio: 2
raised: 2
ramakrishnan: 2
ramamritham: 2
randomness: 2
ranges: 2
rank: 2
rateless: 2
rational: 2
ratios: 2
reacts: 2
readily: 2
ready: 2
realizes: 2
rears: 2
reasonably: 2
reception: 2
reciprocation: 2
recognition: 2
recompute: 2
reconciliation: 2
recycling: 2
redesigned: 2
redesigning: 2
reductions: 2
referred: 2
refraining: 2
refreshed: 2
regard: 2
registration: 2
reimplemented: 2
reissue: 2
reissued: 2
rejaie: 2
rejected: 2
rejecting: 2
rejects: 2
relaxed: 2
relay: 2
relevance: 2
relied: 2
relies: 2
reliminaries: 2
relying: 2
remarks: 2
remotely: 2
removes: 2
rendering: 2
rep: 2
repaired: 2
repeatable: 2
repetitions: 2
reporting: 2
repurposing: 2
reputation: 2
requisite: 2
resending: 2
resends: 2
reserves: 2
resident: 2
resolutions: 2
respecting: 2
responsive: 2
restarted: 2
retaliate: 2
retried: 2
retries: 2
reverse: 2
reviewers: 2
revisiting: 2
rewarded: 2
rewritten: 2
reykjavik: 2
reynolds: 2
ricci: 2
rightful: 2
rigid: 2
rigorous: 2
rigorously: 2
rimon: 2
rising: 2
rivalry: 2
roberts: 2
rohrs: 2
rome: 2
roots: 2
rose: 2
rosenblum: 2
ross: 2
rounding: 2
routinely: 2
row: 2
rp: 2
rsized: 2
rt: 2
rtts: 2
ruling: 2
runners: 2
rvr: 2
sabul: 2
safe: 2
saha: 2
said: 2
sake: 2
sales: 2
satellite: 2
saxena: 2
scans: 2
scatter: 2
scattered: 2
scheduler: 2
schedules: 2
sci: 2
scientist: 2
scratch: 2
scsi: 2
seamless: 2
secondgeneration: 2
seda: 2
seeking: 2
seemingly: 2
seldom: 2
seltzer: 2
seminar: 2
senior: 2
sensible: 2
sept: 2
serial: 2
serialize: 2
serially: 2
serious: 2
serverlets: 2
serverpull: 2
settle: 2
shape: 2
shapley: 2
sharp: 2
sheds: 2
shelby: 2
shell: 2
shi: 2
shieh: 2
shifts: 2
shokrollahi: 2
shortcut: 2
shortly: 2
sidebotham: 2
sigact: 2
signs: 2
sigops: 2
sigurbjornsson: 2
silicon: 2
silverlight: 2
simplification: 2
simplified: 2
simulating: 2
singh: 2
sinks: 2
sister: 2
sivakumar: 2
slashdot: 2
slashes: 2
slows: 2
slush: 2
smooth: 2
soar: 2
soars: 2
soas: 2
societies: 2
society: 2
solaris: 2
solely: 2
solheim: 2
solid: 2
solved: 2
something: 2
son: 2
sonic: 2
sons: 2
soper: 2
sourceforge: 2
south: 2
sovran: 2
specialists: 2
speedups: 2
spend: 2
spending: 2
splits: 2
spreads: 2
spreitzer: 2
srs: 2
st: 2
stabilizes: 2
staggering: 2
standalone: 2
stands: 2
stat: 2
statement: 2
station: 2
statqwest: 2
stats: 2
steal: 2
stefan: 2
stephen: 2
stocks: 2
stoller: 2
stops: 2
stories: 2
storms: 2
story: 2
stripe: 2
striping: 2
sturgis: 2
styles: 2
su: 2
subgroup: 2
submits: 2
submitted: 2
submitting: 2
subscribed: 2
subversive: 2
subverted: 2
succession: 2
successively: 2
sudden: 2
suffice: 2
suggest: 2
suggestions: 2
suited: 2
summation: 2
sundr: 2
supergame: 2
supergames: 2
supervisors: 2
supply: 2
suppose: 2
sure: 2
surpass: 2
surprise: 2
survey: 2
susceptibility: 2
suspect: 2
sustain: 2
swallow: 2
swanson: 2
swapping: 2
swift: 2
swinehart: 2
swiss: 2
sybil: 2
synchronize: 2
synthesis: 2
systematic: 2
systemic: 2
tablets: 2
tagged: 2
tailer: 2
tandard: 2
tango: 2
tardos: 2
tation: 2
tauber: 2
tc: 2
technically: 2
tempted: 2
tend: 2
termed: 2
testbed: 2
tgperf: 2
theimer: 2
thick: 2
thing: 2
thirtieth: 2
thumb: 2
tiered: 2
ties: 2
tional: 2
tions: 2
tirumala: 2
toappliance: 2
tock: 2
tods: 2
tolerates: 2
tolerating: 2
topeer: 2
topologically: 2
totally: 2
touch: 2
touches: 2
toueg: 2
tough: 2
toy: 2
tp: 2
tracing: 2
tracked: 2
trades: 2
tragedy: 2
tranmission: 2
transact: 2
transcoded: 2
transforming: 2
trapezoids: 2
treatment: 2
tremel: 2
triangular: 2
tricky: 2
tries: 2
trivially: 2
trol: 2
trsu: 2
trustworthy: 2
tuft: 2
tuned: 2
tv: 2
twentieth: 2
twofold: 2
ugly: 2
umich: 2
un: 2
unaltered: 2
unattacked: 2
unattractive: 2
uncommitable: 2
uncommitted: 2
unexplored: 2
unfavorable: 2
uninvolved: 2
uniquely: 2
united: 2
unlucky: 2
unnecessarily: 2
unnecessary: 2
unreachable: 2
unresponsive: 2
uploading: 2
urgent: 2
userspace: 2
validating: 2
vancouver: 2
vandermeer: 2
vandermonde: 2
vasek: 2
vcurr: 2
vein: 2
venkataramani: 2
ver: 2
verby: 2
versioned: 2
vicinity: 2
viewers: 2
violations: 2
virtualized: 2
visibility: 2
visited: 2
vko: 2
volumes: 2
vpn: 2
wakeup: 2
walks: 2
wallace: 2
war: 2
warehouse: 2
warship: 2
watching: 2
wattenhofer: 2
weakens: 2
weaker: 2
weaknesses: 2
websphere: 2
welch: 2
wesley: 2
west: 2
whereby: 2
whom: 2
wicker: 2
wider: 2
width: 2
wiley: 2
williams: 2
willing: 2
willner: 2
winter: 2
withholds: 2
witnessed: 2
wizkid: 2
wlog: 2
wo: 2
wolfgang: 2
wong: 2
words: 2
workflow: 2
worsening: 2
wrapping: 2
wrongdoing: 2
wvwv: 2
xie: 2
xored: 2
xp: 2
xth: 2
yang: 2
ymir: 2
yxxy: 2
zoom: 2
aaron: 1
abbreviations: 1
abilalso: 1
absorbs: 1
abstracts: 1
abu: 1
accompanied: 1
accomplish: 1
accomplishing: 1
accounted: 1
accumulate: 1
aceves: 1
acheive: 1
acheived: 1
acls: 1
acmula: 1
acomplish: 1
acquires: 1
acquiring: 1
acthe: 1
activated: 1
actuators: 1
acwe: 1
adamic: 1
adaptable: 1
adapted: 1
adaptively: 1
adaptivity: 1
addi: 1
addiserver: 1
additive: 1
addressable: 1
adelaide: 1
adhere: 1
adjacent: 1
administers: 1
admit: 1
admits: 1
adoption: 1
ads: 1
advertise: 1
advertised: 1
adya: 1
aelstrom: 1
aerospace: 1
af: 1
affirmative: 1
afford: 1
afforded: 1
afraid: 1
afterward: 1
agenda: 1
agent: 1
ager: 1
aggregat: 1
aggregrate: 1
aggressively: 1
aggressiveness: 1
agreements: 1
ahnn: 1
aid: 1
aims: 1
airplane: 1
ak: 1
akkus: 1
alarms: 1
albatross: 1
albrecht: 1
alegre: 1
alexander: 1
alfetching: 1
allavena: 1
allegedly: 1
alleviated: 1
alleviates: 1
allo: 1
alloc: 1
allocations: 1
allthingsdistributed: 1
alof: 1
alpha: 1
altogether: 1
altrustic: 1
am: 1
amar: 1
ambitious: 1
america: 1
amortized: 1
ample: 1
amplify: 1
amsden: 1
analogy: 1
analyse: 1
analyst: 1
analytics: 1
ance: 1
anceaume: 1
anddrop: 1
andersen: 1
andre: 1
andreas: 1
ann: 1
anne: 1
annie: 1
annotated: 1
announce: 1
announcement: 1
announces: 1
annoyingly: 1
annually: 1
anonymous: 1
answered: 1
answers: 1
anticipated: 1
antipolis: 1
antonio: 1
anytime: 1
anyway: 1
anywhere: 1
ap: 1
apa: 1
appeal: 1
appendix: 1
applaud: 1
appleton: 1
appli: 1
applicationdropped: 1
appliit: 1
applior: 1
applithe: 1
approaching: 1
approximates: 1
apps: 1
apthe: 1
arbor: 1
architects: 1
archival: 1
archives: 1
argus: 1
arisen: 1
armies: 1
arranging: 1
arrivals: 1
artifact: 1
artificial: 1
ase: 1
aside: 1
ask: 1
asking: 1
assembling: 1
assist: 1
assisted: 1
associates: 1
associating: 1
astrolabe: 1
aswhen: 1
asynbandwidth: 1
asynchrony: 1
asynmicrobenchmarks: 1
asynmobile: 1
asynqueue: 1
ata: 1
atomically: 1
atr: 1
att: 1
attaches: 1
attaching: 1
attar: 1
attention: 1
attr: 1
attracted: 1
attributable: 1
attributed: 1
atypical: 1
audit: 1
audits: 1
australia: 1
authoritative: 1
authorized: 1
autodesk: 1
automation: 1
autotion: 1
autowriteback: 1
autumn: 1
ava: 1
availto: 1
avatar: 1
awaiting: 1
awareness: 1
axes: 1
azim: 1
backgound: 1
backgrounds: 1
backlog: 1
backlogs: 1
backnt: 1
backups: 1
bakalova: 1
balancers: 1
ballance: 1
ballot: 1
banaei: 1
bandcontain: 1
bandhowever: 1
bandwhile: 1
bandwidthdelay: 1
bandwidthsensitive: 1
banff: 1
barcelona: 1
bare: 1
barracuda: 1
barriers: 1
baseline: 1
bastion: 1
batched: 1
batches: 1
batching: 1
batkin: 1
battle: 1
battlefield: 1
battleground: 1
bayeux: 1
bcc: 1
bcq: 1
became: 1
befriended: 1
behren: 1
beijing: 1
belief: 1
believed: 1
beloved: 1
benchmarking: 1
benchmarks: 1
benenational: 1
benoit: 1
bered: 1
berkeleydb: 1
bernd: 1
bershad: 1
bership: 1
bert: 1
bertier: 1
bhattacharjee: 1
biggest: 1
bile: 1
bill: 1
billed: 1
billing: 1
bills: 1
bindel: 1
binds: 1
bio: 1
bitcoinmines: 1
bk: 1
blades: 1
blame: 1
ble: 1
bleeding: 1
blending: 1
blogs: 1
boa: 1
board: 1
body: 1
bold: 1
bologna: 1
bond: 1
bonding: 1
bonn: 1
book: 1
boosting: 1
boot: 1
borisov: 1
bortnikov: 1
boss: 1
bostic: 1
bother: 1
bottlenecks: 1
bought: 1
boundary: 1
bounds: 1
boys: 1
bq: 1
br: 1
brahms: 1
brazil: 1
breakthrough: 1
bregni: 1
breslau: 1
brian: 1
bridging: 1
bright: 1
british: 1
broad: 1
broberg: 1
brokers: 1
brought: 1
bruno: 1
budget: 1
budgets: 1
buffercould: 1
bug: 1
buggy: 1
bugs: 1
builders: 1
burdens: 1
bureau: 1
burgess: 1
buried: 1
burrows: 1
busnel: 1
button: 1
buyer: 1
buying: 1
buys: 1
cabrera: 1
cacheable: 1
cacheserializability: 1
caise: 1
cal: 1
calability: 1
camargos: 1
cameras: 1
cancelled: 1
candidate: 1
cannes: 1
cantwell: 1
capability: 1
cappuccino: 1
captured: 1
caratti: 1
carded: 1
cardinality: 1
cardoso: 1
career: 1
careers: 1
careful: 1
caribbean: 1
carl: 1
carried: 1
carrier: 1
carrying: 1
cart: 1
carzaniga: 1
cas: 1
cascades: 1
cast: 1
castor: 1
catalog: 1
catastrophe: 1
catastrophic: 1
cated: 1
categorized: 1
cations: 1
causal: 1
cbb: 1
cbbc: 1
cbqpcb: 1
ccb: 1
ccdf: 1
cdf: 1
cdrom: 1
ceives: 1
cell: 1
centered: 1
ceremony: 1
certify: 1
certifying: 1
cess: 1
chained: 1
chainlink: 1
chair: 1
chakka: 1
chakravorty: 1
challenger: 1
chang: 1
changtao: 1
chapman: 1
characterised: 1
chawathe: 1
cheat: 1
checkouts: 1
chenchu: 1
cheslack: 1
chicken: 1
chiefly: 1
chien: 1
chinese: 1
ching: 1
chockler: 1
choke: 1
chose: 1
chow: 1
christened: 1
christmas: 1
chronously: 1
chrony: 1
chu: 1
chuck: 1
chunk: 1
chunks: 1
cincilla: 1
circuitous: 1
circulation: 1
circumvented: 1
circumvents: 1
citation: 1
cites: 1
cities: 1
clara: 1
clarity: 1
cleaned: 1
cleanly: 1
clearer: 1
clements: 1
clientserver: 1
clocks: 1
clone: 1
closest: 1
cloudifying: 1
clutter: 1
cmu: 1
codaniques: 1
coded: 1
coding: 1
coexistence: 1
coexists: 1
coherency: 1
coincide: 1
collaborate: 1
collaborating: 1
collapsing: 1
collateral: 1
collects: 1
collusions: 1
columbia: 1
comings: 1
comitting: 1
comm: 1
commatic: 1
commence: 1
commences: 1
commentary: 1
commenting: 1
commercially: 1
commonplace: 1
communal: 1
communi: 1
commutative: 1
comp: 1
compact: 1
comparably: 1
comparaour: 1
comparative: 1
comparisons: 1
compelling: 1
compensating: 1
competitors: 1
compiler: 1
complementary: 1
complementing: 1
complexities: 1
complimentary: 1
comply: 1
compositional: 1
compressed: 1
compresses: 1
comprising: 1
compromises: 1
compromising: 1
computationally: 1
computfits: 1
comsium: 1
concentrates: 1
concentration: 1
conception: 1
conceptually: 1
concludes: 1
concrete: 1
concurby: 1
concuruses: 1
conditioned: 1
conext: 1
configure: 1
conform: 1
conios: 1
conitbased: 1
conjecture: 1
connec: 1
connectionless: 1
conner: 1
consequent: 1
conserving: 1
consisted: 1
consisupdate: 1
consortium: 1
constantly: 1
constituent: 1
constrain: 1
constructs: 1
consulting: 1
consumer: 1
consumers: 1
contacting: 1
contally: 1
contemplate: 1
contemplated: 1
contemplating: 1
contending: 1
conthe: 1
contingencies: 1
contolerate: 1
contractors: 1
contravention: 1
contributes: 1
controller: 1
controversy: 1
convenience: 1
convention: 1
converged: 1
converging: 1
conversely: 1
converts: 1
conveyed: 1
convoys: 1
cooperating: 1
coordinated: 1
coordinating: 1
coordinators: 1
copied: 1
coping: 1
cops: 1
cornelldeveloped: 1
corr: 1
corrected: 1
corrections: 1
correspondingly: 1
corroborated: 1
corrupted: 1
cotton: 1
counters: 1
counting: 1
couple: 1
crashing: 1
crawl: 1
credit: 1
credo: 1
crete: 1
crippling: 1
criteria: 1
critically: 1
crossroads: 1
crowcroft: 1
csd: 1
cstr: 1
culled: 1
cumulatively: 1
customised: 1
customizability: 1
customizable: 1
customization: 1
customizing: 1
customuserserviceapp: 1
cutler: 1
cuts: 1
cybercaf: 1
cyrus: 1
czerwinski: 1
dallas: 1
danielsson: 1
danilov: 1
dantzig: 1
dat: 1
datagrams: 1
dataset: 1
datastores: 1
daunting: 1
dave: 1
davoli: 1
dazzling: 1
dc: 1
dead: 1
deadlock: 1
deadly: 1
deadtially: 1
dean: 1
debatable: 1
debate: 1
debated: 1
debilitating: 1
debris: 1
debugger: 1
declare: 1
declaring: 1
declines: 1
decode: 1
decoder: 1
decoding: 1
decoupled: 1
decouples: 1
decreased: 1
defend: 1
deferplications: 1
deferrable: 1
defers: 1
defgh: 1
defining: 1
definitions: 1
degrees: 1
deit: 1
delegation: 1
delete: 1
deleted: 1
delivers: 1
demanded: 1
demise: 1
demonstration: 1
denning: 1
dennis: 1
denoting: 1
dep: 1
depart: 1
departments: 1
dependalso: 1
dependenrate: 1
depsa: 1
depth: 1
dequeued: 1
der: 1
dered: 1
deregistered: 1
derivative: 1
derivatives: 1
derives: 1
deriving: 1
des: 1
descending: 1
deserver: 1
deshow: 1
designated: 1
designating: 1
designer: 1
desirability: 1
desirable: 1
desktops: 1
destabilize: 1
destinations: 1
detailing: 1
deterioration: 1
determinants: 1
detrimental: 1
dev: 1
developerhours: 1
deviations: 1
devised: 1
devlin: 1
devoted: 1
devoting: 1
dewitt: 1
dexa: 1
dhs: 1
dht: 1
diamond: 1
dictionaries: 1
diego: 1
dies: 1
differany: 1
differential: 1
differentiates: 1
differentiating: 1
differenwith: 1
differing: 1
diffs: 1
dimensions: 1
dimov: 1
ding: 1
directing: 1
directs: 1
disable: 1
disables: 1
disappearance: 1
disappeared: 1
disastrous: 1
disbut: 1
discard: 1
disconnections: 1
disconnects: 1
discontinuing: 1
discotheque: 1
discounts: 1
discovered: 1
discusses: 1
discussing: 1
disguise: 1
disinclined: 1
disjoing: 1
dislike: 1
dismiss: 1
dispatch: 1
dispatcher: 1
dispatching: 1
displayed: 1
displaying: 1
displays: 1
dispools: 1
disregarded: 1
dissatisfied: 1
disseminating: 1
distill: 1
distorted: 1
diverges: 1
diversion: 1
diversity: 1
dll: 1
dlls: 1
documented: 1
dol: 1
domains: 1
dominating: 1
donet: 1
door: 1
dou: 1
doubled: 1
douceur: 1
doug: 1
downgraded: 1
downtime: 1
dozen: 1
dr: 1
drain: 1
drained: 1
drawbacks: 1
drawing: 1
draws: 1
drift: 1
drifting: 1
drive: 1
drivers: 1
drone: 1
duals: 1
ducing: 1
dummynet: 1
dundant: 1
dunn: 1
duplicates: 1
dur: 1
durably: 1
durations: 1
dwarf: 1
dx: 1
dynamics: 1
ear: 1
eastham: 1
economies: 1
ecution: 1
edd: 1
edges: 1
edit: 1
editors: 1
edits: 1
eds: 1
eduardo: 1
educational: 1
edutella: 1
eed: 1
efficacies: 1
eg: 1
egemen: 1
egg: 1
ekin: 1
elasticity: 1
elect: 1
electric: 1
electricity: 1
electronics: 1
eleventh: 1
eliability: 1
elicit: 1
eliciting: 1
elkin: 1
embark: 1
embody: 1
embrace: 1
embraces: 1
emerged: 1
emerges: 1
emitting: 1
emmanuelle: 1
empted: 1
emto: 1
emulating: 1
encapsulates: 1
encod: 1
encode: 1
encompass: 1
encourages: 1
encrypt: 1
encrypts: 1
endeavor: 1
endowment: 1
endpoints: 1
endtransaction: 1
endtransport: 1
enemy: 1
enforced: 1
engine: 1
engineers: 1
enlarge: 1
enlarges: 1
enlarging: 1
enputing: 1
entail: 1
entering: 1
entitled: 1
entropy: 1
enumerate: 1
episodes: 1
epositories: 1
epstein: 1
equeation: 1
equipped: 1
erally: 1
erates: 1
erent: 1
ering: 1
erodes: 1
erred: 1
errorprone: 1
ery: 1
eschewing: 1
esprit: 1
establish: 1
establishes: 1
etup: 1
eugster: 1
evalappended: 1
eventoriented: 1
everyday: 1
everywhere: 1
evocative: 1
evolves: 1
evolving: 1
exacerbating: 1
exaggerated: 1
examined: 1
excellently: 1
excess: 1
exchanging: 1
excitement: 1
exclusively: 1
exec: 1
execusystem: 1
executable: 1
exemplifies: 1
exercise: 1
exhibitthe: 1
existed: 1
exited: 1
exiting: 1
expects: 1
expedited: 1
expense: 1
experiencing: 1
expert: 1
expire: 1
explanation: 1
explanatory: 1
exploits: 1
exponentiated: 1
exporting: 1
expose: 1
exposition: 1
expunged: 1
expurge: 1
exsmart: 1
exspecified: 1
extending: 1
extensible: 1
extensively: 1
extracting: 1
extracts: 1
facilitates: 1
facilitating: 1
facing: 1
factory: 1
failing: 1
failuredetectio: 1
failwhen: 1
faithful: 1
faloutsos: 1
falsely: 1
faltered: 1
famous: 1
farber: 1
farewell: 1
farm: 1
farnoush: 1
farther: 1
fascination: 1
fashioned: 1
fastest: 1
featured: 1
federal: 1
federica: 1
feel: 1
feels: 1
feet: 1
feldman: 1
fell: 1
fellow: 1
fellowship: 1
felt: 1
ferred: 1
ferris: 1
ffs: 1
fic: 1
fidelity: 1
fifteen: 1
figured: 1
fikes: 1
filing: 1
filled: 1
films: 1
filtered: 1
filters: 1
finance: 1
findings: 1
finegrained: 1
finergrained: 1
finish: 1
fiorano: 1
firewall: 1
firms: 1
fisher: 1
fitted: 1
fitting: 1
fixes: 1
flavors: 1
flaws: 1
flickr: 1
flood: 1
flooding: 1
fluctuating: 1
fluke: 1
flushing: 1
fly: 1
focs: 1
football: 1
forcibly: 1
forecast: 1
foregoing: 1
foremost: 1
foresee: 1
forgoing: 1
fork: 1
forked: 1
formal: 1
formally: 1
formed: 1
formerly: 1
fort: 1
fortune: 1
forwards: 1
founder: 1
fractions: 1
franke: 1
frans: 1
freed: 1
freenix: 1
freeze: 1
freshness: 1
fricano: 1
friends: 1
friendship: 1
frightening: 1
frontend: 1
frost: 1
ftcs: 1
fugal: 1
fulfilling: 1
fulfillment: 1
functional: 1
fund: 1
funding: 1
furniture: 1
furthest: 1
gabit: 1
gabriel: 1
gallager: 1
garbinato: 1
garcia: 1
gates: 1
gathering: 1
gauge: 1
gauthier: 1
gave: 1
gb: 1
gbit: 1
gcheap: 1
geambasu: 1
generalized: 1
genercache: 1
generous: 1
geneva: 1
genit: 1
genuinely: 1
geodistributed: 1
geoff: 1
geoffrey: 1
gershinsky: 1
gestion: 1
getting: 1
ghemawat: 1
gi: 1
gian: 1
giardullo: 1
gifford: 1
gilbert: 1
ginting: 1
ginza: 1
gis: 1
gist: 1
giving: 1
glade: 1
glance: 1
glitches: 1
globalized: 1
globecom: 1
goel: 1
gold: 1
goldberg: 1
googles: 1
gov: 1
governed: 1
governmental: 1
grade: 1
gradual: 1
grande: 1
granting: 1
granularity: 1
graphical: 1
grc: 1
gree: 1
greece: 1
grepwe: 1
griffioen: 1
grimm: 1
grips: 1
grochowski: 1
grounds: 1
groundwork: 1
grove: 1
gruber: 1
grunwald: 1
guadelope: 1
gubarev: 1
guha: 1
guis: 1
gunnar: 1
gunnars: 1
gurevich: 1
gurus: 1
guy: 1
guyadec: 1
hacked: 1
hacking: 1
hadoop: 1
haifa: 1
halem: 1
halt: 1
halts: 1
halves: 1
hampering: 1
hanan: 1
handing: 1
handled: 1
handler: 1
handoff: 1
handurukande: 1
hang: 1
hansell: 1
happened: 1
haridasan: 1
haridasana: 1
harmful: 1
harnessing: 1
harpaz: 1
hartman: 1
harwood: 1
hasn: 1
hawaii: 1
hazard: 1
hazards: 1
headquarters: 1
heard: 1
heart: 1
heartbeatmonitor: 1
heat: 1
heavyweight: 1
hegde: 1
hegedu: 1
heidemann: 1
heiser: 1
helen: 1
hellerstein: 1
helped: 1
henceforth: 1
her: 1
herein: 1
hersonissos: 1
hesitate: 1
heterogeneity: 1
heuristic: 1
heuristics: 1
hiding: 1
highassurance: 1
highbandwidth: 1
highbut: 1
highlights: 1
highlyavailable: 1
highpower: 1
highquality: 1
hik: 1
hill: 1
him: 1
himself: 1
hisgen: 1
hjelm: 1
hochschild: 1
holbrook: 1
holder: 1
holding: 1
holte: 1
homes: 1
homomorphic: 1
honolulu: 1
honored: 1
hoon: 1
hopcroft: 1
hoping: 1
horizontal: 1
horn: 1
horrible: 1
hospital: 1
hotice: 1
hotly: 1
hotnets: 1
hotzone: 1
hours: 1
howa: 1
hpca: 1
hreshold: 1
hrs: 1
hsieh: 1
htm: 1
hu: 1
huazhong: 1
huberman: 1
hungary: 1
hurricane: 1
hurting: 1
hyder: 1
hyper: 1
ically: 1
icccn: 1
iceland: 1
icomp: 1
icons: 1
icpads: 1
icsoc: 1
idempotence: 1
iden: 1
idenhigh: 1
identically: 1
idigest: 1
ied: 1
igniting: 1
ignorance: 1
ihkj: 1
iis: 1
ilability: 1
illegal: 1
illusion: 1
imaginable: 1
imation: 1
imc: 1
imlocal: 1
immature: 1
immersive: 1
impacts: 1
implememted: 1
implemenfrom: 1
implemenshared: 1
implementapackages: 1
implosion: 1
implying: 1
import: 1
imported: 1
imporwriteback: 1
imposition: 1
impossibility: 1
imprecise: 1
impressive: 1
improv: 1
inadequacy: 1
inadequate: 1
inadequately: 1
inapplicable: 1
inappropriate: 1
inbound: 1
incentivize: 1
inception: 1
inclusive: 1
incompatible: 1
incomplete: 1
incon: 1
inconsisto: 1
incorpoas: 1
increasess: 1
incredibly: 1
incrementing: 1
indefinitely: 1
independence: 1
indexing: 1
indicators: 1
indictment: 1
indirect: 1
indirectly: 1
indispensable: 1
individinterference: 1
individuals: 1
indranil: 1
induced: 1
industrystandard: 1
inefficiencies: 1
inevitable: 1
inexpennet: 1
inf: 1
infect: 1
infected: 1
infection: 1
infectious: 1
inference: 1
inferred: 1
inflate: 1
inflexibility: 1
inflight: 1
informa: 1
informatics: 1
informing: 1
informs: 1
infrequent: 1
infused: 1
inherited: 1
inhibit: 1
inhibiting: 1
inicontention: 1
initialised: 1
initialize: 1
initiating: 1
initiation: 1
inject: 1
injects: 1
inner: 1
innetwork: 1
innotice: 1
innovate: 1
inprocess: 1
inputs: 1
insecure: 1
insensitive: 1
inseparable: 1
inserted: 1
inserts: 1
inspection: 1
inspired: 1
instruct: 1
instructed: 1
instructing: 1
instructions: 1
instrument: 1
instrumented: 1
instrumenting: 1
int: 1
integers: 1
integrity: 1
intellection: 1
intellectual: 1
intelligence: 1
intem: 1
intense: 1
intensity: 1
intention: 1
intentions: 1
interadditional: 1
intercluster: 1
interdependence: 1
interests: 1
interfere: 1
interferes: 1
interject: 1
interlinked: 1
intermittent: 1
intermittently: 1
internally: 1
internships: 1
interoriginally: 1
interpreted: 1
interpreting: 1
interprocess: 1
interrogates: 1
interrupt: 1
interrupts: 1
interspersed: 1
intervenallows: 1
intra: 1
intractable: 1
intrapartition: 1
intrusion: 1
intrusions: 1
intuitively: 1
invaluable: 1
invariant: 1
invest: 1
investigations: 1
invisible: 1
invocation: 1
invocations: 1
involve: 1
involvement: 1
involving: 1
iperfthe: 1
ipto: 1
irections: 1
irregularity: 1
irregularly: 1
irrelevant: 1
irrespectively: 1
isca: 1
isola: 1
isolate: 1
isolated: 1
isolating: 1
israel: 1
istemi: 1
istva: 1
itcc: 1
items: 1
iterators: 1
ities: 1
itors: 1
iyengar: 1
jacobson: 1
jade: 1
jain: 1
janne: 1
jannotti: 1
jansch: 1
jared: 1
jari: 1
je: 1
jerian: 1
jesi: 1
jian: 1
jiang: 1
jin: 1
jini: 1
jit: 1
jiun: 1
jk: 1
jmc: 1
jms: 1
job: 1
jobs: 1
joined: 1
jones: 1
jong: 1
jorge: 1
jostling: 1
jr: 1
judicious: 1
julkunen: 1
jump: 1
jumpy: 1
juni: 1
junqueira: 1
justice: 1
justification: 1
kallman: 1
kalogeras: 1
kamilmani: 1
kaminsky: 1
kamra: 1
kanthak: 1
karamanolis: 1
karels: 1
karp: 1
kashani: 1
katti: 1
kay: 1
kde: 1
keidl: 1
keith: 1
keller: 1
kempe: 1
kent: 1
kerberos: 1
kernels: 1
kernilized: 1
kevin: 1
keyboard: 1
khan: 1
khorlin: 1
kib: 1
kick: 1
kicking: 1
kicks: 1
kid: 1
kilobyte: 1
kilobytes: 1
kirk: 1
kistler: 1
kit: 1
kk: 1
kleiman: 1
kliot: 1
kloc: 1
knights: 1
knowledgments: 1
kodali: 1
kogan: 1
korhonen: 1
koskela: 1
kostic: 1
kouznetsov: 1
kr: 1
kramer: 1
kraska: 1
krishnakumar: 1
krishnamurthy: 1
kristjan: 1
kristjanvj: 1
krohn: 1
kubiatowicz: 1
kulkarni: 1
kumar: 1
kupfer: 1
kwiatkowski: 1
la: 1
laboratories: 1
laboratory: 1
lacked: 1
ladis: 1
lafayette: 1
lag: 1
lags: 1
laid: 1
laing: 1
lamb: 1
land: 1
landlord: 1
lands: 1
landscapes: 1
lapping: 1
larry: 1
lasting: 1
lauderdale: 1
launch: 1
law: 1
lay: 1
layed: 1
layering: 1
lazy: 1
leaks: 1
learned: 1
learners: 1
leasing: 1
lecture: 1
led: 1
lee: 1
leff: 1
legends: 1
lenient: 1
lenz: 1
lesser: 1
lets: 1
lever: 1
levin: 1
libdeh: 1
liberal: 1
licensing: 1
lie: 1
lied: 1
lieu: 1
lighter: 1
likelihood: 1
limitation: 1
linden: 1
lindsay: 1
linearizable: 1
linger: 1
linkages: 1
lion: 1
listen: 1
listening: 1
littered: 1
liveness: 1
lives: 1
livestreaming: 1
livny: 1
lkjj: 1
ln: 1
lo: 1
localized: 1
localizes: 1
lockfree: 1
logarithmic: 1
logarithmically: 1
logics: 1
login: 1
logstructured: 1
lombard: 1
longput: 1
longrunning: 1
lookup: 1
loose: 1
loses: 1
loudifying: 1
louisiana: 1
lowand: 1
lowbandwidth: 1
lowerfile: 1
lowmfs: 1
lowney: 1
lowpower: 1
lpdc: 1
lr: 1
lugano: 1
luna: 1
luo: 1
lying: 1
lyles: 1
maarten: 1
mach: 1
macrobenchmarks: 1
maffeis: 1
magazine: 1
maglaris: 1
magnetic: 1
magnified: 1
magninetwork: 1
mahajan: 1
maheshwari: 1
mailing: 1
mailoth: 1
mainly: 1
mainteconsequently: 1
mak: 1
maki: 1
malloth: 1
man: 1
mandated: 1
mandreoli: 1
manipulates: 1
manm: 1
mann: 1
mao: 1
marandi: 1
marchukov: 1
marcon: 1
margo: 1
marie: 1
marin: 1
mario: 1
markoff: 1
markus: 1
marrying: 1
marshal: 1
martignon: 1
maryland: 1
marzullo: 1
mash: 1
mashing: 1
masking: 1
mass: 1
massachussetts: 1
matches: 1
materials: 1
matically: 1
matskin: 1
matt: 1
maxcontiguous: 1
maxim: 1
maximizing: 1
maymounkov: 1
mazieres: 1
mazon: 1
mbit: 1
mcauliffe: 1
mcelroy: 1
mckenney: 1
mea: 1
meaning: 1
meaningfully: 1
meantime: 1
mechacies: 1
medians: 1
mediarich: 1
mediately: 1
medical: 1
meet: 1
meetings: 1
megabytes: 1
megastore: 1
meirong: 1
melnik: 1
mem: 1
memcache: 1
memcopy: 1
memoryrelated: 1
men: 1
mendel: 1
menus: 1
mer: 1
merchant: 1
merging: 1
meta: 1
metaphor: 1
miami: 1
miao: 1
mib: 1
migrate: 1
mika: 1
mike: 1
mikhail: 1
mile: 1
milestones: 1
millions: 1
mimic: 1
mindset: 1
minh: 1
minimise: 1
minimised: 1
minimized: 1
minitransactions: 1
minjun: 1
minneapolis: 1
minnesota: 1
minobrowser: 1
mirrored: 1
mirrors: 1
misbehavior: 1
misfinally: 1
miskin: 1
mislove: 1
misra: 1
mistakes: 1
mitigates: 1
mitigating: 1
mitzenmacher: 1
mixes: 1
mmcn: 1
moderate: 1
modewell: 1
modularity: 1
mofavouring: 1
mohan: 1
moll: 1
moments: 1
monetary: 1
monin: 1
monnet: 1
mono: 1
monolithic: 1
monotonically: 1
moon: 1
morning: 1
morris: 1
mostlyreads: 1
motes: 1
motivating: 1
motivations: 1
mounted: 1
mouse: 1
movement: 1
mpi: 1
mplementation: 1
mscorwks: 1
msgs: 1
msiegen: 1
msn: 1
mts: 1
mulsequence: 1
multiframed: 1
multigigabit: 1
multiin: 1
multimedia: 1
multiplexing: 1
multispeed: 1
multitier: 1
multitude: 1
multiversioning: 1
multiwas: 1
multo: 1
mummert: 1
murderous: 1
music: 1
mutexes: 1
mvs: 1
mwaura: 1
na: 1
naaman: 1
nagle: 1
nahrstedt: 1
naively: 1
naks: 1
namespace: 1
nance: 1
napper: 1
narada: 1
nary: 1
nate: 1
nats: 1
naval: 1
navigate: 1
navy: 1
nawab: 1
nca: 1
ndi: 1
neatly: 1
necessity: 1
needing: 1
needless: 1
needlessly: 1
negative: 1
negatively: 1
negligibly: 1
negotiate: 1
nei: 1
neighboring: 1
nelson: 1
ness: 1
netecon: 1
neting: 1
neufeld: 1
newarr: 1
newscasts: 1
nextgeneration: 1
nfs: 1
ngas: 1
nicely: 1
niche: 1
nick: 1
night: 1
nikolov: 1
nimble: 1
ninth: 1
nishimura: 1
nishita: 1
nism: 1
nization: 1
noisy: 1
nomad: 1
nonblockingtransport: 1
noncongestion: 1
nondeterministic: 1
nonempty: 1
nossdav: 1
noteworthy: 1
notified: 1
notoriously: 1
nowadays: 1
np: 1
npapers: 1
nsfc: 1
ntserver: 1
num: 1
numb: 1
numeric: 1
nutanong: 1
nygren: 1
obeyed: 1
obeys: 1
obfuscates: 1
objective: 1
objectivity: 1
objectoriented: 1
obligation: 1
obliging: 1
observable: 1
observes: 1
obsessively: 1
obsoleted: 1
obstacle: 1
obstructs: 1
occurrence: 1
ofc: 1
offenders: 1
offerings: 1
officially: 1
offline: 1
offset: 1
oforder: 1
ogy: 1
oltp: 1
omitting: 1
oneanother: 1
ongoing: 1
ontology: 1
onwards: 1
opearting: 1
openafs: 1
opennt: 1
opens: 1
opensketch: 1
operafrom: 1
operamfs: 1
operat: 1
operatencies: 1
opposing: 1
opposition: 1
optimality: 1
optimally: 1
optimisation: 1
optimisations: 1
optimise: 1
optimised: 1
optimistically: 1
optional: 1
orchestrating: 1
orderings: 1
organised: 1
origin: 1
originated: 1
originating: 1
originator: 1
ority: 1
orks: 1
orleans: 1
orma: 1
ormance: 1
ortributed: 1
orts: 1
oscillate: 1
oscillating: 1
ost: 1
otivation: 1
ource: 1
ous: 1
outcontent: 1
outlook: 1
outof: 1
outperform: 1
outperformed: 1
outright: 1
outweighs: 1
overcomes: 1
overhaul: 1
overlaid: 1
overlayed: 1
overloading: 1
overpredict: 1
overprediction: 1
overreach: 1
overrequest: 1
overrequesting: 1
oversight: 1
oversold: 1
overweigh: 1
overwritten: 1
owing: 1
owned: 1
ozalp: 1
ozsu: 1
pa: 1
pack: 1
package: 1
packparently: 1
packs: 1
pain: 1
pairing: 1
paleczny: 1
pallickara: 1
palossless: 1
pan: 1
panel: 1
pang: 1
panning: 1
pans: 1
paolo: 1
papazoglou: 1
parallelising: 1
parallelism: 1
parallelized: 1
parallelizing: 1
parameterizing: 1
parent: 1
parents: 1
paritybased: 1
parliament: 1
parsa: 1
partitionable: 1
partners: 1
party: 1
passes: 1
pastry: 1
pat: 1
paterson: 1
patin: 1
patino: 1
pavlo: 1
pdc: 1
peculiar: 1
peek: 1
peep: 1
peking: 1
penalized: 1
pennsylvania: 1
penzo: 1
perceive: 1
perceiving: 1
percentiles: 1
perception: 1
perdichizzi: 1
perf: 1
performances: 1
perience: 1
periments: 1
permission: 1
permute: 1
permutes: 1
permuting: 1
perobject: 1
persisted: 1
persistence: 1
persisting: 1
personalize: 1
personalized: 1
personally: 1
pertaining: 1
perturbances: 1
perturbation: 1
perturbations: 1
perv: 1
pervasively: 1
pervasiveness: 1
petko: 1
petrov: 1
pfhsn: 1
phani: 1
philadelphia: 1
philosophical: 1
phones: 1
phpmyadmin: 1
physician: 1
pianese: 1
picconi: 1
picking: 1
picks: 1
piece: 1
pieces: 1
piles: 1
pirahesh: 1
pittsburgh: 1
pivotal: 1
plain: 1
planes: 1
planned: 1
planning: 1
plans: 1
plants: 1
plasma: 1
plat: 1
plausible: 1
please: 1
plentiful: 1
plotted: 1
pluggable: 1
plugins: 1
pn: 1
podcasts: 1
pointer: 1
pointers: 1
poirier: 1
police: 1
political: 1
portability: 1
portal: 1
porting: 1
portob: 1
portray: 1
posix: 1
post: 1
postava: 1
posted: 1
posters: 1
postponed: 1
postponing: 1
potencan: 1
potholes: 1
powell: 1
powerhouse: 1
powering: 1
powers: 1
powersavings: 1
ppendix: 1
practices: 1
pratt: 1
pray: 1
preallocating: 1
precede: 1
precious: 1
precision: 1
preclude: 1
predetermining: 1
predictability: 1
predicting: 1
predictions: 1
predominant: 1
predominantly: 1
preempted: 1
preexisting: 1
preferences: 1
prefetchthe: 1
preguica: 1
preparation: 1
prepare: 1
prepared: 1
prepares: 1
preprocessing: 1
pressing: 1
presume: 1
pretend: 1
pretending: 1
pretends: 1
prevailing: 1
prevalent: 1
previewer: 1
previwhen: 1
prices: 1
prifetched: 1
priin: 1
primaldual: 1
princehouse: 1
priorispeedup: 1
prioritized: 1
priortwo: 1
prito: 1
priviledges: 1
privileged: 1
pro: 1
probed: 1
probes: 1
procedures: 1
proceedin: 1
professional: 1
profiled: 1
profiles: 1
profiling: 1
programmed: 1
progressed: 1
prohibited: 1
prohibitive: 1
prohibitively: 1
prohibits: 1
projected: 1
proliferating: 1
prometheus: 1
prominently: 1
promised: 1
promotional: 1
promptly: 1
pronounced: 1
propagates: 1
propagating: 1
propel: 1
propgated: 1
proportionally: 1
proposal: 1
proposes: 1
prothe: 1
prototypes: 1
protruding: 1
proverbial: 1
provers: 1
provisions: 1
provoke: 1
proximity: 1
prudently: 1
pruned: 1
ptions: 1
publications: 1
publishsubscribe: 1
pubsub: 1
punishing: 1
purchased: 1
purdue: 1
putation: 1
puter: 1
puts: 1
puzar: 1
pvalues: 1
pvm: 1
pvt: 1
qnx: 1
qppq: 1
qu: 1
quadrant: 1
quadrants: 1
qualities: 1
quantified: 1
quantity: 1
quarterman: 1
quarters: 1
quasi: 1
quema: 1
questionable: 1
quinlan: 1
quired: 1
quorum: 1
quotes: 1
raab: 1
races: 1
rachid: 1
racing: 1
radar: 1
radi: 1
rago: 1
raid: 1
rails: 1
raincloud: 1
raisepriority: 1
raising: 1
rameter: 1
ramifications: 1
randomised: 1
ranks: 1
ratnasamy: 1
ratner: 1
rayfield: 1
rbudp: 1
rchitecture: 1
reaction: 1
reactive: 1
readiness: 1
readwrite: 1
realistically: 1
realities: 1
realization: 1
realtime: 1
reardon: 1
reboot: 1
rebuilt: 1
recast: 1
rechecks: 1
recipients: 1
recite: 1
reclamation: 1
recode: 1
recommendation: 1
recommended: 1
recommends: 1
reconfigurable: 1
reconfiguration: 1
reconfigure: 1
reconfiguring: 1
reconnect: 1
reconstruction: 1
recorded: 1
recov: 1
recovrequests: 1
recovthroughput: 1
recurrence: 1
recursive: 1
recursively: 1
redesign: 1
redirect: 1
redirected: 1
redirecting: 1
redisplaying: 1
reedsolomon: 1
referenced: 1
referring: 1
refers: 1
refines: 1
reflectsan: 1
refuse: 1
reg: 1
regenerate: 1
registering: 1
registry: 1
regularity: 1
reid: 1
reiher: 1
reimplementing: 1
relational: 1
relationship: 1
relationships: 1
relayed: 1
religion: 1
relinked: 1
remained: 1
removal: 1
ren: 1
rename: 1
rency: 1
render: 1
renderers: 1
renders: 1
rendezvous: 1
renessea: 1
renewed: 1
rently: 1
reordering: 1
replacements: 1
replicates: 1
reportedly: 1
repre: 1
reprefetch: 1
representa: 1
reproduced: 1
rescuer: 1
researcher: 1
resembles: 1
resend: 1
resetting: 1
reside: 1
resides: 1
resiliency: 1
resolves: 1
resolving: 1
resorting: 1
respected: 1
restarts: 1
restrict: 1
restructured: 1
resumed: 1
retained: 1
retaining: 1
retains: 1
rethese: 1
rethink: 1
retriev: 1
retrieving: 1
reusability: 1
reusable: 1
reuse: 1
reused: 1
revalidate: 1
revealed: 1
revealing: 1
reverts: 1
revisited: 1
revived: 1
revoked: 1
revolution: 1
rewind: 1
rexford: 1
rhee: 1
ricardo: 1
ride: 1
righteous: 1
rio: 1
rive: 1
rlogin: 1
ro: 1
roads: 1
rockell: 1
rocky: 1
rodrigues: 1
rodriguez: 1
rolig: 1
roll: 1
rollback: 1
rolled: 1
rollout: 1
room: 1
rooted: 1
roselli: 1
rotating: 1
rotations: 1
rough: 1
roundrobin: 1
roussel: 1
roy: 1
rss: 1
ru: 1
rubenstein: 1
ruichuan: 1
rush: 1
rushed: 1
rx: 1
saab: 1
sacrificing: 1
saikat: 1
saito: 1
sakoda: 1
salt: 1
sambamurthy: 1
samet: 1
sandber: 1
sankaran: 1
santa: 1
sarana: 1
sarcasm: 1
saroiu: 1
sata: 1
satpep: 1
saturated: 1
saturates: 1
saturating: 1
saturation: 1
savage: 1
saying: 1
says: 1
scaleable: 1
scarce: 1
scenarmobile: 1
scenes: 1
schedule: 1
schematic: 1
schiper: 1
schizophrenic: 1
schlosser: 1
schmidt: 1
schroeder: 1
schuh: 1
schultz: 1
sciascia: 1
scott: 1
screen: 1
screenshots: 1
scripting: 1
scripts: 1
scrutiny: 1
sdns: 1
seagate: 1
searchers: 1
searching: 1
searing: 1
sears: 1
secretly: 1
seeing: 1
seely: 1
seemed: 1
selec: 1
selection: 1
selectively: 1
selfinterested: 1
selforganizing: 1
semanticweb: 1
senses: 1
sensitivfigure: 1
sentative: 1
separating: 1
sequencing: 1
ser: 1
serialised: 1
sericola: 1
serverless: 1
servicing: 1
serving: 1
setceiver: 1
setups: 1
seven: 1
severely: 1
shacham: 1
shaded: 1
shah: 1
shahabi: 1
shalunov: 1
shao: 1
shaped: 1
shapers: 1
shapiro: 1
sharding: 1
shayee: 1
shed: 1
shelf: 1
shenghua: 1
shielding: 1
shim: 1
shipping: 1
shirriff: 1
shop: 1
shopping: 1
shoring: 1
shortcomings: 1
shorter: 1
shouldn: 1
shraer: 1
shrideep: 1
shtml: 1
shupp: 1
shutdown: 1
si: 1
sidebar: 1
siegenthaler: 1
siena: 1
sig: 1
sigkdd: 1
sigmetrics: 1
signature: 1
signed: 1
signers: 1
significance: 1
signing: 1
silberstein: 1
silently: 1
similarities: 1
similarity: 1
simon: 1
simulaneous: 1
simulates: 1
singhai: 1
sintek: 1
sishim: 1
sistencies: 1
sitaraman: 1
sits: 1
sivasubramaniam: 1
sive: 1
sjsu: 1
skepticism: 1
sky: 1
skyrocketing: 1
slash: 1
slay: 1
sleeps: 1
slide: 1
slip: 1
slowdowns: 1
sluggish: 1
smartphone: 1
smith: 1
smoothly: 1
snapshots: 1
snooping: 1
soa: 1
socc: 1
sock: 1
softway: 1
solicited: 1
solves: 1
somefound: 1
sonicmq: 1
sonicsoftware: 1
sooner: 1
sophia: 1
sorted: 1
sought: 1
spain: 1
spanningtree: 1
spans: 1
spared: 1
spawned: 1
speaking: 1
speaks: 1
speci: 1
specializes: 1
specificity: 1
specifies: 1
specifying: 1
spectrum: 1
speech: 1
spends: 1
spielman: 1
spiked: 1
spinning: 1
spirits: 1
spix: 1
splay: 1
splitx: 1
sponse: 1
sporting: 1
sports: 1
sprays: 1
spring: 1
squash: 1
squirrelmail: 1
sridharan: 1
srrs: 1
srsr: 1
ssh: 1
stabilizing: 1
stadrops: 1
stafford: 1
stand: 1
standardizing: 1
stanford: 1
stanislav: 1
stanton: 1
startup: 1
starved: 1
starving: 1
statemachine: 1
statems: 1
stationary: 1
statistic: 1
stead: 1
steen: 1
steep: 1
steer: 1
steere: 1
stepping: 1
stipulating: 1
sto: 1
stochastic: 1
stocking: 1
stodolsky: 1
stoica: 1
stor: 1
stordifferent: 1
straight: 1
street: 1
strengths: 1
stretagy: 1
strike: 1
strikes: 1
strikingly: 1
strings: 1
stripped: 1
strongest: 1
stronglytraces: 1
structuring: 1
studying: 1
stumbled: 1
stylistic: 1
suba: 1
subing: 1
subintervals: 1
subj: 1
subkilobyte: 1
submission: 1
subnetworks: 1
subordinate: 1
subramanian: 1
subscribes: 1
subscription: 1
subscriptions: 1
subsections: 1
subsequence: 1
subservicecontrol: 1
subserviceprocess: 1
substandard: 1
substitute: 1
substreams: 1
subtitles: 1
subtransactions: 1
succeeds: 1
successor: 1
sue: 1
suffix: 1
suggestive: 1
sul: 1
summarise: 1
summarised: 1
summarizes: 1
summarizing: 1
summer: 1
sunos: 1
sup: 1
superbowl: 1
superceded: 1
superfluous: 1
superimpose: 1
superior: 1
superlinearly: 1
supersede: 1
superseded: 1
supervisory: 1
supplementing: 1
supposed: 1
suppressing: 1
surely: 1
surements: 1
surge: 1
surplus: 1
surrounding: 1
surtani: 1
survivors: 1
suryanarayana: 1
suspended: 1
sussman: 1
sw: 1
swart: 1
swivel: 1
swws: 1
sympo: 1
syn: 1
synchro: 1
synchronise: 1
synchronizing: 1
systraditional: 1
szeged: 1
szymaniak: 1
tablet: 1
tag: 1
tags: 1
tailor: 1
tains: 1
talking: 1
talks: 1
tam: 1
tamma: 1
tan: 1
tance: 1
tanin: 1
tao: 1
tapped: 1
tapping: 1
tari: 1
taught: 1
tdi: 1
te: 1
technetwork: 1
technicalsessions: 1
technion: 1
technologists: 1
telecommunications: 1
telemetry: 1
templates: 1
tempt: 1
tems: 1
tency: 1
tended: 1
tension: 1
tent: 1
tentative: 1
tention: 1
terleaving: 1
terlinked: 1
terminal: 1
terminate: 1
terminated: 1
testimony: 1
textures: 1
thanks: 1
thefly: 1
ther: 1
thereafter: 1
thereby: 1
thorsten: 1
thrashing: 1
threading: 1
threetier: 1
throughputs: 1
throughxors: 1
tial: 1
tiate: 1
tib: 1
ticast: 1
ticipant: 1
ticker: 1
ticular: 1
tied: 1
tightrope: 1
timecritical: 1
timeframe: 1
timeline: 1
timers: 1
timescales: 1
timesharing: 1
timo: 1
tination: 1
tings: 1
tiple: 1
titles: 1
tity: 1
tively: 1
tivity: 1
todd: 1
todisincentivize: 1
toend: 1
toknow: 1
tokyo: 1
tolercations: 1
tom: 1
tone: 1
tons: 1
toplas: 1
topoltifiers: 1
tortures: 1
touted: 1
traceroute: 1
traf: 1
trafficshaping: 1
trailing: 1
tranasctions: 1
transactionally: 1
transactypes: 1
transcoding: 1
transformed: 1
transis: 1
transit: 1
transitional: 1
translated: 1
translates: 1
translation: 1
translators: 1
translucence: 1
transportation: 1
transporting: 1
travels: 1
treatments: 1
tri: 1
trials: 1
tricks: 1
tried: 1
trillion: 1
trim: 1
trips: 1
truncate: 1
truncated: 1
truong: 1
tsatalos: 1
ttls: 1
tude: 1
tudy: 1
tunable: 1
tung: 1
tuples: 1
turing: 1
tus: 1
tweb: 1
twelth: 1
twin: 1
twitter: 1
twotier: 1
tx: 1
txcache: 1
txn: 1
typed: 1
typwrite: 1
ual: 1
ubicomm: 1
ubiquitously: 1
ublcs: 1
uc: 1
ucb: 1
ufrgs: 1
ular: 1
ulate: 1
ultrareliable: 1
unacceptably: 1
unavoidable: 1
unbe: 1
uncertain: 1
unclustered: 1
unconstrained: 1
uncontrolled: 1
uncorrelated: 1
underdog: 1
undergo: 1
underlies: 1
underneath: 1
underperform: 1
understandable: 1
understanddevices: 1
understands: 1
understood: 1
undertake: 1
undertaken: 1
underutilisation: 1
underway: 1
undesired: 1
undisturbed: 1
unencrypted: 1
unflattering: 1
unfortunate: 1
unidirectional: 1
unifies: 1
uniformally: 1
unilaterally: 1
unintended: 1
uninterference: 1
unites: 1
univ: 1
univerisity: 1
universal: 1
universe: 1
universita: 1
unjustified: 1
unlink: 1
unlinking: 1
unmodified: 1
unnoticed: 1
unparalleled: 1
unrealistic: 1
unreasonable: 1
unrecoverable: 1
unreserved: 1
unresilient: 1
unresolved: 1
unresponsiveness: 1
unrpcs: 1
unspecified: 1
unsuitable: 1
untouched: 1
unusually: 1
unwilling: 1
upare: 1
upcalls: 1
upcan: 1
upcations: 1
upcoming: 1
upgrade: 1
upgrades: 1
upisting: 1
uploads: 1
upreader: 1
upson: 1
upstudies: 1
upthe: 1
upwidth: 1
ures: 1
urgently: 1
url: 1
urls: 1
usages: 1
usdoj: 1
usefully: 1
usermakes: 1
uservisible: 1
utilising: 1
utilized: 1
utilizes: 1
utilizing: 1
utrsut: 1
utt: 1
uture: 1
uut: 1
uutt: 1
validations: 1
vanilla: 1
vanishes: 1
var: 1
variances: 1
vasilatos: 1
vb: 1
vectored: 1
vehicles: 1
veitch: 1
velenis: 1
venkataraman: 1
vercurr: 1
verification: 1
versa: 1
vertical: 1
victims: 1
videos: 1
vidhyashankar: 1
viding: 1
viewer: 1
viewsynchronous: 1
violated: 1
violates: 1
viral: 1
vironment: 1
virtually: 1
virtue: 1
vishnumurthy: 1
visibly: 1
vision: 1
visit: 1
visiting: 1
vista: 1
visualize: 1
visualizing: 1
vital: 1
vivek: 1
vlo: 1
vmm: 1
vms: 1
voelker: 1
vogel: 1
voip: 1
vollset: 1
voluntary: 1
vrable: 1
wa: 1
waived: 1
wallach: 1
wans: 1
warp: 1
wasn: 1
wasteful: 1
wastes: 1
wasting: 1
watches: 1
wave: 1
wcnc: 1
weaken: 1
weakness: 1
webfs: 1
weblogs: 1
webtier: 1
weeks: 1
weighed: 1
welldefined: 1
weng: 1
wes: 1
westerlund: 1
wg: 1
whatsnew: 1
whatsoever: 1
wheeler: 1
whereupon: 1
whiteboard: 1
whitepaper: 1
whithout: 1
wholefile: 1
wicom: 1
widens: 1
wieloch: 1
wilma: 1
windowsnt: 1
winnie: 1
wires: 1
withuated: 1
witnesses: 1
wolf: 1
wonder: 1
woo: 1
woodford: 1
worker: 1
worries: 1
worrisome: 1
worthwhile: 1
wouldn: 1
wrapped: 1
wraps: 1
writclassification: 1
writeaccesses: 1
writeinvalidations: 1
writequirement: 1
writeserver: 1
writetive: 1
writewrite: 1
wrote: 1
wscompatible: 1
wsdl: 1
wspds: 1
wstransactions: 1
wu: 1
xaxis: 1
xcp: 1
xiao: 1
xisting: 1
xperimental: 1
xu: 1
xyx: 1
yaghmazadeh: 1
yann: 1
yaxes: 1
yee: 1
yielded: 1
yin: 1
ylianttila: 1
youtube: 1
yuanchao: 1
yuanyuan: 1
yum: 1
yushprakh: 1
zahorjan: 1
zdonik: 1
zeal: 1
zealous: 1
zelenka: 1
zephyr: 1
zettabyte: 1
zhen: 1
zhenqi: 1
zhou: 1
zhuang: 1
zoomed: 1
zooming: 1
zooms: 1
zou: 1
zuck: 1
zwilling: 1
