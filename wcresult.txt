web technologies can web
technologies can web services
can web services scale
web services scale up
cornell university i n
university i n the
i n the past
only major internet players
major internet players such
internet players such as
players such as amazon
implementing high performance multicast
and google were interested
high performance multicast in
google were interested in
performance multicast in a
were interested in deploying
multicast in a managed
interested in deploying large
in a managed environment
a managed environment krzysztof
managed environment krzysztof ostrowski
environment krzysztof ostrowski cornell
krzysztof ostrowski cornell university
ostrowski cornell university ken
cornell university ken birman
university ken birman cornell
ken birman cornell university
birman cornell university abstract
cornell university abstract motes
this is changing rapidly
university abstract motes end
is changing rapidly all
changing rapidly all sorts
transparent error correction for
an adaptive distributed file
rapidly all sorts of
error correction for communication
user application development using
adaptive distributed file system
all sorts of companies
correction for communication between
application development using c
for communication between data
sorts of companies and
communication between data centers
distributed file system for
between data centers mahesh
of companies and governmental
file system for mobile
data centers mahesh balakrishnan
system for mobile hosts
companies and governmental organizations
for mobile hosts benjamin
and governmental organizations are
mobile hosts benjamin atkin
governmental organizations are suddenly
hosts benjamin atkin and
organizations are suddenly looking
benjamin atkin and kenneth
are suddenly looking towards
the company s own
atkin and kenneth p
company s own products
suddenly looking towards web
s own products are
looking towards web services
own products are still
towards web services as
products are still implemented
web services as a
are still implemented primarily
services as a platform
still implemented primarily in
as a platform that
implemented primarily in unmanaged
a platform that might
primarily in unmanaged c
platform that might support
birman department of computer
that might support a
department of computer science
might support a wide
of computer science cornell
support a wide range
computer science cornell university
a wide range of
wide range of demanding
range of demanding applications
by building xyx in
building xyx in the
examples of such systems
xyx in the recommended
of such systems include
in the recommended manner
such systems include big
systems include big banking
include big banking and
big banking and brokerage
banking and brokerage data
we found ourselves breaking
and brokerage data centers
found ourselves breaking new
ourselves breaking new ground
online service centers for
service centers for companies
the multicast protocols employed
centers for companies that
multicast protocols employed by
for companies that operate
edu abstract mfs using
companies that operate on
protocols employed by qsm
that operate on a
abstract mfs using file
employed by qsm were
mfs using file access
operate on a global
using file access traces
on a global scale
file access traces from
by qsm were designed
access traces from windows
qsm were designed for
traces from windows nt
were designed for performance
from windows nt and
designed for performance and
windows nt and unix
for performance and scalability
systems to operate critical
to operate critical infrastructures
operate critical infrastructures like
critical infrastructures like electric
infrastructures like electric power
incorporating a mixture of
and a synthetic workload
a mixture of new
like electric power and
a synthetic workload designed
mixture of new ideas
electric power and transportation
synthetic workload designed to
of new ideas and
workload designed to emulate
new ideas and ideas
designed to emulate sharing
ideas and ideas drawn
to emulate sharing patterns
and ideas drawn from
and government and military
emulate sharing patterns seen
ideas drawn from prior
sharing patterns seen in
government and military systems
abstract the global network
and military systems responsible
patterns seen in mobility
drawn from prior systems
seen in mobility is
military systems responsible for
in mobility is a
the global network of
mobility is a critical
systems responsible for everything
global network of data
is a critical feature
responsible for everything from
network of data centers
a critical feature of
for everything from intelligence
critical feature of computer
of data centers is
the aspects on which
feature of computer systems
aspects on which we
data centers is emerging
on which we focus
everything from intelligence gathering
which we focus here
centers is emerging as
we focus here reflect
from intelligence gathering to
and while collaborative engineering
focus here reflect architectural
while collaborative engineering systems
intelligence gathering to issuing
is emerging as an
gathering to issuing social
here reflect architectural responses
to issuing social security
emerging as an important
issuing social security checks
reflect architectural responses to
wireless networks are common
architectural responses to scheduling
as an important distributed
responses to scheduling delays
an important distributed systems
important distributed systems paradigm
this emerging trend presents
distributed systems paradigm commodity
emerging trend presents developers
systems paradigm commodity clusters
overheads associated with threads
most applications that run
trend presents developers with
paradigm commodity clusters running
presents developers with a
commodity clusters running high
developers with a new
applications that run on
with a new challenge
and costs arising in
that run on existing
costs arising in the
run on existing work
arising in the memory
on existing work in
building web services solutions
in the memory management
web services solutions that
existing work in cache
services solutions that scale
the memory management subsystem
work in cache management
in cache management for
cache management for mobile
speed lambda networks across
management for mobile file
lambda networks across hundreds
for mobile file systems
over the period during
mobile file systems mobile
the period during which
networks across hundreds of
period during which qsm
file systems mobile hosts
during which qsm was
across hundreds of milliseconds
which qsm was developed
systems mobile hosts lack
a scalable system is
mobile hosts lack flexible
hundreds of milliseconds of
hosts lack flexible mechanisms
of milliseconds of network
lack flexible mechanisms for
milliseconds of network latency
scalable system is one
flexible mechanisms for data
system is one that
mechanisms for data access
is one that can
for data access in
one that can flexibly
packet loss on long
that can flexibly accommodate
data access in an
can flexibly accommodate growth
access in an en
flexibly accommodate growth in
these had pervasive consequences
accommodate growth in its
growth in its client
haul networks can cripple
in its client base
networks can cripple the
can cripple the performance
forcing us to redesign
cripple the performance of
us to redesign and
the performance of applications
to redesign and recode
performance of applications and
redesign and recode one
such systems typically run
and recode one layer
of applications and protocols
recode one layer of
systems typically run on
one layer of the
applications and protocols a
layer of the system
typically run on a
of the system after
and protocols a loss
the system after another
run on a clustered
protocols a loss rate
on a clustered computer
a loss rate as
a clustered computer or
loss rate as low
rate as low as
clustered computer or in
computer or in a
or in a large
in a large data
the original system was
a large data center
original system was multithreaded
large data center and
data center and must
center and must be
and must be able
must be able to
be able to handle
able to handle high
to handle high loads
o calls and was
handle high loads or
is sufficient to reduce
high loads or sudden
sufficient to reduce tcp
calls and was rather
loads or sudden demand
and was rather casual
or sudden demand bursts
was rather casual about
sudden demand bursts and
rather casual about buffering
incorporates mechanisms for making
ip throughput by an
casual about buffering and
throughput by an order
mechanisms for making efficient
by an order of
about buffering and caching
an order of magnitude
for making efficient vironment
order of magnitude on
demand bursts and a
making efficient vironment with
bursts and a vast
of magnitude on a
the current system is
and a vast number
current system is single
efficient vironment with large
a vast number of
vironment with large and
vast number of users
with large and frequent
large and frequent variations
and frequent variations in
frequent variations in network
variations in network connec
they must reliably respond
must reliably respond even
use of available bandwidth
reliably respond even in
respond even in the
even in the event
in the event of
the event of failures
and obsessively minimizes memory
event of failures or
obsessively minimizes memory consumption
of failures or reconfiguration
it has mostly focused
maelstrom is an edge
has mostly focused on
is an edge appliance
mostly focused on tivity
an edge appliance that
edge appliance that masks
appliance that masks packet
that masks packet loss
masks packet loss transparently
packet loss transparently and
loss transparently and quickly
transparently and quickly from
and quickly from inter
managed and automate as
and automate as many
in collaborative work adapting
automate as many routine
collaborative work adapting existing
performs well and is
work adapting existing systems
as many routine services
adapting existing systems to
well and is stable
aggregating traffic for high
existing systems to cope
many routine services such
systems to cope with
and is stable at
routine services such as
is stable at high
to cope with periods
stable at high data
speed encoding and using
at high data rates
services such as backups
cope with periods of
such as backups and
with periods of low
encoding and using a
as backups and component
periods of low bandwidth
large scale and under
backups and component upgrades
and using a new
and component upgrades as
scale and under stress
component upgrades as possible
using a new forward
a new forward error
new forward error correction
forward error correction scheme
particularly when wireless and
many settings also require
when wireless and wired
the finished system achieves
wireless and wired users
settings also require security
and wired users share
finished system achieves extremely
wired users share in
also require security against
users share in a
system achieves extremely high
share in a style
require security against attempted
in a style which
achieves extremely high performance
a style which we
security against attempted intrusions
error correction scheme to
against attempted intrusions and
correction scheme to handle
attempted intrusions and distributed
scheme to handle bursty
intrusions and distributed denial
to handle bursty loss
extremely high performance with
style which we will
high performance with relatively
which we will refer
performance with relatively modest
we will refer to
with relatively modest cpu
will refer to as
relatively modest cpu and
refer to as modal
modest cpu and memory
to as modal adaptation
cpu and memory loads
when files or databases
although our paper is
our paper is not
paper is not about
is not about setting
not about setting performance
about setting performance records
setting performance records the
we describe some techniques
performance records the absolute
describe some techniques bandwidth
records the absolute numbers
some techniques bandwidth is
the absolute numbers are
techniques bandwidth is high
absolute numbers are good
the application communicates normally
qsm outperforms the multicast
outperforms the multicast platforms
the multicast platforms we
when for adapting data
multicast platforms we ve
for adapting data access
platforms we ve worked
adapting data access to
we ve worked with
the second builds on
ve worked with in
data access to network
worked with in the
second builds on the
with in the past
access to network variability
in the past systems
builds on the first
the past systems that
to network variability in
past systems that run
on the first and
systems that run in
i ntroduction t a
that run in unmanaged
the first and supports
run in unmanaged settings
ntroduction t a conference
network variability in the
t a conference version
variability in the context
first and supports a
a conference version of
in the context of
and supports a way
the context of bandwidth
conference version of this
context of bandwidth falls
this paper won t
of bandwidth falls below
version of this paper
supports a way to
of this paper appeared
bandwidth falls below a
this paper appeared in
falls below a threshold
paper appeared in nsdi
a way to build
paper won t tell
way to build scripts
won t tell the
to build scripts of
t tell the blow
build scripts of simpler
the application enters a
scripts of simpler transactions
application enters a lowmfs
a client cache manager
some might argue that
client cache manager for
might argue that all
cache manager for a
argue that all reliability
manager for a distributed
that all reliability needs
for a distributed file
all reliability needs can
a distributed file system
reliability needs can be
needs can be recast
can be recast in
be recast in terms
we use qsm in
recast in terms of
use qsm in a
in terms of transactions
we bandwidth mode in
fifth usenix symposium on
qsm in a series
usenix symposium on networked
bandwidth mode in which
symposium on networked systems
in a series of
on networked systems design
mode in which communication
networked systems design and
a series of experiments
systems design and implementation
in which communication is
series of experiments that
the past three decades
which communication is restricted
of experiments that highlight
communication is restricted or
experiments that highlight fundamental
is restricted or deshow
that highlight fundamental factors
restricted or deshow how
past three decades have
or deshow how mfs
three decades have seen
deshow how mfs is
decades have seen one
how mfs is able
have seen one failed
these reveal linkages between
seen one failed attempt
mfs is able to
one failed attempt after
is able to adapt
reveal linkages between achievable
able to adapt to
failed attempt after another
to adapt to widely
linkages between achievable performance
attempt after another to
adapt to widely varying
after another to build
to widely varying bandwidth
between achievable performance and
another to build everything
widely varying bandwidth ferred
to build everything over
achievable performance and the
build everything over a
performance and the costs
everything over a database
and the costs and
over a database system
ms index terms data
the costs and characteristics
index terms data centers
costs and characteristics of
and characteristics of the
an application has a
characteristics of the managed
application has a small
of the managed framework
has a small number
and it s now
a small number of
it s now clear
small number of levels
s now clear that
number of levels through
now clear that many
doing so sheds light
clear that many kinds
of levels through the
that many kinds of
levels through the use
so sheds light on
many kinds of systems
through the use of
sheds light on the
the use of modeless
kinds of systems just
use of modeless adaptation
he emergence of commodity
light on the challenges
of systems just don
emergence of commodity clusters
on the challenges of
systems just don t
of commodity clusters and
the challenges of working
just don t match
commodity clusters and data
don t match the
challenges of working in
t match the model
clusters and data centers
and evaluate the possible
of working in a
and data centers has
evaluate the possible modes
working in a kind
data centers has enabled
the possible modes and
in a kind of
possible modes and chooses
centers has enabled a
these intrinsically distributed systems
a kind of environment
modes and chooses the
has enabled a new
intrinsically distributed systems make
kind of environment that
and chooses the appropriate
enabled a new class
distributed systems make use
of environment that will
systems make use of
a new class of
chooses the appropriate one
environment that will be
make use of direct
that will be more
the appropriate one based
will be more and
use of direct communication
be more and more
appropriate one based on
more and more prevalent
of direct communication between
and more prevalent in
one based on the
more prevalent in years
direct communication between programs
new class of globally
communication between programs via
prevalent in years to
between programs via the
in years to come
programs via the trans
class of globally distributed
based on the benefit
of globally distributed highperformance
on the benefit of
globally distributed highperformance applications
the benefit of mechanisms
our insights should be
benefit of mechanisms for
distributed highperformance applications that
of mechanisms for improving
highperformance applications that coordinate
mechanisms for improving file
insights should be of
for improving file system
applications that coordinate over
improving file system performance
should be of value
file system performance currently
that coordinate over vast
system performance currently available
be of value to
current web services standards
of value to developers
performance currently available bandwidth
value to developers of
web services standards have
to developers of other
coordinate over vast geographical
services standards have many
developers of other high
standards have many critical
over vast geographical distances
have many critical limitations
in the coda file
performance communication and event
the coda file and
coda file and cache
file and cache consistency
and cache consistency using
cache consistency using microbenchmarks
today s web services
consistency using microbenchmarks and
s web services standards
a financial firm s
web services standards seem
using microbenchmarks and file
services standards seem to
microbenchmarks and file system
standards seem to answer
financial firm s new
seem to answer these
and file system system
firm s new york
to answer these needs
s new york city
new york city data
york city data center
city data center may
data center may receive
center may receive real
we propose a new
propose a new positioning
a new positioning of
a more probing analysis
new positioning of multicast
more probing analysis reveals
positioning of multicast technology
probing analysis reveals many
time updates from a
analysis reveals many critical
updates from a stock
reveals many critical limitations
from a stock exchange
a stock exchange in
as an extension of
stock exchange in switzerland
an extension of the
the cache manager operates
extension of the component
cache manager operates in
of the component integration
manager operates in either
the component integration features
operates in either a
component integration features of
conduct financial transactions with
integration features of the
in either a stronglytraces
financial transactions with banks
features of the microsoft
transactions with banks in
the major web services
with banks in asia
major web services standards
web services standards dealing
services standards dealing with
net managed runtime environment
standards dealing with reliability
cache data in london
data in london for
in london for locality
london for locality and
for locality and mirror
locality and mirror it
and mirror it to
mirror it to kansas
it to kansas for
to kansas for disaster
which affects the policy
although we started with
affects the policy for
we started with a
the policy for writing
started with a sophisticated
policy for writing changes
with a sophisticated multicast
reliability provides for reliable
a sophisticated multicast protocol
for writing changes to
to interconnect these bandwidth
provides for reliable handoff
writing changes to files
for reliable handoff between
experiments reveal a series
changes to files back
reveal a series of
to files back to
a series of problematic
files back to the
reliable handoff between a
hungry data centers across
handoff between a client
data centers across the
series of problematic interactions
back to the server
of problematic interactions between
centers across the globe
problematic interactions between its
between a client system
interactions between its high
a client system and
modal adaptation schemes are
client system and a
adaptation schemes are well
system and a queuing
organizations are increasingly deploying
and a queuing system
are increasingly deploying private
a queuing system residing
increasingly deploying private lambda
queuing system residing between
deploying private lambda networks
system residing between the
processing logic and the
residing between the client
logic and the properties
between the client and
and the properties of
the client and some
the properties of the
introduction in which changes
properties of the managed
client and some service
raw bandwidth is ubiquitous
in which changes in
of the managed framework
which changes in bandwidth
bandwidth is ubiquitous and
changes in bandwidth are
is ubiquitous and cheaply
in bandwidth are relatively
ubiquitous and cheaply available
bandwidth are relatively predictable
and cheaply available in
cheaply available in the
the standard isn t
available in the form
standard isn t nearly
in the form of
isn t nearly as
the form of existing
t nearly as comprehensive
form of existing dark
nearly as comprehensive as
of existing dark fiber
such as switching network
as comprehensive as the
as switching network access
comprehensive as the name
switching network access from
as the name implies
network access from an
we addressed these and
access from an ethernet
addressed these and achieved
from an ethernet to
these and achieved high
an ethernet to a
running and maintaining high
ethernet to a modem
and achieved high performance
achieved high performance by
it s limited to
high performance by making
s limited to pipelines
performance by making some
limited to pipelines that
but mobility is now
to pipelines that include
by making some unusual
pipelines that include queuing
mobility is now an
that include queuing subsystems
is now an major
free networks over this
now an major feature
making some unusual architectural
networks over this fiber
some unusual architectural decisions
over this fiber is
an major feature of
this fiber is difficult
major feature of computer
fiber is difficult and
feature of computer systems
is difficult and expensive
which we distill into
reliability boils down to
we distill into general
boils down to a
distill into general insights
over the not as
down to a few
the not as appropriate
not as appropriate in
to a few options
capacity optical links are
as appropriate in for
component integration environments such
appropriate in for wireless
integration environments such as
in for wireless networks
a few options that
optical links are almost
environments such as microsoft
links are almost never
few options that a
are almost never congested
in which bandwidth past
options that a client
which bandwidth past decade
that a client can
they drop packets for
a client can use
drop packets for numerous
ee have become widely
packets for numerous reasons
have become widely popular
for numerous reasons dirty
become widely popular with
client can use to
widely popular with application
held devices capable of
popular with application developers
can use to tell
devices capable of wireless
use to tell the
capable of wireless availability
to tell the queuing
of wireless availability is
tell the queuing system
wireless availability is less
who benefit from standardized
availability is less predictable
benefit from standardized memory
is less predictable and
from standardized memory management
the queuing system whether
less predictable and varies
queuing system whether or
predictable and varies over
system whether or not
and varies over a
whether or not to
varies over a larger
or not to reissue
over a larger possible
not to reissue a
a larger possible network
to reissue a request
larger possible network access
reissue a request if
possible network access have
a request if a
network access have become
request if a failure
access have become common
if a failure occurs
and performance analysis tools
performance analysis tools that
and wireless networks are
analysis tools that operate
wireless networks are range
and a way to
tools that operate across
a way to timestamp
that operate across component
way to timestamp requests
operate across component boundaries
to timestamp requests so
the notion of insufficient
timestamp requests so that
notion of insufficient bandwidth
requests so that a
of insufficient bandwidth can
so that a service
insufficient bandwidth can vary
that a service can
bandwidth can vary dependalso
a service can detect
can vary dependalso proliferating
service can detect duplicates
this paper describes quicksilver
paper describes quicksilver scalable
describes quicksilver scalable multicast
applications that run on
that run on hosts
run on hosts in
on hosts in wireless
transactions actually consists of
hosts in wireless neting
actually consists of two
in wireless neting on
consists of two side
wireless neting on how
neting on how much
on how much data
how much data the
much data the application
data the application is
the application is trying
application is trying to
a new multicast platform
is trying to send
new multicast platform designed
for example and in
multicast platform designed to
example and in different
platform designed to achieve
and in different patterns
one is aimed at
designed to achieve high
is aimed at applications
so that works must
aimed at applications that
to achieve high performance
at applications that perform
achieve high performance in
ranging from singleton drops
high performance in managed
applications that perform database
performance in managed environments
from singleton drops to
that works must cope
singleton drops to extended
that perform database transactions
works must cope with
drops to extended bursts
must cope with constraints
perform database transactions with
memoryrelated overheads and phenomena
cope with constraints on
database transactions with the
overheads and phenomena related
transactions with the usual
with constraints on access
with the usual acid
and phenomena related to
constraints on access to
phenomena related to scheduling
on access to data
related to scheduling are
access to data that
to scheduling are shown
to data that are
scheduling are shown to
data that are genit
are shown to dominate
that are genit may
shown to dominate the
are genit may make
to dominate the behavior
genit may make sense
dominate the behavior of
may make sense to
the behavior of the
make sense to adjust
behavior of the system
sense to adjust network
to adjust network usage
adjust network usage when
network usage when the
usage when the bandwidth
we discuss techniques that
when the bandwidth erally
discuss techniques that helped
the bandwidth erally not
techniques that helped us
bandwidth erally not present
that helped us to
noncongestion loss has been
erally not present in
or the remote procedure
loss has been observed
the remote procedure call
has been observed on
remote procedure call and
been observed on long
helped us to alleviate
not present in wired
us to alleviate these
procedure call and that
present in wired networks
call and that can
haul networks as well
and that can t
to alleviate these problems
that can t tolerate
can t tolerate delay
distance from a base
from a base stadrops
a base stadrops by
base stadrops by half
and argue that they
these systems lack databases
argue that they reveal
systems lack databases clean
that they reveal general
lack databases clean separation
rather than just when
databases clean separation of
than just when it
clean separation of stored
just when it falls
they reveal general principles
separation of stored data
reveal general principles applicable
of stored data from
general principles applicable to
stored data from code
principles applicable to other
when it falls to
applicable to other kinds
it falls to modem
to other kinds of
other kinds of high
and any attempt to
any attempt to force
attempt to force them
to force them into
force them into that
them into that model
into that model results
rate protocols and applications
that model results in
protocols and applications in
model results in unacceptable
and applications in managed
contention with other hosts
applications in managed settings
with other hosts or
results in unacceptable loss
other hosts or processes
in unacceptable loss of
hosts or processes on
unacceptable loss of performance
or processes on the
processes on the same
on the same host
intrinsically distributed systems are
introduction a component integration
distributed systems are common
selecting a mode according
a component integration revolution
a mode according to
component integration revolution is
mode according to the
integration revolution is transforming
according to the available
revolution is transforming the
to the available bandwidth
is transforming the development
the available bandwidth can
and web services will
available bandwidth can uninterference
transforming the development of
web services will need
the development of desktop
services will need to
development of desktop applications
will need to support
and switching between different
need to support them
switching between different wireless
between different wireless media
platforms such as windows
different wireless media all
wireless media all necessarily
media all necessarily constrain
all necessarily constrain communication
the existing reliability options
the inadequacy of commodity
existing reliability options simply
since it ignores what
ee promote an application
inadequacy of commodity tcp
reliability options simply don
it ignores what data
options simply don t
promote an application development
simply don t address
ignores what data compound
don t address the
ip in high bandwidthdelay
t address the requirement
what data compound the
an application development style
in high bandwidthdelay product
data compound the variability
high bandwidthdelay product networks
application development style in
bandwidthdelay product networks is
a lesson from the
product networks is extensively
development style in which
compound the variability in
style in which components
networks is extensively documented
in which components are
the variability in network
which components are implemented
lesson from the past
components are implemented independently
variability in network performance
are implemented independently and
from the past what
implemented independently and heavily
in network performance to
independently and heavily reused
the past what sorts
network performance to which
past what sorts of
performance to which apthe
what sorts of scaling
to which apthe application
sorts of scaling and
which apthe application actually
of scaling and reliability
apthe application actually wants
scaling and reliability features
application actually wants to
by standardizing memory management
and reliability features are
actually wants to send
reliability features are lacking
wants to send over
standardizing memory management and
features are lacking in
memory management and type
to send over the
are lacking in web
management and type checking
lacking in web services
send over the network
in web services standards
web services standards today
these platforms enable safe
deferplications must adapt if
platforms enable safe and
must adapt if they
enable safe and efficient
adapt if they are
safe and efficient cross
if they are to
a good example is
they are to perform
good example is data
are to perform well
example is data replication
ring writing back all
avoiding overheads associated with
building a server that
overheads associated with protection
writing back all modifications
associated with protection boundaries
a server that scales
back all modifications to
server that scales to
all modifications to files
that scales to handle
modifications to files may
scales to handle load
to files may not
to handle load often
ip has three major
handle load often requires
has three major problems
files may not be
three major problems when
load often requires replicating
major problems when used
may not be a
problems when used over
often requires replicating data
when used over such
requires replicating data on
used over such networks
replicating data on multiple
not be a sensible
data on multiple nodes
be a sensible this
on multiple nodes of
a sensible this paper
multiple nodes of a
sensible this paper focuses
nodes of a cluster
our project is interested
this paper focuses on
project is interested in
paper focuses on adaptation
is interested in leveraging
focuses on adaptation techniques
interested in leveraging these
ip suffers throughput collapse
on adaptation techniques for
in leveraging these benefits
adaptation techniques for management
another example is guaranteed
techniques for management policy
example is guaranteed real
suffers throughput collapse if
leveraging these benefits to
throughput collapse if the
for management policy if
collapse if the network
management policy if those
if the network is
policy if those are
the network is even
these benefits to help
network is even slightly
if those are the
benefits to help developers
those are the only
is even slightly prone
are the only messages
to help developers implement
the only messages available
even slightly prone to
help developers implement robust
slightly prone to packet
a company that buys
only messages available to
developers implement robust and
prone to packet loss
company that buys a
messages available to send
implement robust and scalable
that buys a cluster
robust and scalable computing
buys a cluster probably
and scalable computing services
a cluster probably wants
scalable computing services that
conservative flow control mechanisms
of data accessed and
cluster probably wants to
computing services that will
flow control mechanisms designed
services that will run
probably wants to guarantee
data accessed and modified
control mechanisms designed to
that will run on
mechanisms designed to deal
will run on clusters
wants to guarantee that
accessed and modified by
designed to deal with
run on clusters or
to deal with the
on clusters or in
deal with the systematic
and modified by mobile
with the systematic congestion
modified by mobile hosts
to guarantee that some
clusters or in datacenters
guarantee that some service
the systematic congestion of
that some service will
systematic congestion of the
some service will be
congestion of the commodity
we investigate we describe
of the commodity internet
investigate we describe mfs
the commodity internet react
early users of our
service will be responsive
users of our platform
commodity internet react too
of our platform are
internet react too sharply
our platform are creating
will be responsive enough
platform are creating applications
react too sharply to
are creating applications in
be responsive enough to
creating applications in areas
responsive enough to keep
applications in areas such
a flexible cache adaptation
enough to keep its
in areas such as
flexible cache adaptation in
areas such as parallelized
cache adaptation in the
to keep its customers
such as parallelized data
keep its customers happy
as parallelized data mining
its customers happy even
adaptation in the context
customers happy even when
in the context of
happy even when demand
the context of mfs
event stream filtering software
even when demand is
when demand is high
a client cache manager
and scalable web services
client cache manager for
ms w n s
cache manager for a
the missing technologies don
w n s e
missing technologies don t
developers of clustered services
technologies don t stop
of clustered services need
don t stop there
manager for a manager
n s e fig
for a manager for
clustered services need reliable
a manager for a
services need reliable multicast
manager for a distributed
need reliable multicast protocols
for a distributed file
reliable multicast protocols for
a distributed file system
multicast protocols for data
distributed file system client
protocols for data replication
cycle services that can
services that can launch
example lambda network ephemeral
that can launch an
lambda network ephemeral loss
which differs from distributed
network ephemeral loss on
differs from distributed file
and in light of
can launch an application
in light of our
from distributed file system
light of our broader
launch an application on
of our broader goal
an application on demand
our broader goal of
application on demand or
ephemeral loss on over
on demand or restart
we concentrate on distributed
broader goal of leveraging
concentrate on distributed file
demand or restart a
on distributed file systraditional
or restart a failed
goal of leveraging the
provisioned links a single
of leveraging the power
links a single packet
leveraging the power and
restart a failed component
the power and component
a single packet in
power and component integration
single packet in ten
and component integration features
packet in ten thousand
component integration features of
in ten thousand is
integration features of a
ten thousand is enough
features of a managed
thousand is enough to
of a managed framework
is enough to reduce
or load balancers and
distributed file systraditional cache
load balancers and technology
file systraditional cache manager
enough to reduce tcp
the multicast technology must
systraditional cache manager design
balancers and technology to
cache manager design in
multicast technology must run
and technology to automate
technology must run in
ip throughput to a
manager design in two
throughput to a third
design in two important
to a third over
in two important respects
a third over a
must run in a
technology to automate management
run in a managed
to automate management of
in a managed setting
automate management of a
management of a machine
of a machine cluster
a machine cluster running
tems because systems in
but little is known
because systems in this
little is known about
machine cluster running web
is known about highperformance
and one in a
known about highperformance protocols
one in a thousand
about highperformance protocols in
in a thousand drops
highperformance protocols in managed
a thousand drops it
protocols in managed environments
thousand drops it by
systems in this area
cluster running web services
drops it by an
in this area are
it by an order
it is interesting to
this area are highly
by an order of
area are highly developed
is interesting to realize
are highly developed and
interesting to realize that
running web services applications
an order of magnitude
highly developed and have
to realize that although
developed and have mfs
realize that although microsoft
and have mfs uses
that although microsoft pro
have mfs uses an
mfs uses an rpc
uses an rpc library
an rpc library supporting
rpc library supporting priorities
this research was supported
library supporting priorities to
research was supported by
supporting priorities to enable
was supported by afrl
priorities to enable modewell
working groups within the
time or interactive applications
to enable modewell understood
groups within the world
if with additional support
within the world wide
with additional support from
the world wide web
additional support from afosr
world wide web consortium
or interactive applications are
enable modewell understood semantics
interactive applications are impacted
applications are impacted by
are impacted by the
impacted by the reliance
although the techniques we
by the reliance of
the techniques we describe
the reliance of reliability
techniques we describe less
reliance of reliability mechanisms
we describe less adaptation
of reliability mechanisms on
reliability mechanisms on acknowledgments
mechanisms on acknowledgments and
on acknowledgments and retransmissions
limiting the latency of
the primary organization developing
department of computer science
primary organization developing web
the latency of packet
organization developing web services
latency of packet recovery
developing web services standards
of packet recovery to
which allocates available bandwidth
packet recovery to at
allocates available bandwidth based
recovery to at least
available bandwidth based should
to at least the
bandwidth based should be
at least the round
based should be broadly
least the round trip
should be broadly applicable
the round trip time
be broadly applicable in
not one is addressing
broadly applicable in other
one is addressing these
applicable in other application
is addressing these kinds
in other application environments
addressing these kinds of
these kinds of issues
on the types of
the types of messages
a similar dynamic played
types of messages being
similar dynamic played out
if delivery is sequenced
dynamic played out in
of messages being sent
played out in the
out in the early
by assigning priorities such
assigning priorities such as
priorities such as caching
such as caching dynamic
as caching dynamic internet
caching dynamic internet content
each lost packet acts
dynamic internet content or
lost packet acts as
internet content or caching
packet acts as a
content or caching to
acts as a virtual
or caching to improve
as a virtual road
caching to improve appropriately
block in the fifo
in the fifo channel
the fifo channel until
server computing was touted
fifo channel until it
computing was touted as
channel until it is
was touted as the
until it is recovered
such as retrieving files
touted as the next
as the next big
the next big thing
can the performance of
the performance of interactions
performance of interactions with
a silver bullet to
of interactions with web
silver bullet to solve
interactions with web services
bullet to solve every
to solve every problem
ip requires massive buffers
solve every problem related
requires massive buffers at
every problem related to
massive buffers at the
we evaluate proceed concurrently
problem related to older
buffers at the communicating
related to older mainframe
evaluate proceed concurrently with
the embedding of qsm
to older mainframe and
proceed concurrently with background
older mainframe and batch
at the communicating endhosts
embedding of qsm into
the communicating endhosts to
of qsm into windows
communicating endhosts to fully
qsm into windows yielded
endhosts to fully exploit
into windows yielded an
to fully exploit the
windows yielded an unexpected
fully exploit the bandwidth
yielded an unexpected benefit
exploit the bandwidth of
mainframe and batch systems
concurrently with background activities
the bandwidth of a
with background activities such
bandwidth of a long
background activities such as
it enables what we
activities such as writing
enables what we are
companies rushed to move
such as writing the
rushed to move everything
what we are calling
to move everything from
we are calling live
move everything from mainframe
are calling live distributed
everything from mainframe settings
calling live distributed objects
from mainframe settings to
even in the absence
as writing the authors
in the absence of
mainframe settings to client
writing the authors were
as the term suggests
the absence of packet
the authors were supported
absence of packet loss
authors were supported in
were supported in part
supported in part by
these are abstract data
in part by darpa
are abstract data types
part by darpa under
abstract data types in
by darpa under afrl
data types in which
darpa under afrl grant
resistant alternatives to tcp
under afrl grant radc
there were notable successes
types in which content
afrl grant radc back
in which content evolves
grant radc back changes
which content evolves over
ip is not feasible
content evolves over time
is not feasible in
but it quickly became
not feasible in corporate
it quickly became apparent
under the assurance that
when an application binds
the assurance that if
an application binds to
quickly became apparent that
feasible in corporate data
assurance that if bandwidth
application binds to a
became apparent that the
in corporate data centers
apparent that the early
binds to a live
that if bandwidth becomes
that the early platforms
to a live object
if bandwidth becomes f
the early platforms were
where standardization is the
early platforms were strikingly
standardization is the key
platforms were strikingly immature
the current state of
is the key to
current state of the
the key to low
state of the object
key to low and
of the object is
to low and predictable
processes needed to be
low and predictable maintenance
needed to be automated
and predictable maintenance costs
to be automated and
the object is imported
be automated and standardized
object is imported and
is imported and the
imported and the object
neither is eliminating loss
and the object can
and the early generations
the object can send
the early generations of
is eliminating loss events
object can send and
eliminating loss events on
can send and receive
loss events on a
send and receive updates
events on a network
and receive updates at
early generations of client
on a network that
receive updates at high
a network that could
updates at high data
network that could span
at high data rates
server systems cost a
that could span thousands
systems cost a fortune
could span thousands of
cost a fortune to
span thousands of miles
an object could be
a fortune to build
object could be a
could be a place
be a place in
a place in a
place in a game
in a game like
a game like second
game like second life
there is a need
required armies of systems
is a need to
armies of systems administrators
a need to mask
of systems administrators and
need to mask loss
systems administrators and specialists
to mask loss on
mask loss on the
loss on the link
and by afosr under
on the link from
by afosr under muri
and were extremely insecure
the link from the
afosr under muri grant
link from the commodity
under muri grant f
from the commodity protocols
the commodity protocols running
the total cost of
commodity protocols running at
total cost of ownership
protocols running at end
cost of ownership proved
of ownership proved to
ownership proved to be
proved to be unexpectedly
to be unexpectedly and
live objects are a
be unexpectedly and unacceptably
objects are a natural
unexpectedly and unacceptably high
and to do so
are a natural and
to do so rapidly
a natural and powerful
do so rapidly and
the lesson of the
so rapidly and transparently
lesson of the client
natural and powerful idea
server era is that
and we plan to
era is that incomplete
we plan to pursue
is that incomplete platforms
because recovery delays for
plan to pursue the
recovery delays for lost
to pursue the concept
that incomplete platforms can
delays for lost packets
pursue the concept in
incomplete platforms can t
for lost packets translate
the concept in future
lost packets translate into
concept in future work
packets translate into dramatic
platforms can t support
translate into dramatic reductions
can t support major
into dramatic reductions in
dramatic reductions in application
this use of qsm
use of qsm raises
my concern is that
of qsm raises performance
concern is that the
qsm raises performance and
is that the web
raises performance and scalability
that the web services
performance and scalability issues
because applications and os
and scalability issues beyond
the web services community
scalability issues beyond the
web services community is
issues beyond the ones
applications and os networking
beyond the ones seen
services community is about
and os networking stacks
community is about to
the ones seen in
rather than the foreground
ones seen in our
than the foreground ones
seen in our original
is about to face
os networking stacks in
in our original target
networking stacks in commodity
our original target domain
additional support from microsoft
stacks in commodity data
support from microsoft research
in commodity data centers
from microsoft research and
about to face the
commodity data centers cannot
microsoft research and from
data centers cannot be
research and from the
centers cannot be rewritten
and from the intel
cannot be rewritten from
from the intel corporation
be rewritten from scratch
we leave detailed discussion
to face the same
leave detailed discussion of
face the same problem
detailed discussion of the
discussion of the idea
of the idea for
the idea for the
idea for the future
application programs background processing
platform developers are racing
developers are racing forward
programs background processing incoming
are racing forward at
qsm has been available
racing forward at top
has been available for
forward at top speed
been available for free
background processing incoming traffic
available for free download
for free download since
side appliance receiver buffer
free download since mid
appliance receiver buffer overflow
processing incoming traffic cache
jostling for position with
for position with ever
incoming traffic cache consistency
position with ever more
local recovery locations of
with ever more exaggerated
traffic cache consistency demand
recovery locations of packet
ever more exaggerated claims
cache consistency demand fetch
locations of packet loss
of packet loss receive
consistency demand fetch access
demand fetch access monitoring
while closing their eyes
fetch access monitoring prefetch
closing their eyes to
side appliance receiving end
their eyes to the
access monitoring prefetch outgoing
eyes to the dangerous
to the dangerous potholes
monitoring prefetch outgoing traffic
the dangerous potholes in
prefetch outgoing traffic synchronous
dangerous potholes in the
and it has a
outgoing traffic synchronous writeback
potholes in the road
it has a number
traffic synchronous writeback update
in the road ahead
has a number of
synchronous writeback update logging
a number of users
writeback update logging asynchronous
update logging asynchronous writeback
maelstrom communication path forward
logging asynchronous writeback mfs
communication path forward error
most working on clustered
path forward error correction
working on clustered computing
architectural standards for scalability
asynchronous writeback mfs server
standards for scalability to
writeback mfs server adaptive
for scalability to properly
mfs server adaptive rpc
scalability to properly address
server adaptive rpc library
to properly address scalability
adaptive rpc library mfs
properly address scalability in
is a promising solution
address scalability in web
a promising solution for
rpc library mfs cache
promising solution for reliability
library mfs cache manager
solution for reliability over
mfs cache manager will
for reliability over long
cache manager will be
one large project is
scalability in web services
manager will be penalised
large project is pairing
will be penalised first
project is pairing qsm
is pairing qsm with
we need more than
pairing qsm with high
need more than a
more than a long
modeless adaptation using prioritised
than a long list
adaptation using prioritised communication
a long list of
speed event stream filtering
using prioritised communication also
event stream filtering and
long list of reliability
stream filtering and data
list of reliability and
filtering and data mining
of reliability and management
and data mining system
reliability and management standards
data mining system to
prioritised communication also allows
packet recovery latency is
communication also allows mfs
recovery latency is independent
mining system to obtain
latency is independent of
system to obtain a
is independent of the
we need a new
also allows mfs to
need a new methodology
independent of the rtt
a new methodology suitable
of the rtt of
new methodology suitable for
allows mfs to be
methodology suitable for supporting
mfs to be more
to obtain a scalable
to be more flexible
suitable for supporting a
the rtt of the
be more flexible in
for supporting a scalable
rtt of the link
supporting a scalable data
more flexible in response
a scalable data center
flexible in response to
scalable data center architecture
in response to bandwidth
hosted service capable of
response to bandwidth variations
while fec codes have
to bandwidth variations than
service capable of handling
bandwidth variations than would
capable of handling very
variations than would be
of handling very high
than would be possible
handling very high event
fec codes have been
would be possible with
codes have been used
be possible with a
have been used for
possible with a modal
been used for decades
with a modal scheme
used for decades within
very high event rates
for decades within link
mfs incorporates a new
incorporates a new cache
group used for system
a new cache consistency
along with pat helland
new cache consistency algorithm
with pat helland and
used for system management
faster commodity processors have
for system management service
commodity processors have enabled
cache consistency algorithm to
pat helland and dennis
consistency algorithm to efficiently
helland and dennis shasha
system management service b
processors have enabled packet
management service b x
algorithm to efficiently provide
service b x y
recommends that developers think
b x y z
that developers think in
x y z x
to efficiently provide a
y z x y
developers think in terms
level fec at end
think in terms of
z x y z
in terms of a
efficiently provide a high
terms of a reliable
provide a high degree
of a reliable arraystructured
a high degree of
a reliable arraystructured partitioned
x y z x
reliable arraystructured partitioned service
y z x y
high degree of consistency
z x y z
degree of consistency for
x y z a
of consistency for access
y z a b
consistency for access to
z a b service
for access to shared
a b service c
access to shared files
b service c a
implemented as a set
service c a b
as a set of
c a b w
a set of reliable
a b w figure
set of reliable arraystructured
which is required for
of reliable arraystructured clustered
is required for collaborative
reliable arraystructured clustered servers
required for collaborative work
for collaborative work applications
if sets of components
the rest of this
sets of components are
rest of this paper
of components are replicated
of this paper is
this paper is organised
paper is organised as
is organised as follows
this architecture offers scalability
the associated multicast groups
architecture offers scalability and
associated multicast groups overlap
offers scalability and reliability
multicast groups overlap hierarchically
scalability and reliability at
and reliability at two
reliability at two levels
describes the mfs design
the mfs design and
the foregoing is the
mfs design and differences
foregoing is the primary
design and differences from
is the primary use
and differences from existing
the primary use scenario
differences from existing distributed
primary use scenario for
from existing distributed and
use scenario for qsm
existing distributed and mobile
the top level uses
end fec is very
distributed and mobile file
top level uses some
fec is very attractive
but may not be
is very attractive for
and mobile file systems
very attractive for communication
may not be the
level uses some sort
attractive for communication between
not be the only
uses some sort of
for communication between data
as well as giving
be the only one
some sort of application
communication between data centers
well as giving an
as giving an overview
giving an overview of
one could imagine an
specific key to partition
an overview of the
could imagine an approach
key to partition the
imagine an approach to
easy to deploy and
to partition the service
overview of the mfs
an approach to laying
to deploy and customize
approach to laying out
of the mfs rpc
to laying out components
the mfs rpc library
partition the service into
laying out components on
the service into subservices
out components on a
and does not require
components on a cluster
does not require specialized
on a cluster that
not require specialized equipment
describes the use of
require specialized equipment in
the use of prioritised
specialized equipment in the
use of prioritised communication
equipment in the network
the lower level implements
a cluster that would
lower level implements subservices
cluster that would result
level implements subservices using
in the network linking
implements subservices using groups
the network linking the
subservices using groups of
network linking the data
using groups of programs
that would result in
of prioritised communication in
linking the data centers
prioritised communication in mfs
would result in irregular
groups of programs that
communication in mfs and
of programs that run
in mfs and experiments
programs that run on
mfs and experiments to
that run on multiple
and experiments to evaluate
run on multiple machines
experiments to evaluate its
endhost fec has two
result in irregular layouts
to evaluate its effectiveness
fec has two major
perhaps in a cluster
in irregular layouts of
has two major issues
in a cluster computer
irregular layouts of groups
two major issues first
presents and explains experimental
and explains experimental results
the groups replicate data
qsm can support such
groups replicate data so
it s not transparent
replicate data so that
can support such layouts
data so that each
explains experimental results for
so that each can
requiring modification of the
experimental results for the
at least to a
results for the mfs
least to a degree
for the mfs prefetching
that each can handle
modification of the end
each can handle any
the mfs prefetching mechanism
can handle any incoming
but for reasons of
handle any incoming query
for reasons of brevity
any incoming query for
reasons of brevity the
incoming query for its
of brevity the discussion
query for its range
brevity the discussion in
for its range within
does the same for
the discussion in the
its range within the
the same for the
it s not necessarily
range within the keys
discussion in the remainder
same for the cache
in the remainder of
for the cache consistency
the remainder of the
the cache consistency algorithm
remainder of the paper
enabling updates to reach
s not necessarily rapid
of the paper focuses
updates to reach all
the paper focuses on
to reach all the
paper focuses on regular
fec works best over
reach all the replicas
works best over high
concludes and describes future
and describes future work
hierarchically structured communication groups
structured communication groups with
communication groups with extensive
stable traffic rates and
groups with extensive and
traffic rates and performs
with extensive and regular
rates and performs poorly
extensive and regular overlap
and performs poorly if
a raps that an
performs poorly if the
raps that an e
poorly if the data
initial users of our
if the data rate
users of our system
the most important part
of our system haven
most important part of
our system haven t
important part of mfs
system haven t had
part of mfs is
haven t had any
tailer such as amazon
the data rate in
such as amazon might
data rate in the
as amazon might use
rate in the channel
amazon might use to
in the channel is
might use to personalize
the channel is low
use to personalize a
t had any difficulty
of mfs is the
channel is low and
to personalize a product
had any difficulty with
mfs is the cache
is low and sporadic
personalize a product recommendation
any difficulty with this
is the cache manager
difficulty with this constraint
depending on the customer
on the customer s
the customer s profile
which intercepts file system
knowing qsm is particularly
intercepts file system operations
qsm is particularly effective
file system operations from
is particularly effective with
system operations from application
particularly effective with regular
the service ranks matching
operations from application programs
service ranks matching products
effective with regular layouts
as in a single
ranks matching products differently
from application programs and
matching products differently to
in a single end
products differently to maximize
application programs and resolves
they just design to
differently to maximize the
programs and resolves them
just design to favor
to maximize the chance
and resolves them into
design to favor regularity
maximize the chance of
resolves them into accesses
the chance of a
them into accesses to
chance of a purchase
into accesses to its
we present the maelstrom
accesses to its local
usage cases architecture reliable
to its local mfs
cases architecture reliable multicast
present the maelstrom error
its local mfs cache
the maelstrom error correction
architecture reliable multicast is
maelstrom error correction appliance
reliable multicast is a
if the product is
local mfs cache or
error correction appliance a
multicast is a mature
correction appliance a rack
is a mature area
mfs cache or rpcs
appliance a rack of
cache or rpcs to
a rack of proxies
or rpcs to a
rack of proxies residing
but a review of
rpcs to a server
a review of prior
as shown in figure
of proxies residing between
review of prior systems
proxies residing between a
of prior systems convinced
residing between a data
prior systems convinced us
between a data center
the cache manager has
systems convinced us that
a data center and
convinced us that no
data center and its
us that no existing
the service assigns the
cache manager has a
service assigns the search
that no existing system
center and its wan
manager has a number
assigns the search request
no existing system would
the search request to
has a number of
and its wan link
existing system would work
search request to the
a number of components
system would work well
request to the racs
would work well in
to the racs handling
work well in the
those in solid boxes
the racs handling all
well in the scenarios
in solid boxes are
racs handling all ds
in the scenarios targeted
solid boxes are part
the scenarios targeted by
maelstrom encodes fec packets
scenarios targeted by our
boxes are part of
encodes fec packets over
targeted by our project
fec packets over traffic
are part of the
packets over traffic flowing
part of the core
such as the customer
over traffic flowing through
of the core system
traffic flowing through it
as the customer s
flowing through it and
the customer s name
through it and routes
customer s name are
those in dashed boxes
s name are equally
in dashed boxes are
it and routes them
dashed boxes are optional
name are equally plausible
this forced us to
and routes them to
forced us to build
routes them to a
us to build a
them to a corresponding
to build a new
to a corresponding appliance
build a new system
boxes are optional extensions
a corresponding appliance at
a new system that
the load balancer then
are optional extensions which
corresponding appliance at the
new system that combines
load balancer then routes
optional extensions which are
balancer then routes the
extensions which are described
appliance at the destination
system that combines features
then routes the request
that combines features from
at the destination data
which are described in
routes the request to
combines features from a
the request to the
features from a number
request to the appropriate
from a number of
the destination data center
are described in subsequent
to the appropriate program
a number of prior
the appropriate program for
number of prior systems
appropriate program for processing
described in subsequent sections
which decodes them and
program for processing in
decodes them and recovers
our decision not to
for processing in this
them and recovers lost
decision not to use
processing in this case
mfs overview mfs differs
not to use some
overview mfs differs from
to use some existing
mfs differs from earlier
use some existing multicast
and recovers lost data
differs from earlier mobile
some existing multicast system
from earlier mobile file
with support for this
earlier mobile file systems
support for this basic
mobile file systems in
for this basic layout
existing multicast system reflects
maelstrom is completely transparent
file systems in adjusting
is completely transparent it
systems in adjusting to
completely transparent it does
in adjusting to changing
transparent it does not
adjusting to changing network
it does not require
to changing network conditions
does not require modification
changing network conditions using
not require modification of
network conditions using modeless
require modification of end
conditions using modeless adaptation
multicast system reflects a
it s possible to
system reflects a number
s possible to tackle
it comprises a core
possible to tackle a
reflects a number of
host software and is
comprises a core client
software and is agnostic
a number of issues
to tackle a wide
and is agnostic to
tackle a wide range
is agnostic to the
a wide range of
most prior multicast systems
wide range of secondary
and a number of
range of secondary issues
a number of subsystems
prior multicast systems were
agnostic to the network
multicast systems were designed
to the network connecting
systems were designed to
the network connecting the
number of subsystems that
were designed to replicate
we could create standards
of subsystems that perform
network connecting the data
designed to replicate state
could create standards for
to replicate state within
create standards for a
replicate state within just
standards for a self
state within just a
connecting the data centers
subsystems that perform different
within just a single
that perform different kinds
managed raps of racs
perform different kinds of
just a single group
different kinds of adaptation
a single group at
single group at a
or for one that
it eliminates the dependence
group at a time
eliminates the dependence of
and can be selectively
the dependence of fec
can be selectively enabled
dependence of fec recovery
for one that guarantees
for example a single
of fec recovery latency
one that guarantees real
fec recovery latency on
example a single distributed
recovery latency on the
shows the structure of
latency on the data
the structure of the
on the data rate
a single distributed service
structure of the system
the data rate in
such a basic architecture
data rate in any
a basic architecture is
rate in any single
in this section we
in any single node
this section we describe
some don t support
basic architecture is effectively
section we describe the
don t support multiple
architecture is effectively a
we describe the core
is effectively a framework
describe the core system
effectively a framework to
node channel by encoding
t support multiple groups
a framework to resolve
channel by encoding over
framework to resolve other
while subsequent sections do
support multiple groups at
by encoding over the
to resolve other related
subsequent sections do the
multiple groups at all
encoding over the aggregated
resolve other related issues
sections do the same
over the aggregated traffic
do the same for
while others have overheads
the same for the
others have overheads linear
the aggregated traffic leaving
have overheads linear in
aggregated traffic leaving the
overheads linear in the
traffic leaving the data
linear in the number
group replication web services
same for the three
replication web services currently
for the three main
web services currently lacks
in the number of
leaving the data center
the three main subsystems
services currently lacks support
the number of groups
currently lacks support for
number of groups to
lacks support for building
of groups to which
support for building scalable
groups to which a
we begin with an
for building scalable services
begin with an overview
maelstrom uses a new
with an overview of
uses a new encoding
an overview of mobile
a new encoding scheme
overview of mobile file
new encoding scheme called
of mobile file system
to which a node
the architecture makes it
encoding scheme called layered
mobile file system design
which a node belongs
architecture makes it easy
scheme called layered interleaving
file system design and
makes it easy to
system design and the
it easy to build
design and the relation
designed especially for time
we looked at jgroups
and the relation of
easy to build a
the relation of mfs
to build a single
sensitive packet recovery in
relation of mfs to
packet recovery in the
of mfs to previous
recovery in the presence
node server that responds
in the presence of
server that responds to
mfs to previous work
that responds to requests
the presence of bursty
responds to requests from
presence of bursty loss
a component of the
to requests from some
component of the jboss
requests from some set
of the jboss platform
from some set of
the jboss platform which
some set of clients
jboss platform which runs
then briefly describe the
maelstrom s positioning as
platform which runs in
briefly describe the adaptive
s positioning as a
which runs in a
positioning as a network
describe the adaptive rpc
as a network appliance
the adaptive rpc library
but there s no
runs in a managed
there s no way
in a managed java
a network appliance reflects
adaptive rpc library used
network appliance reflects the
a managed java framework
appliance reflects the physical
rpc library used in
reflects the physical infrastructure
s no way to
the physical infrastructure of
no way to turn
physical infrastructure of modern
way to turn that
infrastructure of modern data
to turn that single
of modern data centers
turn that single server
modern data centers clean
that single server into
data centers clean insertion
single server into a
centers clean insertion points
server into a racs
clean insertion points for
into a racs or
insertion points for proxy
a racs or turn
jgroups wasn t designed
racs or turn a
points for proxy devices
or turn a set
wasn t designed to
turn a set of
t designed to support
library used in mfs
for proxy devices exist
a set of racs
designed to support large
proxy devices exist on
and the current mfs
to support large numbers
set of racs into
devices exist on the
the current mfs implementation
support large numbers of
of racs into a
exist on the high
large numbers of overlapping
racs into a raps
numbers of overlapping groups
speed lambda links that
lambda links that interconnect
and if configured to
links that interconnect individual
if configured to do
that interconnect individual data
configured to do so
interconnect individual data centers
mfs design and related
individual data centers to
design and related work
it would be easy
and related work the
data centers to each
related work the core
centers to each other
work the core of
would be easy to
there has been a
be easy to bridge
has been a great
easy to bridge the
maelstrom can operate as
been a great deal
the core of mfs
to bridge the gap
can operate as either
bridge the gap if
operate as either a
the gap if vendors
as either a passive
gap if vendors and
either a passive or
if vendors and platform
core of mfs follows
a great deal of
a passive or active
vendors and platform builders
of mfs follows a
and platform builders wanted
passive or active device
great deal of work
mfs follows a design
platform builders wanted to
or active device on
deal of work on
follows a design common
builders wanted to do
active device on these
of work on p
a design common to
wanted to do so
device on these links
design common to many
common to many mobile
p pubsub and content
to many mobile file
pubsub and content delivery
of the three problems
and content delivery platforms
the three problems of
content delivery platforms in
structured partitioned service reliable
delivery platforms in recent
partitioned service reliable array
platforms in recent years
many mobile file systems
three problems of tcp
often oriented towards content
oriented towards content filtering
towards content filtering in
content filtering in document
filtering in document streams
maelstrom solves the first
solves the first two
a good example is
the first two throughput
good example is siena
first two throughput collapse
two throughput collapse and
throughput collapse and realtime
a system that has
collapse and realtime recovery
system that has become
and realtime recovery delays
that has become popular
x y z search
has become popular in
y z search for
realtime recovery delays while
become popular in wan
recovery delays while operating
popular in wan settings
z search for digital
delays while operating as
search for digital camera
while operating as a
for digital camera figure
operating as a passive
as a passive device
a passive device that
passive device that does
device that does not
that does not intervene
does not intervene in
not intervene in the
example of raps of
intervene in the critical
of raps of racs
which use techniques such
in the critical communication
use techniques such as
the critical communication path
techniques such as wholefile
systems in this class
the service assigns a
such as wholefile caching
service assigns a digital
in this class incur
assigns a digital camera
this class incur steep
a digital camera search
class incur steep overheads
digital camera search request
incur steep overheads associated
camera search request to
steep overheads associated with
maelstrom handles the additional
overheads associated with content
handles the additional problem
associated with content filtering
the additional problem of
search request to the
and update logging combined
additional problem of massive
request to the clustered
update logging combined with
problem of massive buffering
to the clustered server
logging combined with asynchronous
of massive buffering requirements
messages often follow circuitous
massive buffering requirements as
often follow circuitous routes
combined with asynchronous writes
the clustered server handling
buffering requirements as well
clustered server handling all
follow circuitous routes from
server handling all ds
to cope with disconnections
circuitous routes from source
cope with disconnections or
at the cost of
routes from source to
the cost of adding
and a load balancer
cost of adding a
a load balancer routes
of adding a point
load balancer routes it
adding a point of
balancer routes it to
from source to destination
with disconnections or intermittent
a point of failure
routes it to the
disconnections or intermittent connectivity
point of failure in
it to the appropriate
of failure in the
to the appropriate process
in high performance settings
failure in the network
the design of mfs
in the network path
design of mfs is
of mfs is closest
these factors would degrade
old and familiar technologies
mfs is closest in
and familiar technologies the
is closest in structure
factors would degrade the
the contributions of this
would degrade the performance
contributions of this paper
familiar technologies the most
closest in structure to
technologies the most standard
in structure to that
degrade the performance of
of this paper are
the most standard form
structure to that of
most standard form of
this paper are as
standard form of system
paper are as follows
the performance of the
to that of coda
form of system support
performance of the replicated
of system support for
of the replicated application
system support for building
support for building a
for building a raps
building a raps of
a raps of racs
the spread multicast system
raps of racs would
spread multicast system implements
end fec for long
of racs would draw
multicast system implements lightweight
racs would draw on
system implements lightweight groups
would draw on virtual
distance communication between data
draw on virtual synchrony
communication between data centers
and argue that the
argue that the rate
that the rate sensitivity
group computing model developed
the rate sensitivity of
computing model developed at
rate sensitivity of fec
model developed at cornell
sensitivity of fec codes
developed at cornell in
of fec codes and
at cornell in the
fec codes and the
codes and the opacity
the groups seen by
and the opacity of
groups seen by applications
the opacity of their
seen by applications are
opacity of their implementations
a host acting as
of their implementations present
host acting as a
their implementations present major
acting as a client
implementations present major obstacles
as a client of
present major obstacles to
a client of an
major obstacles to their
client of an mfs
obstacles to their usage
of an mfs file
s and used today
by applications are an
an mfs file system
and used today to
applications are an illusion
mfs file system runs
used today to run
a gateway appliance that
file system runs a
today to run the
gateway appliance that transparently
there is really only
appliance that transparently aggregates
to run the new
that transparently aggregates traffic
run the new york
transparently aggregates traffic and
the new york and
aggregates traffic and encodes
new york and swiss
traffic and encodes over
is really only one
system runs a user
york and swiss stock
and encodes over the
really only one use
and swiss stock exchange
only one use of
swiss stock exchange systems
one use of qsm
encodes over the resulting
which receives file system
use of qsm in
over the resulting high
the french air traffic
of qsm in our
receives file system operations
qsm in our target
file system operations intercepted
in our target settings
system operations intercepted by
our target settings gives
french air traffic control
target settings gives rise
air traffic control system
settings gives rise to
we describe layered interleaving
operations intercepted by a
gives rise to potentially
intercepted by a kernel
and the us navy
rise to potentially large
by a kernel module
the us navy s
a new fec scheme
to potentially large numbers
new fec scheme used
potentially large numbers of
interacting with the vfs
us navy s aegis
fec scheme used by
large numbers of overlapping
scheme used by maelstrom
numbers of overlapping communication
with the vfs layer
used by maelstrom where
of overlapping communication groups
by maelstrom where for
the vfs layer of
maelstrom where for constant
vfs layer of the
ibm s websphere platform
as we have seen
s websphere platform and
where for constant encoding
websphere platform and the
layer of the local
platform and the windows
of the local file
and the windows vista
for constant encoding overhead
the primary goal is
constant encoding overhead the
primary goal is to
encoding overhead the latency
goal is to support
overhead the latency of
the windows vista clustering
the local file system
windows vista clustering system
the latency of packet
is to support data
vista clustering system also
we adopt the same
to support data replication
latency of packet recovery
clustering system also use
adopt the same approach
support data replication in
of packet recovery degrades
system also use versions
the same approach to
also use versions of
packet recovery degrades gracefully
use versions of the
recovery degrades gracefully as
versions of the model
same approach to intercepting
data replication in scalable
degrades gracefully as losses
approach to intercepting vfs
gracefully as losses get
although developers can t
to intercepting vfs operations
as losses get burstier
developers can t access
intercepting vfs operations as
in which sets of
can t access the
vfs operations as lbfs
which sets of components
we discuss implementation considerations
t access the internal
sets of components are
access the internal mechanisms
of components are interconnected
the internal mechanisms directly
components are interconnected and
we built two versions
making use of the
are interconnected and cooperate
built two versions of
use of the kernel
the other popular standard
interconnected and cooperate to
two versions of maelstrom
of the kernel module
other popular standard uses
the kernel module provided
popular standard uses a
kernel module provided as
standard uses a state
module provided as part
and cooperate to perform
one runs in user
provided as part of
cooperate to perform requests
runs in user mode
machine approach to guarantee
as part of the
approach to guarantee stronger
part of the arla
to guarantee stronger durability
while the other runs
components sets are normally
the other runs within
sets are normally colocated
other runs within the
leslie lamport s paxos
of the arla afs
runs within the linux
when a service is
within the linux kernel
a service is replicated
the arla afs client
lamport s paxos algorithm
we evaluate maelstrom on
each of its constituent
evaluate maelstrom on emulab
of its constituent components
which is implemented in
its constituent components will
is implemented in scalable
constituent components will need
implemented in scalable file
components will need to
in scalable file systems
will need to replicate
scalable file systems and
need to replicate its
the cache manager maintains
to replicate its portion
and show that it
replicate its portion of
show that it provides
its portion of the
that it provides near
portion of the service
it provides near lossless
cache manager maintains a
file systems and other
of the service state
provides near lossless tcp
manager maintains a cache
systems and other ultrareliable
maintains a cache of
if qsm is used
and other ultrareliable server
a cache of recently
ip throughput and latency
qsm is used to
other ultrareliable server designs
throughput and latency over
accessed mfs files on
and latency over lossy
mfs files on the
latency over lossy links
files on the local
is used to disseminate
on the local disk
used to disseminate updates
and recovers packets with
one architecture could support
recovers packets with latency
architecture could support both
packets with latency independent
this results in a
with latency independent of
results in a pattern
when a vfs operation
could support both of
latency independent of the
in a pattern of
a vfs operation is
support both of these
vfs operation is intercepted
both of these powerful
operation is intercepted for
of these powerful technologies
is intercepted for a
a pattern of communication
independent of the rtt
intercepted for a file
a natural option would
of the rtt of
pattern of communication groups
for a file that
natural option would be
the rtt of the
of communication groups that
a file that is
option would be to
rtt of the link
communication groups that are
file that is not
would be to offer
of the link and
groups that are exactly
that is not in
be to offer them
the link and the
that are exactly overlapped
is not in the
to offer them in
link and the rate
not in the cache
offer them in the
and the rate in
each replicated component will
them in the context
the rate in any
replicated component will have
it is retrieved in
in the context of
rate in any single
component will have one
is retrieved in full
the context of ws
in any single channel
will have one or
retrieved in full from
have one or more
in full from the
one or more associated
full from the appropriate
or more associated groups
m odel loss model
from the appropriate server
delivering update streams to
update streams to its
packet loss typically occurs
and the vfs operation
streams to its replicas
loss typically occurs at
if you re replicating
the vfs operation is
typically occurs at two
you re replicating data
vfs operation is then
occurs at two points
re replicating data within
operation is then resumed
at two points in
a datacenter will typically
replicating data within some
two points in an
mfs uses the writeback
data within some form
datacenter will typically host
points in an end
within some form of
will typically host many
some form of group
typically host many services
close semantics first implemented
semantics first implemented in
first implemented in the
you can just as
implemented in the andrew
can just as easily
in the andrew file
just as easily imagine
each with a disjoint
end communication path between
the andrew file system
as easily imagine that
with a disjoint set
communication path between two
easily imagine that it
a disjoint set of
path between two data
imagine that it has
disjoint set of components
between two data centers
that it has a
it has a subject
has a subject name
a subject name in
and often deployed on
as shown in figure
subject name in a
often deployed on disjoint
when a dirty file
name in a publish
deployed on disjoint sets
a dirty file is
on disjoint sets of
dirty file is closed
area network connecting them
disjoint sets of nodes
network connecting them and
connecting them and at
advantages with this type
the entire file contents
with this type of
entire file contents are
this type of process
file contents are transferred
in cases where two
them and at the
contents are transferred to
cases where two services
and at the receiving
are transferred to the
where two services are
at the receiving end
transferred to the server
data can be anything
two services are co
located on the same
on the same node
loss in the lambda
in the lambda link
the lambda link can
lambda link can occur
link can occur for
though scheme for minimising
can occur for many
scheme for minimising bandwidth
we ll still see
occur for many reasons
for minimising bandwidth utilisation
ll still see heavy
minimising bandwidth utilisation when
still see heavy overlap
bandwidth utilisation when transferring
utilisation when transferring files
when transferring files is
transferring files is not
files is not used
but unless the degree
is not used in
unless the degree of
dirty or degraded fiber
not used in mfs
the degree of replication
w e b te
degree of replication is
malfunctioning or misconfigured equipment
e b te c
of replication is identical
b te c h
although it is orthogonal
te c h n
low receiver power and
c h n o
it is orthogonal to
h n o l
is orthogonal to mfs
there may be two
receiver power and burst
n o l o
orthogonal to mfs adaptation
o l o g
to mfs adaptation and
may be two cases
mfs adaptation and could
l o g i
power and burst switching
o g i e
and burst switching contention
nodes that host both
adaptation and could be
g i e s
burst switching contention are
i e s concerns
switching contention are some
that host both services
and could be added
e s concerns experience
contention are some reasons
s concerns experience with
and hence both sets
concerns experience with corba
hence both sets of
could be added to
experience with corba even
both sets of qsm
with corba even good
sets of qsm groups
be added to further
corba even good ideas
added to further improve
even good ideas can
to further improve performance
good ideas can be
ideas can be used
can be used in
and nodes that just
be used in ways
the server that stores
used in ways that
nodes that just host
server that stores a
in ways that developers
that stores a file
ways that developers dislike
stores a file is
that developers dislike and
a file is responsible
developers dislike and ultimately
file is responsible for
that just host one
dislike and ultimately reject
is responsible for maintaining
just host one of
responsible for maintaining the
host one of them
for maintaining the mutual
maintaining the mutual consistency
the mutual consistency of
a good example of
mutual consistency of the
cluster management systems use
good example of this
consistency of the copies
example of this occurred
management systems use groups
of the copies cached
of this occurred when
systems use groups for
this occurred when the
the copies cached by
use groups for purposes
occurred when the corba
copies cached by clients
groups for purposes other
when the corba community
for purposes other than
the corba community decided
it records which clients
purposes other than component
corba community decided to
records which clients cache
other than component replication
community decided to tackle
which clients cache the
decided to tackle replication
clients cache the file
such as tracking node
to tackle replication for
as tracking node status
tackle replication for fault
loss can also occur
replication for fault tolerance
and is responsible for
for fault tolerance but
is responsible for notifying
tracking node status and
can also occur at
fault tolerance but then
responsible for notifying them
tolerance but then stumbled
also occur at receiving
but then stumbled by
occur at receiving end
node status and launching
for notifying them of
then stumbled by presenting
status and launching applications
hosts within the destination
stumbled by presenting the
notifying them of changes
within the destination data
by presenting the technology
the destination data center
presenting the technology to
these groups will span
mfs implements a variation
the technology to developers
groups will span large
technology to developers in
these are usually cheap
implements a variation of
are usually cheap commodity
a variation of the
will span large numbers
to developers in a
usually cheap commodity machines
variation of the scheme
cheap commodity machines prone
of the scheme used
commodity machines prone to
developers in a way
machines prone to temporary
in a way that
prone to temporary overloads
a way that was
to temporary overloads that
the scheme used by
temporary overloads that cause
scheme used by coda
overloads that cause packets
way that was much
span large numbers of
when a file is
that was much too
that cause packets to
was much too limiting
cause packets to be
much too limiting for
packets to be dropped
large numbers of nodes
a file is retrieved
too limiting for general
to be dropped by
limiting for general use
be dropped by the
file is retrieved from
perhaps the entire cluster
dropped by the kernel
is retrieved from the
by the kernel in
retrieved from the server
such groups overlap with
the kernel in bursts
tolerance mechanism is based
groups overlap with everything
mechanism is based on
the server issues a
is based on the
server issues a limited
based on the virtual
the result is an
on the virtual synchrony
result is an environment
the virtual synchrony model
is an environment in
an environment in which
environment in which there
obliging it to inform
this loss mode occurs
it to inform the
loss mode occurs with
to inform the client
but the programming tools
in which there will
the programming tools built
which there will be
programming tools built over
inform the client through
tools built over this
the client through a
built over this model
client through a callback
mode occurs with udp
there will be a
over this model prevent
through a callback if
will be a hierarchy
this model prevent developers
a callback if another
based traffic but not
model prevent developers from
callback if another host
traffic but not with
prevent developers from using
if another host modifies
but not with tcp
developers from using threads
another host modifies the
host modifies the file
if the callback promise
which advertises receiver windows
the callback promise expires
advertises receiver windows to
callback promise expires without
receiver windows to prevent
guis or other direct
promise expires without a
windows to prevent end
or other direct end
qsm is highly effective
expires without a callback
is highly effective in
without a callback being
highly effective in supporting
a callback being issued
what are typical loss
effective in supporting this
are typical loss rates
in supporting this style
typical loss rates on
supporting this style of
the client must revalidate
loss rates on long
this style of use
client must revalidate the
must revalidate the file
revalidate the file before
the file before using
file before using it
the answer to this
answer to this question
the cache consistency algorithm
or even prebuilt libraries
cache consistency algorithm is
to this question is
consistency algorithm is described
this question is surprisingly
recover in y inter
question is surprisingly hard
algorithm is described in
in the corba approach
is surprisingly hard to
region protocol y intra
is described in more
described in more detail
in more detail in
more detail in section
a developer who obeys
developer who obeys this
consisting of a small
who obeys this long
of a small set
obeys this long list
a small set of
this long list of
small set of servers
long list of constraints
set of servers to
list of constraints can
of servers to which
of constraints can do
servers to which client
constraints can do lockstep
to which client systems
can do lockstep replication
which client systems connect
do lockstep replication of
adaptive rpc library the
lockstep replication of a
rpc library the fundamental
replication of a program
library the fundamental difference
of a program for
the fundamental difference between
a program for tolerance
fundamental difference between mfs
program for tolerance of
level multicast is vectored
difference between mfs and
for tolerance of hardware
between mfs and other
tolerance of hardware faults
mfs and other file
multicast is vectored through
and other file systems
is vectored through a
other file systems we
vectored through a server
file systems we have
systems we have described
we have described is
have described is in
which multicasts it to
the scheme doesn t
described is in the
multicasts it to its
scheme doesn t protect
is in the communication
it to its peers
doesn t protect against
in the communication between
t protect against software
the communication between the
these filter the ordered
communication between the cache
filter the ordered multicast
between the cache manager
the ordered multicast stream
the cache manager and
ordered multicast stream and
cache manager and servers
multicast stream and relay
stream and relay messages
and relay messages back
relay messages back out
developers regard the standard
messages back out to
while lbfs uses a
regard the standard as
back out to receivers
lbfs uses a variant
the standard as rigid
uses a variant of
standard as rigid and
a variant of the
this approach can support
as rigid and limited
variant of the nfs
approach can support huge
of the nfs rpc
can support huge numbers
the nfs rpc protocol
they need fault tolerance
support huge numbers of
huge numbers of groups
numbers of groups with
of groups with irregular
groups with irregular overlap
but not in this
with irregular overlap patterns
not in this very
in this very narrow
this very narrow form
but the servers are
the servers are a
servers are a point
are a point of
a point of contention
systems like the isis
like the isis toolkit
and the indirect communication
the indirect communication pathway
indirect communication pathway introduces
popular during the early
communication pathway introduces potentially
uses a customised rpc
pathway introduces potentially high
during the early and
introduces potentially high latencies
the early and mid
these considerations convinced us
unlike coda s rpc
considerations convinced us that
convinced us that a
us that a new
that a new system
a new system was
the rpc used in
new system was needed
rpc used in mfs
used in mfs incorporates
in mfs incorporates novel
mfs incorporates novel features
incorporates novel features to
qsm implements a approach
novel features to allow
also used virtual synchrony
implements a approach similar
features to allow it
used virtual synchrony but
a approach similar to
to allow it to
virtual synchrony but had
approach similar to spread
allow it to adapt
synchrony but had fewer
similar to spread s
it to adapt to
but had fewer limitations
to spread s lightweight
to adapt to network
spread s lightweight group
adapt to network variability
s lightweight group abstraction
they supported many of
supported many of the
many of the mechanisms
of the mechanisms needed
but without a separate
the mechanisms needed to
without a separate server
mechanisms needed to build
the mfs rpc library
of lost packets fig
mfs rpc library is
a separate server group
needed to build and
rpc library is implemented
to build and manage
library is implemented on
build and manage a
we define a region
is implemented on top
define a region of
implemented on top of
a region of overlap
and manage a raps
region of overlap to
manage a raps of
of overlap to be
on top of the
loss rates on teragrid
a raps of racs
overlap to be a
top of the adaptive
rates on teragrid determine
to be a set
of the adaptive transport
and their successes have
be a set of
their successes have clearly
perhaps because such links
a set of nodes
because such links are
set of nodes with
such links are a
successes have clearly demonstrated
links are a relatively
have clearly demonstrated the
the adaptive transport protocol
of nodes with approximately
are a relatively recent
clearly demonstrated the model
a relatively recent addition
nodes with approximately the
relatively recent addition to
demonstrated the model s
recent addition to the
with approximately the same
addition to the networking
approximately the same group
the model s effectiveness
in discussing mfs rpc
the same group membership
to the networking landscape
the networking landscape and
isis is no longer
we give an overview
is no longer available
give an overview of
no longer available as
an overview of the
networking landscape and their
longer available as a
landscape and their ownership
available as a product
and their ownership is
overview of the parts
their ownership is still
of the parts of
ownership is still mostly
the parts of atp
is still mostly restricted
parts of atp which
still mostly restricted to
yet many critical systems
under the assumptions of
of atp which are
mostly restricted to commercial
many critical systems continue
restricted to commercial organizations
critical systems continue to
to commercial organizations disinclined
systems continue to use
commercial organizations disinclined to
continue to use isis
organizations disinclined to reveal
atp which are most
the assumptions of section
disinclined to reveal such
which are most relevant
based solutions or other
to reveal such information
are most relevant to
solutions or other virtual
most relevant to mfs
or other virtual synchrony
our cluster should be
one source of information
cluster should be nicely
source of information is
should be nicely tiled
of information is teragrid
be nicely tiled by
other virtual synchrony implementations
nicely tiled by regions
atp and its design
and its design motivations
its design motivations have
design motivations have been
qsm uses regions for
motivations have been described
machine approach as used
uses regions for multicast
approach as used in
regions for multicast dissemination
have been described in
for multicast dissemination and
been described in more
multicast dissemination and for
described in more detail
an optical network interconnecting
in more detail in
as used in the
dissemination and for recovery
used in the paxos
more detail in our
in the paxos algorithm
and for recovery of
the paxos algorithm is
detail in our earlier
paxos algorithm is also
for recovery of lost
algorithm is also becoming
recovery of lost packets
is also becoming more
in our earlier work
optical network interconnecting major
also becoming more popular
network interconnecting major supercomputing
employing different protocols for
interconnecting major supercomputing sites
different protocols for each
major supercomputing sites in
protocols for each purpose
the key insight is
supercomputing sites in the
key insight is that
sites in the us
insight is that these
protocol node x recover
is that these successes
node x recover in
that these successes use
the hypothesis underlying atp
teragrid has a monitoring
hypothesis underlying atp is
has a monitoring framework
underlying atp is that
a monitoring framework within
atp is that adapting
monitoring framework within which
is that adapting to
framework within which ten
that adapting to network
within which ten sites
adapting to network variation
these successes use similar
to network variation by
which ten sites periodically
network variation by structuring
ten sites periodically send
variation by structuring applications
sites periodically send each
by structuring applications according
successes use similar ideas
x recover in x
use similar ideas but
recover in x region
similar ideas but in
structuring applications according to
periodically send each other
in x region figure
ideas but in ways
applications according to modes
but in ways very
according to modes is
gbps streams of udp
in ways very different
to modes is not
streams of udp packets
ways very different from
hierarchical recovery in qsm
modes is not always
of udp packets and
very different from what
is not always appropriate
a group spans multiple
different from what the
udp packets and measure
group spans multiple regions
from what the corba
packets and measure the
and can sometimes lead
what the corba fault
and measure the resulting
each region has an
can sometimes lead to
measure the resulting loss
region has an associated
sometimes lead to poor
the resulting loss rate
has an associated structure
lead to poor performance
what we need today
an associated structure of
associated structure of token
we need today is
structure of token rings
need today is a
today is a modern
shows the results of
is a modern revisiting
the results of an
a modern revisiting of
results of an experiment
modern revisiting of this
of an experiment in
to recover from packet
an experiment in which
revisiting of this technology
experiment in which modeless
recover from packet loss
in which modeless adaptation
of this technology that
which modeless adaptation over
each site measures the
qsm uses a hierarchical
site measures the loss
uses a hierarchical structure
measures the loss rate
a hierarchical structure of
the loss rate to
hierarchical structure of token
loss rate to every
this technology that draws
modeless adaptation over atp
structure of token rings
adaptation over atp achieves
technology that draws on
over atp achieves higher
rate to every other
atp achieves higher bandwidth
to every other site
achieves higher bandwidth utilisation
that draws on group
higher bandwidth utilisation than
every other site once
bandwidth utilisation than we
other site once an
utilisation than we will
site once an hour
than we will concentrate
draws on group communication
we considered using other
on group communication but
resulting in a total
considered using other structures
we will concentrate on
group communication but packages
in a total of
communication but packages it
will concentrate on a
but packages it in
concentrate on a system
packages it in a
on a system with
it in a way
but token rings produce
a system with a
loss rate measurements collected
in a way that
rate measurements collected across
system with a single
token rings produce a
a way that developers
measurements collected across the
way that developers perceive
collected across the network
with a single server
rings produce a more
that developers perceive as
across the network every
developers perceive as solving
the network every hour
mfs is designed to
produce a more predictable
perceive as solving their
is designed to support
as solving their most
designed to support multiple
solving their most pressing
a more predictable traffic
shows that between nov
their most pressing scalability
to support multiple mfs
more predictable traffic pattern
most pressing scalability problems
support multiple mfs file
pressing scalability problems and
multiple mfs file servers
scalability problems and that
the importance of this
problems and that flexibly
importance of this will
and that flexibly matches
of this will become
that flexibly matches their
this will become clear
modal adaptation modeless adaptation
flexibly matches their preferred
will become clear later
matches their preferred styles
their preferred styles and
preferred styles and tools
other kinds of persistent
the basic structure is
true bandwidth bandwidth used
basic structure is illustrated
kinds of persistent objects
structure is illustrated in
is illustrated in figure
at the highest level
the user simply designs
user simply designs a
qsm circulates tokens around
simply designs a data
circulates tokens around sets
designs a data structure
tokens around sets of
a data structure and
around sets of regions
data structure and employs
structure and employs multicast
and employs multicast technology
employs multicast technology to
multicast technology to transmit
aggregating information that can
technology to transmit updates
of all such measurements
information that can be
to transmit updates to
all such measurements were
that can be used
transmit updates to the
can be used by
updates to the group
be used by a
such measurements were over
to the group members
used by a group
by a group sender
a group sender to
group sender to retransmit
which apply them in
sender to retransmit packets
apply them in the
to retransmit packets that
them in the same
retransmit packets that were
in the same order
packets that were missed
the same order everywhere
that were missed by
were missed by entire
missed by entire regions
can be done on
be done on any
of them were over
done on any desired
on any desired copy
a token circulates to
token circulates to provide
circulates to provide loss
to provide loss recovery
examples of updates include
provide loss recovery at
of updates include a
loss recovery at the
updates include a stock
recovery at the level
include a stock trade
at the level of
after eliminating a single
a stock trade or
the level of nodes
eliminating a single site
stock trade or stock
level of nodes belonging
trade or stock market
of nodes belonging to
or stock market quote
nodes belonging to the
belonging to the region
that dropped incoming packets
dropped incoming packets steadily
a new object detected
incoming packets steadily at
new object detected by
packets steadily at a
object detected by radar
steadily at a rate
detected by radar in
at a rate of
by radar in an
if regions become large
radar in an air
in an air traffic
an air traffic control
air traffic control system
qsm partitions them into
partitions them into smaller
them into smaller rings
a communication to or
communication to or from
to or from an
this is illustrated in
or from an aircraft
is illustrated in figure
or the addition of
the addition of a
addition of a node
of a node to
in the experiments reported
a node to a
the experiments reported in
node to a distributed
experiments reported in this
to a distributed data
reported in this paper
of the remainder were
a distributed data structure
the remainder were over
distributed data structure containing
data structure containing an
no token ring ever
structure containing an index
token ring ever grows
containing an index of
ring ever grows larger
an index of pending
ever grows larger than
index of pending orders
grows larger than about
of pending orders in
pending orders in an
orders in an online
in an online warehouse
data replication can be
replication can be remarkably
can be remarkably cheap
and the system uses
the system uses single
system uses single and
uses single and two
with modern technology and
modern technology and small
technology and small updates
true bandwidth bandwidth used
we plan to experiment
plan to experiment with
to experiment with larger
experiment with larger configurations
with larger configurations and
computer chrony service can
these numbers may look
larger configurations and will
chrony service can run
numbers may look small
configurations and will work
service can run at
may look small in
and will work with
can run at rates
look small in absolute
will work with deeper
run at rates well
small in absolute terms
work with deeper hierarchies
at rates well in
rates well in excess
well in excess of
but they are sufficient
they are sufficient to
the qsm recovery protocol
are sufficient to bring
qsm recovery protocol uses
sufficient to bring tcp
recovery protocol uses tokens
protocol uses tokens to
uses tokens to track
tokens to track message
to track message status
ip throughput crashing down
throughput crashing down on
crashing down on high
conventional wisdom states that
wisdom states that optical
states that optical links
that optical links do
optical links do not
links do not drop
do not drop packets
the token carries ack
token carries ack and
carries ack and nak
ack and nak information
ordered updates per second
grade optical equipment is
aggregated over the nodes
optical equipment is configured
even if an update
equipment is configured to
over the nodes below
if an update requires
the nodes below each
an update requires a
is configured to shut
nodes below each ring
update requires a large
configured to shut down
requires a large message
to shut down beyond
token rings avoid the
shut down beyond bit
rings avoid the kinds
down beyond bit error
it s possible to
avoid the kinds of
s possible to maintain
the kinds of ack
possible to maintain rates
beyond bit error rates
to maintain rates of
bit error rates of
maintain rates of thousands
nak implosion problems with
rates of thousands per
implosion problems with which
of thousands per second
problems with which reliable
thousands per second on
with which reliable multicast
per second on typical
which reliable multicast protocols
second on typical hardware
reliable multicast protocols traditionally
multicast protocols traditionally have
protocols traditionally have struggled
one out of a
out of a trillion
the virtual synchrony and
of a trillion bits
virtual synchrony and statemachine
but problems of their
synchrony and statemachine models
problems of their own
and statemachine models show
statemachine models show how
models show how a
if a message is
show how a tremendous
the reliability of the
how a tremendous range
a message is lost
reliability of the lambda
a tremendous range of
of the lambda network
tremendous range of application
the lambda network is
range of application requirements
lambda network is clearly
of application requirements can
network is clearly not
application requirements can map
is clearly not equal
requirements can map down
clearly not equal to
can map down to
not equal to the
the sender may not
map down to a
equal to the sum
sender may not find
down to a rigorously
to the sum of
may not find out
to a rigorously precise
the sum of its
not find out for
a rigorously precise execution
sum of its optical
find out for quite
modal versus modeless adaptation
out for quite a
versus modeless adaptation with
of its optical parts
rigorously precise execution model
for quite a while
modeless adaptation with atp
which in turn can
in turn can be
the left graph shows
it s less reliable
left graph shows performance
this isn t a
graph shows performance with
isn t a major
shows performance with modal
t a major issue
s less reliable by
a major issue because
less reliable by orders
major issue because most
reliable by orders of
issue because most message
performance with modal adaptation
turn can be used
by orders of magnitude
because most message losses
can be used to
most message losses can
and the right graph
be used to validate
the right graph shows
used to validate a
right graph shows a
applications and protocols such
to validate a platform
message losses can be
graph shows a scheme
and protocols such as
shows a scheme in
protocols such as tcp
a scheme in which
because the models have
scheme in which there
the models have formal
in which there are
models have formal specifications
which there are four
ip which expect extreme
losses can be corrected
there are four classes
you can test the
are four classes of
can test the correctness
four classes of messages
test the correctness of
classes of messages being
the correctness of an
of messages being sent
correctness of an implementation
messages being sent simultaneously
which expect extreme reliability
can be corrected locally
expect extreme reliability from
and even use theorem
extreme reliability from the
even use theorem provers
reliability from the high
the lowest line corresponds
use theorem provers to
through cooperation among receivers
theorem provers to assist
lowest line corresponds to
provers to assist developers
line corresponds to the
to assist developers in
speed network are instead
assist developers in testing
network are instead subjected
corresponds to the highest
the basic idea is
developers in testing their
are instead subjected to
to the highest priority
basic idea is to
in testing their most
instead subjected to unexpectedly
idea is to perform
testing their most critical
subjected to unexpectedly high
is to perform recovery
their most critical application
dark horizontal lines represent
most critical application components
horizontal lines represent operating
to perform recovery as
to unexpectedly high loss
lines represent operating modes
perform recovery as locally
unexpectedly high loss rates
represent operating modes on
one reason that we
recovery as locally as
reason that we lack
as locally as possible
operating modes on the
that we lack this
modes on the left
we lack this sort
these numbers reflect the
lack this sort of
numbers reflect the loss
reflect the loss rate
and the highest priority
the loss rate specifically
the highest priority of
loss rate specifically experienced
highest priority of data
this sort of support
rate specifically experienced by
priority of data being
sort of support today
if a message is
of support today is
a message is available
specifically experienced by udp
of data being sent
support today is that
message is available within
today is that vendors
is available within the
experienced by udp traffic
data being sent during
is that vendors and
available within the same
that vendors and platform
within the same token
by udp traffic on
being sent during a
vendors and platform developers
the same token ring
and platform developers worry
sent during a second
platform developers worry that
during a second on
developers worry that these
some process that has
worry that these forms
process that has a
that these forms of
that has a a
these forms of replication
has a a a
forms of replication haven
a a a c
of replication haven t
a a c ac
replication haven t achieved
udp traffic on an
a second on the
a c ac ab
haven t achieved huge
traffic on an end
second on the right
c ac ab abc
t achieved huge market
ac ab abc bc
achieved huge market success
ab abc bc b
the modeless scheme achieves
abc bc b c
end path and may
modeless scheme achieves higher
as the experience with
scheme achieves higher utilisation
the experience with corba
path and may not
bc b c b
experience with corba sidebar
and may not generalize
b c b figure
with corba sidebar describes
may not generalize to
not generalize to tcp
generalize to tcp packets
the common object request
common object request broker
object request broker architecture
groups overlap to form
request broker architecture offers
overlap to form regions
broker architecture offers a
architecture offers a fault
we do not know
mb of data sent
do not know if
nodes belong to the
not know if packets
tolerant groups mechanism that
belong to the same
because it always has
to the same region
it always has messages
the same region if
always has messages to
same region if they
has messages to send
region if they have
know if packets were
groups mechanism that was
if they have similar
while the modal scheme
mechanism that was based
the modal scheme is
that was based on
modal scheme is dependent
they have similar group
scheme is dependent on
have similar group membership
is dependent on a
was based on the
dependent on a rapid
based on the virtual
on a rapid and
if packets were dropped
on the virtual synchrony
packets were dropped within
the virtual synchrony model
qsm currently uses an
were dropped within the
a rapid and accurate
dropped within the optical
currently uses an unreliable
within the optical network
uses an unreliable ip
the optical network or
an unreliable ip multicast
optical network or at
rapid and accurate estimate
the corba standard is
and accurate estimate of
corba standard is widely
accurate estimate of the
standard is widely viewed
estimate of the available
since a single group
network or at intermediate
is widely viewed as
of the available bandwidth
a single group may
the available bandwidth in
single group may span
available bandwidth in order
group may span multiple
bandwidth in order to
widely viewed as rigid
or at intermediate devices
may span multiple regions
in order to select
viewed as rigid and
at intermediate devices within
order to select its
to send to group
to select its correct
send to group g
select its correct operating
as rigid and limited
intermediate devices within either
its correct operating mode
devices within either data
a node multicasts a
within either data center
node multicasts a message
i believe that the
multicasts a message to
believe that the corba
a message to each
that the corba community
though it s unlikely
the corba community erred
it s unlikely that
corba community erred by
message to each of
s unlikely that they
community erred by embedding
to each of the
erred by embedding a
each of the regions
by embedding a powerful
of the regions separately
unlikely that they were
embedding a powerful solution
that they were dropped
a powerful solution into
they were dropped at
powerful solution into a
these graphs are reproduced
were dropped at the
solution into a tool
graphs are reproduced from
dropped at the end
into a tool mismatched
a tool mismatched to
our approach makes it
tool mismatched to developer
approach makes it easy
mismatched to developer needs
makes it easy to
it easy to aggregate
easy to aggregate messages
many of the measurements
to aggregate messages across
web services move beyond
of the measurements lost
aggregate messages across different
the measurements lost just
an equivalent modal scheme
measurements lost just one
services move beyond corba
messages across different groups
lost just one or
move beyond corba in
other experiments have shown
just one or two
beyond corba in many
experiments have shown that
one or two packets
corba in many ways
have shown that modeless
or two packets whereas
shown that modeless adaptation
if a node has
two packets whereas kernel
that modeless adaptation can
but the corba community
a node has two
the corba community s
node has two messages
nic losses are known
has two messages to
corba community s failed
modeless adaptation can achieve
losses are known to
adaptation can achieve improvements
are known to be
can achieve improvements of
community s failed effort
two messages to send
s failed effort to
messages to send to
failed effort to implement
to send to a
known to be bursty
effort to implement virtual
send to a pair
to implement virtual synchrony
to a pair of
implement virtual synchrony carries
a pair of groups
virtual synchrony carries an
pair of groups g
synchrony carries an important
carries an important lesson
an important lesson to
important lesson to current
lesson to current researchers
which overlap in region
overlap in region r
any technology offered to
technology offered to developers
offered to developers must
and it is possible
loss occurred on paths
it is possible to
occurred on paths where
is possible to construct
on paths where levels
possible to construct cases
paths where levels of
to construct cases in
to developers must support
then while transmitting to
where levels of optical
construct cases in which
developers must support the
while transmitting to r
levels of optical link
cases in which the
must support the programming
of optical link utilization
the node can batch
support the programming styles
in which the improvement
node can batch these
the programming styles they
which the improvement is
can batch these messages
programming styles they prefer
the improvement is even
batch these messages together
improvement is even greater
management policies a scalable
policies a scalable services
apps send to a
work on adaptation in
send to a send
on adaptation in mobile
to a send to
adaptation in mobile file
a scalable services architecture
were consistently lower than
scalable services architecture for
in mobile file systems
services architecture for building
mobile file systems has
architecture for building raps
file systems has generally
for building raps of
systems has generally relied
a send to b
building raps of racs
send to b group
raps of racs alone
to b group senders
has generally relied on
b group senders a
generally relied on modal
of racs alone isn
group senders a b
relied on modal schemes
ruling out congestion as
racs alone isn t
senders a b c
out congestion as a
a b c region
congestion as a possible
b c region senders
as a possible cause
c region senders a
alone isn t enough
region senders a ab
senders a ab ac
a ab ac abc
a conclusion supported by
ab ac abc b
conclusion supported by dialogue
ac abc b c
supported by dialogue with
abc b c bc
scale systems that will
by dialogue with the
systems that will likely
dialogue with the network
that will likely soon
with the network administrators
will likely soon rely
b c bc region
likely soon rely on
c bc region leader
soon rely on standardized
but our evaluation of
rely on standardized web
bc region leader figure
on standardized web services
our evaluation of atp
standardized web services including
evaluation of atp demonstrated
web services including global
of atp demonstrated that
services including global banks
atp demonstrated that it
to multicast to a
demonstrated that it could
multicast to a group
that it could also
what are some possible
it could also improve
are some possible causes
could also improve the
some possible causes for
also improve the performance
possible causes for such
improve the performance of
causes for such high
the performance of file
the entire us air
qsm sends a copy
for such high loss
sends a copy to
such high loss rates
a copy to each
high loss rates on
copy to each of
loss rates on teragrid
to each of the
performance of file system
entire us air force
each of the underlying
of the underlying regions
a likely hypothesis is
likely hypothesis is device
and the supervisory control
hypothesis is device clutter
the supervisory control and
is device clutter the
supervisory control and data
device clutter the critical
control and data acquisition
clutter the critical communication
and data acquisition systems
partition leader token intrapartition
data acquisition systems that
leader token intrapartition token
acquisition systems that operate
token intrapartition token partition
systems that operate the
the critical communication path
that operate the us
intrapartition token partition figure
operate the us power
critical communication path between
we discuss the implementation
communication path between nodes
discuss the implementation of
path between nodes in
the implementation of modeless
between nodes in different
implementation of modeless adaptation
nodes in different data
of modeless adaptation in
in different data centers
modeless adaptation in mfs
different data centers is
adaptation in mfs further
data centers is littered
the us power grid
a hierarchy of token
in mfs further in
centers is littered with
us power grid will
hierarchy of token rings
mfs further in section
is littered with multiple
power grid will also
littered with multiple electronic
grid will also require
with multiple electronic devices
will also require policies
also require policies to
atp is implemented at
require policies to manage
is implemented at user
each of which represents
policies to manage security
implemented at user level
naks ack through upcalls
of which represents a
to manage security keys
which represents a potential
on top of kernel
represents a potential point
qsm is also registered
top of kernel udp
a potential point of
is also registered as
potential point of failure
also registered as a
it has a message
registered as a shell
as a shell extension
another possibility is that
possibility is that such
oriented interface for communication
automated tools for monitoring
is that such loss
tools for monitoring large
that such loss rates
for monitoring large complex
such loss rates may
in which messages of
monitoring large complex systems
which messages of an
large complex systems will
making it possible to
loss rates may be
messages of an arbitrary
complex systems will be
of an arbitrary size
systems will be needed
an arbitrary size can
rates may be typical
arbitrary size can be
may be typical for
size can be reliably
be typical for any
it possible to access
will be needed as
can be reliably transmitted
typical for any large
be reliably transmitted with
be needed as well
reliably transmitted with their
possible to access the
transmitted with their boundaries
to access the communication
scale network where the
access the communication subsystem
network where the cost
the communication subsystem directly
where the cost of
communication subsystem directly from
the cost of immediately
researchers must think about
cost of immediately detecting
with their boundaries preserved
of immediately detecting and
their boundaries preserved at
immediately detecting and fixing
boundaries preserved at the
detecting and fixing failures
must think about how
subsystem directly from the
think about how monitoring
and fixing failures is
about how monitoring and
fixing failures is prohibitively
preserved at the receiver
directly from the windows
how monitoring and management
failures is prohibitively high
monitoring and management policies
from the windows gui
and management policies in
at the receiver s
management policies in different
the receiver s side
policies in different organizations
in different organizations should
different organizations should talk
we found through dialogue
organizations should talk to
an application can send
should talk to one
application can send a
the user can store
talk to one another
found through dialogue with
can send a message
through dialogue with the
send a message synchronously
dialogue with the administrators
a message synchronously or
user can store a
to one another when
with the administrators that
message synchronously or asynchronously
the administrators that the
one another when web
administrators that the steady
another when web services
that the steady loss
when web services interactions
in the latter case
web services interactions cross
the steady loss rate
can store a shortcut
steady loss rate experienced
store a shortcut to
loss rate experienced by
a shortcut to a
rate experienced by the
services interactions cross boundaries
the latter case the
shortcut to a qsm
latter case the sender
to a qsm stream
case the sender provides
experienced by the indiana
a qsm stream in
by the indiana university
qsm stream in the
the indiana university site
the sender provides a
these are tough problems
stream in the file
indiana university site was
sender provides a function
in the file system
university site was due
provides a function to
but they can be
a function to be
they can be solved
function to be executed
site was due to
to be executed when
was due to a
be executed when transmission
due to a faulty
executed when transmission of
to a faulty line
when transmission of the
at cornell we recently
transmission of the message
click to attach a
a faulty line card
cornell we recently developed
of the message completes
to attach a previewer
we recently developed astrolabe
attach a previewer or
and the measurements showed
a previewer or a
the measurements showed that
and the send operation
measurements showed that the
a scalable technology for
showed that the error
scalable technology for distributed
that the error persisting
previewer or a viewer
the send operation itself
technology for distributed monitoring
the error persisting over
for distributed monitoring and
error persisting over at
or a viewer to
send operation itself is
distributed monitoring and control
persisting over at least
a viewer to an
operation itself is non
monitoring and control that
over at least a
viewer to an event
and control that has
at least a three
to an event stream
control that has attracted
least a three month
that has attracted tremendous
this is similar to
a three month period
has attracted tremendous interest
the overall architecture is
is similar to the
attracted tremendous interest and
overall architecture is summarized
similar to the queued
tremendous interest and attention
architecture is summarized in
to the queued rpc
points for loss rates
is summarized in figure
the queued rpc developed
for loss rates on
researchers at other institutions
queued rpc developed for
loss rates on high
at other institutions are
rpc developed for rover
the system is single
other institutions are working
institutions are working on
are working on other
working on other promising
on other promising solutions
haul networks are provided
networks are provided by
are provided by the
provided by the back
calability isn t just
isn t just a
t just a technology
we use a windows
bone networks of tier
use a windows i
it s also a
s also a mindset
also a mindset with
atp also allows the
a mindset with ramifications
also allows the sender
global crossing reports average
allows the sender to
crossing reports average loss
the sender to attach
reports average loss rates
henceforth referred to as
mindset with ramifications at
sender to attach a
average loss rates between
referred to as an
with ramifications at many
to attach a priority
to as an i
ramifications at many levels
attach a priority to
a priority to each
priority to each message
to ensure true scalability
to collect all asynchronous
to control the order
collect all asynchronous i
control the order in
web services platforms must
the order in which
services platforms must begin
order in which the
platforms must begin to
in which the queued
including notifications of any
must begin to standardize
which the queued messages
begin to standardize application
the queued messages are
notifications of any received
to standardize application architectures
queued messages are transmitted
standardize application architectures that
of any received messages
application architectures that promote
architectures that promote reliability
on four of its
messages are queued at
that promote reliability and
four of its six
promote reliability and interoperability
of its six inter
are queued at the
reliability and interoperability when
queued at the sender
and interoperability when developers
at the sender according
interoperability when developers build
the sender according to
a single core thread
when developers build systems
haul links for the
developers build systems of
links for the month
build systems of systems
for the month of
sender according to their
single core thread synchronously
the month of december
according to their receivers
work with intrinsically distributed
core thread synchronously polls
with intrinsically distributed programs
and each queue is
thread synchronously polls the
each queue is ordered
intrinsically distributed programs that
synchronously polls the i
queue is ordered by
distributed programs that don
is ordered by priority
programs that don t
o queue to retrieve
that don t fit
queue to retrieve incoming
don t fit a
to retrieve incoming messages
messages of the same
t fit a transactional
of the same priority
fit a transactional model
the core thread also
the same priority within
core thread also maintains
same priority within a
thread also maintains an
and must provide responsiveness
priority within a queue
qwest reports loss rates
within a queue are
reports loss rates of
a queue are transmitted
also maintains an alarm
must provide responsiveness guarantees
queue are transmitted in
maintains an alarm queue
provide responsiveness guarantees to
are transmitted in first
responsiveness guarantees to their
guarantees to their users
implemented as a splay
as a splay tree
applications with these sorts
with these sorts of
these sorts of requirements
sorts of requirements are
of requirements are already
requirements are already in
are already in the
atp also allows a
already in the pipeline
also allows a sender
in the pipeline and
allows a sender to
the pipeline and even
a sender to specify
pipeline and even more
and a request queue
sender to specify a
and even more of
to specify a send
even more of them
specify a send timeout
in either direction on
a send timeout for
either direction on its
send timeout for a
direction on its trans
timeout for a message
implemented as a lockfree
more of them are
as a lockfree queue
pacific link for the
of them are on
a lockfree queue with
which causes the transmission
link for the same
them are on drawing
lockfree queue with cas
causes the transmission to
for the same month
are on drawing boards
the transmission to be
on drawing boards in
transmission to be suspended
drawing boards in government
to be suspended if
for requests from the
be suspended if it
suspended if it expires
so that the sender
that the sender can
the sender can react
sender can react to
can react to it
the only option for
we expect privately managed
only option for the
expect privately managed lambdas
option for the web
privately managed lambdas to
for the web services
the core thread polls
an analogous mechanism is
managed lambdas to exhibit
the web services community
core thread polls all
analogous mechanism is available
lambdas to exhibit higher
web services community is
thread polls all queues
mechanism is available for
to exhibit higher loss
services community is to
exhibit higher loss rates
community is to take
higher loss rates due
is to take on
loss rates due to
is available for receive
polls all queues in
to take on the
rates due to the
available for receive operations
all queues in a
take on the challenge
due to the inherent
queues in a round
besides detecting when a
to the inherent tradeoff
if they do so
detecting when a remote
the inherent tradeoff between
robin fashion and processes
when a remote host
solutions will be readily
fashion and processes the
will be readily available
and processes the events
inherent tradeoff between fiber
a remote host is
processes the events sequentially
remote host is inaccessible
web services are going
equipment quality and cost
services are going to
events of the same
send timeouts do not
of the same type
timeouts do not play
the same type are
do not play a
same type are processed
not play a major
type are processed in
play a major role
are processed in batches
a major role in
are going to be
major role in mfs
going to be the
up to the limit
to be the ubiquitous
to the limit determined
an additional use for
the limit determined by
be the ubiquitous platform
as well as the
additional use for timeouts
well as the difficulty
the ubiquitous platform technology
limit determined by a
use for timeouts would
as the difficulty of
for timeouts would be
the difficulty of performing
timeouts would be to
determined by a quantum
would be to detect
difficulty of performing routine
be to detect prefetches
of performing routine maintenance
to detect prefetches which
performing routine maintenance on
ubiquitous platform technology for
detect prefetches which are
routine maintenance on longdistance
prefetches which are not
maintenance on longdistance links
which are not making
platform technology for next
are not making progress
not making progress and
making progress and reissue
progress and reissue a
and reissue a prefetch
generation critical computing systems
reissue a prefetch for
a prefetch for a
prefetch for a different
for a different file
and we ve no
we ve no one
ve no one but
no one but ourselves
end paths as dropping
there is no limit
paths as dropping packets
one but ourselves to
is no limit for
as dropping packets at
but ourselves to blame
no limit for local
dropping packets at rates
ourselves to blame if
limit for local push
atp administers priorities by
packets at rates of
administers priorities by deriving
to blame if these
priorities by deriving an
pull data sender inter
by deriving an estimate
blame if these systems
deriving an estimate for
if these systems don
an estimate for the
these systems don t
estimate for the bandwidth
systems don t work
for the bandwidth available
don t work properly
the bandwidth available between
pull region partition figure
bandwidth available between the
available between the sender
between the sender and
the sender and receiver
do we really want
we really want to
really want to create
recovery inside and across
want to create a
inside and across partitions
in order to minimise
to create a world
order to minimise the
create a world in
to minimise the transmission
copy will forward it
to capture a wide
a world in which
minimise the transmission delay
world in which minor
the transmission delay when
will forward it to
capture a wide range
in which minor computer
transmission delay when a
which minor computer glitches
delay when a new
forward it to the
minor computer glitches shut
it to the process
a wide range of
when a new message
computer glitches shut down
to the process missing
glitches shut down massive
the process missing the
wide range of deployed
a new message is
shut down massive critical
process missing the message
down massive critical applications
new message is sent
range of deployed networks
massive critical applications and
critical applications and in
applications and in which
atp uses a form
and in which hackers
qsm implements a scheme
in which hackers can
implements a scheme originally
uses a form of
which hackers can readily
e xisting r eliability
a scheme originally proposed
a form of rate
hackers can readily disrupt
xisting r eliability o
scheme originally proposed by
can readily disrupt access
r eliability o ptions
originally proposed by zhao
readily disrupt access to
eliability o ptions tcp
each second is divided
disrupt access to banking
second is divided into
access to banking records
ip is the default
is divided into twenty
is the default reliable
divided into twenty send
the default reliable communication
into twenty send periods
air traffic control systems
twenty send periods of
default reliable communication option
even in a large
reliable communication option for
in a large ring
and even shut down
communication option for contemporary
even shut down the
option for contemporary networked
shut down the power
no more than five
for contemporary networked applications
and at most one
more than five nodes
down the power grid
than five nodes cache
five nodes cache any
nodes cache any given
twentieth of the available
cache any given message
of the available bandwidth
time is running out
the available bandwidth is
exclusive embeddings in commodity
available bandwidth is used
embeddings in commodity operating
bandwidth is used during
in commodity operating systems
is used during a
commodity operating systems and
current halfway solutions will
qsm also uses this
halfway solutions will tempt
also uses this idea
used during a single
operating systems and networking
solutions will tempt developers
systems and networking apis
during a single send
uses this idea at
will tempt developers to
a single send period
tempt developers to embark
this idea at the
developers to embark on
idea at the level
to embark on a
at the level of
without such a constraint
most applications requiring reliable
embark on a path
applications requiring reliable communication
on a path that
requiring reliable communication over
a path that will
reliable communication over any
path that will soon
communication over any form
that will soon lead
over any form of
will soon lead many
any form of network
soon lead many of
form of network use
lead many of them
of network use tcp
many of them into
the level of partitions
atp would send as
of them into real
would send as much
them into real trouble
send as much data
each message is cached
as much data as
message is cached in
much data as it
the entire industry clients
is cached in a
data as it could
ip has three major
as it could on
has three major problems
it could on receipt
three major problems when
could on receipt of
major problems when used
on receipt of a
problems when used over
receipt of a low
when used over high
cached in a single
and vendors as well
in a single partition
vendors as well as
as well as the
well as the government
as the government have
the government have a
and this data could
government have a shared
this data could then
have a shared obligation
data could then be
a shared obligation to
could then be buffered
shared obligation to make
then be buffered at
if some partition is
be buffered at an
some partition is missing
buffered at an intermediate
partition is missing a
at an intermediate link
is missing a message
throughput collapse in lossy
obligation to make web
collapse in lossy networks
to make web services
delaying the transmission of
make web services better
the transmission of any
the partition caching it
transmission of any high
partition caching it steps
caching it steps in
s ken birman is
it steps in to
ken birman is a
priority message which might
birman is a professor
message which might be
is a professor in
which might be sent
a professor in the
steps in to resend
ip is unable to
might be sent later
is unable to distinguish
in to resend it
professor in the department
unable to distinguish between
in the department of
to distinguish between ephemeral
the department of computer
distinguish between ephemeral loss
department of computer science
between ephemeral loss modes
the disadvantage of this
if an entire region
ephemeral loss modes due
of computer science at
disadvantage of this scheme
an entire region is
of this scheme is
entire region is missing
this scheme is that
region is missing a
loss modes due to
computer science at cornell
scheme is that heavy
is missing a message
is that heavy contention
science at cornell university
that heavy contention at
modes due to transient
heavy contention at the
due to transient congestion
contention at the sender
the sender becomes involved
at the sender may
contact him at ken
sender becomes involved and
the sender may delay
becomes involved and re
sender may delay a
or bad fiber and
may delay a new
bad fiber and persistent
delay a new message
fiber and persistent congestion
a new message by
new message by as
qsm tokens also carry
message by as much
tokens also carry other
the loss of one
by as much as
loss of one packet
also carry other information
of one packet out
one packet out of
packet out of ten
out of ten thousand
including data used to
of ten thousand is
data used to perform
ten thousand is sufficient
used to perform rate
thousand is sufficient to
to perform rate control
is sufficient to reduce
perform rate control and
sufficient to reduce tcp
rate control and information
regardless of its priority
department of computer engineering
control and information used
and information used to
ip throughput to a
information used to trigger
san jose state university
used to trigger garbage
throughput to a third
this inefficiency of the
to trigger garbage collection
inefficiency of the atp
to a third of
of the atp implementation
a third of its
the atp implementation is
third of its lossless
the overall system configuration
atp implementation is most
overall system configuration is
of its lossless maximum
system configuration is managed
implementation is most visible
configuration is managed by
is most visible when
is managed by what
most visible when there
managed by what we
if one packet is
visible when there is
one packet is lost
when there is contention
by what we call
packet is lost out
there is contention between
what we call the
is contention between different
we call the configuration
contention between different priorities
call the configuration management
between different priorities at
the configuration management service
different priorities at high
is lost out of
priorities at high bandwidth
lost out of a
out of a thousand
throughput collapses to a
collapses to a thirtieth
to a thirtieth of
which handles join and
a thirtieth of the
handles join and leave
thirtieth of the maximum
join and leave requests
mfs implementation the version
implementation the version of
the version of mfs
the root cause of
version of mfs described
root cause of throughput
of mfs described in
cause of throughput collapse
mfs described in this
of throughput collapse is
and uses these to
described in this paper
throughput collapse is tcp
uses these to generate
in this paper is
these to generate a
this paper is implemented
to generate a sequence
ip s fundamental reliance
generate a sequence of
paper is implemented in
a sequence of membership
s fundamental reliance on
is implemented in c
fundamental reliance on loss
implemented in c and
reliance on loss as
in c and runs
on loss as a
sequence of membership views
c and runs on
of membership views for
and runs on freebsd
membership views for each
loss as a signal
views for each multicast
as a signal of
a signal of congestion
the cms also determines
cms also determines and
while recent approaches have
also determines and continuously
recent approaches have sought
determines and continuously updates
approaches have sought to
and continuously updates region
have sought to replace
both the client and
sought to replace loss
continuously updates region boundaries
to replace loss with
the client and server
replace loss with delay
client and server have
loss with delay as
and server have multiple
maintains sequences of region
with delay as a
server have multiple threads
sequences of region views
delay as a congestion
have multiple threads to
of region views for
as a congestion signal
multiple threads to cope
region views for each
threads to cope with
views for each region
to cope with simultaneous
cope with simultaneous file
with simultaneous file system
simultaneous file system requests
and tracks the mapping
tracks the mapping from
the mapping from group
mapping from group views
and the rpc library
from group views to
the rpc library has
group views to region
rpc library has its
views to region views
library has its own
has its own thread
or to specifically identify
to specifically identify loss
therefore there are two
specifically identify loss caused
there are two mandatory
identify loss caused by
are two mandatory thread
the cms runs on
two mandatory thread context
cms runs on a
mandatory thread context switches
loss caused by non
runs on a single
thread context switches on
on a single node
context switches on any
switches on any message
on any message send
any message send or
but we intend to
message send or receive
we intend to replace
send or receive operation
intend to replace this
to replace this with
replace this with a
this with a state
as we shall describe
we shall describe in
shall describe in subsequent
describe in subsequent sections
machine replicated version in
replicated version in the
version in the future
older variants prominently reno
in the future to
variants prominently reno remain
some subsystems have additional
prominently reno remain ubiquitously
subsystems have additional threads
reno remain ubiquitously deployed
the future to eliminate
have additional threads to
future to eliminate the
additional threads to carry
to eliminate the risk
threads to carry out
eliminate the risk of
to carry out background
the risk of single
carry out background processing
recovery delays for real
in the longer term
our experiments were conducted
the longer term we
experiments were conducted with
longer term we will
were conducted with a
term we will move
conducted with a default
we will move to
ip uses positive acknowledgments
with a default client
will move to a
cloudifying source code repositories
uses positive acknowledgments and
a default client cache
positive acknowledgments and retransmissions
default client cache size
move to a hierarchically
acknowledgments and retransmissions to
how much does it
and retransmissions to ensure
much does it cost
to a hierarchically structured
client cache size of
retransmissions to ensure reliability
a hierarchically structured cms
michael siegenthaler hakim weatherspoon
to ensure reliability the
siegenthaler hakim weatherspoon dept
ensure reliability the sender
reliability the sender buffers
the sender buffers packets
sender buffers packets until
of computer science cornell
buffers packets until their
computer science cornell university
packets until their receipt
science cornell university msiegen
until their receipt is
their receipt is acknowledged
receipt is acknowledged by
is acknowledged by the
rpcs with priorities mfs
acknowledged by the receiver
with priorities mfs rpcs
priorities mfs rpcs are
mfs rpcs are implemented
rpcs are implemented on
alarm queue application thread
are implemented on top
and resends if an
implemented on top of
resends if an acknowledgment
queue application thread operating
on top of atp
application thread operating system
top of atp in
if an acknowledgment is
of computer science cornell
thread operating system kernel
of atp in the
operating system kernel implementation
atp in the natural
system kernel implementation qsm
computer science cornell university
an acknowledgment is not
in the natural way
kernel implementation qsm qsm
science cornell university hweather
acknowledgment is not received
implementation qsm qsm request
is not received within
qsm qsm request queue
not received within some
qsm request queue core
received within some time
an rpc request constitutes
request queue core thread
within some time period
rpc request constitutes one
edu abstract cloud computing
request constitutes one message
queue core thread i
abstract cloud computing provides
cloud computing provides us
computing provides us with
and its reply another
provides us with general
o queue socket figure
us with general purpose
a lost packet is
with general purpose storage
lost packet is received
priorities are used to
packet is received in
general purpose storage and
is received in the
purpose storage and server
received in the form
qsm uses a single
in the form of
are used to differentiate
storage and server hosting
used to differentiate types
and server hosting platforms
to differentiate types of
server hosting platforms at
the form of a
differentiate types of rpcs
hosting platforms at a
form of a retransmission
with a core thread
types of rpcs to
platforms at a reasonable
of a retransmission that
a core thread that
a retransmission that arrives
core thread that controls
retransmission that arrives no
thread that controls three
that arrives no earlier
that controls three queues
of rpcs to improve
at a reasonable price
arrives no earlier than
rpcs to improve performance
we explore the possibility
explore the possibility of
the possibility of tapping
possibility of tapping these
of tapping these resources
rtts after the original
tapping these resources for
or those which would
these resources for the
those which would cause
resources for the purpose
and requests from the
for the purpose of
requests from the possibly
which would cause an
the sender has to
from the possibly multithreaded
the purpose of hosting
would cause an interactive
purpose of hosting source
cause an interactive client
sender has to buffer
the possibly multithreaded application
of hosting source code
an interactive client to
hosting source code repositories
interactive client to block
source code repositories for
when we set out
code repositories for individual
has to buffer each
repositories for individual projects
to buffer each packet
for individual projects as
buffer each packet until
are given high priority
we set out to
individual projects as well
each packet until it
set out to implement
projects as well as
packet until it s
rpcs for background activities
out to implement qsm
as well as entire
until it s acknowledged
well as entire open
as entire open source
such as writing back
entire open source communities
our intent was to
as writing back files
intent was to leverage
writing back files to
was to leverage the
back files to the
rtt in lossless operation
to leverage the component
files to the server
leverage the component integration
an analysis of storage
the component integration tools
and it has to
component integration tools available
analysis of storage costs
it has to perform
integration tools available on
has to perform additional
of storage costs is
tools available on the
are performed at low
to perform additional work
storage costs is presented
perform additional work to
performed at low priority
additional work to retransmit
available on the windows
work to retransmit the
on the windows platform
to retransmit the packet
and a complete hosting
so that they do
a complete hosting solution
that they do not
we didn t expect
they do not slow
didn t expect that
do not slow down
t expect that co
not slow down high
retransmit the packet if
complete hosting solution is
the packet if it
hosting solution is built
existence with the managed
packet if it does
with the managed environment
if it does not
the managed environment would
it does not receive
managed environment would require
solution is built and
does not receive the
environment would require any
is built and evaluated
shows the priority levels
not receive the acknowledgment
would require any special
built and evaluated as
the priority levels for
require any special architectural
and evaluated as a
priority levels for different
any special architectural features
evaluated as a proof
levels for different types
any packets that arrive
for different types of
packets that arrive with
qsm is implemented much
that arrive with higher
is implemented much like
different types of rpcs
arrive with higher sequence
implemented much like any
with higher sequence numbers
higher sequence numbers than
assigning priorities to rpcs
sequence numbers than that
priorities to rpcs allows
numbers than that of
to rpcs allows mfs
than that of a
rpcs allows mfs to
that of a lost
allows mfs to adapt
of a lost packet
mfs to adapt to
a lost packet must
to adapt to bandwidth
i ntroduction the advent
the system is coded
ntroduction the advent of
adapt to bandwidth variation
the advent of cloud
system is coded in
lost packet must be
to bandwidth variation in
packet must be queued
bandwidth variation in a
must be queued while
variation in a straightforward
be queued while the
in a straightforward way
queued while the receiver
is coded in c
advent of cloud computing
while the receiver waits
of cloud computing has
the receiver waits for
cloud computing has brought
receiver waits for the
computing has brought us
waits for the lost
all rpcs complete quickly
has brought us a
for the lost packet
brought us a dazzling
the lost packet to
us a dazzling array
lost packet to arrive
a dazzling array of
with or without priorities
dazzling array of public
array of public computing
of public computing services
public computing services that
computing services that can
services that can be
that can be instantly
throughput financial banking application
can be instantly tapped
financial banking application running
be instantly tapped by
banking application running in
instantly tapped by anyone
application running in a
tapped by anyone with
running in a data
by anyone with a
in a data center
anyone with a credit
a data center in
with a credit card
data center in new
a credit card number
center in new york
in new york city
users are spared from
sending updates to a
are spared from having
updates to a sister
spared from having to
to a sister site
from having to invest
a sister site in
having to invest in
corresponding rpc types fetch
sister site in switzerland
to invest in expensive
rpc types fetch attributes
to interface to the
invest in expensive infrastructure
the rtt value between
in expensive infrastructure such
rtt value between these
expensive infrastructure such as
value between these two
interface to the native
callbacks fetch file data
infrastructure such as servers
between these two centers
to the native windows
these two centers is
the native windows asynchronous
directory contents write back
two centers is typically
contents write back directory
native windows asynchronous i
write back directory and
and cooling equipment because
back directory and metadata
cooling equipment because the
directory and metadata updates
equipment because the service
and metadata updates write
because the service provider
metadata updates write back
the service provider takes
updates write back shared
service provider takes care
write back shared files
provider takes care of
back shared files write
and is accessible from
takes care of these
shared files write back
is accessible from any
care of these and
files write back unshared
of these and amortizes
write back unshared files
these and amortizes the
back unshared files prefetch
and amortizes the cost
in the case of
amortizes the cost across
unshared files prefetch file
the case of a
windows understands qsm to
the cost across many
understands qsm to be
cost across many clients
qsm to be the
case of a lost
to be the handler
of a lost packet
be the handler for
files prefetch file data
achieving efficiency through economies
prefetch file data section
efficiency through economies of
the handler for operations
all packets received within
through economies of scale
handler for operations on
packets received within the
for operations on new
operations on new kind
on new kind of
companies are realizing that
new kind of event
are realizing that it
kind of event stream
realizing that it no
that it no longer
it no longer makes
no longer makes sense
longer makes sense to
milliseconds or more between
makes sense to build
or more between the
sense to build and
an application can obtain
independently and may compete
application can obtain handles
more between the original
to build and manage
between the original packet
build and manage all
the original packet send
can obtain handles from
and manage all of
original packet send and
obtain handles from these
by making writes asynchronous
manage all of their
packet send and the
handles from these qsm
send and the receipt
all of their own
and the receipt of
of their own infrastructure
the receipt of its
update logging pushes read
receipt of its retransmission
of its retransmission have
its retransmission have to
and services in the
retransmission have to be
write contention into the
have to be buffered
contention into the future
to be buffered at
and can then invoke
services in the cloud
be buffered at the
can then invoke methods
in the cloud are
buffered at the receiver
to occur at the
then invoke methods on
the cloud are quickly
occur at the next
invoke methods on those
cloud are quickly becoming
at the next log
methods on those handles
the loss of a
on those handles to
are quickly becoming popular
the next log flush
loss of a single
those handles to send
of a single packet
handles to send events
a single packet stops
the designers of little
single packet stops all
designers of little work
packet stops all traffic
of little work incorporated
incoming messages are delivered
little work incorporated a
messages are delivered application
that software development projects
are delivered application requests
software development projects will
work incorporated a low
development projects will turn
stops all traffic in
projects will turn to
all traffic in the
will turn to cloud
traffic in the channel
level priority mechanism at
in the channel to
priority mechanism at the
the channel to the
turn to cloud computing
o event representing a
to cloud computing to
event representing a received
cloud computing to store
representing a received packet
computing to store their
a received packet is
to store their master
received packet is retrieved
channel to the application
mechanism at the ip
store their master code
at the ip packet
their master code repositories
packet is retrieved for
to the application for
the ip packet level
is retrieved for a
ip packet level to
retrieved for a given
either on a project
the application for a
packet level to further
for a given socket
level to further reduce
application for a seventh
to further reduce interference
for a seventh of
further reduce interference between
project basis or as
the socket is drained
a seventh of a
reduce interference between writeback
basis or as part
interference between writeback traffic
or as part of
between writeback traffic and
as part of a
writeback traffic and other
seventh of a second
socket is drained to
part of a larger
traffic and other network
is drained to minimize
of a larger migration
and other network traffic
a larger migration of
other network traffic sent
larger migration of a
network traffic sent by
migration of a sourceforge
traffic sent by the
drained to minimize the
a sequence of such
sent by the client
sequence of such blocks
to minimize the probability
of such blocks can
minimize the probability of
such blocks can have
even small code repositories
the probability of loss
small code repositories represent
blocks can have devastating
code repositories represent a
can have devastating effect
repositories represent a huge
have devastating effect on
represent a huge investment
several aspects of the
a huge investment of
aspects of the architecture
huge investment of developerhours
devastating effect on a
of the architecture are
effect on a high
the architecture are noteworthy
architecture are noteworthy because
so the need to
are noteworthy because of
the need to store
priority levels for mfs
throughput system where every
need to store this
noteworthy because of their
levels for mfs rpcs
system where every spare
to store this data
because of their performance
where every spare cycle
store this data durably
of their performance implications
symbolic names are given
every spare cycle counts
this data durably and
names are given for
data durably and reliably
are given for the
durably and reliably is
given for the priority
qsm assigns priorities to
and reliably is obvious
in applications with many
assigns priorities to different
for the priority levels
applications with many fine
priorities to different types
less obvious are the
to different types of
obvious are the shortcomings
listed from highest to
different types of i
are the shortcomings of
from highest to lowest
a lost packet can
highest to lowest priority
the shortcomings of traditional
lost packet can potentially
shortcomings of traditional storage
packet can potentially trigger
of traditional storage systems
can potentially trigger a
the third column gives
potentially trigger a butterfly
the basic idea is
trigger a butterfly effect
basic idea is that
a butterfly effect of
idea is that when
third column gives the
butterfly effect of missed
is that when an
column gives the section
effect of missed deadlines
gives the section in
of missed deadlines along
the section in which
missed deadlines along a
section in which the
that when an i
deadlines along a distributed
in which the corresponding
along a distributed workflow
which the corresponding rpc
protect against data loss
the corresponding rpc types
we retrieve all events
corresponding rpc types are
retrieve all events from
but they are neither
rpc types are described
all events from the
they are neither cheap
overloaded networks and end
are neither cheap nor
types are described in
events from the i
neither cheap nor simple
are described in detail
hosts can exhibit continuous
can exhibit continuous packet
exhibit continuous packet loss
especially when developers and
when developers and server
determine the type of
developers and server administrators
with each lost packet
and server administrators are
the type of each
each lost packet driving
server administrators are geographically
lost packet driving the
administrators are geographically spread
packet driving the system
are geographically spread thin
driving the system further
asynchronous writeback though it
the system further and
and then place it
system further and further
then place it in
further and further out
place it in an
and further out of
writeback though it reduces
it in an appropriate
further out of sync
we focus on the
though it reduces bandwidth
focus on the costs
it reduces bandwidth consumption
in an appropriate priority
out of sync with
on the costs of
an appropriate priority queue
the costs of moving
update logging is fundamentally
of sync with respect
logging is fundamentally unsuitable
sync with respect to
is fundamentally unsuitable for
with respect to its
fundamentally unsuitable for use
costs of moving source
respect to its real
of moving source code
the system processes queued
unsuitable for use at
moving source code repositories
system processes queued events
source code repositories to
processes queued events in
for use at high
code repositories to the
queued events in priority
use at high bandwidth
repositories to the cloud
events in priority order
to the cloud as
the cloud as an
massive buffering needs for
since it imposes a
cloud as an example
buffering needs for high
it imposes a delay
as an example of
needs for high throughput
imposes a delay on
an example of moving
for high throughput applications
example of moving services
a delay on transmitting
of moving services in
by prioritizing incoming i
delay on transmitting updates
moving services in general
on transmitting updates to
ip uses fixed size
transmitting updates to the
uses fixed size buffers
services in general to
updates to the server
in general to the
fixed size buffers at
general to the cloud
size buffers at receivers
buffers at receivers to
systems using update logging
at receivers to prevent
using update logging must
especially collaborative open source
receivers to prevent overflows
update logging must therefore
collaborative open source projects
logging must therefore switch
must therefore switch to
therefore switch to a
and by prioritizing control
the sender never pushes
by prioritizing control packets
sender never pushes more
prioritizing control packets over
never pushes more unacknowledged
control packets over data
pushes more unacknowledged data
packets over data we
such an endeavor includes
switch to a synchronous
more unacknowledged data into
over data we reduce
unacknowledged data into the
data we reduce delays
data into the network
we reduce delays in
into the network than
reduce delays in reacting
the network than the
delays in reacting to
network than the receiver
in reacting to packet
than the receiver is
reacting to packet loss
the receiver is capable
to packet loss or
receiver is capable of
to a synchronous writes
an endeavor includes many
packet loss or other
is capable of holding
a synchronous writes when
endeavor includes many costs
loss or other control
synchronous writes when bandwidth
writes when bandwidth is
when bandwidth is high
the most critical of
most critical of which
the size of the
critical of which is
size of the fluctuating
of which is storage
of the fluctuating window
which is storage since
we will see that
with a threshold controlling
the fluctuating window at
a threshold controlling switches
will see that this
is storage since that
fluctuating window at the
storage since that is
window at the sender
since that is the
at the sender is
that is the simplest
the sender is bounded
is the simplest and
see that this slashes
threshold controlling switches between
sender is bounded by
the simplest and likely
that this slashes system
controlling switches between the
is bounded by the
simplest and likely first
switches between the two
bounded by the size
and likely first component
between the two modes
by the size of
likely first component to
the pros and cons
the size of the
pros and cons of
size of the buffer
and cons of using
of the buffer at
cons of using threads
the buffer at the
of using threads in
buffer at the receiver
using threads in eventoriented
first component to be
the mode switch also
threads in eventoriented systems
component to be moved
in eventoriented systems are
mode switch also changes
eventoriented systems are hotly
switch also changes the
systems are hotly debated
also changes the semantics
changes the semantics of
we set an agenda
the semantics of the
set an agenda for
semantics of the file
an agenda for demonstrating
of the file system
the quantity of inflight
threads turned out to
quantity of inflight unacknowledged
turned out to be
agenda for demonstrating the
of inflight unacknowledged data
and the developers of
for demonstrating the financial
the developers of coda
inflight unacknowledged data has
developers of coda have
demonstrating the financial storage
of coda have noted
unacknowledged data has to
coda have noted that
data has to be
have noted that undetected
has to be extremely
noted that undetected mode
to be extremely high
that undetected mode changes
be extremely high for
undetected mode changes can
extremely high for the
mode changes can surprise
the financial storage and
out to be a
financial storage and computing
to be a bad
storage and computing costs
changes can surprise the
high for the flow
be a bad idea
and computing costs of
can surprise the user
for the flow to
computing costs of moving
surprise the user in
the flow to saturate
although we used threads
costs of moving source
we used threads rather
of moving source code
used threads rather casually
moving source code repositories
threads rather casually in
source code repositories to
rather casually in the
code repositories to the
casually in the first
flow to saturate the
the user in undesirable
repositories to the cloud
in the first year
to saturate the network
user in undesirable ways
the first year of
first year of our
in section ii we
year of our effort
since the size of
section ii we explain
the size of the
ii we explain what
size of the receiver
we explain what it
that version of the
of the receiver window
explain what it means
version of the system
what it means to
the receiver window limits
it means to store
receiver window limits the
of the system was
means to store a
window limits the sending
to store a code
limits the sending envelope
store a code repository
the system was annoyingly
a code repository in
such as cache inconsistencies
code repository in the
as cache inconsistencies arising
repository in the cloud
it plays a major
in the cloud and
plays a major role
the cloud and why
a major role in
cloud and why there
major role in determining
and why there are
cache inconsistencies arising due
system was annoyingly process
role in determining tcp
why there are cost
inconsistencies arising due to
was annoyingly process requests
there are cost advantages
arising due to unexpectedly
annoyingly process requests incoming
are cost advantages to
process requests incoming control
due to unexpectedly delayed
requests incoming control outgoing
to unexpectedly delayed writes
cost advantages to doing
the default receiver buffer
incoming control outgoing control
default receiver buffer sizes
control outgoing control outgoing
receiver buffer sizes in
rather than relying on
outgoing control outgoing data
buffer sizes in many
advantages to doing so
than relying on a
control outgoing data feed
relying on a modal
sizes in many standard
outgoing data feed sink
section iii is a
data feed sink limit
on a modal adaptation
in many standard tcp
a modal adaptation scheme
feed sink limit sending
modal adaptation scheme incorporating
sink limit sending rate
adaptation scheme incorporating a
limit sending rate limit
ip implementations are in
sending rate limit concurrency
implementations are in the
rate limit concurrency limit
iii is a case
scheme incorporating a transition
are in the range
incorporating a transition to
in the range of
a transition to update
is a case study
limit concurrency limit window
the range of tens
transition to update logging
a case study on
concurrency limit window size
range of tens of
to update logging when
case study on using
limit window size figure
of tens of kilobytes
update logging when bandwidth
study on using amazon
logging when bandwidth is
on using amazon s
when bandwidth is low
and consequently inadequate receiver
using amazon s s
consequently inadequate receiver buffering
in a pull protocol
inadequate receiver buffering is
mfs uses a modeless
receiver buffering is the
to host some popular
buffering is the first
a pull protocol a
uses a modeless asynchronous
host some popular open
is the first hurdle
a modeless asynchronous writeback
the first hurdle faced
modeless asynchronous writeback mechanism
first hurdle faced by
some popular open source
hurdle faced by most
popular open source communities
registers the intent to
which is active at
faced by most practical
the intent to send
is active at all
intent to send with
active at all bandwidth
by most practical deployments
and includes a cost
to send with a
at all bandwidth levels
send with a sink
includes a cost analysis
with a sink that
a natural solution is
a sink that may
natural solution is to
just as with update
solution is to increase
in section iv we
is to increase the
section iv we present
as with update logging
sink that may be
to increase the size
that may be controlled
increase the size of
may be controlled by
iv we present an
the size of the
we present an implementation
size of the receiver
present an implementation that
of the receiver buffers
an implementation that ties
be controlled by a
when an application performs
implementation that ties subversion
an application performs an
that ties subversion to
application performs an operation
ties subversion to s
performs an operation that
controlled by a policy
an operation that changes
in many cases the
by a policy limiting
operation that changes a
many cases the receiving
a policy limiting the
that changes a file
cases the receiving end
policy limiting the send
end servers running on
limiting the send rate
servers running on amazon
such as a write
running on amazon s
host may not have
as a write or
may not have the
on amazon s ec
when the sink is
not have the spare
a write or metadata
have the spare memory
write or metadata update
the spare memory capacity
the sink is ready
and using yahoo s
spare memory capacity to
sink is ready to
using yahoo s zookeeper
memory capacity to buffer
is ready to send
yahoo s zookeeper for
capacity to buffer the
s zookeeper for consistency
to buffer the entire
create directory and so
it issues an upcall
buffer the entire bandwidth
directory and so on
in section v we
section v we evaluate
app elements of the
v we evaluate the
delay product of the
elements of the protocol
we evaluate the performance
product of the long
of the protocol stack
evaluate the performance of
the protocol stack f
the performance of this
the update is then
performance of this solution
update is then passed
is then passed to
the need for larger
then passed to the
need for larger buffers
o events according to
for larger buffers is
events according to priorities
larger buffers is orthogonal
according to priorities incoming
buffers is orthogonal to
to priorities incoming data
is orthogonal to the
priorities incoming data policy
orthogonal to the flow
incoming data policy get
to the flow control
data policy get messages
passed to the writeback
and in section vi
the flow control mechanisms
policy get messages pre
to the writeback subsystem
in section vi we
flow control mechanisms used
section vi we address
control mechanisms used within
vi we address related
mechanisms used within tcp
which sends it to
o events process timer
sends it to the
events process timer events
it to the server
process timer events register
to the server when
timer events register to
the server when there
events register to send
server when there is
register to send app
when there is sufficient
to send app app
there is sufficient bandwidth
send app app f
we address related work
ip and impacts all
and impacts all variants
impacts all variants equally
asynchronous writeback therefore only
writeback therefore only delays
therefore only delays updates
only delays updates when
delays updates when there
c loudifying s ource
updates when there is
loudifying s ource r
when there is foreground
s ource r epositories
there is foreground traffic
ource r epositories in
r epositories in a
epositories in a revision
one can think of
when bandwidth is high
in a revision control
fec fec encoders are
can think of qsm
a revision control system
think of qsm as
the performance of asynchronous
of qsm as a
performance of asynchronous writeback
qsm as a collection
of asynchronous writeback should
as a collection of
asynchronous writeback should be
fec encoders are typically
a master copy of
a collection of protocol
writeback should be comparable
collection of protocol stacks
should be comparable to
of protocol stacks in
master copy of the
protocol stacks in which
copy of the source
stacks in which components
of the source code
encoders are typically parameterized
be comparable to purely
in which components act
are typically parameterized with
which components act as
typically parameterized with an
components act as both
comparable to purely synchronous
act as both feeds
is stored in a
as both feeds and
stored in a logically
both feeds and as
in a logically centralized
feeds and as sinks
a logically centralized repository
to purely synchronous writes
tuple for each outgoing
but when bandwidth is
the overall structure is
when bandwidth is insufficient
overall structure is of
for each outgoing sequence
each developer checks out
structure is of a
each outgoing sequence of
asynchronous writes will improve
is of a forest
developer checks out and
outgoing sequence of r
checks out and then
sequence of r data
out and then keeps
of a forest of
and then keeps a
a forest of trees
then keeps a working
of r data packets
keeps a working copy
writes will improve the
a working copy on
will improve the performance
working copy on his
a total of r
improve the performance non
copy on his machine
on his machine that
his machine that mirrors
machine that mirrors the
c data and error
that mirrors the repository
data and error correction
o was to reduce
and error correction packets
was to reduce staleness
error correction packets are
to reduce staleness by
the developer edits files
correction packets are sent
reduce staleness by postponing
an implementation without priorities
developer edits files in
implementation without priorities will
staleness by postponing the
without priorities will result
edits files in his
priorities will result in
by postponing the creation
packets are sent over
postponing the creation of
are sent over the
files in his working
will result in the
in his working copy
result in the completion
his working copy and
in the completion times
working copy and periodically
the completion times for
copy and periodically commits
completion times for all
and periodically commits the
sent over the channel
the creation of control
times for all rpcs
creation of control messages
for all rpcs increasing
periodically commits the changes
of control messages until
all rpcs increasing uniformly
control messages until the
commits the changes back
messages until the time
the changes back to
until the time when
changes back to the
the time when transmission
back to the repository
when priorities are used
redundancy information cannot be
time when transmission is
information cannot be generated
when transmission is actually
cannot be generated and
transmission is actually about
and updates his working
a backlog of low
updates his working copy
is actually about to
his working copy to
actually about to take
working copy to reflect
about to take place
priority rpcs will accumulate
copy to reflect the
be generated and sent
to reflect the changes
generated and sent until
reflect the changes made
and sent until all
the changes made by
sent until all r
while the time taken
changes made by other
until all r data
the time taken for
made by other developers
all r data packets
time information is more
time taken for high
r data packets are
information is more accurate
each commit is assigned
data packets are available
commit is assigned a
priority rpcs to complete
and this makes qsm
is assigned a unique
packets are available for
rpcs to complete will
this makes qsm more
are available for sending
to complete will increase
makes qsm more stable
complete will increase more
will increase more gradually
the repository maintains complete
repository maintains complete history
an unintended benefit is
maintains complete history so
our design is based
the latency of packet
design is based on
latency of packet recovery
is based on the
complete history so at
unintended benefit is that
history so at any
benefit is that the
of packet recovery is
based on the assumption
so at any point
is that the pull
packet recovery is determined
that the pull architecture
recovery is determined by
the pull architecture slashes
is determined by the
pull architecture slashes buffering
determined by the rate
architecture slashes buffering and
by the rate at
slashes buffering and memory
the rate at which
buffering and memory overheads
rate at which the
on the assumption that
at any point in
at which the sender
any point in time
which the sender transmits
the assumption that when
point in time it
the sender transmits data
in time it is
as we shall demonstrate
time it is possible
assumption that when bandwidth
it is possible to
that when bandwidth is
is possible to check
when bandwidth is low
turns out to have
possible to check out
generating error correction packets
out to have an
to check out a
error correction packets from
to have an enormous
correction packets from less
check out a working
packets from less than
have an enormous impact
from less than r
an enormous impact on
an assignment of differentiated
out a working copy
assignment of differentiated priorities
enormous impact on performance
of differentiated priorities will
less than r data
differentiated priorities will improve
than r data packets
priorities will improve the
a working copy for
r data packets at
in qsm each element
data packets at the
qsm each element of
packets at the sender
each element of a
at the sender is
element of a protocol
the sender is not
of a protocol stack
sender is not a
a protocol stack acts
is not a viable
protocol stack acts as
not a viable option
stack acts as a
will improve the response
working copy for any
a viable option even
acts as a feed
viable option even though
as a feed that
option even though the
copy for any specified
improve the response times
a feed that has
even though the data
for any specified version
the response times for
feed that has data
though the data rate
any specified version number
response times for interactive
that has data to
the data rate in
times for interactive tasks
has data to send
storing a repository in
data rate in this
a repository in the
if a task which
rate in this channel
a task which predominantly
in this channel is
repository in the cloud
or a sink that
in the cloud eliminates
a sink that can
the cloud eliminates worries
sink that can send
task which predominantly performs
this channel is low
which predominantly performs reads
that can send it
predominantly performs reads executes
cloud eliminates worries of
performs reads executes in
eliminates worries of data
reads executes in parallel
worries of data loss
executes in parallel to
of data loss due
in parallel to a
data loss due to
parallel to a task
loss due to hardware
to a task which
due to hardware failure
a task which performs
task which performs many
which performs many writes
and many play both
many play both roles
but issues of access
issues of access control
of access control and
access control and consistency
control and consistency must
and consistency must still
consistency must still be
the first task will
must still be addressed
first task will receive
task will receive a
will receive a higher
receive a higher share
a higher share of
authorized users should be
higher share of the
users should be able
share of the bandwidth
should be able to
h a b c
be able to commit
rather than creating a
able to commit new
than creating a message
to commit new versions
creating a message and
commit new versions of
a message and handing
new versions of files
message and handing it
versions of files to
and handing it down
of files to the
handing it down to
files to the repository
a b c d
many applications have patterns
it down to the
applications have patterns of
down to the sink
but not edit existing
have patterns of interactive
b c d x
patterns of interactive file
c d x x
of interactive file access
not edit existing history
interactive file access involving
d x x e
a feed registers the
file access involving both
feed registers the intent
access involving both reads
users expect the repository
involving both reads and
x x e f
registers the intent to
expect the repository to
both reads and writes
the repository to be
the intent to send
repository to be consistent
intent to send a
to be consistent and
to send a message
be consistent and for
send a message with
consistent and for any
x e f g
compiling source files involves
and for any changes
a message with the
e f g h
source files involves interspersed
for any changes they
files involves interspersed reads
any changes they make
involves interspersed reads and
changes they make not
interspersed reads and writes
they make not to
message with the sink
f g h x
make not to be
g h x x
but does not issue
h x x a
not to be pre
does not issue concurrent
the message can be
x x a c
message can be created
x a c b
can be created at
not issue concurrent rpcs
a c b e
be created at this
issue concurrent rpcs frequently
c b e d
even in the face
created at this time
b e d a
in the face of
such an application will
the face of cloud
at this time and
an application will have
face of cloud services
application will have improved
of cloud services that
will have improved read
cloud services that offer
have improved read performance
this time and buffered
improved read performance when
time and buffered in
read performance when there
and buffered in the
performance when there is
g g x x
services that offer lesser
buffered in the feed
when there is contention
g x x f
that offer lesser guarantees
there is contention with
x x f h
but the creation may
is contention with other
the creation may also
contention with other applications
x f h x
for these reasons we
creation may also be
f h x x
may also be postponed
but will correspondingly be
h x x b
will correspondingly be penalised
also be postponed until
these reasons we do
be postponed until the
correspondingly be penalised on
postponed until the time
be penalised on writes
until the time when
reasons we do not
the time when the
we do not expect
time when the sink
do not expect that
this does not match
when the sink polls
not expect that clients
does not match our
the sink polls the
expect that clients will
not match our design
sink polls the feed
that clients will be
match our design goal
polls the feed for
clients will be directly
our design goal of
will be directly using
design goal of having
be directly using the
goal of having interactive
directly using the cloud
the feed for messages
separate encoding for odd
using the cloud storage
encoding for odd and
the cloud storage api
for odd and even
feed for messages to
odd and even packets
for messages to transmit
read applications obtain a
cloud storage api anytime
and even packets could
applications obtain a larger
even packets could be
the sink determines its
obtain a larger share
sink determines its readiness
a larger share of
determines its readiness to
larger share of bandwidth
its readiness to send
packets could be operating
storage api anytime soon
readiness to send based
could be operating at
to send based on
be operating at near
send based on a
operating at near full
based on a control
at near full capacity
on a control policy
near full capacity with
we have implemented two
but that they will
full capacity with data
have implemented two solutions
capacity with data from
implemented two solutions to
with data from other
two solutions to this
data from other senders
solutions to this problem
that they will contact
they will contact one
will contact one of
contact one of a
one of a set
based on making writes
fec is also very
of a set of
on making writes asynchronous
is also very susceptible
when the socket at
also very susceptible to
the socket at the
very susceptible to bursty
socket at the root
susceptible to bursty losses
at the root of
a set of front
the root of the
used in several existing
root of the tree
in several existing systems
of the tree is
several existing systems and
the tree is ready
existing systems and incorporated
tree is ready for
end servers that are
systems and incorporated in
is ready for transmission
and incorporated in mfs
servers that are responsible
incorporated in mfs for
that are responsible for
in mfs for the
messages will be recursively
mfs for the purposes
are responsible for enforcing
will be recursively pulled
for the purposes of
be recursively pulled from
the purposes of comparison
recursively pulled from the
responsible for enforcing access
pulled from the tree
for enforcing access control
from the tree of
the tree of protocol
tree of protocol stack
of protocol stack components
which is new to
is a standard encoding
is new to mfs
a standard encoding technique
standard encoding technique used
encoding technique used to
technique used to combat
used to combat bursty
an alternative approach is
to combat bursty loss
and pushing the data
alternative approach is to
pushing the data into
feeds that no longer
approach is to retain
the data into the
where error correction packets
that no longer have
is to retain synchronous
no longer have data
to retain synchronous writes
longer have data to
error correction packets are
data into the cloud
correction packets are generated
have data to send
packets are generated from
but assign priorities according
data to send are
assign priorities according to
to send are automatically
priorities according to some
send are automatically deregistered
according to some notion
these might consist of
are generated from alternate
to some notion of
might consist of virtualized
generated from alternate disjoint
some notion of relative
consist of virtualized server
from alternate disjoint sub
of virtualized server instances
notion of relative importance
virtualized server instances in
of relative importance of
server instances in the
streams of data rather
instances in the cloud
of data rather than
relative importance of processes
sharing and priority i
data rather than from
rather than from consecutive
or traditional physical machines
than from consecutive packets
traditional physical machines owned
physical machines owned by
machines owned by the
owned by the community
existing operating systems and
operating systems and applications
systems and applications generally
and applications generally do
and prone to oscillatory
applications generally do not
prone to oscillatory throughput
generally do not provide
to oscillatory throughput when
with an interleave index
but in either case
do not provide this
in either case their
not provide this information
either case their local
an interleave index of
case their local storage
oscillatory throughput when scaled
their local storage systems
so we have not
local storage systems are
we have not investigated
storage systems are allowed
throughput when scaled up
systems are allowed to
have not investigated it
are allowed to be
the encoder would create
when we decided to
encoder would create correction
not investigated it further
allowed to be cheap
we decided to take
would create correction packets
to be cheap and
create correction packets separately
the cache manager s
correction packets separately from
cache manager s writeback
packets separately from three
manager s writeback thread
separately from three disjoint
s writeback thread divides
be cheap and unresilient
decided to take control
from three disjoint sub
writeback thread divides updates
cheap and unresilient against
to take control over
thread divides updates into
and unresilient against hardware
take control over event
divides updates into metadata
unresilient against hardware failure
control over event processing
updates into metadata operations
the first containing data
over event processing order
first containing data packets
another consideration with any
containing data packets numbered
consideration with any hosting
such as directory modifications
we also eliminated multithreading
with any hosting solution
as directory modifications and
any hosting solution is
directory modifications and file
hosting solution is resource
modifications and file status
solution is resource provisioning
and file status changes
grained scheduling eliminated convoy
scheduling eliminated convoy behavior
open source communities with
eliminated convoy behavior and
source communities with limited
convoy behavior and oscillatory
communities with limited budgets
the two types of
with limited budgets and
two types of operations
limited budgets and private
types of operations are
budgets and private enterprises
of operations are queued
and private enterprises that
operations are queued and
private enterprises that are
are queued and replayed
enterprises that are increasingly
queued and replayed to
behavior and oscillatory throughput
that are increasingly cost
and oscillatory throughput of
and replayed to the
oscillatory throughput of the
replayed to the server
throughput of the sort
sensitive may well prefer
to the server separately
may well prefer to
of the sort that
well prefer to pay
the sort that can
prefer to pay just
sort that can disrupt
to pay just for
that can disrupt reliable
pay just for the
can disrupt reliable multicast
so that a metadata
just for the resources
that a metadata rpc
for the resources they
a metadata rpc can
the resources they use
metadata rpc can proceed
disrupt reliable multicast systems
rpc can proceed in
reliable multicast systems when
can proceed in parallel
the second with data
multicast systems when they
rather than trying to
systems when they run
second with data packets
proceed in parallel with
than trying to budget
when they run at
with data packets numbered
in parallel with a
trying to budget in
they run at high
parallel with a file
to budget in advance
run at high data
with a file writeback
budget in advance what
at high data rates
in advance what they
high data rates on
advance what they are
when an rpc from
data rates on a
what they are going
an rpc from a
rates on a large
they are going to
rpc from a particular
on a large scale
are going to need
from a particular queue
a particular queue completes
cloud computing makes this
computing makes this a
we say that the
makes this a possibility
the last aspect relates
say that the update
last aspect relates to
that the update has
aspect relates to the
the update has been
and increased competition among
relates to the creation
increased competition among providers
to the creation of
update has been committed
competition among providers of
the creation of new
among providers of commodity
creation of new messages
providers of commodity services
has been committed at
of commodity services will
been committed at the
commodity services will ensure
committed at the server
particularly by qsm itself
services will ensure that
will ensure that prices
ensure that prices are
that prices are reasonable
the next update is
readers who have implemented
next update is then
who have implemented multicast
update is then dequeued
have implemented multicast protocols
is then dequeued and
implemented multicast protocols will
c ase s tudy
and the third with
multicast protocols will know
the third with data
protocols will know that
third with data packets
will know that most
with data packets numbered
know that most existing
that most existing systems
most existing systems are
existing systems are push
update logging an asynchronous
logging an asynchronous rpc
an asynchronous rpc for
asynchronous rpc for it
rpc for it is
by far the most
for it is initiated
far the most popular
some layer initiates a
the most popular general
layer initiates a new
most popular general purpose
separating the small update
popular general purpose cloud
the small update logging
general purpose cloud storage
initiates a new message
purpose cloud storage service
a new message at
cloud storage service today
new message at will
storage service today is
which is implemented in
service today is amazon
is implemented in some
today is amazon s
implemented in some mobile
is amazon s s
and lower layers then
in some mobile file
lower layers then buffer
some mobile file sys
layers then buffer that
then buffer that message
buffer that message until
that message until it
message until it can
metadata rpcs from file
we chose to use
rpcs from file writes
chose to use this
from file writes allows
until it can be
file writes allows remote
it can be sent
writes allows remote clients
to use this as
allows remote clients to
use this as a
remote clients to see
this as a basis
clients to see statems
as a basis for
this makes sense under
a basis for cost
makes sense under the
basis for cost studies
sense under the assumption
for cost studies and
under the assumption that
cost studies and for
the assumption that senders
studies and for the
assumption that senders often
and for the implementation
that senders often generate
for the implementation of
senders often generate bursts
the implementation of our
often generate bursts of
implementation of our system
generate bursts of packets
interleaving adds burst tolerance
adds burst tolerance to
burst tolerance to fec
is an appealing choice
the communication subsystem can
an appealing choice because
tolerance to fec but
communication subsystem can smooth
to fec but exacerbates
subsystem can smooth the
fec but exacerbates its
can smooth the traffic
appealing choice because amazon
but exacerbates its sensitivity
choice because amazon also
exacerbates its sensitivity to
because amazon also offers
its sensitivity to sending
smooth the traffic flow
sensitivity to sending rate
the traffic flow and
amazon also offers the
traffic flow and keep
also offers the ec
flow and keep the
to sending rate with
and keep the network
sending rate with an
keep the network interface
rate with an interleave
the network interface busy
with an interleave index
tus changes to files
an interleave index of
changes to files without
so it is possible
to files without having
it is possible to
files without having to
is possible to use
without having to wait
possible to use their
having to wait for
interleave index of i
one consequence is that
to use their services
consequence is that messages
index of i and
is that messages can
of i and an
that messages can linger
i and an encoding
messages can linger for
use their services as
to wait for intervening
their services as a
wait for intervening writequirement
services as a complete
for intervening writequirement that
as a complete hosting
can linger for a
a complete hosting solution
linger for a while
complete hosting solution with
for a while before
hosting solution with low
a while before they
solution with low latency
intervening writequirement that processes
and an encoding rate
while before they are
with low latency access
writequirement that processes wait
an encoding rate of
before they are sent
low latency access to
that processes wait for
latency access to storage
processes wait for writes
not only does this
only does this increase
does this increase memory
this increase memory consumption
rather than sending an
than sending an back
sending an back traffic
but if a message
if a message contains
the sender would have
a message contains current
a similar motivation underlies
message contains current state
sender would have to
similar motivation underlies the
contains current state information
motivation underlies the cache
would have to wait
underlies the cache consisupdate
have to wait for
the cache consisupdate to
to wait for i
cache consisupdate to the
that state may be
consisupdate to the server
state may be stale
the cost analysis is
to the server as
may be stale by
cost analysis is based
the server as soon
be stale by the
analysis is based on
server as soon as
stale by the time
is based on real
as soon as a
by the time it
soon as a file
the time it s
as a file is
world traces taken from
a file is closed
traces taken from the
packets before sending any
taken from the subversion
time it s sent
before sending any redundancy
from the subversion repositories
the cache manager tency
the subversion repositories of
cache manager tency scheme
subversion repositories of popular
manager tency scheme for
repositories of popular open
tency scheme for high
of popular open source
in contrast to this
sending any redundancy information
scheme for high read
popular open source projects
contrast to this usual
to this usual approach
these two obstacles to
two obstacles to using
write contention environments we
subversion represents each revision
obstacles to using fec
contention environments we logs
qsm implements a pull
environments we logs the
implements a pull architecture
we logs the update
to using fec in
logs the update and
using fec in time
represents each revision in
the update and periodically
each revision in a
update and periodically flushes
revision in a repository
and periodically flushes logged
evaluation evaluation of qsm
periodically flushes logged updates
evaluation of qsm could
flushes logged updates to
of qsm could pursue
logged updates to the
qsm could pursue many
updates to the describe
could pursue many directions
to the describe in
in a repository s
sensitive settings rate sensitivity
the describe in section
settings rate sensitivity and
costs of the domain
rate sensitivity and burst
of the domain crossing
a repository s history
the domain crossing between
sensitivity and burst susceptibility
domain crossing between the
and burst susceptibility are
crossing between the application
burst susceptibility are interlinked
between the application and
the chief complexity in
susceptibility are interlinked through
the application and qsm
chief complexity in implementing
regardless of how many
are interlinked through the
complexity in implementing asynchronous
of how many changes
interlinked through the tuning
protocol design and scalability
in implementing asynchronous writeserver
how many changes it
through the tuning knobs
many changes it contains
and interactions between protocol
these systems enable logging
interactions between protocol properties
an interleave of i
between protocol properties and
systems enable logging when
interleave of i and
enable logging when bandwidth
the first for data
logging when bandwidth is
protocol properties and the
of i and a
when bandwidth is low
properties and the managed
i and a rate
as a diff against
and the managed framework
to improve read performance
a diff against previous
and a rate of
improve read performance and
here we focus on
diff against previous revisions
read performance and reduce
we focus on the
performance and reduce write
focus on the latter
and reduce write traffic
and the second for
reduce write traffic by
the second for meta
write traffic by aggregat
our goal is to
provides tolerance to a
goal is to arrive
tolerance to a burst
data such as the
back lies in resolving
to a burst of
lies in resolving dependencies
a burst of up
is to arrive at
such as the author
in resolving dependencies between
burst of up to
resolving dependencies between metadata
to arrive at a
dependencies between metadata operations
of up to c
between metadata operations ing
up to c i
arrive at a deep
metadata operations ing updates
at a deep understanding
operations ing updates to
to c i consecutive
and other revision properties
a deep understanding of
ing updates to the
deep understanding of the
updates to the same
c i consecutive packets
understanding of the performance
to the same file
of the performance limits
our cost analysis is
the performance limits of
cost analysis is based
performance limits of qsm
analysis is based on
limits of qsm when
is based on the
the burst tolerance of
of qsm when operating
burst tolerance of an
qsm when operating at
tolerance of an fec
when operating at high
of an fec code
operating at high data
an fec code can
at high data rates
fec code can be
high data rates with
code can be changed
data rates with large
can be changed by
rates with large numbers
be changed by modulating
based on the sizes
changed by modulating either
with large numbers of
by modulating either the
large numbers of overlapping
modulating either the c
numbers of overlapping groups
either the c or
on the sizes of
the same file in
the sizes of these
same file in the
the c or the
sizes of these files
for reasons of brevity
of these files and
c or the i
file in the log
these files and the
or the i parameters
we are unable to
files and the time
are unable to undertake
and the time at
unable to undertake a
the time at which
in the log before
to undertake a detailed
increasing c enhances burst
time at which each
the log before they
undertake a detailed analysis
c enhances burst tolerance
at which each revision
log before they are
a detailed analysis of
enhances burst tolerance at
detailed analysis of oscillatory
before they are transmitted
analysis of oscillatory phenomena
burst tolerance at the
which each revision was
of oscillatory phenomena in
tolerance at the cost
each revision was committed
oscillatory phenomena in this
and updates to the
at the cost of
phenomena in this paper
updates to the same
the cost of network
looking up the size
to the same file
cost of network and
also called convoys and
of network and encoding
called convoys and broadcast
network and encoding overhead
convoys and broadcast storms
up the size of
the size of these
size of these special
a file may be
potentially worsening the packet
file may be created
worsening the packet loss
these plague many multicast
the packet loss experienced
plague many multicast and
packet loss experienced and
many multicast and pub
loss experienced and reducing
update logging separates communication
of these special files
logging separates communication with
experienced and reducing throughput
separates communication with the
these special files is
communication with the server
special files is only
with the server into
files is only possible
the server into modified
is only possible if
server into modified and
only possible if one
into modified and closed
increasing i trades off
event prioritization eliminated such
i trades off recovery
possible if one has
trades off recovery latency
prioritization eliminated such problems
off recovery latency for
and the length of
recovery latency for better
the length of the
latency for better burst
length of the metadata
for better burst tolerance
of the metadata queue
better burst tolerance without
the metadata queue may
if one has filesystem
eliminated such problems in
one has filesystem level
such problems in the
has filesystem level access
metadata queue may two
burst tolerance without adding
problems in the configurations
tolerance without adding overhead
in the configurations tested
without adding overhead as
the configurations tested by
filesystem level access to
queue may two distinct
level access to the
may two distinct streams
access to the disk
configurations tested by our
adding overhead as mentioned
to the disk on
tested by our experiments
the disk on which
updates to files and
disk on which the
for higher values of
to files and directories
on which the repository
higher values of i
which the repository is
the repository is stored
and all be enough
all be enough to
the encoder has to
be enough to mean
encoder has to wait
so we had to
has to wait for
we had to use
to wait for more
had to use subversion
wait for more data
to use subversion s
for more data packets
use subversion s mirroring
more data packets to
subversion s mirroring capability
data packets to be
s mirroring capability to
packets to be transmitted
mirroring capability to fetch
to be transmitted before
capability to fetch revisions
be transmitted before it
enough to mean that
on varying numbers of
to fetch revisions from
transmitted before it can
to mean that the
varying numbers of nodes
mean that the file
before it can send
fetch revisions from the
that the file update
it can send error
we ll find that
can send error correction
ll find that the
send error correction packets
find that the experiments
the file update would
revisions from the network
that the experiments have
file update would be
the experiments have a
update would be initiated
experiments have a pattern
would be initiated first
once the fec encoding
accessible repository and replay
the fec encoding is
repository and replay them
fec encoding is parameterized
in scenario after scenario
encoding is parameterized with
and replay them against
is parameterized with a
replay them against a
parameterized with a rate
them against a local
with a rate and
against a local copy
a rate and an
these two types of
rate and an interleave
the performance of qsm
and an interleave to
two types of communication
an interleave to tolerate
types of communication are
performance of qsm is
doing this also implicitly
of qsm is ultimately
of communication are scheduled
qsm is ultimately limited
communication are scheduled this
is ultimately limited by
are scheduled this case
interleave to tolerate a
this also implicitly gives
ultimately limited by overheads
also implicitly gives us
limited by overheads associated
implicitly gives us the
to tolerate a certain
gives us the log
tolerate a certain burst
us the log of
a certain burst length
the log of timestamps
certain burst length b
scheduled this case the
by overheads associated with
log of timestamps indicating
this case the file
overheads associated with memory
of timestamps indicating when
associated with memory management
timestamps indicating when each
with memory management in
indicating when each revision
memory management in the
when each revision was
management in the managed
each revision was committed
in the managed environment
case the file update
the file update must
file update must wait
thus it is possible
it is possible to
is possible to calculate
possible to calculate the
to calculate the bandwidth
the more memory in
more memory in use
a file may be
the higher the overheads
higher the overheads of
test activity gc grep
the overheads of the
activity gc grep compile
overheads of the memory
gc grep compile grep
of the memory management
transaction costs of pushing
the memory management subsystem
grep compile grep write
to tolerate a burst
memory management subsystem and
costs of pushing the
management subsystem and the
tolerate a burst of
compile grep write read
of pushing the two
grep write read compile
pushing the two files
write read compile read
the two files for
read compile read write
a burst of length
compile read write gw
two files for each
subsystem and the more
read write gw rc
files for each revision
and the more cpu
write gw rc rw
for each revision into
the more cpu time
gw rc rw synchronous
each revision into s
more cpu time it
rc rw synchronous uniform
cpu time it consumes
rw synchronous uniform priorities
leaving less time for
based on amazon s
less time for qsm
on amazon s current
time for qsm to
amazon s current pricing
for qsm to run
s current pricing structure
these aren t just
shown in table i
all losses occurring in
aren t just garbage
losses occurring in bursts
t just garbage collection
occurring in bursts of
table i a mazon
just garbage collection costs
in bursts of size
i a mazon s
bursts of size less
a mazon s s
of size less than
every aspect of memory
size less than or
aspect of memory management
less than or equal
of memory management gets
than or equal to
memory management gets expensive
or equal to b
equal to b are
to b are recovered
b are recovered with
and the costs grow
are recovered with the
the costs grow linearly
recovered with the same
costs grow linearly in
with the same latency
grow linearly in the
the same latency and
linearly in the amount
same latency and this
in the amount of
latency and this latency
the amount of memory
and this latency depends
amount of memory in
this latency depends on
of memory in use
latency depends on the
depends on the i
on the i parameter
when qsm runs flat
we d like to
cpu cycles are a
d like to parameterize
cycles are a precious
like to parameterize the
are a precious commodity
to parameterize the encoding
parameterize the encoding to
the encoding to tolerate
encoding to tolerate a
to tolerate a maximum
tolerate a maximum burst
minimizing the memory footprint
a maximum burst length
the memory footprint turns
maximum burst length and
memory footprint turns out
burst length and then
footprint turns out to
length and then have
turns out to be
and then have recovery
out to be the
then have recovery latency
to be the key
have recovery latency depend
be the key to
recovery latency depend on
the key to high
latency depend on the
key to high performance
depend on the actual
on the actual burstiness
the actual burstiness of
actual burstiness of the
burstiness of the loss
all results reported here
results reported here come
reported here come from
here come from experiments
come from experiments on
at the same time
from experiments on a
we would like the
would like the encoding
like the encoding to
the encoding to have
encoding to have a
to have a constant
have a constant rate
a constant rate for
constant rate for network
rate for network provisioning
for network provisioning and
not included in the
network provisioning and stability
included in the analysis
cluster of pentium iii
in the analysis is
the analysis is the
analysis is the cost
is the cost of
the cost of fetching
cost of fetching data
of fetching data out
fetching data out of
an fec scheme is
data out of s
fec scheme is required
scheme is required where
is required where latency
required where latency of
to be served to
where latency of recovery
be served to clients
latency of recovery degrades
of recovery degrades gracefully
recovery degrades gracefully as
degrades gracefully as losses
gracefully as losses get
this cost will vary
as losses get burstier
cost will vary depending
will vary depending on
vary depending on how
depending on how much
connected into a single
even as the encoding
into a single broadcast
as the encoding overhead
a single broadcast domain
on how much caching
single broadcast domain using
the encoding overhead stays
how much caching is
encoding overhead stays constant
broadcast domain using a
much caching is done
domain using a switched
caching is done on
is done on the
done on the front
nodes run windows server
and dedicated servers potentially
dedicated servers potentially having
servers potentially having much
potentially having much more
having much more due
much more due to
more due to inexpensive
due to inexpensive sata
to inexpensive sata disks
it is not unreasonable
is not unreasonable to
not unreasonable to assume
unreasonable to assume that
to assume that a
assume that a cache
our benchmark is an
that a cache hit
benchmark is an nary
a cache hit rate
cache hit rate of
hit rate of close
rate of close to
end flow control x
flow control x appliance
control x appliance appliance
x appliance appliance end
linked to the qsm
to the qsm library
running in the same
in the same process
public subversion repositories of
subversion repositories of the
repositories of the debian
of the debian linux
the debian linux community
split flow control fig
debian linux community amount
linux community amount to
community amount to a
amount to a total
to a total of
a total of only
at the maximum possible
the maximum possible rate
flow control options in
control options in maelstrom
the majority of the
majority of the figures
the only outgoing bandwidth
of the figures include
only outgoing bandwidth costs
outgoing bandwidth costs are
bandwidth costs are then
costs are then to
are then to to
then to to replace
lan mtu lambda jumbo
to to replace failed
mtu lambda jumbo mtu
to replace failed frontend
lambda jumbo mtu recipe
replace failed frontend servers
jumbo mtu recipe list
failed frontend servers or
but these intervals are
frontend servers or to
these intervals are sometimes
servers or to synchronize
intervals are sometimes so
or to synchronize replicas
are sometimes so small
to synchronize replicas if
sometimes so small that
synchronize replicas if more
so small that they
replicas if more than
small that they may
if more than one
that they may not
more than one is
they may not always
than one is in
may not always be
one is in use
not always be visible
in the case of
growing cost of memory
the case of ec
cost of memory allocation
the bandwidth costs are
bandwidth costs are actually
costs are actually waived
are actually waived and
actually waived and the
waived and the user
and the user then
the user then pays
user then pays only
then pays only for
pays only for the
only for the traffic
for the traffic between
the traffic between the
traffic between the front
end servers and their
servers and their clients
table ii shows the
ii shows the cost
shows the cost of
the cost of using
cost of using s
for a number of
a number of individual
number of individual open
of individual open source
individual open source projects
throughput as a function
as a function of
a function of the
as well as an
function of the number
well as an aggregate
of the number of
as an aggregate for
the number of nodes
an aggregate for the
repositories of the debian
of the debian community
also shown is an
shown is an estimate
is an estimate for
an estimate for the
estimate for the apache
for the apache software
the apache software foundation
repair packets are injected
packets are injected into
are injected into stream
injected into stream transparently
apache has taken the
into stream transparently iv
has taken the unusual
taken the unusual approach
processor utilization as a
the unusual approach of
utilization as a function
m aelstrom d esign
as a function of
unusual approach of using
aelstrom d esign and
approach of using a
a function of the
d esign and i
of using a single
esign and i mplementation
using a single repository
and i mplementation we
a single repository for
function of the multicast
single repository for all
of the multicast rate
repository for all of
i mplementation we describe
for all of its
mplementation we describe the
all of its projects
we describe the maelstrom
describe the maelstrom appliance
the maelstrom appliance as
maelstrom appliance as a
appliance as a single
both public and restricted
as a single machine
a single machine later
due to access control
to access control restrictions
access control restrictions on
we will show how
control restrictions on some
will show how more
restrictions on some paths
show how more machines
how more machines can
more machines can be
subversion s mirroring tool
machines can be added
s mirroring tool was
can be added to
mirroring tool was unable
be added to the
tool was unable to
added to the appliance
was unable to create
to the appliance to
memory overheads on the
unable to create local
the appliance to balance
overheads on the sender
to create local copy
appliance to balance encoding
on the sender we
to balance encoding load
the sender we begin
balance encoding load and
the complete log of
encoding load and scale
complete log of timestamps
load and scale to
sender we begin by
and scale to multiple
we begin by showing
scale to multiple gigabits
begin by showing that
to multiple gigabits per
by showing that memory
multiple gigabits per second
showing that memory overhead
gigabits per second of
that memory overhead at
per second of traffic
memory overhead at the
overhead at the sender
at the sender is
the sender is a
sender is a central
how much does it
is a central to
much does it cost
a central to throughput
basic mechanism the basic
description monthly storage bandwidth
mechanism the basic operation
monthly storage bandwidth in
the basic operation of
storage bandwidth in bandwidth
basic operation of maelstrom
bandwidth in bandwidth out
operation of maelstrom is
in bandwidth out per
of maelstrom is shown
shows throughput in messages
maelstrom is shown in
is shown in figure
s in experiments with
senders multicasting to a
it intercepts outgoing data
multicasting to a varying
intercepts outgoing data packets
to a varying number
outgoing data packets and
a varying number of
data packets and routes
varying number of receivers
packets and routes them
and routes them to
routes them to the
them to the destination
to the destination data
all of which belong
the destination data center
of which belong to
which belong to a
belong to a single
to a single group
generating and injecting fec
and injecting fec repair
injecting fec repair packets
reads apache software foundation
fec repair packets into
apache software foundation debian
repair packets into the
software foundation debian linux
packets into the stream
with a single sender
foundation debian linux community
into the stream in
the stream in their
stream in their wake
no rate limit was
rate limit was used
a repair packet consists
the sender has more
repair packet consists of
sender has more work
packet consists of a
has more work to
consists of a recipe
more work to do
of a recipe list
work to do than
a recipe list of
to do than the
recipe list of data
do than the receivers
list of data packet
than the receivers and
of data packet identifiers
the receivers and on
data packet identifiers and
receivers and on our
packet identifiers and fec
and on our clusters
identifiers and fec information
and fec information generated
fec information generated from
information generated from these
generated from these packets
isn t fast enough
t fast enough to
fast enough to saturate
enough to saturate the
to saturate the network
in the example in
the example in figure
this information is a
information is a simple
is a simple xor
the size of the
size of the xor
we report the highest
of the xor is
report the highest combined
the xor is equal
the highest combined send
xor is equal to
highest combined send rate
is equal to the
combined send rate that
equal to the mtu
send rate that the
to the mtu of
rate that the system
the mtu of the
that the system could
mtu of the data
the system could sustain
of the data center
system could sustain without
the data center network
could sustain without developing
sustain without developing backlogs
without developing backlogs at
developing backlogs at the
backlogs at the senders
and to avoid fragmentation
to avoid fragmentation of
why does performance decrease
avoid fragmentation of repair
does performance decrease with
fragmentation of repair packets
performance decrease with the
of repair packets we
decrease with the number
repair packets we require
with the number of
packets we require that
the number of receivers
we require that the
require that the mtu
that the mtu of
the mtu of the
mtu of the long
let s focus on
haul network be set
s focus on a
network be set to
be set to a
set to a slightly
to a slightly larger
a slightly larger value
this requirement is easily
requirement is easily satisfied
is easily satisfied in
easily satisfied in practice
since gigabit links very
gigabit links very often
shows that whereas receivers
links very often use
that whereas receivers are
very often use jumbo
whereas receivers are not
often use jumbo frames
receivers are not cpu
use jumbo frames of
jumbo frames of up
frames of up to
and loss rates in
loss rates in this
rates in this experiment
the sender is saturated
and hence is the
hence is the bottleneck
while lan networks have
running this test again
lan networks have standard
this test again in
networks have standard mtus
test again in a
have standard mtus of
again in a profiler
in a profiler reveals
a profiler reveals that
profiler reveals that the
reveals that the percentage
that the percentage of
the percentage of time
percentage of time spent
of time spent in
time spent in qsm
size of repository stored
spent in qsm code
of repository stored in
in qsm code is
repository stored in s
qsm code is decreasing
at the receiving data
the receiving data center
whereas more and more
more and more time
and more time is
the appliance examines incoming
more time is spent
appliance examines incoming repair
time is spent in
examines incoming repair packets
so we based our
incoming repair packets and
is spent in mscorwks
repair packets and uses
we based our analysis
packets and uses them
based our analysis on
and uses them to
our analysis on that
uses them to recover
analysis on that along
them to recover missing
on that along with
to recover missing data
that along with the
recover missing data packets
along with the assumption
with the assumption each
the assumption each revision
assumption each revision data
each revision data file
revision data file would
data file would be
the data packet is
data packet is injected
packet is injected transparently
is injected transparently into
injected transparently into the
transparently into the stream
into the stream to
the stream to the
stream to the receiving
to the receiving end
kib and each revision
recovered data packets will
and each revision property
data packets will typically
each revision property file
packets will typically arrive
shows that the main
will typically arrive out
that the main culprit
the main culprit behind
main culprit behind the
culprit behind the increase
behind the increase of
the increase of overhead
increase of overhead is
of overhead is a
overhead is a figure
order at the end
the averages observed for
averages observed for the
observed for the other
for the other repositories
and hence it is
the other repositories in
hence it is vital
the percentages of the
it is vital that
other repositories in table
is vital that packets
repositories in table ii
percentages of the profiler
vital that packets be
of the profiler samples
that packets be recovered
the profiler samples taken
packets be recovered by
table ii m ost
be recovered by the
ii m ost recent
profiler samples taken from
recovered by the appliance
samples taken from qsm
m ost recent monthly
by the appliance extremely
ost recent monthly cost
taken from qsm and
the appliance extremely quickly
recent monthly cost of
appliance extremely quickly to
monthly cost of storing
extremely quickly to avoid
cost of storing repositories
quickly to avoid triggering
of storing repositories in
from qsm and clr
to avoid triggering mechanisms
storing repositories in s
avoid triggering mechanisms in
qsm and clr dlls
triggering mechanisms in commodity
mechanisms in commodity stacks
in commodity stacks that
commodity stacks that interpret
stacks that interpret out
for individual projects and
individual projects and entire
projects and entire communities
and entire communities software
entire communities software project
communities software project squirrelmail
order arrival as congestion
software project squirrelmail phpmyadmin
arrival as congestion in
memory allocation and garbage
project squirrelmail phpmyadmin subversion
allocation and garbage collection
as congestion in the
and garbage collection overheads
congestion in the network
garbage collection overheads on
squirrelmail phpmyadmin subversion mono
collection overheads on the
phpmyadmin subversion mono kde
overheads on the sender
subversion mono kde hosting
on the sender node
mono kde hosting community
kde hosting community debian
flow control while relaying
hosting community debian linux
control while relaying tcp
community debian linux community
the former grows by
debian linux community apache
linux community apache software
community apache software foundation
apache software foundation monthly
software foundation monthly cost
maelstrom has two flow
has two flow control
two flow control modes
and the latter by
illustrates these two modes
this configuration is typical
configuration is typical of
is typical of the
typical of the host
of the host environment
the host environment expected
host environment expected for
environment expected for our
expected for our target
for our target applications
the appliance treats tcp
ip packets as conventional
packets as conventional ip
as conventional ip packets
conventional ip packets and
ip packets and routes
packets and routes them
and routes them through
routes them through without
of the overhead is
them through without modification
the overhead is the
overhead is the allocation
is the allocation of
the allocation of byte
allocation of byte arrays
of byte arrays to
byte arrays to send
arrays to send in
control to proceed between
to send in the
to proceed between the
send in the application
proceed between the end
ip s semantics are
s semantics are not
semantics are not modified
when the sending endhost
the sending endhost receives
sending endhost receives an
endhost receives an acknowledgment
it can assume that
can assume that the
assume that the receiving
that the receiving end
host successfully received the
successfully received the message
even for the fairly
for the fairly large
the fairly large apache
fairly large apache software
large apache software foundation
of time is spent
maelstrom functions as a
time is spent exclusively
functions as a passive
is spent exclusively on
as a passive device
the current cost of
spent exclusively on copying
current cost of using
exclusively on copying memory
cost of using s
on copying memory in
copying memory in the
snooping outgoing and incoming
memory in the clr
outgoing and incoming traffic
for storage is less
and incoming traffic at
storage is less than
incoming traffic at the
traffic at the data
at the data center
the data center s
data center s edge
center s edge its
even though we used
s edge its failure
though we used our
edge its failure does
we used our own
its failure does not
used our own scatter
it is very unlikely
failure does not disrupt
is very unlikely that
does not disrupt the
very unlikely that any
gather serialization scheme that
not disrupt the flow
serialization scheme that efficiently
unlikely that any vendor
scheme that efficiently uses
disrupt the flow of
that efficiently uses scatter
the flow of packets
that any vendor could
flow of packets between
any vendor could provide
of packets between the
vendor could provide a
packets between the two
could provide a traditional
between the two data
provide a traditional storage
the two data centers
a traditional storage solution
traditional storage solution consisting
storage solution consisting of
the increase in the
solution consisting of scsi
increase in the memory
consisting of scsi disks
in the memory allocation
of scsi disks and
the memory allocation overhead
scsi disks and tape
memory allocation overhead and
disks and tape backup
allocation overhead and the
and tape backup at
overhead and the activity
side appliance acts as
and the activity of
appliance acts as a
tape backup at this
the activity of the
acts as a tcp
activity of the garbage
backup at this price
of the garbage collector
the garbage collector are
garbage collector are caused
collector are caused by
are caused by the
the amount of s
caused by the increasing
by the increasing memory
terminating connections and sending
the increasing memory usage
connections and sending back
and sending back acks
storage required of course
sending back acks immediately
required of course increases
back acks immediately before
of course increases each
acks immediately before relaying
course increases each month
immediately before relaying data
increases each month as
before relaying data on
each month as the
relaying data on appliance
month as the repository
reflectsan increase of the
as the repository grows
increase of the average
of the average number
the average number of
average number of multicasts
number of multicasts pending
but as shown in
of multicasts pending completion
as shown in figure
split mode is extremely
mode is extremely useful
is extremely useful when
extremely useful when endhosts
useful when endhosts have
when endhosts have limited
endhosts have limited buffering
have limited buffering capacity
the increase is roughly
increase is roughly linear
since it allows the
it allows the receive
as developer productivity remains
developer productivity remains constant
side appliance to buffer
appliance to buffer incoming
the cost of storage
to buffer incoming data
a copy is kept
buffer incoming data over
copy is kept by
incoming data over the
is kept by the
data over the highspeed
cost of storage is
kept by the sender
over the highspeed long
of storage is declining
by the sender for
storage is declining exponentially
the sender for possible
sender for possible loss
for possible loss recovery
it also mitigates tcp
notice that memory consumption
that memory consumption grows
memory consumption grows nearly
times faster than the
so if amazon s
start effects for short
faster than the number
if amazon s pricing
than the number of
amazon s pricing stays
the number of messages
s pricing stays competitive
number of messages pending
of messages pending acknowledgement
if we freeze the
maelstrom has to operate
we freeze the sender
term trend is towards
has to operate as
freeze the sender process
trend is towards lower
the sender process and
is towards lower costs
sender process and inspect
to operate as an
process and inspect the
operate as an active
and inspect the contents
as an active device
inspect the contents of
additional costs will be
the contents of the
costs will be incurred
contents of the managed
will be incurred for
of the managed heap
be incurred for front
inserted into the critical
into the critical communication
the critical communication path
critical communication path its
we find that the
communication path its failure
find that the number
path its failure disconnects
that the number of
its failure disconnects the
for the case of
failure disconnects the communication
the case of ec
the number of objects
disconnects the communication path
number of objects in
the communication path between
of objects in memory
communication path between the
objects in memory is
path between the two
in memory is more
between the two data
memory is more than
a standard machine instance
is more than twice
standard machine instance is
more than twice the
machine instance is billed
than twice the number
instance is billed at
twice the number of
the two data centers
the number of multicasts
number of multicasts pending
of multicasts pending acknowledgement
although some of these
some of these have
of these have already
these have already been
have already been acknowledged
while maelstrom respects endto
they haven t yet
haven t yet been
end flow control connections
t yet been garbage
yet been garbage collected
plus data transfer of
or splits them and
splits them and implements
the growing amount of
them and implements its
growing amount of unacknowledged
and implements its own
amount of unacknowledged data
implements its own proxy
of unacknowledged data is
unacknowledged data is caused
data is caused by
is caused by the
caused by the increase
by the increase of
proxy flow control as
per gib in and
flow control as described
the increase of the
control as described above
increase of the average
of the average time
the average time to
average time to acknowledge
time to acknowledge a
to acknowledge a message
it is not designed
is not designed for
not designed for routinely
designed for routinely congested
for routinely congested networks
the addition of fec
addition of fec under
of fec under tcp
discounts are available if
are available if data
available if data transfer
if data transfer exceeds
ip flow control allows
this grows because of
flow control allows it
grows because of the
control allows it to
because of the increasing
allows it to steal
of the increasing time
it to steal bandwidth
the increasing time to
to steal bandwidth from
increasing time to circulate
steal bandwidth from other
time to circulate a
and the instance cost
to circulate a token
the instance cost may
circulate a token around
instance cost may be
bandwidth from other competing
a token around the
from other competing flows
cost may be reduced
other competing flows running
may be reduced to
token around the region
competing flows running without
around the region for
flows running without fec
the region for purposes
running without fec in
region for purposes of
without fec in the
for purposes of state
fec in the link
purposes of state aggregation
though maintaining fairness versus
maintaining fairness versus similarly
fairness versus similarly fec
per hour by paying
hour by paying a
the time to acknowledge
time to acknowledge is
to acknowledge is only
acknowledge is only slightly
is only slightly higher
only slightly higher than
slightly higher than the
higher than the expected
year reservation fee in
reservation fee in advance
friendliness with conventional tcp
s to wait until
this gives an amortized
to wait until the
gives an amortized monthly
ip flows is not
an amortized monthly cost
wait until the next
flows is not a
amortized monthly cost of
until the next token
is not a primary
the next token round
not a primary protocol
a primary protocol design
primary protocol design goal
protocol design goal on
design goal on over
plus the roundtrip time
as we scale up
which are often dedicated
are often dedicated to
roundtrip time becomes dominant
often dedicated to specific
dedicated to specific highvalue
to specific highvalue applications
as we show in
these experiments show that
we show in the
experiments show that the
show in the next
show that the critical
we see evidence for
in the next section
see evidence for this
that the critical factor
evidence for this assertion
the critical factor determining
for this assertion in
critical factor determining performance
this assertion in the
factor determining performance is
assertion in the routine
one instance should be
determining performance is the
in the routine use
performance is the time
instance should be enough
is the time needed
should be enough for
the time needed for
be enough for almost
time needed for the
enough for almost any
needed for the system
the routine use of
for almost any individual
for the system to
almost any individual project
the system to aggregate
any individual project or
system to aggregate state
individual project or moderately
to aggregate state over
project or moderately sized
aggregate state over regions
or moderately sized community
routine use of parallel
use of parallel flows
they shed light on
usage patterns in addition
shed light on a
patterns in addition to
light on a mechanism
in addition to getting
on a mechanism that
addition to getting a
a mechanism that links
and udp blast protocols
to getting a grasp
mechanism that links latency
getting a grasp of
that links latency to
a grasp of the
links latency to throughput
grasp of the costs
of the costs involved
the costs involved in
costs involved in moving
involved in moving a
in moving a repository
via increased memory consumption
moving a repository to
increased memory consumption and
a repository to s
memory consumption and the
consumption and the resulting
and the resulting increase
the resulting increase in
resulting increase in allocation
increase in allocation and
in allocation and garbage
allocation and garbage collection
it is important to
and garbage collection overheads
is important to understand
important to understand the
to understand the usage
understand the usage patterns
especially the rate at
the rate at which
rate at which commits
at which commits take
which commits take place
ms increase in latency
since achieving the consistency
achieving the consistency properties
the consistency properties that
consistency properties that developers
properties that developers expect
that developers expect will
developers expect will require
expect will require a
will require a consistency
both in commercial deployments
mb increase in memory
require a consistency layer
in commercial deployments and
a consistency layer to
increase in memory consumption
commercial deployments and by
consistency layer to be
deployments and by researchers
layer to be built
and by researchers seeking
to be built in
can inflate overheads by
by researchers seeking to
be built in front
researchers seeking to transfer
built in front of
seeking to transfer large
in front of s
to transfer large amounts
transfer large amounts of
large amounts of data
amounts of data over
of data over high
it is crucial that
is crucial that any
crucial that any such
that any such layer
any such layer be
such layer be able
layer be able to
layered interleaving in layered
be able to handle
interleaving in layered interleaving
able to handle the
performance of mfs priorities
to handle the load
of mfs priorities and
handle the load of
mfs priorities and writeback
the load of commits
an fec protocol with
and degrade the throughput
priorities and writeback schemes
fec protocol with rate
degrade the throughput by
the critical statistic to
critical statistic to consider
statistic to consider is
each test consists of
to consider is the
test consists of two
consider is the number
consists of two concurrent
is the number of
of two concurrent processes
the number of simultaneous
two concurrent processes executing
number of simultaneous commits
concurrent processes executing different
is produced by running
processes executing different workloads
produced by running c
one way to alleviate
for centralized revision control
way to alleviate the
centralized revision control system
to alleviate the problem
revision control system such
by running c multiple
mean times to completion
alleviate the problem we
control system such as
running c multiple instances
times to completion are
system such as subversion
to completion are shown
c multiple instances of
ve identified could be
completion are shown with
identified could be to
are shown with standard
multiple instances of an
each commit is assigned
could be to reduce
shown with standard deviations
commit is assigned a
be to reduce the
is assigned a unique
to reduce the latency
reduce the latency of
the latency of state
latency of state aggregation
three different policies for
different policies for writing
policies for writing back
so that it grows
fec protocol simultaneously with
for writing back files
protocol simultaneously with increasing
writing back files are
simultaneously with increasing interleave
back files are listed
with increasing interleave indices
and any change to
that it grows sub
any change to a
increasing interleave indices i
change to a versioned
under uniform or differentiated
to a versioned file
uniform or differentiated priorities
a versioned file is
versioned file is stored
file is stored as
is stored as a
stored as a diff
reads take precedence over
as a diff against
take precedence over writes
a diff against its
this might be achieved
diff against its previous
might be achieved by
against its previous version
be achieved by using
achieved by using a
by using a deeper
values in bold are
using a deeper hierarchy
in bold are of
a deeper hierarchy of
bold are of particular
deeper hierarchy of rings
are of particular significance
a commit must be
commit must be rejected
must be rejected if
and by letting tokens
be rejected if any
by letting tokens in
note that elapsed times
rejected if any of
that elapsed times for
letting tokens in each
elapsed times for write
tokens in each of
times for write workloads
in each of these
if any of the
for write workloads give
each of these rings
write workloads give the
of these rings circulate
workloads give the time
these rings circulate independently
give the time until
any of the versioned
the time until the
of the versioned files
time until the process
this would create a
until the process running
would create a more
the process running the
create a more complex
process running the workload
a more complex structure
running the workload finishes
the versioned files that
versioned files that it
files that it touches
but aggregation latency would
that it touches have
aggregation latency would grow
not when the log
latency would grow logarithmically
when the log is
would grow logarithmically rather
the log is flushed
grow logarithmically rather than
it touches have been
logarithmically rather than linearly
touches have been changed
have been changed in
this is shown in
been changed in an
is shown in figure
changed in an earlier
is reducing state aggregation
in an earlier revision
reducing state aggregation latency
an earlier revision that
state aggregation latency the
earlier revision that the
aggregation latency the only
revision that the developer
latency the only option
that the developer performing
the developer performing the
developer performing the commit
performing the commit was
the commit was unaware
we evaluated two alternative
commit was unaware of
evaluated two alternative approaches
modified and then deleted
but found that neither
this ensures that every
which requires the file
found that neither can
requires the file update
that neither can substitute
the file update rpc
neither can substitute for
file update rpc to
ensures that every conflict
can substitute for lowering
that every conflict gets
substitute for lowering the
update rpc to be
for lowering the latency
every conflict gets resolved
rpc to be cancelled
conflict gets resolved by
to be cancelled if
gets resolved by a
be cancelled if it
lowering the latency of
resolved by a human
cancelled if it is
by a human before
if it is still
a human before becoming
it is still in
human before becoming part
is still in transmission
before becoming part of
still in transmission when
the latency of the
in transmission when the
latency of the recovery
transmission when the remove
of the recovery state
when the remove rpc
the recovery state aggregation
the remove rpc is
becoming part of the
remove rpc is initiated
part of the repository
of the repository s
the repository s state
our first approach varies
first approach varies the
an update to a
approach varies the rate
update to a file
varies the rate of
three instances of an
the rate of aggregation
to a file will
rate of aggregation by
a file will supersede
exclusive locking is required
of aggregation by increasing
file will supersede any
aggregation by increasing the
will supersede any previous
by increasing the rate
supersede any previous queued
increasing the rate at
any previous queued updates
the rate at which
locking is required on
rate at which tokens
is required on commits
at which tokens are
which tokens are released
taking a loose definition
compiles the entire mfs
a loose definition of
the entire mfs file
loose definition of simultaneous
entire mfs file system
definition of simultaneous to
mfs file system and
the first instance with
of simultaneous to be
file system and its
first instance with interleave
simultaneous to be within
system and its rpc
instance with interleave i
to be within one
and its rpc library
be within one minute
this helps only up
helps only up to
only up to a
up to a point
the apache repository had
apache repository had a
repository had a maximum
had a maximum of
simultaneous commits and the
the second with interleave
commits and the debian
files and directories comprising
second with interleave i
and the debian community
ignoring for now that
for now that their
now that their use
that their use of
more than one aggregation
than one aggregation is
one aggregation is underway
aggregation is underway at
and the third with
is underway at a
the third with interleave
underway at a time
third with interleave i
separate repositories allows for
repositories allows for finergrained
none of the files
allows for finergrained locking
and successive tokens perform
of the files are
successive tokens perform redundant
the files are initially
tokens perform redundant work
an aggregate maximum of
files are initially in
are initially in the
initially in the cache
processing all these tokens
this workload performs an
all these tokens is
in determining these numbers
workload performs an intensive
these tokens is costly
performs an intensive pattern
determining these numbers we
an intensive pattern of
these numbers we filtered
intensive pattern of reads
numbers we filtered out
pattern of reads and
we filtered out any
of reads and writes
filtered out any sequences
reads and writes files
out any sequences of
and writes files without
any sequences of multiple
fec encoding is simply
writes files without raising
encoding is simply an
sequences of multiple commits
is simply an xor
files without raising the
simply an xor of
of multiple commits by
an xor of the
without raising the issue
s decreases the amount
xor of the r
multiple commits by the
raising the issue of
commits by the same
the issue of concurrent
decreases the amount of
of the r data
by the same author
issue of concurrent accesses
the amount of unacknowledged
the r data packets
amount of unacknowledged data
r data packets hence
of unacknowledged data by
the same author during
a topic we tackle
topic we tackle in
same author during a
we tackle in section
in layered interleaving each
author during a one
layered interleaving each data
during a one minute
interleaving each data packet
a one minute period
each data packet is
one minute period since
data packet is included
minute period since those
packet is included in
period since those were
but increases throughput by
since those were likely
increases throughput by less
is included in c
those were likely sequential
throughput by less than
were likely sequential rather
included in c xors
likely sequential rather than
sequential rather than simultaneous
rather than simultaneous and
performance evaluation of these
each of which is
evaluation of these workloads
than simultaneous and do
of which is generated
simultaneous and do nor
which is generated at
and do nor represent
is generated at different
do nor represent the
generated at different interleaves
nor represent the common
at different interleaves from
we classified grep and
different interleaves from the
represent the common case
interleaves from the original
classified grep and read
from the original data
grep and read as
the original data stream
time spent allocating byte
and read as foreground
the average rates were
spent allocating byte arrays
read as foreground workloads
allocating byte arrays in
byte arrays in the
arrays in the application
as we shall describe
and compile and write
we shall describe shortly
compile and write as
and write as background
write as background workloads
ensures that the c
that the c xors
four combined workloads were
the c xors containing
combined workloads were then
c xors containing a
workloads were then generated
xors containing a data
were then generated by
containing a data packet
then generated by running
a data packet do
generated by running a
data packet do not
by running a foreground
packet do not have
running a foreground and
do not have any
a foreground and a
not have any other
foreground and a background
have any other data
and a background workload
any other data packet
a background workload concurrently
other data packet in
memory used on sender
data packet in common
used on sender and
on sender and the
so exclusive locking for
sender and the number
exclusive locking for commits
and the number of
locking for commits should
the number of multicast
we denote these as
the resulting protocol effectively
for commits should not
resulting protocol effectively has
denote these as gc
number of multicast requests
commits should not pose
protocol effectively has a
of multicast requests in
should not pose any
effectively has a rate
not pose any scalability
has a rate of
pose any scalability problems
multicast requests in progress
any scalability problems in
scalability problems in a
problems in a typical
in a typical environment
we did not consider
did not consider the
not consider the rate
consider the rate of
with each xor generated
the rate of read
each xor generated from
token roundtrip time and
xor generated from r
roundtrip time and an
generated from r data
time and an average
from r data packets
and an average time
r data packets and
an average time to
data packets and each
average time to acknowledge
packets and each data
time to acknowledge a
and each data packet
to acknowledge a message
rate of read operations
each data packet included
of read operations because
data packet included in
read operations because clients
packet included in c
operations because clients updating
included in c xors
because clients updating their
clients updating their working
updating their working copies
or reading from the
reading from the repository
illustrates layered interleaving for
varying token circulation rate
layered interleaving for a
do not require a
three types of rpcs
not require a lock
types of rpcs predominate
the debian community today
debian community today uses
community today uses only
today uses only a
uses only a single
fetches of file data
only a single subversion
our second approach increased
a single subversion server
second approach increased the
approach increased the amount
increased the amount of
and store operations for
the amount of feedback
store operations for files
amount of feedback to
and the apache foundation
of feedback to the
the apache foundation has
feedback to the sender
apache foundation has a
in descending order of
foundation has a master
descending order of priority
has a master server
a master server plus
in our base implementation
master server plus a
server plus a european
plus a european mirror
the aim of the
aim of the experiments
each aggregate ack contains
of the experiments was
aggregate ack contains a
the experiments was to
primarily for latency reasons
experiments was to demonstrate
ack contains a single
was to demonstrate that
contains a single value
to demonstrate that priorities
a single value maxcontiguous
demonstrate that priorities improve
that priorities improve the
priorities improve the performance
we expect that most
improve the performance of
expect that most communities
representing the maximum number
the performance of the
the maximum number such
that most communities will
maximum number such that
performance of the foreground
most communities will have
number such that messages
communities will have at
such that messages with
of the foreground workloads
will have at most
that messages with this
have at most a
messages with this and
at most a handful
the four combined workloads
with this and all
four combined workloads were
this and all lower
combined workloads were executed
and all lower numbers
most a handful of
all lower numbers are
a handful of front
lower numbers are stable
standard fec schemes can
numbers are stable in
workloads were executed on
fec schemes can be
were executed on top
are stable in the
schemes can be made
executed on top of
can be made resistant
on top of mfs
stable in the region
be made resistant to
top of mfs configured
made resistant to a
of mfs configured with
achieving consistency amazon s
mfs configured with either
resistant to a certain
configured with either synchronous
to increase the amount
consistency amazon s infrastructure
to a certain loss
amazon s infrastructure is
increase the amount of
s infrastructure is built
the amount of feedback
infrastructure is built on
a certain loss burst
is built on the
with either synchronous writes
certain loss burst length
built on the principle
loss burst length at
on the principle of
burst length at the
the principle of eventual
length at the cost
principle of eventual consistency
at the cost of
update logging or asynchronous
we permit ack to
the cost of increased
logging or asynchronous writeback
cost of increased recovery
permit ack to contain
of increased recovery latency
ack to contain up
increased recovery latency for
to contain up to
recovery latency for all
contain up to k
latency for all lost
up to k numeric
for all lost packets
to k numeric ranges
the update logging mechanism
update logging mechanism was
and does not directly
logging mechanism was configured
does not directly support
mechanism was configured to
not directly support the
was configured to delay
directly support the locking
configured to delay flushing
support the locking required
to delay flushing an
the locking required for
delay flushing an update
locking required for revision
flushing an update for
required for revision control
an update for at
including smaller bursts and
update for at least
smaller bursts and singleton
for at least a
originally developed to run
bursts and singleton drops
developed to run the
at least a second
to run the company
run the company s
the company s own
company s own online
s own online store
every experiment was repeated
layered interleaving provides graceful
experiment was repeated ten
interleaving provides graceful degradation
was repeated ten times
the system preferred availability
repeated ten times at
provides graceful degradation in
ten times at each
system preferred availability over
graceful degradation in the
preferred availability over consistency
degradation in the face
availability over consistency because
times at each of
over consistency because downtime
in the face of
consistency because downtime translated
at each of five
because downtime translated directly
each of five possible
downtime translated directly into
of five possible bandwidth
translated directly into lost
five possible bandwidth values
directly into lost revenue
the face of bursty
face of bursty loss
of bursty loss for
bursty loss for constant
customers may opt to
loss for constant encoding
may opt to shop
for constant encoding overhead
shows the time taken
constant encoding overhead singleton
the time taken for
opt to shop elsewhere
time taken for each
encoding overhead singleton random
to shop elsewhere or
overhead singleton random losses
taken for each workload
singleton random losses are
for each workload at
random losses are recovered
each workload at a
losses are recovered as
workload at a bandwidth
are recovered as quickly
the system can now
shop elsewhere or to
at a bandwidth of
recovered as quickly as
system can now cleanup
elsewhere or to simply
as quickly as possible
or to simply forgo
can now cleanup message
to simply forgo impulse
now cleanup message sequences
simply forgo impulse purchases
cleanup message sequences that
forgo impulse purchases that
by xors generated with
impulse purchases that they
xors generated with an
message sequences that have
purchases that they didn
generated with an interleave
sequences that have as
that they didn t
with an interleave of
that have as gaps
they didn t really
didn t really need
t really need anyway
messages that are still
that are still unstable
and each successive layer
shows overall results for
each successive layer of
overall results for selected
an inconsistent shopping cart
successive layer of xors
results for selected configurations
in the experiment shown
layer of xors generated
the experiment shown in
of xors generated at
experiment shown in figures
the results in table
xors generated at a
could be resolved by
generated at a higher
be resolved by heuristics
at a higher interleave
resolved by heuristics or
demonstrate the benefit of
a higher interleave catches
by heuristics or user
the benefit of priorities
higher interleave catches larger
benefit of priorities when
interleave catches larger bursts
of priorities when there
catches larger bursts missed
priorities when there is
larger bursts missed by
intervention at checkout time
when there is high
bursts missed by the
we set k to
missed by the previous
set k to the
by the previous layer
k to the number
it is well known
there is high contention
to the number of
is well known that
is high contention between
the implementation of this
well known that consistency
high contention between high
the number of partitions
implementation of this algorithm
known that consistency and
of this algorithm is
this algorithm is simple
that consistency and availability
priority rpcs and writes
algorithm is simple and
consistency and availability cannot
is simple and shown
while the amount of
and availability cannot both
the amount of acknowledged
simple and shown in
amount of acknowledged data
and shown in figure
of acknowledged data is
availability cannot both be
in both the i
acknowledged data is reduced
cannot both be achieved
data is reduced by
both be achieved simultaneously
be achieved simultaneously in
achieved simultaneously in any
simultaneously in any real
bound gw and rw
in any real network
a set of repair
any real network where
set of repair bins
gw and rw workloads
of repair bins is
real network where hosts
repair bins is maintained
network where hosts or
bins is maintained for
where hosts or entire
is maintained for each
adding priorities decreases the
hosts or entire subnetworks
priorities decreases the time
and the overall throughput
decreases the time required
or entire subnetworks are
the time required for
the overall throughput is
time required for the
entire subnetworks are sometimes
maintained for each layer
subnetworks are sometimes unreachable
required for the foreground
are sometimes unreachable due
for the foreground workload
sometimes unreachable due to
the foreground workload to
unreachable due to connectivity
foreground workload to execute
due to connectivity losses
overall throughput is actually
with i bins for
throughput is actually lower
i bins for a
is actually lower because
bins for a layer
actually lower because token
for a layer with
lower because token processing
a layer with interleave
because token processing becomes
layer with interleave i
token processing becomes more
processing becomes more costly
a repair bin consists
repair bin consists of
bin consists of a
consists of a partially
if a cloud service
of a partially constructed
a cloud service is
a partially constructed repair
see elapsed times for
the system becomes unstable
cloud service is designed
partially constructed repair packet
service is designed to
elapsed times for rw
is designed to provide
notice the large variances
designed to provide high
the large variances in
to provide high availability
read with synchronous writes
provide high availability but
with synchronous writes in
large variances in figure
an xor and the
high availability but an
xor and the recipe
availability but an application
and the recipe list
but an application instead
synchronous writes in the
an application instead requires
writes in the table
application instead requires perfect
the recipe list of
instead requires perfect consistency
recipe list of identifiers
list of identifiers of
of identifiers of data
identifiers of data packets
of data packets that
additional software infrastructure is
this is particularly true
software infrastructure is required
is particularly true in
infrastructure is required to
particularly true in the
is required to bridge
true in the rw
required to bridge the
data packets that compose
because our flow control
in the rw test
to bridge the gap
packets that compose the
our flow control scheme
that compose the xor
where the foreground workload
for revision control it
the foreground workload generates
revision control it makes
foreground workload generates heavy
control it makes sense
workload generates heavy contention
it makes sense to
generates heavy contention by
makes sense to adopt
heavy contention by fetching
sense to adopt eventual
contention by fetching a
to adopt eventual consistency
by fetching a large
adopt eventual consistency for
fetching a large volume
eventual consistency for read
a large volume of
consistency for read operations
large volume of data
each intercepted data packet
based on limiting the
intercepted data packet is
on limiting the amount
data packet is added
since at worst an
packet is added to
at worst an earlier
limiting the amount of
the greatest benefits are
is added to each
greatest benefits are observable
the amount of unacknowledged
benefits are observable for
amount of unacknowledged data
are observable for the
added to each layer
observable for the combination
worst an earlier revision
for the combination of
an earlier revision will
the combination of asynchronous
earlier revision will fig
combination of asynchronous writes
to each layer where
while the sender can
each layer where adding
the sender can cleanup
layer where adding to
of asynchronous writes with
sender can cleanup any
where adding to a
can cleanup any portion
asynchronous writes with priorities
adding to a layer
cleanup any portion of
to a layer simply
any portion of the
a layer simply means
portion of the message
system architecture be returned
since here the performance
of the message sequence
layer simply means choosing
here the performance of
simply means choosing a
if the user is
means choosing a repair
the user is aware
choosing a repair bin
receivers have to deliver
the performance of the
have to deliver in
a repair bin from
performance of the background
to deliver in fifo
of the background workload
repair bin from the
the background workload can
bin from the layer
through some other channel
deliver in fifo order
background workload can also
from the layer s
workload can also improve
the layer s set
that a newer version
can also improve by
the amount of data
also improve by not
amount of data they
a newer version should
incrementally updating the xor
newer version should exist
updating the xor with
of data they cache
improve by not having
the xor with the
by not having to
xor with the new
not having to wait
data they cache is
having to wait for
they cache is larger
to wait for its
with the new data
he can retry and
wait for its writes
can retry and expect
for its writes to
retry and expect that
its writes to be
and expect that version
and this reduces their
expect that version to
writes to be committed
the new data packet
this reduces their ability
that version to be
reduces their ability to
to be committed at
version to be available
their ability to accept
to be available within
ability to accept incoming
be available within a
to accept incoming traffic
available within a short
and adding the data
be committed at the
adding the data packet
committed at the server
the data packet s
notice the linkage to
data packet s header
the linkage to memory
packet s header to
within a short timeframe
s header to the
in the gc and
header to the recipe
the gc and rc
to the recipe list
gc and rc tests
the growth in memory
growth in memory occurs
in memory occurs on
a counter is incremented
where there is lighter
perfect consistency is required
there is lighter contention
memory occurs on the
counter is incremented as
consistency is required and
is incremented as each
is required and a
incremented as each data
required and a locking
as each data packet
and a locking layer
each data packet arrives
a locking layer must
the impact of priorities
occurs on the receivers
data packet arrives at
locking layer must be
impact of priorities is
packet arrives at the
layer must be built
but the pattern is
arrives at the appliance
the pattern is similar
must be built to
of priorities is negligible
pattern is similar to
be built to support
is similar to what
and choosing the repair
similar to what we
built to support this
and in some cases
to what we saw
choosing the repair bin
in some cases results
what we saw earlier
some cases results in
this may result in
the repair bin from
may result in a
cases results in a
result in a commit
results in a slight
in a commit being
in a slight overhead
merely having more cached
repair bin from the
a commit being rejected
bin from the layer
having more cached data
but this is chiefly
more cached data is
this is chiefly after
cached data is enough
is chiefly after adding
data is enough to
chiefly after adding priorities
from the layer s
commit being rejected if
the layer s set
after adding priorities to
being rejected if consensus
adding priorities to rpcs
rejected if consensus cannot
layer s set is
is enough to slow
s set is done
enough to slow them
if consensus cannot be
it is natural to
to slow them down
is natural to ask
consensus cannot be reached
set is done by
natural to ask when
is done by taking
to ask when they
done by taking the
ask when they are
by taking the modulo
when they are beneficial
taking the modulo of
but shouldn t be
the modulo of the
token roundtrip time increases
modulo of the counter
shouldn t be a
and to what degree
of the counter with
t be a problem
the counter with the
be a problem because
counter with the number
a problem because code
in addition to comparing
problem because code changes
addition to comparing mfs
with the number of
because code changes are
this delays state aggregation
code changes are usually
to comparing mfs with
changes are usually not
comparing mfs with and
are usually not impulse
the number of bins
mfs with and without
increases pending messages and
usually not impulse decisions
number of bins in
not impulse decisions and
of bins in each
impulse decisions and the
pending messages and reduces
decisions and the commit
messages and reduces throughput
and the commit can
bins in each layer
with and without prioritised
the commit can be
and without prioritised rpcs
commit can be retried
can be retried later
for a layer with
a layer with interleave
we also investigate the
also investigate the performance
investigate the performance impact
the performance impact of
d esign as a
performance impact of replacing
esign as a proof
impact of replacing synchronous
of replacing synchronous rpcs
replacing synchronous rpcs for
the xth intercepted packet
synchronous rpcs for file
xth intercepted packet is
rpcs for file updates
intercepted packet is added
for file updates with
packet is added to
file updates with asynchronous
is added to the
updates with asynchronous writeback
more aggressive cleanup with
aggressive cleanup with o
the performance of these
performance of these alternatives
of these alternatives is
a tool for integrating
these alternatives is compared
tool for integrating subversion
alternatives is compared in
for integrating subversion with
is compared in a
integrating subversion with s
compared in a set
feedback in the token
in a set of
in the token and
a set of microbenchmarks
the token and in
token and in acks
when a repair bin
a repair bin fills
repair bin fills up
and with workloads gathered
bin fills up its
with workloads gathered from
fills up its recipe
workloads gathered from windows
up its recipe list
gathered from windows nt
its recipe list contains
vn is colocated with
recipe list contains r
from windows nt file
list contains r data
windows nt file system
contains r data packets
nt file system traces
is colocated with subversion
r data packets it
colocated with subversion and
data packets it fires
with subversion and inserts
more work with o
subversion and inserts a
our experimental setup consists
and inserts a layer
experimental setup consists of
inserts a layer between
setup consists of two
a repair packet is
a layer between subversion
repair packet is generated
layer between subversion and
packet is generated consisting
ghz pentium iii desktop
between subversion and s
is generated consisting of
and lower rates despite
generated consisting of the
lower rates despite saving
consisting of the xor
pentium iii desktop machines
rates despite saving on
iii desktop machines running
despite saving on memory
desktop machines running the
as shown in figure
machines running the freebsd
of the xor and
the xor and the
xor and the recipe
and the recipe list
the recipe list and
recipe list and is
list and is scheduled
and is scheduled for
for simplicity we did
is scheduled for sending
simplicity we did not
we did not modify
did not modify the
not modify the subversion
modify the subversion server
while the repair bin
the subversion server in
the repair bin is
subversion server in any
repair bin is re
server in any way
one of which acts
memory overheads on the
of which acts as
overheads on the receiver
which acts as an
on the receiver the
acts as an mfs
initialized with an empty
the receiver the reader
as an mfs server
receiver the reader may
vn is responsible for
the reader may doubt
with an empty recipe
reader may doubt that
an empty recipe list
may doubt that memory
empty recipe list and
doubt that memory overhead
is responsible for receiving
that memory overhead on
recipe list and blank
memory overhead on receivers
list and blank xor
overhead on receivers is
responsible for receiving event
and the other as
for receiving event notifications
on receivers is the
receiving event notifications from
receivers is the real
the other as an
event notifications from subversion
is the real issue
notifications from subversion and
other as an mfs
from subversion and transferring
as an mfs client
subversion and transferring data
incoming repair packets are
and transferring data between
repair packets are processed
considering that their cpus
transferring data between the
packets are processed as
data between the local
are processed as follows
between the local disk
the client machine makes
that their cpus are
client machine makes use
the local disk on
machine makes use of
local disk on the
if all the data
their cpus are half
all the data packets
disk on the ec
the data packets contained
makes use of the
data packets contained in
use of the dummynet
packets contained in the
of the dummynet trafficshaping
contained in the repair
the dummynet trafficshaping module
in the repair s
dummynet trafficshaping module in
the repair s recipe
trafficshaping module in freebsd
repair s recipe list
module in freebsd to
s recipe list have
in freebsd to limit
recipe list have been
freebsd to limit its
list have been received
to limit its incoming
have been received successfully
limit its incoming and
its incoming and outgoing
incoming and outgoing bandwidth
can increasing memory consumption
vn at the start
the repair packet is
at the start and
the experiments we conduct
the start and end
experiments we conduct in
increasing memory consumption affect
we conduct in this
memory consumption affect a
repair packet is discarded
start and end of
conduct in this section
consumption affect a half
in this section have
and end of each
this section have a
end of each commit
section have a constant
if the repair s
have a constant bandwidth
the repair s recipe
a constant bandwidth over
repair s recipe list
constant bandwidth over the
s recipe list contains
bandwidth over the duration
recipe list contains a
over the duration of
list contains a single
the duration of the
contains a single missing
we performed an experiment
a single missing data
performed an experiment with
single missing data packet
vn acquires and releases
duration of the experiment
acquires and releases locks
and releases locks using
releases locks using yahoo
recovery can occur immediately
locks using yahoo s
can occur immediately by
using yahoo s open
but we analyse the
yahoo s open source
we analyse the performance
s open source zookeeper
analyse the performance of
open source zookeeper lock
the performance of mfs
source zookeeper lock service
performance of mfs when
of mfs when the
mfs when the bandwidth
in which we vary
when the bandwidth varies
which we vary the
the difficulty achieving consistency
the bandwidth varies over
difficulty achieving consistency with
bandwidth varies over the
achieving consistency with a
varies over the course
consistency with a service
over the course of
with a service such
the course of an
a service such as
course of an experiment
service such as amazon
of an experiment in
such as amazon s
an experiment in section
as amazon s s
we vary the number
vary the number of
the number of receivers
number of receivers that
of receivers that cache
receivers that cache a
stems from the fact
that cache a copy
from the fact that
cache a copy of
the fact that files
a copy of each
fact that files pushed
copy of each message
that files pushed into
files pushed into the
pushed into the storage
into the storage cloud
replication factor in figure
the storage cloud do
storage cloud do not
cloud do not simultaneously
do not simultaneously become
not simultaneously become available
simultaneously become available on
microbenchmarks the first set
become available on all
the first set of
available on all service
first set of experiments
on all service endpoints
set of experiments compares
of experiments compares different
experiments compares different mfs
compares different mfs configurations
increasing this value results
different mfs configurations for
if a file is
mfs configurations for specific
a file is overwritten
configurations for specific types
this value results in
for specific types of
value results in a
specific types of contention
results in a linear
different clients may read
in a linear increase
clients may read back
a linear increase of
may read back different
linear increase of memory
four workloads were used
read back different versions
increase of memory usage
of memory usage on
memory usage on receivers
and even the same
even the same client
executes the grep utility
the same client may
the grep utility several
if memory overheads were
grep utility several times
same client may see
utility several times on
memory overheads were not
client may see the
overheads were not a
several times on each
may see the old
were not a significant
see the old version
not a significant issue
the old version if
a significant issue on
times on each of
old version if it
significant issue on half
version if it suddenly
if it suddenly switches
it suddenly switches to
suddenly switches to speaking
switches to speaking with
to speaking with a
speaking with a different
with a different s
we would expect performance
would expect performance to
expect performance to remain
performance to remain unchanged
the file will always
file will always be
the files are present
will always be internally
files are present in
we see a dramatic
always be internally consistent
are present in the
present in the cache
layer with interleave of
since put and get
put and get operations
but must be validated
and get operations are
must be validated before
get operations are atomic
be validated before they
linear increase of the
validated before they are
increase of the token
before they are used
of the token roundtrip
but its contents may
the token roundtrip time
its contents may not
contents may not reflect
may not reflect expectations
not reflect expectations that
a slow increase of
reflect expectations that the
slow increase of the
expectations that the client
increase of the number
that the client formed
of the number of
the client formed based
the number of messages
client formed based on
number of messages pending
formed based on other
of messages pending ack
based on other files
messages pending ack on
on other files and
pending ack on the
other files and out
ack on the sender
files and out of
and out of band
out of band communication
mb files in sequence
and a sharp decrease
a sharp decrease in
writing the contents of
sharp decrease in throughput
the contents of each
contents of each file
vn works around the
of each file to
works around the consistency
around the consistency problem
the consistency problem by
consistency problem by storing
problem by storing the
by storing the number
storing the number of
the number of the
number of the latest
of the latest revision
the latest revision into
latest revision into zookeeper
the files are not
files are not initially
are not initially present
not initially present in
the underlying mechanism is
initially present in the
underlying mechanism is as
present in the cache
mechanism is as follows
even if multiple files
if multiple files were
multiple files were changed
files were changed by
were changed by the
the increased activity of
changed by the client
increased activity of the
activity of the garbage
of the garbage collector
is represented by subversion
the garbage collector and
represented by subversion has
garbage collector and allocation
by subversion has a
collector and allocation overheads
subversion has a single
and allocation overheads slow
has a single file
allocation overheads slow the
a single file containing
mb files from the
single file containing binary
files from the local
file containing binary diffs
from the local file
containing binary diffs against
the local file system
binary diffs against earlier
local file system into
diffs against earlier revisions
file system into the
overheads slow the system
system into the mfs
slow the system down
into the mfs file
the system down and
the mfs file system
system down and processing
a revision is never
down and processing of
revision is never changed
and processing of the
is never changed after
processing of the incoming
never changed after the
of the incoming packets
changed after the fact
the incoming packets and
incoming packets and tokens
packets and tokens takes
and tokens takes more
tokens takes more time
end server attempting to
although the effect is
server attempting to fetch
the effect is not
attempting to fetch a
effect is not significant
to fetch a revision
is not significant when
fetch a revision i
not significant when considering
a revision i from
significant when considering a
revision i from s
when considering a single
considering a single node
a single node in
single node in isolation
will receive either the
receive either the one
either the one true
a token must visit
token must visit all
must visit all nodes
visit all nodes in
all nodes in a
nodes in a region
in a region to
or a missing file
a region to aggregate
a missing file error
region to aggregate the
missing file error if
to aggregate the recovery
file error if i
aggregate the recovery state
error if i was
if i was posted
i was posted so
was posted so recently
posted so recently that
and delays are cumulative
so recently that it
recently that it has
that it has not
qsm is configured so
is configured so that
configured so that five
so that five nodes
that five nodes in
combining the xor in
five nodes in each
the xor in the
nodes in each region
xor in the repair
in each region cache
in the repair with
each region cache each
the repair with the
region cache each packet
repair with the other
with the other successfully
the other successfully received
other successfully received data
successfully received data packets
if half the nodes
half the nodes in
the nodes in a
if the repair contains
the repair contains multiple
repair contains multiple missing
contains multiple missing data
multiple missing data packets
it cannot be used
cannot be used immediately
be used immediately for
node region cache each
used immediately for recovery
region cache each figure
immediately for recovery it
for recovery it is
recovery it is instead
it is instead stored
is instead stored in
instead stored in a
stored in a table
in a table that
a table that maps
table that maps missing
that maps missing data
maps missing data packets
missing data packets to
data packets to repair
packets to repair packets
whenever a data packet
a data packet is
data packet is subsequently
packet is subsequently received
is subsequently received or
subsequently received or recovered
this table is checked
table is checked to
varying the number of
is checked to see
the number of caching
checked to see if
number of caching replicas
to see if any
of caching replicas per
see if any xors
caching replicas per message
replicas per message in
if any xors now
per message in a
any xors now have
xors now have singleton
now have singleton losses
have singleton losses due
singleton losses due to
losses due to the
due to the presence
to the presence of
the presence of the
presence of the new
of the new packet
the new packet and
new packet and can
packet and can be
and can be used
as the replication factor
can be used for
the replication factor increasess
be used for recovering
used for recovering other
for recovering other missing
recovering other missing packets
the sender s flow
sender s flow control
s flow control policy
flow control policy kicks
control policy kicks in
xors received from different
and the system goes
received from different layers
the system goes into
from different layers interact
end servers are equivalent
different layers interact to
servers are equivalent and
layers interact to recover
are equivalent and clients
interact to recover missing
equivalent and clients may
to recover missing data
and clients may interact
recover missing data packets
clients may interact with
may interact with any
interact with any of
with any of them
any of them fig
a form of the
since an xor received
form of the oscillating
an xor received at
of the oscillating state
xor received at a
the oscillating state we
received at a higher
oscillating state we encountered
at a higher interleave
state we encountered in
a higher interleave can
we encountered in figure
higher interleave can recover
interleave can recover a
can recover a packet
recover a packet that
a packet that makes
packet that makes an
that makes an earlier
e valuation we observe
makes an earlier xor
valuation we observe that
an earlier xor at
we observe that running
the amount of memory
observe that running multiple
earlier xor at a
amount of memory in
xor at a lower
that running multiple front
at a lower interleave
of memory in use
a lower interleave usable
memory in use at
lower interleave usable hence
in use at the
use at the sender
at the sender ceases
the sender ceases to
which cloud computing makes
though layered interleaving is
cloud computing makes easy
sender ceases to be
layered interleaving is equivalent
ceases to be a
interleaving is equivalent to
to be a good
is equivalent to c
computing makes easy to
be a good predictor
equivalent to c different
makes easy to do
a good predictor of
good predictor of the
predictor of the amount
increases the throughput of
of the amount of
the throughput of read
the amount of memory
throughput of read operations
amount of memory in
of memory in use
memory in use at
in use at receivers
instances in terms of
in terms of overhead
vn by running a
violating what turns out
by running a fixed
what turns out to
terms of overhead and
running a fixed number
turns out to be
a fixed number of
out to be an
of overhead and design
to be an implicit
fixed number of clients
be an implicit requirement
an implicit requirement of
implicit requirement of our
its recovery power is
requirement of our flow
recovery power is much
each repeatedly checking out
power is much higher
repeatedly checking out about
is much higher and
much higher and comes
higher and comes close
and comes close to
comes close to standard
overheads in a perturbed
in a perturbed system
a perturbed system the
perturbed system the reader
system the reader might
optimizations staggered start for
the reader might wonder
staggered start for rate
gc test rw test
reader might wonder whether
might wonder whether our
wonder whether our results
limiting in the naive
whether our results would
in the naive implementation
our results would be
the naive implementation of
results would be different
naive implementation of the
would be different if
implementation of the layered
be different if the
of the layered interleaving
different if the system
the layered interleaving algorithm
if the system experienced
the system experienced high
system experienced high loss
experienced high loss rates
high loss rates or
repair packets are transmitted
loss rates or was
packets are transmitted as
rates or was otherwise
are transmitted as soon
or was otherwise perturbed
transmitted as soon as
yet propagated through s
as soon as repair
soon as repair bins
as repair bins fill
repair bins fill and
bins fill and allow
fill and allow them
and allow them to
in the latter case
we performed an experiment
allow them to be
performed an experiment in
them to be constructed
an experiment in which
the server retries indefinitely
experiment in which one
server retries indefinitely until
in which one of
retries indefinitely until the
which one of the
indefinitely until the file
one of the receiver
until the file is
of the receiver nodes
the file is available
the receiver nodes experiences
all the repair bins
receiver nodes experiences a
the repair bins in
nodes experiences a periodic
repair bins in a
bins in a layer
zookeeper ensures that the
in a layer fill
ensures that the latest
a layer fill in
that the latest revision
layer fill in quick
the latest revision number
fill in quick succession
latest revision number is
revision number is incremented
number is incremented atomically
s the node sleeps
the node sleeps for
zookeeper maintains a simple
maintains a simple filesystem
a simple filesystem like
simple filesystem like tree
filesystem like tree of
the arrival of packets
like tree of nodes
nodes may store a
may store a small
store a small amount
this simulates the effect
a small amount of
simulates the effect of
small amount of data
the effect of disruptive
amount of data and
of data and can
data and can have
and can have children
in the loss scenario
vn stores the latest
stores the latest revision
the latest revision number
latest revision number in
s the node drops
the node drops all
node drops all incoming
drops all incoming packets
all incoming packets for
gw test rc test
will successively fill the
successively fill the four
fill the four repair
the four repair bins
four repair bins in
repair bins in layer
this behavior leads to
supporting multiple named repositories
behavior leads to a
multiple named repositories in
leads to a large
named repositories in a
to a large number
repositories in a single
a large number of
in a single zookeeper
large number of repair
a single zookeeper tree
number of repair packets
the loss rate is
of repair packets being
loss rate is higher
repair packets being generated
before pushing a new
packets being generated and
pushing a new revision
being generated and sent
generated and sent within
and sent within a
sent within a short
within a short period
a short period of
short period of time
end server must acquire
server must acquire a
must acquire a lock
which results in undesirable
acquire a lock by
results in undesirable overhead
a lock by creating
in undesirable overhead and
lock by creating a
undesirable overhead and traffic
by creating a sequence
overhead and traffic spikes
creating a sequence node
because recovery traffic interferes
recovery traffic interferes with
traffic interferes with regular
interferes with regular multicast
we would like to
would like to rate
limit transmissions of repair
transmissions of repair packets
of repair packets to
cpu utilization at the
utilization at the receivers
repair packets to one
at the receivers is
packets to one for
relative speedup relative speedup
to one for every
the receivers is in
speedup relative speedup relative
one for every r
relative speedup relative speedup
for every r data
receivers is in the
every r data packets
to which zookeeper will
this problem is fixed
which zookeeper will append
problem is fixed by
zookeeper will append a
is fixed by staggering
will append a unique
fixed by staggering the
by staggering the starting
staggering the starting sizes
the starting sizes of
starting sizes of the
monotonically increasing sequence number
sizes of the bins
range and doesn t
analogous to the starting
end server then lists
to the starting positions
server then lists the
the starting positions of
then lists the children
starting positions of runners
lists the children of
positions of runners in
uniform priorities async relative
and doesn t grow
of runners in a
priorities async relative speedup
doesn t grow with
runners in a sprint
async relative speedup gc
t grow with system
relative speedup gc test
grow with system size
the very first time
very first time bin
first time bin number
time bin number x
bin number x in
number x in a
x in a layer
in a layer of
a layer of interleave
layer of interleave i
of interleave i fires
if its own lock
its own lock node
it does so at
own lock node has
does so at size
lock node has the
so at size x
node has the lowest
at size x mod
has the lowest number
in the sleep scenario
size x mod r
the decrease starts at
it may proceed with
decrease starts at about
may proceed with the
proceed with the commit
otherwise it watches the
it watches the node
nodes and proceeds steadily
the first repair bin
watches the node with
first repair bin in
and proceeds steadily thereafter
the node with the
repair bin in the
node with the next
bin in the second
with the next lower
in the second layer
the next lower number
the second layer with
it doesn t appear
next lower number in
doesn t appear to
second layer with interleave
t appear to be
lower number in order
appear to be correlated
number in order to
to be correlated to
in order to be
be correlated to the
order to be notified
correlated to the amount
would fire at size
to be notified when
to the amount of
be notified when that
the amount of loss
notified when that node
when that node and
that node and its
node and its associated
which oscillates at the
and its associated lock
the second would fire
oscillates at the level
second would fire at
at the level of
would fire at size
its associated lock go
associated lock go away
after comitting the revision
comitting the revision to
the revision to s
in the controlled loss
the controlled loss scenario
throughput remains fairly constant
it releases its lock
releases its lock by
its lock by deleting
lock by deleting the
by deleting the lock
until it falls sharply
deleting the lock node
it falls sharply beyond
lock nodes are marked
nodes are marked with
are marked with zookeeper
marked with zookeeper s
with zookeeper s ephemeral
zookeeper s ephemeral flag
s ephemeral flag to
ephemeral flag to ensure
flag to ensure that
to ensure that the
ensure that the lock
that the lock is
the lock is forcibly
performance does not appear
lock is forcibly released
does not appear to
is forcibly released if
not appear to be
forcibly released if the
appear to be directly
released if the front
to be directly correlated
be directly correlated to
directly correlated to the
correlated to the observed
to the observed packet
the observed packet loss
zookeeper runs as a
runs as a replicated
as a replicated service
throughput is uncorrelated with
is uncorrelated with memory
so it remains available
uncorrelated with memory use
it remains available as
with memory use both
remains available as long
memory use both on
available as long as
use both on the
as long as a
both on the perturbed
long as a majority
on the perturbed receiver
as a majority of
a majority of the
majority of the hosts
of the hosts are
the hosts are up
hosts are up and
are up and reachable
relative speedup relative speedup
speedup relative speedup relative
relative speedup relative speedup
a client only speaks
client only speaks to
only speaks to one
speaks to one zookeeper
to one zookeeper server
one zookeeper server at
zookeeper server at a
server at a time
though it may fail
at scales of up
over to another server
scales of up to
to another server if
another server if necessary
but the server ensures
the server ensures that
memory usage actually decreases
server ensures that the
ensures that the relevant
that the relevant state
the relevant state has
a consequence of the
relevant state has been
consequence of the cooperative
state has been replicated
of the cooperative caching
has been replicated before
the cooperative caching policy
been replicated before responding
cooperative caching policy described
replicated before responding to
caching policy described in
before responding to a
policy described in section
responding to a client
to a client s
a client s request
in general multiple front
the shape of the
shape of the performance
of the performance curve
the performance curve does
end servers may be
servers may be run
each on its own
on its own ec
correlate closely with the
closely with the number
with the number of
the number of unacknowledged
number of unacknowledged requests
the system is organized
system is organized as
is organized as in
organized as in figure
unlike the traditional replicated
the traditional replicated subversion
traditional replicated subversion setups
replicated subversion setups that
we conclude that the
subversion setups that are
conclude that the drop
setups that are used
that the drop in
that are used today
the drop in performance
drop in performance in
in performance in these
performance in these scenarios
no single server acts
in these scenarios can
single server acts as
these scenarios can t
server acts as a
scenarios can t be
acts as a master
can t be explained
t be explained by
be explained by correlation
explained by correlation with
by correlation with cpu
correlation with cpu activity
vn all are equivalent
performance of simultaneous checkouts
or loss rates at
loss rates at the
rates at the receivers
but that it does
that it does appear
it does appear correlated
does appear correlated to
appear correlated to slower
correlated to slower cleanup
to slower cleanup and
slower cleanup and the
cleanup and the resulting
and the resulting memory
related overheads at the
overheads at the sender
the effect is much
effect is much stronger
is much stronger than
much stronger than in
stronger than in the
than in the undisturbed
in the undisturbed experiments
second set of rsized
the number of pending
set of rsized xors
number of pending messages
of rsized xors staggered
of pending messages starts
rsized xors staggered start
pending messages starts at
xors staggered start xors
performance of simultaneous commits
messages starts at a
of simultaneous commits source
starts at a higher
simultaneous commits source code
at a higher level
commits source code from
source code from an
code from an ec
token roundtrip time increases
and varying the number
varying the number of
the number of servers
number of servers over
of servers over which
servers over which the
over which the load
which the load was
the load was distributed
and if a failure
if a failure occurs
token rounds before repair
rounds before repair occurs
write performance was measured
performance was measured by
was measured by observing
and then another round
measured by observing the
then another round before
by observing the latency
another round before cleanup
observing the latency of
round before cleanup takes
the latency of simultaneous
before cleanup takes place
latency of simultaneous commits
of simultaneous commits from
simultaneous commits from different
commits from different clients
since simultaneous commits to
simultaneous commits to a
commits to a single
to a single repository
a single repository would
single repository would not
repository would not be
would not be a
not be a typical
be a typical case
these account for the
account for the rapid
for the rapid increase
the rapid increase in
rapid increase in acknowledgement
increase in acknowledgement latency
vn repositories were used
performance of prioritised rpc
of prioritised rpc with
all sharing the same
prioritised rpc with respect
sharing the same set
rpc with respect to
the same set of
with respect to bandwidth
same set of front
respect to bandwidth variation
as the number of
the number of caching
end servers and same
number of caching replicas
servers and same set
of caching replicas increases
and same set of
each pair of graphs
same set of three
pair of graphs in
set of three zookeeper
of graphs in shows
of three zookeeper servers
graphs in shows the
in shows the speedup
shows the speedup of
the speedup of one
speedup of one of
each client checked out
of one of three
client checked out a
one of three cache
checked out a random
of three cache manager
out a random repository
three cache manager configurations
a random repository from
random repository from a
repository from a random
from a random front
throughput in the experiments
in the experiments with
relative to the time
the experiments with a
to the time taken
experiments with a perturbed
the time taken by
with a perturbed node
time taken by uniform
taken by uniform priorities
by uniform priorities with
and then repeatedly committed
uniform priorities with synchronous
then repeatedly committed small
priorities with synchronous rpcs
repeatedly committed small amounts
with synchronous rpcs at
committed small amounts of
small amounts of data
changes were propgated in
were propgated in the
propgated in the background
in the background to
the background to the
background to the other
to the other front
as well as uniform
well as uniform priorities
as uniform priorities and
uniform priorities and synchronous
priorities and synchronous rpcs
average packet loss observed
packet loss observed at
loss observed at the
observed at the perturbed
at the perturbed node
shows that adding front
the graphs also show
graphs also show curves
also show curves for
end servers can indeed
show curves for differentiated
servers can indeed alleviate
curves for differentiated priorities
can indeed alleviate latency
for differentiated priorities and
indeed alleviate latency problems
differentiated priorities and synchronous
alleviate latency problems caused
priorities and synchronous rpcs
latency problems caused by
problems caused by high
caused by high load
memory usage at the
usage at the perturbed
at the perturbed node
and that the overhead
and differentiated priorities and
at unperturbed nodes it
that the overhead of
differentiated priorities and asynchronous
unperturbed nodes it is
the overhead of propagating
priorities and asynchronous rpcs
overhead of propagating data
nodes it is similar
of propagating data in
propagating data in the
data in the backgound
in the backgound is
the backgound is not
backgound is not significant
is not significant enough
not significant enough to
significant enough to negatively
enough to negatively affect
the values plotted for
to negatively affect performance
values plotted for bandwidth
plotted for bandwidth of
although it would be
it would be hard
would be hard to
r elated w orks
be hard to precisely
elated w orks moving
hard to precisely measure
w orks moving services
to precisely measure these
orks moving services to
precisely measure these delays
moving services to the
services to the cloud
to the cloud has
the cloud has been
cloud has been published
s are the same
measuring alarm delays sheds
has been published on
are the same as
alarm delays sheds light
the same as shown
been published on in
same as shown in
published on in other
delays sheds light on
as shown in table
on in other contexts
sheds light on the
light on the magnitude
on the magnitude of
the magnitude of the
magnitude of the problem
due to the overhead
to the overhead of
recall that our timesharing
the overhead of priorities
that our timesharing policy
overhead of priorities for
our timesharing policy assigns
of priorities for small
timesharing policy assigns quanta
priorities for small rpcs
policy assigns quanta to
is a backup application
assigns quanta to different
for small rpcs mentioned
a backup application that
quanta to different types
small rpcs mentioned in
backup application that implements
to different types of
rpcs mentioned in section
application that implements a
different types of events
that implements a custom
implements a custom block
high volumes of i
based file system to
file system to store
system to store multiple
to store multiple versions
store multiple versions of
multiple versions of backup
versions of backup data
such as caused by
of backup data on
as caused by the
backup data on s
caused by the increased
comparing the execution time
by the increased forwarding
the execution time of
the increased forwarding traffic
execution time of the
time of the foreground
of the foreground workloads
the foreground workloads with
foreground workloads with synchronous
will cause qsm to
the authors make the
cause qsm to use
authors make the distinction
qsm to use a
make the distinction between
to use a larger
the distinction between thin
use a larger fraction
workloads with synchronous writes
a larger fraction of
larger fraction of its
fraction of its i
clouds that provide a
that provide a low
update logging and asynchronous
o quantum to process
logging and asynchronous writeback
quantum to process i
and asynchronous writeback reveals
asynchronous writeback reveals that
level api and thick
writeback reveals that the
reveals that the latter
that the latter two
the latter two options
clouds that are designed
with the consequence that
latter two options generally
that are designed for
two options generally perform
are designed for a
options generally perform comparably
designed for a specific
the consequence that timers
generally perform comparably to
for a specific application
perform comparably to or
consequence that timers will
comparably to or better
that timers will fire
to or better than
timers will fire late
thick clouds for a
or better than synchronous
clouds for a variety
better than synchronous writes
for a variety of
this effect is magnified
a variety of purposes
effect is magnified each
is magnified each time
logging and asynchronous writeback
magnified each time qsm
and asynchronous writeback greatly
each time qsm is
including backup and source
time qsm is preempted
backup and source code
qsm is preempted by
and source code repository
asynchronous writeback greatly improve
is preempted by other
writeback greatly improve the
preempted by other processes
greatly improve the performance
by other processes or
improve the performance of
other processes or by
source code repository hosting
the performance of the
processes or by its
performance of the background
or by its own
of the background workloads
by its own garbage
its own garbage collector
as has been noted
with sourceforge and google
has been noted previously
sourceforge and google code
such delays are typically
and google code being
delays are typically shorter
google code being examples
are typically shorter than
code being examples of
typically shorter than the
being examples of the
shorter than the i
examples of the latter
the authors of cumulus
authors of cumulus and
of cumulus and we
cumulus and we show
yet longer than the
and we show that
longer than the alarm
we show that thin
than the alarm quantum
cloud solutions can be
thus causing the alarm
solutions can be a
can be a cost
but not the i
we focus on mfs
focus on mfs with
on mfs with asynchronous
mfs with asynchronous writeback
another example of moving
with asynchronous writeback in
example of moving a
asynchronous writeback in the
of moving a service
writeback in the rest
moving a service to
in the rest of
a service to the
the rest of this
the maximum alarm firing
service to the cloud
rest of this paper
maximum alarm firing delays
of this paper because
to the cloud is
this paper because it
the cloud is metacdn
paper because it provides
alarm firing delays taken
because it provides comparable
firing delays taken from
it provides comparable performance
delays taken from samples
provides comparable performance to
taken from samples in
comparable performance to logged
performance to logged updates
s intervals are indeed
intervals are indeed much
are indeed much larger
indeed much larger in
allows straightforward modeless adaptation
much larger in the
straightforward modeless adaptation to
larger in the perturbed
modeless adaptation to bandwidth
in the perturbed experiments
adaptation to bandwidth variation
a content distribution network
both on the sender
and is easily extensible
on the sender and
is easily extensible to
the work evaluates the
easily extensible to more
the sender and on
extensible to more than
sender and on the
to more than one
and on the receiver
more than one level
on the receiver side
than one level of
work evaluates the latency
one level of priority
evaluates the latency of
the latency of various
latency of various cloud
which is required for
of various cloud storage
is required for our
required for our cache
various cloud storage services
for our cache consistency
cloud storage services from
our cache consistency algorithm
storage services from several
services from several locations
from several locations and
several locations and provides
since reducing available bandwidth
locations and provides an
reducing available bandwidth increases
and provides an abstraction
available bandwidth increases the
provides an abstraction to
bandwidth increases the contention
an abstraction to integrate
increases the contention between
abstraction to integrate the
the contention between rpcs
large delays are also
contention between rpcs of
delays are also more
between rpcs of different
are also more frequent
rpcs of different types
to integrate the different
integrate the different offerings
the different offerings into
different offerings into a
offerings into a single
the benefits of rpc
into a single system
benefits of rpc priorities
of rpc priorities should
rpc priorities should be
priorities should be more
should be more apparent
the maximum delay measured
be more apparent at
maximum delay measured on
more apparent at lower
delay measured on receivers
apparent at lower priorities
measured on receivers in
on receivers in the
receivers in the perturbed
in the perturbed runs
the perturbed runs is
like transactional data store
shows the experiments of
transactional data store backed
the experiments of table
data store backed by
store backed by s
extended to a wider
to a wider range
a wider range of
wider range of bandwidth
range of bandwidth values
and faced similar issues
faced similar issues as
similar issues as s
in these and later
these and later experiments
vn due to its
due to its need
to its need for
its need for high
we evaluate mfs performance
need for high consistency
evaluate mfs performance with
mfs performance with bandwidths
performance with bandwidths from
elastras assigns update priviledges
assigns update priviledges for
update priviledges for different
priviledges for different areas
for different areas of
different areas of the
areas of the data
of the data store
ms in the unperturbed
the data store to
in the unperturbed experiments
data store to individual
store to individual front
the value grows from
using the lock service
the lock service to
lock service to elect
service to elect an
to elect an owner
elect an owner for
an owner for each
owner for each partition
much in the style
in the style described
the style described by
style described by google
described by google s
by google s chubby
s is not low
is not low in
not low in the
low in the sense
in the sense of
the sense of prior
sense of prior work
the problem could be
problem could be alleviated
it is low enough
could be alleviated by
is low enough to
be alleviated by making
low enough to cause
alleviated by making our
enough to cause significant
by making our priority
to cause significant contention
making our priority scheduling
cause significant contention for
our priority scheduling more
significant contention for the
priority scheduling more fine
a lock service based
contention for the workloads
lock service based on
for the workloads we
service based on paxos
the workloads we have
workloads we have considered
and we believe that
we believe that our
believe that our results
that our results will
our results will hold
results will hold if
varying priorities for control
will hold if available
priorities for control packets
hold if available bandwidth
defers finegrained locking to
if available bandwidth and
finegrained locking to the
available bandwidth and grep
locking to the application
bandwidth and grep write
or by assigning priorities
to the application in
by assigning priorities to
the application in order
assigning priorities to feeds
application in order not
priorities to feeds in
in order not to
to feeds in the
order not to burden
feeds in the sending
not to burden the
in the sending stack
to burden the global
burden the global lock
the global lock service
global lock service with
lock service with high
service with high traffic
afs mfs afs mfs
vn we opted to
mfs afs mfs elapsed
we opted to use
afs mfs elapsed time
opted to use the
number of messages awaiting
to use the lock
of messages awaiting acknowledgement
use the lock service
messages awaiting acknowledgement in
awaiting acknowledgement in experiments
acknowledgement in experiments with
in experiments with perturbances
grained locking instead of
locking instead of just
instead of just leader
of just leader election
token roundtrip time and
since the latter would
roundtrip time and the
the latter would have
time and the time
latter would have required
and the time to
would have required duplicating
the time to recover
have required duplicating much
time to recover in
required duplicating much of
to recover in the
duplicating much of zookeeper
much of zookeeper s
of zookeeper s functionality
zookeeper s functionality to
s functionality to replicate
functionality to replicate the
to replicate the leader
replicate the leader s
the leader s state
scalability is not an
is not an obstacle
not an obstacle because
an obstacle because there
comparison of packet recovery
obstacle because there is
of packet recovery probability
because there is no
there is no need
is no need for
token roundtrip time and
no need for global
roundtrip time and the
need for global locking
time and the time
for global locking across
and the time to
global locking across multiple
the time to recover
locking across multiple repositories
time to recover in
to recover in the
the load can be
load can be partitioned
can be partitioned across
be partitioned across as
partitioned across as many
across as many zookeeper
as many zookeeper instances
many zookeeper instances as
it is worth noting
zookeeper instances as necessary
is worth noting that
worth noting that the
noting that the doubled
that the doubled token
the doubled token roundtrip
replication is not without
doubled token roundtrip time
is not without its
staggered start first i
not without its dangers
start first i data
first i data packets
as compared to unperturbed
i data packets added
compared to unperturbed experiments
data packets added to
packets added to a
added to a layer
to a layer with
a layer with interleave
can t be accounted
layer with interleave i
t be accounted for
be accounted for by
accounted for by the
for by the increase
by the increase in
and it has been
the increase in memory
it has been shown
r fire immediately with
increase in memory overhead
has been shown that
fire immediately with just
been shown that replicating
immediately with just one
shown that replicating too
in memory overhead or
that replicating too eagerly
memory overhead or cpu
replicating too eagerly leads
overhead or cpu activity
too eagerly leads quickly
or cpu activity on
eagerly leads quickly to
cpu activity on the
leads quickly to degraded
activity on the receivers
quickly to degraded performance
with just one packet
just one packet in
one packet in them
as was the case
the solution proposed is
was the case in
solution proposed is to
the case in experiments
proposed is to use
for the next i
is to use master
the next i data
to use master copy
next i data packets
use master copy replication
i data packets added
case in experiments where
in experiments where we
experiments where we varied
where we varied the
where a transaction does
we varied the replication
a transaction does not
varied the replication factor
transaction does not immediately
does not immediately update
r fire immediately with
not immediately update all
fire immediately with two
the problem can be
immediately with two data
problem can be traced
with two data packets
can be traced to
two data packets in
be traced to a
data packets in them
traced to a priority
immediately update all replicas
to a priority inversion
and so on until
so on until r
because of repeated losses
on until r i
until r i data
r i data packets
i data packets have
the system maintains a
data packets have been
system maintains a high
as the master copy
packets have been added
maintains a high volume
have been added to
a high volume of
been added to the
high volume of forwarding
added to the layer
volume of forwarding traffic
to the layer and
and only the lock
the layer and all
only the lock service
layer and all bins
comparison of mfs and
and all bins have
of mfs and afs
all bins have fired
mfs and afs performance
bins have fired exactly
the forwarded messages tend
which deals with simple
forwarded messages tend to
have fired exactly once
messages tend to get
mfs with synchronous rpcs
tend to get ahead
with synchronous rpcs and
to get ahead of
synchronous rpcs and priorities
get ahead of the
bandwidth operations that may
rpcs and priorities is
all bins fire at
and priorities is compared
ahead of the token
operations that may be
bins fire at size
that may be concentrated
priorities is compared to
fire at size r
is compared to a
both on the send
may be concentrated on
compared to a version
on the send path
be concentrated on a
to a version of
concentrated on a small
a version of the
on a small number
now that they have
where in the sinks
that they have been
version of the andrew
a small number of
they have been staggered
of the andrew file
small number of servers
have been staggered at
we use a simple
the andrew file system
been staggered at the
use a simple round
staggered at the start
must be eagerly replicated
speedups for the two
for the two workloads
robin policy of multiplexing
also relevant is sundr
policy of multiplexing between
the two workloads of
of multiplexing between data
two workloads of the
multiplexing between data feeds
r fire for any
the secure untrusted data
fire for any i
secure untrusted data repository
for any i data
workloads of the gw
and on the receive
of the gw test
on the receive path
any i data packets
the gw test are
gw test are shown
where forwarded packets are
forwarded packets are treated
the outlined scheme works
relative to the performance
outlined scheme works when
to the performance of
scheme works when i
the performance of afs
packets are treated as
performance of afs at
works when i is
are treated as control
when i is greater
treated as control traffic
i is greater than
this file system allows
is greater than or
file system allows clients
greater than or equal
system allows clients to
and while they re
than or equal to
while they re prioritized
or equal to r
they re prioritized over
allows clients to detect
re prioritized over data
clients to detect against
to detect against malicious
as is usually the
traffic are scaled down
detect against malicious or
are scaled down further
they are treated as
scaled down further in
against malicious or compromised
is usually the case
malicious or compromised storage
down further in parallel
or compromised storage servers
are treated as equally
compromised storage servers or
treated as equally important
storage servers or hosting
as equally important as
the graphs in figure
equally important as tokens
if i is smaller
servers or hosting platforms
i is smaller than
or hosting platforms by
they also increase the
hosting platforms by providing
also increase the overall
platforms by providing fork
validate the incorporation of
is smaller than r
increase the overall volume
by providing fork consistency
the incorporation of rpc
the overall volume of
incorporation of rpc priorities
the bin with index
overall volume of i
bin with index x
a property which ensures
with index x fires
property which ensures that
since all the foreground
which ensures that clients
all the foreground workloads
index x fires at
the foreground workloads improve
ensures that clients can
foreground workloads improve their
o that the nodes
workloads improve their performance
that the nodes process
improve their performance substantially
that clients can detect
their performance substantially at
clients can detect integrity
performance substantially at lower
can detect integrity failures
substantially at lower bandwidths
detect integrity failures as
integrity failures as long
tokens are processed with
failures as long as
are processed with higher
as long as they
processed with higher latency
long as they see
relative to mfs with
as they see each
to mfs with no
they see each other
mfs with no priorities
see each other s
each other s file
other s file modifications
similar techniques could be
the decrease in throughput
techniques could be used
decrease in throughput for
could be used to
in throughput for the
be used to recover
used to recover data
to recover data from
recover data from client
parameter trace mostly writes
data from client working
the initial firing sizes
from client working copies
initial firing sizes would
client working copies in
firing sizes would be
working copies in the
copies in the event
histogram of maximum alarm
in the event of
of maximum alarm delays
the event of a
for the first bin
event of a catastrophic
the first bin and
of a catastrophic cloud
maximum alarm delays in
a catastrophic cloud failure
for the second bin
once code repositories are
code repositories are stored
repositories are stored in
if r and i
are stored in the
r and i are
stored in the cloud
and i are not
i are not integral
are not integral multiples
not integral multiples of
integral multiples of each
one might imagine enabling
multiples of each other
might imagine enabling mashups
imagine enabling mashups in
enabling mashups in ways
histogram of maximum alarm
mashups in ways not
of maximum alarm delays
in ways not previously
maximum alarm delays in
ways not previously possible
limiting still works but
still works but is
works but is slightly
but is slightly less
is slightly less effective
slightly less effective due
less effective due to
web based code viewers
effective due to rounding
due to rounding errors
delaying xors in the
xors in the straightforward
in the straightforward implementation
and cross reference viewers
cross reference viewers might
reference viewers might be
viewers might be built
overheads in a lightly
might be built by
repair packets are transmitted
be built by third
packets are transmitted as
are transmitted as soon
transmitted as soon as
loaded system so far
as soon as they
system so far the
soon as they are
so far the evaluation
as they are generated
far the evaluation has
pulling data from the
the evaluation has focused
data from the repositories
evaluation has focused on
from the repositories of
has focused on scenarios
this results in the
focused on scenarios where
the repositories of several
on scenarios where the
results in the repair
scenarios where the system
repositories of several distinct
in the repair packet
of several distinct communities
where the system was
the repair packet leaving
the system was heavily
repair packet leaving immediately
system was heavily loaded
packet leaving immediately after
leaving immediately after the
immediately after the last
after the last data
the last data packet
last data packet that
with unbounded multicast rates
data packet that was
unbounded multicast rates and
packet that was added
multicast rates and occasional
that was added to
rates and occasional perturbations
was added to it
seeks to enable such
to enable such applications
which lowers burst tolerance
enable such applications by
lowers burst tolerance if
we traced degraded performance
burst tolerance if the
traced degraded performance or
tolerance if the repair
degraded performance or scheduling
if the repair packet
performance or scheduling delays
the repair packet was
or scheduling delays to
such applications by granting
repair packet was generated
applications by granting direct
packet was generated at
scheduling delays to memory
was generated at interleave
by granting direct access
generated at interleave i
granting direct access of
direct access of cloud
access of cloud storage
of cloud storage to
cloud storage to third
storage to third parties
the resulting protocol can
but how does the
resulting protocol can tolerate
how does the system
protocol can tolerate a
does the system behave
can tolerate a burst
subject to the data
tolerate a burst of
the system behave when
a burst of i
system behave when lightly
burst of i lost
behave when lightly loaded
of i lost data
to the data owner
i lost data packets
the data owner s
lost data packets excluding
data owner s security
data packets excluding the
do similar phenomena occur
packets excluding the repair
owner s security requirements
here we ll see
we ll see that
but the burst could
ll see that load
a question that may
the burst could swallow
question that may naturally
see that load has
burst could swallow both
that load has a
that may naturally arise
load has a super
could swallow both the
may naturally arise is
swallow both the repair
both the repair and
linear impact on performance
the repair and the
repair and the last
why not use a
and the last data
not use a general
the last data packet
use a general purpose
last data packet in
a general purpose file
data packet in it
general purpose file system
the growth in memory
purpose file system interface
packet in it as
file system interface to
growth in memory consumption
in it as they
system interface to s
in memory consumption causes
it as they are
these traces are representative
as they are not
memory consumption causes slowdowns
they are not separated
traces are representative periods
are not separated by
consumption causes slowdowns that
not separated by the
are representative periods of
separated by the requisite
causes slowdowns that amplify
by the requisite interleave
representative periods of mixed
slowdowns that amplify the
periods of mixed read
that amplify the increased
of mixed read and
amplify the increased latencies
mixed read and write
and store a repository
the increased latencies associated
read and write activity
the solution to this
store a repository on
solution to this is
a repository on that
increased latencies associated with
the durations are from
to this is simple
latencies associated with the
durations are from the
this is simple delay
are from the original
associated with the growth
this is indeed possible
from the original ntfs
is indeed possible to
the original ntfs traces
indeed possible to do
with the growth in
is simple delay sending
the growth in traffic
simple delay sending the
note that the total
but would entail pushing
that the total file
delay sending the repair
to show this we
the total file sizes
show this we designed
sending the repair packet
this we designed experiments
total file sizes represent
we designed experiments that
file sizes represent the
designed experiments that vary
sizes represent the amount
experiments that vary the
the repair packet generated
would entail pushing temporary
repair packet generated by
entail pushing temporary files
represent the amount fetched
pushing temporary files such
packet generated by a
that vary the multicast
generated by a repair
vary the multicast rate
the amount fetched by
temporary files such as
amount fetched by mfs
files such as transactions
fetched by mfs during
by a repair bin
by mfs during the
a repair bin until
mfs during the trace
repair bin until the
bin until the next
until the next time
the next time a
and incurring additional monetary
showed that the load
incurring additional monetary costs
that the load on
additional monetary costs due
the load on receivers
monetary costs due to
load on receivers grows
costs due to the
on receivers grows roughly
due to the increased
receivers grows roughly linearly
to the increased number
next time a data
where this is exceed
time a data packet
this is exceed by
a data packet is
as expected given the
data packet is added
expected given the linearly
packet is added to
given the linearly increasing
is added to the
the linearly increasing load
added to the now
the increased number of
is exceed by the
to the now empty
increased number of s
exceed by the write
the now empty bin
negligible loss rates and
by the write traffic
loss rates and the
rates and the nearly
and the nearly flat
the nearly flat curve
which happens i packets
the additional traffic is
happens i packets later
nearly flat curve of
i packets later and
additional traffic is due
packets later and introduces
traffic is due to
there would also likely
is due to new
would also likely be
due to new files
also likely be performance
to new files being
likely be performance problems
new files being created
later and introduces the
files being created or
flat curve of memory
and introduces the required
being created or existing
introduces the required interleave
created or existing ones
curve of memory consumption
the required interleave between
or existing ones extended
required interleave between the
since file append and
interleave between the repair
file append and rename
between the repair packet
append and rename operations
the repair packet and
and rename operations do
repair packet and the
time spent on rpcs
packet and the last
rename operations do not
and the last data
operations do not map
the last data packet
do not map efficiently
last data packet included
not map efficiently to
data packet included in
map efficiently to s
packet included in it
the latter reflecting our
latter reflecting our cooperative
notice that although transmitting
reflecting our cooperative caching
that although transmitting the
our cooperative caching policy
although transmitting the xor
transmitting the xor immediately
the xor immediately results
xor immediately results in
load on the sender
immediately results in faster
results in faster recovery
fs that is aware
that is aware of
is aware of subversion
doing so also reduces
aware of subversion s
so also reduces the
of subversion s file
also reduces the probability
subversion s file naming
because the linear growth
s file naming and
the linear growth of
reduces the probability of
file naming and use
the probability of a
linear growth of traffic
naming and use scenario
probability of a lost
and use scenario could
of a lost packet
use scenario could of
a lost packet being
scenario could of course
combined with our fixed
could of course overcome
with our fixed rate
of course overcome these
our fixed rate of
lost packet being recovered
course overcome these limitations
fixed rate of state
overcome these limitations by
rate of state aggregation
these limitations by pushing
limitations by pushing only
by pushing only what
pushing only what is
increases the amount of
only what is actually
off results in a
what is actually required
the amount of unacknowledged
results in a minor
amount of unacknowledged data
is actually required into
in a minor control
actually required into s
a minor control knob
minor control knob permitting
control knob permitting us
knob permitting us to
permitting us to balance
us to balance speed
to balance speed against
balance speed against burst
but we believe that
speed against burst tolerance
we believe that such
believe that such specialized
that such specialized tools
such specialized tools are
our default configuration is
specialized tools are better
default configuration is to
tools are better built
configuration is to transmit
are better built on
is to transmit the
better built on top
to transmit the xor
this triggers higher overheads
built on top of
transmit the xor immediately
on top of a
top of a file
of a file system
a file system abstraction
file system abstraction than
system abstraction than pushed
abstraction than pushed underneath
the time spent in
than pushed underneath it
time spent in the
spent in the garbage
in the garbage collector
the garbage collector grows
garbage collector grows from
c onclusion we have
onclusion we have shown
envelope analysis to start
we have shown that
analysis to start with
have shown that the
shown that the cost
that the cost of
the cost of using
we note that no
cost of using a
note that no two
ntfs workloads in addition
that no two repair
of using a cloud
workloads in addition to
using a cloud computing
in addition to measuring
a cloud computing storage
no two repair packets
cloud computing storage service
two repair packets generated
computing storage service for
repair packets generated at
storage service for source
packets generated at different
service for source code
generated at different interleaves
for source code repository
at different interleaves i
source code repository hosting
addition to measuring the
code repository hosting is
to measuring the performance
combined with a linear
measuring the performance of
with a linear growth
the performance of mfs
repository hosting is low
a linear growth of
performance of mfs with
linear growth of cpu
of mfs with synthetic
growth of cpu usage
mfs with synthetic workloads
of cpu usage due
both for individual projects
cpu usage due to
for individual projects and
usage due to the
individual projects and moderately
due to the increasing
projects and moderately sized
to the increasing volume
and moderately sized communities
the increasing volume of
we have also conducted
increasing volume of traffic
have also conducted experiments
also conducted experiments with
considering the costs of
conducted experiments with traces
the costs of a
these overheads cause the
experiments with traces gathered
will have more than
with traces gathered from
overheads cause the super
traces gathered from the
have more than one
gathered from the windows
costs of a resilient
more than one data
of a resilient local
linear growth of cpu
than one data packet
from the windows nt
a resilient local storage
the windows nt file
one data packet in
growth of cpu overhead
data packet in common
of cpu overhead shown
packet in common as
cpu overhead shown on
in common as long
overhead shown on figure
common as long as
windows nt file system
resilient local storage system
as long as the
local storage system of
long as the least
storage system of scsi
as the least common
system of scsi disks
the least common multiple
of scsi disks and
scsi disks and tape
disks and tape backup
the increasing number of
cloud computing is a
increasing number of unacknowledged
of the interleaves is
computing is a very
the interleaves is greater
number of unacknowledged requests
is a very attractive
interleaves is greater than
a very attractive solution
is greater than r
very attractive solution for
greater than r i
attractive solution for this
of unacknowledged requests and
solution for this application
unacknowledged requests and the
requests and the resulting
although mfs is implemented
and the resulting overheads
mfs is implemented on
our implementation of s
is implemented on a
pairings of repair bins
implemented on a variant
the resulting overheads rise
of repair bins in
resulting overheads rise sharply
repair bins in two
vn brings this concept
bins in two different
overheads rise sharply at
in two different layers
brings this concept a
two different layers with
this concept a step
different layers with interleaves
concept a step closer
layers with interleaves i
a step closer to
on a variant of
rise sharply at the
step closer to becoming
sharply at the highest
closer to becoming reality
at the highest rates
a variant of unix
the highest rates because
highest rates because of
rates because of the
because of the increasing
and provides evidence that
and ntfs has a
provides evidence that performance
of the increasing token
evidence that performance will
the increasing token roundtrip
that performance will be
increasing token roundtrip time
performance will be acceptable
ntfs has a somewhat
will be acceptable for
has a somewhat different
be acceptable for typical
a somewhat different interface
acceptable for typical use
somewhat different interface to
for typical use scenarios
the issue here is
different interface to the
issue here is that
interface to the file
here is that the
to the file system
is that the amount
that the amount of
the amount of i
the traces were converted
a good rule of
traces were converted to
o to be processed
were converted to run
to be processed increases
converted to run on
good rule of thumb
to run on top
rule of thumb is
run on top of
of thumb is to
much as in some
thumb is to select
as in some of
on top of mfs
in some of the
top of mfs with
some of the earlier
is to select interleaves
of mfs with little
to select interleaves that
mfs with little difficulty
of the earlier scenarios
select interleaves that are
technological impact of magnetic
interleaves that are relatively
impact of magnetic hard
that are relatively prime
of magnetic hard disk
the original traces recorded
this delays tokens as
magnetic hard disk drives
delays tokens as a
original traces recorded file
tokens as a function
hard disk drives on
as a function of
disk drives on storage
a function of the
drives on storage systems
function of the growing
traces recorded file accesses
are relatively prime to
recorded file accesses on
relatively prime to maximize
file accesses on a
prime to maximize their
accesses on a set
to maximize their lcm
on a set of
of the growing volume
a set of machines
the growing volume of
set of machines in
growing volume of multicast
of machines in a
and also ensure that
volume of multicast traffic
also ensure that the
machines in a lan
ensure that the larger
that the larger interleave
the larger interleave is
larger interleave is greater
we confirm the hypothesis
interleave is greater than
confirm the hypothesis by
a majority of the
the hypothesis by looking
is greater than r
majority of the accesses
hypothesis by looking at
of the accesses were
by looking at the
the accesses were local
looking at the end
accesses were local but
let us assume that
were local but some
us assume that packets
local but some were
assume that packets are
but some were to
that packets are dropped
some were to remote
packets are dropped with
were to remote machines
are dropped with uniform
we extracted subintervals from
extracted subintervals from the
subintervals from the traces
given a lost data
from the traces which
a lost data packet
the traces which featured
traces which featured interesting
which featured interesting file
featured interesting file system
what is the probability
interesting file system behaviour
is the probability that
file system behaviour and
the probability that we
system behaviour and processed
probability that we can
behaviour and processed them
that we can recover
and processed them to
we can recover it
we would expect latency
processed them to remove
would expect latency to
them to remove accesses
expect latency to decrease
to remove accesses to
latency to decrease as
we can recover a
to decrease as the
remove accesses to files
decrease as the sending
accesses to files over
can recover a data
as the sending rate
recover a data packet
the sending rate increases
a data packet if
sending rate increases because
data packet if at
rate increases because the
packet if at least
increases because the system
if at least one
this preprocessing was necessary
at least one of
because the system operates
least one of the
the system operates more
one of the c
system operates more smoothly
preprocessing was necessary to
of the c xors
was necessary to eliminate
the c xors containing
necessary to eliminate the
c xors containing it
to eliminate the influence
xors containing it is
eliminate the influence of
avoiding context switching overheads
the influence of extremely
containing it is received
influence of extremely large
context switching overheads and
of extremely large nt
it is received correctly
extremely large nt system
switching overheads and the
is received correctly and
overheads and the extra
received correctly and usable
large nt system files
and the extra latencies
the extra latencies caused
extra latencies caused by
latencies caused by the
caused by the small
by the small amount
the small amount of
small amount of buffering
amount of buffering in
of buffering in our
buffering in our protocol
all the other data
in our protocol stack
the other data packets
other data packets in
data packets in it
packets in it have
of the file system
with larger packets once
in it have also
larger packets once the
the file system traffic
packets once the rate
it have also been
file system traffic in
have also been received
once the rate exceeds
also been received correctly
system traffic in some
traffic in some portions
in some portions of
some portions of the
portions of the original
the probability of which
of the original traces
probability of which is
of which is simply
given that mfs retrieves
that mfs retrieves and
mfs retrieves and writes
retrieves and writes back
and writes back whole
writes back whole files
including these system files
the latency starts increasing
these system files would
latency starts increasing again
system files would have
files would have distorted
would have distorted the
have distorted the experiments
the probability of a
due to the longer
probability of a received
distorted the experiments at
to the longer pipeline
the experiments at low
of a received xor
experiments at low bandwidths
the longer pipeline at
a received xor being
longer pipeline at the
received xor being unusable
pipeline at the receive
xor being unusable is
at the receive side
being unusable is the
the receive side and
unusable is the complement
receive side and other
side and other phenomena
gives statistics for the
and other phenomena just
statistics for the three
other phenomena just mentioned
for the three traces
this is not the
a trace in which
is not the case
trace in which reads
not the case for
in which reads predominate
the case for small
case for small packets
a trace in which
trace in which writes
in which writes predominate
and one containing exceptionally
one containing exceptionally heavy
containing exceptionally heavy file
exceptionally heavy file system
heavy file system traffic
here the load on
each trace was run
the load on the
trace was run over
load on the system
was run over mfs
on the system is
run over mfs with
the system is much
over mfs with the
the probability x of
system is much smaller
mfs with the combinations
probability x of a
with the combinations of
x of a sent
the combinations of synchronous
of a sent xor
combinations of synchronous and
a sent xor being
of synchronous and asynchronous
sent xor being dropped
the above observations are
xor being dropped or
above observations are consistent
synchronous and asynchronous writes
observations are consistent with
brewer s conjecture and
are consistent with the
and asynchronous writes and
consistent with the sharp
s conjecture and the
with the sharp rise
conjecture and the feasibility
the sharp rise of
and the feasibility of
sharp rise of the
asynchronous writes and differentiated
being dropped or unusable
writes and differentiated and
rise of the average
and differentiated and uniform
of the average delay
differentiated and uniform priorities
the average delay for
and uniform priorities in
average delay for timer
the feasibility of consistent
dropped or unusable is
feasibility of consistent available
delay for timer events
uniform priorities in previous
or unusable is the
priorities in previous experiments
of consistent available partition
unusable is the sum
is the sum of
the sum of the
and the results are
sum of the probability
the results are given
of the probability that
results are given in
the probability that it
in in acm sigact
probability that it was
in acm sigact news
that it was dropped
are given in figure
it was dropped and
was dropped and the
dropped and the probability
and the probability that
as the rate changes
the probability that it
the rate changes from
probability that it was
that it was received
to interpret these graphs
it was received and
was received and unusable
look for instance at
for instance at the
instance at the heavy
at the heavy load
the heavy load bar
heavy load bar mostly
load bar mostly reads
timer delays at the
delays at the receiver
at the receiver increase
the receiver increase from
and on the sender
filesystem backup to the
backup to the cloud
since it is easy
it is easy to
number of unacknowledged messages
is easy to ensure
of unacknowledged messages and
easy to ensure that
unacknowledged messages and average
to ensure that no
messages and average token
ensure that no two
and average token roundtrip
that no two xors
average token roundtrip time
no two xors share
token roundtrip time as
two xors share more
roundtrip time as a
xors share more than
time as a function
share more than one
as a function of
more than one data
a function of the
than one data packet
function of the sending
of the sending rate
applications unique files total
the usability probabilities of
unique files total file
usability probabilities of different
files total file sizes
probabilities of different xors
of different xors are
different xors are independent
the probability of all
probability of all the
of all the c
all the c xors
linearly growing memory use
the c xors being
growing memory use on
c xors being dropped
memory use on sender
xors being dropped or
use on sender and
being dropped or unusable
on sender and the
dropped or unusable is
sender and the nearly
or unusable is xc
and the nearly flat
the nearly flat usage
nearly flat usage on
flat usage on the
usage on the receiver
on the receiver as
the receiver as a
the probability of correctly
receiver as a function
probability of correctly receiving
as a function of
of correctly receiving at
a function of the
correctly receiving at least
function of the sending
receiving at least one
grep in the gw
of the sending rate
in the gw workload
at least one usable
the gw workload even
least one usable xor
gw workload even is
one usable xor is
workload even is less
even is less than
is less than would
less than would be
than would be expected
would be expected with
be expected with reduced
expected with reduced bandwidth
here uniform priorities result
the probability of recovering
uniform priorities result in
probability of recovering the
priorities result in throughput
of recovering the lost
result in throughput linear
recovering the lost data
in throughput linear in
receive latency for varying
the lost data packet
latency for varying rate
lost data packet is
throughput linear in the
linear in the bandwidth
harnessing storage clouds for
storage clouds for high
with various message sizes
clouds for high performance
for high performance content
while differentiated priorities are
high performance content delivery
differentiated priorities are less
priorities are less sensitive
the rc and gc
rc and gc tests
and gc tests show
gc tests show the
tests show the benefit
alarm firing delays on
show the benefit of
firing delays on sender
the benefit of asynchronous
delays on sender and
benefit of asynchronous writeback
on sender and receiver
sender and receiver as
and receiver as a
th international conference on
receiver as a function
international conference on service
as a function of
since the updates from
a function of sending
the updates from the
function of sending rate
updates from the compile
from the compile workload
the compile workload are
compile workload are committed
workload are committed sooner
are committed sooner to
committed sooner to the
form formula only gives
sooner to the server
formula only gives us
to the server than
only gives us a
the server than with
gives us a lower
server than with synchronous
us a lower bound
than with synchronous writes
a lower bound on
lower bound on the
bound on the recovery
on the recovery probability
due to the overlap
to the overlap of
since the xor usability
the overlap of think
the xor usability formula
overlap of think time
xor usability formula does
of think time with
usability formula does not
group memory consumption in
think time with asynchronous
memory consumption in a
time with asynchronous writes
consumption in a final
formula does not factor
in a final set
does not factor in
a final set of
not factor in the
final set of experiments
factor in the probability
in the probability of
the probability of the
though uniform priorities provide
probability of the other
we focus on scalability
of the other data
focus on scalability with
uniform priorities provide better
on scalability with the
the other data packets
scalability with the number
priorities provide better performance
other data packets in
provide better performance for
data packets in the
better performance for the
packets in the xor
performance for the write
in the xor being
with the number of
for the write component
the number of groups
the write component of
the xor being dropped
write component of the
xor being dropped and
component of the rw
being dropped and recovered
of the rw test
a single sender multicasts
the rw test at
single sender multicasts to
sender multicasts to a
multicasts to a varying
to a varying number
a varying number of
varying number of groups
number of groups in
we extend the analysis
of groups in a
extend the analysis to
groups in a roundrobin
the analysis to bursty
in a roundrobin fashion
analysis to bursty losses
all receivers join all
if the lost data
receivers join all groups
the lost data packet
lost data packet was
data packet was part
packet was part of
as is to be
was part of a
and since the groups
part of a loss
since the groups are
of a loss burst
the groups are perfectly
a loss burst of
groups are perfectly overlapped
loss burst of size
is to be expected
burst of size b
the system contains a
an elastic transactional data
since we are prioritising
system contains a single
we are prioritising reads
contains a single region
repair packets generated at
elastic transactional data store
packets generated at interleaves
transactional data store in
generated at interleaves less
data store in the
qsm s regional recovery
at interleaves less than
s regional recovery protocol
store in the cloud
this benefit largely vanishes
regional recovery protocol is
benefit largely vanishes at
recovery protocol is oblivious
largely vanishes at lower
protocol is oblivious to
vanishes at lower bandwidths
is oblivious to the
interleaves less than b
oblivious to the groups
less than b are
than b are dropped
b are dropped or
though we have concentrated
are dropped or useless
we have concentrated on
dropped or useless with
hence the receivers behave
have concentrated on determining
the receivers behave identically
or useless with high
receivers behave identically no
useless with high probability
behave identically no matter
concentrated on determining the
identically no matter how
on determining the benefit
no matter how many
determining the benefit of
and we can discount
the benefit of rpc
we can discount them
matter how many groups
benefit of rpc priorities
how many groups we
of rpc priorities by
many groups we use
rpc priorities by a
priorities by a comparison
by a comparison of
a comparison of different
on the other hand
of recovering the data
comparison of different configurations
recovering the data packet
of different configurations of
the data packet is
different configurations of mfs
data packet is then
configurations of mfs to
the sender maintains a
of mfs to one
sender maintains a number
mfs to one another
maintains a number of
a number of per
the chubby lock service
chubby lock service for
we have also performed
lock service for loosely
have also performed a
also performed a few
is the number of
this affects the sender
the number of xors
affects the sender s
number of xors generated
the sender s memory
of xors generated at
sender s memory footprint
performed a few experiments
xors generated at interleaves
a few experiments to
generated at interleaves greater
few experiments to compare
at interleaves greater than
so changes to throughput
experiments to compare the
interleaves greater than b
to compare the performance
changes to throughput or
compare the performance of
to throughput or protocol
the performance of mfs
throughput or protocol behavior
the formulae derived for
or protocol behavior must
formulae derived for xor
protocol behavior must be
performance of mfs to
behavior must be directly
derived for xor usability
must be directly or
for xor usability still
be directly or indirectly
xor usability still hold
directly or indirectly linked
of mfs to a
or indirectly linked to
mfs to a standard
indirectly linked to memory
to a standard distributed
linked to memory usage
a standard distributed file
th conference on usenix
standard distributed file system
since packet losses with
conference on usenix symposium
packet losses with more
on usenix symposium on
we do not expect
usenix symposium on operating
losses with more than
do not expect the
with more than b
symposium on operating systems
more than b intervening
not expect the token
than b intervening packets
illustrates the result of
b intervening packets between
the result of running
intervening packets between them
expect the token roundtrip
on operating systems design
the token roundtrip time
operating systems design and
result of running the
systems design and implementation
of running the gw
packets between them have
token roundtrip time or
between them have independent
running the gw test
roundtrip time or the
the gw test over
them have independent probability
time or the amount
gw test over mfs
or the amount of
test over mfs and
the amount of messages
over mfs and an
amount of messages pending
there is only correlation
of messages pending acknowledgement
is only correlation within
messages pending acknowledgement to
only correlation within the
mfs and an andrew
pending acknowledgement to vary
correlation within the bursts
and an andrew file
acknowledgement to vary with
an andrew file system
to vary with the
vary with the number
with the number of
the number of groups
how does this compare
does this compare to
this compare to traditional
we used the arla
used the arla implementation
the arla implementation of
arla implementation of the
implementation of the afs
of the afs cache
the afs cache manager
codes such as reed
groups this is the
this is the case
and the openafs server
afs uses a udp
based rpc library without
rpc library without priorities
in this range memory
this range memory consumption
range memory consumption on
memory consumption on the
c repair packets are
consumption on the sender
repair packets are generated
on the sender grows
packets are generated and
the results largely correspond
are generated and sent
results largely correspond to
generated and sent for
largely correspond to those
and sent for every
correspond to those in
sent for every r
to those in figure
for every r data
every r data packets
and the correct delivery
the correct delivery of
mfs significantly outperforms afs
correct delivery of any
significantly outperforms afs for
and so does the
delivery of any r
so does the time
of any r of
does the time spent
any r of the
the time spent in
r of the r
time spent in the
outperforms afs for the
spent in the clr
afs for the foreground
for the foreground grep
the foreground grep workload
c packets transmitted is
packets transmitted is sufficient
transmitted is sufficient to
is sufficient to reconstruct
sufficient to reconstruct the
since afs effectively uses
to reconstruct the original
afs effectively uses synchronous
reconstruct the original r
effectively uses synchronous rpcs
the original r data
uses synchronous rpcs with
original r data packets
synchronous rpcs with uniform
rpcs with uniform priorities
in the background write
the background write workload
given a lost data
a lost data packet
afs slightly outperforms mfs
we can recover it
can recover it if
but it is both
recover it if at
it is both a
it if at least
is both a more
if at least r
both a more mature
at least r packets
a more mature system
least r packets are
inspection of the managed
r packets are received
of the managed heap
packets are received correctly
the managed heap in
and more optimised than
managed heap in a
more optimised than mfs
heap in a debugger
optimised than mfs for
are received correctly in
in a debugger shows
than mfs for this
received correctly in the
a debugger shows that
mfs for this sort
debugger shows that the
for this sort of
correctly in the encoding
shows that the growth
this sort of communication
that the growth in
in the encoding set
the growth in memory
the encoding set of
growth in memory used
encoding set of r
in memory used is
memory used is caused
since the results of
used is caused not
the results of running
is caused not by
results of running the
caused not by messages
c data and repair
of running the other
data and repair packets
running the other tests
and repair packets that
the other tests are
repair packets that the
other tests are similar
packets that the lost
but by the per
that the lost packet
the lost packet belongs
lost packet belongs to
we omit them for
omit them for brevity
group elements of the
elements of the protocol
of the protocol stack
each maintains a queue
the probability of recovering
mostly reads mostly writes
probability of recovering a
reads mostly writes heavy
of recovering a lost
mostly writes heavy load
recovering a lost packet
writes heavy load store
a lost packet is
heavy load store overhead
lost packet is equivalent
load store overhead priorities
packet is equivalent to
store overhead priorities uniform
small structures for profiling
is equivalent to the
overhead priorities uniform priorities
equivalent to the probability
structures for profiling etc
to the probability of
priorities uniform priorities uniform
the probability of losing
uniform priorities uniform synchronous
probability of losing c
priorities uniform synchronous asynchronous
with thousands of groups
uniform synchronous asynchronous time
synchronous asynchronous time spent
asynchronous time spent on
or less packets from
time spent on rpcs
these add up to
less packets from the
add up to tens
packets from the total
up to tens of
from the total r
to tens of megabytes
we can confirm the
can confirm the theory
confirm the theory by
the theory by turning
since the number of
theory by turning on
the number of other
by turning on additional
number of other lost
turning on additional tracing
of other lost packets
on additional tracing in
other lost packets in
additional tracing in the
lost packets in the
tracing in the per
packets in the xor
in the xor is
the xor is a
xor is a random
is a random variable
a random variable y
random variable y and
this tracing is lightweight
variable y and has
tracing is lightweight and
y and has a
is lightweight and has
and has a binomial
lightweight and has little
has a binomial distribution
and has little effect
a binomial distribution with
has little effect on
binomial distribution with parameters
little effect on cpu
effect on cpu consumption
but it increases the
it increases the memory
increases the memory footprint
the memory footprint by
memory footprint by adding
footprint by adding additional
by adding additional data
adding additional data structures
additional data structures that
data structures that are
structures that are updated
that are updated once
are updated once per
updated once per second
the dangers of replication
dangers of replication and
of replication and a
replication and a solution
which burdens the gc
is the summation p
the summation p z
summation p z c
acm sigmod international conference
sigmod international conference on
it is worth noting
international conference on management
is worth noting that
conference on management of
worth noting that the
on management of data
noting that the memory
that the memory usages
the memory usages reported
memory usages reported here
we plot the recovery
usages reported here are
plot the recovery probability
reported here are averages
the recovery probability curves
recovery probability curves for
probability curves for layered
curves for layered interleaving
for layered interleaving and
layered interleaving and reed
solomon against uniformly random
and the peak values
against uniformly random loss
the peak values are
uniformly random loss rate
peak values are typically
the nodes on our
note that the curves
nodes on our cluster
that the curves are
on our cluster only
the curves are very
our cluster only have
curves are very close
are very close to
very close to each
close to each other
especially in the loss
in the loss range
the loss range of
loss range of interest
range of interest between
local recovery for receiver
recovery for receiver loss
for receiver loss in
receiver loss in the
memory footprint is significant
loss in the absence
in the absence of
the absence of intelligent
absence of intelligent flow
of intelligent flow control
intelligent flow control mechanisms
flow control mechanisms like
control mechanisms like tcp
inexpensive data center end
the peak footprint approaches
hosts can be easily
can be easily overwhelmed
be easily overwhelmed and
easily overwhelmed and drop
overwhelmed and drop packets
and drop packets during
drop packets during traffic
packets during traffic spikes
during traffic spikes or
traffic spikes or cpu
and the system is
the system is close
intensive maintenance tasks like
system is close to
maintenance tasks like garbage
is close to swapping
tasks like garbage collection
level protocols layered over
protocols layered over udp
layered over udp for
over udp for reliable
udp for reliable multicast
or high speed data
high speed data transfer
groups are enough to
are enough to trigger
enough to trigger signs
to trigger signs of
trigger signs of instability
token roundtrip times start
roundtrip times start to
times start to grow
for example would ordinarily
example would ordinarily go
would ordinarily go back
thus delaying message cleanup
ordinarily go back to
go back to the
back to the sender
to the sender to
the sender to retrieve
sender to retrieve the
to retrieve the lost
retrieve the lost packet
even though it was
though it was dropped
it was dropped at
and increasing memory overhead
was dropped at the
dropped at the receiver
at the receiver after
the receiver after covering
receiver after covering the
after covering the entire
covering the entire geographical
the entire geographical distance
the maelstrom proxy acts
maelstrom proxy acts as
proxy acts as a
acts as a local
as a local packet
a local packet cache
although the process is
the process is fairly
process is fairly unpredictable
storing incoming packets for
incoming packets for a
we see spikes and
see spikes and anomalies
packets for a short
for a short period
secure untrusted data repository
a short period of
short period of time
period of time and
we can easily recognize
of time and providing
can easily recognize a
easily recognize a super
time and providing hooks
and providing hooks that
providing hooks that allow
linear trend starting at
hooks that allow protocols
trend starting at around
that allow protocols to
allow protocols to first
protocols to first query
to first query the
first query the cache
query the cache to
the cache to locate
cache to locate missing
to locate missing packets
th conference on symposium
locate missing packets before
conference on symposium on
missing packets before sending
on symposium on opearting
packets before sending retransmission
symposium on opearting systems
before sending retransmission requests
at around this point
sending retransmission requests back
on opearting systems design
retransmission requests back to
requests back to the
back to the sender
we also start to
also start to see
start to see occasional
to see occasional bursts
see occasional bursts of
occasional bursts of packet
future versions of maelstrom
bursts of packet losses
versions of maelstrom could
of maelstrom could potentially
maelstrom could potentially use
could potentially use knowledge
potentially use knowledge of
use knowledge of protocol
knowledge of protocol internals
of protocol internals to
protocol internals to transparently
internals to transparently intervene
often roughly correlated across
roughly correlated across receivers
such events trigger bursty
by intercepting and satisfying
events trigger bursty recovery
intercepting and satisfying retransmission
trigger bursty recovery overloads
and satisfying retransmission requests
satisfying retransmission requests sent
retransmission requests sent by
requests sent by the
sent by the receiver
by the receiver in
the receiver in a
receiver in a nak
or by resending packets
by resending packets when
resending packets when acknowledgments
number of messages pending
packets when acknowledgments are
of messages pending ack
when acknowledgments are not
messages pending ack and
acknowledgments are not observed
pending ack and token
are not observed within
ack and token roundtrip
not observed within a
and token roundtrip time
observed within a certain
token roundtrip time as
within a certain time
roundtrip time as a
a certain time period
time as a function
certain time period in
as a function of
time period in an
a function of the
period in an ack
function of the number
of the number of
the number of groups
implementation details we initially
details we initially implemented
we initially implemented and
initially implemented and evaluated
implemented and evaluated maelstrom
memory usage grows with
and evaluated maelstrom as
usage grows with the
evaluated maelstrom as a
grows with the number
maelstrom as a user
with the number of
the number of groups
beyond a certain threshold
performance turned out to
turned out to be
the system is increasingly
communal data sharing in
system is increasingly unstable
out to be limited
data sharing in public
to be limited by
sharing in public clouds
be limited by copying
limited by copying and
by copying and context
and we subsequently reimplemented
time spent in the
we subsequently reimplemented the
spent in the clr
subsequently reimplemented the system
in the clr code
reimplemented the system as
the system as a
system as a module
as a module that
a module that runs
module that runs within
that runs within the
runs within the linux
throughput decreases with the
decreases with the number
with the number of
the number of groups
at an encoding rate
an encoding rate of
all groups have the
groups have the same
have the same subscribers
the experimental prototype of
experimental prototype of the
prototype of the kernel
of the kernel version
the kernel version reaches
kernel version reaches output
version reaches output speeds
reaches output speeds close
output speeds close to
gigabit per second of
the key insight is
per second of combined
key insight is that
second of combined data
insight is that all
of combined data and
is that all these
combined data and fec
that all these effects
data and fec traffic
all these effects originate
these effects originate at
effects originate at the
originate at the sender
at the sender node
limited only by the
only by the capacity
by the capacity of
the capacity of the
capacity of the outbound
which is more loaded
of the outbound network
is more loaded and
the outbound network card
more loaded and less
loaded and less responsive
lambda networks are already
networks are already reaching
detailed analysis of the
are already reaching speeds
analysis of the captured
already reaching speeds of
of the captured network
the captured network traffic
captured network traffic shows
network traffic shows that
traffic shows that the
shows that the multicast
that the multicast stream
the multicast stream in
multicast stream in all
stream in all cases
in all cases looks
all cases looks basically
cases looks basically identical
and hence we cannot
hence we cannot attribute
we cannot attribute token
cannot attribute token latency
attribute token latency or
token latency or losses
latency or losses to
and higher speeds are
or losses to the
higher speeds are a
losses to the increased
speeds are a certainty
to the increased volume
are a certainty down
the increased volume of
a certainty down the
increased volume of traffic
certainty down the road
throughput spikes or longer
spikes or longer bursts
or longer bursts of
longer bursts of data
we envision maelstrom as
envision maelstrom as a
maelstrom as a small
as a small rack
the sender spends more
sender spends more time
spends more time transmitting
more time transmitting at
time transmitting at lower
style cluster of servers
transmitting at lower rates
each acting as an
acting as an individual
but doesn t produce
as an individual proxy
doesn t produce any
t produce any faster
produce any faster data
any faster data bursts
faster data bursts than
traffic would be distributed
data bursts than those
would be distributed over
bursts than those we
be distributed over such
than those we observe
distributed over such a
those we observe with
over such a rack
we observe with smaller
such a rack by
observe with smaller numbers
a rack by partitioning
with smaller numbers of
smaller numbers of groups
rack by partitioning the
by partitioning the address
partitioning the address space
the address space of
address space of the
space of the remote
of the remote data
the remote data center
remote data center and
data center and routing
center and routing different
and routing different segments
routing different segments of
different segments of the
segments of the space
of the space through
the space through distinct
receiver performance indicators such
space through distinct maelstrom
performance indicators such as
through distinct maelstrom appliance
indicators such as delays
distinct maelstrom appliance pairs
such as delays in
as delays in firing
delays in firing timer
in firing timer event
firing timer event or
timer event or cpu
event or cpu utilization
or cpu utilization don
we plan to experiment
cpu utilization don t
plan to experiment with
utilization don t show
to experiment with such
don t show any
experiment with such configurations
t show any noticeable
show any noticeable trend
which would also permit
would also permit us
also permit us to
permit us to explore
us to explore fault
all roads lead back
roads lead back to
lead back to the
back to the sender
if a maelstrom blade
and the main thing
a maelstrom blade fails
the main thing going
main thing going on
thing going on in
going on in the
on in the sender
in the sender is
the sender is that
sender is that it
is that it has
that it has a
it has a steadily
and to support load
has a steadily growing
a steadily growing memory
steadily growing memory footprint
balancing schemes that might
schemes that might vary
we also looked at
that might vary the
also looked at token
might vary the ip
looked at token round
vary the ip address
the ip address space
ip address space partitioning
address space partitioning dynamically
space partitioning dynamically to
partitioning dynamically to spread
dynamically to spread the
the distribution of token
to spread the encoding
distribution of token roundtrip
spread the encoding load
of token roundtrip times
the encoding load over
token roundtrip times for
encoding load over multiple
roundtrip times for different
load over multiple machines
times for different numbers
for different numbers of
different numbers of groups
numbers of groups shows
of groups shows an
groups shows an increase
shows an increase of
an increase of the
increase of the token
of the token roundtrip
the token roundtrip time
we present the implementation
present the implementation and
the miner s dilemma
the implementation and performance
caused almost entirely by
miner s dilemma ittay
implementation and performance of
s dilemma ittay eyal
and performance of a
dilemma ittay eyal cornell
performance of a single
ittay eyal cornell university
eyal cornell university abstract
cornell university abstract an
university abstract an open
of the tokens that
abstract an open distributed
the tokens that are
the kernel implementation is
an open distributed system
kernel implementation is a
tokens that are delayed
open distributed system can
that are delayed the
implementation is a module
distributed system can be
are delayed the most
system can be secured
is a module for
can be secured by
a module for linux
be secured by requiring
secured by requiring participants
by requiring participants to
requiring participants to present
participants to present proof
to present proof of
present proof of work
proof of work and
of work and rewarding
work and rewarding them
and rewarding them for
rewarding them for participation
which points to disruptive
points to disruptive events
to disruptive events as
disruptive events as the
events as the culprit
the bitcoin digital currency
with hooks into the
bitcoin digital currency introduced
hooks into the kernel
digital currency introduced this
into the kernel packet
currency introduced this mechanism
the kernel packet filter
rather than a uniform
than a uniform increase
a uniform increase of
uniform increase of the
which is adopted by
increase of the token
is adopted by almost
of the token processing
adopted by almost all
the token processing overhead
by almost all contemporary
almost all contemporary digital
all contemporary digital currencies
contemporary digital currencies and
digital currencies and related
currencies and related services
maelstrom proxies work in
a natural process leads
proxies work in pairs
we find that these
natural process leads participants
find that these tokens
process leads participants of
that these tokens were
leads participants of such
these tokens were most
participants of such systems
one on each side
of such systems to
tokens were most commonly
on each side of
were most commonly delayed
each side of the
most commonly delayed on
side of the long
commonly delayed on the
of the long haul
such systems to form
delayed on the sender
the long haul link
systems to form pools
with many thousands of
many thousands of groups
each proxy acts both
where members aggregate their
proxy acts both as
members aggregate their power
acts both as an
aggregate their power and
both as an ingress
the average time to
as an ingress and
their power and share
an ingress and egress
power and share the
average time to travel
ingress and egress router
and share the rewards
and egress router at
egress router at the
router at the same
at the same time
the same time since
experience with bitcoin shows
same time since they
with bitcoin shows that
time since they handle
bitcoin shows that the
since they handle duplex
shows that the largest
time to travel by
they handle duplex traffic
to travel by one
handle duplex traffic in
travel by one hop
duplex traffic in the
that the largest pools
by one hop from
the largest pools are
traffic in the following
one hop from sender
in the following manner
largest pools are often
hop from sender to
pools are often open
from sender to receiver
sender to receiver or
to receiver or receiver
receiver or receiver to
the egress router captures
allowing anyone to join
or receiver to sender
egress router captures ip
receiver to sender can
router captures ip packets
to sender can grow
captures ip packets and
sender can grow to
ip packets and creates
it has long been
can grow to nearly
packets and creates redundant
has long been known
and creates redundant fec
long been known that
creates redundant fec packets
been known that a
known that a member
that a member can
a member can sabotage
the original ip packets
member can sabotage an
original ip packets are
can sabotage an open
ip packets are routed
sabotage an open pool
packets are routed through
an open pool by
are routed through unaltered
open pool by seemingly
routed through unaltered as
pool by seemingly joining
through unaltered as they
by seemingly joining it
unaltered as they would
seemingly joining it but
as they would have
joining it but never
they would have been
it but never sharing
would have been originally
but never sharing its
as compared to an
never sharing its proofs
compared to an average
sharing its proofs of
its proofs of work
the redundant packets are
redundant packets are then
packets are then forwarded
ms per hop from
are then forwarded to
the pool shares its
then forwarded to the
per hop from receiver
pool shares its revenue
forwarded to the remote
shares its revenue with
hop from receiver to
to the remote ingress
from receiver to receiver
its revenue with the
the remote ingress router
revenue with the attacker
remote ingress router via
ingress router via a
router via a udp
via a udp channel
and so each of
so each of its
each of its participants
of its participants earns
the ingress router captures
its participants earns less
ingress router captures and
router captures and stores
captures and stores ip
the overloaded sender occasionally
and stores ip packets
overloaded sender occasionally releases
stores ip packets coming
sender occasionally releases the
ip packets coming from
occasionally releases the tokens
packets coming from the
releases the tokens with
we define and analyze
coming from the direction
the tokens with a
define and analyze a
from the direction of
and analyze a game
the direction of the
tokens with a delay
analyze a game where
direction of the egress
a game where pools
of the egress router
game where pools use
where pools use some
pools use some of
mostly reads mostly writes
use some of their
upon receipt of a
reads mostly writes heavy
receipt of a redundant
some of their participants
mostly writes heavy load
of a redundant packet
writes heavy load store
of their participants to
heavy load store overhead
their participants to infiltrate
load store overhead priorities
participants to infiltrate other
store overhead priorities uniform
to infiltrate other pools
an ip packet is
infiltrate other pools and
overhead priorities uniform priorities
other pools and perform
ip packet is recovered
pools and perform such
priorities uniform priorities uniform
and perform such an
packet is recovered if
uniform priorities uniform synchronous
is recovered if there
priorities uniform synchronous asynchronous
recovered if there is
perform such an attack
the value of the
uniform synchronous asynchronous figure
value of the delay
if there is an
of the delay grows
there is an opportunity
the delay grows with
is an opportunity to
delay grows with the
an opportunity to do
grows with the number
opportunity to do so
with the number of
with any number of
the number of groups
graphs of ntfs traces
any number of pools
redundant packets that can
packets that can be
that can be used
each trace ran with
can be used at
trace ran with synchronous
be used at a
ran with synchronous or
used at a later
with synchronous or asynchronous
at a later time
synchronous or asynchronous writes
attacks is not a
or asynchronous writes and
is not a nash
a later time are
asynchronous writes and uniform
not a nash equilibrium
writes and uniform or
our old culprit is
later time are stored
and uniform or differentiated
old culprit is back
uniform or differentiated priorities
we study the special
study the special cases
if the redundant packet
the special cases where
the redundant packet is
the total height of
redundant packet is useless
special cases where either
packet is useless it
related costs at the
total height of each
cases where either two
is useless it is
costs at the sender
height of each bar
where either two pools
of each bar denotes
useless it is immediately
each bar denotes the
either two pools or
bar denotes the time
it is immediately discarded
denotes the time from
two pools or any
the time from the
increasing the number of
pools or any number
time from the first
or any number of
upon recovery the ip
from the first to
recovery the ip packet
the first to last
the number of groups
any number of identical
number of groups slows
first to last write
the ip packet is
number of identical pools
ip packet is sent
of groups slows the
packet is sent through
groups slows the sender
is sent through a
and the shaded portion
of identical pools play
the shaded portion denotes
sent through a raw
identical pools play the
through a raw socket
shaded portion denotes the
a raw socket to
pools play the game
and this cascades to
play the game and
this cascades to create
the game and the
raw socket to its
game and the rest
socket to its intended
and the rest of
to its intended destination
the rest of the
cascades to create all
portion denotes the time
to create all sorts
denotes the time from
rest of the participants
create all sorts of
of the participants are
the time from the
using fec requires that
all sorts of downstream
the participants are uninvolved
sorts of downstream problems
fec requires that each
of downstream problems that
time from the first
downstream problems that can
from the first to
problems that can destabilize
requires that each data
that can destabilize the
in both of these
can destabilize the system
that each data packet
destabilize the system as
both of these cases
each data packet have
the system as a
of these cases there
system as a whole
data packet have a
these cases there exists
the first to last
packet have a unique
cases there exists an
have a unique identifier
first to last read
a unique identifier that
there exists an equilibrium
discussion the experiments just
unique identifier that the
the experiments just reported
exists an equilibrium that
experiments just reported make
the white portions denote
identifier that the receiver
white portions denote the
an equilibrium that constitutes
portions denote the extra
that the receiver can
denote the extra time
equilibrium that constitutes a
the extra time required
the receiver can use
extra time required to
that constitutes a tragedy
time required to complete
receiver can use to
required to complete all
constitutes a tragedy of
to complete all writes
can use to keep
complete all writes after
a tragedy of the
all writes after the
use to keep track
just reported make it
to keep track of
reported make it clear
tragedy of the commons
writes after the last
of the commons where
make it clear that
keep track of received
it clear that the
the commons where the
after the last read
track of received data
clear that the performance
of received data packets
the last read has
received data packets and
last read has finished
commons where the participating
data packets and to
limiting factor in the
packets and to identify
factor in the qsm
and to identify missing
in the qsm system
where the participating pools
to identify missing data
the qsm system is
identify missing data packets
qsm system is latency
missing data packets in
for asynchronous writeback with
the participating pools attack
asynchronous writeback with priorities
data packets in a
writeback with priorities in
packets in a repair
with priorities in the
in a repair packet
participating pools attack one
and that in addition
pools attack one another
that in addition to
attack one another and
in addition to protocol
one another and earn
addition to protocol factors
another and earn less
if we had access
and earn less than
we had access to
earn less than they
had access to end
less than they would
to protocol factors such
than they would have
protocol factors such as
they would have if
factors such as the
would have if none
such as the length
have if none had
as the length of
this shows that the
if none had attacked
shows that the total
we could have added
the length of token
could have added a
length of token rings
that the total duration
have added a header
the total duration of
added a header to
total duration of the
a header to each
duration of the trace
the decision whether or
header to each packet
latency is strongly influenced
of the trace with
decision whether or not
the trace with this
is strongly influenced by
trace with this mfs
whether or not to
to each packet with
or not to attack
each packet with a
not to attack is
packet with a unique
to attack is the
with a unique sequence
attack is the miner
a unique sequence number
is the miner s
with this mfs configuration
strongly influenced by the
the miner s dilemma
influenced by the memory
this mfs configuration is
by the memory footprint
the memory footprint of
memory footprint of the
footprint of the system
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
when we built the
we built the system
built the system it
the game is played
the system it was
game is played daily
system it was obvious
we intercept traffic transparently
it was obvious that
but all the fetch
was obvious that minimizing
all the fetch traffic
intercept traffic transparently and
the fetch traffic is
obvious that minimizing latency
is played daily by
that minimizing latency would
played daily by the
minimizing latency would be
daily by the active
latency would be important
fetch traffic is completed
traffic transparently and need
by the active bitcoin
traffic is completed within
transparently and need to
the active bitcoin pools
this motivated several of
motivated several of the
several of the design
of the design decisions
route it without modification
the design decisions discussed
it without modification or
which apparently choose not
design decisions discussed in
without modification or addition
decisions discussed in section
apparently choose not to
choose not to attack
seconds of the start
if this balance breaks
but the repeated linkage
the repeated linkage of
this is a significant
repeated linkage of latency
we identify ip packets
the revenue of open
identify ip packets by
revenue of open pools
is a significant improvement
linkage of latency and
a significant improvement over
of latency and oscillatory
significant improvement over the
latency and oscillatory throughputs
improvement over the alternative
of open pools might
over the alternative configurations
open pools might diminish
the alternative configurations measured
and oscillatory throughputs to
ip packets by a
oscillatory throughputs to memory
packets by a tuple
throughputs to memory was
making them unattractive to
by a tuple consisting
to memory was a
a tuple consisting of
memory was a surprise
tuple consisting of the
them unattractive to participants
consisting of the source
of the source and
the source and destination
source and destination ip
we expected a much
and destination ip address
expected a much smaller
seconds of the trace
a much smaller impact
of the trace are
the trace are taken
trace are taken up
are taken up by
taken up by asynchronously
we can summarize our
up by asynchronously writing
can summarize our design
by asynchronously writing back
summarize our design insights
size of the ip
our design insights as
of the ip header
asynchronously writing back file
design insights as follows
is a digital currency
writing back file updates
a digital currency that
the ip header plus
digital currency that is
ip header plus data
currency that is gaining
that is gaining acceptance
in all cases the
all cases the traces
and a checksum over
cases the traces take
a checksum over the
the traces take significantly
checksum over the ip
traces take significantly longer
over the ip data
take significantly longer than
minimize the memory footprint
significantly longer than they
the ip data payload
longer than they originally
than they originally did
they originally did in
originally did in ntfs
we expected that the
the checksum over the
expected that the primary
checksum over the payload
that the primary cost
where they were mostly
over the payload is
they were mostly accessing
the primary cost of
were mostly accessing the
primary cost of managed
the payload is necessary
cost of managed memory
payload is necessary since
of managed memory would
mostly accessing the local
with an estimated market
managed memory would be
an estimated market capitalization
accessing the local file
estimated market capitalization of
the local file system
market capitalization of over
memory would be associated
is necessary since the
would be associated with
local file system and
necessary since the ip
file system and therefore
since the ip identification
system and therefore had
be associated with garbage
and therefore had no
the ip identification field
associated with garbage collection
ip identification field is
therefore had no bandwidth
identification field is only
had no bandwidth constraints
the results largely repeat
results largely repeat those
all costs associated with
largely repeat those seen
bits long and a
costs associated with managed
repeat those seen in
associated with managed memory
those seen in the
with managed memory rise
long and a single
managed memory rise in
seen in the microbenchmarks
memory rise in the
and a single pair
rise in the amount
a single pair of
in the amount of
single pair of end
the amount of allocated
to the extent that
amount of allocated memory
the extent that the
extent that the greatest
that the greatest performance
hosts communicating at high
the greatest performance improvements
at least in the
greatest performance improvements are
least in the windows
communicating at high speeds
in the windows clr
performance improvements are seen
at high speeds will
improvements are seen at
bitcoin s security stems
high speeds will use
s security stems from
are seen at low
speeds will use the
seen at low bandwidth
security stems from a
at low bandwidth when
will use the same
low bandwidth when there
stems from a robust
bandwidth when there is
use the same identifier
when there is high
from a robust incentive
the same identifier for
there is high read
a robust incentive system
same identifier for different
identifier for different data
for different data packets
different data packets within
participants are required to
data packets within a
are required to provide
packets within a fairly
whereas traditional multicast systems
within a fairly short
required to provide expensive
a fairly short interval
to provide expensive proofs
such as in the
provide expensive proofs of
as in the mostly
expensive proofs of work
fairly short interval unless
traditional multicast systems accept
short interval unless the
multicast systems accept messages
interval unless the checksum
systems accept messages whenever
writes trace where there
accept messages whenever the
trace where there is
and they are rewarded
unless the checksum is
messages whenever the application
the checksum is added
they are rewarded according
where there is an
whenever the application layer
checksum is added to
the application layer or
is added to differentiate
application layer or the
added to differentiate between
layer or the multicast
to differentiate between them
or the multicast protocols
are rewarded according to
the multicast protocols produce
rewarded according to their
multicast protocols produce it
according to their efforts
decrease in the time
in the time spent
qsm uses an upcall
this architecture has proved
unique identifiers result in
the time spent to
identifiers result in garbled
architecture has proved both
result in garbled recovery
has proved both stable
in garbled recovery by
proved both stable and
time spent to read
garbled recovery by maelstrom
both stable and scalable
often we can delay
spent to read all
we can delay generating
to read all the
can delay generating a
an event which will
and it is used
delay generating a message
read all the files
generating a message until
it is used by
event which will be
is used by most
a message until the
used by most contemporary
message until the last
by most contemporary digital
which will be caught
until the last minute
most contemporary digital currencies
will be caught by
contemporary digital currencies and
even at the higher
be caught by higher
at the higher bandwidth
digital currencies and related
caught by higher level
the higher bandwidth of
and we can also
currencies and related services
we can also avoid
by higher level checksums
can also avoid situations
higher level checksums designed
also avoid situations in
level checksums designed to
avoid situations in which
checksums designed to deal
situations in which data
designed to deal with
in which data piles
to deal with tranmission
which data piles up
deal with tranmission errors
data piles up on
with tranmission errors on
piles up on behalf
tranmission errors on commodity
up on behalf of
errors on commodity networks
on behalf of an
there is a decrease
on commodity networks and
behalf of an aggressive
is a decrease of
commodity networks and hence
of an aggressive sender
networks and hence does
and hence does not
hence does not have
does not have significant
not have significant consequences
have significant consequences unless
significant consequences unless it
consequences unless it occurs
unless it occurs frequently
the mostlyreads trace is
limit buffering and caching
the kernel version of
mostlyreads trace is not
kernel version of maelstrom
trace is not much
version of maelstrom can
is not much affected
of maelstrom can generate
not much affected by
most existing multicast protocols
much affected by changes
maelstrom can generate up
existing multicast protocols buffer
can generate up to
affected by changes in
generate up to a
by changes in the
up to a gigabit
changes in the configuration
to a gigabit per
multicast protocols buffer data
a gigabit per second
protocols buffer data at
gigabit per second of
buffer data at many
per second of data
data at many layers
second of data and
although there is a
at many layers and
there is a slight
many layers and cache
is a slight decrease
layers and cache data
of data and fec
a slight decrease in
and cache data rather
slight decrease in both
cache data rather casually
decrease in both read
data rather casually for
data and fec traffic
rather casually for recovery
in both read and
casually for recovery purposes
both read and write
read and write times
and write times for
with the input data
write times for prioritised
the input data rate
times for prioritised asynchronous
input data rate depending
for prioritised asynchronous writeback
data rate depending on
this turns out to
rate depending on the
turns out to be
depending on the encoding
out to be extremely
on the encoding rate
to be extremely costly
our results apply to
be extremely costly in
results apply to all
extremely costly in a
apply to all such
costly in a managed
to all such incentive
in a managed setting
all such incentive systems
a managed setting and
managed setting and must
we were able to
setting and must be
were able to saturate
and must be avoided
able to saturate the
but we use bitcoin
to saturate the outgoing
must be avoided whenever
saturate the outgoing card
we use bitcoin terminology
the outgoing card at
be avoided whenever possible
use bitcoin terminology and
outgoing card at rates
bitcoin terminology and examples
card at rates as
terminology and examples since
load trace performs best
and examples since it
trace performs best with
at rates as high
performs best with uniform
rates as high as
best with uniform asynchronous
examples since it serves
with uniform asynchronous writeback
since it serves as
it serves as an
serves as an active
as an active and
an active and archetypal
we once again attribute
cumulative distribution of the
once again attribute this
distribution of the multicast
active and archetypal example
of the multicast rates
again attribute this to
the multicast rates for
attribute this to inefficiency
this to inefficiency in
to inefficiency in the
bitcoin implements its incentive
inefficiency in the rpc
implements its incentive systems
in the rpc protocol
its incentive systems with
incentive systems with a
systems with a data
with a data structure
with cpu overload occurring
a data structure called
cpu overload occurring at
since under extremely heavy
data structure called the
under extremely heavy load
structure called the blockchain
extremely heavy load and
heavy load and high
load and high bandwidth
and high bandwidth it
the blockchain is a
high bandwidth it performs
blockchain is a serialization
token roundtrip times for
bandwidth it performs better
is a serialization of
it performs better when
a serialization of all
performs better when all
serialization of all bitcoin
better when all messages
of all bitcoin transactions
when all messages have
where each incoming data
all messages have the
each incoming data packet
messages have the same
incoming data packet had
have the same priority
data packet had to
it is a single
packet had to be
is a single global
had to be xored
a single global ledger
single global ledger maintained
global ledger maintained by
ledger maintained by an
maintained by an open
by an open distributed
a file group is
an open distributed system
file group is implemented
group is implemented as
is implemented as a
implemented as a special
buffering requirements at the
since anyone can join
requirements at the receive
intervals between the subsequent
as a special type
anyone can join the
between the subsequent tokens
can join the open
a special type of
join the open system
special type of file
the open system and
type of file within
open system and participate
of file within the
system and participate in
incoming data packets are
and participate in maintaining
file within the mfs
data packets are buffered
within the mfs file
participate in maintaining the
packets are buffered so
in maintaining the blockchain
the mfs file system
are buffered so that
buffered so that they
so that they can
bitcoin uses a proof
with its own file
uses a proof of
its own file identifier
a proof of work
that they can be
proof of work mechanism
they can be used
of work mechanism to
can be used in
work mechanism to deter
be used in conjunction
mechanism to deter attacks
but not attached to
used in conjunction with
not attached to any
in conjunction with xors
attached to any specific
conjunction with xors to
to any specific directory
with xors to recover
participation requires exerting significant
xors to recover missing
requires exerting significant compute
to recover missing data
exerting significant compute resources
recover missing data packets
the file group a
clear messages out of
file group a file
messages out of the
group a file belongs
out of the system
a file belongs to
of the system quickly
a participant that proves
any received xor that
participant that proves she
data paths should have
received xor that is
paths should have rapid
that proves she has
xor that is missing
should have rapid data
is one of its
proves she has exerted
that is missing more
she has exerted enough
is missing more than
have rapid data movement
missing more than one
has exerted enough resources
more than one data
rapid data movement as
one of its attributes
exerted enough resources with
than one data packet
data movement as a
one data packet is
movement as a key
data packet is stored
as a key goal
the mfs prefetching subsystem
packet is stored temporarily
mfs prefetching subsystem derives
enough resources with a
prefetching subsystem derives much
resources with a proof
subsystem derives much of
with a proof of
derives much of its
in case all but
much of its effectiveness
a proof of work
of its effectiveness from
case all but one
its effectiveness from being
proof of work is
effectiveness from being combined
all but one of
from being combined with
of work is allowed
being combined with prioritised
but one of the
work is allowed to
we ve already mentioned
is allowed to take
one of the missing
allowed to take a
of the missing packets
to take a step
ve already mentioned that
take a step in
the missing packets are
combined with prioritised rpcs
missing packets are received
a step in the
packets are received later
step in the protocol
are received later or
in the protocol by
while the prefetching algorithm
the protocol by generating
already mentioned that data
received later or recovered
mentioned that data paths
later or recovered through
that data paths should
protocol by generating a
the prefetching algorithm in
by generating a block
data paths should clear
or recovered through other
prefetching algorithm in mfs
paths should clear messages
recovered through other xors
algorithm in mfs is
should clear messages quickly
participants are compensated for
in mfs is straightforward
are compensated for their
compensated for their efforts
allowing the recovery of
for their efforts with
the recovery of the
their efforts with newly
but there are other
it can still make
there are other important
recovery of the remaining
can still make bad
of the remaining missing
efforts with newly minted
are other important forms
with newly minted bitcoins
other important forms of
still make bad decisions
the remaining missing packet
important forms of delay
remaining missing packet from
make bad decisions without
the process of creating
missing packet from this
process of creating a
packet from this xor
of creating a block
bad decisions without a
creating a block is
decisions without a large
a block is called
without a large overall
block is called mining
most situations in which
in practice we stored
situations in which qsm
a large overall performance
practice we stored data
large overall performance penalty
and the participants miners
in which qsm developed
we stored data and
which qsm developed convoy
overall performance penalty because
stored data and xor
performance penalty because the
data and xor packets
in order to win
and xor packets in
order to win the
xor packets in double
to win the reward
penalty because the interference
like behavior or oscillatory
because the interference of
packets in double buffered
the interference of prefetching
in double buffered red
many miners try to
interference of prefetching with
miners try to generate
double buffered red black
behavior or oscillatory throughput
of prefetching with other
try to generate blocks
prefetching with other file
or oscillatory throughput can
with other file system
buffered red black trees
oscillatory throughput can be
red black trees for
other file system activity
throughput can be traced
file system activity is
the system automatically adjusts
can be traced to
system automatically adjusts the
system activity is minimised
automatically adjusts the difficulty
be traced to design
adjusts the difficulty of
traced to design decisions
the difficulty of block
to design decisions that
difficulty of block generation
design decisions that caused
in the same way
decisions that caused scheduling
the same way that
that caused scheduling jitter
same way that some
caused scheduling jitter or
such that one block
scheduling jitter or allowed
that one block is
way that some local
one block is added
jitter or allowed some
that some local file
or allowed some form
block is added every
allowed some form of
some local file systems
some form of priority
local file systems execute
form of priority inversion
file systems execute speculative
of priority inversion to
systems execute speculative operations
priority inversion to occur
execute speculative operations to
entries this occupies around
speculative operations to improve
operations to improve performance
minutes to the blockchain
delaying a crucial message
a crucial message behind
crucial message behind a
message behind a less
this means that each
behind a less important
means that each miner
a less important one
that each miner seldom
each miner seldom generates
miner seldom generates a
seldom generates a block
implications included the following
the repair bins in
repair bins in the
mfs makes use of
bins in the layered
although its revenue may
in the layered interleaving
its revenue may be
makes use of the
the layered interleaving scheme
revenue may be positive
use of the speculative
may be positive in
layered interleaving scheme store
of the speculative communication
interleaving scheme store incrementally
the speculative communication of
be positive in expectation
speculative communication of prioritised
event handlers should be
communication of prioritised rpcs
handlers should be short
scheme store incrementally computed
of prioritised rpcs in
store incrementally computed xors
prioritised rpcs in the
incrementally computed xors and
rpcs in the hope
computed xors and lists
in the hope of
xors and lists of
a miner may have
the hope of achieving
miner may have to
hope of achieving a
and lists of data
may have to wait
of achieving a benefit
have to wait for
we struggled to make
to wait for an
achieving a benefit through
wait for an extended
a benefit through prefetching
for an extended period
benefit through prefetching files
lists of data packet
struggled to make the
an extended period to
of data packet headers
extended period to create
to make the overall
period to create a
to create a block
make the overall behavior
create a block and
without the data packet
a block and earn
the overall behavior of
block and earn the
the data packet payloads
overall behavior of the
and earn the actual
behavior of the system
earn the actual bitcoins
of the system as
mfs prefetching implementation the
resulting in low storage
prefetching implementation the mfs
the system as predictable
implementation the mfs cache
in low storage overheads
the mfs cache manager
system as predictable as
mfs cache manager incorporates
low storage overheads for
miners form mining pools
cache manager incorporates a
as predictable as possible
manager incorporates a small
storage overheads for each
incorporates a small prefetching
predictable as possible not
a small prefetching module
where all members mine
as possible not a
overheads for each layer
all members mine concurrently
for each layer that
possible not a trivial
each layer that rise
which can be optionally
not a trivial task
members mine concurrently and
layer that rise linearly
mine concurrently and they
that rise linearly with
can be optionally enabled
a trivial task in
be optionally enabled at
rise linearly with the
concurrently and they share
trivial task in configurations
and they share their
optionally enabled at start
they share their revenue
task in configurations where
share their revenue whenever
in configurations where hundreds
their revenue whenever one
configurations where hundreds of
revenue whenever one of
where hundreds of processes
whenever one of them
hundreds of processes might
one of them creates
linearly with the value
when it is initialised
with the value of
of them creates a
of processes might be
the value of the
them creates a block
processes might be multicasting
value of the interleave
might be multicasting in
a prefetching thread starts
be multicasting in thousands
prefetching thread starts and
pools are typically implemented
thread starts and initiates
are typically implemented as
the memory footprint for
typically implemented as a
starts and initiates prefetch
implemented as a pool
memory footprint for a
as a pool manager
and initiates prefetch requests
a pool manager and
footprint for a longrunning
multicasting in thousands of
initiates prefetch requests in
pool manager and a
prefetch requests in parallel
manager and a cohort
for a longrunning proxy
in thousands of overlapping
a longrunning proxy was
thousands of overlapping groups
longrunning proxy was around
and a cohort of
requests in parallel with
a cohort of miners
in parallel with the
parallel with the main
with the main activity
by keeping event handlers
the main activity of
keeping event handlers short
main activity of the
mb in our experiments
activity of the cache
event handlers short and
the pool manager joins
handlers short and predictable
of the cache manager
short and predictable and
pool manager joins the
and predictable and eliminating
manager joins the bitcoin
predictable and eliminating the
joins the bitcoin system
and eliminating the need
the bitcoin system as
eliminating the need for
bitcoin system as a
the need for locking
the core component of
other performance enhancing roles
system as a single
core component of the
performance enhancing roles maelstrom
as a single miner
component of the cache
we obtained a more
of the cache manager
obtained a more predictable
enhancing roles maelstrom appliances
a more predictable system
instead of generating proof
roles maelstrom appliances can
of generating proof of
the cache manager alerts
generating proof of work
maelstrom appliances can optionally
more predictable system and
cache manager alerts the
predictable system and were
appliances can optionally aggregate
system and were able
it outsources the work
and were able to
outsources the work to
were able to eliminate
the work to the
able to eliminate multithreading
work to the miners
manager alerts the prefetching
can optionally aggregate small
alerts the prefetching module
optionally aggregate small subkilobyte
the prefetching module every
with the associated context
in order to evaluate
prefetching module every time
order to evaluate the
the associated context switching
to evaluate the miners
associated context switching and
aggregate small subkilobyte packets
module every time an
evaluate the miners efforts
every time an application
small subkilobyte packets from
time an application reads
context switching and locking
an application reads or
switching and locking overheads
application reads or writes
subkilobyte packets from different
reads or writes a
packets from different flows
or writes a file
the pool manager accepts
from different flows into
pool manager accepts partial
different flows into larger
manager accepts partial proof
by calling the file
accepts partial proof of
flows into larger ones
partial proof of work
into larger ones for
calling the file access
larger ones for better
the file access routine
ones for better communication
proof of work and
for better communication efficiency
of work and estimates
better communication efficiency over
here we encounter a
communication efficiency over the
this routine checks whether
work and estimates each
routine checks whether the
efficiency over the long
checks whether the file
and estimates each miner
we encounter a tension
estimates each miner s
whether the file belongs
each miner s power
the file belongs to
encounter a tension between
file belongs to a
miner s power according
a tension between two
s power according to
tension between two goals
belongs to a file
power according to the
to a file group
according to the rate
a file group if
to the rate with
file group if not
from a memory footprint
in split flow control
a memory footprint perspective
the rate with which
split flow control mode
rate with which it
flow control mode they
with which it submits
control mode they can
which it submits such
one might prefer not
mode they can perform
might prefer not to
they can perform send
prefer not to pull
it submits such partial
not to pull in
submits such partial proof
to pull in a
such partial proof of
pull in a message
partial proof of work
in a message until
the access is ignored
a message until qsm
side buffering of in
message until qsm can
until qsm can process
when a miner generates
qsm can process it
a miner generates a
flight data for multi
miner generates a full
generates a full proof
prefetching it is a
a full proof of
but in a datacenter
gigabyte flows that exceed
in a datacenter or
flows that exceed the
full proof of work
it is a member
a datacenter or cluster
is a member of
that exceed the sending
a member of a
exceed the sending end
member of a file
it sends it to
most message loss occurs
sends it to the
message loss occurs in
of a file group
loss occurs in the
host s buffering capacity
it to the pool
occurs in the operating
to the pool manager
in the operating system
the pool manager which
the group is put
pool manager which publishes
group is put at
manager which publishes this
is put at the
not on the network
which publishes this proof
maelstrom appliances can act
put at the head
appliances can act as
at the head of
publishes this proof of
can act as multicast
the head of the
hence message loss rates
this proof of work
message loss rates soar
proof of work to
loss rates soar if
head of the prefetch
act as multicast forwarding
of work to the
as multicast forwarding nodes
work to the bitcoin
rates soar if we
of the prefetch list
soar if we leave
to the bitcoin system
if we leave messages
appliances send multicast packets
we leave messages on
send multicast packets to
the prefetch thread periodically
multicast packets to each
leave messages on input
the pool manager thus
prefetch thread periodically examines
pool manager thus receives
messages on input sockets
manager thus receives the
on input sockets for
packets to each other
thread periodically examines the
thus receives the full
periodically examines the prefetching
to each other across
examines the prefetching is
each other across the
input sockets for long
receives the full revenue
the prefetching is commonly
the full revenue of
prefetching is commonly used
full revenue of the
is commonly used to
other across the long
commonly used to improve
revenue of the block
used to improve the
of the block and
to improve the performance
the block and distributes
improve the performance of
block and distributes it
the performance of lo
and distributes it fairly
distributes it fairly according
and use ip multicast
it fairly according to
control the event processing
fairly according to its
the event processing order
group at the head
according to its members
at the head of
to its members power
the head of the
head of the list
many of the pools
to spread them within
of the pools are
spread them within their
if the group file
the pools are open
the group file for
them within their data
pools are open they
group file for the
within their data centers
file for the group
are open they allow
for the group is
and the imposition of
the group is cal
open they allow any
group is cal file
they allow any miner
is cal file systems
the imposition of an
allow any miner to
appliances can take on
any miner to join
can take on other
imposition of an internal
take on other existing
as well as distributed
on other existing roles
of an internal event
other existing roles in
an internal event processing
existing roles in the
internal event processing prioritization
miner to join them
well as distributed file
roles in the data
as distributed file systems
in the data center
to join them using
small delays add up
join them using a
delays add up in
them using a public
add up in large
using a public internet
up in large systems
a public internet interface
acting as security and
not in the cache
as security and vpn
security and vpn gateways
and vpn gateways and
tight control over event
such open pools are
vpn gateways and as
open pools are susceptible
gateways and as conventional
control over event processing
it retrieves it from
over event processing largely
retrieves it from the
pools are susceptible to
and as conventional performance
are susceptible to the
as conventional performance enhancing
susceptible to the classical
it from the server
to the classical block
conventional performance enhancing proxies
the classical block withholding
event processing largely eliminated
classical block withholding attack
processing largely eliminated convoy
then it scans the
largely eliminated convoy effects
it scans the in
eliminated convoy effects and
scans the in a
convoy effects and oscillatory
the in a file
effects and oscillatory throughput
in a file system
and oscillatory throughput problems
a file system with
file system with whole
a mechanism is required
mechanism is required files
where a miner sends
is required files in
a miner sends only
required files in the
miner sends only partial
act on fresh state
sends only partial proof
files in the group
only partial proof of
in the group in
e valuation we evaluated
partial proof of work
valuation we evaluated maelstrom
many inefficiencies can be
we evaluated maelstrom on
proof of work to
evaluated maelstrom on the
inefficiencies can be traced
maelstrom on the emulab
of work to the
on the emulab testbed
can be traced to
the emulab testbed at
work to the pool
the group in order
to the pool manager
be traced to situations
the pool manager and
traced to situations in
pool manager and discards
group in order until
manager and discards full
to situations in which
emulab testbed at utah
situations in which one
and discards full proof
in which one node
discards full proof of
in order until it
which one node takes
order until it finds
full proof of work
until it finds the
one node takes action
it finds the first
node takes action on
finds the first one
takes action on the
the first one which
action on the basis
due to the partial
first one which is
on the basis of
one which is not
the basis of stale
which is not to
to the partial proof
is not to determine
for all the experiments
not to determine appropriate
the partial proof of
to determine appropriate prefetching
partial proof of work
determine appropriate prefetching hints
proof of work it
basis of stale state
of work it sends
we used a dumbbell
of stale state information
work it sends to
used a dumbbell topology
stale state information from
earlier work in file
state information from some
work in file in
information from some other
in file in the
from some other node
a dumbbell topology of
it sends to the
dumbbell topology of two
file in the cache
topology of two clusters
sends to the pool
of two clusters of
triggering redundant retransmissions or
two clusters of nodes
redundant retransmissions or other
clusters of nodes connected
retransmissions or other overheads
of nodes connected via
the miner is considered
nodes connected via routing
miner is considered a
connected via routing nodes
is considered a regular
via routing nodes with
the pull architecture has
routing nodes with a
considered a regular pool
pull architecture has the
a regular pool member
and issues a prefetch
regular pool member and
architecture has the secondary
nodes with a high
issues a prefetch request
pool member and the
has the secondary benefit
a prefetch request or
member and the pool
prefetch request or system
and the pool can
request or system prefetching
the pool can estimate
the secondary benefit of
pool can estimate its
or system prefetching has
latency link in between
system prefetching has used
secondary benefit of letting
prefetching has used clustering
link in between them
has used clustering to
benefit of letting us
used clustering to derive
can estimate its power
clustering to derive file
of letting us delay
to derive file groups
designed to emulate the
derive file groups from
to emulate the setup
file groups from validation
emulate the setup in
groups from validation request
the setup in figure
from validation request for
letting us delay the
validation request for it
the attacker shares the
us delay the preparation
attacker shares the revenue
delay the preparation of
shares the revenue obtained
the preparation of status
the revenue obtained by
preparation of status packets
revenue obtained by the
and ran the proxy
obtained by the other
ran the proxy code
by the other pool
the proxy code on
the other pool members
proxy code on the
if all the files
of status packets until
all the files are
code on the routers
the files are valid
but does not contribute
files are valid and
status packets until they
are valid and are
packets until they are
valid and are in
it reduces the revenue
and are in the
reduces the revenue of
are in the cache
the revenue of the
until they are about
in the cache access
they are about to
the cache access statistics
are about to be
revenue of the other
about to be transmitted
of the other members
show the performance of
the performance of the
but also its own
performance of the kernel
of the kernel version
the kernel version at
conclusions the premise of
kernel version at gigabit
we provide necessary background
the premise of our
provide necessary background on
version at gigabit speeds
premise of our work
necessary background on the
of our work is
background on the bitcoin
our work is that
on the bitcoin protocol
predicted future file accesses
the remainder of the
work is that developers
remainder of the graphs
future file accesses from
of the graphs show
is that developers of
the graphs show the
that developers of services
graphs show the performance
pools and the classical
file accesses from cache
and the classical block
show the performance of
the classical block withholding
the performance of the
developers of services intended
classical block withholding attack
performance of the user
block withholding attack in
the group is moved
of services intended to
group is moved to
withholding attack in section
is moved to the
attack in section ii
moved to the end
space version at slower
services intended to run
version at slower speeds
to the end of
intended to run on
the end of the
to run on clustered
end of the prefetch
run on clustered platforms
of the prefetch list
and specify our model
on clustered platforms desire
to emulate the mtu
clustered platforms desire the
emulate the mtu difference
specify our model in
the mtu difference between
platforms desire the productivity
mtu difference between the
our model in section
desire the productivity and
difference between the long
the productivity and robustness
model in section iii
productivity and robustness benefits
and robustness benefits of
robustness benefits of managed
haul link and the
benefits of managed environments
link and the data
for a broader view
and the data center
a broader view of
the data center network
broader view of the
or allowed applications to
and need replication tools
allowed applications to specify
view of the protocol
applications to specify prefetch
need replication tools integrated
of the protocol and
replication tools integrated with
the protocol and ecosystem
tools integrated with those
protocol and ecosystem the
integrated with those environments
and ecosystem the reader
we set an mtu
ecosystem the reader may
the thread rechecks the
the reader may refer
set an mtu of
reader may refer to
building such tools so
thread rechecks the head
such tools so posed
may refer to the
tools so posed challenges
refer to the survey
so posed challenges to
to the survey by
rechecks the head of
posed challenges to us
the survey by bonneau
challenges to us as
survey by bonneau et
to us as protocol
by bonneau et al
us as protocol and
the head of the
as protocol and system
head of the list
protocol and system designers
of the list ing
bytes on the network
the list ing hints
on the network connecting
list ing hints explicitly
the network connecting the
network connecting the end
which were the primary
were the primary focus
the primary focus of
primary focus of our
focus of our paper
hosts to the proxy
to the proxy and
the proxy and an
proxy and an mtu
and an mtu of
a central insight is
central insight is that
insight is that high
in this work we
performance protocols running in
this work we analyze
protocols running in managed
work we analyze block
running in managed settings
we analyze block withholding
in managed settings need
analyze block withholding attacks
managed settings need to
block withholding attacks among
settings need to maintain
withholding attacks among pools
bytes on the long
need to maintain the
to maintain the smallest
maintain the smallest possible
to find the next
the smallest possible memory
haul link between proxies
find the next file
a pool that employs
smallest possible memory footprint
the next file to
pool that employs the
next file to prefetch
the only exception is
that employs the pool
only exception is figure
employs the pool block
the pool block withholding
pool block withholding attack
a new group may
block withholding attack registers
new group may now
withholding attack registers with
group may now be
attack registers with the
may now be at
registers with the victim
now be at the
with the victim pool
be at the inter
the victim pool as
where we maintained equal
victim pool as a
we maintained equal mtus
pool as a regular
maintained equal mtus of
file dependencies can also
as a regular miner
dependencies can also be
can also be used
plication of this principle
also be used as
be used as a
used as a source
as a source of
it receives tasks from
a source of hints
receives tasks from the
qsm achieves scalability and
tasks from the victim
achieves scalability and stability
from the victim pool
head of the list
the victim pool and
bytes on both links
victim pool and transfers
of the list as
pool and transfers them
the list as a
and transfers them to
list as a result
transfers them to some
as a result of
them to some of
scalability and stability even
to some of its
and stability even at
some of its own
all the experiments are
a result of further
the experiments are done
of its own miners
experiments are done with
result of further application
stability even at very
are done with maelstrom
even at very high
done with maelstrom using
we call these infiltrating
with maelstrom using end
call these infiltrating miners
at very high loads
of further application accesses
further application accesses to
application accesses to files
and the mining power
an unexpected side effect
the mining power spent
unexpected side effect of
mining power spent by
side effect of building
power spent by a
effect of building qsm
spent by a pool
of building qsm in
it may be known
building qsm in windows
by a pool the
qsm in windows was
a pool the infiltration
in windows was that
may be known that
windows was that by
pool the infiltration rate
was that by integrating
be known that a
that by integrating our
known that a certain
by integrating our system
that a certain shared
integrating our system tightly
a certain shared library
our system tightly with
when the attacking pool
system tightly with the
certain shared library is
tightly with the platform
the attacking pool s
shared library is reprefetch
attacking pool s infiltrating
library is reprefetch requests
pool s infiltrating miners
is reprefetch requests are
s infiltrating miners deliver
reprefetch requests are similar
infiltrating miners deliver partial
requests are similar to
miners deliver partial proofs
are similar to regular
deliver partial proofs of
similar to regular fetch
partial proofs of work
which illustrates the performance
we created a new
illustrates the performance of
to regular fetch requests
the performance of split
regular fetch requests for
performance of split mode
fetch requests for files
of split mode flow
created a new kind
the attacker transfers them
a new kind of
split mode flow control
attacker transfers them to
quired to run a
transfers them to the
to run a text
them to the victim
run a text editor
to the victim pool
new kind of live
kind of live distributed
of live distributed objects
letting the attacked pool
in this case it
the attacked pool estimate
attacked pool estimate their
this case it would
pool estimate their power
abstract data types that
case it would be
data types that form
types that form groups
it would be advantageous
would be advantageous with
when the infiltrating miners
be advantageous with the
the infiltrating miners deliver
advantageous with the exception
show that commodity tcp
infiltrating miners deliver a
and that are updated
miners deliver a full
that are updated using
deliver a full proof
with the exception that
are updated using qsm
a full proof of
ip throughput collapses in
the exception that they
throughput collapses in the
full proof of work
updated using qsm multicasts
exception that they are
collapses in the presence
that they are issued
in the presence of
the attacking pool discards
these look natural to
attacking pool discards it
look natural to the
the presence of non
they are issued at
natural to the windows
are issued at the
to the windows user
this attack affects the
issued at the lowest
attack affects the revenues
at the lowest level
affects the revenues of
the lowest level of
the revenues of the
lowest level of prito
revenues of the pools
such an object changes
and that maelstrom successfully
an object changes faster
of the pools in
object changes faster than
the pools in several
changes faster than the
pools in several ways
faster than the average
that maelstrom successfully masks
than the average windows
level of prito retrieve
maelstrom successfully masks loss
of prito retrieve the
successfully masks loss and
prito retrieve the shared
masks loss and prevents
retrieve the shared library
loss and prevents this
the shared library from
and prevents this collapse
shared library from the
prevents this collapse from
library from the server
this collapse from occurring
from the server as
the victim pool s
the average windows object
victim pool s effective
the server as well
pool s effective mining
server as well as
s effective mining rate
as well as retriev
effective mining rate is
mining rate is unchanged
but the same basic
the same basic mechanisms
same basic mechanisms can
basic mechanisms can support
mechanisms can support them
but its total revenue
shows the performance of
its total revenue is
the performance of the
all other rpc traffic
total revenue is divided
and the component integration
revenue is divided among
the component integration environment
is divided among more
performance of the userspace
other rpc traffic takes
of the userspace version
divided among more miners
the userspace version on
rpc traffic takes precedence
userspace version on a
traffic takes precedence over
takes precedence over a
precedence over a prefetch
the attacker s mining
over a prefetch rpc
attacker s mining power
s mining power is
mining power is reduced
extends seamlessly to encompass
ing the text editor
seamlessly to encompass them
mbps link and figure
the text editor executable
since some of its
some of its miners
of its miners are
although a great deal
its miners are used
a great deal of
miners are used for
great deal of additional
are used for block
deal of additional work
used for block withholding
of additional work is
shows the kernel version
additional work is needed
the kernel version on
kernel version on a
as shown in table
but it earns additional
it earns additional revenue
qsm should eventually enable
earns additional revenue through
should eventually enable casual
additional revenue through its
eventually enable casual use
revenue through its infiltration
enable casual use of
through its infiltration of
the experiment in each
its infiltration of the
casual use of live
experiment in each case
use of live objects
in each case involves
and only one tion
infiltration of the other
only one tion such
of the other pool
of live objects not
each case involves running
live objects not just
case involves running iperf
objects not just in
one tion such as
not just in datacenters
tion such as the
just in datacenters but
such as the operating
in datacenters but also
as the operating system
datacenters but also on
the operating system s
but also on desktops
the total effective mining
operating system s database
total effective mining power
also on desktops in
effective mining power in
system s database of
mining power in the
on desktops in wan
s database of installed
power in the system
database of installed software
in the system is
of installed software prefetch
the system is reduced
desktops in wan settings
flows from one node
installed software prefetch is
from one node to
software prefetch is made
one node to another
prefetch is made at
node to another across
is made at a
opening the door to
made at a time
causing the bitcoin protocol
to another across the
the bitcoin protocol to
another across the long
bitcoin protocol to reduce
the door to a
protocol to reduce the
door to a new
to reduce the difficulty
to a new style
this is more a
distance link with and
is more a matter
a new style of
link with and without
new style of distributed
taking all these factors
style of distributed programming
all these factors into
more a matter of
with and without intermediary
these factors into account
and without intermediary maelstrom
a matter of implementapackages
without intermediary maelstrom proxies
the current version of
intermediary maelstrom proxies and
current version of qsm
maelstrom proxies and measuring
we observe that a
proxies and measuring obtained
version of qsm is
and measuring obtained throughput
of qsm is stable
observe that a pool
measuring obtained throughput while
that a pool might
obtained throughput while varying
a pool might be
throughput while varying loss
pool might be able
specified dependency information tion
might be able to
while varying loss rate
be able to increase
dependency information tion convenience
able to increase its
qsm is stable in
to increase its revenue
is stable in cluster
increase its revenue by
left graph on each
its revenue by attacking
graph on each figure
revenue by attacking other
information tion convenience than
stable in cluster settings
tion convenience than a
in cluster settings and
convenience than a design
by attacking other pools
than a design decision
each pool therefore makes
other work has shown
has a growing community
work has shown can
pool therefore makes a
a growing community of
therefore makes a choice
growing community of users
has shown can be
makes a choice of
shown can be used
a choice of whether
the error bars on
choice of whether to
error bars on the
of whether to attack
looking to the future
whether to attack each
the benefits initiating multiple
to attack each of
bars on the graphs
benefits initiating multiple concurrent
attack each of the
on the graphs to
each of the other
initiating multiple concurrent prefetches
of the other pools
the graphs to the
the other pools in
multiple concurrent prefetches from
we plan to scale
graphs to the left
plan to scale qsm
to the left are
to scale qsm into
concurrent prefetches from differany
other pools in the
the left are standard
scale qsm into wan
left are standard errors
qsm into wan settings
are standard errors of
pools in the system
standard errors of the
prefetches from differany of
errors of the throughput
from differany of these
to support a wider
of the throughput over
and with what infiltration
the throughput over ten
with what infiltration rate
throughput over ten runs
differany of these techniques
support a wider range
of these techniques could
a wider range of
these techniques could be
wider range of multicast
techniques could be used
this gives rise to
range of multicast reliability
could be used to
gives rise to the
be used to derive
rise to the pool
used to derive hints
ip s cache of
to derive hints for
s cache of tuning
derive hints for use
cache of tuning parameters
hints for use ent
of multicast reliability properties
to the pool game
of tuning parameters to
for use ent servers
tuning parameters to allow
parameters to allow for
to allow for repeatable
and to introduce a
we specify this game
allow for repeatable results
specify this game and
to introduce a gossip
this game and provide
introduce a gossip infrastructure
game and provide initial
a gossip infrastructure that
and provide initial analysis
gossip infrastructure that would
provide initial analysis in
infrastructure that would support
initial analysis in section
the clients in the
that would support configuration
analysis in section iv
would support configuration discovery
clients in the experiment
support configuration discovery and
in the experiment are
configuration discovery and other
mfs does not currently
discovery and other self
the experiment are running
in section v we
does not currently make
experiment are running tcp
not currently make use
section v we analyze
currently make use of
v we analyze the
make use of timeouts
we analyze the scenario
ip reno on a
analyze the scenario where
reno on a linux
use of timeouts by
the scenario where exactly
live objects pose a
of timeouts by the
objects pose a protocol
scenario where exactly two
timeouts by the mfs
where exactly two of
pose a protocol design
exactly two of the
a protocol design challenge
by the mfs prefetching
two of the pools
the mfs prefetching subsystem
of the pools take
the pools take part
they give rise to
pools take part in
give rise to irregular
our evaluation uses hand
rise to irregular patterns
take part in the
to irregular patterns of
part in the game
irregular patterns of overlapping
in the game and
patterns of overlapping multicast
the game and only
of overlapping multicast groups
game and only one
and only one can
as we have noted
only one can attack
we have noted earlier
the maelstrom parameters used
one can attack the
maelstrom parameters used are
can attack the other
parameters used are r
oriented state aggregation mechanisms
but it could easily
state aggregation mechanisms will
it could easily to
aggregation mechanisms will need
could easily to exspecified
mechanisms will need to
easily to exspecified dependency
will need to be
to exspecified dependency information
need to be redesigned
the attacker can always
attacker can always increase
can always increase its
always increase its revenue
which is inaccurate in
we have an idea
is inaccurate in some
have an idea for
inaccurate in some tended
increase its revenue by
in some tended to
its revenue by attacking
some tended to abandon
an idea for solving
tended to abandon a
idea for solving this
to abandon a prefetching
abandon a prefetching attempt
we conclude that in
a prefetching attempt that
conclude that in the
prefetching attempt that does
that in the general
attempt that does not
in the general case
that does not complete
does not complete cases
recovery would be performed
would be performed by
be performed by selecting
with any number of
performed by selecting a
rather than reimplementing an
by selecting a subset
than reimplementing an existing
selecting a subset of
reimplementing an existing hint
any number of pools
a subset of nodes
subset of nodes that
of nodes that form
generation in a timely
nodes that form a
in a timely manner
that form a clean
form a clean overlay
a clean overlay structure
attacks is not a
is not a nash
rather than just treating
not a nash equilibrium
we focus on the
than just treating every
focus on the performance
just treating every single
on the performance of
treating every single receiver
the performance of mfs
every single receiver as
performance of mfs with
single receiver as a
of mfs with prefetchthe
receiver as a member
mfs with prefetchthe main
as a member of
section vi deals with
a member of a
space version involved running
member of a recovery
vi deals with the
with prefetchthe main complexity
deals with the case
of a recovery region
with the case of
prefetchthe main complexity in
version involved running a
main complexity in implementing
the case of two
complexity in implementing the
case of two pools
in implementing the prefetching
involved running a single
implementing the prefetching subing
whether this can really
this can really scale
where each can attack
can really scale remains
each can attack the
really scale remains to
can attack the other
scale remains to be
using a deliberately simple
remains to be seen
second iperf flow from
a deliberately simple hint
iperf flow from one
deliberately simple hint mechanism
flow from one node
simple hint mechanism for
from one node to
analysis becomes more complicated
hint mechanism for the
becomes more complicated in
one node to another
more complicated in two
mechanism for the purposes
node to another with
for the purposes system
complicated in two ways
to another with and
the purposes system lies
another with and without
purposes system lies in
system lies in handling
with and without maelstrom
lies in handling a
in handling a demand
and without maelstrom running
handling a demand fetch
without maelstrom running on
the revenue of each
maelstrom running on the
revenue of each pool
running on the routers
a compulsory fetch to
of each pool affects
on the routers and
each pool affects the
compulsory fetch to of
pool affects the revenue
fetch to of evaluation
affects the revenue of
the routers and measuring
the revenue of the
routers and measuring throughput
revenue of the other
and measuring throughput while
dependencies between files are
of the other through
between files are conveyed
the other through the
files are conveyed using
other through the infiltrating
are conveyed using a
through the infiltrating miners
conveyed using a service
measuring throughput while varying
using a service a
throughput while varying the
a service a cache
while varying the random
service a cache miss
varying the random loss
we prove that for
the random loss rate
prove that for a
random loss rate on
that for a static
loss rate on the
for a static choice
for a file which
a static choice of
a file which is
static choice of infiltration
file which is already
choice of infiltration rates
rate on the link
of infiltration rates the
which is already being
infiltration rates the pool
is already being prefetched
rates the pool revenues
on the link and
the pool revenues converge
the link and the
link and the oneway
and the oneway latency
which is a list
to test the kernel
is a list of
test the kernel version
once one pool changes
the kernel version at
a list of file
one pool changes its
list of file identifiers
kernel version at gigabit
of file identifiers for
pool changes its infiltration
file identifiers for the
version at gigabit speeds
identifiers for the related
changes its infiltration rate
for the related files
its infiltration rate of
infiltration rate of the
rate of the other
we ran eight parallel
ran eight parallel iperf
this conflict arises very
eight parallel iperf flows
conflict arises very frequently
parallel iperf flows from
iperf flows from one
flows from one node
from one node to
the latter may prefer
one node to another
latter may prefer to
node to another for
may prefer to change
particularly when an appliit
prefer to change its
when an appliit is
to change its infiltration
an appliit is assumed
design and implementation of
change its infiltration rate
appliit is assumed that
and implementation of a
its infiltration rate of
implementation of a reliable
infiltration rate of the
of a reliable group
rate of the former
is assumed that after
a reliable group communication
assumed that after one
reliable group communication toolkit
that after one file
the curves obtained from
after one file in
therefore the game itself
one file in the
the game itself takes
file in the group
game itself takes multiple
in the group has
itself takes multiple rounds
group communication toolkit for
curves obtained from the
the group has been
obtained from the two
group has been accessed
from the two versions
communication toolkit for java
takes multiple rounds to
the two versions are
multiple rounds to converge
two versions are almost
cation performs a fast
versions are almost identical
performs a fast linear
a fast linear scan
fast linear scan of
linear scan of files
we show analytically that
scan of files in
we present both to
show analytically that the
of files in a
present both to show
analytically that the game
files in a file
that the game has
both to show that
the game has a
in a file group
game has a single
to show that the
has a single nash
show that the kernel
a single nash equilibrium
that the kernel version
single nash equilibrium and
an it becomes advantageous
the kernel version successfully
nash equilibrium and numerically
it becomes advantageous to
equilibrium and numerically study
kernel version successfully scales
and numerically study the
becomes advantageous to prefetch
numerically study the equilibrium
version successfully scales up
study the equilibrium points
advantageous to prefetch the
the equilibrium points for
successfully scales up the
equilibrium points for different
to prefetch the remainder
points for different pool
scales up the performance
for different pool sizes
prefetch the remainder of
up the performance of
the remainder of the
the performance of the
remainder of the files
performance of the userspace
for pools smaller than
of the userspace version
of the files in
the userspace version to
the files in efficient
userspace version to hundreds
files in efficient implementation
version to hundreds of
in efficient implementation of
to hundreds of megabits
efficient implementation of prefetching
hundreds of megabits of
implementation of prefetching requires
of megabits of traffic
of prefetching requires that
megabits of traffic per
prefetching requires that the
of traffic per second
requires that the demand
at the equilibrium point
the equilibrium point both
equilibrium point both pools
point both pools earn
both pools earn less
pools earn less than
design and evaluation of
earn less than they
and evaluation of a
less than they would
evaluation of a wide
than they would have
they would have in
would have in the
have in the nonequilibrium
area event notification service
in the nonequilibrium no
acm transactions on computer
transactions on computer systems
since pools can decide
pools can decide to
can decide to start
decide to start or
we show how tcp
to start or stop
start or stop attacking
or stop attacking at
stop attacking at any
attacking at any point
ip performance degrades on
performance degrades on a
this can be modeled
can be modeled as
be modeled as the
modeled as the miner
ms link as the
as the miner s
link as the loss
the miner s dilemma
as the loss rate
miner s dilemma an
the loss rate is
s dilemma an instance
loss rate is increased
dilemma an instance of
rate is increased from
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
attacking is the dominant
is the dominant strategy
the dominant strategy in
dominant strategy in each
strategy in each iteration
but if the pools
if the pools can
the pools can agree
pools can agree not
can agree not to
agree not to attack
both benefit in the
benefit in the long
in the long run
maelstrom masks loss up
masks loss up to
we address in section
address in section vii
in section vii the
section vii the case
without significant throughput degradation
vii the case where
the case where the
case where the participants
where the participants are
the participants are an
with the kernel version
participants are an arbitrary
the kernel version achieving
are an arbitrary number
kernel version achieving two
an arbitrary number of
version achieving two orders
arbitrary number of identical
achieving two orders of
number of identical pools
two orders of magnitude
orders of magnitude higher
of magnitude higher throughput
magnitude higher throughput that
higher throughput that conventional
there exists a symmetric
throughput that conventional tcp
exists a symmetric equilibrium
a symmetric equilibrium in
symmetric equilibrium in which
equilibrium in which each
in which each participating
which each participating pool
each participating pool attacks
participating pool attacks each
pool attacks each of
attacks each of the
each of the other
of the other participating
the other participating pools
weight process groups in
process groups in the
the graphs on the
groups in the isis
graphs on the right
in the isis system
as in the minority
on the right side
in the minority two
the right side of
right side of figures
here too at equilibrium
too at equilibrium all
at equilibrium all pools
equilibrium all pools earn
all pools earn less
pools earn less than
earn less than with
less than with the
than with the no
ip throughput declining on
throughput declining on a
declining on a link
on a link of
a link of increasing
link of increasing length
of increasing length when
increasing length when subjected
our results imply that
length when subjected to
results imply that block
when subjected to uniform
imply that block withholding
subjected to uniform loss
that block withholding by
to uniform loss rates
block withholding by pools
uniform loss rates of
withholding by pools leads
by pools leads to
pools leads to an
leads to an unfavorable
to an unfavorable equilibrium
due to the anonymity
to the anonymity of
the anonymity of miners
a single pool might
single pool might be
pool might be tempted
might be tempted to
be tempted to attack
the top line in
top line in the
line in the graphs
leading the other pools
in the graphs is
the other pools to
the graphs is the
other pools to attack
graphs is the performance
pools to attack as
is the performance of
to attack as well
the performance of tcp
constructing reliable distributed communication
the implications might be
ip without loss and
reliable distributed communication systems
without loss and provides
distributed communication systems with
loss and provides an
communication systems with corba
and provides an upper
implications might be devastating
provides an upper bound
might be devastating for
an upper bound for
be devastating for open
upper bound for performance
devastating for open pools
bound for performance on
ieee communications magazine feature
for performance on the
communications magazine feature topic
performance on the link
if their revenues are
magazine feature topic issue
their revenues are reduced
feature topic issue on
topic issue on distributed
issue on distributed object
on distributed object computing
miners will prefer to
will prefer to form
space and kernel versions
prefer to form closed
to form closed pools
form closed pools that
closed pools that cannot
pools that cannot be
maelstrom masks packet loss
that cannot be attacked
masks packet loss and
cannot be attacked in
packet loss and tracks
be attacked in this
loss and tracks the
attacked in this manner
and tracks the lossless
tracks the lossless line
the lossless line closely
though this may be
this may be conceived
lagging only when the
may be conceived as
only when the link
be conceived as bad
when the link latency
conceived as bad news
the link latency is
as bad news for
link latency is low
bad news for public
latency is low and
news for public mining
is low and tcp
for public mining pools
ip s throughput is
on the whole it
s throughput is very
the whole it may
throughput is very high
whole it may be
it may be good
may be good news
be good news to
good news to the
news to the bitcoin
to the bitcoin system
which prefers small pools
we examine the practicality
examine the practicality of
the practicality of the
practicality of the attack
of the attack in
the attack in section
attack in section viii
in section viii and
section viii and discuss
viii and discuss implications
and discuss implications and
discuss implications and model
implications and model extensions
and model extensions in
model extensions in section
extensions in section ix
our contributions are the
hierarchical clustering of message
contributions are the following
clustering of message flows
of message flows in
message flows in a
flows in a multicast
in a multicast data
a multicast data dissemination
multicast data dissemination system
definition of the pool
of the pool game
the pool game where
pool game where pools
game where pools in
where pools in a
pools in a proof
ofwork secured system attack
secured system attack one
system attack one another
attack one another with
one another with a
another with a pool
with a pool block
a pool block withholding
pool block withholding attack
in the general case
optimizing buffer management for
buffer management for reliable
management for reliable multicast
attacks is not an
is not an equilibrium
proceedings of the international
of the international conference
the international conference on
international conference on dependable
conference on dependable systems
on dependable systems and
dependable systems and networks
with two minority pools
two minority pools participating
the only nash equilibrium
only nash equilibrium is
nash equilibrium is when
equilibrium is when the
is when the pools
when the pools attack
ip no loss maelstrom
the pools attack one
no loss maelstrom no
pools attack one another
loss maelstrom no loss
maelstrom no loss maelstrom
and both earn less
both earn less than
earn less than if
less than if none
than if none had
if none had attacked
miners therefore face the
therefore face the miner
face the miner s
the miner s dilemma
an instance of the
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
repeatedly choosing between attack
choosing between attack and
between attack and no
with multiple pools of
multiple pools of equal
pools of equal size
of equal size there
equal size there is
size there is a
there is a symmetric
prefetch no prefetch prefetch
a group membership service
no prefetch prefetch no
group membership service for
prefetch prefetch no prefetch
membership service for wans
is a symmetric nash
a symmetric nash equilibrium
acm transactions on computer
transactions on computer systems
where all pools earn
all pools earn less
pools earn less than
earn less than if
less than if none
than if none had
if none had attacked
prefetch no prefetch relative
no prefetch relative speedup
prefetch relative speedup relative
relative speedup relative speedup
inefficient equilibria for open
equilibria for open pools
for open pools may
open pools may serve
pools may serve the
may serve the system
serve the system by
the system by reducing
system by reducing their
by reducing their attraction
reducing their attraction and
their attraction and pushing
attraction and pushing miners
and pushing miners towards
pushing miners towards smaller
miners towards smaller closed
towards smaller closed pools
the classical block withholding
classical block withholding attack
block withholding attack is
withholding attack is old
attack is old as
is old as pools
old as pools themselves
but its use by
its use by pools
use by pools has
by pools has not
pools has not been
has not been suggested
not been suggested until
been suggested until recently
we overview related attacks
overview related attacks and
related attacks and prior
attacks and prior work
and prior work in
prior work in section
prefetch no prefetch relative
work in section x
no prefetch relative speedup
prefetch relative speedup relative
relative speedup relative speedup
and conclude with final
conclude with final remarks
with final remarks in
final remarks in section
remarks in section xi
prefetch no prefetch relative
no prefetch relative speedup
p reliminaries b itcoin
reliminaries b itcoin and
b itcoin and p
itcoin and p ooled
and p ooled m
p ooled m ining
ooled m ining bitcoin
m ining bitcoin is
ining bitcoin is a
bitcoin is a distributed
prefetch no prefetch relative
no prefetch relative speedup
prefetch relative speedup bad
relative speedup bad groups
clients use the system
use the system by
the system by issuing
system by issuing transactions
and the system s
the system s only
system s only task
s only task is
only task is to
task is to serialize
is to serialize transactions
to serialize transactions in
serialize transactions in a
transactions in a single
in a single ledger
a single ledger and
single ledger and reject
ledger and reject transactions
and reject transactions that
reject transactions that cannot
transactions that cannot be
that cannot be serialized
cannot be serialized due
be serialized due to
serialized due to conflicts
due to conflicts with
to conflicts with previous
conflicts with previous transactions
bitcoin transactions are protected
transactions are protected with
are protected with cryptographic
protected with cryptographic techniques
with cryptographic techniques that
cryptographic techniques that ensure
techniques that ensure that
that ensure that only
ensure that only the
that only the rightful
only the rightful owner
the rightful owner of
rightful owner of a
owner of a bitcoin
of a bitcoin can
a bitcoin can transfer
bitcoin can transfer it
the transaction ledger is
transaction ledger is stored
ledger is stored by
is stored by a
stored by a network
by a network of
a network of miners
network of miners in
of miners in a
miners in a data
in a data structure
a data structure caller
data structure caller the
structure caller the blockchain
revenue for proof of
for proof of work
proof of work the
of work the blockchain
work the blockchain records
the blockchain records the
blockchain records the transactions
records the transactions in
the transactions in units
transactions in units of
in units of blocks
dubbed the genesis block
is defined as part
defined as part of
as part of the
part of the protocol
a valid block contains
valid block contains the
block contains the hash
contains the hash of
the hash of the
hash of the previous
of the previous block
the hash of the
hash of the transactions
of the transactions in
the transactions in the
transactions in the current
in the current block
and a bitcoin address
a bitcoin address which
bitcoin address which is
address which is to
which is to be
is to be credited
to be credited with
be credited with a
credited with a reward
with a reward for
a reward for generating
reward for generating the
for generating the block
any miner may add
miner may add a
may add a valid
add a valid block
a valid block to
valid block to the
block to the chain
to the chain by
proving that it has
that it has spent
it has spent a
has spent a certain
spent a certain amount
a certain amount of
certain amount of work
amount of work and
of work and publishing
work and publishing the
and publishing the block
publishing the block with
the block with the
relative speedup of workloads
block with the proof
speedup of workloads with
with the proof over
of workloads with prefetching
the proof over an
proof over an overlay
over an overlay network
an overlay network to
overlay network to all
these graphs show the
network to all other
graphs show the speedup
to all other miners
show the speedup gained
the speedup gained by
speedup gained by adding
gained by adding prefetching
by adding prefetching for
when a miner creates
adding prefetching for a
a miner creates a
tcp no loss maelstrom
prefetching for a range
miner creates a block
no loss maelstrom no
for a range of
loss maelstrom no loss
a range of bandwidth
maelstrom no loss maelstrom
range of bandwidth values
it is compensated for
is compensated for its
compensated for its efforts
relative to the time
for its efforts with
to the time taken
its efforts with bitcoins
the time taken with
time taken with a
taken with a bandwidth
with a bandwidth of
this compensation includes a
compensation includes a per
transaction fee paid by
s and no prefetching
fee paid by the
paid by the users
by the users whose
the users whose transactions
users whose transactions are
where a test comprises
whose transactions are included
a test comprises two
test comprises two separate
comprises two separate processes
and an amount of
an amount of minted
only the speedup for
amount of minted bitcoins
the speedup for the
of minted bitcoins that
speedup for the foreground
for the foreground process
minted bitcoins that are
the foreground process is
bitcoins that are thus
foreground process is shown
that are thus introduced
are thus introduced into
thus introduced into the
introduced into the system
fetch wait for the
wait for the prefetch
for the prefetch to
the prefetch to complete
the work which a
work which a miner
which a miner is
or that the prefetch
a miner is required
that the prefetch be
miner is required to
the prefetch be aborted
is required to do
required to do is
to do is to
do is to repeatedly
issuing a fetch rpc
is to repeatedly calculate
a fetch rpc at
to repeatedly calculate a
fetch rpc at the
repeatedly calculate a a
rpc at the same
calculate a a hash
at the same time
a a hash function
the same time as
a hash function specifically
same time as a
hash function specifically the
time as a prefetch
function specifically the sha
as a prefetch is
a prefetch is in
prefetch is in progress
is in progress needlessly
in progress needlessly wastes
progress needlessly wastes bandwidth
since it retrieves the
it retrieves the same
retrieves the same file
the same file from
same file from the
file from the server
from the server twice
the same could be
same could be true
could be true if
be true if we
true if we opt
if we opt for
we opt for aborting
opt for aborting prefetches
of a block header
since an aborted prefetch
an aborted prefetch could
aborted prefetch could be
to indicate that he
prefetch could be very
indicate that he has
could be very close
that he has performed
be very close to
he has performed this
very close to completion
has performed this work
one way link latency
mfs therefore makes the
the miner provides a
therefore makes the demand
miner provides a probabilistic
makes the demand fetch
provides a probabilistic proof
the demand fetch wait
a probabilistic proof as
demand fetch wait for
probabilistic proof as follows
fetch wait for the
wait for the prefetch
the generated block has
generated block has a
but also raises the
block has a nonce
also raises the priority
has a nonce field
raises the priority of
the priority of the
priority of the prefetch
of the prefetch rpc
which can contain any
the prefetch rpc to
can contain any value
prefetch rpc to that
rpc to that of
to that of a
that of a regular
of a regular fetch
the miner places different
a regular fetch operation
miner places different values
places different values in
different values in this
values in this field
to prevent a priority
in this field and
prevent a priority inversion
this field and calculates
field and calculates the
and calculates the hash
calculates the hash for
this requires an additional
the hash for each
requires an additional raise
hash for each value
aware adaptation techniques for
priority rpc to the
way latency throughput as
if the result of
rpc to the server
the result of the
latency throughput as a
adaptation techniques for mobile
result of the hash
techniques for mobile file
of the hash is
for mobile file systems
the hash is smaller
mobile file systems benjamin
hash is smaller than
file systems benjamin atkin
which results in more
throughput as a function
results in more overhead
as a function of
in more overhead than
a function of latency
is smaller than a
systems benjamin atkin kenneth
smaller than a target
benjamin atkin kenneth p
than a target value
more overhead than the
overhead than the case
than the case where
the case where a
birman nec laboratories america
case where a demand
nec laboratories america cornell
where a demand fetch
laboratories america cornell university
a demand fetch occurs
america cornell university atkin
demand fetch occurs without
the nonce is considered
fetch occurs without a
nonce is considered a
occurs without a fetch
is considered a solution
and the block is
the block is valid
on the other hand
the number of attempts
number of attempts to
of attempts to find
attempts to find a
to find a single
ip to attain very
find a single hash
to attain very high
a single hash is
attain very high speeds
edu abstract therefore react
single hash is therefore
abstract therefore react to
hash is therefore random
therefore react to bandwidth
the fetch can frequently
react to bandwidth variations
very high speeds on
to bandwidth variations in
fetch can frequently make
bandwidth variations in a
high speeds on the
can frequently make use
speeds on the gigabit
is therefore random with
variations in a fine
therefore random with a
on the gigabit link
random with a geometric
frequently make use of
with a geometric distribution
make use of the
use of the data
we had to set
of the data already
had to set the
the data already transferred
to set the mtu
data already transferred and
as each attempt is
life file system traffic
already transferred and so
set the mtu of
transferred and so still
the mtu of the
and so still results
mtu of the entire
so still results in
file system traffic featuring
still results in a
of the entire path
results in a faster
system traffic featuring high
in a faster response
traffic featuring high read
a faster response to
the entire path to
each attempt is a
entire path to be
faster response to the
attempt is a bernoulli
write wireless networks present
is a bernoulli trial
path to be the
a bernoulli trial with
to be the maximum
response to the application
wireless networks present unusual
bernoulli trial with a
networks present unusual challenges
trial with a success
present unusual challenges for
with a success probability
unusual challenges for mobile
a success probability determined
challenges for mobile file
success probability determined by
for mobile file contention
as we have explained
probability determined by the
determined by the target
by the target value
mafs is able to
the implementation of the
is able to achieve
implementation of the prefetching
able to achieve improvements
of the prefetching subsystem
at the existing huge
the prefetching subsystem is
which meant that the
to achieve improvements in
the existing huge hashing
achieve improvements in execusystem
meant that the long
improvements in execusystem clients
existing huge hashing rates
prefetching subsystem is not
huge hashing rates and
subsystem is not sophisticated
hashing rates and small
haul link had the
rates and small target
link had the same
and small target values
since they are characterised
while it will reach
they are characterised by
had the same mtu
are characterised by unpredictable
the same mtu as
characterised by unpredictable tion
it will reach an
by unpredictable tion time
same mtu as the
the time to find
will reach an equilibrium
time to find a
mtu as the inter
to find a single
reach an equilibrium if
find a single hash
unpredictable tion time of
a single hash can
tion time of up
single hash can be
an equilibrium if the
hash can be approximated
time of up to
can be approximated by
equilibrium if the total
be approximated by an
this resulted in the
approximated by an exponential
if the total size
resulted in the fragmentation
by an exponential distribution
the total size of
in the fragmentation of
total size of the
the fragmentation of repair
size of the file
fragmentation of repair packets
of the file groups
the average time for
the file groups in
of repair packets sent
file groups in the
average time for a
groups in the prefetch
repair packets sent over
in the prefetch list
packets sent over udp
time for a miner
the prefetch list is
for a miner to
prefetch list is less
sent over udp on
at both low and
over udp on the
both low and high
list is less than
a miner to find
is less than the
low and high bandwidths
udp on the longhaul
miner to find a
on the longhaul link
less than the cache
the longhaul link into
than the cache size
longhaul link into two
to find a solution
link into two ip
find a solution is
into two ip packet
a solution is therefore
two ip packet fragments
solution is therefore proportional
there is no mechanism
is therefore proportional to
is no mechanism to
the traditional approach to
therefore proportional to its
no mechanism to prevent
proportional to its hashing
traditional approach to adapting
to its hashing rate
mechanism to prevent the
approach to adapting network
its hashing rate or
since the loss of
to prevent the prefetching
the loss of a
hashing rate or mining
loss of a single
rate or mining power
of a single fragment
prevent the prefetching subsystem
a single fragment resulted
to adapting network communication
the prefetching subsystem running
single fragment resulted in
prefetching subsystem running ahead
fragment resulted in the
to maintain a constant
resulted in the loss
subsystem running ahead of
adapting network communication to
running ahead of actual
in the loss of
ahead of actual file
the loss of the
maintain a constant rate
network communication to these
of actual file accesses
communication to these conditions
actual file accesses and
loss of the repair
file accesses and evicting
to these conditions is
accesses and evicting useful
a constant rate of
and evicting useful files
these conditions is to
constant rate of bitcoin
we observed a higher
rate of bitcoin generation
observed a higher loss
conditions is to write
a higher loss rate
evicting useful files from
is to write back
higher loss rate for
to write back file
loss rate for repairs
write back file updates
rate for repairs than
back file updates asynchronously
for repairs than for
file updates asynchronously when
repairs than for data
useful files from the
and as part of
updates asynchronously when bandwidth
as part of its
asynchronously when bandwidth is
part of its defense
files from the cache
of its defense against
than for data packets
its defense against denial
defense against denial of
against denial of service
denial of service and
or evicting files which
of service and other
evicting files which it
service and other attacks
files which it has
which it has prefetched
we expect performance to
this can lead to
it has prefetched but
can lead to underutilisation
the system normalizes the
lead to underutilisation of
has prefetched but have
to underutilisation of bandwidth
prefetched but have not
underutilisation of bandwidth and
but have not yet
of bandwidth and inconsistencies
have not yet been
bandwidth and inconsistencies between
not yet been referenced
expect performance to be
system normalizes the rate
performance to be better
normalizes the rate of
to be better on
the rate of block
and inconsistencies between clients
yet been referenced by
be better on a
been referenced by the
rate of block generation
better on a network
referenced by the user
on a network where
we describe a new
a network where the
describe a new mobile
network where the mtu
a new mobile access
where the mtu of
new mobile access to
the mtu of the
techniques for preventing this
mobile access to shared
for preventing this behaviour
access to shared data
preventing this behaviour have
to shared data is
this behaviour have been
the protocol deterministically defines
mtu of the long
shared data is complicated
behaviour have been discussed
data is complicated by
have been discussed elsewhere
is complicated by an
protocol deterministically defines the
complicated by an unpredictable
haul link is truly
by an unpredictable mobile
deterministically defines the target
an unpredictable mobile file
link is truly larger
defines the target value
is truly larger than
unpredictable mobile file system
truly larger than the
the target value for
larger than the mtu
target value for each
than the mtu within
value for each block
the mtu within each
for each block according
mtu within each cluster
each block according to
block according to the
that supports graceful degradation
according to the time
supports graceful degradation computing
even with zero loss
graceful degradation computing environment
to the time required
the time required to
time required to generate
in order to characterise
required to generate recent
order to characterise the
to generate recent blocks
the network or a
to characterise the effect
network or a particular
ip throughput in figure
or a particular destination
characterise the effect of
a particular destination of
the effect of adding
particular destination of file
effect of adding prefetching
destination of file system
of file system performance
file system performance as
system performance as bandwidth
performance as bandwidth is
we ran a set
as bandwidth is reduced
ran a set of
a set of eight
set of eight microbenchmarks
declines with link latency
is updated once every
as well as may
well as may be
the experimental setup was
as may be unavailable
this is due to
experimental setup was the
is due to the
setup was the same
due to the cap
was the same as
to the cap on
the same as in
or the throughput may
the cap on throughput
the throughput may be
same as in the
throughput may be substandard
cap on throughput placed
as in the priority
on throughput placed by
blocks such that the
throughput placed by the
such that the average
placed by the buffering
as rapid propagation of
by the buffering available
rapid propagation of essential
the buffering available at
propagation of essential file
buffering available at the
of essential file updates
available at the receiving
that the average time
in the priority tests
the average time for
at the receiving end
average time for each
mafs is able to
time for each block
is able to shown
for each block to
though this time mfs
each block to be
this time mfs was
block to be found
able to shown in
time mfs was configured
to be found is
the preceding experiments were
mfs was configured to
preceding experiments were done
was configured to run
experiments were done with
configured to run with
were done with maelstrom
to run with asynchronous
done with maelstrom in
to shown in figure
run with asynchronous writeback
with maelstrom in endto
and rpc with priorities
end flow control mode
note that the exponential
this graph shows results
that the exponential distribution
graph shows results from
the exponential distribution is
shows results from packet
exponential distribution is memoryless
and only prefetching was
where it is oblivious
only prefetching was either
it is oblivious to
prefetching was either enabled
is oblivious to tcp
was either enabled or
if all miners mine
either enabled or disabled
all miners mine for
miners mine for block
mine for block number
ip and does not
for block number b
the tests were run
and does not split
tests were run at
does not split connections
were run at a
once the block is
run at a range
the block is found
at a range of
block is found at
a range of bandwidth
is found at time
range of bandwidth values
found at time t
and is consequently sensitive
is consequently sensitive to
consequently sensitive to the
sensitive to the size
improvements in execution time
to the size of
in execution time for
the size of the
execution time for real
size of the receiver
all miners switch to
of the receiver buffer
miners switch to mine
as in the previous
switch to mine for
life measurements of available
in the previous section
measurements of available bandwidth
to mine for the
of available bandwidth between
mine for the subsequent
available bandwidth between a
for the subsequent block
bandwidth between a mobile
each microbenchmark consists of
between a mobile host
the subsequent block b
a mobile host on
shows the performance of
mobile host on a
microbenchmark consists of one
the performance of split
consists of one or
performance of split mode
host on a wireless
of one or two
of split mode flow
on a wireless network
one or two processes
split mode flow control
at t without changing
or two processes accessing
t without changing their
two processes accessing files
and a wired host
without changing their probability
a wired host near
changing their probability distribution
wired host near the
where maelstrom breaks a
their probability distribution of
host near the base
probability distribution of finding
near the base station
distribution of finding a
maelstrom breaks a single
with some or all
of finding a block
breaks a single tcp
some or all of
finding a block after
file system traces featuring
or all of the
system traces featuring read
all of the files
a block after t
ip connection into three
of the files forming
connection into three hops
the files forming file
files forming file groups
as the mobile host
the mobile host moves
the probability that a
probability that a miner
write test is the
factors such as the
test is the same
that a miner i
is the same as
such as the distance
a miner i with
the same as in
miner i with mining
as the distance to
same as in section
i with mining power
the distance to the
split mode flow control
with mining power mi
mode flow control eliminates
distance to the base
flow control eliminates the
mining power mi finds
to the base station
power mi finds the
the base station and
with a file group
control eliminates the requirement
a file group added
base station and local
file group added for
eliminates the requirement for
mi finds the next
the requirement for large
group added for the
requirement for large buffers
added for the read
for large buffers at
for the read data
large buffers at the
finds the next block
station and local interference
the next block is
buffers at the receiving
next block is its
at the receiving end
the compile mfs test
and local interference cause
block is its ratio
compile mfs test has
local interference cause the
is its ratio out
mfs test has six
its ratio out of
interference cause the host
ratio out of the
throughput is essentially insensitive
test has six file
is essentially insensitive to
out of the total
cause the host s
of the total mining
essentially insensitive to one
the total mining power
the host s network
total mining power m
has six file groups
host s network card
six file groups for
s network card to
file groups for the
network card to switch
groups for the main
mining power m in
for the main directories
power m in the
the main directories of
m in the system
main directories of the
with a slight drop
card to switch to
a slight drop due
to switch to higher
directories of the system
slight drop due to
drop due to buffering
due to buffering overhead
to buffering overhead on
miner miner miner pool
buffering overhead on the
overhead on the maelstrom
on the maelstrom boxes
mb of data in
miner miner miner pool
compares split mode to
such switching causes available
split mode to end
switching causes available bandwidth
forming a single file
causes available bandwidth to
a single file group
available bandwidth to oscillate
bandwidth to oscillate distributed
to oscillate distributed file
oscillate distributed file systems
distributed file systems are
file systems are a
systems are a common
mb of small files
are a common feature
a common feature of
common feature of large
feature of large com
even when the mobile
when the mobile host
the mobile host is
mobile host is stationary
if it is to
all the files are
it is to enputing
the files are in
is to enputing environments
files are in a
are in a single
and one miner mines
in a single file
one miner mines solo
since they simplify sharing
a single file group
they simplify sharing data
simplify sharing data between
sharing data between sure
data between sure that
between sure that clients
sure that clients file
pools datacenters are built
that clients file operations
datacenters are built around
fetch runs as two
clients file operations are
are built around the
runs as two process
built around the world
file operations are executed
operations are executed in
are executed in a
executed in a timely
in a timely way
and can provide scalable
can provide scalable and
provide scalable and highly
scalable and highly available
and highly available file
highly available file ac
mining is only profitable
is only profitable using
only profitable using dedicated
which form a file
file system must adapt
profitable using dedicated hardware
system must adapt to
form a file group
must adapt to this
using dedicated hardware in
adapt to this variation
dedicated hardware in cutting
hardware in cutting edge
in cutting edge mining
the other does the
cutting edge mining rigs
other does the same
otherwise the energy costs
but without a file
the energy costs exceed
without a file group
energy costs exceed the
costs exceed the expected
exceed the expected revenue
simultaneous writeback executes in
writeback executes in the
executes in the same
although expected revenue from
in the same way
expected revenue from mining
revenue from mining is
from mining is proportional
supporting mobile clients requires
mining is proportional to
mobile clients requires coping
is proportional to the
but the second process
proportional to the power
clients requires coping existing
to the power of
the second process writes
the power of the
requires coping existing systems
power of the mining
coping existing systems tailored
of the mining rigs
existing systems tailored to
the mining rigs used
second process writes the
systems tailored to low
process writes the files
writes the files to
a single home miner
the files to the
single home miner using
bandwidth clients differenwith the
files to the server
clients differenwith the atypical
to the server instead
home miner using a
the server instead of
differenwith the atypical patterns
miner using a small
the atypical patterns of
server instead of reading
atypical patterns of connectivity
instead of reading them
patterns of connectivity that
using a small rig
of connectivity that characterise
a small rig is
connectivity that characterise them
small rig is unlikely
rig is unlikely to
the remaining tests investigate
is unlikely to mine
remaining tests investigate the
unlikely to mine a
tiate between types of
to mine a block
between types of file
mine a block for
types of file system
tests investigate the overhead
a block for years
investigate the overhead paid
of file system communication
the overhead paid for
overhead paid for weaknesses
paid for weaknesses in
for weaknesses in the
weaknesses in the prefetching
so that bandwhile a
in the prefetching algorithm
that bandwhile a desktop
bandwhile a desktop client
a desktop client is
desktop client is well
connected to a file
to a file server
a file server un
width can be devoted
can be devoted to
be devoted to important
miners often organize themselves
often organize themselves into
organize themselves into mining
themselves into mining pools
mode buffering flow control
buffering flow control against
flow control against one
way link latency left
a pool is a
pool is a group
is a group of
most bar represents maelstrom
a group of miners
bar represents maelstrom in
group of miners that
represents maelstrom in end
of miners that share
kb files and forming
miners that share their
a mobile client frequently
that share their revenues
files and forming its
share their revenues when
and forming its own
mobile client frequently lacks
forming its own file
end mode with manually
its own file group
their revenues when one
client frequently lacks the
revenues when one of
mode with manually configured
when one of them
with manually configured large
one of them successfully
manually configured large buffers
of them successfully mines
on its first iteration
configured large buffers at
them successfully mines a
large buffers at end
successfully mines a block
the workload accesses the
workload accesses the first
accesses the first file
the first file in
first file in each
for each block found
file in each directory
and the second and
the second and third
second and third bar
the revenue is distributed
and third bar from
revenue is distributed among
third bar from left
is distributed among the
bar from left are
distributed among the pool
from left are split
among the pool members
left are split mode
the pool members in
are split mode and
pool members in proportion
split mode and end
members in proportion to
in proportion to their
to provoke a large
proportion to their mining
provoke a large amount
to their mining power
a large amount of
writes back changes to
large amount of useless
back changes to files
amount of useless prefetches
changes to files asynbandwidth
to files asynbandwidth to
files asynbandwidth to perform
asynbandwidth to perform all
good order and bad
to perform all its
order and bad order
perform all its file
and bad order investigate
all its file operations
the expected revenue of
with standard buffers at
expected revenue of a
standard buffers at end
bad order investigate the
its file operations in
order investigate the effect
file operations in a
revenue of a pool
investigate the effect of
of a pool member
operations in a timely
a pool member is
in a timely fashion
the effect of the
pool member is therefore
effect of the ordered
split mode performs as
of the ordered list
member is therefore the
the ordered list of
mode performs as well
is therefore the same
performs as well with
therefore the same as
as well with default
ordered list of files
well with default sized
the same as its
with default sized buffers
same as its revenue
default sized buffers as
as its revenue had
list of files in
sized buffers as end
its revenue had it
of files in a
revenue had it mined
files in a file
had it mined solo
in a file group
assigns lower priorities to
lower priorities to asynmobile
end mode performs with
priorities to asynmobile file
mode performs with large
to asynmobile file systems
performs with large end
asynmobile file systems typically
due to the large
file systems typically assume
to the large power
systems typically assume that
the large power of
typically assume that a
large power of the
assume that a client
and much better than
power of the pool
prefetching evaluation having added
that a client is
evaluation having added prefetching
a client is strongly
having added prefetching to
much better than end
added prefetching to mfs
it finds blocks at
finds blocks at a
blocks at a much
chronous operations at the
at a much higher
operations at the ip
a much higher rate
at the ip level
we evaluated whether such
the ip level to
evaluated whether such a
ip level to reduce
end mode with default
level to reduce interference
and so the frequency
to reduce interference with
so the frequency of
reduce interference with connected
the frequency of revenue
interference with connected like
frequency of revenue collection
with connected like a
of revenue collection is
connected like a desktop
revenue collection is higher
like a desktop host
whether such a straightforward
mode with default sized
such a straightforward algorithm
with default sized buffers
a straightforward algorithm can
allowing for a stable
straightforward algorithm can have
for a stable daily
algorithm can have a
a stable daily or
can have a benefit
stable daily or weekly
connected and should foreground
have a benefit for
and should foreground operations
a benefit for some
daily or weekly income
benefit for some repre
limit its bandwidth consumption
its bandwidth consumption to
bandwidth consumption to a
order accesses the files
consumption to a minimum
accesses the files in
most pools are controlled
the files in the
pools are controlled by
files in the group
are controlled by a
in the group in
controlled by a centralized
the group in the
by a centralized pool
group in the same
a centralized pool manager
in the same order
the same order as
same order as the
order as the list
bad order accesses them
miners register with the
order accesses them in
register with the pool
accesses them in reverse
with the pool manager
them in reverse order
the pool manager and
pool manager and mine
manager and mine on
and mine on its
mine on its behalf
adaptation by deferred transmission
by deferred transmission of
deferred transmission of file
transmission of file upwidth
the pool manager generates
of file upwidth lies
pool manager generates tasks
file upwidth lies between
manager generates tasks and
upwidth lies between these
generates tasks and the
lies between these extremes
tasks and the miners
and the miners search
the miners search for
miners search for solutions
assuming weak connectivity dates
search for solutions based
weak connectivity dates has
for solutions based on
analysis of prefetching the
solutions based on these
of prefetching the graphs
connectivity dates has the
prefetching the graphs in
based on these tasks
the graphs in figure
dates has the disadvantage
on these tasks that
has the disadvantage of
these tasks that can
the disadvantage of increasing
tasks that can serve
disadvantage of increasing the
that can serve as
of increasing the delay
can serve as proof
show the results of
serve as proof of
the results of the
as proof of work
results of the experiments
increasing the delay before
the delay before upcan
delay before upcan be
before upcan be too
upcan be too conservative
where a test such
once they find a
a test such as
they find a solution
test such as simultaneous
such as simultaneous demand
since it delays sending
it delays sending updates
they send it to
delays sending updates to
send it to the
sending updates to the
it to the pool
fetch incorporates more than
updates to the dates
incorporates more than one
to the pool manager
to the dates are
more than one workload
the dates are applied
dates are applied at
are applied at the
applied at the file
the pool manager behaves
at the file server
pool manager behaves as
only the elapsed time
manager behaves as a
the elapsed time for
behaves as a single
elapsed time for the
as a single miner
time for the foreground
a single miner in
and therefore reduces the
for the foreground workload
therefore reduces the deserver
single miner in the
reduces the deserver in
miner in the bitcoin
the deserver in order
in the bitcoin system
deserver in order to
the one accessing a
in order to aggregate
one accessing a file
order to aggregate modifications
accessing a file group
once it obtains a
it obtains a legitimate
obtains a legitimate block
a legitimate block from
gree of consistency between
legitimate block from one
of consistency between clients
block from one of
consistency between clients cached
in most of the
between clients cached copies
from one of its
most of the microbenchmarks
one of its miners
for its own this
its own this paper
own this paper examines
adding prefetching from the
this paper examines the
prefetching from the file
paper examines the effectiveness
from the file groups
examines the effectiveness of
the block transfers the
the effectiveness of mafs
the file groups specified
block transfers the revenue
file groups specified has
transfers the revenue to
groups specified has a
the revenue to the
specified has a substantial
revenue to the control
has a substantial improvement
to the control of
a substantial improvement on
the control of the
substantial improvement on the
control of the pool
improvement on the performance
of the pool manager
bandwidth client may decide
on the performance of
client may decide to
the performance of the
may decide to delay
performance of the workload
the pool manager then
decide to delay sending
pool manager then distributes
to delay sending a
manager then distributes the
delay sending a file
then distributes the revenue
varying with how amenable
distributes the revenue among
with how amenable it
the revenue among the
how amenable it is
sending a file system
revenue among the miners
a file system that
among the miners according
amenable it is to
the miners according to
file system that propagates
miners according to their
it is to prefetching
according to their mining
system that propagates file
to their mining power
that propagates file modifications
propagates file modifications asynchronously
file modifications asynchronously file
modifications asynchronously file s
the architecture is illustrated
asynchronously file s update
architecture is illustrated in
file s update to
is illustrated in figure
s update to the
more surplus bandwidth and
update to the file
surplus bandwidth and more
to the file server
bandwidth and more think
in order to estimate
and more think time
order to estimate the
more think time result
to estimate the mining
think time result in
estimate the mining power
time result in improved
the mining power of
result in improved performance
but this decision may
mining power of a
this decision may also
power of a miner
decision may also affect
may also affect at
this naturally means that
also affect at all
naturally means that the
affect at all bandwidth
means that the greatest
at all bandwidth levels
the pool manager sets
that the greatest improvements
pool manager sets a
the greatest improvements from
manager sets a partial
greatest improvements from prefetching
rather than delaying writes
sets a partial target
improvements from prefetching are
a partial target for
from prefetching are evident
partial target for each
prefetching are evident at
target for each member
mafs other clients that
are evident at higher
other clients that would
evident at higher bandwidths
clients that would like
that would like to
would like to read
like to read the
to read the file
six out of eight
out of eight microbenchmarks
of eight microbenchmarks run
eight microbenchmarks run at
microbenchmarks run at least
optimistic concuruses rpc priorities
concuruses rpc priorities to
rpc priorities to reduce
priorities to reduce interference
to reduce interference between
reduce interference between read
interference between read and
between read and rency
than the target of
faster when bandwidth is
the target of the
read and rency control
target of the bitcoin
and rency control and
of the bitcoin system
rency control and reconciliation
control and reconciliation of
and reconciliation of conflicting
reconciliation of conflicting updates
each miner is required
of conflicting updates are
miner is required to
conflicting updates are typwrite
is required to send
updates are typwrite traffic
required to send the
are typwrite traffic at
to send the pool
typwrite traffic at low
send the pool manager
traffic at low bandwidth
the pool manager blocks
pool manager blocks that
manager blocks that are
blocks that are correct
that are correct according
to ensure that file
are correct according to
ensure that file modifications
correct according to the
that file modifications ically
according to the partial
file modifications ically used
to the partial target
modifications ically used to
ically used to resolve
at low bandwidth most
used to resolve inconsistencies
low bandwidth most workloads
bandwidth most workloads see
most workloads see no
the partial target is
workloads see no benefit
partial target is chosen
target is chosen to
is chosen to be
chosen to be large
since all the bandwidth
all the bandwidth is
the bandwidth is dedicated
bandwidth is dedicated to
such that partial solutions
is dedicated to higher
that partial solutions arrive
partial solutions arrive frequently
solutions arrive frequently enough
arrive frequently enough for
frequently enough for the
enough for the manager
for the manager to
only two tests perform
the manager to accurately
two tests perform worse
manager to accurately estimate
tests perform worse with
to accurately estimate the
perform worse with prefetching
accurately estimate the power
when bandwidth are rapidly
estimate the power of
worse with prefetching than
bandwidth are rapidly propagated
with prefetching than without
are rapidly propagated to
the power of the
rapidly propagated to the
power of the miner
propagated to the clients
to the clients that
the clients that need
clients that need them
write test performs slightly
test performs slightly worse
mafs is very low
performs slightly worse due
slightly worse due to
worse due to its
to reduce management overhead
this can be an
due to its already
can be an acceptable
to its already heavy
be an acceptable price
its already heavy network
an acceptable price to
already heavy network contention
as the value of
acceptable price to pay
the value of bitcoin
price to pay for
value of bitcoin rose
to pay for the
the bad groups test
pay for the abilalso
for the abilalso incorporates
the abilalso incorporates a
bitcoin mining has become
abilalso incorporates a new
mining has become a
incorporates a new invalidation
has become a rapidly
which exploits poor prefetching
become a rapidly advancing
exploits poor prefetching hints
a rapidly advancing industry
based update propagation ity
update propagation ity to
propagation ity to continue
ity to continue accessing
technological advancements lead to
to continue accessing a
advancements lead to ever
continue accessing a file
lead to ever more
performs when prefetching is
to ever more efficient
accessing a file server
ever more efficient hashing
when prefetching is used
more efficient hashing asics
but if bandwidth is
if bandwidth is less
this effect is due
bandwidth is less scheme
effect is due to
is due to the
due to the useless
to the useless prefetching
unlike previous mobile file
the useless prefetching rpcs
previous mobile file systems
useless prefetching rpcs flooding
prefetching rpcs flooding the
rpcs flooding the outgoing
flooding the outgoing link
the outgoing link and
outgoing link and imposing
link and imposing minor
and imposing minor delays
imposing minor delays on
minor delays on each
this is a simplification
delays on each demand
is a simplification that
on each demand fetch
a simplification that is
simplification that is sufficient
that is sufficient for
client consistency is achievable
is sufficient for our
sufficient for our analysis
cumulatively these slow down
these slow down the
way delivery latency against
slow down the overall
codaniques that are oblivious
delivery latency against loss
the intricacies of reward
down the overall performance
that are oblivious to
latency against loss rate
intricacies of reward systems
are oblivious to the
of reward systems are
oblivious to the exact
reward systems are explained
to the exact bandwidth
systems are explained in
the exact bandwidth level
an usual phenomenon is
usual phenomenon is that
phenomenon is that the
is that the bad
and can like file
that the bad order
can like file systems
the bad order test
like file systems therefore
bad order test consistently
file systems therefore switch
order test consistently outperforms
systems therefore switch between
test consistently outperforms good
therefore switch between a
consistently outperforms good order
switch between a low
even though the latter
though the latter triggers
the latter triggers prefetches
latter triggers prefetches in
triggers prefetches in the
prefetches in the correct
a notable exception is
in the correct order
writes mode and a
notable exception is p
mode and a synchronous
the explanation is that
acthe authors were supported
authors were supported in
the good order test
were supported in part
good order test suffers
supported in part by
order test suffers from
in part by darpa
test suffers from the
part by darpa under
suffers from the fast
by darpa under afrl
from the fast linear
darpa under afrl grant
the fast linear scan
under afrl grant radc
fast linear scan phenomenon
afrl grant radc cording
linear scan phenomenon described
grant radc cording to
scan phenomenon described in
radc cording to the
phenomenon described in section
cording to the available
which we discuss in
to the available bandwidth
we discuss in section
discuss in section ix
forks block propagation in
block propagation in the
propagation in the overlay
in a wireless f
in the overlay network
the overlay network takes
overlay network takes seconds
all prefetches in this
prefetches in this test
in this test conflict
therefore it is possible
this test conflict with
it is possible for
test conflict with demand
is possible for two
conflict with demand fetches
possible for two distant
for two distant miners
two distant miners to
distant miners to generate
miners to generate competing
to generate competing blocks
both of which name
at the start of
of which name the
the start of the
which name the same
start of the bad
name the same block
of the bad order
the same block as
the bad order test
same block as their
block as their predecessor
the prefetching subsystem is
prefetching subsystem is able
subsystem is able to
is able to prefetch
able to prefetch some
to prefetch some files
prefetch some files accessed
some files accessed at
files accessed at the
are rare since the
accessed at the end
rare since the average
at the end of
since the average mining
the end of the
the average mining interval
end of the test
average mining interval is
without conflicting with a
conflicting with a demand
with a demand fetch
and by afosr under
by afosr under muri
afosr under muri grant
under muri grant f
it can therefore achieve
and they occur on
can therefore achieve a
they occur on average
therefore achieve a greater
occur on average once
achieve a greater speedup
on average once every
the system has a
system has a mechanism
has a mechanism to
a mechanism to solve
mechanism to solve forks
to solve forks when
solve forks when they
forks when they do
when they do occur
causing one of the
one of the blocks
of the blocks to
the blocks to be
blocks to be discarded
we ignore bifurcations for
ignore bifurcations for the
bifurcations for the sake
for the sake of
variations in bandwidth can
the sake of simplicity
in bandwidth can occur
bandwidth can occur without
can occur without the
occur without the user
since the choice of
without the user s
the choice of the
the user s with
choice of the discarded
user s with additional
of the discarded block
s with additional support
the discarded block on
with additional support from
discarded block on bifurcation
additional support from microsoft
block on bifurcation is
support from microsoft research
on bifurcation is random
from microsoft research and
microsoft research and from
research and from the
and from the intel
from the intel corporation
one may incorporate this
may incorporate this event
incorporate this event into
this event into the
event into the probability
into the probability of
the probability of finding
probability of finding a
of finding a block
so that changing modes
that changing modes creates
changing modes creates unexpected
modes creates unexpected incon
and consider instead the
consider instead the probability
instead the probability of
the probability of finding
several clients concurrently modify
probability of finding a
clients concurrently modify a
of finding a block
concurrently modify a file
finding a block that
a block that is
block that is not
that is not discarded
the final contents depend
final contents depend on
contents depend on the
depend on the client
pools often charge a
on the client that
often charge a small
the client that closed
charge a small percentage
client that closed it
a small percentage of
that closed it last
small percentage of the
percentage of the revenue
of the revenue as
the revenue as fee
a client can lock
client can lock a
can lock a file
lock a file to
we discuss in section
a file to synchronise
discuss in section ix
file to synchronise accesses
in section ix the
section ix the implications
ix the implications of
the implications of such
the server grants the
implications of such fees
server grants the client
of such fees to
grants the client a
such fees to our
the client a lease
fees to our analysis
many pools are open
pools are open and
are open and accept
open and accept any
and accept any interested
accept any interested miner
that is renewed each
is renewed each time
renewed each time the
each time the client
time the client communicates
a pool interface is
the client communicates with
pool interface is typically
client communicates with the
interface is typically comprised
communicates with the file
is typically comprised of
with the file server
typically comprised of a
comprised of a web
of a web interface
a web interface for
web interface for registration
interface for registration and
for registration and a
registration and a miner
and a miner interface
a miner interface for
miner interface for the
interface for the mining
for the mining software
in order to mine
order to mine for
to mine for a
mine for a pool
a miner registers with
miner registers with the
registers with the web
with the web interface
supplies a bitcoin address
a bitcoin address to
bitcoin address to receive
address to receive its
to receive its future
receive its future shares
its future shares of
future shares of the
shares of the revenue
and receives from the
receives from the pool
from the pool credentials
the pool credentials for
pool credentials for mining
number of rpcs by
of rpcs by type
then he feeds his
rpcs by type in
he feeds his credentials
by type in bandwidth
feeds his credentials and
type in bandwidth variability
his credentials and the
in bandwidth variability test
credentials and the pool
and the pool s
the pool s address
pool s address to
s address to its
the entries under p
address to its mining
entries under p denote
to its mining rig
under p denote periods
p denote periods in
denote periods in the
periods in the test
the mining rig obtains
mining rig obtains its
rig obtains its tasks
gives the abbreviations for
obtains its tasks from
the abbreviations for rpc
its tasks from the
abbreviations for rpc types
tasks from the pool
from the pool and
the pool and sends
pool and sends partial
and sends partial and
are likely to be
sends partial and full
likely to be beneficial
partial and full proof
and full proof of
full proof of work
the first would reduce
first would reduce the
would reduce the aggressiveness
typically with the stratum
reduce the aggressiveness of
with the stratum protocol
the aggressiveness of prefetching
packet delivery latencies throughput
setting a byte threshold
from a file group
a file group if
file group if it
group if it appeared
as it finds blocks
if it appeared that
it appeared that a
appeared that a process
that a process was
the pool manager credits
a process was not
pool manager credits the
process was not using
manager credits the miner
was not using the
credits the miner s
not using the files
the miner s account
using the files prefetched
miner s account according
the files prefetched based
s account according to
files prefetched based on
account according to its
prefetched based on its
according to its share
adaptive remote procedure call
based on its prior
to its share of
remote procedure call figure
on its prior accesses
its share of the
share of the work
this would reduce the
would reduce the overhead
and transfers these funds
reduce the overhead in
transfers these funds either
the overhead in the
these funds either on
overhead in the bad
time series of wireless
funds either on request
in the bad groups
series of wireless bandwidth
either on request or
the bad groups case
on request or automatically
request or automatically to
or automatically to the
mafs uses adaptive remote
automatically to the aforementioned
uses adaptive remote procedure
mbps flow alongside on
adaptive remote procedure call
the second would explicitly
to the aforementioned bitcoin
second would explicitly detect
the aforementioned bitcoin address
would explicitly detect a
remote procedure call for
flow alongside on the
explicitly detect a fast
alongside on the same
detect a fast linear
on the same link
a fast linear scan
the same link to
fast linear scan by
same link to simulate
linear scan by a
link to simulate a
scan by a process
to simulate a real
too big pools despite
procedure call for client
big pools despite their
pools despite their important
despite their important role
by counting the instances
their important role of
time stream combined with
counting the instances of
stream combined with other
important role of enabling
combined with other inter
role of enabling small
the instances of prefetch
instances of prefetch and
of prefetch and demand
prefetch and demand fetch
and demand fetch conflict
demand fetch conflict for
fetch conflict for a
conflict for a file
for a file group
pools can constitute a
can constitute a threat
adaptation based on low
constitute a threat to
a threat to the
and then disable prefetching
threat to the bitcoin
then disable prefetching from
to the bitcoin system
disable prefetching from the
the bitcoin system if
prefetching from the group
bitcoin system if their
system if their size
if their size is
shows the average delivery
their size is too
adaptive rpc is based
size is too large
rpc is based on
the average delivery latency
is based on our
average delivery latency of
based on our earlier
on our earlier work
our earlier work in
earlier work in modes
if one pool controls
work in modes can
prefetching and bandwidth variability
one pool controls the
in modes can be
pool controls the majority
modes can be ill
controls the majority of
level packets in the
and bandwidth variability so
the majority of mining
bandwidth variability so far
majority of mining power
suited to situations where
to situations where bandwidth
situations where bandwidth is
where bandwidth is not
bandwidth is not network
our experimental results have
the system becomes unstable
experimental results have demonstrated
results have demonstrated the
have demonstrated the benefits
demonstrated the benefits of
as loss rates go
the benefits of mfs
loss rates go up
benefits of mfs adaptation
of mfs adaptation mechanisms
mfs adaptation mechanisms at
adaptation mechanisms at various
mechanisms at various levels
at various levels of
various levels of bandwidth
levels of bandwidth availability
and differs from severely
differs from severely constrained
but not when the
not when the bandwidth
when the bandwidth is
the bandwidth is changing
but insufficient for a
bandwidth is changing over
insufficient for a client
is changing over the
for a client to
changing over the duration
a client to ignore
over the duration of
client to ignore it
the duration of the
to ignore it a
duration of the test
ignore it a typical
it a typical rpc
shows the same scenario
a typical rpc system
the same scenario with
typical rpc system in
same scenario with a
rpc system in allowing
scenario with a constant
to conclude this section
with a constant uniformly
system in allowing applications
a constant uniformly random
conclude this section we
constant uniformly random loss
in allowing applications to
this section we will
allowing applications to control
uniformly random loss rate
applications to control how
random loss rate of
to control how concurrent
section we will describe
control how concurrent rpcs
warns that the system
we will describe an
how concurrent rpcs are
that the system is
concurrent rpcs are transmitted
will describe an example
the system is unstable
describe an example of
system is unstable with
an example of mfs
is unstable with even
example of mfs traffic
and special handling for
of mfs traffic under
special handling for failwhen
mfs traffic under the
unstable with even smaller
traffic under the execution
with even smaller pools
under the execution of
handling for failwhen deciding
the execution of the
for failwhen deciding what
execution of the simultaneous
failwhen deciding what to
of the simultaneous writeback
deciding what to send
maelstrom s delivery latency
the simultaneous writeback test
s delivery latency is
what to send over
delivery latency is almost
to send over the
latency is almost exactly
send over the network
is almost exactly equal
in realistic scenarios of
almost exactly equal to
simultaneous writeback test described
realistic scenarios of the
writeback test described in
exactly equal to the
scenarios of the bitcoin
ures due to insufficient
of the bitcoin system
due to insufficient bandwidth
test described in section
equal to the one
the bitcoin system no
bitcoin system no pool
system no pool controls
adaptive rpc requests and
no pool controls a
way latency on the
rpc requests and replies
pool controls a majority
latency on the link
controls a majority of
requests and replies can
a majority of the
and replies can contain
majority of the mining
replies can contain an
of the mining power
can contain an arbitrary
this test involves two
contain an arbitrary amount
test involves two simultaneous
ip takes more than
an arbitrary amount of
takes more than twice
involves two simultaneous workloads
arbitrary amount of data
more than twice as
than twice as long
for one day in
twice as long once
one day in june
as long once one
a sender also attaches
sender also attaches a
also attaches a priority
attaches a priority and
way latencies go past
a priority and timeout
kb to the server
priority and timeout to
to the server and
and timeout to the
the server and the
timeout to the send
server and the other
to the send operation
and the other reads
a single pool called
single pool called ghash
file system overview rover
kb files from the
system overview rover queued
files from the server
overview rover queued rpc
but is slightly modified
is slightly modified from
slightly modified from original
modified from original version
of the blocks in
from original version to
the blocks in the
original version to use
blocks in the bitcoin
version to use a
in the bitcoin main
to use a longer
the bitcoin main chain
use a longer think
a longer think time
an adaptive rpc can
longer think time of
adaptive rpc can be
rpc can be asynchronous
the bitcoin community backlashed
bitcoin community backlashed at
community backlashed at the
backlashed at the pool
adaptive mobile file system
which has done nothing
has done nothing worse
done nothing worse than
nothing worse than being
is a distributed file
worse than being extremely
seconds when accessing each
than being extremely successful
when accessing each file
a distributed file sys
ip one way link
one way link latency
improving the potential for
so that an application
the potential for rpcs
that an application need
potential for rpcs to
an application need not
for rpcs to overlap
application need not block
io reduced its relative
need not block waiting
reduced its relative mining
not block waiting for
its relative mining power
block waiting for the
relative mining power and
waiting for the result
mining power and publicly
power and publicly committed
we enabled asynchronous writeback
and publicly committed to
enabled asynchronous writeback and
intem designed to support
publicly committed to stay
designed to support efficient
committed to stay away
asynchronous writeback and ran
to stay away from
to support efficient access
writeback and ran the
support efficient access to
stay away from the
efficient access to a
and ran the test
access to a remote
ran the test with
to a remote file
the test with the
a remote file server
test with the synthetic
remote file server stead
with the synthetic bandwidth
the synthetic bandwidth trace
split with regular buffers
synthetic bandwidth trace shown
bandwidth trace shown in
trace shown in figure
the library makes an
library makes an upcall
makes an upcall when
an upcall when the
upcall when the reply
when the reply arrives
block withholding and its
withholding and its detection
and its detection classical
its detection classical block
since an application can
detection classical block withholding
an application can perform
end with large buffers
application can perform multiple
can perform multiple rpcs
which changes the bandwidth
perform multiple rpcs concurby
changes the bandwidth once
multiple rpcs concurby mobile
the bandwidth once per
rpcs concurby mobile clients
bandwidth once per second
concurby mobile clients that
mobile clients that must
clients that must cope
that must cope with
must cope with variations
this has three sections
cope with variations in
is an attack performed
and outperforms it with
with variations in available
an attack performed by
outperforms it with regular
attack performed by a
it with regular buffers
performed by a pool
a brief period when
variations in available bandwidth
brief period when the
by a pool member
period when the bandwidth
a pool member against
when the bandwidth is
pool member against the
the bandwidth is at
the mafs design and
member against the other
mafs design and terminology
against the other pool
design and terminology are
the other pool members
and terminology are similar
terminology are similar to
are similar to rently
latency metrics to measure
metrics to measure the
the attacking miner registers
to measure the latency
attacking miner registers with
adaptive rpc schedules their
miner registers with the
rpc schedules their transmission
registers with the pool
measure the latency effects
with the pool and
a gradual decrease to
the pool and apparently
the latency effects of
this corresponds to allocating
pool and apparently starts
corresponds to allocating bandwidth
latency effects of tcp
to allocating bandwidth among
and apparently starts mining
allocating bandwidth among the
apparently starts mining honestly
bandwidth among the competing
starts mining honestly it
among the competing rpcs
mining honestly it regularly
honestly it regularly sends
it regularly sends the
regularly sends the pool
sends the pool partial
the andrew file system
the pool partial proof
s over the course
pool partial proof of
over the course of
partial proof of work
the course of ten
course of ten seconds
mbps stream between two
and then the maintenance
stream between two nodes
then the maintenance of
between two nodes over
the maintenance of the
two nodes over a
the attacking miner sends
attacking miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
if it finds a
it finds a full
finds a full solution
attaching priorities to rpcs
a full solution that
priorities to rpcs allows
full solution that constitutes
to rpcs allows applications
s rate until the
rpcs allows applications to
rate until the end
allows applications to control
until the end of
solution that constitutes a
applications to control this
that constitutes a full
to control this scheduling
the end of the
control this scheduling policy
end of the test
constitutes a full proof
a full proof of
full proof of work
proof of work it
a programmer divides rpcs
of work it discards
programmer divides rpcs into
work it discards the
divides rpcs into classes
it discards the solution
plots delivery latency against
delivery latency against message
latency against message identifier
reducing the pool s
summary of results the
the pool s total
of results the test
pool s total revenue
results the test was
a key point is
the test was executed
key point is that
file access model based
test was executed once
point is that we
access model based on
was executed once with
is that we are
executed once with prefetching
that we are plotting
once with prefetching enabled
we are plotting the
this attack is illustrated
are plotting the delivery
model based on the
plotting the delivery latency
attack is illustrated in
and despite the simplicity
is illustrated in figure
based on the importance
the delivery latency of
on the importance of
delivery latency of all
the importance of their
latency of all packets
importance of their results
despite the simplicity of
of their results to
the simplicity of the
their results to the
simplicity of the mfs
results to the user
of the mfs prefetching
not just lost ones
the mfs prefetching implementation
the attacker does not
attacker does not change
does not change the
and then mafs clients
not change the pool
then mafs clients use
change the pool s
the spikes in latency
once with no prefetching
mafs clients use whole
the pool s effective
spikes in latency are
pool s effective mining
in latency are triggered
s effective mining power
latency are triggered by
and the rpcs were
are triggered by losses
the rpcs were then
triggered by losses that
rpcs were then divided
when a file is
and does not affect
a file is accessed
does not affect directly
were then divided acwe
not affect directly the
file is accessed assigns
affect directly the revenue
then divided acwe have
by losses that lead
divided acwe have shown
directly the revenue of
acwe have shown that
losses that lead to
have shown that workloads
the revenue of other
shown that workloads which
revenue of other pools
that workloads which are
that lead to packets
is accessed assigns priorities
lead to packets piling
accessed assigns priorities to
to packets piling up
assigns priorities to the
packets piling up both
priorities to the classes
piling up both at
workloads which are amenable
up both at the
the attacked pool shares
which are amenable to
attacked pool shares its
the library schedules rpcs
pool shares its revenue
library schedules rpcs for
shares its revenue with
schedules rpcs for the
its revenue with the
rpcs for the first
revenue with the attacker
for the first time
are amenable to file
both at the receiver
at the receiver and
the receiver and the
therefore each miner earns
receiver and the sender
each miner earns less
a client fetches the
client fetches the entire
level cording to which
fetches the entire file
cording to which period
as the same revenue
to which period of
the entire file from
which period of the
the same revenue is
period of the trace
entire file from the
ip delays correctly received
file from the file
delays correctly received packets
from the file based
correctly received packets at
same revenue is distributed
of the trace they
the file based on
received packets at the
file based on priorities
packets at the receiver
revenue is distributed among
at the receiver while
is distributed among more
the trace they terminated
based on priorities whenever
the receiver while waiting
on priorities whenever there
receiver while waiting for
priorities whenever there is
while waiting for missing
whenever there is insufficient
waiting for missing packets
there is insufficient bandwidth
for missing packets sequenced
distributed among more miners
trace they terminated in
is insufficient bandwidth to
missing packets sequenced earlier
insufficient bandwidth to server
packets sequenced earlier by
bandwidth to server and
sequenced earlier by the
recall that the proof
to server and caches
that the proof of
server and caches it
the proof of work
earlier by the sender
proof of work is
for each prefetching can
of work is only
each prefetching can achieve
work is only valid
prefetching can achieve speedups
mafs only sends the
can achieve speedups of
it also delays packets
only sends the server
is only valid for
sends the server the
only valid for a
also delays packets at
valid for a specific
the server the contents
delays packets at the
server the contents transmit
for a specific block
the contents transmit competing
packets at the sender
contents transmit competing rpcs
at the sender when
transmit competing rpcs without
the sender when it
competing rpcs without a
as it is the
rpcs without a noticeable
sender when it cuts
without a noticeable delay
it is the nonce
when it cuts down
is the nonce with
it cuts down on
the nonce with which
four quantities are calculated
nonce with which the
rpcs of a modified
with which the block
of a modified file
which the block s
a modified file when
the block s hash
modified file when it
block s hash is
file when it is
s hash is smaller
when it is closed
hash is smaller than
it is closed by
is smaller than its
is closed by an
smaller than its target
closed by an application
the time spent queued
cuts down on the
time spent queued for
down on the sending
spent queued for as
on the sending window
the attacking miner cannot
the sending window size
attacking miner cannot use
queued for as much
this is from higher
sending window size in
miner cannot use it
for as much as
window size in response
size in response to
priority classes are performed
in response to the
classes are performed first
response to the loss
to the loss events
although the term block
and rpcs of referred
the term block withholding
rpcs of referred to
term block withholding has
of referred to as
block withholding has become
referred to as writeback
withholding has become canonical
at bandwidths as low
the delays caused by
bandwidths as low as
delays caused by these
caused by these two
by these two mechanisms
note that the block
these two mechanisms are
that the block is
two mechanisms are illustrated
the block is discarded
mechanisms are illustrated in
block is discarded and
are illustrated in figure
is discarded and never
directory operations cache equal
discarded and never introduced
operations cache equal priority
and never introduced into
cache equal priority are
never introduced into the
equal priority are performed
introduced into the system
priority are performed in
into the system as
are performed in parallel
the system as the
prefetching both the rpc
system as the name
both the rpc request
as the name block
the rpc request and
the name block withholding
rpc request and reply
name block withholding implies
this ensures that the
where single packet losses
ensures that the directory
single packet losses cause
that the directory contents
packet losses cause spikes
the directory contents and
and the time taken
directory contents and apply
losses cause spikes in
the time taken for
cause spikes in delivery
miners miners miners pool
spikes in delivery latency
time taken for each
in delivery latency that
taken for each to
delivery latency that last
for each to be
latency that last for
each to be carries
that last for hundreds
to be carries a
last for hundreds of
contents and apply changes
be carries a small
for hundreds of packets
and apply changes locally
carries a small performance
classical block withholding attack
a small performance overhead
the maelstrom configuration used
as well as mak
maelstrom configuration used is
configuration used is r
a group of miners
even when performed at
group of miners attack
when performed at received
application adapts itself to
of miners attack pool
adapts itself to the
itself to the available
to the available bandwidth
the available bandwidth gracefully
from the first to
with a block withholding
the first to the
a block withholding attack
first to the last
to the last packet
ing an rpc to
an rpc to apply
rpc to apply the
to apply the changes
denoted by a dashed
apply the changes to
by a dashed red
the changes to the
a dashed red arrow
changes to the server
this ignores the time
to the server s
ignores the time the
the server s copy
the time the lowest
time the lowest priority
whole since lower bandwidth
this attack reduces the
since lower bandwidth translates
attack reduces the attacker
which can reduce its
lower bandwidth translates into
can reduce its effectiveness
reduces the attacker s
bandwidth translates into longer
the attacker s revenue
reduce its effectiveness for
attacker s revenue compared
its effectiveness for fast
s revenue compared to
effectiveness for fast lin
translates into longer delays
revenue compared to solo
into longer delays for
compared to solo mining
longer delays for lowerfile
to solo mining or
delays for lowerfile caching
solo mining or honest
spent at the server
for lowerfile caching is
at the server servicing
mining or honest pool
lowerfile caching is effective
or honest pool participation
the server servicing the
caching is effective if
server servicing the rpc
is effective if a
effective if a client
if a client s
it suffers from the
a client s connectivity
suffers from the reduced
client s connectivity is
from the reduced revenue
s connectivity is uncertain
the reduced revenue like
reduced revenue like the
trip time ear scan
revenue like the other
time ear scan workloads
like the other pool
the other pool participants
it is possible to
is possible to construct
rpc timeouts allow the
and its revenue is
possible to construct combination
its revenue is less
timeouts allow the application
revenue is less than
to construct combination of
is less than its
allow the application to
less than its share
construct combination of file
than its share of
combination of file between
its share of the
of file between the
share of the total
file between the client
of the total mining
between the client and
the total mining power
the client and the
the application to prevent
total mining power in
application to prevent since
mining power in the
client and the server
to prevent since the
power in the system
prevent since the client
since the client can
the client can always
client can always use
but these quantities are
this attack can therefore
can always use cached
attack can therefore only
always use cached copies
can therefore only be
these quantities are small
therefore only be used
use cached copies of
only be used for
quantities are small groups
be used for sabotage
cached copies of files
are small groups and
copies of files instead
small groups and a
of files instead low
groups and a workload
at a cost to
and a workload for
a cost to the
a workload for which
cost to the attacker
priority rpcs being silently
workload for which prefetching
rpcs being silently starved
for which prefetching can
which prefetching can significantly
prefetching can significantly compared
can significantly compared to
significantly compared to the
using priorities alof incrementally
compared to the other
priorities alof incrementally fetching
to the other costs
alof incrementally fetching them
even if a pool
incrementally fetching them from
if a pool detects
fetching them from the
a pool detects that
them from the server
pool detects that it
these values are added
detects that it is
values are added up
that it is under
are added up for
it is under a
added up for each
is under a block
up for each degrade
under a block withholding
for each degrade performance
a block withholding attack
lows a programmer to
a programmer to write
programmer to write an
of the rpcs within
to write an adaptive
it might not be
write an adaptive application
might not be able
the rpcs within a
an adaptive application without
rpcs within a particular
not be able to
adaptive application without ports
be able to detect
within a particular period
able to detect which
application without ports this
to detect which of
without ports this type
detect which of its
ports this type of
which of its registered
this type of disconnected
of its registered miners
type of disconnected operation
its registered miners are
and the results are
registered miners are the
the results are shown
miners are the perpetrators
results are shown within
are shown within the
shown within the constraints
within the constraints imposed
the constraints imposed by
constraints imposed by our
imposed by our file
by our file group
our file group representa
a pool can estimate
pool can estimate its
but not to the
can estimate its expected
not to the ex
estimate its expected mining
its expected mining power
expected mining power and
mining power and its
having to take account
power and its actual
to take account of
and its actual mining
take account of the
its actual mining power
account of the actual
actual mining power by
of the actual bandwidth
mining power by the
the actual bandwidth or
power by the rates
actual bandwidth or current
by the rates of
bandwidth or current mix
the rates of partial
or current mix tent
rates of partial proofs
current mix tent of
of partial proofs of
mix tent of automatic
partial proofs of work
tent of automatic reconciliation
proofs of work and
of automatic reconciliation of
of work and full
automatic reconciliation of update
work and full proofs
reconciliation of update conflicts
and full proofs of
full proofs of work
supplied by its miners
a difference above a
difference above a set
above a set confidence
a set confidence interval
the main conclusion we
set confidence interval indicates
on of rpcs at
confidence interval indicates an
main conclusion we draw
interval indicates an attack
of rpcs at runtime
conclusion we draw from
we draw from the
draw from the test
to detect whether a
and avoid having to
detect whether a single
from the test cases
whether a single miner
avoid having to specify
the test cases exhibitthe
having to specify thresholds
a single miner is
test cases exhibitthe graphs
single miner is attacking
to specify thresholds at
miner is attacking it
specify thresholds at the
cases exhibitthe graphs show
thresholds at the other
exhibitthe graphs show how
at the other hand
graphs show how priorities
the pool must use
show how priorities affect
pool must use a
how priorities affect rpcs
must use a similar
priorities affect rpcs and
use a similar technique
affect rpcs and how
rpcs and how prefetching
level caching reduces the
and how prefetching a
caching reduces the delay
how prefetching a prefetch
reduces the delay incurred
prefetching a prefetch penalty
the delay incurred which
a prefetch penalty is
delay incurred which it
prefetch penalty is that
incurred which it should
penalty is that the
which it should switch
is that the implementation
it should switch communication
that the implementation could
should switch communication modes
the implementation could be
comparing the estimated mining
implementation could be im
the estimated mining power
estimated mining power of
an rpc whose results
mining power of the
rpc whose results are
ing changes mfs behaviour
whose results are urgently
power of the attacker
results are urgently required
of the attacker based
are urgently required should
the attacker based on
in all three time
urgently required should be
all three time periods
attacker based on its
required should be aswhen
based on its partial
should be aswhen an
on its partial proof
be aswhen an application
its partial proof of
more time proved to
aswhen an application opens
partial proof of work
time proved to incorporate
proof of work with
proved to incorporate a
of work with the
to incorporate a mechanism
work with the fact
incorporate a mechanism to
an application opens a
a mechanism to inhibit
application opens a file
mechanism to inhibit prefetching
with the fact it
the fact it never
percentage of packets recovered
fact it never supplies
it never supplies a
the is spent on
never supplies a full
is spent on rpcs
supplies a full proof
spent on rpcs to
as has been shown
a full proof of
on rpcs to fetch
has been shown in
full proof of work
rpcs to fetch file
been shown in the
to fetch file attributes
shown in the low
fetch file attributes with
if the attacker has
file attributes with prefetching
the attacker has a
attributes with prefetching enabled
attacker has a small
with prefetching enabled current
has a small mining
prefetching enabled current prefetching
a small mining power
enabled current prefetching algorithm
current prefetching algorithm does
prefetching algorithm does not
algorithm does not correlate
does not correlate file
it will send frequent
not correlate file accesses
will send frequent partial
correlate file accesses with
send frequent partial proofs
file accesses with than
frequent partial proofs of
accesses with than without
partial proofs of work
relatively prime interleaves offer
prime interleaves offer better
interleaves offer better performance
it is possible to
since the time to
but the pool will
is possible to use
the pool will only
possible to use a
the time to receive
to use a signed
time to receive a
use a signed the
to receive a fetch
a signed the highest
pool will only expect
signed the highest priority
will only expect to
only expect to see
attributes request the processes
expect to see a
particularly if the rpc
request the processes which
to see a full
if the rpc contains
the processes which make
see a full proof
the rpc contains outcontent
processes which make them
a full proof of
full proof of work
proof of work at
of work at very
based division of files
but if this were
division of files into
if this were done
work at very low
of files into blocks
at very low frequency
files into blocks as
into blocks as the
two changes or reply
blocks as the basis
changes or reply is
as the basis for
or reply is negligible
the basis for re
it cannot obtain statistically
cannot obtain statistically significant
obtain statistically significant results
the increased time is
statistically significant results that
increased time is due
significant results that would
time is due to
results that would indicate
is due to a
that would indicate an
due to a greater
would indicate an attack
to a greater queue
an attacker can use
but still important rpcs
attacker can use multiple
still important rpcs can
can use multiple small
rpc times at intermediate
important rpcs can ducing
times at intermediate bandwidth
rpcs can ducing client
use multiple small block
multiple small block withholding
small block withholding miners
block withholding miners and
withholding miners and replace
miners and replace them
and replace them frequently
a small miner is
while the lowest levels
a miners whose expected
the lowest levels are
miners whose expected full
lowest levels are useful
whose expected full proof
levels are useful for
expected full proof of
are useful for server
full proof of work
useful for server traffic
proof of work frequency
for server traffic does
of work frequency is
server traffic does not
work frequency is yearly
traffic does not eliminate
does not eliminate the
not eliminate the fundamental
eliminate the fundamental problem
such a miner will
the fundamental problem of
a miner will see
fundamental problem of rpcs
miner will see a
problem of rpcs that
will see a non
of rpcs that can
rpcs that can be
that can be arbitrarily
can be arbitrarily delayed
negligible average daily revenue
such as speculative activities
as speculative activities like
speculative activities like prefetching
activities like prefetching and
like prefetching and transferring
prefetching and transferring archival
and transferring archival data
if the inicontention for
the inicontention for insufficient
inicontention for insufficient bandwidth
tial assumption regarding the
assumption regarding the correct
regarding the correct priority
the correct priority level
correct priority level for
priority level for an
level for an rpc
for an rpc proves
an rpc proves incorrect
a call to the
call to the library
to the library can
the library can be
library can be made
can be made to
be made to assign
made to assign a
if the attacker replaces
the attacker replaces such
attacker replaces such a
replaces such a small
such a small miner
a small miner every
small miner every month
client cache consistency new
cache consistency new priority
he will collect about
will collect about b
when a client fetches
a client fetches a
at the end of
client fetches a file
the end of each
end of each month
the file server grants
file server grants it
the pool must decide
server grants it permission
pool must decide within
grants it permission to
must decide within this
it permission to cache
decide within this month
permission to cache the
within this month whether
to cache the file
this month whether the
cache the file for
month whether the miner
the file for a
whether the miner is
file for a limited
the miner is an
for a limited period
miner is an attacker
and adds it to
and revoke its earnings
adds it to a
it to a list
or just an unlucky
just an unlucky honest
an unlucky honest miner
implementation of clients that
of clients that cache
clients that cache the
since an honest miner
that cache the file
an honest miner of
honest miner of this
miner of this power
of this power is
if the client modifies
this power is unlikely
the client modifies and
power is unlikely to
client modifies and then
is unlikely to find
modifies and then closes
unlikely to find a
and then closes the
to find a full
then closes the file
find a full proof
a full proof of
full proof of work
proof of work within
of work within a
it transmits the new
work within a month
transmits the new contents
the new contents to
new contents to the
contents to the server
which mafs is implemented
mafs is implemented in
is implemented in c
implemented in c on
in c on freebsd
according to the exponential
to the exponential distribution
the client is a
client is a usermakes
a pool that rejects
is a usermakes a
pool that rejects miners
a usermakes a callback
that rejects miners based
usermakes a callback rpc
rejects miners based on
a callback rpc to
miners based on this
callback rpc to any
based on this criterion
rpc to any other
on this criterion would
to any other clients
u trsu t u
any other clients on
this criterion would reject
other clients on the
trsu t u trsu
criterion would reject the
clients on the list
would reject the majority
t u trsu t
reject the majority of
u trsu t utrsut
the majority of its
majority of its honest
of its honest miners
a client level process
request queued request send
client level process that
the alternative of rejecting
level process that stores
queued request send reply
process that stores cached
alternative of rejecting small
request send reply queued
that stores cached files
of rejecting small miners
send reply queued reply
rejecting small miners in
stores cached files in
small miners in general
reply queued reply send
cached files in a
miners in general or
files in a local
in general or distributing
in a local filesystem
general or distributing revenue
or distributing revenue on
distributing revenue on a
revenue on a yearly
the that receives a
on a yearly basis
that receives a callback
a yearly basis contradicts
receives a callback rpc
yearly basis contradicts the
a callback rpc discards
basis contradicts the goal
callback rpc discards its
contradicts the goal of
rpc discards its cached
the goal of pooled
discards its cached copy
goal of pooled mining
its cached copy of
cached copy of the
copy of the file
server also stores its
also stores its copies
m odel and s
stores its copies of
odel and s tandard
its copies of files
and s tandard o
copies of files in
s tandard o peration
of files in a
tandard o peration we
files in a local
o peration we specify
in a local filesystem
peration we specify the
we specify the basic
specify the basic model
the basic model in
basic model in which
model in which participants
in which participants operate
which participants operate in
if an application has
participants operate in section
an application has the
operate in section iii
application has the file
has the file open
the file open when
file open when its
open when its client
when its client re
layered interleaving recovery percentage
interleaving recovery percentage and
recovery percentage and latency
percentage and latency c
proceed to describe how
system operations from applications
to describe how honest
operations from applications are
describe how honest miners
from applications are redirected
how honest miners operate
applications are redirected to
honest miners operate in
layered interleaving and bursty
miners operate in this
are redirected to user
operate in this environment
interleaving and bursty loss
in this environment in
redirected to user level
this environment in sections
and bursty loss thus
to user level ceives
bursty loss thus far
user level ceives the
environment in sections iii
level ceives the callback
loss thus far we
thus far we have
far we have shown
we have shown how
have shown how maelstrom
the file is discarded
shown how maelstrom effectively
file is discarded once
how maelstrom effectively hides
is discarded once it
maelstrom effectively hides loss
discarded once it is
effectively hides loss from
once it is closed
hides loss from tcp
and how the classical
how the classical block
the classical block withholding
classical block withholding attack
when through a kernel
block withholding attack is
through a kernel module
ip for packets dropped
a kernel module at
for packets dropped with
withholding attack is implemented
kernel module at the
attack is implemented with
packets dropped with uniform
module at the client
is implemented with our
dropped with uniform randomness
implemented with our model
with our model in
our model in section
model in section iii
we examine the performance
examine the performance of
the performance of the
performance of the layered
of the layered interleaving
fetch prefetch metadata store
the layered interleaving algorithm
prefetch metadata store fetch
metadata store fetch file
model the system is
store fetch file attributes
the system is comprised
system is comprised of
showing how different parameterizations
is comprised of the
how different parameterizations handle
comprised of the bitcoin
different parameterizations handle bursty
of the bitcoin network
parameterizations handle bursty loss
the bitcoin network and
handle bursty loss patterns
bitcoin network and nodes
pull file update fetch
network and nodes with
file update fetch file
and nodes with unique
update fetch file data
nodes with unique ids
we use a loss
use a loss model
rpc times at high
a loss model where
times at high bandwidth
loss model where packets
and progresses in steps
model where packets are
where packets are dropped
packets are dropped in
are dropped in bursts
dropped in bursts of
a node i generates
prefetch file data lock
node i generates tasks
file data lock a
i generates tasks which
data lock a file
in bursts of fixed
generates tasks which are
bursts of fixed length
tasks which are associated
which are associated with
are associated with its
associated with its id
with its id i
allowing us to study
most metadata rpcs store
us to study the
metadata rpcs store file
to study the impact
rpcs store file data
study the impact of
a node can work
the impact of burst
node can work on
impact of burst length
can work on a
of burst length on
unlink file such as
work on a task
file such as deleting
on a task for
such as deleting a
a task for the
as deleting a modified
task for the duration
burst length on performance
deleting a modified file
for the duration of
the duration of a
duration of a step
the link has a
such optimisations can be
link has a one
optimisations can be effective
can be effective at
the result of this
be effective at low
result of this work
effective at low bandwidth
of this work is
this work is a
work is a set
is a set of
when there is a
a set of partial
there is a natural
set of partial proofs
is a natural delay
percentage of packets recovered
of partial proofs of
partial proofs of work
proofs of work and
but at high bandwidth
of work and a
work and a set
and a set of
a set of full
set of full proofs
an artificial delay in
of full proofs of
artificial delay in writing
full proofs of work
delay in writing back
in writing back updates
writing back updates introduces
back updates introduces inconsistencies
updates introduces inconsistencies between
reed solomon layered interleaving
introduces inconsistencies between the
inconsistencies between the client
the number of proofs
between the client and
number of proofs in
the client and the
of proofs in each
client and the file
proofs in each set
and the file server
in each set has
each set has a
set has a poisson
has a poisson distribution
this can be acceptable
can be acceptable at
be acceptable at low
acceptable at low bandwidths
partial proofs with a
proofs with a large
with a large mean
a large mean and
large mean and full
when the user may
mean and full proofs
the user may table
and full proofs with
full proofs with a
proofs with a small
with a small mean
nodes that work on
priorities for mafs remote
that work on tasks
for mafs remote procedure
work on tasks are
mafs remote procedure calls
on tasks are called
tasks are called a
are called a miners
be grateful to be
grateful to be able
miners have identical power
to be able to
be able to use
able to use the
to use the file
use the file system
and hence identical probabilities
the file system at
hence identical probabilities to
file system at all
identical probabilities to generate
probabilities to generate proofs
to generate proofs of
generate proofs of work
but should be avoided
should be avoided when
be avoided when bandwidth
avoided when bandwidth is
the bitcoin network pays
when bandwidth is unconstrained
bitcoin network pays for
network pays for full
pays for full proofs
for full proofs of
full proofs of work
to acquire this payoff
acquire this payoff an
this payoff an entity
payoff an entity publishes
an entity publishes a
entity publishes a task
mafs avoids the need
publishes a task task
avoids the need for
a task task and
the need for modes
task task and its
need for modes by
task and its corresponding
for modes by using
and its corresponding proof
modes by using asynchronous
its corresponding proof of
by using asynchronous remote
corresponding proof of work
using asynchronous remote procedure
proof of work to
asynchronous remote procedure calls
of work to the
remote procedure calls between
work to the network
procedure calls between a
calls between a client
between a client and
a client and the
client and the file
the payoff goes to
and the file server
payoff goes to the
the file server writeback
goes to the id
file server writeback at
to the id associated
server writeback at all
the id associated with
writeback at all bandwidth
id associated with task
at all bandwidth levels
the bitcoin protocol normalizes
and incorporates a new
bitcoin protocol normalizes revenue
incorporates a new upare
protocol normalizes revenue such
a new upare divided
solomon versus layered interleaving
new upare divided into
normalizes revenue such that
upare divided into several
versus layered interleaving latency
divided into several types
revenue such that the
into several types depending
layered interleaving latency of
several types depending on
such that the average
types depending on their
that the average total
depending on their function
the average total revenue
average total revenue distributed
total revenue distributed in
revenue distributed in each
ms and a loss
rpcs date propagation algorithm
and a loss rate
distributed in each step
date propagation algorithm to
in each step is
a loss rate of
each step is a
propagation algorithm to reduce
step is a constant
algorithm to reduce the
is a constant throughout
to reduce the possibility
a constant throughout the
reduce the possibility of
constant throughout the execution
the possibility of inconsisto
throughout the execution of
possibility of inconsisto fetch
the execution of the
of inconsisto fetch and
execution of the system
inconsisto fetch and store
fetch and store data
and store data are
store data are self
any node can transact
node can transact bitcoins
can transact bitcoins to
transact bitcoins to another
bitcoins to another node
to another node by
another node by issuing
node by issuing a
by issuing a bitcoin
issuing a bitcoin transaction
where it is varied
nodes that generate tasks
that generate tasks but
generate tasks but outsource
tasks but outsource the
but outsource the work
as new operations are
outsource the work are
new operations are added
the work are called
operations are added to
work are called pools
are added to the
added to the tail
to the tail tions
mbps flow of udp
the tail tions include
flow of udp packets
tail tions include fetching
of udp packets is
pools send tasks to
tions include fetching and
send tasks to miners
udp packets is sent
include fetching and setting
tasks to miners over
fetching and setting file
to miners over the
and setting file attributes
miners over the network
packets is sent over
is sent over it
and directory of the
the miners receive the
directory of the log
miners receive the tasks
the client flushes operations
client flushes operations serially
we show that our
flushes operations serially from
show that our observation
operations serially from the
and send the partial
serially from the head
that our observation in
from the head of
our observation in section
the head of operations
observation in section iv
head of operations such
send the partial and
of operations such as
the partial and full
operations such as creating
partial and full proofs
such as creating and
and full proofs of
as creating and unlinking
full proofs of work
creating and unlinking files
proofs of work to
e is correct for
of work to the
is correct for high
work to the pool
correct for high loss
control rpcs the log
for high loss rates
high loss rates if
loss rates if the
apart from working on
rates if the interleaves
from working on tasks
if the interleaves are
the interleaves are relatively
interleaves are relatively prime
server traffic consists of
traffic consists of a
consists of a variety
performance improves substantially when
of a variety of
improves substantially when loss
a variety of foreground
substantially when loss rates
variety of foreground include
when loss rates are
of foreground include locking
loss rates are high
foreground include locking files
rates are high and
include locking files and
are high and losses
locking files and the
high and losses are
and receipt are instantaneous
and losses are bursty
files and the server
and the server s
the server s callback
server s callback to
we assume that the
s callback to invalidate
the graph plots the
callback to invalidate a
assume that the number
to invalidate a rpcs
graph plots the percentage
invalidate a rpcs for
that the number of
a rpcs for control
plots the percentage of
rpcs for control operations
the number of miners
for control operations and
the percentage of lost
control operations and fetching
percentage of lost packets
operations and fetching file
number of miners is
of lost packets successfully
and fetching file data
lost packets successfully recovered
of miners is large
packets successfully recovered on
miners is large enough
successfully recovered on the
is large enough such
recovered on the y
and a stream client
large enough such that
a stream client s
enough such that mining
stream client s cached
such that mining power
client s cached copy
that mining power can
s cached copy of
axis against an xaxis
mining power can be
cached copy of a
power can be split
copy of a file
can be split arbitrarily
against an xaxis of
be split arbitrarily without
an xaxis of loss
split arbitrarily without resolution
xaxis of loss rates
arbitrarily without resolution constraints
of loss rates on
of background rpcs for
loss rates on a
background rpcs for logged
rates on a log
rpcs for logged operations
on a log scale
denote the number of
when bandwidth is high
the maelstrom configuration used
the number of pools
maelstrom configuration used is
number of pools with
configuration used is r
of pools with p
replayed logged operations complete
logged operations complete quickly
the total number of
with little extra delay
total number of mining
number of mining power
of mining power in
mining power in the
when bandwidth is low
power in the system
in the system with
the system with m
system with m and
logged operations are de
with m and the
m and the miners
and the miners participating
the miners participating in
communication adaptation layed in
miners participating in pool
adaptation layed in proportion
participating in pool i
layed in proportion to
in proportion to the
proportion to the foreground
to the foreground rpc
the foreground rpc traffic
foreground rpc traffic and
rpc traffic and the
traffic and the availto
and the availto reduce
the availto reduce its
availto reduce its network
reduce its network communication
its network communication when
network communication when bandwidth
we use a quasistatic
communication when bandwidth is
use a quasistatic analysis
when bandwidth is low
a quasistatic analysis where
quasistatic analysis where miner
analysis where miner participation
where miner participation in
miner participation in a
participation in a pool
in a pool does
a pool does not
pool does not change
a mobile file system
does not change over
mobile file system client
not change over time
file system client can
system client can automatically
client can automatically adapt
can automatically adapt its
automatically adapt its communication
adapt its communication strategy
its communication strategy to
communication strategy to the
solo mining a solo
strategy to the available
mining a solo miner
to the available bandwidth
a solo miner is
solo miner is a
miner is a node
is a node that
a node that generates
node that generates its
that generates its own
generates its own tasks
in every step it
every step it generates
step it generates a
it generates a task
rpc priorities cations transfer
priorities cations transfer a
cations transfer a large
transfer a large volume
works on it for
a large volume of
on it for the
large volume of data
it for the duration
volume of data that
for the duration of
of data that the
the duration of the
data that the user
we show the ability
that the user is
duration of the step
the user is unlikely
show the ability of
user is unlikely to
of the step and
is unlikely to require
the step and if
the ability of layered
unlikely to require immediately
ability of layered interleaving
step and if it
of layered interleaving to
and if it finds
layered interleaving to provide
if it finds a
consuming bandwidth that can
it finds a full
interleaving to provide gracefully
bandwidth that can be
to provide gracefully degrading
finds a full proof
provide gracefully degrading performance
a full proof of
gracefully degrading performance in
that can be used
full proof of work
can be used mafs
degrading performance in the
be used mafs uses
performance in the face
used mafs uses priorities
in the face of
mafs uses priorities to
it publishes this proof
uses priorities to reduce
publishes this proof of
the face of bursty
this proof of work
face of bursty loss
proof of work to
priorities to reduce contention
of work to earn
to reduce contention between
work to earn the
reduce contention between foreground
to earn the payoff
contention between foreground for
between foreground for important
foreground for important tasks
we plot the percentage
plot the percentage of
the percentage of lost
pools a pool is
percentage of lost packets
a pool is a
of lost packets successfully
pool is a node
lost packets successfully recovered
is a node that
consider an application that
packets successfully recovered against
an application that activities
a node that serves
application that activities and
successfully recovered against the
that activities and deferrable
node that serves as
activities and deferrable background
recovered against the length
and deferrable background activities
that serves as a
against the length of
serves as a coordinator
the length of loss
as a coordinator and
length of loss bursts
a coordinator and multiple
adaptive rpc fetches images
coordinator and multiple miners
rpc fetches images from
and multiple miners can
of loss bursts for
multiple miners can register
fetches images from a
miners can register to
images from a file
can register to a
from a file server
register to a pool
loss bursts for two
to a pool and
bursts for two different
a pool and work
for two different sets
pool and work for
processes each in turn
two different sets of
and work for it
different sets of interleaves
and in the bottom
preferentially allocates bandwidth to
in the bottom graph
allocates bandwidth to foreground
the bottom graph we
in every step it
bottom graph we plot
bandwidth to foreground rpcs
graph we plot the
every step it generates
we plot the average
step it generates a
plot the average latency
unlike plays the resulting
it generates a task
the average latency at
generates a task for
average latency at which
a task for each
latency at which the
task for each registered
plays the resulting image
for each registered miner
at which the packets
each registered miner and
which the packets were
registered miner and sends
the packets were recovered
miner and sends it
and writes it to
and sends it over
writes it to the
sends it over the
it to the server
it over the network
recovery latency is defined
latency is defined as
is defined as the
if the user little
defined as the difference
each miner receives its
the user little work
miner receives its task
as the difference between
receives its task and
the difference between the
its task and works
difference between the eventual
task and works on
between the eventual delivery
and works on it
the eventual delivery time
works on it for
eventual delivery time of
on it for the
delivery time of the
it for the duration
time of the recovered
for the duration of
of the recovered packet
the duration of the
the recovered packet and
duration of the step
which assigns a lower
recovered packet and the
assigns a lower priority
packet and the oneway
a lower priority to
and the oneway latency
lower priority to writeback
at the end of
priority to writeback in
the end of the
to writeback in wants
the oneway latency of
end of the step
oneway latency of the
writeback in wants to
latency of the link
in wants to see
wants to see the
to see the processed
the miner sends the
see the processed images
miner sends the pool
sends the pool the
we confirmed that the
the pool the full
confirmed that the emulab
pool the full and
that the emulab link
the full and the
the emulab link had
full and the partial
emulab link had almost
and the partial proofs
link had almost no
one else wants to
had almost no jitter
else wants to im
almost no jitter on
the partial proofs of
no jitter on correctly
partial proofs of work
jitter on correctly delivered
proofs of work it
on correctly delivered packets
of work it has
work it has found
mafs has a finer
the pool receives the
way latency an accurate
pool receives the proofs
latency an accurate estimate
receives the proofs of
an accurate estimate of
the proofs of work
accurate estimate of expected
proofs of work of
grained differentiation mediately read
estimate of expected lossless
differentiation mediately read them
of work of all
of expected lossless delivery
work of all its
expected lossless delivery time
of all its miners
writing the output back
the output back will
output back will interfere
back will interfere with
registers the partial proofs
will interfere with between
the partial proofs of
interfere with between rpcs
partial proofs of work
proofs of work and
of work and publishes
work and publishes the
increasing the interleaves results
and uses priorities at
and publishes the full
the interleaves results in
publishes the full proofs
uses priorities at all
interleaves results in much
priorities at all bandwidths
results in much higher
in much higher recovery
much higher recovery percentages
it calculates its overall
higher recovery percentages at
calculates its overall revenue
recovery percentages at large
this alfetching the next
percentages at large burst
alfetching the next image
at large burst sizes
and proceeds to distribute
proceeds to distribute it
to distribute it among
and slow down the
distribute it among its
slow down the application
but comes at the
it among its miners
comes at the cost
at the cost of
the cost of higher
cost of higher recovery
lows control over bandwidth
of higher recovery latency
each miner receives revenue
control over bandwidth allocation
miner receives revenue proportional
over bandwidth allocation at
receives revenue proportional to
bandwidth allocation at the
revenue proportional to its
allocation at the level
proportional to its success
at the level of
to its success in
the level of individinterference
its success in the
level of individinterference due
success in the current
of individinterference due to
in the current step
individinterference due to write
due to write traffic
to write traffic is
write traffic is often
traffic is often solved
namely the ratio of
is often solved by
the ratio of its
often solved by writing
ratio of its partial
solved by writing ual
of its partial proofs
by writing ual rpcs
its partial proofs of
partial proofs of work
proofs of work out
of work out of
work out of all
without requiring that an
out of all partial
requiring that an mafs
of all partial proofs
that an mafs client
all partial proofs of
an mafs client is
partial proofs of work
mafs client is aware
proofs of work the
client is aware of
of work the pool
is aware of back
work the pool received
set of interleaves catches
aware of back updates
of interleaves catches almost
of back updates asynchronously
interleaves catches almost all
catches almost all packets
we assume that pools
almost all packets in
assume that pools do
all packets in an
that pools do not
packets in an extended
pools do not collect
in an extended burst
do not collect fees
an extended burst of
not collect fees of
the application in our
collect fees of the
application in our example
fees of the revenue
in our example the
our example the precise
example the precise bandwidth
packets at an average
pool fees and their
at an average latency
fees and their implications
an average latency of
and their implications on
can start reading another
their implications on our
average latency of around
implications on our analysis
start reading another image
on our analysis are
reading another image without
our analysis are discussed
another image without waiting
analysis are discussed in
image without waiting for
are discussed in section
without waiting for the
discussed in section ix
waiting for the previwhen
for the previwhen choosing
the previwhen choosing priorities
while repairing all random
repairing all random singleton
all random singleton losses
random singleton losses within
automatic assignment and fine
block withholding miner a
assignment and fine ous
withholding miner a miner
and fine ous output
miner a miner registered
fine ous output to
a miner registered at
ous output to be
miner registered at a
output to be sent
registered at a pool
to be sent to
at a pool can
be sent to the
a pool can perform
sent to the file
pool can perform the
to the file server
can perform the classical
the graphs also show
perform the classical block
graphs also show recovery
the classical block withholding
also show recovery latency
asynchronous writeback granularity are
show recovery latency rising
writeback granularity are preferable
classical block withholding attack
recovery latency rising gracefully
latency rising gracefully with
rising gracefully with the
to avoid the need
gracefully with the increase
avoid the need for
an attacker miner operates
the need for user
with the increase in
need for user intervenallows
attacker miner operates as
the increase in loss
miner operates as if
increase in loss burst
operates as if it
in loss burst length
as if it worked
for user intervenallows i
if it worked for
it worked for the
worked for the pool
the longer the burst
o and cpu processing
and cpu processing to
cpu processing to be
processing to be overlapped
it receives its tasks
the longer it takes
receives its tasks and
longer it takes to
its tasks and works
it takes to recover
tasks and works on
takes to recover the
and works on them
to recover the lost
request queued request send
recover the lost packets
tion and provide the
queued request send reply
and provide the maximum
request send reply queued
only at the end
send reply queued reply
provide the maximum degree
the maelstrom configuration used
at the end of
maelstrom configuration used is
the maximum degree of
reply queued reply send
maximum degree of differentiation
configuration used is r
degree of differentiation among
the end of each
of differentiation among ecution
end of each round
differentiation among ecution time
of each round it
among ecution time and
each round it sends
ecution time and utilising
round it sends only
time and utilising bandwidth
it sends only its
and utilising bandwidth more
sends only its partial
utilising bandwidth more efficiently
only its partial proofs
its partial proofs of
partial proofs of work
e dd e dd
dd e dd f
and omits full proofs
e dd f edd
omits full proofs of
dd f edd f
full proofs of work
f edd f g
proofs of work if
edd f g fg
of work if it
scheduling rpcs based on
work if it had
rpcs based on priorities
if it had found
f g fg e
based on priorities is
g fg e ed
on priorities is only
fg e ed e
priorities is only ever
e ed e e
it had found any
ed e e d
e e d f
e d f eed
if bandwidth is low
d f eed f
the pool registers the
f eed f g
pool registers the miner
eed f g fg
registers the miner s
f g fg e
the miner s partial
g fg e d
miner s partial proofs
fg e d e
contention arises when files
e d e d
d e d f
arises when files are
when files are being
but cannot distinguish between
files are being effective
cannot distinguish between miners
are being effective if
distinguish between miners running
being effective if concurrent
between miners running honestly
effective if concurrent rpcs
miners running honestly and
if concurrent rpcs usually
running honestly and block
concurrent rpcs usually end
honestly and block withholding
rpcs usually end up
and block withholding miners
usually end up with
end up with different
up with different prifetched
with different prifetched at
different prifetched at the
the implications are that
prifetched at the same
implications are that a
at the same time
are that a miner
the same time as
that a miner that
same time as updates
a miner that engages
time as updates are
miner that engages in
as updates are written
that engages in block
updates are written back
engages in block withholding
in block withholding does
block withholding does not
withholding does not contribute
does not contribute to
not contribute to the
contribute to the pool
to the pool s
the pool s overall
pool s overall mining
s overall mining power
but processes are too
processes are too coarse
bcq pcb c bq
but still shares the
pcb c bq pcb
grained for this purpose
c bq pcb cbqpcb
still shares the pool
bq pcb cbqpcb n
shares the pool s
pcb cbqpcb n n
the pool s revenue
we show histograms of
tention can be mitigated
pool s revenue according
can be mitigated by
s revenue according to
be mitigated by prioritising
revenue according to its
mitigated by prioritising file
according to its sent
by prioritising file fetch
to its sent partial
prioritising file fetch rpcs
its sent partial proofs
file fetch rpcs above
sent partial proofs of
fetch rpcs above file
partial proofs of work
cbqpcb n n on
show histograms of recovery
n n on n
histograms of recovery latencies
n on n c
based priorities provide some
on n c bc
priorities provide some more
n c bc bonn
provide some more detail
c bc bonn c
of recovery latencies for
to reason about a
recovery latencies for the
bc bonn c bc
latencies for the two
bonn c bc b
for the two interleave
but the imporwriteback rpcs
the two interleave configurations
c bc b cbcb
two interleave configurations under
the imporwriteback rpcs to
interleave configurations under different
imporwriteback rpcs to ensure
configurations under different burst
rpcs to ensure that
under different burst lengths
reason about a pool
to ensure that they
about a pool s
ensure that they will
a pool s efficiency
that they will be
pool s efficiency we
they will be preferentially
s efficiency we define
will be preferentially allo
efficiency we define its
the histograms confirm the
we define its per
histograms confirm the trends
confirm the trends described
the trends described above
tance of a file
of a file can
miner revenue as follows
a file can be
packet recoveries take longer
c bc b cbcb
recoveries take longer from
file can be hard
take longer from left
can be hard to
longer from left to
be hard to determine
from left to right
hard to determine automatically
left to right as
to right as we
right as we increase
as we increase loss
we increase loss burst
increase loss burst length
and from top to
from top to bottom
top to bottom as
the revenue density of
to bottom as we
bottom as we increase
revenue density of a
as we increase the
we increase the interleave
c bc b cbcb
increase the interleave values
density of a pool
files can be too
of a pool is
can be too numerous
a pool is the
be too numerous for
pool is the ratio
too numerous for the
is the ratio between
numerous for the user
the ratio between the
for the user to
c bc b cbcb
ratio between the average
the user to manually
illustrates the difference between
user to manually assign
the difference between a
to manually assign priin
between the average revenue
difference between a traditional
manually assign priin this
between a traditional fec
assign priin this section
the average revenue a
a traditional fec code
average revenue a pool
traditional fec code and
revenue a pool member
fec code and layered
a pool member earns
code and layered interleaving
we assess the effectiveness
pool member earns and
assess the effectiveness of
and layered interleaving by
the effectiveness of asynchronous
layered interleaving by plotting
effectiveness of asynchronous orities
interleaving by plotting a
member earns and the
c b cb a
earns and the average
b cb a a
and the average revenue
cb a a k
the average revenue it
a a k k
rpcs are more numerous
average revenue it would
a k k j
revenue it would have
k k j jk
it would have earned
would have earned as
have earned as a
but priorities can be
earned as a solo
priorities can be autowriteback
as a solo miner
can be autowriteback and
be autowriteback and rpc
autowriteback and rpc priorities
and rpc priorities in
c bc b cbcb
rpc priorities in mafs
the revenue density of
priorities in mafs under
bc b cbcb kk
in mafs under different
revenue density of a
b cbcb kk j
mafs under different levels
cbcb kk j m
density of a solo
kk j m lkjj
under different levels matically
j m lkjj ml
of a solo miner
m lkjj ml ml
different levels matically assigned
lkjj ml ml c
levels matically assigned to
ml ml c b
matically assigned to them
ml c b c
assigned to them according
c b c b
and that of a
b c b cb
to them according to
that of a miner
them according to the
of a miner working
according to the operation
a miner working with
to the operation the
miner working with an
the operation the rpc
working with an unattacked
operation the rpc of
with an unattacked pool
the rpc of bandwidth
an unattacked pool are
rpc of bandwidth availability
unattacked pool are one
c b cb kj
b cb kj ih
cb kj ih i
kj ih i h
ih i h ih
i h ih j
if a pool is
a pool is attacked
pool is attacked with
is attacked with block
we examine the degree
attacked with block withholding
examine the degree corresponds
the degree corresponds to
its revenue density decreases
as shown in table
continuous analysis because our
analysis because our analysis
because our analysis will
our analysis will be
analysis will be of
or rpcs to which
will be of the
rpcs to which a
be of the average
to which a file
of the average revenue
which a file system
a file system client
file system client that
system client that avoids
client that avoids switching
we will consider proofs
that avoids switching modes
will consider proofs of
avoids switching modes in
consider proofs of work
switching modes in re
c bc b c
bc b c bc
b c bc b
c bc b cbcb
both full and partial
that the user has
bc b cbcb rpc
the user has to
b cbcb rpc times
user has to wait
cbcb rpc times at
has to wait for
rpc times at low
as continuous deterministic sizes
times at low bandwidth
according to their probability
request queued request send
work on a task
queued request send reply
on a task therefore
request send reply queued
or sponse to bandwidth
send reply queued reply
a task therefore results
reply queued reply send
sponse to bandwidth changes
task therefore results in
queued reply send total
therefore results in a
reply send total time
to bandwidth changes is
results in a deterministic
bandwidth changes is able
in a deterministic fraction
changes is able to
a deterministic fraction of
is able to adapt
deterministic fraction of proof
able to adapt to
fraction of proof of
to adapt to both
of proof of work
adapt to both insufficient
to both insufficient rpcs
both insufficient rpcs whose
insufficient rpcs whose results
rpcs whose results can
whose results can be
results can be delayed
t he p ool
he p ool g
p ool g ame
ool g ame a
such as writing back
as writing back data
writing back data bandwidth
the pool block withholding
pool block withholding attack
and conditions under which
block withholding attack just
conditions under which bandwidth
withholding attack just as
under which bandwidth is
attack just as a
which bandwidth is plentiful
just as a miner
as a miner can
a miner can perform
miner can perform block
can perform block withholding
perform block withholding on
block withholding on a
withholding on a pool
on a pool j
prefetching is an example
is an example of
an example of speculative
a pool i can
example of speculative communication
pool i can use
i can use some
can use some of
use some of its
some of its mining
of its mining power
its mining power to
priority rpc whose results
mining power to infiltrate
rpc whose results can
power to infiltrate a
whose results can improve
to infiltrate a pool
results can improve performance
infiltrate a pool j
can improve performance if
a pool j and
improve performance if bandwidth
pool j and perform
performance if bandwidth is
j and perform a
if bandwidth is high
and perform a block
perform a block withholding
a block withholding attack
block withholding attack on
withholding attack on j
denote the amount of
the amount of such
asynchronous writeback but can
amount of such infiltrating
writeback but can be
of such infiltrating mining
but can be safely
such infiltrating mining power
can be safely omitted
infiltrating mining power at
be safely omitted if
mining power at step
safely omitted if bandwidth
rpc traffic with varying
omitted if bandwidth is
power at step t
traffic with varying bandwidth
if bandwidth is low
at step t by
step t by xi
mafs asynchronous writeback is
asynchronous writeback is based
writeback is based on
is based on similar
based on similar mechanisms
on similar mechanisms the
miners working for pool
similar mechanisms the initial
working for pool i
mechanisms the initial priority
the initial priority is
initial priority is never
priority is never modified
either mining honestly or
mining honestly or used
honestly or used for
or used for infiltrating
but the file server
used for infiltrating pool
the file server somefound
show the time spent
file server somefound in
for infiltrating pool j
server somefound in many
the time spent on
somefound in many mobile
time spent on rpcs
in many mobile file
spent on rpcs during
many mobile file systems
on rpcs during an
are loyal to pool
rpcs during an execution
loyal to pool i
during an execution of
an execution of the
execution of the simultaneous
of the simultaneous writeback
at the end of
the simultaneous writeback test
the end of a
simultaneous writeback test from
end of a round
writeback test from section
pool i aggregates its
i aggregates its revenue
aggregates its revenue from
its revenue from mining
revenue from mining in
from mining in the
rather than making times
mining in the current
than making times requests
in the current round
making times requests an
the current round and
with the bandwidth varying
times requests an increase
the bandwidth varying according
requests an increase in
bandwidth varying according to
current round and from
an increase in the
round and from its
varying according to the
and from its infiltration
increase in the priority
from its infiltration in
according to the curve
its infiltration in the
to the curve in
infiltration in the previous
in the priority of
in the previous round
the priority of an
priority of an rpc
of an rpc to
an rpc to transmit
it distributes the revenue
rpc to transmit an
distributes the revenue evenly
to transmit an rpc
the revenue evenly among
transmit an rpc when
revenue evenly among all
rpcs are labelled as
evenly among all its
are labelled as follows
among all its loyal
an rpc when an
all its loyal miners
rpc when an application
its loyal miners according
when an application performs
loyal miners according to
an application performs a
miners according to their
application performs a metadata
according to their partial
performs a metadata update
to their partial proofs
a metadata update or
their partial proofs of
metadata update or file
partial proofs of work
update or file data
the pool s miners
pool s miners are
s miners are oblivious
miners are oblivious to
the operation is logged
are oblivious to their
operation is logged and
oblivious to their role
is logged and replayed
to their role and
logged and replayed to
their role and they
and replayed to the
role and they operate
replayed to the file
and they operate as
to the file server
they operate as regular
the file server after
operate as regular honest
file server after a
as regular honest miners
server after a delay
demand fetch to raise
fetch to raise priority
this scheme reduces bandwidth
to raise priority of
scheme reduces bandwidth utilisation
raise priority of a
reduces bandwidth utilisation because
priority of a prefetch
bandwidth utilisation because some
of a prefetch rpc
revenue convergence note that
utilisation because some logged
convergence note that pool
because some logged operations
note that pool j
some logged operations may
that pool j sends
logged operations may be
pool j sends its
operations may be superceded
j sends its revenue
may be superceded by
sends its revenue to
be superceded by later
its revenue to infiltrators
superceded by later ones
revenue to infiltrators from
the time spent on
to infiltrators from pool
time spent on rpcs
infiltrators from pool i
spent on rpcs is
from pool i at
on rpcs is shown
pool i at the
rpcs is shown with
i at the end
is shown with prefetching
at the end of
shown with prefetching enabled
the end of the
end of the step
and this revenue is
this revenue is calculated
revenue is calculated in
is calculated in pool
calculated in pool i
in pool i at
pool i at the
i at the beginning
at the beginning of
the beginning of the
beginning of the subsequent
of the subsequent step
if there is a
there is a chain
is a chain of
a chain of pools
chain of pools of
of pools of length
note that rpc interactions
that rpc interactions can
where each pool infiltrates
rpc interactions can overlap
each pool infiltrates the
interactions can overlap so
pool infiltrates the next
can overlap so the
overlap so the quantities
so the quantities for
the quantities for different
the pool revenue will
quantities for different rpc
pool revenue will not
for different rpc types
revenue will not be
different rpc types are
will not be static
rpc types are not
types are not additive
since the revenue from
for some rpc types
the revenue from infiltration
revenue from infiltration takes
from infiltration takes one
infiltration takes one step
takes one step to
the time spent on
one step to take
time spent on particular
step to take each
spent on particular activities
to take each hop
on particular activities is
particular activities is negligible
activities is negligible in
is negligible in proportion
negligible in proportion to
in proportion to the
proportion to the overall
to the overall time
max is the longest
is the longest chain
the longest chain in
longest chain in the
chain in the system
latency histograms for i
the revenue stabilizes after
attribute requests are small
requests are small and
are small and have
small and have a
and have a very
have a very low
if there are loops
a very low transmission
there are loops in
very low transmission time
are loops in the
low transmission time relative
loops in the infiltration
transmission time relative to
in the infiltration graph
time relative to their
relative to their queueing
to their queueing delays
the system will converge
system will converge to
will converge to a
such users happen to
converge to a certain
users happen to be
to a certain revenue
happen to be working
to be working on
be working on the
working on the same
on the same element
as stated in the
the same element of
stated in the following
same element of the
in the following lemma
element of the design
it is clear that
is clear that satisfying
clear that satisfying a
that satisfying a request
satisfying a request from
a request from stale
request from stale data
whether in from the
in from the cache
if infiltration rates are
infiltration rates are constant
or on a server
on a server that
a server that has
server that has yet
the pool revenues converge
that has yet to
has yet to see
yet to see a
to see a delayed
see a delayed writeback
denote the revenue density
would be visible to
the revenue density of
be visible to the
revenue density of pool
visible to the user
density of pool i
to the user and
of pool i at
the user and costly
pool i at the
i at the end
at the end of
the end of step
end of step t
of step t by
step t by ri
strong cache consistency is
cache consistency is certainly
consistency is certainly achievable
is certainly achievable in
certainly achievable in distributed
achievable in distributed file
in distributed file systems
and define the revenue
define the revenue density
the revenue density vector
revenue density vector r
but must be implemented
must be implemented with
be implemented with synchronous
implemented with synchronous rpcs
and requires either readers
requires either readers or
either readers or writers
readers or writers to
or writers to incur
writers to incur a
to incur a delay
incur a delay to
a delay to ensure
delay to ensure that
to ensure that only
ensure that only the
that only the latest
only the latest version
the latest version of
latest version of a
version of a file
of a file is
a file is accessed
as we have noted
we have noted in
have noted in section
p in every round
sending file updates to
file updates to a
updates to a server
pool i uses its
to a server asynchronously
i uses its mining
a server asynchronously has
uses its mining power
server asynchronously has two
its mining power of
asynchronously has two potential
mining power of m
has two potential benefits
writes execution time speedup
the process modifying the
process modifying the file
modifying the file need
the file need not
file need not wait
j used for direct
need not wait for
used for direct mining
not wait for the
for direct mining p
wait for the write
for the write to
the write to complete
if the update is
and shares it among
the update is delayed
shares it among its
update is delayed in
it among its m
is delayed in the
delayed in the log
in the log for
the log for some
execution time speedup execution
log for some interval
time speedup execution time
for some interval before
speedup execution time speedup
some interval before being
execution time speedup execution
interval before being written
time speedup execution time
before being written back
speedup execution time speedup
execution time speedup no
time speedup no priorities
it may be superseded
may be superseded by
be superseded by a
superseded by a later
by a later update
all sums are over
sums are over the
and therefore can be
are over the range
therefore can be omitted
can be omitted entirely
latency histograms for i
these benefits come at
benefits come at the
come at the cost
at the cost of
the cost of reduced
cost of reduced cache
of reduced cache consistency
since the version of
the version of the
version of the file
of the file stored
the file stored at
file stored at the
stored at the server
at the server is
denote the direct mining
the server is inconsistent
the direct mining revenue
server is inconsistent during
direct mining revenue density
is inconsistent during the
mining revenue density of
inconsistent during the time
revenue density of each
during the time that
density of each pool
the time that the
time that the update
that the update remains
the update remains queued
update remains queued for
remains queued for transmission
which is a constant
is a constant factor
even though asynchronous writes
though asynchronous writes in
asynchronous writes in mfs
writes in mfs are
in mfs are not
mfs are not delayed
are not delayed to
not delayed to aggregate
delayed to aggregate updates
a burst of updates
burst of updates to
of updates to a
updates to a sequence
to a sequence of
a sequence of files
sequence of files may
of files may flood
files may flood the
may flood the link
flood the link to
the link to the
link to the server
to the server and
the server and increase
server and increase the
moving average of recovery
and increase the delay
average of recovery latencies
increase the delay before
of recovery latencies for
the delay before updates
recovery latencies for both
delay before updates towards
latencies for both codes
before updates towards the
updates towards the end
towards the end of
the end of the
end of the burst
the channel is configured
of the burst are
channel is configured to
the burst are committed
is configured to lose
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
any other client accessing
singleton packets randomly at
other client accessing the
packets randomly at a
client accessing the file
randomly at a loss
at a loss rate
a loss rate of
cache consistency will access
consistency will access the
will access the stale
access the stale version
p the revenue of
rather than one which
the revenue of pool
than one which incorporates
revenue of pool i
and additionally lose long
of pool i in
additionally lose long bursts
one which incorporates the
pool i in step
which incorporates the pending
lose long bursts of
incorporates the pending update
i in step t
in step t taken
step t taken through
t taken through infiltration
taken through infiltration from
we therefore refer to
through infiltration from pool
therefore refer to this
packets at occasional intervals
infiltration from pool j
refer to this as
from pool j s
to this as a
pool j s revenue
this as a hidden
j s revenue in
both codes are configured
s revenue in step
as a hidden upstudies
codes are configured with
a hidden upstudies of
revenue in step t
hidden upstudies of distributed
are configured with r
upstudies of distributed file
of distributed file systems
distributed file systems have
file systems have largely
systems have largely concluded
have largely concluded that
largely concluded that file
concluded that file date
and the cache consistency
the cache consistency problem
cache consistency problem caused
consistency problem caused by
problem caused by asynchronous
caused by asynchronous sharing
and recover all lost
by asynchronous sharing is
recover all lost packets
asynchronous sharing is infrequent
all lost packets reedsolomon
pool i distributes this
lost packets reedsolomon uses
sharing is infrequent in
packets reedsolomon uses an
is infrequent in general
reedsolomon uses an interleave
i distributes this revenue
uses an interleave of
distributes this revenue among
this revenue among its
revenue among its mi
and layered interleaving uses
layered interleaving uses interleaves
i members loyal and
interleaving uses interleaves of
members loyal and infiltrators
define the p p
the p p infiltration
p p infiltration matrix
p infiltration matrix by
infiltration matrix by its
matrix by its i
writes as the hidden
as the hidden update
the hidden update problem
and consequently both have
consequently both have a
both have a maximum
have a maximum tolerable
we have identified a
a maximum tolerable burst
have identified a class
maximum tolerable burst length
identified a class of
tolerable burst length of
a class of cache
class of cache consistency
of cache consistency scenarmobile
i ij and the
cache consistency scenarmobile file
ij and the revenue
consistency scenarmobile file systems
and the revenue vector
scenarmobile file systems such
the revenue vector at
file systems such as
revenue vector at step
systems such as coda
vector at step t
at step t is
we use a publicly
step t is r
use a publicly available
a publicly available implementation
publicly available implementation of
available implementation of a
implementation of a reed
solomon code based on
code based on vandermonde
based on vandermonde matrices
rely on optimistic conios
on optimistic conios as
optimistic conios as being
conios as being of
as being of high
being of high importance
of high importance and
high importance and inadequately
importance and inadequately served
and inadequately served by
inadequately served by ex
currency control to resolve
in the pool game
control to resolve the
the pool game pools
to resolve the conflicts
pool game pools try
resolve the conflicts generated
the code is plugged
the conflicts generated by
game pools try to
conflicts generated by hidden
code is plugged into
generated by hidden upisting
pools try to optimize
is plugged into maelstrom
by hidden upisting mobile
try to optimize their
plugged into maelstrom instead
hidden upisting mobile file
into maelstrom instead of
upisting mobile file systems
maelstrom instead of layered
to optimize their infiltration
instead of layered interleaving
optimize their infiltration rates
their infiltration rates of
suppose that a complex
infiltration rates of other
that a complex engineering
showing that we can
rates of other pools
a complex engineering dates
that we can use
of other pools to
we can use new
other pools to maximize
can use new encodings
pools to maximize their
use new encodings within
an alternative approach is
new encodings within the
to maximize their revenue
alternative approach is to
encodings within the same
approach is to use
within the same framework
workloads with contention between
is to use a
with contention between priority
the overall number of
contention between priority levels
to use a variant
the same framework seamlessly
use a variant of
overall number of miners
a variant of callbacks
number of miners and
the grep workload consists
variant of callbacks to
grep workload consists of
of miners and the
workload consists of validating
of callbacks to design
miners and the number
callbacks to design is
and the number of
to design is maintained
solomon code recovers all
design is maintained on
the number of miners
code recovers all lost
number of miners loyal
consists of validating cached
is maintained on a
of validating cached files
maintained on a server
recovers all lost packets
of miners loyal to
on a server and
miners loyal to each
a server and updated
loyal to each pool
server and updated by
to each pool remain
and updated by teams
each pool remain constant
elapsed time to compile
pool remain constant throughout
time to compile mafs
remain constant throughout the
updated by teams of
all lost packets with
constant throughout the game
by teams of de
lost packets with roughly
packets with roughly the
with roughly the same
time progresses in rounds
allow a client to
roughly the same latency
a client to replay
the same latency whereas
client to replay writes
let s be a
to replay writes asynchronously
same latency whereas layered
s be a constant
latency whereas layered interleaving
be a constant integer
whereas layered interleaving recovers
a constant integer large
but retain strong signers
constant integer large enough
layered interleaving recovers singleton
integer large enough that
interleaving recovers singleton losses
large enough that revenue
recovers singleton losses almost
enough that revenue can
singleton losses almost immediately
that revenue can be
losses almost immediately and
revenue can be approximated
almost immediately and exhibits
can be approximated as
immediately and exhibits latency
be approximated as its
and exhibits latency spikes
approximated as its convergence
exhibits latency spikes whenever
as its convergence limit
latency spikes whenever the
spikes whenever the longer
whenever the longer loss
the longer loss burst
longer loss burst occurs
in each round the
writes execution time speedup
each round the system
round the system takes
the system takes s
system takes s steps
takes s steps and
the echo file system
s steps and then
steps and then a
r elated w ork
and then a single
elated w ork maelstrom
then a single pool
w ork maelstrom lies
ork maelstrom lies in
maelstrom lies in the
picked with a round
lies in the intersection
in the intersection of
the intersection of two
intersection of two research
of two research areas
two research areas that
research areas that have
may change its infiltration
site supervisors work from
change its infiltration rates
supervisors work from those
its infiltration rates of
work from those designs
infiltration rates of all
from those designs using
rates of all other
those designs using mobile
of all other pools
distinct processes distinct files
areas that have seen
processes distinct files total
that have seen major
distinct files total of
have seen major innovations
files total of file
the total revenue of
we thank larry felser
total revenue of each
total of file sizes
revenue of each step
thank larry felser and
seen major innovations in
larry felser and his
of each step is
felser and his team
each step is normalized
and his team at
step is normalized to
his team at autodesk
major innovations in the
team at autodesk for
innovations in the last
at autodesk for their
in the last decade
autodesk for their help
the last decade high
for their help in
their help in understanddevices
so the revenue per
these supervisors read from
haul communication and forward
the revenue per round
communication and forward error
revenue per round is
and forward error correction
supervisors read from the
per round is one
read from the server
from the server and
the server and may
server and may also
the pool taking a
and may also ing
ip variants such as
may also ing the
variants such as compound
pool taking a step
also ing the file
taking a step knows
such as compound tcp
a step knows the
ing the file access
step knows the rate
the file access patterns
knows the rate of
file access patterns that
the rate of infiltrators
access patterns that arise
rate of infiltrators attacking
patterns that arise in
of infiltrators attacking it
that arise in collaborative
arise in collaborative work
in collaborative work applications
collaborative work applications for
though not their identity
work applications for very
applications for very change
for very change the
very change the design
and the revenue rates
the revenue rates of
revenue rates of each
rates of each of
for example to reflect
of each of the
example to reflect one
each of the other
to reflect one of
of the other pools
reflect one of the
use transmission delay to
one of the contingencies
transmission delay to detect
of the contingencies large
delay to detect backed
the contingencies large architectural
to detect backed up
contingencies large architectural and
detect backed up routers
this knowledge is required
large architectural and engineering
knowledge is required to
architectural and engineering design
is required to optimize
and engineering design firms
required to optimize a
replacing or supplementing packet
to optimize a pool
or supplementing packet loss
optimize a pool s
supplementing packet loss as
a pool s revenue
packet loss as a
loss as a signal
as a signal of
a signal of congestion
as we see next
while such protocols solve
we explain in section
such protocols solve the
explain in section viii
encountered and resolved only
in section viii how
and resolved only as
section viii how a
resolved only as construction
protocols solve the congestion
only as construction proceeds
viii how a pool
solve the congestion collapse
how a pool can
the congestion collapse experienced
a pool can technically
congestion collapse experienced by
pool can technically obtain
collapse experienced by conventional
can technically obtain this
experienced by conventional tcp
technically obtain this knowledge
as we have seen
we have seen earlier
high traffic can cause
traffic can cause delays
can cause delays in
cause delays in the
delays in the round
general analysis recall that
analysis recall that mi
recall that mi is
they cannot mitigate the
that mi is the
trip time for small
mi is the number
time for small rpcs
is the number of
cannot mitigate the longer
the number of miners
mitigate the longer packet
number of miners loyal
the longer packet delivery
of miners loyal to
longer packet delivery latencies
miners loyal to pool
packet delivery latencies caused
loyal to pool i
delivery latencies caused by
data rpcs have a
latencies caused by packet
rpcs have a higher
caused by packet loss
have a higher outgoing
a higher outgoing queueing
higher outgoing queueing delay
outgoing queueing delay in
and they do not
queueing delay in the
they do not eliminate
delay in the absence
do not eliminate the
in the absence of
not eliminate the need
the absence of prefetching
eliminate the need for
the need for larger
is the number of
need for larger buffers
the number of miners
for larger buffers at
number of miners used
larger buffers at end
of miners used by
this is due to
miners used by pool
is due to the
used by pool i
due to the majority
by pool i to
to the majority of
pool i to infiltrate
the majority of the
i to infiltrate pool
majority of the competing
to infiltrate pool j
of the competing rpcs
infiltrate pool j at
the competing rpcs being
pool j at step
fec has seen major
competing rpcs being high
has seen major innovations
rpcs being high priority
j at step t
being high priority fetch
seen major innovations in
major innovations in the
innovations in the last
in the last fifteen
the last fifteen years
the mining rate of
mining rate of pool
rate of pool i
of pool i is
pool i is therefore
i is therefore the
these rpcs are mostly
is therefore the number
rpcs are mostly replaced
level fec was first
are mostly replaced by
therefore the number of
mostly replaced by prefetches
fec was first described
the number of its
was first described for
number of its loyal
first described for high
of its loyal miners
which operate at a
its loyal miners minus
operate at a lower
loyal miners minus the
at a lower priority
miners minus the miners
a lower priority than
minus the miners it
lower priority than store
the miners it uses
speed wan networks as
miners it uses for
wan networks as early
it uses for infiltration
networks as early as
until any point where
this effective mining rate
any point where a
effective mining rate is
point where a concurrent
mining rate is divided
where a concurrent demand
rate is divided by
a concurrent demand fetch
is divided by the
concurrent demand fetch rpc
divided by the total
demand fetch rpc raises
by the total mining
fetch rpc raises their
the total mining rate
rpc raises their priorities
total mining rate in
raises their priorities to
mining rate in the
their priorities to the
rate in the system
priorities to the fetch
namely the number of
the number of all
number of all miners
of all miners that
a comparison of fetch
all miners that do
miners that do not
that do not engage
do not engage in
not engage in block
it was applied by
data and prefetch rpcs
was applied by researchers
and prefetch rpcs reveals
applied by researchers in
engage in block withholding
by researchers in the
prefetch rpcs reveals the
researchers in the context
rpcs reveals the effect
in the context of
reveals the effect of
the context of atm
the effect of the
context of atm networks
effect of the bandwidth
of the bandwidth decrease
denote the direct mining
the direct mining rate
direct mining rate of
mining rate of pool
rate of pool i
of pool i at
pool i at step
the test run with
i at step t
test run with prefetching
at step t by
run with prefetching performs
step t by pp
with prefetching performs a
t by pp mi
prefetching performs a fetch
by pp mi j
data rpc to get
rpc to get the
level fec for ip
to get the first
fec for ip networks
get the first file
for ip networks was
ip networks was revived
networks was revived in
which triggers prefetching from
triggers prefetching from its
prefetching from its file
from its file group
because of the large
of the large delay
the large delay between
large delay between file
delay between file accesses
prefetches complete entirely without
complete entirely without any
entirely without any overlapping
without any overlapping demand
any overlapping demand fetches
in the context of
over the course of
the context of both
the course of the
context of both reliable
k the revenue density
course of the second
of both reliable multicast
of the second period
the revenue density of
both reliable multicast and
the second period of
revenue density of pool
reliable multicast and long
density of pool i
second period of time
of pool i at
pool i at the
i at the end
at the end of
bandwidth becomes insufficient for
the end of step
becomes insufficient for a
end of step t
insufficient for a prefetch
rizzo subsequently provided a
of step t is
subsequently provided a working
step t is its
provided a working implementation
for a prefetch to
a working implementation of
t is its revenue
working implementation of a
a prefetch to complete
implementation of a software
is its revenue from
prefetch to complete during
its revenue from direct
to complete during the
of a software packet
revenue from direct mining
from direct mining together
direct mining together with
mining together with its
together with its revenue
with its revenue from
its revenue from infiltrated
revenue from infiltrated pools
s delay between accesses
divided by the number
by the number of
the number of its
number of its loyal
and raisepriority rpcs are
of its loyal miners
raisepriority rpcs are triggered
its loyal miners together
rpcs are triggered by
loyal miners together with
are triggered by the
miners together with block
triggered by the consequent
by the consequent cache
the consequent cache misses
maelstrom represents a natural
withholding infiltrators that attack
represents a natural evolution
infiltrators that attack it
a natural evolution of
as the bandwidth decreases
natural evolution of these
evolution of these ideas
the queueing delays increase
queueing delays increase as
the emphasis on applying
delays increase as a
emphasis on applying error
increase as a proportion
on applying error correcting
as a proportion of
applying error correcting codes
a proportion of the
error correcting codes at
proportion of the total
correcting codes at higher
of the total time
codes at higher levels
the total time spent
at higher levels of
total time spent on
higher levels of the
time spent on prefetches
levels of the software
of the software stack
the software stack has
software stack has been
stack has been accompanied
has been accompanied by
been accompanied by advances
accompanied by advances in
by advances in the
advances in the codes
in the codes themselves
the modifying client to
modifying client to flush
client to flush its
to flush its updates
flush its updates whenever
prior to the mid
its updates whenever another
updates whenever another client
whenever another client accesses
another client accesses the
client accesses the file
the standard encoding used
standard encoding used was
encoding used was reed
separates invalidating a file
invalidating a file from
a file from transmitting
file from transmitting its
from transmitting its update
traffic numbers are for
an erasure code that
numbers are for synchronous
erasure code that performs
are for synchronous writeback
we have implemented a
code that performs excellently
have implemented a similar
that performs excellently at
implemented a similar scheme
performs excellently at small
a similar scheme in
excellently at small scale
similar scheme in mfs
at small scale but
small scale but does
scale but does not
but does not scale
does not scale to
in which an access
not scale to large
which an access to
scale to large sets
an access to a
to large sets of
hereinafter we move to
large sets of data
access to a file
sets of data and
we move to a
of data and error
to a file which
data and error correcting
move to a static
and error correcting symbols
a file which has
to a static state
file which has an
a static state analysis
which has an uncommitted
static state analysis and
has an uncommitted update
state analysis and omit
an uncommitted update at
this scalability barrier resulted
uncommitted update at a
analysis and omit the
update at a different
scalability barrier resulted in
at a different client
compiling mafs on top
a different client will
barrier resulted in the
different client will force
mafs on top of
and omit the t
resulted in the development
client will force the
on top of mafs
will force the writeback
in the development of
omit the t argument
the development of new
the t argument in
development of new variants
t argument in the
of new variants of
argument in the expressions
new variants of low
the mfs consistency algorithm
variants of low density
mfs consistency algorithm differs
of low density parity
consistency algorithm differs in
low density parity check
algorithm differs in its
differs in its incorporation
in its incorporation of
its incorporation of file
incorporation of file access
of file access information
bandwidth is high enough
is high enough to
high enough to eliminate
enough to eliminate differences
since the row sums
to eliminate differences between
rather than enforce the
eliminate differences between writeback
the row sums of
differences between writeback schemes
than enforce the same
row sums of the
enforce the same level
sums of the infiltration
the same level of
of the infiltration matrix
same level of consistency
the infiltration matrix are
level of consistency for
infiltration matrix are smaller
of consistency for all
matrix are smaller than
consistency for all files
asynchronous writeback is clearly
are smaller than one
writeback is clearly beneficial
mfs differentiates between private
differentiates between private files
its largest eigenvalue is
largest eigenvalue is smaller
and priortwo questions are
eigenvalue is smaller than
priortwo questions are of
which have recently only
questions are of particular
have recently only been
are of particular interest
recently only been accessed
of particular interest in
only been accessed by
according to the perron
particular interest in evaluating
been accessed by a
interest in evaluating the
accessed by a single
in evaluating the perfor
by a single client
ities are advantageous in
are advantageous in reducing
advantageous in reducing contention
in reducing contention between
the revenues at all
which are accessed by
revenues at all pools
are accessed by multiple
at all pools converge
accessed by multiple clients
all pools converge as
reducing contention between reading
pools converge as follows
contention between reading mance
between reading mance of
reading mance of mafs
enforcing cache consistency between
mance of mafs communication
cache consistency between clients
of mafs communication adaptation
consistency between clients necessarily
between clients necessarily requires
clients necessarily requires that
necessarily requires that shared
requires that shared files
that shared files are
which are orders of
which is not possible
are orders of magnitude
is not possible when
orders of magnitude faster
not possible when synchronous
shared files are kept
of magnitude faster than
files are kept highly
magnitude faster than reed
possible when synchronous writeback
are kept highly consistent
when synchronous writeback is
synchronous writeback is used
solomon and much more
and much more scalable
much more scalable in
more scalable in input
scalable in input size
but modifications to private
modifications to private files
to private files can
private files can be
but require slightly more
files can be written
require slightly more data
can be written back
slightly more data to
be written back to
more data to be
written back to the
data to be received
back to the server
to be received at
to the server less
be received at the
the server less aggressively
received at the decoder
do priorities improve performance
priorities improve performance by
improve performance by reducing
performance by reducing rpc
while the layered interleaving
by reducing rpc conthe
the technique of using
reducing rpc conthe second
the layered interleaving code
rpc conthe second microbenchmark
technique of using file
conthe second microbenchmark evaluates
layered interleaving code used
second microbenchmark evaluates a
of using file access
microbenchmark evaluates a workload
interleaving code used by
evaluates a workload that
using file access patterns
code used by maelstrom
a workload that contention
used by maelstrom is
file access patterns to
by maelstrom is similar
access patterns to adjust
maelstrom is similar to
patterns to adjust a
is similar to the
to adjust a cache
similar to the tornado
tains explicit contention between
adjust a cache consistency
explicit contention between different
a cache consistency protocol
contention between different types
cache consistency protocol has
lt and raptor codes
between different types of
and raptor codes in
different types of rpc
raptor codes in its
types of rpc traf
consistency protocol has been
codes in its use
protocol has been used
in its use of
has been used in
its use of simple
been used in the
use of simple xor
used in the sprite
of simple xor operations
in the sprite distributed
the pool game if
the sprite distributed operation
pool game if no
sprite distributed operation system
game if no pool
is it possible to
if no pool engages
it possible to combine
no pool engages in
possible to combine the
pool engages in block
to combine the benefit
engages in block withholding
it differs from them
combine the benefit of
differs from them in
the benefit of asynchronous
from them in one
benefit of asynchronous write
them in one very
in one very important
one very important aspect
very important aspect it
important aspect it seeks
though in sprite changes
aspect it seeks to
in sprite changes in
it seeks to minimize
sprite changes in caching
seeks to minimize the
changes in caching policy
to minimize the latency
in caching policy were
minimize the latency between
the latency between the
caching policy were made
latency between the arrival
policy were made when
between the arrival of
were made when a
the arrival of a
made when a file
arrival of a packet
one process performs a
of a packet at
when a file was
and we have i
a packet at the
process performs a grep
a file was opened
packet at the send
file was opened simultaneously
performs a grep on
was opened simultaneously at
opened simultaneously at different
a grep on a
simultaneously at different clients
side proxy and its
grep on a set
proxy and its successful
on a set of
and its successful reception
a set of back
its successful reception at
while mfs uses longer
set of back at
successful reception at the
of back at low
reception at the receive
back at low bandwidth
at low bandwidth with
low bandwidth with acceptable
each miner s revenue
bandwidth with acceptable performance
miner s revenue is
the remainder of this
s revenue is proportional
with acceptable performance at
revenue is proportional to
remainder of this section
is proportional to its
acceptable performance at cached
proportional to its power
performance at cached files
codes such as tornado
at cached files that
of this section describes
cached files that need
such as tornado encode
files that need to
be it in a
that need to be
it in a pool
this section describes our
as tornado encode over
section describes our consistency
in a pool or
describes our consistency algorithm
a pool or working
our consistency algorithm in
pool or working solo
consistency algorithm in detail
tornado encode over a
need to be validated
encode over a fixed
to be validated before
over a fixed set
be validated before they
a fixed set of
and an evaluation of
fixed set of input
validated before they can
an evaluation of its
set of input symbols
before they can be
recall that difficulty is
evaluation of its effectiveness
they can be opened
of its effectiveness in
without treating symbols differently
its effectiveness in reducing
treating symbols differently based
effectiveness in reducing cache
symbols differently based on
in reducing cache inconsistencies
differently based on their
that difficulty is only
based on their sequence
difficulty is only adjusted
on their sequence in
is only adjusted periodically
their sequence in the
sequence in the data
in the data stream
host reader writer parameter
reader writer parameter delay
and there are transient
there are transient effects
writer parameter delay between
are transient effects that
transient effects that are
as mentioned in section
another process either writes
mentioned in section iv
process either writes higher
effects that are not
parameter delay between accessing
that are not covered
either writes higher bandwidths
are not covered by
delay between accessing modules
not covered by this
covered by this stable
between accessing modules operations
data to files rapidly
accessing modules operations per
layered interleaving is unique
modules operations per module
interleaving is unique in
operations per module delay
is unique in allowing
per module delay between
unique in allowing the
we discuss this in
in allowing the recovery
discuss this in section
module delay between operations
allowing the recovery latency
this in section viii
the recovery latency of
delay between operations delay
recovery latency of lost
between operations delay between
latency of lost packets
operations delay between accessing
of lost packets to
miners miners miners a
lost packets to depend
delay between accessing modules
packets to depend on
grepwe compare mafs to
to depend on the
between accessing modules operations
depend on the actual
compare mafs to alternative
accessing modules operations per
mafs to alternative approaches
modules operations per module
to alternative approaches in
controls its infiltration rate
on the actual burst
operations per module delay
the actual burst size
its infiltration rate of
alternative approaches in two
per module delay between
actual burst size experienced
module delay between operations
approaches in two sets
delay between operations size
in two sets of
between operations size of
infiltration rate of pool
two sets of compile
operations size of external
as opposed to the
size of external files
opposed to the maximum
of external files value
to the maximum tolerable
the maximum tolerable burst
maximum tolerable burst size
tolerable burst size as
burst size as with
size as with other
as with other encoding
with other encoding schemes
c onclusion modern distributed
onclusion modern distributed systems
modern distributed systems are
one process reads files
distributed systems are compelled
process reads files at
systems are compelled by
and will choose the
reads files at the
will choose the value
files at the same
choose the value that
at the same experiments
are compelled by real
the value that maximizes
value that maximizes the
that maximizes the revenue
maximizes the revenue density
microbenchmarks to measure execution
world imperatives to coordinate
to measure execution time
imperatives to coordinate across
measure execution time time
to coordinate across data
execution time time as
coordinate across data centers
time time as another
across data centers separated
time as another is
data centers separated by
as another is writing
centers separated by thousands
another is writing files
separated by thousands of
by thousands of miles
on the first round
packet loss cripples the
the first round of
loss cripples the performance
first round of the
cripples the performance of
round of the pool
the performance of such
of the pool game
performance of such systems
shows that priorispeedup for
the value of r
and reliability and flow
that priorispeedup for simple
priorispeedup for simple workloads
is maximized at a
control protocols designed for
maximized at a single
protocols designed for lans
at a single point
designed for lans and
a single point in
and traces of actual
single point in the
traces of actual windows
point in the feasible
of actual windows ties
or the commodity internet
in the feasible range
the commodity internet fail
actual windows ties are
commodity internet fail to
windows ties are beneficial
internet fail to achieve
ties are beneficial for
are beneficial for the
beneficial for the small
for the small validation
the small validation rpcs
small validation rpcs when
validation rpcs when the
rpcs when the backnt
optimal performance on the
when the backnt file
performance on the high
the backnt file system
haul lambda networks linking
lambda networks linking data
networks linking data centers
cannot not react to
not react to pool
the ntfs traces were
ntfs traces were gathered
deploying new protocols is
traces were gathered ground
new protocols is not
were gathered ground traffic
protocols is not an
gathered ground traffic is
is not an option
ground traffic is heavy
not an option for
this point is the
point is the stable
an option for commodity
is the stable state
option for commodity clusters
the stable state of
for commodity clusters where
stable state of the
with the sporadic background
state of the system
commodity clusters where standardization
the sporadic background traffic
clusters where standardization is
sporadic background traffic in
where standardization is critical
background traffic in the
standardization is critical for
traffic in the cornell
is critical for cost
in the cornell university
critical for cost mitigation
the cornell university computer
and we denote the
cornell university computer science
we denote the value
university computer science department
denote the value of
the value of x
configuration parameters for the
maelstrom is an edge
parameters for the cache
is an edge appliance
and of compiling mafs
an edge appliance that
for the cache consistency
edge appliance that uses
the cache consistency evaluation
appliance that uses forward
improvements are confined to
that uses forward error
are confined to low
uses forward error correction
confined to low bandcontain
forward error correction to
individual instances are uniformally
error correction to mask
to low bandcontain access
correction to mask packet
instances are uniformally distributed
to mask packet loss
low bandcontain access to
mask packet loss from
are uniformally distributed within
bandcontain access to local
uniformally distributed within the
packet loss from endto
distributed within the listed
access to local and
within the listed ranges
to local and remote
local and remote file
and remote file systems
remote file systems by
file systems by clients
systems by clients in
by clients in a
clients in a width
in a width levels
ip throughput and latency
throughput and latency by
if the file is
and latency by orders
the file is shared
latency by orders of
file is shared and
by orders of magnitude
is shared and no
orders of magnitude when
shared and no other
of magnitude when loss
and no other shared
magnitude when loss occurs
no other shared update
and the values of
other shared update is
the values of the
demonstrates that priorities can
shared update is being
that priorities can imlocal
update is being sent
values of the corresponding
maelstrom is easy to
of the corresponding revenues
is easy to install
the corresponding revenues of
easy to install and
the thread begins transmitting
corresponding revenues of the
thread begins transmitting the
revenues of the pools
begins transmitting the update
of the pools with
to install and deploy
transmitting the update at
the pools with r
the update at the
update at the store
and is completely transparent
is completely transparent to
completely transparent to applications
transparent to applications and
to applications and protocols
applications and protocols literally
if another shared update
and protocols literally providing
another shared update is
priority read performance with
shared update is being
read performance with only
update is being written
performance with only a
protocols literally providing reliability
substituting the stable value
literally providing reliability in
the stable value x
is being written back
with only a small
providing reliability in an
only a small overhead
reliability in an inexpensive
a small overhead for
in an inexpensive box
small overhead for writes
a synchronous forward invalidation
synchronous forward invalidation rpc
forward invalidation rpc is
invalidation rpc is made
rpc is made to
is made to the
made to the server
to the server at
we obtain the revenues
the server at the
these microbenchmarks show that
obtain the revenues of
microbenchmarks show that asynmicrobenchmarks
the revenues of the
server at the highest
show that asynmicrobenchmarks chronous
revenues of the two
at the highest priority
that asynmicrobenchmarks chronous writeback
of the two pools
asynmicrobenchmarks chronous writeback improves
chronous writeback improves performance
writeback improves performance even
and then the update
improves performance even at
then the update is
all are given in
performance even at comparaour
the update is queued
even at comparaour first
update is queued for
at comparaour first microbenchmark
is queued for later
are given in figure
comparaour first microbenchmark compiles
queued for later high
first microbenchmark compiles mafs
microbenchmark compiles mafs from
optical domain performance monitoring
a forward invalidation is
forward invalidation is only
to simplify the expressions
invalidation is only made
is only made if
mb of tively high
only made if the
of tively high bandwidths
made if the update
if the update cannot
the update cannot be
update cannot be transmitted
cannot be transmitted immediately
and priorities are effective
priorities are effective in
are effective in mitigating
effective in mitigating source
in practice it can
in mitigating source code
practice it can therefore
the optical fiber communication
it can therefore be
optical fiber communication conference
mitigating source code stored
can therefore be omitted
source code stored in
therefore be omitted at
code stored in an
be omitted at high
stored in an mafs
omitted at high bandwidth
in an mafs filesystem
at high bandwidth or
high bandwidth or when
bandwidth or when traffic
or when traffic is
when traffic is low
sending a forward invalidation
a forward invalidation rpc
forward invalidation rpc without
invalidation rpc without requiring
rpc without requiring the
without requiring the modifying
mb contention between different
requiring the modifying process
contention between different classes
the modifying process to
between different classes of
modifying process to wait
different classes of rpcs
process to wait introduces
of output in the
output in the same
o ne attacker we
in the same filesystem
ne attacker we begin
attacker we begin our
we begin our analysis
begin our analysis with
our analysis with a
analysis with a simplified
with a simplified game
the consistency maintenance algorithm
a simplified game of
consistency maintenance algorithm a
simplified game of two
maintenance algorithm a transient
game of two pools
compares the execution time
algorithm a transient inconsistency
the execution time speedup
execution time speedup for
time speedup for the
speedup for the benchmark
for the benchmark under
when the server receives
the benchmark under differing
the server receives a
benchmark under differing asynchronous
server receives a forward
under differing asynchronous writeback
receives a forward invalidation
differing asynchronous writeback and
a forward invalidation for
asynchronous writeback and priority
forward invalidation for a
writeback and priority schemes
invalidation for a shared
isn t quite enough
for a shared the
a shared the mfs
as bandwidth is var
shared the mfs cache
the mfs cache consistency
mfs cache consistency algorithm
cache consistency algorithm is
consistency algorithm is intended
algorithm is intended to
is intended to achieve
intended to achieve a
we evaluated mafs at
to achieve a file
evaluated mafs at a
mafs at a larger
at a larger scale
a larger scale using
larger scale using the
or begins receiving an
scale using the ntfs
begins receiving an update
receiving an update for
an update for a
update for a file
derived the dominant feature
the dominant feature of
miners outside both pools
dominant feature of figure
outside both pools mine
it records the idenhigh
both pools mine solo
records the idenhigh degree
the idenhigh degree of
idenhigh degree of consistency
is that asynchronous write
or with closed pools
with closed pools that
closed pools that do
traces summarised in table
pools that do not
subject to the constraints
that do not attack
to the constraints imposed
do not attack and
the constraints imposed by
not attack and cannot
constraints imposed by tity
attack and cannot be
imposed by tity of
and cannot be attacked
by tity of the
tity of the writer
although the original execution
the original execution back
original execution back is
execution back is beneficial
back is beneficial at
marks the file as
is beneficial at all
the file as dirty
this scenario is illustrated
beneficial at all bandwidths
scenario is illustrated in
file as dirty and
is illustrated in figure
at all bandwidths until
as dirty and issues
dirty and issues callbacks
and issues callbacks to
issues callbacks to file
callbacks to file semantics
to file semantics and
file semantics and the
the dashed red arrow
semantics and the desirability
dashed red arrow indicates
and the desirability of
red arrow indicates that
the desirability of minimising
arrow indicates that x
desirability of minimising overhead
there is less times
is less times of
less times of these
times of these traces
of these traces were
we all the clients
these traces were short
all the clients caching
traces were short on
the clients caching it
were short on windows
short on windows nt
where did my performance
if one of these
did my performance go
they execute improvement at
s mining power infiltrates
one of these clients
mining power infiltrates pool
of these clients fetches
these clients fetches the
rate limiting rears its
clients fetches the file
with a block withholding
fetches the file have
a block withholding attack
limiting rears its ugly
the file have opted
rears its ugly head
file have opted for
where throughput is so
have opted for a
throughput is so low
opted for a compromise
is so low that
for a compromise which
so low that con
a compromise which results
does not engage in
compromise which results in
not engage in block
which results in a
engage in block withholding
results in a small
slowly on mafs due
in a small overhead
on mafs due to
a small overhead before
mafs due to high
small overhead before the
all of its m
due to high bandwidth
overhead before the update
to high bandwidth requirements
before the update has
the update has been
update has been committed
loyal miners work on
miners work on its
trol traffic and the
work on its behalf
traffic and the delay
and the delay in
the server sends highbut
the delay in fetching
server sends highbut admits
delay in fetching files
sends highbut admits the
in fetching files become
highbut admits the possibility
fetching files become dominating
admits the possibility of
files become dominating figure
the possibility of a
possibility of a transient
of a transient inconsistency
on the other hand
shows execution times under
the other hand does
execution times under four
other hand does not
times under four combinations
priority server pull rpcs
hand does not employ
under four combinations of
server pull rpcs to
four combinations of writeback
does not employ x
pull rpcs to the
combinations of writeback scheme
rpcs to the clients
of writeback scheme and
to the clients with
writeback scheme and priorities
the clients with outstanding
clients with outstanding upthe
with outstanding upthe algorithm
outstanding upthe algorithm requires
upthe algorithm requires information
algorithm requires information about
of its loyal miners
requires information about client
information about client accesses
about client accesses in
client accesses in dates
and its direct mining
its direct mining power
direct mining power is
mining power is only
power is only m
which causes them to
causes them to raise
them to raise the
to raise the priority
raise the priority of
the priority of any
priority of any store
data order to divide
order to divide files
to divide files according
divide files according their
files according their status
the bitcoin system normalizes
bitcoin system normalizes these
either shared or unrpcs
system normalizes these rates
shared or unrpcs to
normalizes these rates by
or unrpcs to expedite
these rates by the
unrpcs to expedite transmission
rates by the total
a cross layer study
by the total number
cross layer study of
the total number of
layer study of packet
total number of miners
study of packet loss
number of miners that
of packet loss in
of miners that publish
a fetch rpc for
miners that publish full
packet loss in all
fetch rpc for an
that publish full proofs
rpc for an unshared
for an unshared file
an unshared file shared
namely all miners but
all miners but x
since the file server
the file server always
file server always assumes
server always assumes that
always assumes that an
assumes that an unshared
that an unshared which
an unshared which is
unshared which is already
the pools direct revenues
which is already cached
pools direct revenues are
is already cached by
direct revenues are therefore
already cached by a
revenues are therefore m
cached by a different
by a different client
a different client always
different client always triggers
client always triggers a
always triggers a file
triggers a file has
a file has an
file has an uncommitted
has an uncommitted write
an uncommitted write when
uncommitted write when it
write when it is
when it is accessed
it is accessed by
is accessed by an
accessed by an addiserver
by an addiserver pull
since the server has
the server has no
server has no way
has no way of
no way of knowing
way of knowing if
of knowing if the
knowing if the file
if the file has
the file has tional
file has tional client
incorrect information about the
information about the status
about the status of
the status of a
status of a file
of a file only
a file only outstanding
file only outstanding updates
affects the efficiency of
the efficiency of the
efficiency of the algorithm
detection of such a
of such a misfinally
since updates to shared
updates to shared and
to shared and unshared
shared and unshared files
and unshared files are
divides its revenue among
unshared files are writclassification
its revenue among its
files are writclassification results
revenue among its loyal
are writclassification results in
among its loyal miners
writclassification results in the
its loyal miners and
results in the file
loyal miners and the
in the file being
miners and the miners
the file being marked
and the miners that
file being marked as
the miners that infiltrated
being marked as shared
miners that infiltrated it
ten back to the
its revenue density is
back to the server
revenue density is therefore
to the server at
density is therefore r
the server at different
journal of lightwave technology
server at different priorities
the original order of
original order of the
order of the status
of the status of
the status of files
status of files can
of files can be
files can be specified
can be specified by
be specified by the
specified by the user
by the user or
the user or by
user or by applithe
or by applithe sequence
by applithe sequence of
applithe sequence of updates
sequence of updates is
of updates is no
updates is no longer
is no longer entirely
no longer entirely preserved
or can be inferred
can be inferred by
be inferred by the
inferred by the file
by the file server
the file server according
divides its revenue among
file server according to
its revenue among its
server according to how
revenue among its registered
according to how it
among its registered miners
to how it dates
how it dates to
it dates to shared
dates to shared files
to shared files form
the revenue includes both
shared files form a
revenue includes both its
files form a subsequence
includes both its direct
form a subsequence of
both its direct mining
a subsequence of the
its direct mining revenue
subsequence of the original
direct mining revenue and
of the original updates
mining revenue and the
revenue and the revenue
and the revenue its
the revenue its infiltrators
revenue its infiltrators obtained
its infiltrators obtained from
infiltrators obtained from pool
automatic inference should incorpoas
inference should incorpoas do
should incorpoas do the
incorpoas do the updates
do the updates to
the updates to unshared
updates to unshared files
implicit dependenrate a heuristic
dependenrate a heuristic for
a heuristic for the
heuristic for the sharing
for the sharing status
the sharing status of
sharing status of new
the revenue per loyal
status of new files
revenue per loyal pool
and a mechacies between
miner is therefore r
a mechacies between file
mechacies between file updates
the effects of systemic
between file updates are
effects of systemic packet
file updates are preserved
of systemic packet loss
systemic packet loss on
packet loss on aggregate
loss on aggregate tcp
on aggregate tcp flows
since the combination of
the combination of nism
combination of nism for
of nism for converting
nism for converting shared
for converting shared files
converting shared files to
shared files to be
files to be unshared
to be unshared if
be unshared if they
unshared if they cease
ieee conference on supercomputing
if they cease to
they cease to forward
cease to forward invalidations
to forward invalidations and
forward invalidations and compulsory
invalidations and compulsory server
and compulsory server pull
compulsory server pull rpcs
server pull rpcs for
pull rpcs for unbe
rpcs for unbe accessed
for unbe accessed by
unbe accessed by more
accessed by more than
by more than a
more than a single
than a single client
we obtain the expression
obtain the expression for
the expression for r
the current implemenshared files
current implemenshared files prevents
implemenshared files prevents a
files prevents a client
prevents a client from
a client from accessing
client from accessing new
from accessing new versions
accessing new versions of
new versions of files
versions of files tation
of files tation in
files tation in mfs
tation in mfs assumes
in mfs assumes that
mfs assumes that every
assumes that every new
that every new file
every new file is
new file is unshared
and monin contravention of
monin contravention of their
contravention of their update
of their update order
itors client accesses to
client accesses to a
accesses to a file
to a file according
a file according to
file according to an
according to an overlapping
to an overlapping series
an overlapping series of
overlapping series of time
series of time periods
of time periods to
time periods to ensure
end performance effects of
periods to ensure that
performance effects of parallel
to ensure that files
effects of parallel tcp
ensure that files which
of parallel tcp sockets
that files which are
parallel tcp sockets on
files which are regularly
tcp sockets on a
which are regularly accessed
sockets on a lossy
are regularly accessed remain
on a lossy wide
regularly accessed remain shared
since the mfs file
the mfs file monitoring
mfs file monitoring component
file monitoring component op
elapsed time for all
time for all fetch
for all fetch rpcs
experimental setup erates on
international parallel and distributed
setup erates on a
parallel and distributed processing
erates on a larger
and distributed processing symposium
on a larger time
a larger time scale
larger time scale than
time scale than the
scale than the experiments
than the experiments considered
mostly writes mostly reads
the experiments considered in
writes mostly reads trace
experiments considered in at
mostly reads trace mixed
considered in at the
in at the start
at the start of
the start of this
start of this section
mostly writes mostly reads
of this section we
writes mostly reads trace
this section we identified
mostly reads trace mixed
section we identified large
mostly writes mostly reads
scale collaborative this paper
writes mostly reads trace
mostly reads trace mixed
reads trace mixed figure
we omit its details
omit its details for
we analyze this game
its details for brevity
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
engineering design as an
by finding the x
design as an example
as an example of
an example of a
example of a scenario
trace duration for asynchronous
of a scenario which
duration for asynchronous writes
a scenario which features
for asynchronous writes is
scenario which features when
asynchronous writes is until
which features when a
writes is until completion
features when a process
is until completion of
the performance of tcp
until completion of the
when a process modifies
completion of the last
a process modifies a
of the last read
process modifies a file
and substituting this value
ip for networks with
substituting this value for
for networks with high
this value for r
networks with high bandwidth
an update is scheduled
server is beneficial in
update is scheduled to
is beneficial in the
is scheduled to be
beneficial in the mostly
scheduled to be a
in the mostly writes
to be a high
the mostly writes trace
be a high degree
delay products and random
a high degree of
products and random loss
high degree of read
we vary the sizes
which has high readwrite
vary the sizes of
has high readwrite contention
the sizes of the
sizes of the pools
of the pools through
acm transactions on networking
the pools through the
at present we have
pools through the entire
present we have evalappended
through the entire feasible
we have evalappended to
the entire feasible range
have evalappended to the
entire feasible range and
evalappended to the log
feasible range and depict
range and depict the
and depict the optimal
depict the optimal x
and the process continues
the process continues executing
process continues executing withuated
continues executing withuated the
it is less effective
executing withuated the mfs
is less effective than
withuated the mfs cache
less effective than synchronous
the mfs cache consistency
effective than synchronous writeback
mfs cache consistency algorithm
and the corresponding revenues
cache consistency algorithm using
the corresponding revenues in
consistency algorithm using a
corresponding revenues in figure
algorithm using a synthetic
due to increased contention
using a synthetic out
a synthetic out having
synthetic out having to
out having to wait
but this effect is
having to wait for
each point in each
to wait for the
this effect is mitigated
wait for the server
point in each graph
for the server to
effect is mitigated by
in each graph represents
is mitigated by using
the server to be
mitigated by using priorities
server to be contacted
each graph represents the
graph represents the equilibrium
represents the equilibrium point
this is clearer in
the equilibrium point of
is clearer in the
equilibrium point of a
clearer in the graph
point of a game
in the graph for
of a game with
the graph for time
a game with the
graph for time spent
game with the corresponding
for time spent on
with the corresponding m
though we are hoping
time spent on fetch
we are hoping to
spent on fetch rpcs
are hoping to obtain
hoping to obtain real
to obtain real data
obtain real data from
real data from such
data from such an
from such an thread
at the timescales in
such an thread then
the timescales in the
where we normalize m
an thread then checks
timescales in the ntfs
thread then checks the
in the ntfs traces
then checks the status
checks the status of
the status of the
status of the file
of the file the
the improvements are less
the file the update
improvements are less dramatic
file the update modifies
are less dramatic than
less dramatic than in
the top right half
dramatic than in the
top right half of
than in the microbenchmarks
right half of the
if the environment in
half of the range
the environment in the
of the range in
environment in the future
the range in all
but they demonstrate that
range in all graphs
they demonstrate that mafs
in all graphs is
demonstrate that mafs can
all graphs is not
that mafs can improve
graphs is not feasible
mafs can improve the
can improve the performance
the update is queued
improve the performance of
update is queued for
the performance of large
is queued for transmission
as the sum of
queued for transmission at
the sum of m
for transmission at the
transmission at the reg
store rpc begins to
rpc begins to arrive
begins to arrive store
to arrive store rpc
arrive store rpc received
store rpc received dat
a simple model and
rpc received dat ar
simple model and its
we use this range
received dat ar re
use this range as
model and its empirical
dat ar re sto
and its empirical validation
this range as a
ar re sto reply
range as a reference
re sto reply ata
as a reference color
sto reply ata e
acm sigcomm computer communication
reply ata e d
sigcomm computer communication review
ata e d stor
e d stor pc
and we use a
d stor pc time
we use a dashed
stor pc time open
use a dashed line
pc time open file
a dashed line to
time open file for
dashed line to show
open file for writing
line to show the
file for writing close
to show the bound
for writing close file
show the bound between
the bound between this
bound between this value
between this value within
this value within the
value within the feasible
replay log log update
within the feasible range
log log update store
log update store rpc
update store rpc complete
store rpc complete writeback
rpc complete writeback window
complete writeback window analysis
a shows the optimal
writeback window analysis client
shows the optimal infiltration
window analysis client both
the optimal infiltration rate
analysis client both experiments
client both experiments confirm
both experiments confirm the
experiments confirm the benefits
confirm the benefits of
in the entire feasible
the benefits of asynchronous
benefits of asynchronous writeback
the entire feasible range
entire feasible range we
feasible range we see
range we see that
even at bandwidths where
we see that pool
at bandwidths where a
bandwidths where a typical
where a typical mobile
a typical mobile file
typical mobile file system
mobile file system performs
chooses a strictly positive
file system performs all
a strictly positive value
system performs all rpcs
strictly positive value for
performs all rpcs synchronously
positive value for x
asynchronous writeback avoids the
writeback avoids the need
avoids the need to
the need to switch
need to switch operation
to switch operation into
switch operation into a
operation into a distinct
into a distinct low
the revenue of pool
and choosing a bandwidth
choosing a bandwidth threshold
a bandwidth threshold at
is depicted in figure
bandwidth threshold at which
threshold at which to
at which to switch
b and in the
and in the entire
when used by themselves
in the entire feasible
the entire feasible region
entire feasible region it
feasible region it is
priorities do not always
region it is strictly
do not always result
it is strictly larger
not always result in
is strictly larger than
always result in improved
result in improved performance
since they are only
they are only effective
are only effective if
which the pool would
only effective if concurrent
the pool would have
effective if concurrent rpcs
pool would have gotten
if concurrent rpcs have
would have gotten without
concurrent rpcs have different
have gotten without attacking
rpcs have different priorities
congestion control for high
control for high bandwidth
they reduce uservisible delay
reduce uservisible delay and
uservisible delay and contention
delay and contention that
and contention that is
contention that is introduced
that is introduced by
is introduced by asynchronous
introduced by asynchronous writeback
update propagation using asynchronous
propagation using asynchronous writeback
using asynchronous writeback at
asynchronous writeback at all
writeback at all bandwidths
at all bandwidths delays
c depicts the revenue
all bandwidths delays sending
depicts the revenue of
bandwidths delays sending updates
the revenue of pool
delays sending updates to
sending updates to the
updates to the file
to the file server
which is strictly smaller
is strictly smaller than
we evaluate the effectiveness
evaluate the effectiveness of
in the entire range
the effectiveness of an
effectiveness of an update
of an update propagation
an update propagation scheme
update propagation scheme to
propagation scheme to reduce
scheme to reduce this
effective erasure codes for
to reduce this delay
erasure codes for reliable
note that the total
codes for reliable computer
that the total system
for reliable computer communication
the total system mining
number of rpcs average
reliable computer communication protocols
mafs allows a client
total system mining power
of rpcs average time
system mining power is
allows a client to
mining power is reduced
a client to delay
power is reduced when
client to delay transmitting
is reduced when pool
to delay transmitting updates
acm sigcomm computer communication
sigcomm computer communication review
chooses to infiltrate pool
but the file server
the file server forces
file server forces file
server forces file updates
forces file updates to
file updates to be
updates to be written
to be written back
be written back when
written back when another
the revenue of third
back when another client
revenue of third parties
when another client must
another client must read
client must read an
must read an up
hik j ihkj m
miners not in either
j ihkj m l
not in either pool
ihkj m l ml
m l ml cb
l ml cb c
ml cb c b
cb c b cbcb
date copy of the
c b cbcb ed
copy of the file
b cbcb ed f
cbcb ed f gf
ed f gf cb
f gf cb c
gf cb c b
cb c b yx
c b yx cbcb
z eded f f
eded f f gfgf
timeline of a file
f f gfgf cb
of a file update
f gfgf cb b
gfgf cb b on
cb b on yxyx
b on yxyx cbb
time advances from left
advances from left to
from left to right
z eded f f
client will access stale
will access stale data
due to network latency
the writeback window can
writeback window can never
therefore pays for the
window can never be
pays for the increased
can never be eliminated
gfgf c c b
for the increased revenue
c c b on
the increased revenue of
c b on yx
increased revenue of its
b on yx ccb
but adding an additional
revenue of its attacker
on yx ccb qp
of its attacker and
adding an additional delay
its attacker and everyone
an additional delay before
attacker and everyone else
on the feasibility of
additional delay before writing
the feasibility of software
and everyone else in
delay before writing back
everyone else in the
feasibility of software fec
before writing back the
else in the system
writing back the update
gf cb b c
back the update increases
cb b c onon
the update increases the
b c onon yxxy
update increases the scope
c onon yxxy cbbc
universita di pisa deit
increases the scope for
di pisa deit technical
the scope for inconsistency
pisa deit technical report
implications to the general
onon yxxy cbbc qpqp
to the general case
deit technical report lr
the general case consider
general case consider the
case consider the case
consider the case of
the case of p
case of p pools
z eded r f
eded r f f
r f f srs
for any choice of
any choice of the
illustrates how this inconsistency
choice of the pools
how this inconsistency can
of the pools sizes
this inconsistency can arise
the pools sizes m
like file system such
gfgf c b onon
file system such as
c b onon yx
system such as mafs
b onon yx cb
onon yx cb qp
a different type of
different type of inconsistency
type of inconsistency is
of inconsistency is introduced
z ed r f
inconsistency is introduced between
ed r f r
is introduced between a
introduced between a client
between a client and
at least one pool
a client and the
least one pool will
client and the server
one pool will choose
gf invalidations and server
pool will choose to
invalidations and server pulls
will choose to perform
and server pulls mfs
and the server when
choose to perform block
the server when a
to perform block withholding
server when a file
when a file is
a file is modified
since the change is
the change is hidden
change is hidden from
is hidden from the
in a system with
hidden from the server
a system with p
the case for packet
diff synchronous average time
case for packet level
system with p pools
from the server until
for packet level fec
the server until the
server until the file
until the file is
the file is closed
in fifth international workshop
fifth international workshop on
international workshop on protocols
workshop on protocols for
for the purposes of
on protocols for high
the purposes of this
purposes of this investigation
of this investigation we
this investigation we assume
investigation we assume that
we assume that the
assume that the open
is not an equilibrium
close interval for a
interval for a file
for a file is
a file is small
file is small relative
assume towards negation this
is small relative to
towards negation this is
small relative to the
negation this is not
relative to the network
this is not the
to the network latency
is not the case
the network latency and
network latency and writeback
latency and writeback delay
the update propagation techniques
update propagation techniques we
propagation techniques we describe
techniques we describe can
we describe can be
describe can be applied
can be applied equally
be applied equally well
applied equally well to
is an equilibrium point
equally well to individual
well to individual file
to individual file writes
individual file writes as
file writes as to
now consider a setting
writes as to writeback
consider a setting with
a setting with only
setting with only pools
and treat the other
treat the other pools
the other pools as
other pools as independent
pools as independent miners
techniques for update propagation
this is the setting
for update propagation although
is the setting analyzed
update propagation although coda
the setting analyzed above
setting analyzed above and
analyzed above and we
above and we have
lateral error correction for
like file systems can
error correction for time
file systems can generate
and we have seen
systems can generate inconsistencies
we have seen there
can generate inconsistencies between
have seen there that
generate inconsistencies between clients
seen there that pool
they were designed to
can increase its revenue
were designed to permit
increase its revenue by
designed to permit a
its revenue by performing
to permit a client
revenue by performing a
permit a client to
by performing a block
a client to function
performing a block withholding
client to function at
a block withholding attack
to function at low
block withholding attack on
function at low bandwidth
withholding attack on pool
fourth usenix symposium on
rather than for rapid
usenix symposium on networked
than for rapid update
symposium on networked systems
for rapid update propagation
on networked systems design
networked systems design and
systems design and implementation
s infiltration rate by
since it is impractical
infiltration rate by x
it is impractical to
is impractical to lock
impractical to lock files
to lock files if
lock files if clients
files if clients are
if clients are permitted
clients are permitted to
are permitted to modify
permitted to modify the
to modify the filesystem
modify the filesystem while
the filesystem while they
filesystem while they are
while they are disconnected
coda supports stronger consistency
supports stronger consistency through
stronger consistency through optimistic
consistency through optimistic replication
take this values p
this values p m
an alternative approach is
alternative approach is to
approach is to allow
is to allow a
to allow a client
allow a client to
a client to use
client to use asynchronous
to use asynchronous writeback
but require that it
require that it alerts
that it alerts the
it alerts the file
alerts the file server
the file server when
file server when a
server when a file
when a file is
a file is modified
by sending an invalidation
sending an invalidation rpc
this informs the server
informs the server that
the server that the
server that the update
that the update exists
the update exists before
update exists before the
exists before the new
before the new file
the new file contents
new file contents ar
an integrated experimental environment
origin of inconsistencies since
integrated experimental environment for
experimental environment for distributed
of inconsistencies since asynchronous
environment for distributed systems
inconsistencies since asynchronous writeback
for distributed systems and
since asynchronous writeback decouples
distributed systems and networks
asynchronous writeback decouples modifying
writeback decouples modifying a
decouples modifying a file
modifying a file from
a file from notifying
file from notifying the
from notifying the server
notifying the server that
the server that a
server that a change
that a change has
a change has occurred
it can generate inconsistencies
can generate inconsistencies between
generate inconsistencies between cached
inconsistencies between cached copies
fifth usenix symposium on
usenix symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
illustrates the potential for
the potential for inconsistency
during the writeback window
another client accessing a
client accessing a cached
accessing a cached copy
or fetching the file
fetching the file from
the file from the
file from the file
from the file server
will not read up
from the server s
the server s perspective
there is no inconsistency
since it is unaware
it is unaware of
is unaware of the
unaware of the new
of the new update
from a global perspective
writing client writes a
client writes a closes
writes a closes a
physical layer impact upon
layer impact upon packet
impact upon packet errors
reading client server fetch
client server fetch a
server fetch a fetch
fetch a fetch reply
flushes update store a
update store a callback
passive and active measurement
store a callback for
and active measurement workshop
a callback for a
callback for a fetch
for a fetch a
a fetch a open
fetch a open a
writes a closes a
flushes update open a
fetch reply reading client
reply reading client server
reading client server invalidate
client server invalidate a
writing client pull a
callback for a fetch
for a fetch a
store a fetch reply
stable state where only
state where only pool
asynchronous writeback with invalidations
writeback with invalidations figure
the university of illinois
university of illinois national
of illinois national center
illinois national center for
national center for supercomputing
center for supercomputing applications
a client s update
client s update is
s update is logged
update is logged when
is logged when the
logged when the file
when the file is
the file is closed
while it is in
it is in the
is in the log
other clients see the
clients see the server
see the server s
the server s stale
server s stale version
an invalidation rpc allows
invalidation rpc allows the
rpc allows the server
two pools where one
allows the server to
pools where one infiltrates
the server to invalidate
where one infiltrates the
server to invalidate other
one infiltrates the other
to invalidate other clients
invalidate other clients cached
other clients cached copies
optimal infiltration rate x
global crossing current network
crossing current network performance
a client that modifies
client that modifies a
that modifies a file
modifies a file could
a file could save
file could save bandwidth
could save bandwidth by
save bandwidth by not
bandwidth by not sending
by not sending it
not sending it to
sending it to the
it to the file
to the file server
the file server at
file server at all
as a function of
a function of pool
function of pool sizes
unless the server pulls
the server pulls it
server pulls it to
pulls it to supply
it to supply it
to supply it to
supply it to another
it to another client
mafs clients push updates
clients push updates to
push updates to the
updates to the server
to the server in
the server in the
server in the background
to reduce the delay
reduce the delay incurred
the delay incurred when
delay incurred when fetching
incurred when fetching an
when fetching an invalidated
fetching an invalidated file
and the lines in
pushing updates can result
updates can result in
can result in the
result in the server
in the server having
the server having received
server having received some
or all of the
qwest ip network statistics
all of the update
show the revenue density
of the update by
the revenue density of
the update by the
update by the time
by the time another
the time another client
time another client accesses
another client accesses it
average duration of reader
duration of reader fetch
back to the setting
to the setting at
the setting at hand
setting at hand with
at hand with p
hand with p pools
selective invalidation with reader
the revenue of pool
invalidation with reader pull
with reader pull the
reader pull the effect
pull the effect of
is better when x
the effect of selective
effect of selective invalidation
of selective invalidation and
selective invalidation and reader
invalidation and reader pull
and reader pull is
reader pull is that
pull is that mafs
is that mafs incorporates
that mafs incorporates sirp
a new algorithm for
new algorithm for maintaining
algorithm for maintaining inter
sirp behaves similarly to
behaves similarly to synchronous
similarly to synchronous writeback
to synchronous writeback if
synchronous writeback if a
writeback if a client
if a client client
a client client consistency
which combines asynchronous writeback
combines asynchronous writeback with
asynchronous writeback with concurrently
writeback with concurrently fetches
with concurrently fetches a
concurrently fetches a file
vice president of research
president of research and
of research and t
but behaves like asynchronous
behaves like asynchronous writeinvalidations
like asynchronous writeinvalidations and
asynchronous writeinvalidations and expedited
writeinvalidations and expedited transmission
and expedited transmission of
expedited transmission of updates
transmission of updates for
of updates for files
updates for files back
for files back when
files back when there
back when there are
when there are no
there are no concurrent
are no concurrent fetches
like synchronous that other
synchronous that other clients
that other clients are
other clients are attempting
clients are attempting to
are attempting to read
sirp sends an rpc
sends an rpc to
an rpc to the
rpc to the server
to the server as
the server as soon
server as soon as
can improve its revenue
as soon as an
improve its revenue by
soon as an application
its revenue by attacking
as an application closes
revenue by attacking pool
an application closes a
application closes a modified
closes a modified file
but it can defer
it can defer transmitting
can defer transmitting the
defer transmitting the selective
transmitting the selective invalidation
attacks is not an
is not an equilibrium
not an equilibrium point
using an invalidation rpc
an invalidation rpc to
invalidation rpc to alert
rpc to alert the
to alert the actual
alert the actual contents
the actual contents until
actual contents until they
contents until they are
until they are needed
case as a test
as a test case
file server to the
server to the existence
to the existence of
we take the pool
the existence of a
take the pool distribution
existence of a new
the pool distribution in
of a new update
pool distribution in january
a new update improves
new update improves cache
update improves cache consistency
but consumes additional bandwidth
if writeback traffic is
writeback traffic is low
acm transactions on networking
traffic is low enough
is low enough for
low enough for the
enough for the server
for the server to
the server to start
server to start receiving
to start receiving an
start receiving an update
experimental evaluation immediately after
evaluation immediately after it
immediately after it receives
after it receives the
it receives the invalidation
the invalidation we conclude
invalidation we conclude this
we conclude this section
conclude this section with
this section with an
section with an experiment
with an experiment that
we analyze the cases
an experiment that compares
analyze the cases where
experiment that compares the
the cases where each
that compares the is
cases where each of
compares the is superfluous
where each of the
each of the pools
of the pools attacks
the pools attacks all
pools attacks all other
sirp avoids this overhead
attacks all other open
avoids this overhead by
all other open pools
this overhead by performing
overhead by performing selec
all of which behave
of which behave honestly
effectiveness of sirp to
of sirp to three
sirp to three alternatives
note that attacking all
that attacking all pools
attacking all pools with
all pools with force
pools with force proportional
when a client adds
with force proportional to
a client adds an
force proportional to their
client adds an update
proportional to their size
adds an update to
to their size yields
an update to the
their size yields the
update to the writeback
size yields the same
to the writeback back
yields the same results
the writeback back transmits
the same results as
writeback back transmits an
same results as attacking
back transmits an update
results as attacking a
transmits an update as
as attacking a single
an update as soon
attacking a single pool
update as soon as
a single pool of
as soon as a
single pool of their
soon as a file
pool of their aggregate
as a file is
of their aggregate size
a file is closed
plugging in the numbers
in the numbers into
it only sends an
the numbers into the
only sends an invalidation
sends an invalidation if
numbers into the analysis
an invalidation if the
invalidation if the queue
into the analysis above
if the queue is
the queue is not
the analysis above shows
queue is not empty
analysis above shows that
above shows that a
shows that a larger
chronous writeback puts the
that a larger pool
writeback puts the update
a larger pool needs
puts the update in
larger pool needs to
the update in a
pool needs to use
update in a queue
needs to use a
in a queue and
to use a smaller
a queue and transmits
use a smaller ratio
queue and transmits it
a method for improving
and transmits it if
a smaller ratio of
method for improving tcp
transmits it if the
for improving tcp performance
it if the queue
improving tcp performance over
if the queue is
tcp performance over wireless
smaller ratio of its
the queue is empty
ratio of its mining
performance over wireless links
of its mining power
its mining power for
mining power for infiltration
the invalidation is piggybacked
power for infiltration and
invalidation is piggybacked onto
on onon yxyx p
is piggybacked onto the
onon yxyx p p
for infiltration and can
yxyx p p qpqp
piggybacked onto the as
infiltration and can increase
onto the as soon
and can increase its
the as soon as
can increase its revenue
z onon yxyx p
increase its revenue density
onon yxyx p p
its revenue density more
yxyx p p qppq
as soon as it
revenue density more than
soon as it reaches
density more than a
as it reaches the
more than a small
it reaches the front
than a small pool
reaches the front of
the front of the
front of the queue
z on yx p
nd ieee wireless communications
on yx p qp
ieee wireless communications and
wireless communications and networking
we also compare update
communications and networking conference
z onon yxxy p
onon yxxy p p
yxxy p p qpqp
sirp against a policy
against a policy we
a policy we refer
policy we refer to
achieves its optimum attack
we refer to as
its optimum attack rate
refer to as sirp
optimum attack rate at
z on yx p
on yx p qp
which only differs from
only differs from sirp
differs from sirp in
z time spent on
from sirp in performing
time spent on invalidations
of the pool s
sirp in performing compulsory
the pool s mining
in performing compulsory invalidations
pool s mining power
increasing its revenue by
its revenue by almost
when the server receives
the server receives an
server receives an invalidation
receives an invalidation from
an invalidation from a
invalidation from a date
from a date results
a date results in
date results in an
results in an invalidation
this amounts to a
in an invalidation rpc
amounts to a daily
an invalidation rpc to
to a daily revenue
invalidation rpc to the
a daily revenue increase
rpc to the server
daily revenue increase of
revenue increase of b
average store rpc duration
an adaptive forward error
adaptive forward error correction
forward error correction protocol
error correction protocol for
it makes callbacks to
correction protocol for end
makes callbacks to all
callbacks to all the
to all the other
all the other clients
the other clients that
other clients that cache
clients that cache the
end transport of real
that cache the are
cache the are of
the are of particular
are of particular interest
of particular interest in
particular interest in this
interest in this comparison
usd at the exchange
at the exchange rate
the exchange rate on
exchange rate on that
rate on that date
this represents a considerable
to tell them to
represents a considerable increase
tell them to discard
a considerable increase of
them to discard their
considerable increase of the
to discard their copies
increase of the pools
of the pools net
the pools net revenue
if several clients modify
several clients modify are
clients modify are the
th international conference on
modify are the files
international conference on computer
are the files readers
conference on computer communications
the files readers read
on computer communications and
for the smallest pool
computer communications and networks
how is the performance
is the performance of
the attack is much
the performance of the
attack is much less
performance of the same
is much less profitable
of the same file
to reach the optimum
modifications are serialised in
reach the optimum it
are serialised in the
the optimum it needs
serialised in the order
optimum it needs almost
in the order of
it needs almost a
the order of their
needs almost a third
order of their readers
almost a third of
of their readers and
a third of its
their readers and writers
third of its power
readers and writers affected
of its power for
and writers affected by
its power for attacking
writers affected by stronger
power for attacking but
affected by stronger consistency
for attacking but increases
attacking but increases its
but increases its revenue
increases its revenue density
its revenue density by
revenue density by merely
the client that made
client that made the
that made the update
made the update only
the update only transmits
update only transmits it
only transmits it when
transmits it when it
it when it reaches
when it reaches the
it reaches the head
reaches the head of
the head of the
head of the writeback
of the writeback queue
based loss recovery for
loss recovery for reliable
if another client attempts
recovery for reliable multicast
another client attempts to
for reliable multicast transmission
client attempts to fetch
attempts to fetch the
to fetch the file
v v w w
fetch the file during
v w w ut
the file during the
w w ut v
file during the update
w ut v wv
during the update s
ut v wv ut
the update s experimental
update s experimental setup
s experimental setup writeback
name size discusfish antpool
experimental setup writeback window
size discusfish antpool ghash
the server blocks that
io btchine btcguild eligius
server blocks that client
btchine btcguild eligius others
blocks that client until
that client until the
client until the update
until the update has
the update has arrived
the server also makes
server also makes a
also makes a pull
makes a pull rpc
a pull rpc to
pull rpc to the
rpc to the client
to the client that
the client that experiments
client that experiments were
that experiments were conducted
experiments were conducted in
were conducted in a
conducted in a network
in a network of
a network of five
network of five hosts
one modified the file
instructing it to expedite
it to expedite sending
to expedite sending the
expedite sending the update
end performance evaluation of
one writer client that
writer client that was
client that was responsible
that was responsible for
was responsible for modifying
responsible for modifying when
for modifying when it
modifying when it receives
when it receives the
it receives the pull
receives the pull rpc
graphs for cache consistency
the client begins sending
for cache consistency trace
client begins sending back
begins sending back a
sending back a collection
back a collection of
a collection of files
these graphs show various
graphs show various features
show various features of
various features of the
features of the performance
and three reader clients
of the performance results
three reader clients that
reader clients that only
clients that only read
that only read the
only read the the
th symposium on high
read the the update
symposium on high performance
the the update at
on high performance interconnects
async denotes asynchronous invalidations
the update at the
update at the same
at the same priority
the same priority as
same priority as an
priority as an rpc
as an rpc to
and none no invalidations
an rpc to fetch
rpc to fetch file
to fetch file data
diff denotes differentiated writeback
denotes differentiated writeback priorities
differentiated writeback priorities for
writeback priorities for shared
priorities for shared and
for shared and unshared
shared and unshared files
the bandwidth between the
bandwidth between the writer
between the writer client
the writer client and
and unif denotes uniform
writer client and the
unif denotes uniform priorities
client and the server
and the server that
the server that it
server that it will
that it will be
it will be preferentially
will be preferentially allocated
be preferentially allocated bandwidth
cc is the mfs
is the mfs cache
the mfs cache consistency
mfs cache consistency algorithm
if the update was
the update was set
update was set to
the height of a
height of a bar
of a bar counts
a bar counts the
bar counts the number
end forward error correction
counts the number of
the number of invalidations
the white portion counts
white portion counts the
portion counts the number
counts the number of
the number of server
our experimental setup consisting
experimental setup consisting of
setup consisting of three
international zurich seminar on
consisting of three hosts
zurich seminar on communications
and the reader client
server was already being
was already being written
already being written back
and a writer client
the client increases its
the bandwidth from the
client increases its priority
bandwidth from the reader
from the reader to
the reader to the
reader to the server
to the server was
bandwidth was always set
the server was fixed
was always set to
server was fixed at
so that it can
that it can prevent
it can prevent inconsistencies
can prevent inconsistencies by
prevent inconsistencies by inhibiting
inconsistencies by inhibiting access
by inhibiting access to
and the bandwidth from
inhibiting access to the
the bandwidth from the
access to the file
bandwidth from the writer
to the file by
from the writer to
the file by other
the writer to the
file by other clients
writer to the server
to the server was
the server was varied
server was varied according
was varied according to
as shown in figure
varied according to the
according to the experiment
the writer was configured
writer was configured in
was configured in one
configured in one of
in one of seven
one of seven different
the case for application
of seven different ways
invalidations are used in
are used in fluid
level network striping for
used in fluid replication
network striping for data
striping for data intensive
for data intensive applications
data intensive applications using
intensive applications using high
applications using high speed
synchronous or no invalidations
using high speed wide
high speed wide area
speed wide area networks
and differentiated or uniform
to allow clients to
differentiated or uniform priorities
allow clients to avoid
or uniform priorities for
clients to avoid sending
uniform priorities for writing
to avoid sending data
priorities for writing back
avoid sending data across
for writing back shared
sending data across a
writing back shared and
data across a wide
back shared and unshared
shared and unshared files
the six largest open
six largest open pool
largest open pool sizes
the mfs concurrency control
ieee conference on supercomputing
mfs concurrency control algorithm
open pool sizes as
pool sizes as of
sizes as of january
the server only asks
server only asks the
only asks the client
asks the client for
the client for a
client for a file
for a file s
a file s data
corresponds to asynchronous invalidations
file s data if
to asynchronous invalidations with
s data if another
asynchronous invalidations with differentiated
data if another client
invalidations with differentiated priority
if another client requests
with differentiated priority for
another client requests it
differentiated priority for shared
priority for shared files
both clients access a
clients access a shared
access a shared repository
a shared repository of
shared repository of files
repository of files stored
of files stored on
files stored on the
stored on the file
on the file server
s read staleness at
their optimal infiltration rates
tsunami file transfer protocol
of each pool as
each module has a
each pool as a
module has a descriptor
pool as a fraction
has a descriptor file
as a fraction of
a descriptor file and
a fraction of its
descriptor file and a
fraction of its size
file and a set
and a set of
if it attacked all
it attacked all others
attacked all others without
all others without reciprocation
first international workshop on
international workshop on protocols
workshop on protocols for
and their revenue density
on protocols for fast
their revenue density when
protocols for fast long
revenue density when attacking
module descriptor files are
descriptor files are about
kb in size and
in size and the
t wo p ools
wo p ools we
p ools we proceed
ools we proceed to
we proceed to analyze
proceed to analyze the
to analyze the case
analyze the case where
member files take up
the case where two
files take up an
case where two pools
take up an average
where two pools may
up an average of
two pools may attack
pools may attack each
may attack each other
attack each other and
each other and the
other and the other
and the other miners
the other miners mine
other miners mine solo
the total size of
total size of all
again we have pool
size of all the
of all the files
all the files in
the files in the
files in the collection
in the collection is
the writer workload consists
writer workload consists of
workload consists of the
consists of the writer
of the writer updating
the writer updating modules
controls its infiltration rate
writer updating modules in
its infiltration rate x
updating modules in a
synchronous writeback asynchronous writeback
modules in a random
writeback asynchronous writeback sirp
in a random order
asynchronous writeback sirp c
writeback sirp c sirp
an update to a
update to a module
to a module consists
a module consists of
module consists of a
consists of a sequence
of a sequence of
a sequence of operations
predictable high performance bulk
high performance bulk data
performance bulk data transfer
also controls its infiltration
controls its infiltration rate
its infiltration rate x
of which are reads
which are reads and
staleness of version retrieved
ieee international conference on
international conference on cluster
conference on cluster computing
are writes to a
writes to a file
to a file in
a file in the
file in the module
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the total mining power
total mining power in
mining power in the
power in the system
in the system is
the system is m
system is m x
consist of writes to
of writes to unshared
writes to unshared external
to unshared external files
which are each created
are each created with
each created with a
created with a unique
with a unique name
there is a pause
is a pause between
a pause between each
pause between each operation
between each operation and
each operation and a
operation and a longer
and a longer pause
the direct revenues r
a longer pause between
longer pause between updates
pause between updates to
between updates to modules
the reader workload is
of the pools from
reader workload is similar
the pools from mining
pools from mining are
solomon codes and their
from mining are their
codes and their applications
synchronous writeback asynchronous writeback
but an access to
writeback asynchronous writeback sirp
an access to a
mining are their effective
asynchronous writeback sirp c
are their effective mining
writeback sirp c sirp
access to a module
their effective mining rates
to a module consists
a module consists of
module consists of a
consists of a series
of a series of
a series of reads
and external files are
external files are never
files are never accessed
cumulative proportion of reads
the configuration parameters used
configuration parameters used to
parameters used to generate
used to generate the
to generate the reader
generate the reader and
the reader and writer
reader and writer workload
and writer workload are
writer workload are listed
workload are listed in
are listed in table
the writer workload has
writer workload has a
workload has a nominal
has a nominal duration
a nominal duration of
nominal duration of two
duration of two minutes
while the reader workload
the reader workload is
reader workload is extended
workload is extended to
is extended to terminate
extended to terminate at
nat and packet mangling
to terminate at the
and packet mangling for
terminate at the same
packet mangling for linux
at the same time
the same time as
same time as the
time as the writer
as the writer workload
the writer workload actually
writer workload actually finishes
staleness of version retrieved
of version retrieved read
version retrieved read staleness
two attacking pools system
retrieved read staleness at
since low bandwidth could
low bandwidth could extend
bandwidth could extend its
could extend its running
extend its running time
its running time beyond
running time beyond two
time beyond two minutes
analysis of the results
of the results figure
cumulative proportion of reads
proportion of reads cumulative
of reads cumulative proportion
reads cumulative proportion of
as a function of
shows graphs of some
cumulative proportion of reads
a function of pool
graphs of some selected
function of pool sizes
of some selected results
some selected results from
selected results from the
results from the experiments
while synchronous writes provide
synchronous writes provide strong
writes provide strong concurrency
provide strong concurrency control
they resulted in the
resulted in the lowest
in the lowest rate
the lowest rate of
lowest rate of completed
multicast routing in datagram
rate of completed writes
routing in datagram internetworks
of completed writes in
in datagram internetworks and
completed writes in all
datagram internetworks and extended
writes in all the
internetworks and extended lans
in all the tests
acm transactions on computers
since the writer had
transactions on computers systems
the writer had no
writer had no possibility
had no possibility of
no possibility of over
lapping think time with
think time with asynchronous
time with asynchronous writeback
at all bandwidth levels
all bandwidth levels the
bandwidth levels the mfs
cc algorithm outperformed synchronous
algorithm outperformed synchronous writes
outperformed synchronous writes by
synchronous writes by at
writes by at least
synchronous writeback asynchronous writeback
writeback asynchronous writeback sirp
asynchronous writeback sirp c
writeback sirp c sirp
and was among the
was among the options
among the options with
the options with the
options with the highest
with the highest write
the highest write throughput
this is clear from
is clear from graph
which shows the average
shows the average time
staleness of version retrieved
the average time to
average time to complete
time to complete store
to complete store rpcs
complete store rpcs initiated
store rpcs initiated by
rpcs initiated by the
initiated by the writer
staleness of reader file
of reader file accesses
cc outperforms all of
outperforms all of the
cumulative distributions for the
all of the alternatives
distributions for the staleness
for the staleness of
the staleness of all
staleness of all accesses
this is because of
of all accesses to
is because of the
all accesses to files
because of the reduced
accesses to files by
two pools infiltrating each
of the reduced number
pools infiltrating each other
the reduced number of
to files by the
reduced number of invalidations
files by the three
number of invalidations it
by the three readers
of invalidations it generates
the three readers are
three readers are shown
divided by the total
by the total mining
the total mining rate
higher curves represent less
curves represent less staleness
in contrast to most
contrast to most of
performance enhancing proxies intended
to most of the
total writer execution time
enhancing proxies intended to
most of the other
proxies intended to mitigate
of the other schemes
intended to mitigate link
it is able to
is able to take
able to take advantage
to take advantage of
take advantage of both
advantage of both differentiated
of both differentiated writeback
pull rpcs to raise
rpcs to raise the
to raise the priority
raise the priority of
synchronous writeback asynchronous writeback
the priority of its
writeback asynchronous writeback sirp
priority of its writes
asynchronous writeback sirp c
writeback sirp c sirp
shows the performance from
the performance from the
performance from the reader
from the reader s
the reader s perspective
while the writer is
the writer is able
writer is able to
is able to decrease
able to decrease its
to decrease its time
decrease its time spent
its time spent performing
time spent performing store
spent performing store rpcs
the reader s average
reader s average time
s average time spent
average time spent on
time spent on fetches
spent on fetches increases
synchronous writeback asynchronous writeback
on fetches increases sharply
writeback asynchronous writeback sirp
fetches increases sharply when
asynchronous writeback sirp c
increases sharply when the
writeback sirp c sirp
sharply when the file
when the file in
the file in question
file in question must
in question must be
question must be pulled
must be pulled from
be pulled from the
pulled from the writer
this cost must be
cost must be weighed
the total revenue of
must be weighed against
total revenue of each
be weighed against the
revenue of each pool
udp bandwidth measurement tool
weighed against the benefit
of each pool is
against the benefit of
each pool is its
the benefit of substantially
pool is its direct
benefit of substantially increased
is its direct mining
of substantially increased writer
its direct mining revenue
substantially increased writer throughput
differentiated writeback succeeds in
writeback succeeds in reducing
succeeds in reducing the
and the infiltration revenue
in reducing the time
the infiltration revenue from
reducing the time the
infiltration revenue from the
the time the reader
revenue from the previous
time the reader has
from the previous round
the reader has to
reader has to wait
has to wait when
to wait when accessing
wait when accessing a
which is the attacked
when accessing a shared
is the attacked pool
accessing a shared file
the attacked pool s
attacked pool s total
pool s total revenue
s total revenue multiplied
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
is divided among its
divided among its loyal
show statistics for invalidations
among its loyal miners
statistics for invalidations and
its loyal miners and
for invalidations and serverpull
loyal miners and miners
invalidations and serverpull rpcs
miners and miners that
and serverpull rpcs for
and miners that infiltrated
serverpull rpcs for those
miners that infiltrated it
rpcs for those writer
for those writer configurations
those writer configurations which
writer configurations which make
configurations which make use
at stable state this
which make use of
stable state this is
make use of them
state this is r
cc significantly reduces the
significantly reduces the number
reduces the number of
the number of invalidations
number of invalidations it
of invalidations it must
invalidations it must transmit
a scalable and tcp
it must transmit by
must transmit by putting
transmit by putting off
by putting off invalidating
friendly congestion control for
putting off invalidating a
congestion control for high
off invalidating a file
invalidating a file until
a file until it
file until it is
until it is added
it is added to
is added to the
added to the log
yet the effect of
the effect of this
effect of this policy
of this policy on
this policy on the
policy on the number
on the number of
the number of serverpull
number of serverpull rpcs
of serverpull rpcs is
serverpull rpcs is minor
average reader execution time
which differs from mfs
cc in omitting differentiated
in omitting differentiated writeback
makes more invalidations and
more invalidations and incurs
invalidations and incurs more
and incurs more server
because its store rpcs
its store rpcs must
store rpcs must compete
rpcs must compete with
must compete with the
compete with the rpcs
with the rpcs to
the rpcs to write
rpcs to write back
to write back external
write back external files
this increases the commit
increases the commit delay
the commit delay for
commit delay for each
delay for each file
for each file and
each file and the
file and the likelihood
and the likelihood of
the likelihood of it
likelihood of it being
of it being accessed
it being accessed by
being accessed by the
accessed by the reader
by the reader while
the reader while it
reader while it is
while it is being
we obtain the following
it is being written
obtain the following closed
is being written back
the following closed expressions
following closed expressions for
third international workshop on
closed expressions for each
international workshop on protocols
workshop on protocols for
on protocols for fast
protocols for fast long
we express the revenues
these experiments demonstrate that
express the revenues as
experiments demonstrate that for
the revenues as functions
demonstrate that for the
revenues as functions of
that for the trace
as functions of x
for the trace we
the trace we have
trace we have examined
the mfs algorithm of
execution times for concurrent
times for concurrent access
mfs algorithm of asynchronous
for concurrent access trace
algorithm of asynchronous invalidations
of asynchronous invalidations and
reader execution times are
asynchronous invalidations and differentiated
execution times are averages
times are averages for
invalidations and differentiated writeback
are averages for the
averages for the three
and differentiated writeback is
for the three readers
differentiated writeback is able
writeback is able to
is able to maintain
able to maintain cache
to maintain cache consistency
higher bandwidth results in
maintain cache consistency between
bandwidth results in less
results in less staleness
cache consistency between the
consistency between the two
between the two clients
since writes can be
the two clients and
writes can be sent
two clients and to
can be sent to
clients and to allow
be sent to the
and to allow the
sent to the file
to allow the writer
to the file server
allow the writer to
packet recovery in high
the file server faster
the writer to write
writer to write back
to write back changes
speed networks using coding
write back changes to
networks using coding and
back changes to the
using coding and buffer
changes to the stored
coding and buffer management
to the stored data
the stored data faster
stored data faster than
data faster than is
faster than is possible
than is possible with
is possible with the
possible with the alternative
sirp is most effective
with the alternative schemes
is most effective at
most effective at reducing
effective at reducing staleness
we intend to further
intend to further evaluate
though many reads return
to further evaluate the
many reads return out
further evaluate the perfor
references mance of the
mance of the algorithm
of the algorithm to
date file contents when
the algorithm to determine
file contents when compared
algorithm to determine its
contents when compared to
to determine its effectiveness
when compared to the
determine its effectiveness under
compared to the optimal
its effectiveness under other
to the optimal version
effectiveness under other workloads
and with more clients
more sirp reads are
sirp reads are up
performance evaluation of forward
evaluation of forward error
of forward error correction
forward error correction in
error correction in atm
compared to synchronous or
correction in atm networks
to synchronous or asynchronous
synchronous or asynchronous writeback
allowing higher degrees of
higher degrees of staleness
evaluation of an adaptive
of an adaptive transport
an adaptive transport protocol
in proceedings of the
more reads performed with
reads performed with sirp
performed with sirp are
with sirp are within
nd annual joint conference
annual joint conference of
joint conference of the
versions of the optimal
conference of the ieee
of the ieee computer
the ieee computer and
ieee computer and communications
with this bandwidth level
computer and communications societies
synchronous and asynchronous writeback
and asynchronous writeback coincide
asynchronous writeback coincide in
writeback coincide in performance
since they are constrained
they are constrained by
are constrained by the
constrained by the bandwidth
by the bandwidth bottleneck
the bandwidth bottleneck and
bandwidth bottleneck and send
bottleneck and send updates
and send updates in
send updates in the
updates in the same
in the same order
by suppressing unnecessary invalidations
sirp reduces its bandwidth
reduces its bandwidth usage
its bandwidth usage and
bandwidth usage and achieves
usage and achieves a
and achieves a small
achieves a small improvement
a small improvement over
small improvement over sirp
since devoting less bandwidth
devoting less bandwidth to
less bandwidth to invalidations
bandwidth to invalidations results
to invalidations results in
invalidations results in data
conclusion the growing use
results in data reaching
the growing use of
in data reaching the
growing use of mobile
data reaching the server
use of mobile computers
reaching the server faster
of mobile computers and
mobile computers and wireless
computers and wireless networks
and wireless networks has
wireless networks has greatly
networks has greatly increased
has greatly increased the
asynchronous writeback performs as
greatly increased the scope
writeback performs as well
increased the scope for
performs as well as
the scope for adapting
as well as sirp
scope for adapting data
for adapting data access
adapting data access to
data access to vary
synchronous writeback continues to
writeback continues to underperform
efficient erasure correcting codes
this is because the
is because the progress
because the progress of
the progress of writers
ieee transactions on information
progress of writers using
transactions on information theory
of writers using asynchronous
writers using asynchronous writeback
using asynchronous writeback schemes
asynchronous writeback schemes is
writeback schemes is less
schemes is less constrained
is less constrained by
less constrained by the
constrained by the bandwidth
and they can overlap
they can overlap computation
can overlap computation and
overlap computation and fetching
computation and fetching file
and fetching file contents
fetching file contents with
file contents with writeback
rather than simply being
than simply being a
simply being a selfinterested
being a selfinterested optimisation
each pool controls only
a selfinterested optimisation by
pool controls only its
selfinterested optimisation by writers
controls only its own
optimisation by writers to
only its own infiltration
by writers to improve
its own infiltration rate
writers to improve their
to improve their own
improve their own performance
this paper has explored
in each round of
paper has explored applying
each round of the
has explored applying and
round of the pool
asynchronous writeback therefore benefits
explored applying and j
writeback therefore benefits both
of the pool game
therefore benefits both writers
benefits both writers and
both writers and readers
each pool will optimize
pool will optimize its
will optimize its infiltration
the files shared between
optimize its infiltration rate
files shared between the
its infiltration rate of
measurements of a distributed
shared between the clients
of a distributed file
infiltration rate of the
a distributed file the
between the clients were
distributed file the technique
the clients were divided
rate of the other
file the technique of
clients were divided into
the technique of modeless
technique of modeless adaptation
of modeless adaptation to
modeless adaptation to a
adaptation to a distributed
to a distributed file
acts at step t
a distributed file system
distributed file system system
it optimizes its revenue
optimizes its revenue with
in proceedings of the
its revenue with x
file lengths were randomised
with an average length
an average length of
th acm symposium to
acm symposium to improve
symposium to improve its
to improve its performance
the cache manager for
cache manager for our
manager for our mfs
for our mfs on
our mfs on operating
mfs on operating systems
on operating systems principles
to prevent the clients
prevent the clients falling
the clients falling into
clients falling into lockstep
falling into lockstep in
into lockstep in the
lockstep in the course
in the course of
the course of fetching
course of fetching and
of fetching and writing
fetching and writing back
and writing back the
writing back the files
rd annual ieee symposium
annual ieee symposium on
ieee symposium on foundations
symposium on foundations of
on foundations of computer
foundations of computer science
pacific file system incorporates
file system incorporates features
consisting of selecting a
system incorporates features that
of selecting a random
incorporates features that are
selecting a random file
features that are not
a random file set
that are not present
random file set and
are not present in
file set and performing
not present in existing
set and performing a
present in existing grove
and performing a sequence
performing a sequence of
a sequence of reads
sequence of reads or
of reads or writes
reads or writes on
or writes on files
writes on files in
on files in it
the writer performed a
writer performed a file
performed a file set
a file set operation
file set operation of
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with x
file systems for mobile
systems for mobile hosts
adaptation to bandwidth variation
to bandwidth variation through
bandwidth variation through the
ieee transactions on information
variation through the use
transactions on information theory
through the use of
the use of prioritised
use of prioritised communication
with each access being
each access being equally
access being equally likely
being equally likely to
equally likely to open
likely to open a
to open a file
open a file for
a file for reading
file for reading or
for reading or writing
readers performed a file
performed a file set
a file set operation
file set operation of
o hint genercache consistency
hint genercache consistency protocol
genercache consistency protocol using
consistency protocol using file
protocol using file access
using file access information
file access information to
access information to imation
information to imation through
to imation through speculative
imation through speculative execution
in operating systems prove
operating systems prove performance
file sets were treated
sets were treated as
were treated as hot
an equilibrium exists where
equilibrium exists where neither
exists where neither pool
can improve its revenue
of the file set
improve its revenue by
the file set operations
its revenue by changing
file set operations were
revenue by changing its
set operations were directed
by changing its infiltration
operations were directed to
changing its infiltration rate
were directed to those
directed to those file
to those file sets
read staleness comparing update
any pair of values
staleness comparing update propagation
pair of values x
comparing update propagation schemes
update propagation schemes requires
we have evaluated the
propagation schemes requires a
have evaluated the effect
schemes requires a criterion
evaluated the effect of
requires a criterion for
the effect of these
a criterion for measuring
effect of these features
criterion for measuring the
of these features on
for measuring the staleness
these features on performance
measuring the staleness of
features on performance at
the staleness of file
on performance at varying
staleness of file reads
performance at varying bandwidth
such that arg maxx
at varying bandwidth levels
varying bandwidth levels and
bandwidth levels and under
levels and under both
we identified updates to
and under both synthetic
identified updates to files
under both synthetic and
updates to files by
both synthetic and real
to files by associating
files by associating a
by associating a version
associating a version number
a version number with
version number with each
number with each file
and incrementing it every
incrementing it every time
it every time the
every time the file
time the file was
the file was modified
reads were labelled with
were labelled with the
labelled with the version
with the version number
the version number of
version number of the
number of the file
of the file at
the file at the
file at the time
at the time the
the time the read
time the read occurred
the staleness of a
staleness of a particular
of a particular read
a particular read was
particular read was determined
including a workload emulating
read was determined according
a workload emulating collaborative
was determined according to
workload emulating collaborative data
determined according to an
according to an ideal
to an ideal version
an ideal version number
ideal version number derived
version number derived from
number derived from executing
derived from executing the
from executing the experiment
executing the experiment with
the experiment with all
experiment with all participants
with all participants running
all participants running on
participants running on a
running on a single
on a single host
performance measurements access with
measurements access with high
access with high read
in a real execution
the difference between the
difference between the version
and found that while
between the version number
found that while the
the version number a
that while the of
version number a read
while the of automatic
number a read returns
the of automatic prefetching
a read returns and
read returns and the
returns and the optimal
and the optimal version
in proceedings of the
the optimal version number
proceedings of the isca
optimal version number determines
of the isca interadditional
version number determines how
the isca interadditional costs
number determines how stale
isca interadditional costs imposed
determines how stale the
interadditional costs imposed are
how stale the read
costs imposed are mostly
stale the read is
imposed are mostly hidden
they can have benenational
can have benenational conference
have benenational conference on
shows cumulative distributions for
benenational conference on parallel
cumulative distributions for the
conference on parallel and
distributions for the staleness
on parallel and distributed
for the staleness of
parallel and distributed computfits
the staleness of reads
and distributed computfits which
staleness of reads at
distributed computfits which are
of reads at different
computfits which are very
reads at different writer
which are very visible
improved consistency results in
consistency results in fewer
results in fewer stale
in fewer stale reads
modal nature of ing
nature of ing systems
and this is reflected
this is reflected by
is reflected by a
reflected by a curve
by a curve that
a curve that is
curve that is higher
that is higher on
is higher on the
higher on the left
on the left side
the left side of
left side of the
side of the graph
consistency maintenance cost the
maintenance cost the overhead
cost the overhead of
the overhead of the
overhead of the update
adaptation in mfs allows
of the update propagation
in mfs allows clients
the update propagation schemes
mfs allows clients to
update propagation schemes can
allows clients to adapt
propagation schemes can be
clients to adapt quickly
schemes can be compared
to adapt quickly to
can be compared by
adapt quickly to a
be compared by referring
quickly to a variety
compared by referring to
to a variety of
by referring to the
a variety of bandwidth
referring to the reader
variety of bandwidth conditions
to the reader and
of bandwidth conditions without
the reader and writer
bandwidth conditions without substantial
reader and writer execution
conditions without substantial changes
and writer execution times
without substantial changes in
substantial changes in operation
acknowledgements shown in figure
the feasible region for
reader execution time is
feasible region for the
execution time is the
region for the pool
time is the average
for the pool sizes
is the average for
the pool sizes is
the average for all
pool sizes is m
average for all three
for all three readers
the reduced staleness achievable
reduced staleness achievable by
staleness achievable by sirp
achievable by sirp has
by sirp has little
sirp has little or
has little or no
little or no cost
or no cost compared
no cost compared to
cost compared to asynchronous
compared to asynchronous writeback
to asynchronous writeback with
asynchronous writeback with no
writeback with no invalidations
our evaluation has included
since the writer is
evaluation has included comparisons
the writer is up
has included comparisons of
writer is up to
included comparisons of mfs
comparisons of mfs to
of mfs to cache
mfs to cache manm
the revenue function for
revenue function for ri
function for ri is
for ri is concave
ri is concave in
slower when using sirp
is concave in xi
concave in xi for
in xi for all
xi for all feasible
c compared to sirp
for all feasible values
all feasible values of
feasible values of the
values of the variables
selective invalidation is clearly
invalidation is clearly beneficial
sirp has the highest
ager configurations corresponding to
has the highest average
configurations corresponding to prior
the highest average execution
corresponding to prior work
highest average execution time
and confirmed scale and
but this is because
confirmed scale and performance
this is because it
scale and performance in
is because it provides
and performance in a
because it provides the
performance in a distributed
it provides the best
in a distributed file
provides the best consistency
a distributed file system
the best consistency of
best consistency of all
therefore the solutions for
consistency of all the
the solutions for equations
of all the schemes
acm that there are
that there are situations
there are situations in
are situations in which
if a reader reads
situations in which mfs
a reader reads more
in which mfs would
reader reads more up
which mfs would outperform
mfs would outperform afs
transactions on computer systems
are unique and are
unique and are either
and are either at
are either at the
then it transfers more
either at the borders
it transfers more data
at the borders of
the borders of the
borders of the feasible
of the feasible region
the feasible region or
feasible region or where
region or where ri
the reader execution time
reader execution time for
execution time for each
time for each case
for each case is
each case is proportional
case is proportional to
is proportional to the
proportional to the amount
to the amount of
the amount of data
amount of data transferred
of data transferred between
data transferred between the
from section v we
transferred between the reader
section v we know
between the reader and
v we know that
the reader and server
we know that no
attack is not an
though lack of space
is not an equilibrium
lack of space precludes
not an equilibrium point
of space precludes showing
space precludes showing this
precludes showing this in
showing this in a
this in a graph
since each pool can
each pool can increase
pool can increase its
can increase its revenue
we thank robbert van
increase its revenue by
thank robbert van renesse
its revenue by choosing
revenue by choosing a
by choosing a strictly
choosing a strictly positive
coda and little work
a strictly positive infiltration
strictly positive infiltration rate
emin gu n sirer
these earlier systems were
earlier systems were designed
systems were designed for
rimon barr and stephen
were designed for a
barr and stephen rago
designed for a mobile
and stephen rago for
for a mobile environment
stephen rago for comments
a mobile environment which
rago for comments regarding
mobile environment which is
for comments regarding this
environment which is substantially
comments regarding this work
which is substantially different
is not a solution
not a solution to
a solution to equations
partially connected operafrom that
connected operafrom that available
operafrom that available today
evaluation of an adaptive
of an adaptive transport
an adaptive transport protocol
in proceedings of the
mfs is able to
proceedings of the twenty
is able to provide
able to provide tion
second annual joint conference
nash equilibrium therefore exists
annual joint conference of
equilibrium therefore exists with
joint conference of the
therefore exists with x
conference of the ieee
of the ieee computer
the ieee computer and
ieee computer and communications
computer and communications societies
improved performance in periods
performance in periods of
in periods of high
periods of high network
of high network contention
high network contention by
mofavouring cache validation and
cache validation and rpcs
validation and rpcs to
and rpcs to retrieve
rpcs to retrieve files
to retrieve files over
retrieve files over other
enforcing fairness in a
files over other bile
fairness in a live
over other bile computing
other bile computing with
bile computing with the
computing with the rover
with the rover toolkit
streaming system maya haridasana
ieee transactypes of traffic
we have not compared
have not compared mfs
not compared mfs with
portob and robbert van
the importance of translucence
and robbert van renessea
compared mfs with lbfs
robbert van renessea a
importance of translucence in
van renessea a dept
mfs with lbfs since
of translucence in mobile
with lbfs since tions
translucence in mobile computing
lbfs since tions on
in mobile computing systems
since tions on computers
acm transactions on computer
special issue on mobile
issue on mobile computing
using symbolic computation tools
new york b institute
york b institute of
b institute of informatics
their approaches are orthogonal
we see that there
see that there is
that there is a
there is a single
federal university of rio
is a single pair
university of rio grande
a single pair of
of rio grande do
single pair of values
rio grande do sul
pair of values for
grande do sul porto
of values for which
do sul porto alegre
values for which equation
holds for any feasible
for any feasible choice
any feasible choice of
feasible choice of m
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
analysis confirms these observations
we simulate the pool
simulate the pool game
the pool game for
pool game for a
game for a range
for a range of
edu abstract we describe
abstract we describe a
we describe a practical
describe a practical auditing
a practical auditing approach
practical auditing approach designed
auditing approach designed to
approach designed to encourage
designed to encourage fairness
to encourage fairness in
encourage fairness in peer
not present in the
present in the earlier
in the earlier systems
the earlier systems we
earlier systems we have
systems we have compared
we have compared against
a range of pool
range of pool sizes
auditing is employed to
we anticipate that implementing
tolerant mechanism for distributed
anticipate that implementing lbfs
mechanism for distributed file
for each choice of
for distributed file cache
is employed to ensure
that implementing lbfs file
employed to ensure that
implementing lbfs file chunks
to ensure that correct
lbfs file chunks in
each choice of pool
distributed file cache consistency
ensure that correct nodes
file chunks in mfs
choice of pool sizes
that correct nodes are
chunks in mfs would
correct nodes are able
in proceedings of the
nodes are able to
proceedings of the twelth
we start the simulation
are able to receive
start the simulation when
of the twelth symposium
the simulation when both
able to receive streams
simulation when both pools
the twelth symposium on
when both pools do
to receive streams even
both pools do not
twelth symposium on operating
pools do not infiltrate
receive streams even in
do not infiltrate each
symposium on operating systems
not infiltrate each other
on operating systems principles
streams even in the
even in the presence
in the presence of
the presence of nodes
presence of nodes that
of nodes that do
nodes that do not
that do not upload
do not upload enough
not upload enough data
and scales well when
scales well when compared
well when compared to
when compared to previous
compared to previous solutions
to previous solutions that
previous solutions that rely
solutions that rely on
that rely on tit
further improve performance its
improve performance its performance
and performance in a
performance in a wide
tat style of data
style of data exchange
auditing involves two roles
and the revenue densities
this experiment demonstrates that
the revenue densities are
in proceedin future work
experiment demonstrates that sirp
revenue densities are r
demonstrates that sirp is
that sirp is preferable
sirp is preferable to
is preferable to asynchronous
untrusted local auditors run
preferable to asynchronous writeback
local auditors run on
to asynchronous writeback at
auditors run on all
asynchronous writeback at low
run on all nodes
writeback at low bandwidth
on all nodes in
we plan to investigate
all nodes in the
plan to investigate the
nodes in the system
to investigate the performance
and adds little additional
investigate the performance of
adds little additional overhead
the performance of ings
and are responsible for
performance of ings of
are responsible for collecting
of ings of the
responsible for collecting and
at each round one
for collecting and maintaining
ings of the first
collecting and maintaining accountable
of the first usenix
the difference between asynchronous
the first usenix conference
difference between asynchronous schemes
each round one pool
between asynchronous schemes is
first usenix conference on
asynchronous schemes is minimal
round one pool chooses
usenix conference on file
and maintaining accountable information
conference on file and
one pool chooses its
on file and storage
maintaining accountable information regarding
file and storage modeless
pool chooses its optimal
but any scheme improves
chooses its optimal infiltration
any scheme improves over
accountable information regarding data
scheme improves over synchronous
its optimal infiltration rate
and storage modeless adaptation
optimal infiltration rate based
storage modeless adaptation and
infiltration rate based on
modeless adaptation and mfs
information regarding data sent
improves over synchronous writeback
regarding data sent and
adaptation and mfs in
data sent and received
and mfs in wide
sent and received by
rate based on the
and received by each
based on the pool
received by each node
for the same reasons
on the pool sizes
the same reasons that
area and more web
same reasons that it
the pool sizes and
reasons that it improves
pool sizes and the
that it improves performance
sizes and the rate
and the rate with
the rate with which
one or more trusted
rate with which it
asynchronous writeback reduces staleness
or more trusted global
with which it is
more trusted global auditors
which it is infiltrated
trusted global auditors periodically
and sirp makes it
global auditors periodically sample
sirp makes it an
auditors periodically sample the
makes it an acceptable
periodically sample the state
it an acceptable choice
sample the state of
an acceptable choice at
the state of participating
acceptable choice at low
state of participating nodes
choice at low bandwidth
and we calculate the
we calculate the revenue
calculate the revenue after
the revenue after convergence
estimate whether the streaming
revenue after convergence with
whether the streaming quality
after convergence with equation
the streaming quality is
streaming quality is satisfactory
and decide whether any
decide whether any actions
whether any actions are
any actions are required
as well as further
recall the players in
well as further evaluating
the players in the
as further evaluating the
players in the pool
further evaluating the performance
in the pool game
evaluating the performance of
the pool game are
the performance of the
we demonstrate through simulation
performance of the mfs
pool game are chosen
of the mfs cache
game are chosen with
the mfs cache consistency
are chosen with the
mfs cache consistency algorithm
chosen with the round
demonstrate through simulation that
with the round robin
through simulation that our
the round robin policy
we also intend to
simulation that our approach
also intend to use
that our approach can
our approach can successfully
so the pools take
approach can successfully detect
the pools take turns
can successfully detect and
successfully detect and react
detect and react to
and react to the
and we let the
react to the presence
we let the game
to the presence of
let the game run
the presence of opportunistic
the game run until
presence of opportunistic nodes
game run until convergence
of opportunistic nodes in
opportunistic nodes in streaming
nodes in streaming sessions
the results are illustrated
results are illustrated in
are illustrated in figure
it incurs low network
incurs low network and
low network and computational
disconnected operamfs to further
network and computational overheads
each run with some
operamfs to further examine
run with some m
to further examine the
further examine the benefits
which remain fixed as
examine the benefits achievable
remain fixed as the
the benefits achievable from
fixed as the system
benefits achievable from the
as the system scales
achievable from the autotion
from the autotion in
the autotion in the
autotion in the coda
values results in a
scale and performance in
results in a single
and performance in a
in the coda file
performance in a distributed
the coda file system
in a distributed file
in a single point
a distributed file system
a single point in
single point in each
introduction video and audio
point in each graph
video and audio streaming
in each graph in
acm transactions on commatic
acm transactions on computer
transactions on commatic generation
transactions on computer systems
on commatic generation of
each graph in figure
commatic generation of caching
and audio streaming account
generation of caching policies
audio streaming account for
of caching policies for
streaming account for a
caching policies for files
account for a large
for a large percentage
we depict the infiltration
a large percentage of
depict the infiltration rates
large percentage of content
the infiltration rates of
percentage of content accessed
infiltration rates of both
of content accessed over
rates of both pools
content accessed over the
of both pools x
accessed over the web
one popular style of
popular style of streaming
style of streaming on
of streaming on the
streaming on the web
on the web is
the web is on
web is on demand
in which users access
which users access pre
stored content at will
another style requires streams
style requires streams to
requires streams to be
streams to be generated
to be generated and
be generated and disseminated
b and the pools
generated and disseminated in
and the pools revenue
and disseminated in real
the pools revenue densities
pools revenue densities r
this may be the
may be the case
be the case with
the case with important
case with important social
an important property of
important property of live
for each choice of
each choice of m
streaming is that data
is that data is
that data is not
data is not available
is not available in
not available in advance
being generated just before
the values of x
generated just before transmission
just before transmission at
before transmission at the
automated hoarding for mobile
transmission at the sender
hoarding for mobile computers
in proceedings of the
proceedings of the sixteenth
of the sixteenth acm
the sixteenth acm symposium
interested users ideally want
sixteenth acm symposium on
users ideally want to
acm symposium on operating
ideally want to receive
symposium on operating systems
want to receive the
on operating systems principles
to receive the stream
receive the stream without
the stream without much
stream without much delay
without much delay from
much delay from its
delay from its original
from its original transmission
are the points in
the points in each
points in each of
in each of the
streaming systems now allow
each of the graphs
systems now allow large
of the graphs with
now allow large numbers
the graphs with the
allow large numbers of
graphs with the respective
large numbers of interested
with the respective coordinates
numbers of interested users
of interested users to
interested users to receive
users to receive streamed
to receive streamed data
receive streamed data in
streamed data in near
data in near real
in near real time
j graphs we draw
graphs we draw a
we draw a border
draw a border around
without requiring extensive amounts
a border around the
requiring extensive amounts of
border around the region
extensive amounts of resources
around the region where
the region where there
region where there is
where there is no
these systems are based
systems are based on
are based on the
based on the peer
attack by i in
by i in equilibrium
acknowledgements we would like
we would like to
for the ri graphs
would like to thank
the ri graphs we
like to thank robbert
ri graphs we draw
to thank robbert van
graphs we draw a
thank robbert van renesse
we draw a line
draw a line around
a line around the
line around the region
around the region where
the region where the
emin gu n sirer
region where the revenue
gu n sirer and
where nodes interested in
where the revenue is
nodes interested in receiving
the revenue is the
interested in receiving data
revenue is the same
in receiving data also
n sirer and paul
mobile computing with the
sirer and paul francis
receiving data also help
and paul francis for
data also help disseminate
paul francis for comments
also help disseminate it
francis for comments and
help disseminate it to
for comments and suggestions
disseminate it to each
comments and suggestions regarding
computing with the rover
and suggestions regarding mfs
with the rover toolkit
is the same as
it to each other
the same as in
same as in the
we also thank rimon
as in the no
ieee transactions on computers
also thank rimon barr
alleviating the bottleneck at
the bottleneck at the
bottleneck at the source
initial protocols were based
protocols were based on
and kevin walsh for
were based on building
kevin walsh for helpful
based on building a
walsh for helpful discussions
on building a tree
for helpful discussions and
we first observe that
helpful discussions and corrections
first observe that only
discussions and corrections to
observe that only in
and corrections to this
that only in extreme
corrections to this paper
based overlay of nodes
only in extreme cases
overlay of nodes through
in extreme cases a
of nodes through which
extreme cases a pool
nodes through which data
cases a pool does
through which data would
a pool does not
which data would be
pool does not attack
data would be pushed
does not attack its
not attack its counterpart
at equilibrium a pool
equilibrium a pool will
a pool will refrain
pool will refrain from
will refrain from attacking
such as chainsaw and
refrain from attacking only
as chainsaw and coolstreaming
from attacking only if
attacking only if the
only if the other
if the other pool
the other pool is
have shown that the
other pool is larger
shown that the use
pool is larger than
that the use of
is larger than about
the use of a
use of a mesh
of a mesh of
a mesh of connected
mesh of connected nodes
of connected nodes and
connected nodes and a
nodes and a pull
of the total mining
based data dissemination approach
the total mining power
data dissemination approach can
dissemination approach can provide
approach can provide similar
a coherent distributed file
can provide similar results
coherent distributed file cache
provide similar results with
distributed file cache with
similar results with better
file cache with directory
results with better resilience
cache with directory write
with better resilience to
better resilience to failures
we observe that a
resilience to failures and
observe that a pool
to failures and churn
that a pool improves
a pool improves its
pool improves its revenue
acm transactions on computer
improves its revenue compared
transactions on computer systems
its revenue compared to
nodes joining and leaving
revenue compared to the
joining and leaving the
compared to the no
and leaving the system
attacks scenario only when
scenario only when it
only when it controls
when it controls a
it controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
and performance in a
nodes notify each other
these are the small
notify each other of
are the small triangular
each other of receipt
performance in a wide
the small triangular regions
other of receipt of
small triangular regions in
of receipt of data
triangular regions in figures
receipt of data packets
in proceedings of the
and request packets from
proceedings of the first
request packets from their
of the first usenix
packets from their neighbors
the first usenix conference
from their neighbors based
first usenix conference on
their neighbors based on
usenix conference on file
neighbors based on the
conference on file and
based on the received
in the rest of
on the received notifications
the rest of the
on file and storage
rest of the space
file and storage technologies
practical systems based on
systems based on pull
the trapezoids in the
trapezoids in the figures
based streaming now exist
streaming now exist in
now exist in china
the revenue of the
revenue of the pool
of the pool is
the pool is inferior
pool is inferior compared
where they are used
is inferior compared to
they are used to
inferior compared to the
are used to disseminate
compared to the no
used to disseminate television
to disseminate television channels
disseminate television channels to
television channels to thousands
channels to thousands of
to thousands of users
the prisoner s dilemma
this paper has described
prisoner s dilemma in
even though the p
s dilemma in a
paper has described mafs
dilemma in a healthy
in a healthy bitcoin
a healthy bitcoin environment
p paradigm allows systems
paradigm allows systems to
a new file system
allows systems to scale
new file system for
systems to scale with
where neither pool controls
to scale with the
file system for mobile
neither pool controls a
system for mobile clients
pool controls a strict
scale with the number
controls a strict majority
with the number of
a strict majority of
the number of users
strict majority of the
for mobile clients that
a lowbandwidth network file
majority of the mining
mobile clients that is
of the mining power
it also leaves them
lowbandwidth network file system
also leaves them vulnerable
clients that is tailored
leaves them vulnerable to
that is tailored for
both pools will earn
them vulnerable to opportunistic
in proceedings of the
vulnerable to opportunistic behavior
proceedings of the seventeenth
pools will earn less
of the seventeenth acm
is tailored for wireless
the seventeenth acm symposium
will earn less at
tailored for wireless networks
earn less at equilibrium
opportunistic nodes attempt to
less at equilibrium than
for wireless networks by
at equilibrium than if
nodes attempt to receive
equilibrium than if both
wireless networks by incorporating
than if both pools
attempt to receive a
seventeenth acm symposium on
to receive a stream
acm symposium on operating
receive a stream without
symposium on operating systems
a stream without uploading
on operating systems principles
networks by incorporating automatic
if both pools ran
by incorporating automatic adaptation
both pools ran without
stream without uploading their
incorporating automatic adaptation to
without uploading their fair
pools ran without attacking
automatic adaptation to the
uploading their fair share
adaptation to the available
their fair share of
to the available bandwidth
fair share of data
we can analyze in
can analyze in this
reducing the overall upload
mafs differs from previous
analyze in this case
differs from previous designs
the overall upload capacity
from previous designs in
overall upload capacity of
in this case a
upload capacity of the
previous designs in making
this case a game
designs in making use
capacity of the system
in making use of
case a game where
making use of asynchronous
a game where each
use of asynchronous writeback
game where each pool
of asynchronous writeback at
where each pool chooses
asynchronous writeback at all
each pool chooses either
writeback at all bandwidth
pool chooses either to
despite the damage that
chooses either to attack
at all bandwidth levels
either to attack and
the damage that they
to attack and optimize
damage that they may
attack and optimize its
that they may cause
and optimize its revenue
rather than switching from
than switching from synchronous
switching from synchronous to
not much work has
from synchronous to asynchronous
much work has been
synchronous to asynchronous writeback
or to refrain from
to asynchronous writeback when
to refrain from attacking
asynchronous writeback when bandwidth
work has been done
writeback when bandwidth is
has been done in
when bandwidth is insufficient
been done in studying
done in studying mechanisms
in studying mechanisms to
studying mechanisms to avoid
without loss of generality
rpc priorities and a
mechanisms to avoid their
priorities and a new
to avoid their presence
and a new update
avoid their presence in
a new update propagation
their presence in live
as we have seen
new update propagation algorithm
we have seen in
have seen in section
seen in section v
the goal of this
reduce a client s
goal of this the
a client s contention
of this the authors
client s contention for
this the authors were
s contention for wireless
the authors were supported
caching in the sprite
contention for wireless bandwidth
in the sprite network
authors were supported by
the sprite network file
were supported by afrl
can increase its revenue
supported by afrl award
increase its revenue above
by afrl award fa
sprite network file system
and permit a degree
permit a degree of
a degree of consistency
degree of consistency that
acm transactions on computer
of consistency that is
transactions on computer systems
consistency that is equivalent
that is equivalent to
is equivalent to instantaneous
equivalent to instantaneous propagation
does attack but pool
to instantaneous propagation of
instantaneous propagation of updates
experiments demonstrate that these
we denote the revenue
demonstrate that these techniques
denote the revenue of
that these techniques allow
the revenue of pool
these techniques allow mafs
techniques allow mafs to
allow mafs to achieve
mafs to achieve performance
to achieve performance that
achieve performance that is
performance that is at
that is at least
is at least equal
at least equal to
the exact value of
exact value of r
and in most cases
in most cases superior
depends on the values
most cases superior to
on the values of
cases superior to that
the values of m
superior to that achievable
to that achievable by
that achievable by conventional
achievable by conventional file
by conventional file system
conventional file system designs
file system designs that
system designs that switch
designs that switch between
that switch between lowand
switch between lowand high
but it is always
it is always smaller
is always smaller than
always smaller than one
bandwidth modes according to
modes according to thresholds
as we have seen
we have seen above
mafs is therefore able
is therefore able to
therefore able to make
able to make efficient
to make efficient use
make efficient use of
does choose to attack
efficient use of the
use of the network
of the network and
the network and provide
network and provide predictable
and provide predictable file
provide predictable file system
predictable file system semantics
but does not surpass
does not surpass one
regardless of the available
of the available bandwidth
the game is summarized
game is summarized in
is summarized in figure
this is the classical
is the classical prisoner
the classical prisoner s
classical prisoner s dilemma
attack is the dominant
is the dominant strategy
chooses to attack or
to attack or not
automated hoarding for mobile
hoarding for mobile computers
the revenue of pool
in proceedings of the
proceedings of the sixteenth
of the sixteenth acm
is larger when attacking
the sixteenth acm symposium
larger when attacking than
sixteenth acm symposium on
when attacking than when
acm symposium on operating
attacking than when refraining
symposium on operating systems
than when refraining from
on operating systems principles
when refraining from attack
and the same for
the same for pool
at equilibrium of this
equilibrium of this attack
perspectives on optimistically replicated
on optimistically replicated peer
when both pools attack
the revenue of each
revenue of each pool
of each pool is
software practice and experience
each pool is smaller
pool is smaller than
is smaller than its
smaller than its revenue
than its revenue if
its revenue if neither
revenue if neither pool
if neither pool attacked
the game is not
game is not played
is not played once
where each pool can
each pool can change
pool can change its
can change its strategy
change its strategy between
its strategy between attack
strategy between attack and
between attack and no
the pools can agree
to refrain from attacking
exploiting weak connectivity for
weak connectivity for mobile
connectivity for mobile file
for mobile file access
the views and conclusions
views and conclusions herein
and in each round
and conclusions herein are
in each round xxx
conclusions herein are those
in proceedings of the
herein are those of
each round xxx xxx
proceedings of the fifteenth
are those of the
of the fifteenth acm
those of the authors
the fifteenth acm symposium
round xxx xxx pool
fifteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
no attack xxx pool
informed prefetching and caching
in proceedings of the
proceedings of the fifteenth
of the fifteenth acm
the fifteenth acm symposium
fifteenth acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
bandwidth network file system
minimum and average download
in proceedings of the
and average download rates
proceedings of the eighteenth
average download rates across
of the eighteenth acm
download rates across all
the eighteenth acm symposium
rates across all nodes
eighteenth acm symposium on
across all nodes when
acm symposium on operating
all nodes when using
symposium on operating systems
nodes when using the
on operating systems principles
when using the bar
using the bar gossip
the bar gossip and
bar gossip and chainsaw
gossip and chainsaw protocols
paper is to propose
is to propose and
to propose and evaluate
propose and evaluate a
and evaluate a mechanism
evaluate a mechanism that
a mechanism that can
mechanism that can defend
that can defend against
can defend against this
defend against this problem
whithout incurring large overheads
the approach that most
design and implementation of
approach that most closely
and implementation of the
that most closely relates
implementation of the sun
most closely relates to
of the sun network
closely relates to our
the sun network file
relates to our work
sun network file system
prisoner s dilemma for
to our work is
s dilemma for two
our work is the
dilemma for two pools
work is the bar
in proceedings of usenix
is the bar gossip
proceedings of usenix summer
the bar gossip protocol
of usenix summer conference
the revenue density of
revenue density of each
density of each pool
of each pool is
each pool is determined
pool is determined by
which employs a tit
is determined by the
determined by the decision
by the decision of
the decision of both
decision of both pools
of both pools whether
both pools whether to
tat approach for encouraging
pools whether to attack
approach for encouraging nodes
whether to attack or
for encouraging nodes to
to attack or not
encouraging nodes to contribute
the dominant strategy of
a node only sends
dominant strategy of each
node only sends as
strategy of each player
only sends as much
of each player is
sends as much data
each player is to
as much data to
player is to attack
much data to another
data to another node
to another node as
another node as it
node as it receives
however the payoff of
as it receives back
the payoff of both
payoff of both would
of both would be
both would be larger
the evolution of coda
would be larger if
it provides an elegant
be larger if they
provides an elegant solution
larger if they both
acm transactions on computer
if they both refrain
transactions on computer systems
an elegant solution shown
they both refrain from
elegant solution shown to
both refrain from attacking
solution shown to tolerate
shown to tolerate both
to tolerate both opportunistic
tolerate both opportunistic behavior
a pool can detect
both opportunistic behavior and
pool can detect whether
opportunistic behavior and other
can detect whether it
behavior and other malicious
detect whether it is
and other malicious attacks
whether it is being
it is being attacked
is being attacked and
being attacked and deduce
attacked and deduce that
and deduce that the
deduce that the other
that the other pool
the other pool is
other pool is violating
pool is violating the
is violating the agreement
tat does present a
does present a few
present a few undesirable
a few undesirable requirements
managing update conflicts in
update conflicts in bayou
cooperation where neither pool
where neither pool attacks
neither pool attacks is
pool attacks is a
a weakly connected replicated
attacks is a possible
weakly connected replicated storage
is a possible stable
the data source should
a possible stable state
connected replicated storage system
data source should ensure
source should ensure that
should ensure that packets
ensure that packets are
in proceedings of the
that packets are evenly
proceedings of the fifteenth
packets are evenly spread
of the fifteenth acm
are evenly spread across
the fifteenth acm symposium
evenly spread across the
fifteenth acm symposium on
spread across the system
acm symposium on operating
across the system by
symposium on operating systems
the system by sending
on operating systems principles
system by sending data
by sending data to
sending data to a
data to a fixed
to a fixed proportion
a fixed proportion of
fixed proportion of nodes
and by sending different
by sending different packets
sending different packets to
different packets to different
packets to different nodes
despite the fact that
the fact that the
fact that the single
that the single nash
the single nash equilibrium
single nash equilibrium in
nash equilibrium in every
equilibrium in every round
it requires the source
in every round is
requires the source and
every round is to
the source and all
round is to attack
source and all nodes
determinism and asynchrony of
and all nodes to
and asynchrony of set
all nodes to have
asynchrony of set iterators
nodes to have full
of set iterators to
to have full membership
set iterators to reduce
have full membership knowledge
iterators to reduce aggregrate
to reduce aggregrate file
reduce aggregrate file i
case as an example
these restrictions affect scalability
as an example we
restrictions affect scalability when
an example we take
affect scalability when the
example we take again
scalability when the data
we take again the
when the data source
take again the pool
in proceedings of the
again the pool sizes
the data source has
the pool sizes shown
proceedings of the sixteenth
pool sizes shown in
data source has bounded
of the sixteenth acm
source has bounded upload
sizes shown in figure
has bounded upload bandwidth
the sixteenth acm symposium
sixteenth acm symposium on
acm symposium on operating
symposium on operating system
on operating system principles
to illustrate this problem
and study the case
study the case where
we fixed the upload
the case where the
fixed the upload capacity
case where the two
the upload capacity of
where the two largest
upload capacity of a
the two largest pools
capacity of a data
of a data source
a data source at
file system usage in
system usage in windows
usage in windows nt
mbps and simulated bar
and simulated bar gossip
simulated bar gossip when
bar gossip when streaming
the optimal infiltration rates
out of the total
of the total system
the total system mining
total system mining power
in proceedings of the
kbps with increasing numbers
proceedings of the seventeenth
with increasing numbers of
of the seventeenth acm
increasing numbers of receivers
the seventeenth acm symposium
seventeenth acm symposium on
acm symposium on operating
symposium on operating systems
varied between one and
on operating systems principles
between one and thirty
one and thirty thousand
and thirty thousand nodes
we compare its scalability
compare its scalability against
its scalability against the
scalability against the chainsaw
against the chainsaw protocol
and the pools would
the pools would lose
for which we fixed
which we fixed the
we fixed the source
fixed the source s
the source s upload
source s upload bandwidth
s upload bandwidth to
file system usage in
system usage in windows
usage in windows nt
we present the average
present the average and
the average and minimum
average and minimum download
compared to the no
and minimum download rates
as ratios of the
ratios of the stream
of the stream rate
in proceedings of the
proceedings of the seventeenth
of the seventeenth acm
the seventeenth acm symposium
q i dentical p
seventeenth acm symposium on
of both protocols when
acm symposium on operating
i dentical p ools
symposium on operating systems
both protocols when the
on operating systems principles
dentical p ools let
protocols when the number
p ools let there
when the number of
ools let there be
the number of nodes
let there be q
number of nodes is
there be q pools
of nodes is increased
be q pools of
q pools of identical
pools of identical size
of identical size that
identical size that engage
size that engage in
that engage in block
engage in block withholding
bar gossip is not
in block withholding against
gossip is not able
block withholding against one
is not able to
withholding against one another
not able to sustain
able to sustain its
to sustain its performance
sustain its performance without
other miners neither attack
its performance without scaling
miners neither attack nor
performance without scaling the
neither attack nor are
without scaling the upload
attack nor are being
scaling the upload capacity
nor are being attacked
the upload capacity of
upload capacity of the
capacity of the source
of the source proportionally
in this case there
the source proportionally with
this case there exists
source proportionally with the
case there exists a
proportionally with the size
there exists a symmetric
with the size of
exists a symmetric equilibrium
the size of the
size of the system
without loss of generality
chainsaw is able to
is able to scale
a step of pool
able to scale well
to scale well even
scale well even with
well even with a
even with a fixed
with a fixed lower
a fixed lower upload
fixed lower upload bandwidth
it controls its attack
lower upload bandwidth at
controls its attack rates
upload bandwidth at the
its attack rates each
bandwidth at the source
attack rates each of
rates each of the
each of the other
of the other pools
but cannot handle the
arla a free afs
cannot handle the presence
a free afs client
handle the presence of
and due to symmetry
the presence of opportunistic
due to symmetry they
presence of opportunistic nodes
to symmetry they are
in proceedings of the
symmetry they are all
they are all the
are all the same
we propose to use
propose to use auditing
to use auditing to
use auditing to encourage
auditing to encourage data
streaming systems like chainsaw
the attack rate of
attack rate of pool
our auditing approach establishes
auditing approach establishes a
against any other pool
approach establishes a minimum
establishes a minimum threshold
a minimum threshold for
each of the other
minimum threshold for the
of the other pools
threshold for the amount
the other pools can
for the amount of
other pools can attack
the amount of data
pools can attack its
amount of data sent
can attack its peers
of data sent by
attack its peers as
data sent by any
its peers as well
sent by any node
by any node in
any node in the
node in the system
all attack rates by
attack rates by all
rates by all attackers
and removes nodes that
by all attackers are
removes nodes that upload
all attackers are identical
nodes that upload less
that upload less data
upload less data than
less data than the
data than the threshold
instead of relying on
of relying on a
relying on a tit
the attack rate of
attack rate of any
rate of any pool
of any pool other
any pool other than
against any other pool
we focus on encouraging
focus on encouraging nodes
on encouraging nodes to
encouraging nodes to respect
nodes to respect the
to respect the established
respect the established protocol
volume leases for consistency
nodes are forced to
leases for consistency in
are forced to provide
for consistency in large
forced to provide accountable
to provide accountable information
provide accountable information regarding
accountable information regarding packets
information regarding packets sent
regarding packets sent to
packets sent to and
sent to and received
ieee transactions on knowledge
to and received from
transactions on knowledge and
and received from neighbors
on knowledge and data
the direct revenue of
knowledge and data engineering
direct revenue of each
revenue of each of
and the auditing system
of each of the
the auditing system is
each of the other
auditing system is responsible
of the other pools
system is responsible for
is responsible for detecting
responsible for detecting and
for detecting and removing
similarly denote by r
detecting and removing misbehaving
and removing misbehaving nodes
notice that identifying the
that identifying the misbehaving
the revenue densities of
identifying the misbehaving nodes
revenue densities of pool
the misbehaving nodes is
misbehaving nodes is not
nodes is not a
is not a trivial
not a trivial task
since there is no
there is no fixed
is no fixed minimum
no fixed minimum amount
fixed minimum amount of
minimum amount of data
amount of data that
of data that nodes
data that nodes should
that nodes should contribute
are instantiated to mi
nodes should contribute to
should contribute to the
contribute to the system
if we assume a
we assume a model
assume a model where
a model where misbehaving
model where misbehaving nodes
where misbehaving nodes simply
misbehaving nodes simply did
nodes simply did not
simply did not upload
did not upload any
not upload any data
detecting them would be
them would be an
would be an easier
be an easier task
once we assume that
we assume that misbehaving
assume that misbehaving nodes
that misbehaving nodes may
misbehaving nodes may adjust
nodes may adjust their
may adjust their contribution
adjust their contribution level
their contribution level based
contribution level based on
level based on the
based on the policy
on the policy used
the policy used by
policy used by an
used by an auditing
by an auditing system
a more elaborate approach
more elaborate approach is
elaborate approach is required
this paper presents and
paper presents and evaluates
presents and evaluates an
and evaluates an auditing
evaluates an auditing model
an auditing model based
auditing model based on
model based on sampling
based on sampling the
on sampling the system
sampling the system and
the system and using
system and using the
and using the sampled
using the sampled information
the sampled information to
sampled information to build
information to build a
to build a global
build a global view
a global view of
software defined networks and
global view of how
view of how the
defined networks and gossip
of how the system
how the system is
networks and gossip protocols
the system is currently
system is currently behaving
and gossip protocols robert
gossip protocols robert soule
protocols robert soule ken
robert soule ken birman
soule ken birman nate
ken birman nate foster
auditors employ strategies to
birman nate foster university
employ strategies to identify
nate foster university of
strategies to identify the
foster university of lugano
to identify the misbehaving
university of lugano cornell
identify the misbehaving nodes
of lugano cornell university
the misbehaving nodes that
lugano cornell university cornell
misbehaving nodes that should
cornell university cornell university
nodes that should be
university cornell university the
that should be punished
cornell university the performance
university the performance of
the performance of data
the paper is organized
paper is organized as
is organized as follows
center applications are critically
applications are critically dependent
are critically dependent on
critically dependent on the
dependent on the underlying
on the underlying network
we state the exact
state the exact problem
given the complexities associated
the exact problem that
the complexities associated with
exact problem that we
complexities associated with management
problem that we aim
that we aim to
we aim to solve
aim to solve and
to solve and the
networks today typically provide
solve and the assumptions
today typically provide little
and the assumptions considered
typically provide little more
the assumptions considered in
provide little more than
assumptions considered in this
little more than best
considered in this work
effort packet delivery between
packet delivery between hosts
symmetric case we have
the emergence of software
case we have r
we review the pull
based streaming protocol employed
streaming protocol employed in
protocol employed in our
employed in our system
has created an opportunity
followed by a description
created an opportunity to
by a description of
an opportunity to build
a description of our
opportunity to build more
the expression is shown
description of our novel
to build more dynamic
of our novel auditing
expression is shown in
build more dynamic networks
is shown in equation
our novel auditing approach
more dynamic networks that
novel auditing approach in
dynamic networks that can
auditing approach in section
networks that can be
that can be tailored
can be tailored precisely
be tailored precisely to
tailored precisely to the
precisely to the needs
to the needs of
the needs of applications
we evaluate the proposed
existing solutions for monitoring
evaluate the proposed approach
solutions for monitoring within
for monitoring within sdns
monitoring within sdns suffer
within sdns suffer from
sdns suffer from several
given any value of
we then discuss the
any value of q
suffer from several short
then discuss the costs
value of q and
discuss the costs of
of q and mi
the costs of auditing
either they are inaccurate
and briefly describe how
briefly describe how to
describe how to extend
how to extend our
due to eventual consistency
to extend our model
to eventual consistency of
extend our model for
eventual consistency of architecture
our model for heterogeneous
model for heterogeneous systems
the feasible range of
feasible range of the
range of the infiltration
of the infiltration rates
the infiltration rates is
we present related work
present related work in
related work in section
due to limitations of
to limitations of current
limitations of current hardware
and conclude in section
within this range ri
this range ri is
range ri is continuous
and concave in x
or too costly to
too costly to be
problem statement our approach
costly to be practical
statement our approach focuses
to be practical at
our approach focuses on
be practical at scale
approach focuses on a
focuses on a target
on a target streaming
a target streaming system
due to reliance on
target streaming system consisting
to reliance on switch
streaming system consisting of
reliance on switch forwarding
system consisting of one
on switch forwarding rules
consisting of one data
switch forwarding rules and
of one data source
forwarding rules and centralization
the optimal point for
optimal point for pool
which disseminates data at
disseminates data at a
data at a fixed
we argue that gossip
at a fixed rate
argue that gossip protocols
a fixed rate to
that gossip protocols offer
fixed rate to a
gossip protocols offer an
rate to a dynamic
protocols offer an ideal
to a dynamic set
offer an ideal alternative
a dynamic set of
an ideal alternative for
dynamic set of receivers
ideal alternative for sdn
alternative for sdn monitoring
the source has limited
source has limited upload
due to their scalability
has limited upload bandwidth
since the function is
to their scalability and
the function is concave
their scalability and resiliency
function is concave the
is concave the equation
and hence can only
concave the equation yields
hence can only send
the equation yields a
can only send data
equation yields a single
only send data directly
yields a single feasible
ignored the crucial monitoring
send data directly to
a single feasible solution
data directly to a
the crucial monitoring component
directly to a small
crucial monitoring component that
to a small subset
monitoring component that aggregates
a small subset of
which is a function
small subset of interested
component that aggregates network
is a function of
that aggregates network and
subset of interested receivers
aggregates network and application
a function of the
network and application state
function of the attack
of the attack rates
the attack rates of
participating nodes are consequently
and sends the events
attack rates of the
nodes are consequently required
sends the events to
are consequently required to
the events to the
consequently required to forward
events to the controller
required to forward packets
rates of the other
to forward packets to
of the other pools
forward packets to their
packets to their neighbors
a complete system would
complete system would have
system would have a
would have a closed
have a closed loop
helping disseminate all packets
disseminate all packets across
all packets across the
packets across the system
continuously monitoring applications and
monitoring applications and the
applications and the network
the streamed data should
streamed data should be
data should be received
should be received by
be received by all
then adjusting sdn policies
received by all nodes
adjusting sdn policies to
by all nodes within
sdn policies to optimize
all nodes within a
policies to optimize the
nodes within a fixed
to optimize the use
within a fixed latency
to find a symmetric
a fixed latency from
optimize the use of
fixed latency from the
the use of resources
latency from the source
find a symmetric equilibrium
from the source s
the source s original
source s original transmission
gossip protocols are an
protocols are an ideal
are an ideal choice
an ideal choice for
even in the presence
ideal choice for implementing
in the presence of
choice for implementing a
the presence of opportunistic
for implementing a wide
presence of opportunistic nodes
implementing a wide range
a wide range monitoring
wide range monitoring tasks
with a gossip protocol
we first assume a
first assume a system
assume a system in
a system in which
each node exchanges information
system in which all
node exchanges information with
in which all nodes
exchanges information with a
information with a randomly
with a randomly selected
a randomly selected peer
randomly selected peer at
selected peer at periodic
peer at periodic intervals
have similar upload and
similar upload and download
upload and download bandwidths
because it is based
and obtain a single
it is based on
obtain a single feasible
is based on periodic
a single feasible solution
based on periodic peer
the equilibrium infiltration rate
equilibrium infiltration rate and
infiltration rate and the
rate and the matching
and the matching revenues
the matching revenues are
matching revenues are shown
gossip s network load
revenues are shown in
s network load tends
are shown in equation
network load tends to
load tends to be
we briefly discuss how
tends to be well
briefly discuss how to
discuss how to extend
how to extend our
to extend our model
extend our model to
our model to work
model to work in
to work in heterogeneous
scaling linearly with system
work in heterogeneous scenarios
linearly with system size
with system size and
system size and not
size and not prone
and not prone to
we assume that malicious
not prone to reactive
assume that malicious nodes
prone to reactive feedback
that malicious nodes exhibit
malicious nodes exhibit byzantine
nodes exhibit byzantine behavior
as in the two
while correct nodes follow
because peers are selected
correct nodes follow the
peers are selected randomly
nodes follow the protocol
follow the protocol as
the protocol as defined
the revenue at the
no single node is
revenue at the symmetric
single node is indispensable
at the symmetric equilibrium
requesting data as needed
the symmetric equilibrium is
data as needed and
symmetric equilibrium is inferior
as needed and sending
equilibrium is inferior to
so tools built on
is inferior to the
needed and sending data
tools built on gossip
and sending data as
inferior to the no
sending data as requested
built on gossip are
data as requested from
on gossip are extremely
as requested from them
gossip are extremely tolerant
are extremely tolerant to
extremely tolerant to disruptions
tolerant to disruptions and
to disruptions and able
altrustic nodes are a
disruptions and able to
nodes are a subgroup
and able to rapidly
are a subgroup of
able to rapidly recover
a subgroup of correct
to rapidly recover from
subgroup of correct nodes
rapidly recover from failures
of correct nodes that
correct nodes that are
nodes that are willing
that are willing to
although individual gossip protocols
are willing to upload
individual gossip protocols are
willing to upload more
gossip protocols are typically
up our analysis addresses
to upload more data
our analysis addresses the
upload more data than
analysis addresses the eventual
more data than required
protocols are typically very
addresses the eventual revenue
data than required from
the eventual revenue of
than required from them
eventual revenue of the
are typically very simple
revenue of the pools
composing multiple protocols can
assuming the mining difficulty
multiple protocols can lead
the mining difficulty is
protocols can lead to
we employ the term
can lead to complex
mining difficulty is set
lead to complex interactions
employ the term opportunistic
to complex interactions with
difficulty is set based
the term opportunistic to
is set based on
complex interactions with unpredictable
set based on the
term opportunistic to refer
based on the effective
interactions with unpredictable behavior
on the effective mining
opportunistic to refer to
the effective mining power
to refer to a
refer to a subgroup
we designed the mica
to a subgroup of
not including mining power
a subgroup of byzantine
including mining power used
subgroup of byzantine nodes
mining power used for
of byzantine nodes that
power used for withholding
byzantine nodes that attempt
nodes that attempt to
that attempt to give
attempt to give less
framework to address this
to give less data
to address this problem
give less data than
less data than they
difficulty is updated only
data than they would
is updated only periodically
than they would if
updated only periodically every
mica allows programmers to
they would if they
allows programmers to describe
would if they behaved
programmers to describe gossip
if they behaved as
to describe gossip protocols
they behaved as correct
describe gossip protocols with
behaved as correct nodes
gossip protocols with a
protocols with a small
with the intention of
the intention of obtaining
intention of obtaining as
of obtaining as much
obtaining as much data
and compose the protocols
as much data as
compose the protocols with
when mining power in
much data as possible
mining power in the
the protocols with a
power in the system
data as possible at
protocols with a rich
as possible at least
in the system is
with a rich collection
the system is regularly
a rich collection of
possible at least feasible
rich collection of operators
system is regularly increasing
at least feasible cost
collection of operators to
of operators to create
operators to create sophisticated
which has been true
to create sophisticated protocols
has been true for
these may employ a
been true for the
may employ a simple
true for the majority
employ a simple strategy
create sophisticated protocols in
for the majority of
sophisticated protocols in a
the majority of bitcoin
protocols in a modular
majority of bitcoin s
in a modular style
of bitcoin s history
such as refuse to
as refuse to contribute
refuse to contribute any
to contribute any upload
mica ensures that the
contribute any upload resources
ensures that the composed
that the composed protocols
the composed protocols maintain
composed protocols maintain strong
or a more elaborate
a more elaborate strategy
more elaborate strategy that
elaborate strategy that allows
strategy that allows them
that allows them to
robustness and convergence guarantees
allows them to cheat
no adjustment may be
them to cheat without
adjustment may be necessary
to cheat without being
in our evaluation of
cheat without being easily
our evaluation of mica
without being easily detected
like it or not
we have built monitoring
notice that our model
have built monitoring tasks
that our model diverges
built monitoring tasks that
our model diverges from
monitoring tasks that maintain
model diverges from the
tasks that maintain a
diverges from the one
that maintain a predictable
from the one used
maintain a predictable performance
the one used in
if an attacker purchases
web services are distributed
an attacker purchases new
services are distributed objects
attacker purchases new mining
one used in bar
purchases new mining hardware
used in bar gossip
even when hundreds of
new mining hardware and
when hundreds of separate
mining hardware and employs
hundreds of separate instances
hardware and employs it
of separate instances are
and employs it directly
separate instances are deployed
employs it directly for
instances are deployed on
it directly for block
are deployed on the
directly for block withholding
deployed on the same
cornell university within the
in which nodes are
university within the community
on the same machines
within the community developing
which nodes are classified
the community developing the
nodes are classified as
community developing the web
are classified as byzantine
developing the web services
this mining power is
the web services architecture
mining power is never
web services architecture and
power is never included
services architecture and products
is never included in
never included in the
included in the difficulty
in the difficulty calculation
an increasingly schizophrenic message
the difficulty calculation the
increasingly schizophrenic message is
a control program reacts
schizophrenic message is emerging
difficulty calculation the system
control program reacts to
calculation the system is
program reacts to network
rational nodes attempt to
the system is never
nodes attempt to maximize
system is never aware
marketing materials assure us
reacts to network events
materials assure us that
is never aware of
assure us that web
never aware of it
us that web services
attempt to maximize their
that web services are
and updates forwarding rules
to maximize their utility
updates forwarding rules on
web services are a
forwarding rules on switches
the difficulty is therefore
rules on switches to
services are a breakthrough
on switches to manage
difficulty is therefore already
maximize their utility while
is therefore already correctly
their utility while still
switches to manage packets
utility while still following
offering unparalleled interoperability and
while still following the
therefore already correctly calculated
still following the defined
unparalleled interoperability and comprehensive
following the defined protocol
already correctly calculated and
building on this interface
correctly calculated and the
interoperability and comprehensive standards
calculated and the attack
and comprehensive standards for
our model is actually
comprehensive standards for associated
our work on merlin
standards for associated technologies
and the attack is
model is actually less
the attack is profitable
is actually less lenient
attack is profitable immediately
nodes employing strategies to
employing strategies to maximize
they portray web services
strategies to maximize their
portray web services as
is novel among network
web services as a
to maximize their utility
services as a seamless
maximize their utility are
as a seamless interconnection
their utility are classified
a seamless interconnection layer
utility are classified as
seamless interconnection layer that
novel among network programming
if the mining power
among network programming languages
the mining power is
are classified as byzantine
interconnection layer that will
network programming languages in
mining power is static
programming languages in that
layer that will propel
languages in that it
that will propel computer
in that it determines
so that we can
that it determines allocations
that we can build
the attack becomes profitable
we can build a
it determines allocations of
can build a practical
attack becomes profitable only
determines allocations of limited
becomes profitable only after
allocations of limited network
computer commerce to a
build a practical punishment
profitable only after the
commerce to a previously
only after the bitcoin
to a previously inaccessible
wide resources such as
after the bitcoin system
based system in which
the bitcoin system has
resources such as bandwidth
a previously inaccessible level
system in which any
bitcoin system has normalized
in which any node
system has normalized the
such as bandwidth and
has normalized the revenues
as bandwidth and paths
normalized the revenues by
and they use language
the revenues by adjusting
which any node not
they use language evocative
any node not contributing
use language evocative of
revenues by adjusting difficulty
language evocative of marketing
node not contributing its
evocative of marketing for
we have used merlin
of marketing for distributed
not contributing its fair
marketing for distributed object
have used merlin to
for distributed object middleware
contributing its fair share
used merlin to improve
its fair share of
merlin to improve the
the revenue of an
to improve the latency
technologists are sending a
revenue of an attacking
improve the latency of
fair share of data
the latency of hadoop
share of data may
latency of hadoop jobs
of data may be
are sending a somewhat
of an attacking pool
sending a somewhat different
data may be expelled
of hadoop jobs running
may be expelled from
a somewhat different message
an attacking pool is
hadoop jobs running in
be expelled from the
jobs running in the
expelled from the system
running in the presence
attacking pool is reduced
in the presence of
pool is reduced due
the presence of udp
is reduced due to
in an essay entitled
reduced due to the
throughout the paper we
an essay entitled web
presence of udp background
essay entitled web services
of udp background traffic
entitled web services are
the paper we use
web services are not
due to the reduction
paper we use the
services are not distributed
to the reduction in
we use the terms
the reduction in block
are not distributed objects
reduction in block generation
use the terms upload
in block generation of
or prioritize classes of
block generation of both
the terms upload factor
generation of both the
werner vogels argues that
terms upload factor and
of both the attacking
prioritize classes of traffic
both the attacking and
upload factor and download
the attacking and attacked
classes of traffic used
vogels argues that web
factor and download factor
argues that web services
of traffic used for
that web services will
traffic used for state
web services will work
and download factor to
services will work well
attacking and attacked pools
will work well for
download factor to refer
work well for important
machine replication in fault
well for important classes
factor to refer to
for important classes of
to refer to the
important classes of applications
refer to the ratio
to the ratio between
pool knowledge and r
the ratio between an
but he also cites
ratio between an upload
he also cites significant
between an upload or
also cites significant limits
an upload or download
upload or download rate
or download rate and
download rate and the
rate and the original
as vogels sees it
and the original stream
the original stream rate
these experiments demonstrate that
experiments demonstrate that an
demonstrate that an sdn
the architecture is so
that an sdn framework
architecture is so centered
is so centered on
so centered on document
centered on document exchange
given a stream rate
with the correct information
a stream rate of
the correct information as
correct information as input
and at its core
at its core is
its core is so
core is so simple
can provide automated network
provide automated network management
automated network management customized
that many features taken
network management customized to
many features taken for
management customized to the
features taken for granted
customized to the needs
taken for granted in
to the needs of
for granted in object
the needs of resident
a download rate of
needs of resident distributed
of resident distributed applications
oriented systems are fundamentally
systems are fundamentally lacking
while the merlin compiler
the merlin compiler generates
merlin compiler generates static
examples include dynamic object
compiler generates static network
include dynamic object creation
generates static network configurations
kbps corresponds to a
dynamic object creation and
corresponds to a download
object creation and garbage
to a download factor
creation and garbage collection
a download factor of
merlin uses a small
runtime component to allow
component to allow for
to allow for dynamic
dynamically created object references
allow for dynamic adaptation
and a variety of
a variety of reliability
variety of reliability and
of reliability and transactional
based approach allows this
reliability and transactional mechanisms
approach allows this adaptation
allows this adaptation to
this adaptation to happen
adaptation to happen safely
streaming system model our
system model our auditing
model our auditing approach
by providing policy language
our auditing approach is
providing policy language constructs
auditing approach is used
policy language constructs that
approach is used over
language constructs that can
is used over the
constructs that can be
used over the chainsaw
that can be automatically
over the chainsaw protocol
can be automatically verified
both perspectives can t
perspectives can t be
can t be correct
implicit in the design
in the design of
the design of this
design of this runtime
all nodes participating in
it s easy to
of this runtime component
s easy to see
nodes participating in the
easy to see how
participating in the system
to see how this
in the system are
see how this situation
the system are organized
how this situation arose
and sdn networks in
system are organized into
sdn networks in general
are organized into a
organized into a fully
web services are the
into a fully connected
services are the most
a fully connected mesh
is the notion that
fully connected mesh overlay
are the most recent
the notion that network
the most recent in
notion that network events
most recent in a
that network events are
where each node has
recent in a long
network events are generated
in a long series
each node has the
a long series of
node has the same
long series of object
has the same number
series of object oriented
the same number of
events are generated in
of object oriented interoperability
are generated in response
object oriented interoperability platforms
same number of neighbors
generated in response to
in response to the
response to the situational
to the situational status
and mixes ideas from
the source is randomly
the situational status culled
source is randomly connected
situational status culled from
is randomly connected to
status culled from a
mixes ideas from corba
culled from a wide
randomly connected to a
from a wide range
connected to a small
a wide range of
to a small subset
wide range of sources
a small subset of
small subset of the
subset of the nodes
the streaming process starts
streaming process starts at
process starts at the
starts at the source
while exploiting xml and
exploiting xml and other
xml and other web
which breaks the data
breaks the data stream
the data stream into
data stream into packets
stream into packets and
developers using popular middleware
into packets and sends
using popular middleware platforms
packets and sends notifications
popular middleware platforms can
and sends notifications to
middleware platforms can transform
sends notifications to its
platforms can transform a
notifications to its neighbors
can transform a program
to its neighbors as
packet and drop rates
its neighbors as soon
transform a program object
neighbors as soon as
and solving we obtain
a program object into
solving we obtain a
program object into a
we obtain a single
object into a web
as soon as it
obtain a single expression
into a web services
a single expression for
a web services object
single expression for any
soon as it has
expression for any ri
as it has packets
it has packets to
or access a remote
has packets to disseminate
access a remote ws
since in the in
a remote ws object
in the in order
the in order to
in order to choose
these notifications are small
order to choose its
notifications are small messages
at the touch of
are small messages used
the touch of a
to choose its optimal
small messages used only
choose its optimal infiltration
touch of a button
its optimal infiltration rate
messages used only to
used only to inform
only to inform neighbors
to inform neighbors of
performance leaves something to
inform neighbors of the
leaves something to be
neighbors of the availability
a pool has to
something to be desired
pool has to know
of the availability of
has to know the
the availability of new
to know the rate
availability of new packets
know the rate at
but computers and networks
the rate at which
computers and networks have
rate at which it
and networks have become
at which it is
based on the received
which it is attacked
on the received notifications
networks have become astonishingly
have become astonishingly fast
and the revenue density
each node requests missing
the revenue density of
node requests missing packets
revenue density of potential
major application providers are
density of potential victim
application providers are planning
of potential victim pools
providers are planning to
are planning to offer
and the source satisfies
planning to offer ws
the source satisfies as
to offer ws interfaces
source satisfies as many
a pool can estimate
offer ws interfaces to
user preferences for a
ws interfaces to their
preferences for a particular
interfaces to their products
for a particular network
satisfies as many requests
pool can estimate the
as many requests as
can estimate the rate
so it makes perfect
estimate the rate with
it makes perfect sense
many requests as allowed
makes perfect sense that
requests as allowed by
perfect sense that the
as allowed by its
sense that the marketing
allowed by its upload
the rate with which
that the marketing community
by its upload capacity
the marketing community would
rate with which it
marketing community would feel
with which it is
community would feel that
which it is attacked
would feel that finally
it is attacked by
is attacked by comparing
attacked by comparing the
with chainsaw the upload
by comparing the rates
they ve reached the
comparing the rates of
ve reached the promised
chainsaw the upload capacity
reached the promised land
the rates of partial
the upload capacity of
rates of partial and
upload capacity of the
of partial and full
capacity of the source
partial and full proofs
of the source does
and full proofs of
the source does not
full proofs of work
source does not need
proofs of work it
does not need to
of work it receives
not need to increase
work it receives from
need to increase with
it receives from its
to increase with the
receives from its miners
increase with the size
has an understandable emphasis
much of this information
with the size of
an understandable emphasis on
of this information must
the size of the
understandable emphasis on facts
size of the system
as explained in section
emphasis on facts on
explained in section ii
this information must be
on facts on the
information must be created
must be created and
even an upload capacity
be created and updated
facts on the ground
an upload capacity of
created and updated dynamically
upload capacity of twice
in order to estimate
capacity of twice the
order to estimate the
on the ground and
to estimate the revenue
of twice the stream
the ground and the
estimate the revenue densities
twice the stream rate
the revenue densities of
ground and the vogels
revenue densities of the
the stream rate is
and the vogels essay
densities of the other
the vogels essay reflects
stream rate is sufficient
existing sdn frameworks have
rate is sufficient to
sdn frameworks have largely
is sufficient to ensure
frameworks have largely closing
sufficient to ensure that
have largely closing the
to ensure that the
vogels essay reflects the
ensure that the system
largely closing the loop
that the system performs
essay reflects the realities
of the other pools
the system performs and
reflects the realities of
system performs and scales
the realities of an
performs and scales well
to accommodate the ever
realities of an architecture
a pool can use
of an architecture focused
pool can use one
as nodes receive packets
an architecture focused at
can use one of
growing demands of cloud
architecture focused at its
use one of two
focused at its core
one of two methods
at its core on
they mimic the role
its core on using
mimic the role of
core on using document
the role of the
demands of cloud and
on using document exchange
of cloud and data
role of the source
cloud and data center
using document exchange to
and data center application
document exchange to access
exchange to access backend
sending notifications to their
to access backend servers
notifications to their own
networks will need to
to their own neighbors
will need to become
their own neighbors in
need to become more
own neighbors in the
to become more flexible
neighbors in the mesh
become more flexible and
this core has been
more flexible and dynamic
core has been extended
has been extended with
allowing packets to be
been extended with such
packets to be propagated
extended with such mechanisms
to be propagated through
with such mechanisms as
be propagated through the
such mechanisms as rpc
propagated through the system
mechanisms as rpc and
as networks continue to
as rpc and asynchronous
networks continue to grow
rpc and asynchronous messaging
continue to grow in
to grow in complexity
based approach to acquisition
approach to acquisition of
to acquisition of packets
it will become increasingly
will become increasingly difficult
become increasingly difficult for
increasingly difficult for network
difficult for network operators
for network operators to
network operators to provide
operators to provide this
to provide this flexibility
a variety of roll
provide this flexibility without
this flexibility without the
flexibility without the support
provides some resilience to
without the support of
forward and rendezvous options
the support of proper
some resilience to failure
support of proper tools
resilience to failure or
of proper tools and
to failure or malicious
proper tools and infrastructure
failure or malicious behavior
but the primary usage
the primary usage case
since a participant will
primary usage case remains
a participant will have
usage case remains that
participant will have multiple
case remains that of
will have multiple possible
remains that of a
have multiple possible sources
that of a client
provide both the control
multiple possible sources for
of a client sending
possible sources for each
both the control and
a client sending documents
sources for each packet
client sending documents to
the control and monitoring
sending documents to a
control and monitoring components
documents to a back
and monitoring components necessary
the mesh overlay defines
monitoring components necessary to
mesh overlay defines a
components necessary to automatically
overlay defines a predetermined
necessary to automatically adapt
end service in a
to automatically adapt the
service in a client
defines a predetermined set
automatically adapt the network
a predetermined set of
adapt the network to
predetermined set of neighbors
the network to the
set of neighbors for
network to the needs
of neighbors for each
to the needs of
neighbors for each peer
the needs of the
needs of the applications
the assumption is that
which also makes it
assumption is that the
because both systems use
is that the application
both systems use a
also makes it hard
systems use a language
that the application can
makes it hard for
the application can tolerate
it hard for malicious
application can tolerate substantial
hard for malicious peers
can tolerate substantial delay
for malicious peers to
tolerate substantial delay before
they have rigorous semantics
malicious peers to round
have rigorous semantics that
substantial delay before a
rigorous semantics that can
peers to round up
semantics that can be
delay before a response
that can be formally
to round up on
can be formally defined
before a response arrives
round up on individual
up on individual peers
on individual peers since
individual peers since attackers
and mechanisms capable of
peers since attackers lack
mechanisms capable of introducing
since attackers lack a
capable of introducing delays
attackers lack a deterministic
of introducing delays are
lack a deterministic means
introducing delays are scattered
they provide predictable operational
delays are scattered throughout
a deterministic means of
are scattered throughout the
provide predictable operational behavior
scattered throughout the architecture
deterministic means of acquiring
means of acquiring control
of acquiring control of
acquiring control of all
control of all of
of all of its
the more basic assumption
all of its neighbors
they allow for the
more basic assumption is
allow for the rigorous
basic assumption is that
for the rigorous expression
assumption is that it
the rigorous expression of
all nodes with exception
rigorous expression of algorithms
is that it all
expression of algorithms for
nodes with exception of
that it all boils
with exception of the
of algorithms for monitoring
exception of the source
algorithms for monitoring or
it all boils down
of the source have
for monitoring or managing
all boils down to
the source have a
monitoring or managing sdn
source have a fixed
or managing sdn networks
have a fixed upper
boils down to moving
a fixed upper limit
down to moving documents
fixed upper limit on
to moving documents around
upper limit on their
moving documents around whereas
limit on their upload
documents around whereas the
on their upload contribution
around whereas the most
whereas the most basic
the most basic assumption
most basic assumption of
basic assumption of a
assumption of a distributed
of a distributed object
a distributed object system
distributed object system is
object system is that
system is that the
is that the world
that the world consists
the world consists of
world consists of programs
consists of programs and
of programs and data
times the stream rate
active and passive objects
the gist of vogel
gist of vogel s
defined by the protocol
of vogel s essay
this work was supported
vogel s essay is
s essay is that
essay is that even
is that even with
that even with all
even with all the
with all the contemplated
this upper limit is
all the contemplated extensions
upper limit is not
by a grant from
limit is not respected
a grant from the
is not respected by
grant from the darpa
not respected by opportunistic
from the darpa mrc
respected by opportunistic nodes
the darpa mrc program
web services are deeply
services are deeply mismatched
are deeply mismatched with
deeply mismatched with distributed
who attempt to reduce
mismatched with distributed object
attempt to reduce it
with distributed object computing
to reduce it with
reduce it with the
it with the goal
with the goal of
the goal of uploading
goal of uploading less
the dilemma underlying the
of uploading less data
dilemma underlying the debate
underlying the debate is
expression for ri in
the debate is that
on the course of
debate is that the
for ri in a
the course of a
ri in a system
course of a streaming
in a system with
of a streaming session
a system with pools
is that the platforms
system with pools of
that the platforms one
with pools of equal
the platforms one uses
pools of equal size
platforms one uses to
each node stores packets
one uses to create
node stores packets and
uses to create wscompatible
stores packets and forwards
to create wscompatible objects
online measurement of large
packets and forwards them
measurement of large traffic
create wscompatible objects impose
of large traffic aggregates
wscompatible objects impose no
large traffic aggregates on
objects impose no such
traffic aggregates on commodity
impose no such restrictions
aggregates on commodity switches
and forwards them to
forwards them to other
them to other peers
to other peers only
there is nothing in
other peers only while
is nothing in j
peers only while the
only while the packet
while the packet is
the packet is within
packet is within its
is within its availability
within its availability window
net that warns a
that warns a user
warns a user that
usually spanning a few
a user that an
spanning a few seconds
user that an intended
that an intended use
an intended use of
intended use of the
each node also maintains
use of the architecture
node also maintains an
of the architecture may
also maintains an interest
the architecture may be
maintains an interest window
architecture may be inappropriate
which represents the set
represents the set of
the set of packets
set of packets in
much of the excitement
of packets in which
of the excitement reflects
packets in which the
the excitement reflects the
in which the peer
excitement reflects the realization
which the peer is
reflects the realization that
the peer is currently
the realization that with
peer is currently interested
realization that with web
that with web services
nodes choose packets to
interoperability really is easier
choose packets to request
packets to request from
to request from each
request from each of
from each of its
each of its neighbors
developers have long struggled
have long struggled with
long struggled with program
respecting a maximum limit
a maximum limit l
maximum limit l on
limit l on the
l on the number
program interconnection and integration
on the number of
q mi q mi
the number of outstanding
number of outstanding requests
of outstanding requests to
outstanding requests to each
and it is natural
it is natural to
is natural to applaud
natural to applaud a
to applaud a widely
applaud a widely adopted
a widely adopted advance
a compositional architecture for
compositional architecture for gossip
architecture for gossip protocols
like it or not
web services are becoming
services are becoming a
are becoming a de
facto standard for everything
that s not all
based direct sales systems
direct sales systems are
sales systems are turning
systems are turning to
are turning to the
turning to the ws
to the ws architecture
the ws architecture as
ws architecture as a
architecture as a means
as a means of
a means of enlarging
means of enlarging their
of enlarging their markets
com has developed a
has developed a web
access library whereby third
party application developers can
application developers can access
developers can access their
can access their datacenters
access their datacenters from
their datacenters from a
datacenters from a diversity
from a diversity of
a diversity of end
an application could order
application could order thus
could order thus supplies
order thus supplies directly
thus supplies directly from
supplies directly from amazon
query the fulfillment system
the fulfillment system to
fulfillment system to track
system to track order
to track order status
track order status or
order status or billing
managing the network with
status or billing data
the network with merlin
both the vendor and
the vendor and the
vendor and the application
and the application developer
the application developer benefit
q symmetric equilibrium values
symmetric equilibrium values for
equilibrium values for a
values for a system
for a system of
a system of q
com enlarges its client
system of q pools
enlarges its client base
of q pools of
q pools of equal
pools of equal sizes
while the developer avoids
the developer avoids duplicating
developer avoids duplicating an
often publish this data
avoids duplicating an enormous
publish this data to
duplicating an enormous technology
this data to demonstrate
an enormous technology investment
data to demonstrate their
to demonstrate their honesty
demonstrate their honesty to
upload factor download factor
their honesty to their
honesty to their miners
web service components will
service components will play
components will play a
will play a critical
play a critical role
a critical role in
critical role in tremendous
role in tremendous numbers
in tremendous numbers of
tremendous numbers of end
the challenge is to
challenge is to make
is to make such
to make such systems
make such systems work
such systems work reliably
outages that plague human
that plague human users
plague human users of
human users of web
users of web browsers
of web browsers don
web browsers don t
browsers don t cause
don t cause much
t cause much harm
outages could disrupt a
could disrupt a computer
a language for provisioning
a pool can infiltrate
language for provisioning network
computer pathway buried deep
pool can infiltrate each
for provisioning network resources
pathway buried deep within
can infiltrate each of
buried deep within an
infiltrate each of the
deep within an application
each of the other
within an application on
of the other pools
an application on which
the other pools with
application on which an
other pools with some
on which an enterprise
pools with some nominal
which an enterprise has
with some nominal probing
an enterprise has become
some nominal probing mining
enterprise has become dependent
nominal probing mining power
probing mining power and
mining power and measure
power and measure the
it is too easy
and measure the revenue
is too easy to
measure the revenue density
too easy to dismiss
the revenue density directly
easy to dismiss these
revenue density directly by
to dismiss these concerns
density directly by monitoring
dismiss these concerns by
directly by monitoring the
these concerns by arguing
by monitoring the probe
concerns by arguing that
monitoring the probe s
by arguing that the
the probe s rewards
arguing that the web
probe s rewards from
that the web is
s rewards from the
the web is extremely
rewards from the pool
web is extremely scalable
is extremely scalable and
extremely scalable and robust
but this ignores the
this ignores the way
block withholding recycling we
ignores the way we
withholding recycling we assume
the way we use
recycling we assume that
way we use the
we assume that the
we use the web
assume that the infiltrating
that the infiltrating miners
the infiltrating miners are
infiltrating miners are loyal
miners are loyal to
a human can deal
are loyal to the
human can deal with
loyal to the attacker
can deal with the
software defined traffic measurement
deal with the many
defined traffic measurement with
with the many error
traffic measurement with opensketch
the many error conditions
many error conditions the
error conditions the web
conditions the web exposes
some of the pool
of the pool s
the pool s members
handling those conditions in
pool s members may
those conditions in a
s members may be
conditions in a seamless
members may be disloyal
may be disloyal infiltrators
automated manner is an
manner is an entirely
when sending disloyal miners
is an entirely different
sending disloyal miners to
an entirely different challenge
disloyal miners to perform
miners to perform block
to perform block withholding
perform block withholding at
block withholding at other
withholding at other pools
when we take what
we take what was
an attacker takes a
take what was once
attacker takes a significant
what was once a
takes a significant risk
was once a batch
once a batch service
a batch service or
maximum upload factor figure
batch service or a
service or a web
or a web site
a web site and
web site and transform
site and transform it
and transform it into
transform it into a
can use a loyal
it into a web
download and upload factors
use a loyal miner
and upload factors of
a loyal miner w
upload factors of nodes
loyal miner w to
factors of nodes in
miner w to infiltrate
into a web service
w to infiltrate pool
of nodes in an
nodes in an ideal
in an ideal system
an ideal system where
ideal system where all
there is no way
system where all nodes
is no way to
where all nodes behave
no way to enforce
all nodes behave correctly
way to enforce appropriate
to enforce appropriate patterns
enforce appropriate patterns of
appropriate patterns of use
thinking the miner is
the miner is loyal
what s to stop
miner is loyal to
s to stop a
is loyal to it
this limit not only
to stop a web
limit not only improves
stop a web client
not only improves the
a web client from
only improves the general
might use it to
improves the general flow
use it to attack
the general flow of
it to attack pool
general flow of packets
web client from trying
client from trying to
from trying to download
trying to download amazon
but also makes it
also makes it harder
the miner m can
com s entire catalog
makes it harder for
miner m can perform
it harder for malicious
m can perform honest
harder for malicious peers
can perform honest mining
for malicious peers to
perform honest mining for
malicious peers to overrequest
honest mining for pool
peers to overrequest packets
the only answer is
to overrequest packets from
overrequest packets from their
packets from their neighbors
rather than withhold its
peers maintain a queue
than withhold its blocks
maintain a queue of
a queue of non
and not return any
not return any revenue
satisfied requests from its
return any revenue to
one might argue that
any revenue to pool
requests from its neighbors
might argue that none
argue that none of
that none of these
none of these uses
keeping only the l
of these uses are
only the l most
these uses are what
the l most recent
uses are what the
l most recent ones
are what the architecture
what the architecture is
it will take its
the architecture is intended
will take its share
architecture is intended to
take its share of
is intended to support
its share of pool
not so many years
so many years ago
which thinks the miner
thinks the miner is
expected behavior our first
the miner is loyal
behavior our first goal
miner is loyal to
our first goal is
server architectures faltered over
is loyal to it
first goal is to
architectures faltered over precisely
goal is to explore
faltered over precisely this
is to explore the
over precisely this type
to explore the typical
precisely this type of
explore the typical signature
this type of situation
and deliver it back
the typical signature of
deliver it back to
typical signature of the
it back to pool
signature of the system
server technologies of the
since an understanding of
an understanding of the
to avoid such a
understanding of the behavior
avoid such a risk
of the behavior of
the behavior of pullbased
behavior of pullbased dissemination
a pool needs a
of pullbased dissemination in
pool needs a sufficient
pullbased dissemination in the
needs a sufficient number
dissemination in the absence
s were widely seen
a sufficient number of
were widely seen as
in the absence of
widely seen as a
sufficient number of verified
seen as a kind
the absence of opportunistic
number of verified miners
as a kind of
of verified miners miners
a kind of panacea
verified miners miners that
absence of opportunistic nodes
miners miners that it
of opportunistic nodes will
miners that it knows
opportunistic nodes will turn
a silver bullet that
that it knows to
silver bullet that would
it knows to be
bullet that would slay
knows to be loyal
that would slay evil
nodes will turn out
would slay evil mainframe
will turn out to
slay evil mainframe architectures
turn out to be
out to be important
to be important when
be important when we
important when we set
the optimal infiltration rate
enterprises fell over themselves
optimal infiltration rate may
fell over themselves in
infiltration rate may be
over themselves in a
rate may be as
themselves in a kind
when we set out
may be as high
we set out to
be as high as
set out to introduce
in a kind of
out to introduce auditing
a kind of technology
the one issue that
kind of technology gold
of technology gold rush
one issue that unites
issue that unites almost
we conducted experiments using
that unites almost all
conducted experiments using an
only to discover that
of the pool size
to discover that the
unites almost all approaches
discover that the technology
experiments using an event
almost all approaches to
that the technology had
but this is only
all approaches to distributed
this is only in
the technology had been
approaches to distributed computing
technology had been oversold
is only in extreme
to distributed computing is
only in extreme cases
which is described in
distributed computing is the
in extreme cases when
computing is the need
extreme cases when pools
the total cost of
is described in more
total cost of ownership
described in more detail
cost of ownership for
in more detail in
is the need to
cases when pools are
the need to know
when pools are large
of ownership for clientserver
more detail in section
ownership for clientserver systems
need to know whether
for clientserver systems remains
to know whether certain
for practical pool sizes
know whether certain components
clientserver systems remains excessively
whether certain components in
systems remains excessively high
certain components in the
components in the system
in the system have
the system have failed
system have failed or
the number of system
a pool may need
number of system administrators
pool may need up
of system administrators remains
we evaluate the performance
may need up to
evaluate the performance of
system administrators remains roughly
have failed or are
administrators remains roughly proportional
failed or are otherwise
remains roughly proportional to
or are otherwise unavailable
roughly proportional to the
proportional to the size
to the size of
the size of the
size of the deployment
when designing and building
of its mining power
designing and building systems
its mining power for
and building systems that
mining power for infiltration
building systems that need
nodes during an ideal
systems that need to
during an ideal execution
a list like these
an ideal execution of
that need to function
list like these comments
need to function at
ideal execution of chainsaw
like these comments might
to function at a
these comments might have
function at a global
comments might have seemed
at a global scale
pools typically have loyal
where all the nodes
might have seemed like
all the nodes behave
have seemed like an
the nodes behave correctly
seemed like an indictment
typically have loyal mining
like an indictment of
failure management needs to
an indictment of the
management needs to be
indictment of the technology
have loyal mining power
we fixed the upload
needs to be considered
fixed the upload factor
loyal mining power either
the upload factor of
because we lacked solutions
upload factor of the
mining power either run
to be considered a
factor of the source
be considered a fundamental
of the source at
power either run directly
considered a fundamental building
either run directly by
a fundamental building block
run directly by the
directly by the pool
by the pool owners
the pool owners or
this paper describes the
pool owners or sold
we know how to
owners or sold as
know how to implement
or sold as a
how to implement management
sold as a service
to implement management tools
as a service but
paper describes the development
implement management tools and
describes the development of
management tools and fault
a service but run
the development of a
service but run on
development of a system
but run on the
run on the pool
on the pool owners
and the stream rate
the pool owners hardware
independent failure management service
how to replicate data
the stream rate to
to replicate data and
replicate data and functionality
which allows systems and
allows systems and applications
systems and applications to
and how to achieve
and applications to incorporate
how to achieve high
applications to incorporate accurate
to achieve high ava
to incorporate accurate detection
achieve high ava ilability
incorporate accurate detection of
accurate detection of failed
detection of failed processes
we ve had decades
we varied the maximum
ve had decades of
varied the maximum upload
had decades of experience
the maximum upload factor
decades of experience with
maximum upload factor of
of experience with large
upload factor of nodes
without the need for
factor of nodes to
the need for making
of nodes to see
need for making compromises
nodes to see how
for making compromises in
scale system monitoring and
making compromises in their
to see how it
compromises in their particular
system monitoring and control
in their particular design
see how it affected
how it affected both
it affected both the
affected both the download
and are beginning to
both the download and
are beginning to understand
the download and upload
beginning to understand how
download and upload factors
to understand how to
and upload factors of
understand how to build
upload factors of nodes
with the advent of
however the size of
how to build solutions
the size of this
to build solutions on
size of this mining
build solutions on an
factors of nodes across
the advent of ubiquitous
of this mining power
solutions on an internet
this mining power is
on an internet scale
of nodes across the
mining power is considered
nodes across the system
power is considered a
is considered a trade
considered a trade secret
a trade secret and
trade secret and is
secret and is not
the maximum upload factor
and is not published
it is becoming clear
maximum upload factor is
is becoming clear that
peer file sharing turns
becoming clear that the
file sharing turns out
clear that the systems
upload factor is a
sharing turns out to
factor is a fixed
turns out to be
is a fixed parameter
that the systems that
a fixed parameter which
the systems that are
countermeasures as in the
systems that are used
fixed parameter which defines
that are used today
as in the case
out to be illegal
in the case of
are used today in
the case of classical
used today in local
case of classical block
parameter which defines the
of classical block withholding
and it doesn t
classical block withholding explained
it doesn t work
block withholding explained in
doesn t work all
which defines the maximum
withholding explained in section
defines the maximum rate
explained in section ii
can not simply be
t work all that
not simply be employed
work all that well
the maximum rate at
simply be employed in
maximum rate at which
be employed in their
rate at which a
employed in their existing
at which a node
in their existing form
a pool might detect
their existing form or
which a node will
existing form or trivially
pool might detect that
form or trivially converted
a node will upload
or trivially converted for
might detect that it
but spawned a new
detect that it is
node will upload data
trivially converted for wide
will upload data to
that it is being
spawned a new generation
upload data to all
a new generation of
data to all its
it is being attacked
new generation of technologies
to all its neighbors
generation of technologies based
of technologies based on
technologies based on distributed
but cannot detect which
based on distributed hash
cannot detect which of
for fairness in nodes
detect which of its
fairness in nodes bandwidth
which of its miners
on distributed hash tables
whatever form such systems
distributed hash tables and
form such systems may
of its miners is
such systems may take
its miners is the
systems may take in
miners is the attacker
may take in the
hash tables and epidemic
in nodes bandwidth consumption
tables and epidemic communication
take in the future
and epidemic communication protocols
therefore a pool cannot
a pool cannot block
pool cannot block or
we would like all
cannot block or punish
whether they are replicated
block or punish withholding
they are replicated databases
or punish withholding miners
these offer remarkably stable
would like all nodes
are replicated databases of
like all nodes to
replicated databases of hyper
all nodes to upload
nodes to upload data
scalable tools for dealing
to upload data at
tools for dealing with
upload data at a
various techniques can be
data at a factor
techniques can be used
at a factor as
can be used to
a factor as close
for dealing with enormous
be used to encourage
dealing with enormous numbers
used to encourage miners
factor as close as
with enormous numbers of
view or virtual synchronous
to encourage miners to
or virtual synchronous groups
encourage miners to submit
as close as possible
enormous numbers of components
virtual synchronous groups or
numbers of components scattered
close as possible to
miners to submit full
synchronous groups or agents
of components scattered over
groups or agents employing
components scattered over a
or agents employing lazy
scattered over a network
agents employing lazy consistency
to submit full blocks
employing lazy consistency schemes
not all the stories
all the stories are
a pool can pay
one of the key
pool can pay a
the stories are positive
can pay a bonus
of the key problems
pay a bonus for
we varied the maximum
a bonus for submitting
varied the maximum upload
bonus for submitting a
the maximum upload factor
for submitting a full
the key problems that
maximum upload factor of
the web services community
upload factor of nodes
web services community decided
factor of nodes from
submitting a full proof
key problems that needs
services community decided not
a full proof of
community decided not to
full proof of work
decided not to adapt
problems that needs to
not to adapt the
that needs to be
to adapt the corba
needs to be addressed
adapt the corba fault
this would increase the
would increase the revenue
increase the revenue of
is that of the
the revenue of the
that of the detection
tolerance standard for their
of the detection and
standard for their setting
the detection and handling
revenue of the miner
detection and handling of
of the miner that
and handling of faulty
the miner that found
this is a specification
handling of faulty components
is a specification i
miner that found a
the left graph shows
that found a block
left graph shows the
a specification i know
found a block while
graph shows the minimum
a block while reducing
specification i know well
block while reducing the
while reducing the revenue
building distributed systems and
reducing the revenue of
average and maximum download
distributed systems and applications
it was based on
the revenue of the
and maximum download factors
revenue of the other
was based on the
systems and applications today
based on the virtual
of the other miners
on the virtual synchrony
the other miners from
maximum download factors across
and applications today is
the virtual synchrony model
applications today is done
download factors across the
today is done using
virtual synchrony model colleagues
is done using a
synchrony model colleagues of
other miners from this
model colleagues of mine
miners from this block
colleagues of mine and
done using a variety
of mine and i
factors across the nodes
using a variety of
across the nodes when
mine and i developed
the nodes when the
and i developed in
nodes when the maximum
i developed in work
when the maximum upload
developed in work on
the maximum upload factor
in work on the
a variety of systems
while the average revenue
variety of systems ranging
the average revenue of
maximum upload factor of
average revenue of each
upload factor of nodes
revenue of each miner
of systems ranging from
of each miner would
factor of nodes is
work on the isis
systems ranging from the
on the isis toolkit
ranging from the bare
each miner would stay
from the bare bone
miner would stay the
the bare bone protocols
would stay the same
of nodes is increased
the standard hasn t
bare bone protocols interfaces
standard hasn t been
bone protocols interfaces like
hasn t been a
protocols interfaces like bsd
t been a commercial
small miners will suffer
interfaces like bsd sockets
miners will suffer from
like bsd sockets and
been a commercial success
will suffer from higher
by increasing the maximum
bsd sockets and the
increasing the maximum upload
sockets and the tdi
the maximum upload factor
but the corba standard
maximum upload factor of
the corba standard limits
upload factor of nodes
suffer from higher variance
corba standard limits itself
from higher variance in
standard limits itself to
higher variance in revenue
to rpc based systems
we increase the global
limits itself to lock
increase the global upload
rpc based systems such
the global upload capacity
based systems such as
another approach is to
global upload capacity of
state replication of a
upload capacity of the
approach is to introduce
systems such as dce
replication of a deterministic
such as dce and
of a deterministic server
as dce and to
is to introduce a
dce and to more
capacity of the system
to introduce a joining
and to more advanced
perhaps the issue is
to more advanced distributed
the issue is the
more advanced distributed support
issue is the way
leading to a better
introduce a joining fee
advanced distributed support systems
is the way the
distributed support systems such
a joining fee by
to a better flow
the way the technology
support systems such as
joining fee by paying
a better flow of
way the technology was
systems such as isis
fee by paying new
better flow of packets
the technology was used
by paying new miners
paying new miners less
new miners less for
not the technology itself
miners less for their
less for their work
the discrepancy among the
for their work until
discrepancy among the upload
their work until they
among the upload factors
work until they have
the upload factors of
until they have established
upload factors of individual
they have established a
factors of individual nodes
have established a reputation
of individual nodes also
established a reputation with
individual nodes also increases
a reputation with the
used in other ways
reputation with the pool
as seen in the
seen in the graph
has been quite successful
in the graph to
miners that seek flexibility
the graph to the
that seek flexibility may
graph to the right
seek flexibility may not
flexibility may not accept
may not accept this
not accept this policy
isis runs the new
when the maximum upload
accept this policy and
the maximum upload factor
runs the new york
maximum upload factor is
this policy and choose
the new york stock
policy and choose another
upload factor is increased
new york stock exchange
and choose another pool
york stock exchange quote
stock exchange quote and
exchange quote and trade
some nodes participate more
quote and trade reporting
nodes participate more actively
and trade reporting system
participate more actively in
more actively in dissemination
actively in dissemination while
the pool can use
in dissemination while others
a role it has
dissemination while others end
role it has played
while others end up
it has played since
others end up contributing
pool can use a
end up contributing less
can use a honeypot
use a honeypot trap
a honeypot trap by
honeypot trap by sending
even though all of
after years of experience
though all of them
trap by sending the
all of them are
years of experience with
by sending the miners
of experience with building
of them are behaving
experience with building these
them are behaving correctly
with building these systems
sending the miners tasks
building these systems and
the miners tasks which
these systems and applications
miners tasks which it
this is an important
tasks which it knows
is an important consideration
which it knows will
it knows will result
knows will result in
it is clear that
will result in a
and the french air
when we introduce auditing
is clear that failure
result in a full
clear that failure management
in a full proof
that failure management is
the french air traffic
failure management is not
french air traffic control
a full proof of
we do not want
management is not just
air traffic control system
is not just a
do not want to
not just a essential
full proof of work
not want to punish
just a essential tool
want to punish nodes
and the us naval
a essential tool for
the us naval aegis
to punish nodes that
us naval aegis warship
essential tool for group
naval aegis warship communication
punish nodes that are
aegis warship communication system
tool for group oriented
nodes that are willing
for group oriented systems
that are willing to
are willing to contribute
to name just a
willing to contribute but
name just a few
to contribute but cannot
all which have built
contribute but cannot do
but cannot do so
if a miner fails
cannot do so because
a miner fails to
do so because of
miner fails to submit
so because of factors
fails to submit the
because of factors such
to submit the full
of factors such as
submit the full proof
factors such as their
the full proof of
such as their physical
but that it is
as their physical positioning
full proof of work
their physical positioning in
that it is a
physical positioning in the
proof of work it
leslie lamport s paxos
it is a fundamental
lamport s paxos protocol
of work it is
s paxos protocol has
work it is tagged
paxos protocol has been
it is tagged as
positioning in the system
is a fundamental service
protocol has been used
a fundamental service that
has been used to
is tagged as an
been used to build
tagged as an attacker
used to build file
fundamental service that should
in all our future
service that should be
all our future experiments
that should be placed
to build file systems
our future experiments we
build file systems and
should be placed among
file systems and scalable
future experiments we set
to prevent the attacker
be placed among such
systems and scalable clusters
placed among such established
prevent the attacker from
among such established basic
the attacker from learning
experiments we set the
such established basic services
we set the maximum
none of these examples
set the maximum upload
of these examples uses
the maximum upload factor
these examples uses lock
maximum upload factor to
established basic services as
attacker from learning them
basic services as naming
step replication of the
replication of the type
of the type mandated
the honeypot tasks have
the type mandated by
honeypot tasks have to
type mandated by corba
tasks have to be
have to be regularly
to be regularly refreshed
every technology has its
service brokerage and ipc
technology has its successes
has its successes and
its successes and failures
pools can also incorporate
this paper reports on
can also incorporate out
also incorporate out of
paper reports on an
incorporate out of band
effect of opportunistic behavior
out of band mechanisms
reports on an ongoing
of band mechanisms to
of opportunistic behavior our
band mechanisms to deter
on an ongoing research
mechanisms to deter attacks
opportunistic behavior our next
an ongoing research effort
behavior our next goal
these technologies could take
our next goal was
technologies could take the
ongoing research effort to
could take the web
next goal was to
take the web services
research effort to abstract
goal was to understand
the web services architecture
such as verifying the
web services architecture to
was to understand the
services architecture to a
as verifying the identity
effort to abstract the
verifying the identity of
to understand the expected
the identity of miners
architecture to a new
to abstract the failure
understand the expected behavior
identity of miners or
the expected behavior of
of miners or using
to a new level
abstract the failure handling
expected behavior of correct
miners or using trusted
the failure handling strategies
or using trusted computing
behavior of correct nodes
using trusted computing technologies
failure handling strategies from
of correct nodes under
handling strategies from a
doing so could greatly
correct nodes under different
so could greatly enlarge
strategies from a variety
could greatly enlarge the
nodes under different scenarios
greatly enlarge the web
from a variety of
under different scenarios where
enlarge the web services
different scenarios where opportunistic
the web services market
a variety of popular
scenarios where opportunistic nodes
where opportunistic nodes compromise
variety of popular distributed
opportunistic nodes compromise the
that assure no block
so what s the
assure no block withholding
what s the bottom
no block withholding is
s the bottom line
block withholding is taking
of popular distributed systems
nodes compromise the system
withholding is taking place
popular distributed systems and
are web services distributed
web services distributed objects
distributed systems and to
we therefore studied how
systems and to develop
therefore studied how the
this would require miners
of course they are
and to develop a
studied how the download
would require miners to
how the download and
require miners to use
to develop a basic
miners to use specialized
the download and contribution
to use specialized hardware
develop a basic failure
use specialized hardware and
download and contribution rates
a basic failure management
specialized hardware and software
the marketing people are
and contribution rates of
marketing people are listening
basic failure management service
contribution rates of correct
people are listening to
failure management service that
are listening to customers
rates of correct nodes
an overhead miners may
of correct nodes are
overhead miners may not
correct nodes are affected
miners may not accept
nodes are affected under
and they want distributed
are affected under these
management service that can
affected under these conditions
they want distributed objects
service that can be
that can be used
can be used by
there is no known
opportunistic nodes may contribute
is no known silver
be used by any
but vogels is right
used by any distributed
no known silver bullet
by any distributed system
nodes may contribute with
any distributed system regardless
may contribute with some
distributed system regardless of
contribute with some data
system regardless of the
all these techniques reduce
regardless of the purpose
with some data in
these techniques reduce the
some data in an
of the purpose of
data in an attempt
techniques reduce the pool
in an attempt to
the purpose of that
an attempt to disguise
reduce the pool s
attempt to disguise their
purpose of that system
to disguise their opportunistic
of that system or
disguise their opportunistic behavior
the pool s attractiveness
it s time for
pool s attractiveness and
that system or the
s attractiveness and deter
system or the techniques
attractiveness and deter miners
or the techniques used
s time for the
time for the web
for the web services
we considered different rates
the web services community
considered different rates of
web services community to
different rates of contribution
the strategies employed by
rates of contribution for
services community to come
of contribution for opportunistic
strategies employed by this
block withholding in practice
employed by this basic
withholding in practice long
community to come to
in practice long term
by this basic service
practice long term block
to come to grips
long term block withholding
this basic service are
term block withholding attacks
come to grips with
block withholding attacks are
to grips with the
withholding attacks are difficult
basic service are specifically
contribution for opportunistic nodes
grips with the needs
attacks are difficult to
with the needs of
service are specifically targeted
are difficult to hide
are specifically targeted towards
the needs of their
specifically targeted towards applications
needs of their customer
targeted towards applications that
of their customer base
towards applications that need
since miners using an
applications that need to
miners using an attacked
that need to operate
using an attacked pool
need to operate on
one can justify solutions
to operate on a
can justify solutions that
an attacked pool would
operate on a global
attacked pool would notice
on a global scale
pool would notice the
justify solutions that make
would notice the reduced
notice the reduced revenue
the reduced revenue density
to build a successful
build a successful service
a successful service the
such attacks are rarely
successful service the following
of the customers happy
service the following goals
the customers happy but
the following goals were
customers happy but leave
following goals were set
attacks are rarely reported
and we can therefore
design a failure management
we can therefore conclude
a failure management system
can therefore conclude that
failure management system that
therefore conclude that they
management system that is
conclude that they are
system that is independent
that they are indeed
that is independent of
they are indeed rare
is independent of the
independent of the distributed
a solution that tries
of the distributed systems
solution that tries to
the distributed systems packages
that tries to do
distributed systems packages in
tries to do better
a recent exception is
to do better will
systems packages in use
recent exception is an
packages in use and
do better will probably
in use and provide
exception is an attack
use and provide failure
better will probably overreach
and provide failure detection
is an attack on
provide failure detection of
an attack on the
failure detection of processes
attack on the eligius
but you can t
on the eligius pool
you can t get
the eligius pool performed
can t get there
eligius pool performed in
t get there if
pool performed in may
presents the average and
get there if you
the average and minimum
improve the accuracy of
average and minimum download
the accuracy of detection
and minimum download factors
accuracy of detection of
minimum download factors among
of detection of process
download factors among all
there if you close
performed in may and
detection of process and
factors among all correct
of process and node
among all correct nodes
process and node failure
in may and june
and node failure through
all correct nodes under
node failure through systems
correct nodes under different
failure through systems support
if you close your
nodes under different configurations
you close your eyes
close your eyes to
your eyes to the
design support for failure
eyes to the way
the stream rate was
to the way the
stream rate was fixed
the way the customers
rate was fixed at
support for failure detectors
way the customers are
for failure detectors to
the customers are likely
failure detectors to work
customers are likely to
detectors to work in
are likely to use
to work in large
likely to use the
work in large scale
to use the technology
in large scale systems
while maintaining a high
will the web services
and all correct nodes
maintaining a high level
all correct nodes had
a high level of
correct nodes had a
high level of accuracy
nodes had a maximum
the web services community
had a maximum upload
web services community have
a maximum upload factor
services community have the
maximum upload factor of
community have the wisdom
provide support for the
have the wisdom to
support for the detection
the wisdom to tackle
for the detection of
wisdom to tackle the
the detection of partitions
to tackle the tough
detection of partitions in
tackle the tough issues
of partitions in networks
the tough issues before
bitcoin before detecting the
tough issues before circumstances
before detecting the attack
issues before circumstances force
before circumstances force it
circumstances force it upon
build a comprehensive software
force it upon them
at which point payouts
a comprehensive software package
which point payouts to
comprehensive software package that
point payouts to the
software package that can
payouts to the attackers
package that can be
to the attackers were
that can be easily
the attackers were blocked
can be easily integrated
be easily integrated into
easily integrated into various
a fellow of the
the attackers continued the
fellow of the acm
integrated into various distributed
attackers continued the attack
into various distributed systems
various distributed systems packages
we ran experiments with
distributed systems packages and
systems packages and applications
the resulting system is
resulting system is implemented
system is implemented and
is implemented and is
implemented and is under
and is under test
is under test in
more bitcoin before realizing
under test in a
bitcoin before realizing they
test in a wide
nodes and increasing percentages
before realizing they were
and increasing percentages of
realizing they were not
increasing percentages of opportunistic
they were not receiving
percentages of opportunistic nodes
were not receiving their
of opportunistic nodes in
not receiving their payout
opportunistic nodes in the
nodes in the system
in a local setting
a local setting of
local setting of a
setting of a mix
the reasons the attack
of a mix of
reasons the attack was
a mix of high
the attack was so
attack was so easily
and has worked on
was so easily subverted
has worked on reliability
so easily subverted is
worked on reliability and
easily subverted is the
speed and traditional networks
subverted is the limited
and traditional networks and
is the limited efforts
traditional networks and in
on reliability and scalability
networks and in the
the limited efforts of
and in the internet
reliability and scalability issues
limited efforts of the
and scalability issues in
efforts of the attackers
scalability issues in distributed
of the attackers to
issues in distributed systems
a first software release
in distributed systems since
the attackers to hide
distributed systems since starting
attackers to hide themselves
systems since starting his
first software release is
since starting his research
software release is planned
starting his research career
release is planned for
they have only used
is planned for the
have only used two
planned for the autumn
we vary the percentage
he is the author
vary the percentage of
is the author of
for the autumn of
the author of many
the percentage of opportunistic
author of many articles
percentage of opportunistic nodes
of many articles on
only used two payout
many articles on the
used two payout addresses
articles on the subject
two payout addresses to
payout addresses to collect
addresses to collect their
to collect their payouts
we can observe that
can observe that the
and so it was
observe that the download
so it was possible
that the download factors
it was possible for
the download factors of
was possible for the
download factors of correct
possible for the alert
factors of correct nodes
external failure detector modules
for the alert pool
failure detector modules originate
and applications will be
detector modules originate in
applications will be published
modules originate in asynchronous
will be published by
of correct nodes decreases
the alert pool manager
correct nodes decreases since
be published by springer
nodes decreases since the
published by springer verlag
originate in asynchronous distributed
alert pool manager to
in asynchronous distributed systems
by springer verlag in
decreases since the aggregated
pool manager to cluster
since the aggregated upload
springer verlag in fall
the aggregated upload capacity
where they were introduced
aggregated upload capacity in
they were introduced to
manager to cluster the
upload capacity in the
to cluster the attacking
capacity in the system
were introduced to de
in the system becomes
cluster the attacking miners
the attacking miners and
attacking miners and obtain
miners and obtain a
couple the mechanism by
and obtain a statistically
the mechanism by which
obtain a statistically significant
mechanism by which failures
a statistically significant proof
by which failures are
statistically significant proof of
which failures are detected
significant proof of their
failures are detected from
proof of their wrongdoing
are detected from the
detected from the protocols
from the protocols used
the protocols used to
protocols used to tolerate
it is unknown whether
used to tolerate those
to tolerate those failures
is unknown whether this
unknown whether this was
whether this was a
avg download factor min
this was a classical
download factor min download
was a classical block
web services are not
factor min download factor
a classical block withholding
services are not distributed
classical block withholding attack
are not distributed objects
chandra and toueg successfully
with the goal of
and toueg successfully show
the goal of sabotage
toueg successfully show that
successfully show that it
show that it is
that it is possible
or a more elaborate
it is possible to
a more elaborate scheme
is possible to develop
possible to develop consensus
to develop consensus algorithms
develop consensus algorithms using
consensus algorithms using failure
to verify the effectiveness
algorithms using failure detectors
verify the effectiveness of
the effectiveness of block
effectiveness of block withholding
of block withholding for
block withholding for profit
even if these failure
if these failure detectors
these failure detectors make
failure detectors make frequent
detectors make frequent mistakes
make frequent mistakes in
frequent mistakes in their
mistakes in their observations
implemented an experimental bitcoin
an experimental bitcoin test
experimental bitcoin test network
bitcoin test network and
test network and demonstrated
network and demonstrated the
and demonstrated the practicality
demonstrated the practicality of
the practicality of the
practicality of the attack
the failure detector work
failure detector work is
detector work is extended
work is extended to
is extended to systems
bitcoin s health large
extended to systems that
s health large pools
to systems that also
health large pools hinder
systems that also take
large pools hinder bitcoin
that also take network
pools hinder bitcoin s
also take network failure
hinder bitcoin s distributed
take network failure into
bitcoin s distributed nature
network failure into account
s distributed nature as
distributed nature as they
nature as they put
as they put a
they put a lot
put a lot of
a lot of mining
lot of mining power
off in designing practical
of mining power in
in designing practical distributed
mining power in the
designing practical distributed systems
power in the hands
practical distributed systems based
in the hands of
distributed systems based on
the hands of a
systems based on the
hands of a few
based on the theory
of a few pool
on the theory developed
a few pool managers
the theory developed for
theory developed for asynchronous
developed for asynchronous systems
for asynchronous systems is
asynchronous systems is where
this has been mostly
systems is where and
has been mostly addressed
is where and how
been mostly addressed by
where and how to
mostly addressed by community
and how to introduce
addressed by community pressure
how to introduce the
by community pressure on
to introduce the notion
community pressure on miners
introduce the notion of
pressure on miners to
the notion of time
on miners to avoid
miners to avoid forming
to avoid forming large
avoid forming large pools
traditionally failure detectors have
failure detectors have been
detectors have been implemented
have been implemented using
been implemented using time
out mechanisms in the
mechanisms in the transport
in the transport layer
the transport layer that
transport layer that implements
layer that implements inter
however such recommendations had
such recommendations had only
recommendations had only had
had only had limited
only had limited success
outs remain an important
and mining is still
remain an important tool
mining is still dominated
an important tool in
is still dominated by
important tool in the
still dominated by a
tool in the failure
dominated by a small
in the failure manager
by a small number
the failure manager described
a small number of
failure manager described in
small number of large
manager described in this
number of large pools
described in this paper
as a characteristic example
the mechanism is integrated
mechanism is integrated into
is integrated into a
in the period of
integrated into a more
the period of november
into a more comprehensive
a more comprehensive approach
more comprehensive approach that
comprehensive approach that treats
approach that treats failure
that treats failure detection
treats failure detection using
failure detection using methods
detection using methods based
using methods based on
methods based on an
based on an analogy
on an analogy with
an analogy with fault
detection techniques used in
techniques used in daily
used in daily life
when trying to contact
three pools generated over
trying to contact a
to contact a person
contact a person who
a person who has
person who has allegedly
who has allegedly disappeared
has allegedly disappeared one
of the proofs of
allegedly disappeared one would
the proofs of work
disappeared one would never
one would never be
would never be satisfied
never be satisfied with
be satisfied with making
satisfied with making repeated
with making repeated phone
making repeated phone calls
repeated phone calls to
phone calls to the
calls to the same
to the same location
the same location for
same location for half
location for half an
the fact that block
for half an hour
fact that block withholding
half an hour and
optimizing power consumption in
that block withholding attacks
an hour and then
power consumption in large
block withholding attacks are
consumption in large scale
hour and then declaring
in large scale storage
withholding attacks are rarely
large scale storage systems
and then declaring the
scale storage systems lakshmi
attacks are rarely observed
storage systems lakshmi ganesh
then declaring the disappearance
are rarely observed may
declaring the disappearance a
the disappearance a fact
rarely observed may indicate
observed may indicate that
may indicate that the
indicate that the active
that the active pools
no matter whether the
the active pools have
matter whether the phone
active pools have reached
whether the phone was
pools have reached an
the phone was not
have reached an implicit
phone was not picked
ken birman computer science
reached an implicit or
birman computer science department
was not picked up
an implicit or explicit
implicit or explicit agreement
or explicit agreement not
explicit agreement not to
agreement not to attack
a busy tone was
not to attack one
busy tone was heard
to attack one another
tone was heard or
was heard or the
heard or the phone
or the phone was
the phone was disconnected
in practice one would
an attacked pool cannot
practice one would work
attacked pool cannot detect
one would work to
pool cannot detect which
would work to gain
cannot detect which of
work to gain more
detect which of its
to gain more confidence
which of its miners
gain more confidence in
of its miners are
more confidence in such
its miners are attacking
confidence in such a
miners are attacking it
in such a decision
such a decision by
a decision by talking
decision by talking to
edu abstract data centers
by talking to the
abstract data centers are
talking to the landlord
of opportunistic nodes figure
let alone which pool
data centers are the
alone which pool controls
centers are the backend
which pool controls the
the neighbors or others
are the backend for
neighbors or others that
the backend for a
or others that may
backend for a large
pool controls the miners
for a large number
others that may have
a large number of
minimum and average download
large number of services
that may have a
number of services that
at some point a
of services that we
some point a pool
services that we take
may have a more
that we take for
point a pool might
we take for granted
have a more informed
and average download factors
a more informed idea
take for granted today
more informed idea about
average download factors across
informed idea about the
a pool might miscalculate
download factors across all
pool might miscalculate and
factors across all correct
a significant fraction of
might miscalculate and decide
significant fraction of the
across all correct nodes
fraction of the total
all correct nodes when
of the total cost
miscalculate and decide to
the total cost of
correct nodes when opportunistic
total cost of ownership
and decide to try
idea about the situation
nodes when opportunistic nodes
about the situation of
when opportunistic nodes are
cost of ownership of
decide to try and
the situation of the
to try and increase
of ownership of these
opportunistic nodes are present
situation of the person
try and increase its
ownership of these large
of the person in
and increase its revenue
the person in question
each curve corresponds to
curve corresponds to a
corresponds to a different
scale storage systems is
to a different contribution
storage systems is the
the failure management described
a different contribution rate
failure management described in
different contribution rate used
management described in this
contribution rate used by
described in this paper
rate used by opportunistic
in this paper is
systems is the cost
one pool might be
is the cost of
pool might be enough
the cost of keeping
might be enough to
cost of keeping hundreds
be enough to break
of keeping hundreds of
enough to break the
used by opportunistic nodes
this paper is capable
keeping hundreds of thousands
paper is capable of
hundreds of thousands of
is capable of following
of thousands of disks
capable of following a
thousands of disks spinning
of following a similar
to break the agreement
following a similar strategy
we present a simple
possibly leading to a
if a process under
leading to a constant
present a simple idea
a process under investigation
to a constant rate
a simple idea that
a constant rate of
process under investigation is
constant rate of attacks
simple idea that allows
rate of attacks among
under investigation is not
of attacks among pools
idea that allows the
attacks among pools and
investigation is not responding
that allows the storage
among pools and a
allows the storage system
pools and a reduced
is not responding it
the storage system to
and a reduced revenue
storage system to turn
not responding it will
system to turn off
responding it will contact
to turn off a
it will contact the
turn off a large
if open pools reach
will contact the operating
open pools reach a
off a large fraction
pools reach a state
a large fraction of
contact the operating system
reach a state where
the operating system under
a state where their
operating system under which
large fraction of its
system under which the
fraction of its disks
under which the process
state where their revenue
which the process is
where their revenue density
the process is running
their revenue density is
revenue density is reduced
without incurring unacceptable performance
density is reduced due
incurring unacceptable performance penalties
is reduced due to
or other nodes on
reduced due to attacks
other nodes on the
nodes on the same
on the same sub
of particular appeal is
particular appeal is the
miners will leave them
appeal is the fact
will leave them in
net to help reach
leave them in favor
is the fact that
them in favor of
to help reach a
in favor of other
the fact that our
favor of other available
help reach a decision
of other available options
fact that our solution
reach a decision in
that our solution is
a decision in which
our solution is not
decision in which one
solution is not application
in which one can
miners of sufficient size
which one can have
of sufficient size can
one can have greater
sufficient size can mine
can have greater confidence
size can mine solo
smaller miners can form
miners can form private
can form private pools
savings for a very
form private pools with
for a very generic
avg upload factor min
a very generic data
upload factor min upload
very generic data center
factor min upload factor
generic data center model
most distributed systems in
private pools with closed
distributed systems in use
pools with closed access
systems in use today
in use today deal
use today deal with
today deal with failure
we describe our solution
deal with failure of
limited to trusted participants
with failure of nodes
failure of nodes or
of nodes or networks
identify the parameters that
nodes or networks in
the parameters that determine
or networks in some
parameters that determine its
networks in some way
that determine its cost
such a change may
a change may be
change may be in
may be in favor
be in favor of
in general the problem
in favor of bitcoin
favor of bitcoin as
general the problem is
of bitcoin as a
and present a simulator
the problem is detected
present a simulator that
bitcoin as a whole
problem is detected in
a simulator that allows
is detected in the
simulator that allows us
detected in the communication
that allows us to
since they require such
allows us to explore
in the communication subsystem
us to explore this
they require such intimate
to explore this parameter
require such intimate trust
explore this parameter space
the communication subsystem where
communication subsystem where session
subsystem where session or
private pools are likely
where session or transport
pools are likely to
we also present some
session or transport protocols
are likely to be
or transport protocols are
likely to be smaller
also present some initial
transport protocols are unable
present some initial simulation
protocols are unable to
some initial simulation results
and form a fine
are unable to make
initial simulation results that
unable to make progress
form a fine grained
to make progress because
simulation results that add
make progress because of
a fine grained distribution
progress because of the
fine grained distribution of
results that add weight
grained distribution of mining
because of the lack
distribution of mining power
of the lack of
of mining power with
that add weight to
the lack of response
mining power with many
add weight to our
lack of response from
weight to our claim
of response from remote
power with many small
to our claim that
with many small pools
response from remote nodes
our claim that our
many small pools and
claim that our solution
small pools and solo
that our solution represents
pools and solo miners
our solution represents a
solution represents a new
traditionally packets are being
represents a new powersaving
packets are being retransmitted
a new powersaving opportunity
are being retransmitted after
new powersaving opportunity for
being retransmitted after a
powersaving opportunity for large
retransmitted after a time
out period and after
period and after a
and after a retry
after a retry threshold
a retry threshold is
retry threshold is reached
threshold is reached the
a pool may engage
is reached the remote
introduction the declining costs
reached the remote destination
pool may engage in
the remote destination is
the declining costs of
remote destination is marked
may engage in an
destination is marked as
declining costs of commodity
is marked as unreachable
engage in an attack
costs of commodity disk
in an attack against
of commodity disk drives
an attack against another
commodity disk drives has
attack against another pool
disk drives has made
some systems inject additional
drives has made online
against another pool not
has made online data
systems inject additional packets
made online data storage
another pool not to
online data storage a
pool not to increase
data storage a way
not to increase its
storage a way of
to increase its absolute
inject additional packets into
a way of life
increase its absolute revenue
additional packets into the
packets into the data
into the data stream
the data stream to
so much so that
but rather to attract
data stream to ensure
rather to attract miners
much so that companies
to attract miners by
stream to ensure timely
attract miners by temporarily
so that companies like
miners by temporarily increasing
to ensure timely detection
by temporarily increasing its
that companies like google
temporarily increasing its revenue
companies like google and
increasing its revenue relative
like google and yahoo
its revenue relative to
ensure timely detection of
revenue relative to a
google and yahoo host
relative to a competing
timely detection of failures
to a competing pool
detection of failures at
and yahoo host hundreds
of failures at moments
yahoo host hundreds of
failures at moments when
recent work has investigated
host hundreds of thousands
at moments when the
hundreds of thousands of
work has investigated the
of thousands of servers
moments when the traffic
thousands of servers for
when the traffic is
of servers for storage
the traffic is low
has investigated the motivation
traffic is low or
investigated the motivation of
is low or unidirectional
the motivation of pools
motivation of pools to
of pools to utilize
pools to utilize part
there is a catch
to utilize part of
utilize part of their
part of their resources
of their resources towards
a hundred thousand servers
their resources towards sabotage
hundred thousand servers consume
resources towards sabotage attacks
thousand servers consume a
towards sabotage attacks against
servers consume a lot
sabotage attacks against each
consume a lot of
attacks against each other
a lot of power
not only does this
only does this translate
does this translate to
this translate to many
translate to many millions
to many millions of
many millions of dollars
millions of dollars annually
of dollars annually on
expect the application to
dollars annually on electricity
the application to handle
annually on electricity bills
application to handle the
to handle the failure
handle the failure management
the failure management as
the heat produced by
failure management as the
heat produced by so
management as the support
produced by so much
as the support system
by so much computing
the support system does
so much computing power
support system does not
much computing power can
system does not contain
computing power can be
does not contain any
power can be searing
not contain any fault
contain any fault management
the model of those
an article in the
model of those works
article in the new
often these systems cannot
in the new york
of those works is
the new york times
these systems cannot distinguish
new york times describes
those works is different
york times describes one
systems cannot distinguish between
times describes one of
works is different from
describes one of google
cannot distinguish between process
one of google s
is different from the
of google s data
google s data centers
different from the pool
node or network failure
from the pool game
the pool game model
pool game model in
game model in two
the mechanisms used to
model in two major
mechanisms used to detect
in two major ways
used to detect failure
two major ways a
to detect failure do
a computing center as
detect failure do not
major ways a sabotage
failure do not adapt
computing center as big
do not adapt to
center as big as
not adapt to changing
as big as two
adapt to changing network
ways a sabotage attack
to changing network conditions
big as two football
a sabotage attack does
as two football fields
sabotage attack does not
attack does not transfer
does not transfer revenue
making it almost impossible
not transfer revenue from
with twin cooling plants
transfer revenue from victim
twin cooling plants protruding
revenue from victim to
cooling plants protruding four
from victim to attacker
it almost impossible to
plants protruding four stories
protruding four stories into
almost impossible to use
four stories into the
of opportunistic nodes figure
impossible to use these
and migrating miners switch
stories into the sky
migrating miners switch to
to use these systems
miners switch to less
switch to less attacked
use these systems unmodified
to less attacked pools
these systems unmodified in
systems unmodified in wide
minimum and average upload
unmodified in wide area
changing pool sizes and
and average upload factors
pool sizes and hence
in wide area systems
sizes and hence revenues
average upload factors across
and hence revenues until
wide area systems without
hence revenues until convergence
upload factors across all
area systems without resorting
factors across all correct
systems without resorting to
across all correct nodes
without resorting to heavy
all correct nodes when
the model is parametrized
correct nodes when opportunistic
resorting to heavy weight
power conservation is an
to heavy weight solutions
conservation is an important
model is parametrized by
is an important concern
heavy weight solutions like
an important concern for
is parametrized by the
nodes when opportunistic nodes
parametrized by the cost
when opportunistic nodes are
by the cost of
important concern for big
the cost of the
concern for big server
cost of the attack
for big server clusters
of the attack and
opportunistic nodes are present
weight solutions like using
the attack and by
solutions like using a
since disks account for
attack and by the
disks account for a
and by the mobility
account for a significant
by the mobility of
for a significant fraction
the mobility of the
each curve corresponds to
like using a tcp
a significant fraction of
mobility of the miners
curve corresponds to a
using a tcp connection
corresponds to a different
significant fraction of the
to a different contribution
fraction of the energy
a different contribution rate
and the analysis demonstrates
of the energy consumed
the analysis demonstrates that
different contribution rate used
analysis demonstrates that when
contribution rate used by
a tcp connection as
demonstrates that when considering
tcp connection as the
rate used by opportunistic
connection as the preferred
used by opportunistic nodes
as the preferred transport
that when considering only
the preferred transport method
when considering only sabotage
preferred transport method for
considering only sabotage attacks
transport method for each
insufficient to provide all
only sabotage attacks there
to provide all nodes
several approaches for disk
provide all nodes with
method for each rpc
sabotage attacks there are
approaches for disk power
attacks there are regions
for each rpc call
all nodes with all
for disk power management
there are regions where
disk power management have
are regions where no
power management have been
nodes with all data
management have been proposed
have been proposed and
been proposed and studied
attack is the best
especially those designed to
is the best strategy
those designed to support
designed to support high
we will examine some
will examine some of
the extent of the
the miner s dilemma
extent of the impact
examine some of these
of the impact may
some of these here
the impact may be
miner s dilemma is
impact may be surprising
s dilemma is therefore
dilemma is therefore not
is therefore not manifested
but first let us
therefore not manifested in
management in a more
not manifested in that
in a more integrated
first let us lay
manifested in that model
let us lay out
a more integrated way
us lay out some
lay out some of
out some of the
some of the groundwork
pool competition for miners
many of these systems
competition for miners is
of these systems are
for miners is an
any disk power management
miners is an incentive
these systems are structured
is an incentive in
performance drops by as
an incentive in and
drops by as much
incentive in and of
by as much as
in and of its
systems are structured as
disk power management scheme
are structured as groups
power management scheme essentially
structured as groups of
management scheme essentially attempts
as groups of cooperating
scheme essentially attempts to
groups of cooperating processes
essentially attempts to exploit
and of its own
of cooperating processes using
attempts to exploit one
cooperating processes using some
to exploit one fact
of its own for
processes using some form
its own for mutual
using some form of
own for mutual attacks
disks can be run
some form of group
presents the average and
form of group membership
can be run in
the average and minimum
be run in highpower
average and minimum upload
run in highpower mode
and minimum upload factors
and a pool may
minimum upload factors among
a pool may therefore
upload factors among all
pool may therefore choose
factors among all correct
detection to be able
may therefore choose to
among all correct nodes
to be able to
therefore choose to perform
be able to reach
choose to perform block
able to reach consensus
to perform block withholding
with a corresponding performance
perform block withholding even
a corresponding performance tradeoff
block withholding even if
various methods are used
withholding even if its
even if its revenue
if its revenue would
axis we vary the
its revenue would increase
of which fault monitors
we vary the percentage
revenue would increase only
vary the percentage of
a disk can be
the percentage of opportunistic
would increase only after
disk can be shut
increase only after the
can be shut off
only after the next
percentage of opportunistic nodes
after the next difficult
be shut off so
the next difficult adjustment
shut off so that
off so that it
so that it consumes
and on the y
that it consumes no
it consumes no power
the two models are
two models are therefore
models are therefore complimentary
axis we present the
we present the upload
given a large cluster
present the upload factors
a large cluster of
the upload factors of
large cluster of disks
upload factors of nodes
the analysis of their
analysis of their combination
of their combination is
their combination is left
only a fraction of
combination is left for
a fraction of them
is left for future
fraction of them is
left for future work
of them is accessed
which can vary up
them is accessed at
can vary up to
is accessed at any
accessed at any time
so that the rest
that the rest could
the rest could potentially
rest could potentially be
could potentially be switched
potentially be switched to
be switched to a
we assumed in our
switched to a low
are the most popular
assumed in our analysis
it is interesting to
in our analysis that
is interesting to note
our analysis that pools
interesting to note that
however in each of
to note that the
analysis that pools do
in each of these
note that the average
that pools do not
since mode transitions consume
that the average upload
each of these systems
the average upload factor
mode transitions consume time
average upload factor among
of these systems the
upload factor among correct
pools do not charge
these systems the failure
do not charge fees
factor among correct nodes
not charge fees from
among correct nodes initially
charge fees from their
correct nodes initially increases
systems the failure management
fees from their members
the failure management is
from their members since
failure management is an
their members since such
management is an integral
members since such fees
and then starts falling
since such fees are
is an integral part
such fees are typically
then starts falling when
fees are typically nominal
an integral part of
starts falling when the
integral part of the
falling when the percentage
part of the particular
when the percentage of
of the particular membership
the percentage of opportunistic
the particular membership or
transitions consume time and
particular membership or transport
percentage of opportunistic nodes
membership or transport system
of opportunistic nodes increases
or transport system and
opportunistic nodes increases significantly
transport system and not
consume time and power
system and not available
and not available for
of a pool s
not available for general
a pool s revenue
available for general use
disk management schemes have
this behavior can be
management schemes have to
behavior can be explained
schemes have to walk
can be explained by
although some research groups
be explained by the
have to walk the
explained by the fact
to walk the tightrope
by the fact that
walk the tightrope of
the tightrope of finding
tightrope of finding the
of finding the right
finding the right balance
the right balance between
right balance between power
balance between power consumption
correct nodes start contributing
between power consumption and
nodes start contributing more
power consumption and performance
the model can be
start contributing more to
model can be extended
contributing more to compensate
can be extended to
more to compensate for
be extended to include
the solution space explored
extended to include pools
to compensate for the
to include pools fees
solution space explored thus
compensate for the lack
space explored thus far
for the lack of
explored thus far in
the lack of data
thus far in the
lack of data provided
far in the literature
of data provided by
fees would add a
in the literature can
would add a friction
the literature can be
add a friction element
literature can be divided
are focusing on wide
data provided by a
a friction element to
provided by a small
focusing on wide area
can be divided as
friction element to the
by a small percentage
element to the flow
a small percentage of
to the flow of
small percentage of opportunistic
the flow of revenue
be divided as follows
on wide area systems
percentage of opportunistic nodes
flow of revenue among
of revenue among infiltrated
revenue among infiltrated and
among infiltrated and infiltrating
the majority of the
infiltrated and infiltrating pools
majority of the existing
of the existing failure
the existing failure detectors
once the effect of
existing failure detectors are
the effect of opportunistic
failure detectors are not
effect of opportunistic nodes
detectors are not suitable
of opportunistic nodes becomes
are not suitable for
opportunistic nodes becomes significant
not suitable for use
suitable for use in
for use in large
use in large scale
would change to take
in large scale systems
change to take into
the system collapses and
to take into account
system collapses and correct
take into account a
collapses and correct nodes
because of their inflexibility
and correct nodes are
of their inflexibility or
correct nodes are not
their inflexibility or the
nodes are not able
inflexibility or the simplicity
are not able to
into account a pool
or the simplicity of
account a pool fee
the simplicity of their
a pool fee of
simplicity of their assumptions
pool fee of f
not able to keep
fee of f pp
able to keep contributing
of f pp ri
another important point to
important point to note
building a failure detector
point to note is
to note is that
a failure detector that
note is that the
is that the minimum
failure detector that is
that the minimum upload
each of these solutions
the minimum upload factor
of these solutions proposes
minimum upload factor does
these solutions proposes a
upload factor does not
solutions proposes a new
factor does not follow
proposes a new system
does not follow a
a new system of
not follow a clearly
detector that is not
follow a clearly defined
new system of some
that is not an
a clearly defined pattern
system of some kind
is not an integral
not an integral part
making it hard to
an integral part of
it hard to estimate
hard to estimate the
integral part of the
to estimate the minimum
based solutions propose novel
part of the communication
estimate the minimum contribution
solutions propose novel storage
the minimum contribution of
of the communication architecture
minimum contribution of correct
propose novel storage hierarchies
contribution of correct nodes
the communication architecture permits
of correct nodes under
novel storage hierarchies to
correct nodes under compromised
communication architecture permits the
nodes under compromised scenarios
storage hierarchies to strike
architecture permits the implementation
hierarchies to strike the
to strike the right
permits the implementation of
strike the right balance
the right balance between
the implementation of a
right balance between performance
balance between performance and
by applying thresholds to
implementation of a collection
applying thresholds to punish
between performance and power
thresholds to punish opportunistic
of a collection of
to punish opportunistic nodes
performance and power consumption
a collection of failure
collection of failure detection
correct nodes may also
of failure detection techniques
disk management solutions interject
nodes may also be
failure detection techniques and
may also be unfairly
management solutions interject a
detection techniques and support
also be unfairly penalized
solutions interject a new
techniques and support for
interject a new disk
and support for failure
a new disk management
support for failure detection
new disk management layer
for failure detection methods
disk management layer on
failure detection methods of
management layer on top
detection methods of varying
layer on top of
methods of varying levels
auditing protocol our idea
on top of the
protocol our idea for
top of the file
of varying levels of
our idea for auditing
varying levels of complexity
idea for auditing the
of the file system
levels of complexity from
for auditing the described
of complexity from which
auditing the described live
complexity from which the
which controls disk configuration
a pool with a
from which the system
pool with a fee
controls disk configuration and
with a fee of
which the system designer
a fee of f
the system designer can
fee of f is
system designer can choose
of f is a
disk configuration and data
f is a less
designer can choose to
is a less attractive
configuration and data layout
a less attractive target
and data layout to
streaming system against opportunistic
can choose to match
less attractive target for
choose to match the
attractive target for block
to match the system
target for block withholding
data layout to achieve
system against opportunistic behavior
match the system requirements
layout to achieve power
since the attacker s
against opportunistic behavior is
the attacker s revenue
opportunistic behavior is motivated
attacker s revenue is
behavior is motivated by
s revenue is reduced
is motivated by the
revenue is reduced by
optimal disk access patterns
the failure management service
motivated by the graphs
failure management service consists
by the graphs presented
management service consists of
the graphs presented in
caching solutions devise new
graphs presented in the
solutions devise new power
presented in the previous
is reduced by f
service consists of three
in the previous section
consists of three functional
of three functional modules
aware caching algorithms that
however it is also
caching algorithms that allow
it is also less
we propose to employ
is also less attractive
algorithms that allow large
also less attractive for
propose to employ auditing
less attractive for miners
that allow large fractions
to employ auditing to
allow large fractions of
employ auditing to ensure
attractive for miners in
auditing to ensure that
for miners in general
to ensure that all
large fractions of the
ensure that all nodes
fractions of the storage
that all nodes in
of the storage system
all nodes in the
trading off the two
nodes in the system
the storage system to
in the system contribute
storage system to remain
the system contribute more
system to remain idle
off the two for
to remain idle for
system contribute more than
remain idle for longer
a library that implements
the two for best
contribute more than a
two for best protection
more than a particular
for best protection is
than a particular specified
best protection is left
a particular specified threshold
protection is left for
library that implements simple
idle for longer periods
that implements simple failure
for longer periods of
is left for future
implements simple failure management
longer periods of time
simple failure management functionality
left for future work
failure management functionality and
management functionality and provide
functionality and provide the
allowing them to be
and provide the api
them to be switched
as part of the
to be switched to
provide the api to
we illustrate the potential
part of the treatment
illustrate the potential benefit
of the treatment of
be switched to lower
the treatment of the
switched to lower power
the api to the
the potential benefit from
treatment of the miner
potential benefit from using
api to the complete
to lower power modes
benefit from using auditing
to the complete service
from using auditing in
using auditing in a
auditing in a system
the principal contribution of
in a system where
a service implementing per
principal contribution of this
service implementing per node
r elated w ork
contribution of this paper
implementing per node failure
of this paper is
per node failure management
this paper is to
elated w ork a
paper is to argue
is to argue that
to argue that there
argue that there is
of the nodes are
that there is a
the nodes are correct
there is a fourth
nodes are correct and
is a fourth niche
combining fault management with
the block withholding attack
fault management with other
a fourth niche as
management with other local
fourth niche as yet
block withholding attack the
with other local nodes
withholding attack the danger
other local nodes to
attack the danger of
local nodes to exploit
niche as yet unexplored
nodes to exploit locality
the danger of a
to exploit locality of
danger of a block
exploit locality of communication
of a block withholding
the latter do not
a block withholding attack
locality of communication and
block withholding attack is
of communication and failure
withholding attack is as
communication and failure patterns
attack is as old
latter do not upload
is as old as
do not upload any
as old as bitcoin
not upload any data
old as bitcoin pools
an inquiry service closely
inquiry service closely coupled
service closely coupled with
closely coupled with the
we do not present
coupled with the operating
the attack was described
with the operating system
do not present a
the operating system which
attack was described by
not present a new
was described by rosenfeld
present a new system
provides information about the
information about the state
no punishment was applied
about the state of
punishment was applied in
we take an idea
was applied in an
the state of local
applied in an attempt
state of local participating
in an attempt to
take an idea that
an attempt to simulate
of local participating processes
attempt to simulate a
an idea that has
to simulate a system
idea that has been
simulate a system with
that has been around
a system with no
has been around for
system with no auditing
been around for well
around for well over
for well over a
the most fundamental operation
well over a decade
most fundamental operation offered
over a decade now
fundamental operation offered by
operation offered by a
as pools were becoming
offered by a failure
pools were becoming a
by a failure detection
were becoming a dominant
a failure detection service
becoming a dominant player
failure detection service is
a dominant player in
detection service is that
dominant player in the
service is that of
player in the bitcoin
is that of the
in the bitcoin world
that of the investigation
of the investigation of
the investigation of a
auditing is enabled and
investigation of a suspected
is enabled and opportunistic
the paper described the
enabled and opportunistic nodes
paper described the standard
of a suspected process
described the standard attack
and opportunistic nodes start
opportunistic nodes start to
nodes start to be
start to be expelled
to be expelled from
used by a miner
to make use of
by a miner to
be expelled from the
a miner to sabotage
expelled from the system
and argue that technological
make use of this
argue that technological evolution
from the system for
that technological evolution has
the system for low
miner to sabotage a
use of this operation
to sabotage a pool
system for low contribution
sabotage a pool at
of this operation it
a pool at the
technological evolution has given
pool at the cost
this operation it is
at the cost of
evolution has given it
operation it is not
has given it a
the cost of reducing
given it a new
cost of reducing its
it a new relevance
the minimum upload factor
it is not necessary
minimum upload factor for
a new relevance today
upload factor for nodes
is not necessary for
factor for nodes to
new relevance today as
for nodes to stay
not necessary for either
nodes to stay in
relevance today as a
to stay in the
today as a natural
stay in the system
as a natural power
in the system was
necessary for either the
of reducing its own
for either the local
reducing its own revenue
the system was set
saving opportunity for large
system was set to
either the local or
the local or remote
local or remote process
a more general view
or remote process to
more general view of
remote process to run
general view of fairness
process to run any
view of fairness in
the key insight is
of fairness in proof
key insight is that
fairness in proof of
to run any of
in proof of work
run any of the
proof of work schemes
any of the heartbeat
where other solutions attempt
of work schemes was
of the heartbeat or
other solutions attempt to
work schemes was discussed
solutions attempt to predict
schemes was discussed in
attempt to predict disk
the heartbeat or polling
to predict disk access
heartbeat or polling patterns
predict disk access to
disk access to determine
access to determine which
to determine which disks
determine which disks to
which disks to power
the reasons that the
disks to power down
reasons that the local
that the local process
the local process began
local process began to
the lfs automatically provides
process began to suspect
lfs automatically provides a
began to suspect the
automatically provides a perfect
to suspect the remote
provides a perfect prediction
suspect the remote process
a perfect prediction mechanism
the remote process are
remote process are not
process are not of
are not of any
not of any importance
simply by virtue of
of any importance to
by virtue of the
any importance to the
virtue of the fact
importance to the failure
of the fact that
to the failure management
the fact that all
in the context of
fact that all write
the context of the
context of the hashcash
of the hashcash system
accesses go to the
without auditing with auditing
go to the log
to the log head
explains and expands on
and expands on this
expands on this idea
early work did not
work did not address
did not address the
not address the possibility
address the possibility of
the possibility of pools
possibility of pools infiltrating
of pools infiltrating other
pools infiltrating other pools
infiltrating other pools for
the process at address
other pools for block
process at address is
idea overview to see
pools for block withholding
overview to see why
at address is investigated
to see why lfs
address is investigated and
see why lfs is
is investigated and a
why lfs is a
investigated and a report
lfs is a natural
and a report is
is a natural solution
a report is returned
a natural solution to
report is returned within
natural solution to the
is returned within the
solution to the problem
returned within the deadline
to the problem of
within the deadline set
the problem of disk
the deadline set by
problem of disk power
deadline set by the
of disk power management
set by the local
by the local process
consider some of the
experimentally demonstrate that block
some of the challenges
the local process does
of the challenges involved
demonstrate that block withholding
local process does not
that block withholding can
process does not have
block withholding can increase
download factor of correct
withholding can increase the
does not have to
can increase the attacker
factor of correct nodes
not have to wait
of correct nodes during
increase the attacker s
correct nodes during a
have to wait for
server systems typically are
the attacker s revenue
to wait for the
systems typically are not
wait for the investigation
typically are not idle
for the investigation to
are not idle long
they do not address
not idle long enough
do not address the
idle long enough to
not address the question
long enough to make
address the question of
enough to make it
the question of mutual
second streaming session with
the investigation to finish
to make it worthwhile
investigation to finish but
make it worthwhile to
question of mutual attacks
to finish but can
it worthwhile to incur
finish but can make
worthwhile to incur the
but can make use
to incur the time
can make use of
make use of the
use of the asynch
of the asynch interface
the asynch interface to
power expense of switching
asynch interface to collect
expense of switching the
auditing is enabled in
of switching the disk
is enabled in the
switching the disk to
enabled in the last
the disk to a
interface to collect the
disk to a lowpower
to collect the result
to a lowpower mode
collect the result at
have recently noted that
the result at a
recently noted that a
result at a later
noted that a pool
at a later moment
and switching it back
that a pool can
switching it back when
a pool can increase
it back when it
pool can increase its
back when it is
can increase its overall
the report contains information
we present the minimum
when it is accessed
increase its overall revenue
report contains information on
its overall revenue with
contains information on whether
overall revenue with block
average and maximum download
information on whether the
this is a notable
revenue with block withholding
is a notable point
on whether the remote
a notable point of
with block withholding if
notable point of difference
whether the remote node
point of difference between
block withholding if all
of difference between server
withholding if all other
difference between server systems
if all other mining
between server systems and
all other mining is
and maximum download factors
other mining is performed
server systems and typical
mining is performed by
maximum download factors across
is performed by honest
systems and typical mobile
the remote node was
and typical mobile device
performed by honest pools
download factors across correct
remote node was reachable
factors across correct nodes
typical mobile device scenarios
node was reachable within
across correct nodes varying
was reachable within the
correct nodes varying along
reachable within the deadline
we consider the general
within the deadline and
consider the general case
the deadline and whether
the general case where
deadline and whether the
general case where not
and whether the process
case where not all
whether the process under
where not all mining
the process under investigation
not all mining is
which makes it hard
all mining is performed
process under investigation was
mining is performed through
makes it hard to
is performed through public
under investigation was still
it hard to translate
investigation was still present
as observed in this
performed through public pools
hard to translate the
was still present at
to translate the solutions
still present at the
observed in this particular
translate the solutions devised
and analyze situations where
the solutions devised for
analyze situations where pools
solutions devised for mobile
situations where pools can
devised for mobile devices
where pools can attack
for mobile devices to
pools can attack one
mobile devices to server
present at the host
in this particular example
can attack one another
devices to server systems
if the mode parameter
auditing has the potential
the mode parameter was
the discrepancy between the
mode parameter was used
discrepancy between the calculations
parameter was used to
between the calculations of
was used to request
has the potential to
used to request a
as we shall see
to request a more
the potential to improve
request a more detailed
potential to improve the
a more detailed remote
to improve the quality
more detailed remote reporting
improve the quality of
the quality of streamed
quality of streamed sessions
access to a small
of streamed sessions significantly
process checkpoint information is
to a small subset
and our results for
a small subset of
checkpoint information is returned
our results for the
information is returned or
and at low cost
is returned or the
results for the special
returned or the remote
small subset of disks
or the remote process
for the special case
the remote process is
one important concern is
remote process is interrupted
important concern is that
process is interrupted to
the special case analyzed
is interrupted to provide
concern is that if
special case analyzed there
is that if the
interrupted to provide status
when combined with a
to provide status information
that if the specified
case analyzed there can
if the specified threshold
combined with a cache
the specified threshold is
with a cache that
specified threshold is too
a cache that absorbs
threshold is too high
cache that absorbs read
analyzed there can be
see the section on
there can be explained
the section on os
can be explained by
section on os integration
be explained by the
more opportunistic nodes may
explained by the strong
opportunistic nodes may be
by the strong approximations
nodes may be caught
the strong approximations in
results in long disk
strong approximations in that
in long disk idle
approximations in that work
long disk idle periods
if the node was
but correct nodes may
the node was not
correct nodes may also
node was not reachable
nodes may also be
low predictability of idle
may also be unfairly
predictability of idle periods
also be unfairly punished
was not reachable and
not reachable and the
we calculate exactly how
reachable and the local
and the local process
calculate exactly how infiltrating
the local process has
exactly how infiltrating miners
local process has requested
how infiltrating miners reduce
no correct nodes were
process has requested extensive
correct nodes were mistakenly
infiltrating miners reduce the
nodes were mistakenly expelled
has requested extensive investigation
were mistakenly expelled from
miners reduce the revenue
mistakenly expelled from the
reduce the revenue density
have shown that there
the revenue density of
expelled from the system
revenue density of the
shown that there exists
the failure investigator will
density of the infiltrated
failure investigator will try
of the infiltrated pool
investigator will try to
that there exists low
will try to contact
there exists low correlation
try to contact a
exists low correlation between
to contact a failure
low correlation between a
contact a failure manager
correlation between a given
a failure manager at
temporary block withholding in
failure manager at the
between a given idle
block withholding in the
a given idle period
auditing components we now
given idle period s
withholding in the block
idle period s duration
components we now give
manager at the node
in the block withholding
period s duration and
the block withholding attack
s duration and the
block withholding attack discussed
duration and the duration
we now give some
and the duration of
withholding attack discussed in
now give some additional
net or within its
give some additional details
the duration of previous
some additional details of
duration of previous idle
additional details of the
of previous idle periods
details of the auditing
or within its administrative
of the auditing architecture
attack discussed in this
within its administrative domain
discussed in this work
its administrative domain which
this variability makes it
in this work the
focusing upon two aspects
variability makes it difficult
administrative domain which should
makes it difficult to
this work the withheld
it difficult to devise
work the withheld blocks
difficult to devise effective
the withheld blocks are
domain which should be
withheld blocks are never
to devise effective predictive
which should be able
devise effective predictive mechanisms
should be able to
effective predictive mechanisms for
be able to give
predictive mechanisms for disk
able to give a
mechanisms for disk idle
to give a more
for disk idle times
blocks are never published
give a more conclusive
collecting accountable information about
a more conclusive answer
accountable information about the
more conclusive answer about
information about the download
conclusive answer about the
the lfs neatly circumvents
about the download and
answer about the node
the download and upload
lfs neatly circumvents this
download and upload factors
blocks can be withheld
and upload factors of
can be withheld temporarily
upload factors of individual
neatly circumvents this problem
factors of individual nodes
s failure to respond
of individual nodes in
circumvents this problem by
not following the bitcoin
this problem by predetermining
following the bitcoin protocol
individual nodes in the
problem by predetermining which
nodes in the system
by predetermining which disk
if network failure is
predetermining which disk is
to improve an attacker
which disk is written
improve an attacker s
disk is written to
an attacker s revenue
is written to at
network failure is the
written to at all
failure is the cause
to at all times
is the cause of
the cause of the
a miner or a
cause of the loss
miner or a pool
of the loss of
or a pool can
the loss of connectivity
a pool can perform
pool can perform a
can perform a selfish
server systems are often
perform a selfish mining
the report will indicate
a selfish mining attack
systems are often constrained
establishing and applying the
are often constrained by
and applying the best
often constrained by service
report will indicate which
applying the best threshold
constrained by service level
will indicate which part
by service level agreements
indicate which part of
service level agreements to
which part of the
level agreements to guarantee
part of the path
agreements to guarantee a
of the path is
to guarantee a certain
the path is reachable
guarantee a certain level
path is reachable and
a certain level of
is reachable and where
certain level of performance
with selfish mining the
the best threshold at
reachable and where the
best threshold at any
selfish mining the attacker
threshold at any given
and where the suspected
at any given time
mining the attacker increases
any given time during
so that finding a
given time during execution
the attacker increases its
that finding a solution
attacker increases its revenue
finding a solution that
increases its revenue by
a solution that provides
we employ two types
its revenue by temporarily
solution that provides acceptable
employ two types of
revenue by temporarily withholding
two types of components
if the failure investigator
by temporarily withholding its
types of components to
that provides acceptable performance
of components to perform
temporarily withholding its blocks
components to perform these
provides acceptable performance to
the failure investigator is
acceptable performance to only
to perform these two
performance to only a
perform these two roles
to only a fraction
failure investigator is configured
only a fraction of
withholding its blocks and
investigator is configured with
its blocks and publishing
local and global auditors
is configured with alternative
a fraction of the
configured with alternative outgoing
fraction of the incoming
blocks and publishing them
with alternative outgoing paths
local auditors are executed
and publishing them in
of the incoming requests
publishing them in response
auditors are executed on
them in response to
are executed on the
these paths are probed
in response to block
albeit a large fraction
executed on the nodes
paths are probed to
on the nodes participating
response to block publication
the nodes participating in
are probed to see
nodes participating in the
may often not be
probed to see if
often not be sufficient
to block publication by
participating in the system
block publication by other
to see if it
publication by other pools
see if it is
by other pools and
if it is possible
and therefore cannot be
other pools and miners
as we shall show
it is possible to
therefore cannot be trusted
is possible to circumvent
possible to circumvent the
to circumvent the network
the lfs provides an
this attack is independent
circumvent the network failure
attack is independent of
the network failure and
if a node is
lfs provides an applicationindependent
is independent of the
provides an applicationindependent solution
independent of the block
an applicationindependent solution that
of the block withholding
network failure and in
the block withholding attack
failure and in such
block withholding attack we
applicationindependent solution that allows
a node is malicious
solution that allows the
withholding attack we discuss
that allows the system
and in such a
allows the system to
in such a way
the system to perform
such a way collect
attack we discuss here
a way collect information
system to perform consistently
way collect information about
we discuss here and
collect information about the
to perform consistently across
it might report false
perform consistently across a
might report false data
consistently across a wide
information about the remote
discuss here and the
about the remote process
across a wide range
here and the two
a wide range of
and the two can
wide range of datasets
the two can be
global auditors are trusted
the report contains information
auditors are trusted components
two can be performed
are trusted components that
can be performed in
trusted components that run
be performed in concert
components that run on
the law of large
that run on dedicated
law of large numbers
run on dedicated external
report contains information about
on dedicated external nodes
an attacker can also
contains information about the
attacker can also perform
information about the results
large scale server systems
about the results of
can also perform a
the results of these
there can be just
scale server systems process
can be just one
results of these probes
be just one or
server systems process incredibly
also perform a double
systems process incredibly large
perform a double spending
process incredibly large request
just one or a
incredibly large request loads
one or a few
early triggers many systems
a double spending attack
or a few global
double spending attack as
a few global auditors
spending attack as follows
directing these to a
triggers many systems find
these to a small
many systems find it
to a small fraction
we describe their roles
a small fraction of
describe their roles and
small fraction of the
their roles and interactions
fraction of the total
roles and interactions in
systems find it desirable
of the total number
find it desirable to
the total number of
and interactions in detail
it desirable to detect
total number of disks
desirable to detect failure
interactions in detail below
to detect failure of
detect failure of remote
he intentionally generates two
failure of remote processes
the fraction that is
of remote processes even
fraction that is in
intentionally generates two conflicting
remote processes even if
generates two conflicting transactions
processes even if there
that is in high
even if there is
if there is no
places one in a
there is no data
one in a block
is no data exchange
in a block it
no data exchange actually
a block it withholds
can significantly raise the
data exchange actually under
significantly raise the probability
exchange actually under way
raise the probability of
local auditors each node
the probability of error
auditors each node n
probability of error and
each node n runs
of error and failure
node n runs a
and publishes the other
systems are free to
publishes the other transaction
n runs a local
are free to implement
the fact that the
runs a local auditor
fact that the disks
free to implement whatever
after the recipient sees
that the disks used
the recipient sees the
to implement whatever scheme
recipient sees the published
which interacts with other
implement whatever scheme they
sees the published transaction
the disks used in
interacts with other local
disks used in these
whatever scheme they find
used in these contexts
with other local auditors
in these contexts are
the attacker publishes the
these contexts are typically
attacker publishes the withheld
contexts are typically low
other local auditors and
scheme they find appropriate
local auditors and has
publishes the withheld block
they find appropriate and
the withheld block to
auditors and has two
withheld block to revoke
and has two main
block to revoke the
has two main roles
to revoke the former
find appropriate and use
end with relatively weak
appropriate and use the
with relatively weak reliability
and use the failure
publish n s data
relatively weak reliability guarantees
revoke the former transaction
use the failure investigator
n s data exchange
the failure investigator from
s data exchange history
failure investigator from the
investigator from the previous
this attack is performed
from the previous section
attack is performed by
as we shall see
the previous section to
n s local auditor
is performed by miners
s local auditor periodically
performed by miners or
previous section to handle
our solution alleviates this
section to handle the
local auditor periodically compiles
by miners or pools
auditor periodically compiles and
miners or pools against
periodically compiles and distributes
or pools against service
compiles and distributes the
pools against service providers
and distributes the history
against service providers that
solution alleviates this problem
service providers that accept
distributes the history of
to handle the suspicions
the history of packets
providers that accept bitcoin
alleviates this problem by
history of packets exchanged
this problem by making
of packets exchanged by
problem by making sure
packets exchanged by n
by making sure that
and it not directly
making sure that the
or they can make
sure that the live
it not directly related
they can make use
that the live subset
not directly related to
can make use of
the live subset of
directly related to this
make use of two
live subset of disks
use of two standardized
subset of disks is
of two standardized schemes
of disks is not
related to this work
it queries the local
two standardized schemes implemented
disks is not constant
standardized schemes implemented by
queries the local streaming
schemes implemented by the
implemented by the failure
the local streaming application
by the failure manager
the rest of this
block withholding defense most
rest of this paper
withholding defense most crypto
of this paper is
local streaming application running
the failure manager library
this paper is organized
streaming application running on
currencies use a proof
paper is organized as
application running on n
is organized as follows
the first scheme uses
running on n for
first scheme uses a
on n for the
scheme uses a heartbeat
n for the set
uses a heartbeat mechanism
work architecture similar to
for the set of
architecture similar to bitcoin
describes some of the
the set of packets
some of the solutions
which sends out i
of the solutions explored
set of packets it
the solutions explored in
where finding proof of
solutions explored in the
of packets it sent
explored in the first
finding proof of work
in the first three
packets it sent and
the first three quadrants
proof of work is
first three quadrants mentioned
alive messages to a
three quadrants mentioned above
of work is the
it sent and received
messages to a group
sent and received using
to a group of
work is the result
a group of processes
is the result of
group of processes using
the result of solution
of processes using multiple
result of solution guessing
processes using multiple point
of solution guessing and
and received using the
solution guessing and checking
presents and analyzes our
received using the streaming
and analyzes our solution
using the streaming protocol
the streaming protocol in
streaming protocol in the
all of the algorithms
protocol in the most
of the algorithms we
in the most recent
point messages or a
the most recent time
messages or a single
most recent time interval
or a single ip
the algorithms we are
discusses our evaluation methodology
algorithms we are aware
our evaluation methodology and
we are aware of
evaluation methodology and results
are aware of are
aware of are susceptible
of are susceptible to
are susceptible to the
each process keeps track
we conclude in section
process keeps track of
susceptible to the block
keeps track of the
to the block withholding
track of the reception
the block withholding attack
of the reception times
the local auditor signs
the reception times of
local auditor signs and
reception times of messages
auditor signs and publishes
as in all of
signs and publishes the
times of messages and
and publishes the collected
in all of them
publishes the collected history
of messages and if
the collected history to
all of them the
collected history to an
messages and if a
history to an assigned
of them the miner
to an assigned subset
and if a number
an assigned subset of
them the miner can
assigned subset of its
if a number of
based solutions the concept
a number of consecutive
subset of its neighboring
number of consecutive heartbeats
of its neighboring nodes
of consecutive heartbeats from
solutions the concept of
consecutive heartbeats from a
the miner can check
heartbeats from a destination
the concept of a
from a destination is
from whom other auditors
a destination is missed
whom other auditors may
destination is missed a
other auditors may obtain
miner can check whether
concept of a memory
can check whether she
auditors may obtain it
check whether she found
of a memory hierarchy
whether she found a
is missed a suspicion
she found a full
missed a suspicion is
found a full or
a suspicion is raised
a full or a
this level of indirection
a memory hierarchy arose
full or a partial
level of indirection is
memory hierarchy arose as
or a partial proof
hierarchy arose as a
a partial proof of
of indirection is used
arose as a result
partial proof of work
as a result of
indirection is used to
a result of the
is used to prevent
result of the natural
fixed period or an
of the natural tradeoff
period or an exponential
used to prevent nodes
or an exponential back
the natural tradeoff between
to prevent nodes from
prominent examples are litecoin
natural tradeoff between memory
prevent nodes from masking
tradeoff between memory speed
nodes from masking their
between memory speed and
from masking their real
memory speed and memory
masking their real upload
speed and memory cost
their real upload and
real upload and download
upload and download factors
and download factors by
download factors by presenting
factors by presenting different
fixed or estimated by
by presenting different information
or estimated by the
presenting different information to
estimated by the system
different information to different
information to different auditors
audit n s neighbors
n s neighbors histories
and multiple suspicion levels
multiple suspicion levels are
suspicion levels are configurable
levels are configurable by
that there exists a
n s local auditor
are configurable by the
s local auditor periodically
configurable by the application
there exists a similar
local auditor periodically audits
exists a similar tradeoff
auditor periodically audits the
a similar tradeoff between
periodically audits the published
the application can provide
similar tradeoff between performance
application can provide application
tradeoff between performance and
can provide application specific
between performance and power
audits the published histories
it is possible to
the published histories of
provide application specific data
published histories of the
is possible to use
histories of the nodes
application specific data to
possible to use an
specific data to be
of the nodes with
data to be piggybacked
performance disks and low
to be piggybacked on
the nodes with whom
be piggybacked on the
nodes with whom n
piggybacked on the heartbeats
with whom n exchanges
to use an alternative
whom n exchanges packets
performance disks such as
use an alternative proof
disks such as laptop
an alternative proof of
the second scheme uses
such as laptop disks
second scheme uses a
alternative proof of work
scheme uses a polling
proof of work mechanism
uses a polling method
if node n exchanges
a polling method to
node n exchanges packets
polling method to collect
n exchanges packets with
method to collect acknowledgments
exchanges packets with nodes
of work mechanism in
they explore the possibility
to collect acknowledgments from
explore the possibility of
collect acknowledgments from the
the possibility of setting
acknowledgments from the peer
possibility of setting up
from the peer processes
packets with nodes p
work mechanism in which
of setting up a
mechanism in which miners
setting up a disk
in which miners would
if no acknowledgments are
q and r in
which miners would not
no acknowledgments are received
and r in the
acknowledgments are received after
r in the livestreaming
up a disk hierarchy
in the livestreaming protocol
a disk hierarchy by
miners would not be
are received after a
would not be able
received after a number
not be able to
after a number of
be able to distinguish
a number of retries
able to distinguish partial
number of retries a
n s local auditor
of retries a suspicion
to distinguish partial from
disk hierarchy by using
s local auditor compares
retries a suspicion is
distinguish partial from full
hierarchy by using high
local auditor compares these
a suspicion is raised
auditor compares these three
partial from full proofs
compares these three nodes
from full proofs of
these three nodes histories
full proofs of work
three nodes histories with
nodes histories with n
histories with n s
performance disks in conjunction
with n s own
disks in conjunction with
n s own history
in conjunction with each
conjunction with each other
this involves ensuring that
and retransmission limits are
in a related vein
retransmission limits are configurable
limits are configurable by
are configurable by the
configurable by the application
by the application or
the application or can
application or can be
or can be adapted
can be adapted by
be adapted by the
adapted by the failure
by the failure manager
the failure manager to
the amount of data
failure manager to the
amount of data sent
manager to the network
of data sent by
data sent by these
sent by these nodes
by these nodes satisfies
instrumenting the operating system
these nodes satisfies the
propose dynamic rotations per
nodes satisfies the defined
dynamic rotations per minute
satisfies the defined minimum
the defined minimum threshold
to achieve greater failure
defined minimum threshold for
achieve greater failure detection
minimum threshold for the
greater failure detection accuracy
threshold for the system
it is necessary to
whereby disks can be
is necessary to instrument
disks can be run
necessary to instrument the
can be run at
to instrument the operating
be run at multiple
instrument the operating environment
such a solution could
the operating environment with
run at multiple speeds
operating environment with support
a solution could reduce
environment with support for
at multiple speeds depending
solution could reduce or
multiple speeds depending on
the set of packets
speeds depending on whether
with support for process
depending on whether power
support for process investigation
on whether power or
set of packets they
whether power or performance
could reduce or remove
of packets they claim
power or performance takes
reduce or remove the
or performance takes precedence
it has always been
packets they claim to
or remove the danger
has always been argued
remove the danger of
they claim to have
the danger of block
always been argued that
claim to have sent
danger of block withholding
been argued that in
to have sent to
argued that in a
have sent to and
poses a significant engineering
sent to and received
a significant engineering challenge
that in a distributed
significant engineering challenge whose
making such a change
engineering challenge whose feasibility
such a change may
to and received from
a change may not
challenge whose feasibility is
change may not be
whose feasibility is far
may not be in
feasibility is far from
not be in the
is far from obvious
be in the interest
and received from node
in a distributed system
received from node n
in the interest of
another approach is proposed
the interest of the
approach is proposed by
a distributed system it
is proposed by colarelli
interest of the community
from node n corresponds
distributed system it is
proposed by colarelli et
system it is impossible
node n corresponds to
it is impossible to
n corresponds to the
is impossible to distinguish
corresponds to the set
impossible to distinguish a
to the set of
to distinguish a crashed
or even its potential
the set of packets
distinguish a crashed process
set of packets n
a crashed process from
of packets n claims
crashed process from one
packets n claims to
process from one that
could lead to a
n claims to have
lead to a reduction
from one that is
to a reduction of
one that is slow
a reduction of pool
claims to have respectively
reduction of pool sizes
to have respectively received
using massive arrays of
have respectively received from
massive arrays of inexpensive
respectively received from and
as explained in section
received from and sent
explained in section ix
from and sent to
arrays of inexpensive disks
and sent to them
but with the proper
if the first check
with the proper system
the first check comparison
the proper system support
first check comparison fails
proper system support this
system support this is
decentralized pools although most
support this is no
pools although most pools
this is no longer
although most pools use
is no longer true
most pools use a
the local auditor issues
they propose the use
local auditor issues an
pools use a centralized
auditor issues an accusation
use a centralized manager
issues an accusation against
propose the use of
an accusation against the
if the node is
accusation against the node
the node is reachable
against the node to
node is reachable and
the node to a
is reachable and operating
the use of a
a prominent exception is
node to a global
reachable and operating correctly
use of a small
prominent exception is p
of a small number
to a global auditor
a small number of
small number of cache
the operating system can
number of cache disks
operating system can determine
of cache disks in
pool a distributed pool
cache disks in addition
system can determine whether
in the second case
can determine whether or
disks in addition to
a distributed pool architecture
determine whether or not
distributed pool architecture with
whether or not the
pool architecture with no
or not the process
architecture with no central
not the process has
in addition to the
the local auditor is
with no central manager
local auditor is not
addition to the maid
auditor is not able
to the maid disks
the process has crashed
is not able to
not able to prove
able to prove the
to prove the neighbor
prove the neighbor s
the neighbor s misbehavior
the data in these
the failure management integrated
data in these cache
failure management integrated into
in these cache disks
management integrated into the
these cache disks is
integrated into the os
cache disks is updated
into the os offers
it instructs its local
the os offers processes
instructs its local streaming
os offers processes a
its local streaming application
offers processes a mechanism
disks is updated to
processes a mechanism to
local streaming application to
a mechanism to register
is updated to reflect
mechanism to register and
streaming application to not
to register and request
updated to reflect the
register and request a
application to not further
and request a certain
to reflect the workload
but the question of
reflect the workload that
request a certain level
the question of whether
the workload that is
to not further exchange
workload that is currently
question of whether a
that is currently being
not further exchange packets
is currently being accessed
of whether a pool
a certain level of
further exchange packets with
whether a pool is
exchange packets with the
certain level of service
packets with the misbehaving
the maid disks can
a pool is run
maid disks can then
with the misbehaving neighbor
disks can then be
pool is run by
can then be powered
is run by a
then be powered down
run by a centralized
more complex types of
by a centralized manager
complex types of checks
a centralized manager or
types of checks may
and need only be
of checks may also
need only be spun
checks may also be
only be spun up
is a simple binary
centralized manager or with
may also be performed
manager or with a
also be performed to
or with a decentralized
be performed to address
with a decentralized architecture
performed to address other
be spun up when
to address other types
spun up when a
address other types of
up when a cache
other types of byzantine
a decentralized architecture is
a simple binary test
decentralized architecture is almost
types of byzantine behavior
architecture is almost immaterial
simple binary test performed
is almost immaterial for
when a cache miss
almost immaterial for the
a cache miss occurs
immaterial for the attack
binary test performed by
for the attack we
test performed by the
the attack we describe
performed by the os
upon which their contents
by the os upon
which their contents are
the os upon receipt
their contents are copied
os upon receipt of
contents are copied onto
upon receipt of an
are copied onto the
receipt of an inquiry
copied onto the cache
onto the cache disks
pool group can be
group can be infiltrated
can be infiltrated and
indicating whether the process
be infiltrated and attacked
whether the process is
this approach has several
the process is still
approach has several of
process is still present
has several of the
is still present in
several of the weaknesses
still present in the
of the weaknesses that
present in the process
pool code can be
in the process table
code can be changed
the weaknesses that memory
can be changed to
weaknesses that memory caches
be changed to support
that memory caches suffer
changed to support attacks
the process table and
to support attacks against
process table and thus
support attacks against other
table and thus not
attacks against other pools
only on a larger
and thus not has
on a larger scale
thus not has crashed
not has crashed or
on the other hand
has crashed or voluntary
crashed or voluntary exited
if the cache disks
the cache disks are
cache disks are insufficient
disks are insufficient to
the two other levels
are insufficient to store
pool can be used
insufficient to store the
can be used by
to store the entire
two other levels that
store the entire working
other levels that are
the entire working set
levels that are currently
entire working set of
be used by groups
that are currently implemented
used by groups of
working set of the
by groups of miners
set of the current
groups of miners to
of the current workload
of miners to easily
miners to easily form
provide a remote process
to easily form closed
a remote process with
easily form closed pools
remote process with information
process with information about
with considerable latency penalties
with information about the
these do not accept
information about the progress
do not accept untrusted
about the progress the
not accept untrusted miners
the progress the local
progress the local process
the local process is
local process is making
and are therefore protected
the cache disks represent
are therefore protected against
process is making which
therefore protected against block
cache disks represent a
protected against block withholding
disks represent a significant
is making which is
represent a significant added
making which is useful
a significant added cost
which is useful in
significant added cost in
is useful in the
added cost in themselves
useful in the investigation
in the investigation of
c onclusion we explored
the investigation of processes
onclusion we explored a
investigation of processes that
disk management solutions pinheiro
of processes that are
we explored a block
processes that are alive
management solutions pinheiro and
explored a block withholding
solutions pinheiro and bianchini
a block withholding attack
block withholding attack among
but that appear slow
withholding attack among bitcoin
that appear slow or
appear slow or unresponsive
attack among bitcoin mining
among bitcoin mining pools
bitcoin mining pools an
mining pools an attack
pools an attack that
an attack that is
attack that is possible
at certain intervals the
suggest that if data
certain intervals the process
that if data is
intervals the process logs
if data is laid
the process logs checkpoint
data is laid out
process logs checkpoint timestamps
is laid out on
that is possible in
laid out on disks
is possible in any
out on disks according
possible in any similar
on disks according to
in any similar system
disks according to frequency
any similar system that
according to frequency of
logs checkpoint timestamps with
similar system that rewards
checkpoint timestamps with the
system that rewards for
timestamps with the failure
that rewards for proof
with the failure service
rewards for proof of
to frequency of access
for proof of work
which simultaneously logs the
simultaneously logs the process
with the most popular
the most popular files
such systems are gaining
most popular files being
systems are gaining popularity
popular files being located
files being located in
being located in one
located in one set
running most digital currencies
the response to an
most digital currencies and
in one set of
digital currencies and related
response to an inquiry
one set of disks
to an inquiry request
currencies and related services
an inquiry request holds
inquiry request holds the
request holds the last
and the least popular
holds the last checkpoint
the least popular ones
the last checkpoint timestamp
we observe that no
least popular ones in
popular ones in another
the current local time
then the latter set
the latter set of
attacks is not a
latter set of disks
is not a nash
set of disks could
not a nash equilibrium
of disks could be
whether the process has
disks could be powered
the process has been
could be powered down
process has been allocated
be powered down to
has been allocated cpu
powered down to conserve
been allocated cpu time
down to conserve energy
if none of the
allocated cpu time since
none of the other
cpu time since the
of the other pools
time since the last
the other pools attack
since the last checkpoint
their scheme is called
scheme is called popular
is called popular data
called popular data concentration
a pool can increase
and whether the process
pool can increase its
whether the process has
can increase its revenue
the process has consumed
increase its revenue by
process has consumed any
its revenue by attacking
has consumed any messages
and they implement and
consumed any messages since
revenue by attacking the
any messages since the
by attacking the others
they implement and evaluate
messages since the last
implement and evaluate a
since the last checkpoint
and evaluate a prototype
evaluate a prototype file
a prototype file server
prototype file server called
file server called nomad
server called nomad fs
when two pools can
two pools can attack
pools can attack each
upon receipt of an
can attack each other
receipt of an inquiry
which runs on top
of an inquiry the
runs on top of
an inquiry the operating
on top of the
they face a version
top of the file
face a version of
of the file system
a version of the
the file system and
version of the prisoner
file system and monitors
of the prisoner s
system and monitors data
the prisoner s dilemma
inquiry the operating system
global auditing there are
the operating system uses
and monitors data layout
auditing there are two
monitors data layout on
if one pool chooses
data layout on disks
one pool chooses to
operating system uses an
there are two ways
system uses an upcall
pool chooses to attack
are two ways in
their findings are that
two ways in which
findings are that if
ways in which a
the victim s revenue
in which a node
victim s revenue is
are that if the
which a node could
to interrupt the process
a node could pretend
interrupt the process and
s revenue is reduced
the process and requests
node could pretend to
process and requests that
that if the low
and requests that the
could pretend to be
requests that the process
and it can retaliate
that the process prepares
it can retaliate by
the process prepares a
access disks are powered
process prepares a special
disks are powered down
prepares a special response
can retaliate by attacking
pretend to be sending
retaliate by attacking and
to be sending more
by attacking and increase
be sending more or
this response is returned
sending more or receiving
response is returned to
attacking and increase its
this results in a
more or receiving less
results in a considerable
and increase its revenue
in a considerable performance
or receiving less data
a considerable performance hit
is returned to the
receiving less data than
returned to the caller
less data than it
data than it actually
than it actually does
they suggest instead that
suggest instead that they
instead that they be
that they be run
they be run at
be run at low
it could send different
the previous sections all
could send different histories
at nash equilibrium both
send different histories to
previous sections all deal
run at low speed
sections all deal with
different histories to each
all deal with provisions
histories to each neighbor
nash equilibrium both earn
deal with provisions targeted
equilibrium both earn less
with provisions targeted towards
both earn less than
provisions targeted towards the
earn less than they
targeted towards the failure
less than they would
towards the failure management
than they would have
the failure management of
they would have if
failure management of processes
would have if neither
always lying about its
while their idea is
lying about its interactions
their idea is sound
about its interactions with
have if neither attacked
exploiting the close coupled
its interactions with other
the close coupled nature
interactions with other neighbors
close coupled nature of
it is not clear
coupled nature of a
with multiple pools of
nature of a process
is not clear whether
of a process and
multiple pools of equal
a process and the
not clear whether this
process and the operating
pools of equal size
n could send a
and the operating system
could send a history
the operating system it
clear whether this scheme
operating system it runs
send a history to
of equal size a
a history to p
system it runs under
history to p pretending
equal size a similar
whether this scheme would
to p pretending to
size a similar situation
this scheme would adapt
a similar situation arises
scheme would adapt to
similar situation arises with
would adapt to different
situation arises with a
to aid accurate detection
p pretending to send
aid accurate detection in
pretending to send more
adapt to different workloads
to send more data
accurate detection in the
send more data to
arises with a symmetric
detection in the case
more data to q
in the case of
data to q than
with a symmetric equilibrium
the case of node
to q than it
case of node failure
q than it actually
of node failure the
than it actually did
node failure the fault
the fact that block
failure the fault management
propose another data layout
the fault management system
fact that block withholding
fault management system implements
while it sends a
that block withholding is
management system implements a
another data layout management
system implements a node
block withholding is not
it sends a different
data layout management scheme
sends a different history
layout management scheme to
implements a node management
withholding is not common
a node management service
management scheme to optimize
a different history to
scheme to optimize disk
is not common may
to optimize disk access
different history to q
not common may be
history to q where
which is based on
to q where it
common may be explained
q where it pretends
is based on the
where it pretends to
may be explained by
it pretends to send
based on the experience
pretends to send more
be explained by modeling
to send more data
on the experience that
send more data to
explained by modeling the
optimize disk access patterns
by modeling the attack
more data to p
modeling the attack decisions
data to p than
the experience that local
the attack decisions as
to p than it
attack decisions as an
p than it actually
decisions as an iterative
than it actually did
as an iterative prisoner
experience that local failure
an iterative prisoner s
that local failure investigation
iterative prisoner s dilemma
local failure investigation on
n s goal would
failure investigation on a
s goal would be
investigation on a subnet
goal would be to
on a subnet is
would be to send
a subnet is more
be to send less
subnet is more accurate
their approach uses finer
is more accurate than
we argue that the
more accurate than investigation
to send less data
accurate than investigation over
argue that the situation
than investigation over the
grained control over data
that the situation is
control over data layout
the situation is unstable
over data layout on
send less data while
investigation over the internet
less data while not
data layout on disk
data while not being
situation is unstable since
while not being caught
is unstable since the
not being caught by
tuning it on a
unstable since the attack
on a participating subnet
since the attack can
it on a per
the attack can be
a participating subnet one
being caught by any
participating subnet one or
attack can be done
subnet one or more
can be done anonymously
one or more node
caught by any of
or more node failure
by any of its
more node failure monitors
any of its neighbors
applications are instrumented and
are instrumented and then
instrumented and then profiled
and then profiled to
one pool may decide
then profiled to obtain
pool may decide to
profiled to obtain array
the process of publishing
may decide to increase
to obtain array access
decide to increase its
obtain array access sequences
process of publishing a
to increase its revenue
these are simple services
increase its revenue and
of publishing a node
its revenue and drag
are simple services capable
revenue and drag the
publishing a node s
and drag the others
simple services capable of
drag the others to
a node s history
which their system then
services capable of performing
their system then uses
capable of performing local
system then uses to
of performing local failure
then uses to determine
node s history to
uses to determine optimal
performing local failure investigations
to determine optimal disk
s history to a
determine optimal disk layouts
local failure investigations upon
optimal disk layouts by
history to a predefined
disk layouts by computing
failure investigations upon requests
layouts by computing optimal
to a predefined set
by computing optimal stripe
investigations upon requests from
the others to attack
upon requests from remote
others to attack as
requests from remote nodes
to attack as well
a predefined set of
computing optimal stripe factor
predefined set of neighbors
set of neighbors ensures
of neighbors ensures that
ending with a reduced
neighbors ensures that the
with a reduced revenue
ensures that the node
a reduced revenue for
that the node cannot
reduced revenue for all
the node cannot send
node cannot send conflicting
multicast to announce their
cannot send conflicting histories
to announce their availability
send conflicting histories to
the inferior revenue would
announce their availability within
inferior revenue would push
conflicting histories to different
revenue would push miners
histories to different neighbors
the wisdom of marrying
to different neighbors undetected
would push miners to
their availability within the
wisdom of marrying the
availability within the organization
of marrying the disk
push miners to join
marrying the disk layout
within the organization where
miners to join private
the disk layout to
to join private pools
the organization where their
therefore avoiding this problem
organization where their presence
disk layout to the
where their presence is
layout to the application
their presence is being
to the application seems
presence is being tracked
the application seems questionable
is being tracked by
a node could also
which can verify that
being tracked by the
can verify that their
tracked by the other
verify that their registered
node could also lie
that their registered miners
by the other nfm
their registered miners do
proposed by zhu et
registered miners do not
could also lie about
miners do not withhold
also lie about the
do not withhold blocks
lie about the set
about the set of
the set of packets
set of packets sent
an nfm accepts queries
of packets sent to
this would lead to
packets sent to or
would lead to smaller
sent to or received
lead to smaller pools
to or received from
nfm accepts queries from
or received from a
accepts queries from remote
received from a particular
queries from remote nodes
and so ultimately to
combines a number of
from a particular neighbor
from remote nodes about
so ultimately to a
remote nodes about the
a particular neighbor p
nodes about the availability
ultimately to a better
about the availability of
a number of ideas
the availability of a
to a better environment
availability of a node
a better environment for
of a node within
better environment for bitcoin
a node within its
environment for bitcoin as
node within its organization
for bitcoin as a
p will be able
it assumes multispeed disks
will be able to
bitcoin as a whole
be able to identify
it will forward this
able to identify that
and computes online the
to identify that the
will forward this request
identify that the node
computes online the optimal
that the node has
online the optimal speed
the node has lied
the optimal speed that
node has lied and
optimal speed that each
has lied and will
speed that each disk
forward this request to
for their valuable advice
lied and will therefore
that each disk should
and will therefore stop
each disk should run
will therefore stop exchanging
disk should run at
therefore stop exchanging packets
this request to an
stop exchanging packets with
the author is grateful
request to an nfm
exchanging packets with n
author is grateful to
to an nfm on
is grateful to ken
to minimize speed transition
grateful to ken birman
minimize speed transition overheads
an nfm on the
given that an opportunistic
nfm on the particular
that an opportunistic node
on the particular subnet
an opportunistic node s
the particular subnet which
opportunistic node s goal
particular subnet which will
disks maintain their speeds
subnet which will investigate
maintain their speeds for
emin gu n sirer
their speeds for a
node s goal is
which will investigate the
speeds for a fixed
will investigate the availability
s goal is to
investigate the availability of
goal is to maximize
the availability of the
is to maximize its
availability of the node
to maximize its utility
of the node by
and the paper shepherd
the node by launching
the paper shepherd joseph
node by launching a
paper shepherd joseph bonneau
by launching a number
it should have no
launching a number of
should have no interest
a number of fault
have no interest in
they call this the
number of fault test
no interest in losing
of fault test requests
interest in losing data
call this the coarse
in losing data exchange
losing data exchange partners
if this is support
this is support by
is support by the
support by the host
by the host under
opportunistic nodes have no
the host under investigation
nodes have no incentive
host under investigation or
hibernator includes a file
under investigation or by
have no incentive to
investigation or by icmp
includes a file server
no incentive to publish
or by icmp echo
incentive to publish incorrect
a file server that
to publish incorrect histories
by icmp echo requests
file server that sits
icmp echo requests if
server that sits on
echo requests if not
peer electronic cash system
that sits on top
sits on top of
on top of the
top of the file
the result of the
of the file system
result of the query
the file system and
local auditing ensures that
file system and manipulates
of the query is
system and manipulates data
auditing ensures that correct
and manipulates data layout
the query is then
manipulates data layout to
ensures that correct information
data layout to put
query is then returned
layout to put the
that correct information is
is then returned to
to put the most
correct information is available
then returned to the
information is available regarding
returned to the requesting
is available regarding the
to the requesting node
available regarding the set
accessed data on the
regarding the set of
data on the highest
the set of data
on the highest speed
set of data sent
the nfm also functions
of data sent and
the highest speed disks
nfm also functions as
data sent and received
also functions as proxy
sent and received by
functions as proxy for
and received by any
the authors address the
as proxy for process
received by any node
authors address the issue
proxy for process availability
address the issue of
for process availability queries
the issue of performance
ebay s paypal unit
and allows nodes to
issue of performance guarantees
allows nodes to monitor
s paypal unit to
nodes to monitor each
paypal unit to start
to monitor each other
of performance guarantees by
process availability queries in
performance guarantees by stipulating
monitor each other s
guarantees by stipulating that
availability queries in the
by stipulating that if
unit to start accepting
stipulating that if performance
to start accepting bitcoin
that if performance drops
start accepting bitcoin payments
if performance drops below
each other s contribution
queries in the case
performance drops below some
in the case where
drops below some threshold
other s contribution rates
the case where a
case where a firewall
where a firewall obstructs
then all disks are
a firewall obstructs the
all disks are spun
firewall obstructs the free
disks are spun up
obstructs the free querying
are spun up to
the free querying of
spun up to their
free querying of the
up to their highest
querying of the nodes
to their highest speed
of the nodes by
the nodes by their
nodes by their peers
caching solutions zhu et
global auditors global auditors
auditors global auditors are
global auditors are trusted
s are configured with
auditors are trusted components
are configured with domain
are trusted components with
configured with domain and
trusted components with global
with domain and acl
components with global membership
domain and acl mechanisms
with global membership knowledge
and acl mechanisms to
observe that the storage
acl mechanisms to control
that the storage cache
mechanisms to control access
the storage cache management
to control access to
storage cache management policy
control access to the
google adds bitcoin currency
who interact with one
adds bitcoin currency conversion
access to the information
bitcoin currency conversion to
interact with one another
currency conversion to search
cache management policy is
with one another and
management policy is pivotal
one another and with
policy is pivotal in
an extension which is
is pivotal in determining
another and with the
pivotal in determining the
and with the local
in determining the sequence
with the local auditors
extension which is under
determining the sequence of
which is under investigation
the sequence of requests
is under investigation is
sequence of requests that
under investigation is to
as shown in figure
of requests that access
investigation is to have
requests that access disks
is to have nodes
to have nodes multicast
have nodes multicast heartbeats
nodes multicast heartbeats with
multicast heartbeats with local
global auditors execute on
heartbeats with local node
auditors execute on nodes
with local node information
execute on nodes external
local node information periodically
on nodes external to
cache management policies could
nodes external to the
management policies could be
external to the system
policies could be tailored
this information can be
could be tailored to
information can be collected
be tailored to change
can be collected by
their main roles are
be collected by the
tailored to change the
collected by the local
to change the average
by the local nfm
change the average idle
define the minimum upload
the average idle time
the minimum upload threshold
average idle time between
idle time between disk
s and shared in
time between disk requests
and shared in compressed
shared in compressed form
global auditors periodically sample
in compressed form among
auditors periodically sample the
compressed form among the
thus providing more opportunities
form among the other
periodically sample the state
providing more opportunities for
sample the state of
more opportunities for reducing
the state of the
opportunities for reducing disk
state of the system
for reducing disk energy
of the system by
reducing disk energy consumption
the system by querying
among the other nfm
system by querying local
by querying local auditors
s in the organization
they then cooperate to
cache policies that are
then cooperate to analyze
policies that are aware
cooperate to analyze the
local system management tools
to analyze the collected
that are aware of
analyze the collected samples
system management tools can
are aware of the
management tools can connect
aware of the underlying
tools can connect to
of the underlying disk
can connect to an
the underlying disk management
and on this basis
underlying disk management schemes
connect to an nfm
on this basis compute
to an nfm to
this basis compute the
an nfm to retrieve
basis compute the minimum
nfm to retrieve the
compute the minimum upload
to retrieve the information
the minimum upload contribution
retrieve the information and
minimum upload contribution threshold
the information and set
which disks are running
information and set trap
disks are running at
and set trap conditions
are running at which
different strategies may be
running at which speeds
strategies may be employed
may be employed for
be employed for choosing
employed for choosing the
for choosing the best
choosing the best possible
in distributed systems build
the best possible threshold
distributed systems build on
can make more intelligent
systems build on top
make more intelligent replacement
build on top of
more intelligent replacement decisions
on top of a
top of a web
of a web of
a web of interconnected
web of interconnected networks
the authors present both
once thresholds are varied
authors present both offline
present both offline and
both offline and online
offline and online power
they are gossiped to
are gossiped to all
gossiped to all local
we have to take
to all local auditors
have to take network
aware cache replacement algorithms
to take network failure
cache replacement algorithms to
take network failure into
replacement algorithms to optimize
network failure into account
algorithms to optimize read
who then enforce the
to optimize read accesses
then enforce the determined
enforce the determined threshold
failures at network level
at network level are
they also show through
network level are in
also show through experiments
expurge nodes from the
show through experiments the
nodes from the system
level are in general
through experiments the somewhat
are in general related
experiments the somewhat obvious
in general related to
the somewhat obvious fact
general related to crash
somewhat obvious fact that
related to crash failures
obvious fact that for
to crash failures of
fact that for write
global auditors are also
crash failures of routers
that for write accesses
auditors are also responsible
failures of routers and
are also responsible for
of routers and gateways
also responsible for verifying
responsible for verifying accusations
for verifying accusations issued
verifying accusations issued by
or to severe degradation
accusations issued by local
back policies offer more
issued by local auditors
policies offer more opportunities
by local auditors against
to severe degradation of
offer more opportunities to
severe degradation of the
more opportunities to save
degradation of the service
opportunities to save power
local auditors against particular
of the service level
auditors against particular nodes
to save power than
the service level due
save power than write
service level due to
level due to network
due to network congestion
and after validating the
after validating the accusation
causing minimum performance requirements
expurging misbehaving nodes from
minimum performance requirements to
misbehaving nodes from the
performance requirements to be
nodes from the system
requirements to be violated
in the context of
the context of write
the failure investigator will
validation involves verifying that
involves verifying that the
verifying that the accused
a very natural candidate
when not able to
that the accused node
not able to reach
very natural candidate is
able to reach the
natural candidate is the
to reach the node
candidate is the log
the accused node s
reach the node under
accused node s history
the node under investigation
node s history indeed
node under investigation or
s history indeed indicates
under investigation or a
history indeed indicates that
investigation or a relevant
indeed indicates that the
or a relevant nfm
indicates that the node
that the node is
the node is sending
node is sending less
is sending less data
perform a path search
sending less data than
a path search to
less data than the
path search to find
data than the current
search to find the
than the current threshold
to find the trouble
find the trouble spot
we now give a
the trouble spot in
now give a brief
trouble spot in the
give a brief overview
expurging a node involves
a brief overview of
spot in the network
brief overview of the
a node involves informing
overview of the log
node involves informing the
involves informing the nodes
it uses the traceroute
informing the nodes immediate
uses the traceroute technique
structured file system before
the traceroute technique of
file system before describing
the nodes immediate neighbors
system before describing the
traceroute technique of emitting
before describing the power
nodes immediate neighbors of
technique of emitting small
immediate neighbors of its
of emitting small messages
neighbors of its status
emitting small messages with
saving opportunity it represents
of its status and
small messages with limited
its status and forcing
messages with limited ttl
status and forcing the
and forcing the removal
forcing the removal of
the removal of the
removal of the node
of the node from
the node from the
node from the overlay
triggering icmp responses from
from the overlay mesh
icmp responses from routers
responses from routers among
from routers among the
routers among the path
repurposing bitcoin work for
the number of global
bitcoin work for data
structured file system the
work for data preservation
if an obstruction is
number of global auditors
an obstruction is found
file system the log
of global auditors may
obstruction is found it
in proceedings of the
global auditors may vary
is found it is
proceedings of the ieee
auditors may vary according
of the ieee symposium
may vary according to
the ieee symposium on
vary according to different
ieee symposium on security
according to different parameters
symposium on security and
was motivated by a
on security and privacy
found it is reported
motivated by a need
it is reported to
by a need to
is reported to the
a need to optimize
reported to the caller
such as the size
need to optimize the
as the size of
to optimize the latency
the size of the
optimize the latency of
size of the system
the failure management library
the latency of write
failure management library offers
management library offers functionality
library offers functionality to
the use of more
offers functionality to keep
use of more global
functionality to keep the
of more global auditors
to keep the obstruction
more global auditors distributes
keep the obstruction under
global auditors distributes the
writing a block of
the obstruction under investigation
a block of data
auditors distributes the load
block of data to
obstruction under investigation and
of data to a
distributes the load of
data to a seagate
under investigation and to
to a seagate barracuda
the load of sampling
a seagate barracuda disk
investigation and to notify
seagate barracuda disk costs
load of sampling and
barracuda disk costs about
and to notify the
of sampling and improves
to notify the application
sampling and improves efficiency
notify the application once
and improves efficiency in
namecoin dns dotbit project
the application once the
improves efficiency in reacting
application once the obstruction
efficiency in reacting to
once the obstruction seems
in reacting to accusations
the obstruction seems to
reacting to accusations against
obstruction seems to be
to accusations against nodes
seems to be removed
ms in seek time
in seek time and
global auditors are also
this way the process
auditors are also perfect
way the process does
are also perfect candidates
the process does not
also perfect candidates to
process does not need
perfect candidates to perform
does not need to
candidates to perform membership
not need to keep
to perform membership tasks
need to keep the
perform membership tasks such
to keep the partitioned
membership tasks such as
keep the partitioned processes
tasks such as acting
the partitioned processes under
such as acting as
kb in transmission time
partitioned processes under investigation
as acting as entry
processes under investigation but
acting as entry points
under investigation but can
as entry points to
investigation but can wait
entry points to the
the key observation here
but can wait until
key observation here is
can wait until the
observation here is that
wait until the connectivity
here is that seek
until the connectivity is
is that seek time
the connectivity is restored
that seek time is
points to the p
seek time is a
connectivity is restored by
time is a large
is restored by simply
is a large and
restored by simply monitoring
a large and constant
by simply monitoring the
large and constant term
simply monitoring the trouble
and constant term in
monitoring the trouble spot
constant term in latency
term in latency computation
since they are required
they are required to
in case the network
a next generation smart
case the network topology
next generation smart contract
the network topology permits
to eliminate this term
network topology permits it
the lfs replaces write
the investigator can be
lfs replaces write operations
investigator can be configured
replaces write operations by
can be configured to
write operations by append
be configured to use
operations by append operations
configured to use alternate
to use alternate paths
secondary storage is treated
storage is treated as
is treated as a
treated as a large
as a large append
are required to have
required to have full
to have full membership
have full membership knowledge
to reach one of
full membership knowledge of
reach one of the
only log and writes
one of the destination
membership knowledge of the
log and writes always
knowledge of the system
of the destination nfm
of the system for
and writes always go
the system for performing
writes always go to
system for performing their
always go to the
for performing their auditing
go to the log
performing their auditing roles
to the log head
from cornell for example
cornell for example it
for example it is
seek time is thus
example it is possible
time is thus eliminated
it is possible to
is possible to construct
global auditing monitors the
auditing monitors the global
and write latency becomes
monitors the global health
write latency becomes purely
the global health of
alternative routes to anywhere
latency becomes purely a
global health of the
routes to anywhere in
becomes purely a function
to anywhere in california
purely a function of
health of the system
a function of the
of the system to
function of the disk
the system to identify
of the disk bandwidth
system to identify the
to identify the best
the request contains sufficient
identify the best value
request contains sufficient information
the best value for
how do reads in
best value for the
contains sufficient information for
value for the minimum
do reads in the
for the minimum upload
reads in the lfs
sufficient information for the
the minimum upload threshold
information for the nfm
in the lfs work
for the nfm to
minimum upload threshold at
the nfm to construct
upload threshold at any
nfm to construct a
threshold at any time
to construct a symmetric
in the same way
at any time during
construct a symmetric return
the same way as
a symmetric return path
same way as in
any time during a
way as in conventional
time during a streaming
as in conventional file
during a streaming session
in conventional file systems
protocols that can exploit
that can exploit this
can exploit this type
exploit this type of
this type of information
and makes final decisions
type of information are
makes final decisions regarding
of information are under
final decisions regarding punishment
information are under development
decisions regarding punishment of
analysis of bitcoin pooled
regarding punishment of nodes
of bitcoin pooled mining
and hence do not
bitcoin pooled mining reward
hence do not avoid
pooled mining reward systems
do not avoid seek
the assumption is that
adaptive threshold strategies choosing
assumption is that with
threshold strategies choosing an
is that with good
strategies choosing an upload
that with good caching
choosing an upload threshold
with good caching mechanisms
an upload threshold requires
upload threshold requires care
reads will be a
will be a small
a low threshold may
be a small fraction
low threshold may not
failure investigation of a
a small fraction of
threshold may not be
investigation of a process
small fraction of disk
may not be sufficient
of a process at
not be sufficient to
a process at the
be sufficient to identify
process at the same
sufficient to identify opportunistic
at the same sub
to identify opportunistic nodes
fraction of disk accesses
net has always been
while high thresholds may
as can be imagined
has always been viewed
high thresholds may incorrectly
always been viewed as
thresholds may incorrectly punish
been viewed as a
may incorrectly punish correct
viewed as a reasonably
incorrectly punish correct nodes
as a reasonably accurate
space reclamation is a
reclamation is a tricky
is a tricky problem
we considered different strategies
a tricky problem in
reasons for false suspicions
considered different strategies for
for false suspicions were
tricky problem in log
false suspicions were overload
problem in log structured
suspicions were overload in
in log structured file
were overload in the
log structured file systems
overload in the receiver
different strategies for the
in the receiver os
strategies for the choice
for the choice of
the choice of the
choice of the minimum
of the minimum contribution
excellent solutions have been
the minimum contribution t
solutions have been proposed
minimum contribution t hreshold
have been proposed to
contribution t hreshold used
been proposed to solve
t hreshold used for
proposed to solve it
hreshold used for identifying
used for identifying misbehaving
for identifying misbehaving nodes
and one such is
one such is of
which could cause high
such is of interest
could cause high message
is of interest to
cause high message loss
of interest to us
the simplest strategy sets
simplest strategy sets a
strategy sets a fixed
sets a fixed threshold
or unresponsiveness due to
the disk is divided
unresponsiveness due to application
disk is divided into
due to application overload
is divided into large
divided into large log
into large log segments
although that could be
that could be seen
could be seen as
once a log segment
be seen as a
a log segment gets
seen as a design
log segment gets filled
as a design error
a new log segment
new log segment is
log segment is allocated
although confident about the
segment is allocated and
confident about the result
is allocated and the
allocated and the log
and the log head
research perspectives on bitcoin
the log head moves
perspectives on bitcoin and
log head moves to
one was never guaranteed
head moves to the
on bitcoin and secondgeneration
was never guaranteed that
bitcoin and secondgeneration cryptocurrencies
moves to the new
never guaranteed that the
independent of the current
guaranteed that the process
to the new segment
of the current state
in ieee symposium on
the current state of
ieee symposium on security
that the process had
current state of the
when some threshold of
state of the system
some threshold of a
the process had truly
symposium on security and
process had truly crashed
on security and privacy
threshold of a segment
of a segment gets
a segment gets invalidated
using the os failure
any node contributing at
the os failure management
node contributing at a
os failure management extensions
its valid data is
contributing at a rate
valid data is moved
at a rate of
data is moved to
a rate of less
is moved to another
rate of less than
moved to another segment
this assurance is now
assurance is now available
replacing that segment s
that segment s invalid
the time needed by
segment s invalid data
time needed by the
needed by the failure
by the failure detector
of the stream rate
the failure detector to
the stream rate would
failure detector to come
stream rate would be
detector to come to
rate would be removed
and it is then
to come to a
it is then added
come to a result
is then added to
to a result has
then added to the
a result has been
added to the pool
result has been greatly
to the pool of
has been greatly reduced
the pool of free
one downside of using
pool of free log
been greatly reduced in
downside of using a
greatly reduced in the
of free log segments
of using a fixed
reduced in the optimistic
using a fixed threshold
a fixed threshold is
fixed threshold is that
threshold is that opportunistic
common case that the
is that opportunistic nodes
case that the node
this process results in
that the node on
process results in a
the node on which
results in a natural
node on which the
that opportunistic nodes that
in a natural division
on which the process
a natural division of
which the process was
natural division of allocated
opportunistic nodes that learn
the process was running
division of allocated segments
nodes that learn the
of allocated segments into
process was running is
allocated segments into stable
was running is reachable
that learn the threshold
learn the threshold can
the threshold can simply
threshold can simply contribute
regardless if the process
can simply contribute at
if the process has
simply contribute at the
the process has failed
contribute at the lowest
process has failed or
at the lowest possible
has failed or not
the lowest possible upload
consisting almost entirely of
lowest possible upload factor
almost entirely of data
entirely of data that
of data that is
the node is able
data that is rarely
node is able to
that is rarely invalidated
is able to indicate
able to indicate whether
to indicate whether or
indicate whether or not
from the graphs in
whether or not the
the graphs in section
or not the process
not the process has
the process has crashed
in general a single
general a single round
it is clear that
which need to be
is clear that such
need to be constantly
clear that such a
to be constantly cleaned
that such a stretagy
trip time is sufficient
such a stretagy may
time is sufficient at
a stretagy may disrupt
is sufficient at the
stretagy may disrupt the
sufficient at the local
may disrupt the streaming
at the local network
disrupt the streaming session
the local network to
we will see how
local network to get
will see how this
network to get a
see how this feature
to get a result
how this feature can
this feature can be
feature can be used
can be used to
choosing a high threshold
be used to save
a high threshold is
used to save power
high threshold is not
threshold is not a
is not a practical
area case this time
not a practical option
case this time is
this time is a
time is a function
is a function of
since correct nodes would
a function of the
correct nodes would get
function of the level
nodes would get unfairly
of the level of
would get unfairly punished
the level of congestion
level of congestion in
of congestion in the
congestion in the network
in the network path
to avoid this problem
we have explored adaptive
the os extensions also
have explored adaptive strategies
os extensions also improve
extensions also improve the
also improve the confidence
saving opportunity we shall
one simple strategy starts
opportunity we shall now
simple strategy starts with
improve the confidence in
we shall now argue
the confidence in the
strategy starts with a
confidence in the failure
starts with a minimum
in the failure investigation
with a minimum threshold
shall now argue that
the failure investigation process
now argue that there
failure investigation process in
argue that there remains
investigation process in the
that there remains an
process in the wide
there remains an unexplored
remains an unexplored quadrant
an unexplored quadrant in
unexplored quadrant in this
quadrant in this solution
in this solution space
using the old strategy
the old strategy of
caches are used to
old strategy of simply
are used to minimize
strategy of simply polling
used to minimize accesses
of simply polling a
to minimize accesses to
simply polling a process
minimize accesses to disk
polling a process until
a process until a
process until a time
good caching algorithms practically
caching algorithms practically eliminate
algorithms practically eliminate read
out occurs gives much
practically eliminate read accesses
occurs gives much less
eliminate read accesses to
gives much less confidence
read accesses to disk
increasing it only if
much less confidence in
it only if the
less confidence in the
only if the system
confidence in the result
if the system is
in the result of
the system is compromised
the result of the
result of the failure
of the failure investigation
global auditors sample the
whether synchronous or not
auditors sample the system
if no response was
sample the system to
no response was received
the system to identify
response was received after
must still eventually access
was received after the
still eventually access the
received after the maximum
eventually access the disk
system to identify the
after the maximum number
to identify the average
the maximum number of
identify the average download
maximum number of retransmission
the average download factor
number of retransmission is
of retransmission is reached
and if this factor
if this factor is
it was not certain
this factor is lower
was not certain whether
factor is lower than
disk access will be
not certain whether this
access will be write
certain whether this was
whether this was because
this was because of
was because of network
because of network failure
putting a disk management
a disk management layer
host failure or process
disk management layer on
failure or process failure
management layer on top
layer on top of
on top of the
top of the file
with the new scheme
the new scheme it
new scheme it is
system to optimize data
scheme it is possible
once the download factor
it is possible to
to optimize data layout
is possible to distinguish
the download factor reaches
possible to distinguish among
download factor reaches a
to distinguish among these
factor reaches a satisfactory
distinguish among these different
reaches a satisfactory level
among these different failures
a satisfactory level again
optimize data layout for
information propagation in the
data layout for writes
propagation in the bitcoin
layout for writes is
in the bitcoin network
additional information the full
for writes is only
the threshold may be
information the full report
threshold may be reduced
writes is only halfway
may be reduced back
the full report contains
be reduced back to
is only halfway to
reduced back to its
only halfway to the
full report contains the
halfway to the solution
back to its initial
report contains the detailed
th ieee international conference
to its initial value
ieee international conference on
contains the detailed results
international conference on peer
to take this idea
the detailed results of
take this idea to
detailed results of the
this stepwise approach allows
results of the trace
this idea to its
of the trace study
idea to its logical
stepwise approach allows the
the trace study on
to its logical conclusion
trace study on the
approach allows the system
study on the accuracy
allows the system to
on the accuracy and
the system to catch
it is necessary to
the accuracy and performance
is necessary to rethink
system to catch opportunistic
necessary to rethink the
accuracy and performance of
to catch opportunistic nodes
and performance of the
to rethink the file
performance of the failure
rethink the file the
of the failure detector
the file the disk
the failure detector in
catch opportunistic nodes in
failure detector in the
opportunistic nodes in case
detector in the internet
nodes in case their
in case their presence
management policies described in
case their presence starts
policies described in the
their presence starts affecting
the effectiveness of its
presence starts affecting the
effectiveness of its partition
starts affecting the performance
of its partition detection
affecting the performance of
its partition detection mechanism
described in the related
the performance of the
in the related works
performance of the system
the related works section
related works section essentially
works section essentially attack
host failure measurements and
section essentially attack the
failure measurements and measurements
while avoiding incorrect accusations
measurements and measurements of
avoiding incorrect accusations of
essentially attack the problem
incorrect accusations of correct
and measurements of failure
attack the problem by
measurements of failure detection
accusations of correct nodes
of failure detection for
bitcoin and the age
failure detection for server
and the age of
detection for server fail
the age of bespoke
the problem by trying
we also considered a
age of bespoke silicon
also considered a second
problem by trying to
considered a second adaptive
by trying to predict
a second adaptive strategy
trying to predict in
in proceedings of the
to predict in advance
predict in advance which
in advance which disk
advance which disk any
it will be available
which disk any given
will be available later
disk any given access
be available later this
any given access will
available later this year
given access will go
for computing the threshold
later this year through
computing the threshold based
access will go to
the threshold based on
this year through the
threshold based on periodically
international conference on compilers
based on periodically sampled
year through the cornell
on periodically sampled download
through the cornell university
periodically sampled download and
the cornell university technical
sampled download and upload
architectures and synthesis for
they optimize the data
and synthesis for embedded
download and upload factors
cornell university technical report
optimize the data layout
synthesis for embedded systems
the data layout on
university technical report server
data layout on disks
the average download factors
layout on disks to
average download factors once
on disks to ensure
download factors once again
disks to ensure that
factors once again are
to ensure that accesses
once again are used
ensure that accesses are
again are used for
that accesses are localized
are used for detecting
accesses are localized to
used for detecting whether
are localized to some
for detecting whether the
localized to some fraction
detecting whether the threshold
to some fraction of
whether the threshold should
some fraction of the
the threshold should be
fraction of the disks
threshold should be varied
should be varied or
be varied or not
so that only these
that only these need
only these need be
these need be powered
need be powered up
our initial threshold is
initial threshold is set
threshold is set to
is set to null
relevant url s the
url s the horus
s the horus project
these are all probabilistic
and the threshold is
are all probabilistic models
the horus project the
the threshold is chosen
horus project the cornell
threshold is chosen from
project the cornell cluster
is chosen from sampled
a new access has
chosen from sampled upload
the cornell cluster computing
from sampled upload factors
new access has some
into the bitcoin mines
access has some probability
cornell cluster computing project
has some probability of
cluster computing project werner
some probability of not
computing project werner vogels
probability of not fitting
project werner vogels personal
of not fitting this
werner vogels personal home
not fitting this model
if the system seems
fitting this model and
vogels personal home page
this model and needing
the system seems to
model and needing to
personal home page papers
and needing to access
home page papers on
needing to access a
page papers on failure
system seems to be
to access a powered
papers on failure detection
seems to be in
on failure detection http
to be in a
be in a compromised
in a compromised state
the collected upload factors
collected upload factors are
upload factors are ordered
factors are ordered and
are ordered and the
ordered and the value
disk layout becomes tied
and the value dividing
layout becomes tied to
the value dividing the
becomes tied to particular
value dividing the lowest
tied to particular applications
two applications that have
applications that have completely
percent is used as
that have completely different
is used as the
have completely different access
used as the new
completely different access patterns
as the new threshold
different access patterns might
access patterns might require
patterns might require completely
might require completely different
this approach relies on
require completely different data
approach relies on efficiently
completely different data layouts
relies on efficiently sampling
different data layouts on
on efficiently sampling the
data layouts on disk
efficiently sampling the system
layouts on disk leading
on disk leading to
disk leading to conflicts
leading to conflicts that
and on fact that
to conflicts that reduce
on fact that if
conflicts that reduce possible
fact that if the
that reduce possible powersavings
that if the system
if the system s
the system s performance
system s performance is
s performance is not
performance is not satisfactory
since all writes in
all writes in an
writes in an lfs
in an lfs are
an lfs are to
lfs are to the
are to the log
to the log head
we know in advance
percent of the nodes
know in advance which
of the nodes are
in advance which disk
the nodes are opportunistic
advance which disk they
which disk they will
disk they will access
this gives us the
gives us the perfect
us the perfect prediction
the perfect prediction mechanism
evaluation in this section
at least for writeaccesses
we evaluate the performance
evaluate the performance of
the performance of our
performance of our proposed
of our proposed auditing
our proposed auditing strategy
this prediction mechanism is
proposed auditing strategy over
prediction mechanism is also
auditing strategy over the
mechanism is also entirely
strategy over the original
is also entirely application
over the original streaming
the original streaming protocol
we built an event
if most accesses to
driven simulator and used
most accesses to disks
simulator and used it
accesses to disks were
and used it to
to disks were writes
used it to simulate
it to simulate streaming
to simulate streaming sessions
simulate streaming sessions on
streaming sessions on networks
we could power down
sessions on networks with
could power down every
power down every disk
down every disk but
every disk but the
disk but the one
but the one that
the one that the
one that the log
that the log head
the log head resides
log head resides on
nodes and an average
and an average of
is an ideal case
an ideal case scenario
our view is that
the target streaming rate
target streaming rate in
with a good caching
streaming rate in the
a good caching algorithm
rate in the experiments
in the experiments was
the experiments was fixed
experiments was fixed to
aware caching algorithms described
caching algorithms described in
algorithms described in the
described in the related
in the related works
the related works section
related works section are
works section are good
section are good candidates
transis a communication subsystem
a communication subsystem for
communication subsystem for high
subsystem for high availability
and all our experiments
all our experiments were
our experiments were repeated
reads to disk can
idigest of papers of
to disk can be
disk can be minimized
and only a small
only a small fraction
confidence intervals were small
a small fraction of
small fraction of the
fraction of the disks
of the disks need
and for simplicity are
the disks need be
for simplicity are omitted
disks need be powered
simplicity are omitted from
need be powered on
are omitted from the
be powered on in
omitted from the graphs
powered on in order
on in order to
in order to serve
order to serve all
to serve all writes
serve all writes as
all writes as well
writes as well as
as well as reads
the source of the
source of the stream
of the stream has
the stream has an
stream has an upload
has an upload capacity
an upload capacity of
what about the performance
upload capacity of four
about the performance and
capacity of four times
the performance and power
of four times the
performance and power costs
four times the stream
and power costs of
times the stream rate
power costs of log
costs of log cleaning
fast message ordering and
message ordering and membership
ordering and membership using
and membership using a
al present some optimizations
membership using a logical
present some optimizations in
and is connected to
using a logical token
to hide the performance
other nodes have enough
hide the performance penalty
nodes have enough download
the performance penalty of
have enough download capacity
performance penalty of log
enough download capacity to
penalty of log cleaning
download capacity to receive
of log cleaning even
capacity to receive the
log cleaning even when
to receive the stream
cleaning even when the
even when the workload
when the workload allows
the workload allows little
workload allows little idle
and upload factor of
allows little idle time
the power costs of
power costs of log
costs of log cleaning
of log cleaning are
log cleaning are a
cleaning are a little
are a little more
a little more tricky
little more tricky to
more tricky to justify
we defined an availability
defined an availability window
an availability window of
this is where the
is where the natural
seconds and an interest
where the natural division
and an interest window
the natural division of
an interest window of
natural division of segments
division of segments into
of segments into stable
segments into stable and
into stable and volatile
stable and volatile ones
to evaluate the quality
and volatile ones that
evaluate the quality of
volatile ones that the
the quality of each
ones that the log
quality of each auditing
that the log cleaning
reliable communication in the
of each auditing strategy
communication in the presence
the log cleaning process
in the presence of
log cleaning process results
the presence of failure
cleaning process results in
we evaluate the average
evaluate the average download
the average download factors
acm transaction on computer
average download factors of
transaction on computer systems
download factors of correct
factors of correct nodes
of correct nodes during
correct nodes during a
after a significant fraction
a significant fraction of
significant fraction of segments
fraction of segments on
of segments on a
segments on a disk
on a disk have
a disk have been
second time interval after
disk have been classified
time interval after auditing
have been classified as
interval after auditing is
been classified as stable
after auditing is first
auditing is first applied
is first applied to
first applied to the
applied to the system
we power the disk
power the disk on
the disk on and
disk on and copy
we considered that global
on and copy the
considered that global auditors
and copy the stable
that global auditors collected
copy the stable segments
global auditors collected information
the stable segments to
auditors collected information from
stable segments to a
segments to a stable
to a stable disk
volatile segments to a
segments to a volatile
to a volatile disk
nodes between each interval
between each interval of
disk is kept on
group membership and viewsynchronous
membership and viewsynchronous communication
and viewsynchronous communication in
and the entire disk
viewsynchronous communication in partitionable
notice that the sample
the entire disk is
that the sample size
entire disk is freed
communication in partitionable asynchronous
the sample size does
in partitionable asynchronous systems
disk is freed for
sample size does not
is freed for reuse
size does not increase
does not increase with
not increase with the
increase with the size
with the size of
this is similar to
the size of the
is similar to the
size of the system
similar to the log
to the log cleaning
the log cleaning scheme
log cleaning scheme described
cleaning scheme described in
which is a positive
is a positive aspect
a positive aspect of
positive aspect of the
aspect of the auditing
of the auditing approach
which uses a hidden
uses a hidden structure
we discuss the costs
a hidden structure embedded
discuss the costs involved
hidden structure embedded in
the costs involved in
structure embedded in the
costs involved in collecting
embedded in the log
involved in collecting these
in the log to
in collecting these samples
the log to track
log to track segment
to track segment utilization
cleaning an entire disk
an entire disk amortizes
entire disk amortizes the
disk amortizes the cost
amortizes the cost of
the cost of powering
cost of powering the
of powering the disk
powering the disk on
number of accesses number
of accesses number of
accesses number of files
number of files touched
of files touched number
files touched number of
touched number of bytes
number of bytes touched
of bytes touched average
bytes touched average number
how a mining monopoly
touched average number of
a mining monopoly can
average number of bytes
mining monopoly can attack
unreliable failure detectors for
monopoly can attack bitcoin
failure detectors for reliable
detectors for reliable distributed
for reliable distributed systems
to appear in journal
appear in journal of
in journal of the
journal of the acm
number of false positives
of false positives download
false positives download factor
impossibility of distributed consensus
of distributed consensus with
distributed consensus with one
consensus with one faulty
with one faulty process
journal of the acm
based simulator of a
simulator of a log
given a trace of
a trace of read
trace of read and
of read and write
read and write requests
logsim returns the observed
returns the observed access
the observed access latencies
r van and vogels
for the chosen set
the chosen set of
chosen set of configuration
support for highly reliable
set of configuration parameters
majority is not enough
world traces for our
traces for our simulations
for our simulations from
our simulations from a
bitcoin mining is vulnerable
simulations from a web
in financial cryptography and
server that serves images
financial cryptography and data
that serves images from
cryptography and data security
serves images from a
images from a database
acm sigops european workshop
describes the characteristics of
the characteristics of a
characteristics of a sample
of a sample trace
while a true evaluation
a true evaluation of
true evaluation of the
evaluation of the feasibility
of the feasibility and
the feasibility and efficacy
feasibility and efficacy of
and efficacy of our
efficacy of our solution
of our solution can
our solution can only
solution can only be
can only be achieved
only be achieved through
be achieved through an
achieved through an actual
through an actual implementation
simulation provides an elegant
provides an elegant way
an elegant way to
elegant way to identify
way to identify and
to identify and explore
reliable multicast for distributed
identify and explore some
multicast for distributed interactive
and explore some of
for distributed interactive simulation
explore some of the
some of the cost
proceedings of acm sigcomm
benefit tradeoffs in a
tradeoffs in a scaled
down version of our
version of our system
the mechanism we simulate
mechanism we simulate is
we simulate is as
simulate is as follows
disks are assumed to
are assumed to begin
assumed to begin in
to begin in the
begin in the on
in the on state
and an access count
cooperative equilibrium for supergames
is maintained for each
maintained for each disk
the review of economic
review of economic studies
the user specifies the
user specifies the maximum
specifies the maximum percentage
view synchronous communication in
of disks that are
synchronous communication in large
disks that are kept
communication in large scale
that are kept powered
are kept powered on
nd open broadcast workshop
a disk check process
disk check process scans
check process scans the
process scans the access
scans the access count
the access count for
access count for each
count for each disk
for each disk and
each disk and powers
disk and powers down
and powers down all
powers down all but
down all but the
all but the most
increasing reliability of communication
reliability of communication in
of communication in large
communication in large scale
in large scale distributed
quality of streaming when
of streaming when applying
term competition a game
streaming when applying the
as well as any
when applying the fixed
well as any disk
applying the fixed threshold
as any disk which
the fixed threshold strategy
any disk which does
disk which does not
which does not have
does not have at
threshold is varied from
not have at least
have at least t
at least t access
least t access count
miss results in an
results in an access
in an access to
an access to a
access to a powered
and the contribution rate
the contribution rate of
then this disk is
contribution rate of opportunistic
this disk is spun
rate of opportunistic nodes
disk is spun up
of opportunistic nodes is
opportunistic nodes is varied
nodes is varied from
to remain powered on
remain powered on until
powered on until the
on until the next
until the next disk
the next disk check
and there is a
a generic architecture for
there is a corresponding
generic architecture for dependable
is a corresponding latency
architecture for dependable distributed
a corresponding latency penalty
for dependable distributed computing
judicious choice of the
presents the average download
choice of the parameters
the average download factors
of the parameters m
average download factors across
the parameters m and
download factors across all
parameters m and t
factors across all correct
m and t minimizes
across all correct nodes
and t minimizes the
t minimizes the probability
minimizes the probability of
the probability of this
probability of this occurrence
presents the number of
the number of correct
number of correct nodes
of correct nodes incorrectly
correct nodes incorrectly punished
methodology we have proposed
we have proposed the
we consider the use
have proposed the use
consider the use of
proposed the use of
the use of fixed
the use of lfs
use of fixed thresholds
use of lfs in
of lfs in lieu
lfs in lieu of
in lieu of ffs
we studied the effects
studied the effects of
or other conventional file
the effects of using
other conventional file systems
effects of using different
a flexible group communications
of using different values
flexible group communications system
using different values for
different values for t
cornell university technical report
center scenarios to achieve
scenarios to achieve power
to achieve power conservation
for this idea to
this idea to be
idea to be accepted
and increasing it until
two questions need to
questions need to be
need to be answered
to be answered in
be answered in the
answered in the affirmative
does this new scheme
this new scheme result
new scheme result in
of the stream rate
scheme result in significant
result in significant power
in significant power savings
and present a detailed
present a detailed set
a detailed set of
detailed set of results
set of results on
of results on applying
results on applying different
on applying different thresholds
io bitcoin mining pool
applying different thresholds to
different thresholds to different
thresholds to different scenarios
does this new scheme
this new scheme provide
new scheme provide comparable
scheme provide comparable performance
provide comparable performance to
comparable performance to existing
performance to existing schemes
the ratio of opportunistic
ratio of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is fixed
nodes is fixed to
the answers to these
answers to these questions
to these questions must
these questions must be
questions must be largely
must be largely applicationindependent
and must apply to
must apply to a
but their contribution factor
apply to a generic
to a generic data
a generic data center
generic data center model
to address these questions
we present a simulator
logsim consists of less
consists of less than
of less than a
less than a thousand
than a thousand lines
a thousand lines of
thousand lines of java
lines of java code
of java code and
java code and is
code and is a
and is a single
we must turn off
must turn off some
turn off some percentage
off some percentage of
some percentage of disks
percentage of disks in
of disks in the
disks in the storage
in the storage system
there are two opposing
are two opposing forces
two opposing forces at
opposing forces at play
forces at play here
nodes follow the protocol
a large number of
large number of powered
with a maximum contribution
a maximum contribution rate
maximum contribution rate set
contribution rate set to
on disks results in
disks results in good
results in good performance
but also low power
also low power savings
on the other hand
decreasing the number of
the number of powered
on disks incurs two
disks incurs two possible
incurs two possible penalties
we present the average
present the average download
the average download rates
and the number of
the number of correct
number of correct nodes
of correct nodes mistakenly
correct nodes mistakenly removed
transitions consume power and
nodes mistakenly removed from
consume power and thus
mistakenly removed from the
power and thus counter
removed from the system
and thus counter the
thus counter the potential
counter the potential savings
the potential savings achieved
potential savings achieved by
savings achieved by powered
to find the optimal
for each of these
find the optimal percentage
each of these configurations
a private framework for
the optimal percentage of
private framework for distributed
optimal percentage of disks
framework for distributed computation
percentage of disks to
for distributed computation edward
of disks to be
the threshold applied is
distributed computation edward tremel
threshold applied is presented
disks to be powered
applied is presented on
to be powered down
is presented on the
presented on the x
we ran a set
ran a set of
a set of simulations
set of simulations on
in the left graph
of simulations on logsim
and ma rk jelasity
simulations on logsim and
ma rk jelasity there
on logsim and varied
as the threshold increases
logsim and varied the
rk jelasity there is
and varied the number
varied the number of
jelasity there is a
the number of disks
higher download averages are
number of disks that
download averages are observed
there is a growing
of disks that we
is a growing class
disks that we kept
a growing class of
since more opportunistic nodes
that we kept powered
more opportunistic nodes are
growing class of distributed
opportunistic nodes are detected
we kept powered up
nodes are detected and
kept powered up from
are detected and punished
class of distributed systems
powered up from none
of distributed systems applications
distributed systems applications in
systems applications in which
applications in which data
in which data stored
the number of nodes
which data stored on
number of nodes incorrectly
data stored on client
of nodes incorrectly accused
stored on client platforms
nodes incorrectly accused also
on client platforms must
incorrectly accused also increases
client platforms must be
accused also increases with
platforms must be aggregated
also increases with higher
must be aggregated or
increases with higher thresholds
be aggregated or analyzed
aggregated or analyzed without
or analyzed without revealing
analyzed without revealing private
as observed in the
without revealing private information
observed in the right
revealing private information to
in the right graph
private information to the
information to the operator
scenarios where opportunistic nodes
where opportunistic nodes contribute
opportunistic nodes contribute at
systems such as the
out of a total
nodes contribute at higher
such as the smart
contribute at higher rates
of a total of
as the smart power
the smart power grid
kncminer bitcoin mining cloud
bitcoin mining cloud mining
control systems for energy
and traffic analysis in
traffic analysis in large
analysis in large cities
are less disruptive to
in large cities all
less disruptive to the
large cities all depend
disruptive to the system
cities all depend on
all depend on the
depend on the analysis
on the analysis of
but they also require
the analysis of data
they also require higher
analysis of data supplied
also require higher thresholds
of data supplied by
require higher thresholds to
data supplied by measurement
higher thresholds to be
supplied by measurement devices
thresholds to be applied
yet the clients being
different thresholds yield best
the clients being tracked
thresholds yield best results
clients being tracked are
yield best results under
being tracked are unwilling
best results under different
tracked are unwilling to
results under different scenarios
are unwilling to reveal
unwilling to reveal such
to reveal such measurement
reveal such measurement data
such measurement data directly
measurement data directly to
data directly to the
directly to the system
from the results presented
to the system owner
the results presented in
results presented in figure
who might be curious
might be curious about
be curious about private
curious about private client
we concluded that the
about private client information
concluded that the best
that the best fixed
disks were kept powered
the best fixed threshold
were kept powered up
best fixed threshold is
fixed threshold is t
these systems thus may
systems thus may elicit
thus may elicit public
may elicit public opposition
elicit public opposition despite
public opposition despite their
opposition despite their useful
despite their useful features
their useful features because
useful features because of
features because of a
because of a perceived
of a perceived privacy
a perceived privacy risk
providing the best compromise
the best compromise in
there are ways to
best compromise in terms
are ways to upload
compromise in terms of
ways to upload sensitive
in terms of performance
to upload sensitive data
terms of performance and
upload sensitive data to
of performance and false
sensitive data to an
performance and false positives
data to an aggregator
and false positives across
to an aggregator without
false positives across all
an aggregator without compromising
positives across all scenarios
aggregator without compromising privacy
but existing options have
existing options have limitations
one possibility is to
we compare all three
possibility is to keep
compare all three strategies
is to keep the
all three strategies proposed
to keep the data
three strategies proposed in
keep the data encrypted
strategies proposed in subsection
the data encrypted with
data encrypted with keys
encrypted with keys known
with keys known only
keys known only to
known only to the
only to the clients
but this requires expensive
against each other and
this requires expensive homomorphic
each other and against
an authorization architecture for
requires expensive homomorphic encryption
authorization architecture for trustworthy
other and against a
architecture for trustworthy computing
expensive homomorphic encryption if
and against a configuration
homomorphic encryption if the
against a configuration with
encryption if the aggregator
a configuration with no
in proceedings of the
if the aggregator is
configuration with no auditing
the aggregator is to
proceedings of the twenty
aggregator is to compute
is to compute directly
to compute directly on
compute directly on it
third acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
another is to employ
is to employ a
to employ a mechanism
employ a mechanism to
a mechanism to de
correlate client identifiers from
client identifiers from their
identifiers from their data
for the fixed threshold
the fixed threshold strategy
as chen et al
fixed threshold strategy and
threshold strategy and as
strategy and as the
and as the initial
as the initial threshold
the initial threshold in
initial threshold in the
threshold in the stepwise
in the stepwise adaptive
the stepwise adaptive strategy
we summarize the three
summarize the three strategies
the three strategies in
three strategies in table
but this imposes restrictions
this imposes restrictions on
imposes restrictions on the
restrictions on the kind
on the kind of
the kind of aggregation
kind of aggregation that
of aggregation that can
we simulated sessions where
aggregation that can be
that can be done
it would be beneficial
of the nodes were
would be beneficial to
the nodes were opportunistic
be beneficial to execute
nodes were opportunistic and
beneficial to execute needed
were opportunistic and with
to execute needed computation
opportunistic and with varying
execute needed computation directly
and with varying ratios
needed computation directly on
with varying ratios of
computation directly on the
varying ratios of contribution
directly on the client
on the client platforms
so that the system
that the system operator
the system operator or
system operator or analyst
operator or analyst only
the contribution rate of
or analyst only sees
contribution rate of opportunistic
analyst only sees aggregate
rate of opportunistic nodes
only sees aggregate results
of opportunistic nodes is
cdf number of accesses
opportunistic nodes is varied
nodes is varied from
this approach would provide
approach would provide a
would provide a better
provide a better alternative
a better alternative to
better alternative to central
alternative to central aggregation
to central aggregation provided
central aggregation provided it
aggregation provided it is
provided it is privacy
all other nodes are
other nodes are correct
contributing at a maximum
at a maximum rate
a maximum rate of
a data aggregation system
data aggregation system based
aggregation system based on
system based on client
side computation suggests a
computation suggests a purely
suggests a purely peer
we present both the
present both the average
both the average and
the average and the
average and the minimum
and the minimum download
the minimum download factors
minimum download factors across
download factors across all
factors across all correct
across all correct nodes
all correct nodes in
correct nodes in the
nodes in the system
as the contribution rate
which many systems have
the contribution rate of
many systems have used
contribution rate of opportunistic
systems have used to
rate of opportunistic nodes
have used to avoid
of opportunistic nodes increases
used to avoid centralized
to avoid centralized control
the download factors are
download factors are expected
factors are expected to
are expected to increase
which is clear from
is clear from the
clear from the curves
from the curves presented
strategy no auditing fixed
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise adaptive
threshold stepwise adaptive percentile
based adaptive description fixed
adaptive description fixed t
peer systems have problems
systems have problems of
have problems of their
problems of their own
even if we set
if we set privacy
we set privacy concerns
set privacy concerns aside
by eschewing centralization entirely
they can no longer
can no longer take
no longer take advantage
longer take advantage of
take advantage of the
advantage of the powerful
of the powerful management
the powerful management tools
powerful management tools developed
management tools developed for
tools developed for today
developed for today s
if avg sampled download
for today s cloud
avg sampled download factor
today s cloud computing
s cloud computing model
on power splitting games
power splitting games in
splitting games in distributed
games in distributed computation
the case of bitcoin
case of bitcoin pooled
of bitcoin pooled mining
clients are isolated network
are isolated network hosts
isolated network hosts rather
network hosts rather than
hosts rather than devices
rather than devices within
than devices within a
devices within a single
within a single administrative
a single administrative domain
and often have difficulty
often have difficulty maintaining
decrease t back to
have difficulty maintaining connections
difficulty maintaining connections to
maintaining connections to each
connections to each other
to each other through
each other through firewalls
other through firewalls and
through firewalls and address
firewalls and address translation
and address translation barriers
when avg download is
avg download is satisfactory
download is satisfactory again
determining the membership of
the membership of a
membership of a peer
peer network is a
network is a surprisingly
is a surprisingly difficult
a surprisingly difficult problem
since there is no
there is no one
if avg sampled download
is no one entity
avg sampled download factor
no one entity that
one entity that knows
entity that knows the
that knows the identities
knows the identities of
the identities of all
identities of all the
of all the clients
effect of increasing percentage
of increasing percentage of
and changes in membership
increasing percentage of powered
changes in membership may
in membership may not
membership may not be
may not be detected
up disks on performance
not be detected and
be detected and propagated
detected and propagated in
and propagated in a
t is chosen based
propagated in a timely
is chosen based on
in a timely fashion
chosen based on sampled
based on sampled upload
on sampled upload factors
effect of increasing percentage
of increasing percentage of
increasing percentage of powered
up disks on power
disks on power consumption
on power consumption both
power consumption both its
consumption both its performance
without a centralized service
a centralized service to
centralized service to assign
service to assign and
as well as its
to assign and manage
well as its power
assign and manage node
and manage node identities
weekly bitcoin network statistics
the former is measured
former is measured using
is measured using the
measured using the observed
using the observed access
the observed access latencies
strategies used for defining
used for defining the
for defining the minimum
defining the minimum upload
while the latter is
the minimum upload threshold
the latter is measured
minimum upload threshold t
latter is measured by
upload threshold t figure
is measured by comparing
measured by comparing the
by comparing the cumulative
comparing the cumulative percentage
peer system is extremely
shows that all strategies
the cumulative percentage of
system is extremely vulnerable
cumulative percentage of time
that all strategies yield
percentage of time the
is extremely vulnerable to
of time the disks
all strategies yield significantly
time the disks are
extremely vulnerable to a
the disks are kept
strategies yield significantly better
vulnerable to a few
disks are kept powered
to a few malicious
are kept powered on
yield significantly better results
a few malicious peers
significantly better results compared
few malicious peers becoming
better results compared to
malicious peers becoming a
results compared to an
peers becoming a majority
compared to an approach
as well as the
to an approach with
well as the number
an approach with no
as the number of
approach with no auditing
the number of mode
becoming a majority of
a majority of the
majority of the apparent
of the apparent nodes
while both adaptive strategies
the apparent nodes in
both adaptive strategies yield
apparent nodes in the
adaptive strategies yield excellent
nodes in the system
strategies yield excellent download
yield excellent download rates
excellent download rates to
download rates to correct
rates to correct nodes
even choosing peers fairly
choosing peers fairly becomes
peers fairly becomes difficult
the fixed threshold strategy
fixed threshold strategy s
because peers usually do
threshold strategy s performance
peers usually do not
strategy s performance is
usually do not store
show the results of
s performance is not
the results of these
do not store the
results of these simulations
performance is not as
not store the entire
is not as good
store the entire membership
not as good when
the entire membership list
as good when opportunistic
entire membership list locally
good when opportunistic nodes
when opportunistic nodes are
opportunistic nodes are contributing
nodes are contributing with
and it is fairly
it is fairly easy
is fairly easy for
of the disks powered
fairly easy for malicious
the disks powered on
easy for malicious peers
for malicious peers to
malicious peers to poison
peers to poison local
or slightly more kbps
to poison local mem
poison local mem cornell
local mem cornell bership
mem cornell bership views
cornell bership views so
bership views so that
views so that they
so that they will
that they will be
they will be preferred
will be preferred as
of the disks can
be preferred as neighbors
the disks can be
preferred as neighbors by
disks can be spun
as neighbors by honest
can be spun down
neighbors by honest nodes
be spun down while
spun down while still
down while still maintaining
at those rates opportunistic
while still maintaining performance
those rates opportunistic nodes
still maintaining performance comparable
rates opportunistic nodes are
maintaining performance comparable to
opportunistic nodes are harmful
performance comparable to that
nodes are harmful to
comparable to that of
are harmful to the
to that of a
harmful to the system
that of a conventional
of a conventional file
a conventional file system
yet the fixed threshold
the fixed threshold of
the performance of our
performance of our system
of our system depends
our system depends very
system depends very heavily
depends very heavily on
very heavily on its
heavily on its cache
since neither completely centralized
on its cache configuration
is not able to
neither completely centralized aggregation
not able to detect
completely centralized aggregation nor
able to detect them
centralized aggregation nor a
since cache optimization is
aggregation nor a completely
cache optimization is an
nor a completely peer
optimization is an orthogonal
is an orthogonal issue
an orthogonal issue that
orthogonal issue that comprises
theoretic analysis of ddos
issue that comprises an
analysis of ddos attacks
that comprises an entire
of ddos attacks against
peer system is adequate
ddos attacks against bitcoin
system is adequate for
attacks against bitcoin mining
is adequate for our
against bitcoin mining pools
adequate for our purposes
comprises an entire field
we consider a scenario
an entire field of
consider a scenario where
entire field of research
in workshop on bitcoin
field of research in
workshop on bitcoin research
of research in itself
a scenario where opportunistic
we explore a new
scenario where opportunistic nodes
explore a new approach
where opportunistic nodes contribute
a new approach that
opportunistic nodes contribute with
new approach that combines
it is important to
approach that combines the
is important to isolate
that combines the features
important to isolate its
combines the features of
to isolate its effect
the features of these
isolate its effect on
features of these two
its effect on performance
of these two extremes
nodes contribute with different
contribute with different rates
although the idea of
the idea of a
we varied the percentage
idea of a communication
varied the percentage of
we implemented an ideal
the percentage of opportunistic
implemented an ideal cache
percentage of opportunistic nodes
an ideal cache algorithm
of a communication system
of opportunistic nodes in
a communication system that
opportunistic nodes in the
communication system that combines
nodes in the system
system that combines some
which we term the
that combines some centralized
we term the oracle
combines some centralized control
in the system from
some centralized control with
centralized control with a
control with a peer
this data point represents
data point represents the
point represents the best
represents the best performance
the best performance we
peer overlay is not
overlay is not new
best performance we could
performance we could achieve
we could achieve since
could achieve since an
we are the first
achieve since an oracle
are the first to
since an oracle has
and evenly assigned them
an oracle has future
the first to use
oracle has future knowledge
first to use such
evenly assigned them different
to use such a
assigned them different contribution
use such a system
them different contribution rates
such a system to
has future knowledge and
a system to preserve
when bitcoin mining pools
future knowledge and is
system to preserve privacy
knowledge and is able
to preserve privacy while
and is able to
preserve privacy while computing
bitcoin mining pools run
privacy while computing on
mining pools run dry
while computing on sensitive
is able to replace
the graphs present the
able to replace items
computing on sensitive data
to replace items accessed
in workshop on bitcoin
graphs present the average
workshop on bitcoin research
present the average and
replace items accessed furthest
the average and minimum
items accessed furthest in
this combination is a
average and minimum download
combination is a sensible
and minimum download rates
is a sensible tradeoff
minimum download rates for
a sensible tradeoff for
download rates for these
accessed furthest in the
sensible tradeoff for the
rates for these scenarios
tradeoff for the kinds
furthest in the future
for the kinds of
the kinds of systems
kinds of systems we
of systems we target
no auditing performs significantly
in which there is
auditing performs significantly worse
which there is an
performs significantly worse than
there is an owner
significantly worse than any
is an owner or
worse than any of
an owner or operator
than any of the
owner or operator who
any of the proposed
or operator who can
of the proposed strategies
operator who can be
we also wish to
who can be trusted
also wish to provide
can be trusted to
wish to provide a
be trusted to provide
to provide a performance
comparison of mining pools
provide a performance comparison
trusted to provide basic
the stepwise adaptive approach
to provide basic services
stepwise adaptive approach yields
provide basic services such
a performance comparison of
basic services such as
adaptive approach yields the
services such as node
performance comparison of our
such as node identification
comparison of our system
approach yields the best
of our system against
as node identification and
our system against conventional
yields the best results
node identification and membership
the best results when
identification and membership tracking
best results when large
and membership tracking but
results when large percentages
membership tracking but not
when large percentages of
tracking but not to
large percentages of opportunistic
but not to see
percentages of opportunistic nodes
not to see non
of opportunistic nodes are
as an approximation of
opportunistic nodes are present
an approximation of such
nodes are present in
approximation of such a
are present in the
of such a system
aggregated raw client data
present in the system
comparison of mining pools
we implemented a random
implemented a random placement
it is also simpler
a random placement algorithm
is also simpler than
also simpler than the
we treat the system
simpler than the percentile
treat the system operator
which maps each block
the system operator as
maps each block to
system operator as an
each block to a
operator as an honest
block to a random
to a random disk
since it is based
it is based only
is based only on
all disks are kept
based only on samples
disks are kept powered
only on samples of
are kept powered up
on samples of the
samples of the download
of the download rates
who will keep the
the download rates of
will keep the system
download rates of nodes
keep the system running
the system running correctly
system running correctly but
in both sets of
running correctly but cannot
both sets of experiments
correctly but cannot be
but cannot be allowed
cannot be allowed to
having set the context
be allowed to see
the number of false
allowed to see more
number of false positives
to see more information
of false positives was
see more information than
let us examine fig
more information than he
false positives was practically
information than he or
hashcash amortizable publicly auditable
than he or she
positives was practically null
he or she needs
amortizable publicly auditable cost
was practically null under
or she needs to
practically null under all
she needs to know
null under all three
under all three strategies
all three strategies considered
at most one in
most one in some
one in some cases
the additional two data
points described above are
described above are represented
above are represented in
are represented in fig
we introduce a method
introduce a method for
a method for constructing
method for constructing a
for constructing a communication
constructing a communication overlay
a communication overlay among
communication overlay among the
overlay among the client
among the client nodes
auditing costs the overheads
the client nodes that
costs the overheads imposed
client nodes that can
the overheads imposed by
nodes that can safely
overheads imposed by auditing
that can safely be
imposed by auditing are
can safely be used
by auditing are an
safely be used to
auditing are an important
be used to perform
are an important consideration
used to perform aggregation
to perform aggregation and
perform aggregation and computation
aggregation and computation on
and computation on private
which we address in
computation on private data
we address in this
address in this subsection
although this overlay is
most of the work
this overlay is set
of the work of
overlay is set up
the work of auditing
is set up and
work of auditing is
set up and operated
of auditing is performed
up and operated by
auditing is performed by
and operated by the
is performed by local
operated by the system
performed by local auditors
by the system owner
which are executed on
are executed on the
it provides minimal opportunity
executed on the user
on the user nodes
provides minimal opportunity for
minimal opportunity for the
opportunity for the owner
the overhead is constant
for the owner to
the owner to learn
owner to learn any
if we imagine a
independent of the size
to learn any information
we imagine a line
of the size of
imagine a line at
the size of the
a line at y
size of the system
learn any information about
hashcash a denial of
any information about the
a denial of service
information about the data
and is not significant
about the data being
denial of service counter
the data being aggregated
data being aggregated other
being aggregated other than
since nodes only exchange
aggregated other than the
nodes only exchange a
other than the final
only exchange a small
than the final result
exchange a small amount
the final result of
a small amount of
final result of the
small amount of accounting
result of the computation
amount of accounting data
of accounting data at
accounting data at pre
when combined with differential
combined with differential privacy
defined intervals of time
with differential privacy techniques
to protect the aggregation
protect the aggregation results
the aggregation results themselves
it can be used
can be used to
be used to ensure
used to ensure that
to ensure that no
of the accesses live
ensure that no query
the accesses live above
that no query made
accesses live above this
no query made to
if we consider a
live above this line
we consider a packet
query made to the
consider a packet rate
made to the system
a packet rate of
to the system reveals
the system reveals the
system reveals the contribution
reveals the contribution of
the contribution of any
contribution of any particular
of any particular node
disks on is the
our overlay network looks
on is the third
overlay network looks a
is the third best
network looks a bit
the third best configuration
looks a bit like
a bit like a
bit like a gossip
like a gossip infrastructure
next only to the
only to the oracle
to the oracle and
seconds the maximum number
the maximum number of
maximum number of packets
number of packets received
of packets received and
packets received and sent
received and sent by
and sent by each
sent by each node
by each node is
and can be used
can be used to
be used to run
used to run gossip
the performance degradation in
with the key difference
performance degradation in going
the key difference that
degradation in going from
key difference that the
for each packet sent
difference that the random
each packet sent or
that the random peer
packet sent or received
the random peer selection
random peer selection of
on subversive miner strategies
peer selection of gossip
subversive miner strategies and
selection of gossip is
the history needs to
of gossip is replaced
miner strategies and block
gossip is replaced with
history needs to indicate
is replaced with a
strategies and block withholding
replaced with a completely
needs to indicate which
with a completely deterministic
to indicate which neighbor
a completely deterministic function
and block withholding attack
indicate which neighbor sent
block withholding attack in
which neighbor sent or
withholding attack in bitcoin
neighbor sent or received
attack in bitcoin digital
sent or received the
nodes are assigned virtual
or received the packet
disks on is negligibly
in bitcoin digital currency
on is negligibly small
are assigned virtual ids
assigned virtual ids that
virtual ids that are
ids that are either
that are either integers
are either integers or
bits to identify each
either integers or finite
to identify each neighbor
integers or finite field
or finite field elements
for the system under
the system under test
the history s size
history s size adds
s size adds up
and each node uses
size adds up to
each node uses a
the optimal configuration is
node uses a function
optimal configuration is to
uses a function based
configuration is to fig
a function based on
function based on either
based on either modular
on either modular arithmetic
either modular arithmetic or
modular arithmetic or finite
shows an estimate of
arithmetic or finite fields
an estimate of the
or finite fields to
estimate of the actual
finite fields to compute
of the actual power
fields to compute the
the actual power savings
to compute the order
actual power savings achieved
compute the order in
power savings achieved by
the order in which
savings achieved by our
order in which it
achieved by our solution
in which it should
which it should communicate
it should communicate with
we assume the following
should communicate with the
assume the following disk
communicate with the other
this is not significant
the following disk specifications
with the other nodes
is not significant compared
not significant compared to
significant compared to the
compared to the amount
to the amount of
we construct this function
the amount of regular
construct this function to
amount of regular data
this function to ensure
of regular data exchanged
function to ensure that
regular data exchanged in
to ensure that the
data exchanged in a
ensure that the network
exchanged in a streaming
that the network is
in a streaming session
the network is optimally
network is optimally robust
is optimally robust and
optimally robust and efficient
we also analyzed the
also analyzed the costs
analyzed the costs of
the costs of the
converging in logarithmic time
costs of the global
in logarithmic time and
of the global auditors
logarithmic time and tolerating
time and tolerating message
and tolerating message failures
tolerating message failures with
since they are dedicated
message failures with minimal
they are dedicated and
failures with minimal delay
are dedicated and external
dedicated and external to
how incentivize large bitcoin
and external to the
incentivize large bitcoin mining
external to the system
large bitcoin mining http
key cryptography to encrypt
cryptography to encrypt messages
the overhead imposed by
overhead imposed by them
imposed by them is
by them is of
them is of higher
ensuring that the the
is of higher concern
that the the system
the the system operator
the system operator cannot
system operator cannot infer
global auditors main tasks
operator cannot infer anything
auditors main tasks consist
cannot infer anything about
main tasks consist of
infer anything about the
tasks consist of sampling
anything about the data
consist of sampling the
about the data being
of sampling the system
the data being aggregated
sampling the system to
data being aggregated by
the system to collect
being aggregated by observing
system to collect download
aggregated by observing network
to collect download and
by observing network traffic
collect download and upload
download and upload rates
and upload rates of
upload rates of nodes
even the communication pattern
avg time for transition
the communication pattern is
communication pattern is completely
and of occasionally disseminating
pattern is completely predictable
of occasionally disseminating updates
is completely predictable and
occasionally disseminating updates to
completely predictable and hence
disseminating updates to the
predictable and hence reveals
updates to the threshold
and hence reveals nothing
to the threshold value
we see that turning
see that turning off
malicious nodes cannot significantly
the sample size remains
nodes cannot significantly deviate
sample size remains fixed
cannot significantly deviate from
size remains fixed independent
significantly deviate from correct
remains fixed independent of
deviate from correct behavior
of the disks results
from correct behavior without
fixed independent of the
the disks results in
independent of the size
correct behavior without being
of the size of
behavior without being detected
the size of the
size of the population
so the network encourages
the network encourages the
we ran simulations to
network encourages the operator
ran simulations to estimate
encourages the operator to
simulations to estimate the
the operator to behave
to estimate the worst
operator to behave correctly
case standard deviation of
and it even tolerates
standard deviation of the
it even tolerates byzantine
deviation of the download
even tolerates byzantine failure
of the download rates
tolerates byzantine failure by
the download rates across
byzantine failure by a
download rates across all
failure by a small
rates across all nodes
with all the disks
by a small minority
all the disks off
a small minority of
small minority of clients
we estimate that a
this ensures that important
estimate that a sample
ensures that important queries
that a sample size
that important queries will
while maintaining acceptable performance
important queries will not
a sample size of
queries will not be
will not be corrupted
not be corrupted or
be corrupted or blocked
corrupted or blocked by
or blocked by compromised
blocked by compromised devices
nodes is sufficient to
and that an adversary
is sufficient to provide
that an adversary cannot
shows some of the
an adversary cannot compromise
some of the tradeoffs
adversary cannot compromise the
of the tradeoffs involved
cannot compromise the privacy
compromise the privacy of
the privacy of client
note that the y
privacy of client data
of client data by
client data by gaining
independent of the population
data by gaining control
axis represents three different
by gaining control of
represents three different quantities
gaining control of a
of the population size
control of a few
of a few devices
a few devices in
the cumulative percentage of
few devices in the
cumulative percentage of time
devices in the system
percentage of time the
of time the disks
such as the ones
time the disks are
as the ones simulated
the disks are powered
the ones simulated in
disks are powered on
ones simulated in this
simulated in this work
the total duration of
total duration of the
even a smaller number
duration of the simulation
a smaller number of
smaller number of samples
number of samples was
of samples was found
samples was found to
was found to be
found to be sufficient
to be sufficient to
be sufficient to yield
sufficient to yield satisfactory
to yield satisfactory results
and the cumulative number
the cumulative number of
ro bert orma ndi
cumulative number of mode
istva n hegedu s
transitions that the disks
centralized costs are fixed
that the disks undergo
and ma rk jelasity
and provide a clear
provide a clear advantage
a clear advantage for
gossip learning with linear
clear advantage for using
learning with linear models
advantage for using auditing
with linear models on
for using auditing against
linear models on fully
using auditing against tit
both the total duration
models on fully distributed
the total duration of
on fully distributed this
total duration of the
fully distributed this work
duration of the experiment
distributed this work was
this work was supported
tat approaches in large
as well as the
well as the number
as the number of
the number of mode
by a grant from
a grant from the
grant from the nsf
from the nsf data
increase as the percentage
as the percentage of
the percentage of disks
percentage of disks that
of disks that is
practice and exsmart grids
disks that is powered
and exsmart grids program
heterogenous systems so far
that is powered on
systems so far we
is powered on is
so far we considered
powered on is decreased
far we considered the
we considered the use
considered the use of
the use of auditing
use of auditing to
of auditing to enforce
auditing to enforce node
to enforce node contribution
enforce node contribution in
node contribution in systems
contribution in systems where
in systems where all
systems where all nodes
where all nodes are
all nodes are assumed
we see that keeping
nodes are assumed to
are assumed to have
assumed to have homogeneous
to have homogeneous bandwidth
have homogeneous bandwidth resources
enough to upload and
disks on strikes an
to upload and download
on strikes an acceptable
upload and download at
strikes an acceptable balance
and download at a
download at a rate
at a rate close
a rate close to
rate close to the
close to the stream
to the stream rate
conclusion in this paper
pullbased streaming may be
streaming may be extended
we point out a
may be extended to
point out a new
be extended to heterogenous
out a new opportunity
extended to heterogenous systems
a new opportunity for
to heterogenous systems by
new opportunity for saving
heterogenous systems by organizing
opportunity for saving power
systems by organizing nodes
for saving power in
by organizing nodes into
saving power in large
organizing nodes into multiple
nodes into multiple groups
the idea is elegant
idea is elegant in
is elegant in its
elegant in its simplicity
log structured file systems
structured file systems write
file systems write only
systems write only to
write only to the
antony rowstron and peter
only to the log
rowstron and peter druschel
to the log head
if read accesses are
read accesses are served
accesses are served by
are served by the
served by the cache
and routing for large
no auditing fixed threshold
then write accesses touch
auditing fixed threshold stepwise
write accesses touch only
fixed threshold stepwise percentile
accesses touch only the
touch only the log
only the log head
the log head disk
potentially allowing us to
allowing us to power
us to power down
to power down all
power down all the
down all the other
all the other disks
avg download factor min
download factor min download
existing solutions like disk
factor min download factor
solutions like disk management
like disk management solutions
the working set model
working set model for
no auditing fixed threshold
set model for program
auditing fixed threshold stepwise
model for program behavior
fixed threshold stepwise percentile
correctness of a gossip
of a gossip based
a gossip based membership
gossip based membership protocol
in proceedings of the
proceedings of the twenty
fourth annual acm sympo
time disks on num
and ma rk jelasity
transitions total time of
total time of run
a private framework for
private framework for distributed
framework for distributed comsium
for distributed comsium on
distributed comsium on principles
comsium on principles of
on principles of distributed
principles of distributed computing
upload rate of opportunistic
rate of opportunistic nodes
improving the performance of
the performance of log
structured file systems with
file systems with adaptive
systems with adaptive methods
uniform node sampling service
node sampling service robust
upload rate of opportunistic
sampling service robust against
rate of opportunistic nodes
service robust against collusions
robust against collusions of
against collusions of malicious
collusions of malicious nodes
minimum and average download
and average download factors
average download factors across
download factors across all
reducing energy consumption of
factors across all correct
energy consumption of disk
across all correct nodes
consumption of disk storage
all correct nodes when
of disk storage using
correct nodes when using
disk storage using power
nodes when using different
when using different strategies
using different strategies for
different strategies for choosing
strategies for choosing the
for choosing the threshold
ifip international conference on
international conference on dependable
conference on dependable systems
on dependable systems and
the upload contribution rate
dependable systems and networks
upload contribution rate of
contribution rate of opportunistic
rate of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is varied
nodes is varied in
is varied in the
varied in the x
and the number of
the number of opportunistic
number of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is fixed
nodes is fixed at
avg download factor min
download factor min download
factor min download factor
byzantine resilient random membership
resilient random membership sampling
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise percentile
in proceedings of the
proceedings of the twenty
seventh acm symposium on
acm symposium on principles
symposium on principles of
on principles of distributed
principles of distributed computing
managed transactional consistency for
effect of increasing percentage
transactional consistency for web
of increasing percentage of
consistency for web caching
increasing percentage of powered
for web caching ittay
web caching ittay eyal
caching ittay eyal ken
ittay eyal ken birman
up disks on power
eyal ken birman robbert
disks on power and
ken birman robbert van
on power and time
birman robbert van renesse
robbert van renesse cornell
van renesse cornell university
renesse cornell university abstract
and caching solutions are
cornell university abstract in
caching solutions are typically
solutions are typically application
no auditing fixed threshold
auditing fixed threshold stepwise
fixed threshold stepwise percentile
on the other hand
only caches are widely
caches are widely used
are widely used in
is applicable to any
widely used in cloud
applicable to any cacheable
used in cloud infrastructure
to any cacheable dataset
in cloud infrastructure to
cloud infrastructure to reduce
infrastructure to reduce access
to reduce access latency
since existing solutions are
reduce access latency and
existing solutions are typically
access latency and to
solutions are typically layered
latency and to reduce
are typically layered on
and to reduce load
typically layered on top
to reduce load on
layered on top of
reduce load on backend
on top of the
load on backend databases
top of the file
operators view coherent caches
view coherent caches as
coherent caches as impractical
they could be used
caches as impractical at
could be used in
as impractical at genuinely
be used in conjunction
impractical at genuinely large
used in conjunction with
at genuinely large scale
in conjunction with our
genuinely large scale and
conjunction with our solution
large scale and many
with our solution to
scale and many client
our solution to take
solution to take advantage
to take advantage of
take advantage of application
facing caches are updated
caches are updated in
are updated in an
updated in an asynchronous
in an asynchronous manner
an asynchronous manner with
we also provide some
asynchronous manner with best
also provide some initial
provide some initial simulation
in proceedings of the
some initial simulation results
proceedings of the acm
initial simulation results that
of the acm sigcomm
simulation results that validate
results that validate our
that validate our claim
validate our claim that
existing solutions that support
our claim that power
solutions that support cache
that support cache consistency
support cache consistency are
savings are possible using
cache consistency are inapplicable
are possible using a
consistency are inapplicable to
possible using a log
are inapplicable to this
inapplicable to this scenario
to this scenario since
this scenario since they
scenario since they require
since they require a
they require a round
while simulations can never
require a round trip
simulations can never provide
a round trip to
can never provide conclusive
round trip to the
never provide conclusive evidence
trip to the database
provide conclusive evidence for
to the database on
conclusive evidence for the
the database on every
evidence for the feasibility
database on every cache
for the feasibility of
on every cache transaction
the feasibility of a
feasibility of a system
existing incoherent cache technologies
they are an effective
incoherent cache technologies are
are an effective means
cache technologies are oblivious
an effective means to
technologies are oblivious to
effective means to identify
are oblivious to transactional
means to identify promising
oblivious to transactional data
to identify promising solutions
to transactional data access
our principal contribution in
even if the backend
principal contribution in this
if the backend database
contribution in this paper
the backend database supports
in this paper is
backend database supports transactions
this paper is in
paper is in having
is in having shown
in having shown a
having shown a new
shown a new fit
a new fit for
new fit for an
fit for an old
for an old idea
we believe that the
believe that the log
aware cache for read
structured file system shows
file system shows promise
system shows promise as
shows promise as a
promise as a powersaving
as a powersaving opportunity
a powersaving opportunity for
powersaving opportunity for large
cache improves cache consistency
improves cache consistency despite
cache consistency despite asynchronous
consistency despite asynchronous and
despite asynchronous and unreliable
acknowledgments this work was
asynchronous and unreliable communication
this work was partially
and unreliable communication between
work was partially funded
unreliable communication between the
was partially funded by
communication between the cache
partially funded by intel
between the cache and
funded by intel corporation
the cache and the
by intel corporation and
cache and the database
intel corporation and the
corporation and the national
and the national science
the national science foundation
special thanks to saikat
thanks to saikat guha
to saikat guha for
saikat guha for his
a variant of serializability
guha for his input
variant of serializability that
for his input in
of serializability that is
his input in the
serializability that is suitable
input in the simulator
that is suitable for
in the simulator design
is suitable for incoherent
suitable for incoherent caches
epidemic algorithms for replicated
algorithms for replicated database
we also wish to
for replicated database maintenance
also wish to thank
and prove that with
wish to thank our
prove that with unbounded
to thank our anonymous
that with unbounded resources
thank our anonymous reviewers
with unbounded resources t
our anonymous reviewers for
in proceedings of the
anonymous reviewers for their
proceedings of the sixth
reviewers for their valuable
of the sixth annual
for their valuable feedback
the sixth annual acm
sixth annual acm symposium
annual acm symposium on
acm symposium on principles
symposium on principles of
on principles of distributed
principles of distributed computing
ratio of freeloaders figure
cache allows the system
allows the system manager
the system manager to
system manager to choose
manager to choose a
to choose a trade
minimum and average download
and average download factors
average download factors across
off between performance and
download factors across all
between performance and consistency
factors across all correct
across all correct nodes
all correct nodes when
correct nodes when using
our evaluation shows that
nodes when using different
evaluation shows that t
when using different strategies
using different strategies for
different strategies for choosing
strategies for choosing the
conserving disk energy in
for choosing the threshold
cache detects many inconsistencies
disk energy in network
detects many inconsistencies with
energy in network servers
many inconsistencies with only
inconsistencies with only nominal
each session has mixed
with only nominal overhead
session has mixed set
has mixed set of
mixed set of opportunistic
set of opportunistic nodes
we use synthetic workloads
use synthetic workloads to
synthetic workloads to demonstrate
contributing at different rates
workloads to demonstrate the
to demonstrate the efficacy
demonstrate the efficacy of
the efficacy of t
and percentage of opportunistic
percentage of opportunistic nodes
of opportunistic nodes is
opportunistic nodes is varied
cache when data accesses
nodes is varied on
when data accesses are
is varied on the
data accesses are clustered
varied on the x
th international conference on
accesses are clustered and
international conference on supercomputing
are clustered and its
clustered and its adaptive
and its adaptive reaction
its adaptive reaction to
adaptive reaction to workload
reaction to workload changes
to their upload bandwidths
with workloads based on
nodes able to upload
workloads based on the
able to upload at
based on the real
to upload at a
upload at a rate
at a rate higher
a rate higher than
rate higher than the
higher than the stream
than the stream rate
the stream rate are
stream rate are placed
rate are placed in
are placed in higher
which are closer to
are closer to the
closer to the source
the source sends data
source sends data to
sends data to the
data to the highest
to the highest level
of the inconsistencies and
the highest level group
the inconsistencies and increases
highest level group only
inconsistencies and increases the
and increases the rate
increases the rate of
the rate of consistent
the case for massive
who uses the basic
case for massive arrays
rate of consistent transactions
for massive arrays of
in lecture notes in
massive arrays of idle
of consistent transactions by
arrays of idle disks
lecture notes in computer
uses the basic protocol
notes in computer science
the basic protocol to
basic protocol to disseminate
protocol to disseminate data
to disseminate data among
disseminate data among each
data among each other
nodes in lower levels
in lower levels may
lower levels may receive
levels may receive data
may receive data at
receive data at smaller
data at smaller rates
after some filtering is
some filtering is applied
conference on file and
on file and storage
file and storage technologies
i ntroduction internet services
level nodes may be
ntroduction internet services like
nodes may be used
internet services like online
may be used to
services like online retailers
be used to act
like online retailers and
used to act as
online retailers and social
to act as sources
retailers and social networks
act as sources to
and social networks store
as sources to the
social networks store important
sources to the lower
networks store important data
store important data sets
important data sets in
data sets in large
sets in large distributed
in large distributed databases
alleviating the burden at
the burden at the
burden at the source
technical challenges have forced
auditing can be used
challenges have forced such
can be used to
have forced such large
be used to avoid
used to avoid the
to avoid the presence
avoid the presence of
system operators to forgo
the presence of opportunistic
operators to forgo transactional
presence of opportunistic and
to forgo transactional consistency
of opportunistic and lower
helping disk arrays sleep
opportunistic and lower bandwidth
disk arrays sleep through
and lower bandwidth nodes
arrays sleep through the
lower bandwidth nodes in
sleep through the winter
bandwidth nodes in the
providing perobject consistency instead
nodes in the higher
often with some form
with some form of
some form of eventual
form of eventual consistency
it can ensure that
can ensure that the
ensure that the hierarchy
that the hierarchy of
proceedings of the twentieth
the hierarchy of nodes
of the twentieth acm
hierarchy of nodes is
the twentieth acm symposium
of nodes is obeyed
twentieth acm symposium on
nodes is obeyed by
acm symposium on operating
is obeyed by all
symposium on operating systems
obeyed by all nodes
on operating systems principles
while allowing the system
allowing the system to
the system to leverage
system to leverage additional
to leverage additional resources
leverage additional resources from
additional resources from privileged
resources from privileged altruistic
from privileged altruistic nodes
privileged altruistic nodes to
altruistic nodes to forward
nodes to forward data
to forward data to
forward data to lower
data to lower level
to lower level groups
we intend to explore
intend to explore this
to explore this further
explore this further in
this further in future
further in future work
interplay of energy and
related work several p
of energy and performance
energy and performance for
and performance for disk
performance for disk arrays
for disk arrays running
support transactions with guarantees
disk arrays running transaction
transactions with guarantees such
streaming protocols have been
with guarantees such as
arrays running transaction processing
guarantees such as snapshot
protocols have been previously
running transaction processing workloads
have been previously proposed
such as snapshot isolation
as snapshot isolation and
snapshot isolation and even
isolation and even full
in ieee international symposium
and even full transactional
ieee international symposium on
even full transactional atomicity
the first generation of
international symposium on performance
first generation of systems
symposium on performance analysis
on performance analysis of
performance analysis of systems
our work begins with
analysis of systems and
work begins with the
of systems and software
begins with the observation
with the observation that
it can be difficult
can be difficult for
be difficult for client
relied on approaches based
on approaches based on
approaches based on pushing
based on pushing data
tier applications to leverage
on pushing data through
applications to leverage the
pushing data through a
to leverage the transactions
data through a single
leverage the transactions that
through a single dissemination
the transactions that the
a single dissemination tree
transactions that the databases
that the databases provide
later approaches focused on
their reads are satisfied
approaches focused on improving
reads are satisfied primarily
focused on improving fairness
are satisfied primarily from
on improving fairness among
satisfied primarily from incoherent
based fast overlay topology
primarily from incoherent cache
improving fairness among peers
fast overlay topology construction
fairness among peers and
among peers and resilience
the benefits of caching
peers and resilience to
benefits of caching are
and resilience to churn
of caching are twofold
resilience to churn by
to churn by breaking
churn by breaking data
by breaking data into
breaking data into multiple
data into multiple substreams
into multiple substreams and
it reduces database load
multiple substreams and sending
substreams and sending them
and sending them along
sending them along disjoing
them along disjoing paths
thereby enabling higher throughput
reducing disk power consumption
disk power consumption in
power consumption in servers
consumption in servers with
in servers with drpm
the caches are typically
caches are typically placed
are typically placed close
typically placed close to
placed close to the
close to the clients
the problem centers on
problem centers on the
centers on the asynchronous
more recent systems like
on the asynchronous style
recent systems like coolstreaming
the asynchronous style of
asynchronous style of communication
style of communication used
of communication used between
communication used between the
used between the database
between the database and
the database and the
database and the geo
based style of data
style of data dissemination
a cache should not
coolstreaming breaks the data
cache should not access
breaks the data into
should not access the
the data into packets
not access the database
access the database on
the database on every
database on every transaction
hiding in plain sight
and peers organized into
peers organized into a
organized into a mesh
any approach requiring a
into a mesh request
google seeks more power
a mesh request packets
approach requiring a high
mesh request packets from
requiring a high rate
request packets from their
a high rate of
packets from their neighbors
high rate of round
from their neighbors using
in the new york
their neighbors using a
the new york times
neighbors using a scheduling
using a scheduling algorithm
trips to an authoritative
to an authoritative backend
an authoritative backend database
authoritative backend database would
as we saw earlier
backend database would cause
database would cause unacceptable
and maarten van steen
would cause unacceptable latency
chainsaw uses a simpler
uses a simpler policy
a simpler policy for
simpler policy for requesting
a cache must respond
policy for requesting packets
cache must respond instantly
randomly fetching them while
and asynchronous updates rule
fetching them while respecting
asynchronous updates rule out
them while respecting a
updates rule out cache
while respecting a maximum
rule out cache coherency
respecting a maximum limit
out cache coherency schemes
a maximum limit on
cache coherency schemes that
maximum limit on the
coherency schemes that would
limit on the number
schemes that would require
on the number of
that would require the
the number of outstanding
would require the backend
number of outstanding requests
require the backend database
of outstanding requests to
the backend database to
outstanding requests to each
backend database to promptly
requests to each neighbor
database to promptly invalidate
to promptly invalidate or
promptly invalidate or update
invalidate or update cached
or update cached this
update cached this work
chainsaw presents smaller delays
cached this work is
presents smaller delays for
this work is supported
berkeley db java edition
smaller delays for the
db java edition architecture
delays for the receipt
for the receipt of
the receipt of packets
receipt of packets compared
an oracle white paper
of packets compared to
packets compared to the
compared to the coolstreaming
by a grant from
to the coolstreaming protocol
a grant from the
grant from the darpa
from the darpa mrc
the darpa mrc program
in a more recent
a more recent work
or even to track
even to track the
to track the locations
track the locations at
the locations at which
locations at which cached
at which cached objects
which cached objects reside
based approaches are shown
approaches are shown to
are shown to present
we define a variant
shown to present better
define a variant of
to present better performance
a variant of serializability
present better performance over
variant of serializability called
better performance over tree
of serializability called cacheserializability
serializability called cacheserializability that
called cacheserializability that is
cacheserializability that is suitable
that is suitable for
is suitable for incoherent
suitable for incoherent caches
previous papers have considered
papers have considered a
have considered a variety
a wide range of
considered a variety of
wide range of web
a variety of possible
range of web applications
variety of possible mechanisms
of possible mechanisms to
possible mechanisms to encourage
mechanisms to encourage node
to encourage node contribution
from social networks to
social networks to online
networks to online retailers
settle for caches that
for caches that are
caches that are oblivious
that are oblivious to
are oblivious to transactions
is a framework proposed
a framework proposed to
framework proposed to enforce
proposed to enforce download
to enforce download rate
despite the fact that
enforce download rate limitations
eduardo pinheiro and ricardo
the fact that an
download rate limitations on
pinheiro and ricardo bianchini
rate limitations on p
fact that an inconsistent
that an inconsistent read
an inconsistent read access
inconsistent read access can
energy conservation techniques for
read access can deter
conservation techniques for disk
access can deter a
techniques for disk array
can deter a client
p media streaming systems
deter a client and
a client and reduce
client and reduce their
and reduce their income
the protocol relies on
protocol relies on a
relies on a set
they cannot afford consistent
on a set of
cannot afford consistent cache
a set of trusted
afford consistent cache techniques
set of trusted nodes
consistent cache techniques that
of trusted nodes that
cache techniques that require
trusted nodes that store
techniques that require backend
nodes that store information
that require backend accesses
that store information on
require backend accesses on
store information on the
backend accesses on every
information on the data
accesses on every transaction
on the data downloaded
the data downloaded by
th annual international conference
data downloaded by each
annual international conference on
downloaded by each node
international conference on supercomputing
by each node receiving
each node receiving data
a novel caching scheme
nodes only send an
novel caching scheme that
only send an object
caching scheme that improves
send an object after
scheme that improves consistency
an object after consulting
that improves consistency at
object after consulting the
improves consistency at the
after consulting the trusted
consistency at the cache
consulting the trusted nodes
at the cache level
the trusted nodes to
the cache level with
trusted nodes to verify
cache level with a
nodes to verify if
level with a nominal
to verify if the
with a nominal storage
verify if the nodes
a nominal storage and
if the nodes requesting
nominal storage and communication
the nodes requesting the
storage and communication tradeoff
nodes requesting the stream
requesting the stream are
the stream are not
stream are not overrequesting
are not overrequesting data
cache significantly improves consistency
it is targeted to
significantly improves consistency for
is targeted to systems
improves consistency for workloads
targeted to systems where
consistency for workloads where
to systems where nodes
for workloads where data
characteristics of file system
systems where nodes upload
of file system workloads
workloads where data accesses
where nodes upload full
where data accesses are
nodes upload full media
data accesses are clustered
upload full media objects
full media objects from
media objects from each
objects from each other
which is common in
is common in today
common in today s
in today s large
and not for live
streaming systems where all
systems where all nodes
where all nodes are
this is achieved while
all nodes are interested
is achieved while retaining
nodes are interested in
achieved while retaining the
are interested in receiving
while retaining the global
interested in receiving the
retaining the global scalability
in receiving the exact
the global scalability afforded
receiving the exact same
global scalability afforded by
the exact same data
scalability afforded by executing
exact same data in
afforded by executing read
same data in close
data in close to
in close to real
close to real time
only transactions on the
transactions on the edge
directly from the cache
mendel rosenblum and john
rosenblum and john k
we do this by
do this by storing
this by storing dependency
consider fairness issues in
by storing dependency information
fairness issues in the
the design and implementation
issues in the context
storing dependency information with
design and implementation of
in the context of
dependency information with the
and implementation of a
the context of tree
information with the cached
implementation of a log
with the cached objects
acm transactions on computer
transactions on computer systems
to identify possible inconsistencies
the authors present mechanisms
identify possible inconsistencies without
authors present mechanisms that
possible inconsistencies without contacting
present mechanisms that rank
inconsistencies without contacting the
mechanisms that rank peers
without contacting the database
that rank peers according
rank peers according to
peers according to their
according to their level
to their level of
the user can improve
their level of cooperation
user can improve the
level of cooperation with
can improve the level
of cooperation with the
improve the level of
cooperation with the system
the level of consistency
level of consistency by
of consistency by adjusting
consistency by adjusting the
by adjusting the size
one of their techniques
adjusting the size of
of their techniques involves
the size of this
their techniques involves the
size of this dependency
techniques involves the reconstruction
of this dependency data
involves the reconstruction of
the reconstruction of trees
reconstruction of trees as
of trees as a
trees as a way
more dependency data leads
as a way of
dependency data leads to
a way of punishing
data leads to increased
way of punishing opportunistic
leads to increased consistency
of punishing opportunistic nodes
to demonstrate the efficacy
demonstrate the efficacy of
most of their mechanisms
the efficacy of the
of their mechanisms require
efficacy of the proposed
their mechanisms require peers
of the proposed scheme
mechanisms require peers to
require peers to keep
peers to keep track
to keep track of
keep track of their
we created a prototype
track of their parents
created a prototype implementation
of their parents and
a prototype implementation and
their parents and children
prototype implementation and exposed
parents and children s
implementation and exposed it
and children s behavior
and exposed it to
exposed it to workloads
it to workloads based
to workloads based on
workloads based on graphically
studied the effect of
the effect of different
effect of different types
of different types of
different types of incentives
types of incentives on
of incentives on the
incentives on the chainsaw
on the chainsaw protocol
such as those seen
as those seen in
those seen in social
disk layout optimization for
layout optimization for reducing
optimization for reducing energy
for reducing energy consumption
tat and some variations
the authors propose an
authors propose an algorithm
propose an algorithm that
an algorithm that sets
algorithm that sets up
that sets up local
sets up local markets
of the inconsistencies and
up local markets at
the inconsistencies and can
local markets at every
inconsistencies and can increase
markets at every node
and can increase the
can increase the ratio
increase the ratio of
the ratio of consistent
th annual international conference
where neighbors compete for
annual international conference on
neighbors compete for the
international conference on supercomputing
compete for the node
ratio of consistent transactions
for the node s
of consistent transactions by
the node s upload
node s upload capacity
nodes favor neighbors who
favor neighbors who contribute
neighbors who contribute more
with nodes classified as
nodes classified as fast
classified as fast or
as fast or slow
fast or slow nodes
both with low overhead
the results indicate that
results indicate that the
we construct synthetic workloads
indicate that the proposed
construct synthetic workloads and
that the proposed algorithm
synthetic workloads and observe
the proposed algorithm improves
workloads and observe how
proposed algorithm improves the
and observe how t
algorithm improves the performance
improves the performance of
the performance of the
performance of the system
cache reacts to different
of the system when
reacts to different clustering
the system when the
to different clustering levels
system when the total
different clustering levels and
when the total upload
clustering levels and how
the total upload capacity
levels and how it
total upload capacity is
and how it adapts
how it adapts as
upload capacity is not
it adapts as clusters
capacity is not enough
adapts as clusters change
is not enough to
not enough to supply
enough to supply all
to supply all the
supply all the nodes
with perfectly clustered workloads
cache implements full cache
streaming system where nodes
system where nodes choose
to explain this perfect
where nodes choose their
explain this perfect behavior
nodes choose their neighbors
this perfect behavior we
choose their neighbors based
perfect behavior we prove
their neighbors based on
behavior we prove a
neighbors based on their
we prove a related
based on their history
prove a related claim
on their history of
a related claim we
their history of interaction
related claim we show
claim we show that
we show that with
show that with unbounded
that with unbounded resources
nodes are placed in
with unbounded resources t
are placed in the
placed in the system
in the system according
the system according to
system according to their
according to their current
to their current trading
their current trading performances
encouraging nodes to contribute
nodes to contribute more
to contribute more and
the contributions of this
contribute more and therefore
contributions of this work
more and therefore be
of this work are
and therefore be closer
therefore be closer to
be closer to the
closer to the source
is a more recent
a more recent live
streaming approach that tolerates
approach that tolerates the
that tolerates the existence
tolerates the existence of
the existence of opportunistic
a variant of serializability
existence of opportunistic and
variant of serializability suitable
of opportunistic and malicious
of serializability suitable for
opportunistic and malicious nodes
serializability suitable for incoherent
suitable for incoherent caches
time is divided into
is divided into rounds
in which each peer
which each peer communicates
each peer communicates with
peer communicates with another
communicates with another peer
with another peer selected
another peer selected using
peer selected using a
selected using a pseudo
which allows trading off
allows trading off efficiency
trading off efficiency and
off efficiency and transaction
consistency in large scale
in large scale cache
large scale cache deployments
peers exchange their current
exchange their current history
their current history containing
current history containing the
history containing the identifiers
containing the identifiers of
the identifiers of all
identifiers of all the
of all the current
all the current data
the current data they
current data they hold
cache with synthetic workloads
as basis for the
basis for the next
for the next exchanges
demonstrating its adaptivity and
its adaptivity and sensitivity
adaptivity and sensitivity to
nodes also perform a
and sensitivity to clustering
also perform a phase
perform a phase of
a phase of optimistic
phase of optimistic push
forwarding useful updates to
useful updates to pseudo
randomly picked peers with
picked peers with no
cache with workloads based
peers with no guarantee
with workloads based on
with no guarantee of
workloads based on graphically
no guarantee of useful
guarantee of useful return
world data demonstrating detection
data demonstrating detection rates
demonstrating detection rates of
conclusion we propose and
we propose and evaluate
propose and evaluate a
and evaluate a scalable
evaluate a scalable auditing
based technique for enforcing
technique for enforcing fairness
for enforcing fairness in
enforcing fairness in a
fairness in a live
and consistency improvements of
our approach employs local
approach employs local auditors
employs local auditors that
local auditors that execute
auditors that execute on
that execute on all
execute on all nodes
on all nodes in
all nodes in a
nodes in a streaming
in a streaming session
they are responsible for
are responsible for collecting
responsible for collecting auditable
for collecting auditable information
collecting auditable information about
auditable information about other
information about other neighbors
about other neighbors data
other neighbors data exchanges
and for verifying that
cache with unbounded resources
for verifying that neighbors
with unbounded resources implements
verifying that neighbors upload
unbounded resources implements cache
that neighbors upload more
neighbors upload more data
upload more data than
more data than a
data than a specified
than a specified threshold
this threshold is defined
threshold is defined by
is defined by dedicated
a scalable services architecture
defined by dedicated global
by dedicated global auditors
scalable services architecture tudor
the complexity of implementing
services architecture tudor marian
complexity of implementing geo
architecture tudor marian ken
tudor marian ken birman
which periodically sample the
marian ken birman department
periodically sample the state
ken birman department of
scale databases with strong
birman department of computer
sample the state of
department of computer science
databases with strong guarantees
the state of the
of computer science cornell
with strong guarantees initially
computer science cornell university
state of the system
strong guarantees initially led
of the system to
guarantees initially led companies
the system to determine
initially led companies to
system to determine if
led companies to abandon
to determine if the
companies to abandon cross
determine if the overall
if the overall download
the overall download rate
overall download rate is
object consistency altogether and
download rate is compromised
consistency altogether and make
rate is compromised by
altogether and make do
is compromised by the
and make do with
compromised by the presence
make do with weak
by the presence of
do with weak guarantees
the presence of opportunistic
with weak guarantees such
presence of opportunistic nodes
weak guarantees such as
guarantees such as per
global auditing determines the
object atomicity or eventual
auditing determines the minimum
atomicity or eventual consistency
determines the minimum threshold
the minimum threshold for
minimum threshold for uploads
and works with local
works with local auditing
such systems do repair
with local auditing to
systems do repair any
local auditing to punish
do repair any problems
auditing to punish nodes
repair any problems that
to punish nodes that
any problems that arise
punish nodes that do
nodes that do not
that do not upload
do not upload enough
not upload enough data
we study the efficiency
study the efficiency of
edu abstract data centers
user is sometimes exposed
the efficiency of our
is sometimes exposed to
efficiency of our auditing
sometimes exposed to inconsistency
of our auditing approach
abstract data centers constructed
our auditing approach through
data centers constructed as
auditing approach through simulation
centers constructed as clusters
for some applications this
constructed as clusters of
some applications this is
as clusters of inexpensive
applications this is acceptable
clusters of inexpensive machines
and show that it
of inexpensive machines have
show that it is
inexpensive machines have compelling
and the approach has
that it is able
the approach has been
machines have compelling cost
approach has been surprisingly
it is able to
has been surprisingly successful
is able to maintain
able to maintain the
to maintain the throughput
in today s cloud
maintain the throughput of
the throughput of the
but developing services to
throughput of the streaming
developing services to run
of the streaming system
relaxed consistency is something
the streaming system even
consistency is something of
services to run on
streaming system even in
to run on them
is something of a
run on them can
something of a credo
on them can be
system even in the
them can be challenging
even in the presence
in the presence of
the presence of a
presence of a large
of a large number
this paper reports on
a large number of
paper reports on a
large number of opportunistic
reports on a new
number of opportunistic nodes
on a new framework
the scalable services architecture
only transactions by accessing
transactions by accessing caches
which helps developers develop
helps developers develop scalable
developers develop scalable clustered
develop scalable clustered applications
which receive their values
receive their values by
their values by reading
values by reading from
the work is focused
by reading from the
work is focused on
reading from the database
is focused on nontransactional
focused on nontransactional high
these are poorly supported
are poorly supported in
update transactions go directly
poorly supported in existing
transactions go directly to
supported in existing platforms
go directly to the
a case for end
directly to the database
case for end system
for end system multicast
a primary goal was
primary goal was to
goal was to keep
was to keep the
to keep the ssa
keep the ssa as
the ssa as small
ssa as small and
as small and simple
small and simple as
subsequent cache invalidations can
and simple as possible
cache invalidations can be
invalidations can be delayed
can be delayed or
be delayed or even
delayed or even lost
key elements include a
or even lost due
elements include a tcp
even lost due to
lost due to race
due to race conditions
based chain replication mechanism
chain replication mechanism and
replication mechanism and a
mechanism and a gossip
leading to a potentially
to a potentially inconsistent
based subsystem for managing
a potentially inconsistent view
subsystem for managing configuration
potentially inconsistent view by
for managing configuration data
inconsistent view by the
managing configuration data and
view by the cache
configuration data and repairing
by the cache clients
data and repairing inconsistencies
and repairing inconsistencies after
repairing inconsistencies after faults
our experimental results confirm
experimental results confirm the
results confirm the effectiveness
confirm the effectiveness of
the effectiveness of the
effectiveness of the approach
large internet services store
internet services store vast
introduction large computing systems
services store vast amounts
large computing systems are
store vast amounts of
computing systems are often
vast amounts of data
systems are often structured
are often structured as
often structured as service
structured as service oriented
online retailers such as
as service oriented architectures
retailers such as amazon
such as amazon and
as amazon and ebay
amazon and ebay maintain
and ebay maintain product
ebay maintain product stocks
maintain product stocks and
product stocks and information
for example using web
example using web services
and social networking sites
using web services platforms
social networking sites such
networking sites such as
sites such as facebook
such as facebook and
as facebook and twitter
facebook and twitter maintain
and twitter maintain graphical
clients access services in
twitter maintain graphical databases
access services in a
maintain graphical databases representing
services in a request
graphical databases representing user
databases representing user relations
representing user relations and
user relations and group
relations and group structures
reliable multicasting with an
multicasting with an overlay
each service is self
with an overlay network
offers its own api
th symposium on operating
such databases are sharded
symposium on operating systems
and handles its own
on operating systems design
databases are sharded and
handles its own quality
operating systems design and
its own quality of
systems design and implementation
own quality of service
are sharded and replicated
quality of service or
of service or availability
service or availability guarantees
the vast majority of
vast majority of accesses
majority of accesses are
for example by arranging
of accesses are read
example by arranging to
by arranging to be
arranging to be restarted
to be restarted after
be restarted after a
restarted after a failure
while many services need
many services need to
services need to maintain
need to maintain availability
to maintain availability in
maintain availability in the
availability in the face
in the face of
the face of challenging
face of challenging operating
of challenging operating conditions
building services with these
services with these properties
with these properties is
these properties is difficult
existing web services platforms
web services platforms offer
services platforms offer load
to reduce database load
reduce database load and
balancing and restart mechanisms
database load and to
and restart mechanisms for
load and to reduce
restart mechanisms for transactional
and to reduce access
mechanisms for transactional services
to reduce access latency
for transactional services implemented
transactional services implemented using
services implemented using a
implemented using a three
these companies employ a
companies employ a twotier
employ a twotier structure
placing layers of cache
but not for services
layers of cache servers
not for services implemented
of cache servers in
for services implemented using
cache servers in front
services implemented using other
servers in front of
implemented using other technologies
in front of the
front of the database
developers of nontransactional web
of nontransactional web services
nontransactional web services must
web services must implement
services must implement their
highbandwidth content distribution in
must implement their own
content distribution in cooperative
implement their own mechanisms
distribution in cooperative environments
their own mechanisms for
own mechanisms for replicating
mechanisms for replicating data
the caches of primary
caches of primary interest
of primary interest to
tracking membership and live
primary interest to us
membership and live this
interest to us are
and live this work
to us are typically
live this work was
us are typically situated
this work was supported
are typically situated far
work was supported by
th acm symposium on
typically situated far from
acm symposium on operating
situated far from the
symposium on operating systems
was supported by darpa
on operating systems principles
far from the backend
from the backend database
the backend database systems
backend database systems to
ipto under the srs
database systems to reduce
under the srs program
systems to reduce latency
the srs program and
srs program and by
program and by the
and by the rome
by the rome air
companies place caches close
the rome air force
place caches close to
rome air force research
caches close to clients
air force research laboratory
timeouts are used to
are used to ensure
used to ensure that
to ensure that stale
ensure that stale cached
that stale cached objects
stale cached objects will
cached objects will eventually
under the prometheus program
objects will eventually be
will eventually be flushed
additional support was provided
support was provided by
but to achieve a
was provided by the
to achieve a high
provided by the nsf
achieve a high cache
a high cache hit
high cache hit ratio
timeout values are generally
values are generally large
robbert van renesse ness
to obtain reasonable consistency
redirecting requests during failures
the database sends an
requests during failures to
database sends an asynchronous
during failures to minimize
sends an asynchronous stream
failures to minimize client
an asynchronous stream of
to minimize client disruption
asynchronous stream of invalidation
stream of invalidation records
of invalidation records or
invalidation records or cache
records or cache updates
and detecting and repairing
detecting and repairing inconsistencies
often using protocols optimized
our premise in this
using protocols optimized for
premise in this paper
in this paper is
protocols optimized for throughput
this paper is that
optimized for throughput and
paper is that for
for throughput and freshness
is that for many
throughput and freshness and
that for many services
and freshness and lacking
freshness and lacking absolute
and lacking absolute guarantees
lacking absolute guarantees of
absolute guarantees of order
the transactional model is
guarantees of order or
transactional model is a
of order or reliability
model is a poor
eliminating trees from overlay
is a poor fit
trees from overlay multicast
a poor fit and
poor fit and hence
fit and hence that
and hence that tools
hence that tools aimed
that tools aimed at
tools aimed at non
it is difficult to
th international workshop on
is difficult to make
international workshop on peer
difficult to make this
to make this invalidation
transactional web services systems
make this invalidation mechanism
web services systems will
this invalidation mechanism reliable
services systems will be
invalidation mechanism reliable without
systems will be needed
mechanism reliable without hampering
reliable without hampering database
without hampering database efficiency
we recognize that this
recognize that this is
that this is debatable
the issues are many
vendors have generally argued
have generally argued that
generally argued that only
argued that only transactional
the databases are large
that only transactional systems
only transactional systems offer
transactional systems offer the
systems offer the hooks
residing on many servers
offer the hooks needed
the hooks needed to
hooks needed to support
needed to support automated
to support automated scalability
databases use locks prudently
use locks prudently in
locks prudently in order
prudently in order to
in order to maximize
order to maximize concurrency
repair and restart mechanisms
to the extent that
key to this argument
the extent that the
to this argument is
extent that the database
this argument is the
that the database keeps
argument is the ease
the database keeps track
is the ease with
database keeps track of
the ease with which
keeps track of the
ease with which interrupted
track of the caches
with which interrupted transactions
of the caches that
which interrupted transactions can
the caches that hold
interrupted transactions can be
caches that hold a
transactions can be rolled
that hold a copy
can be rolled back
hold a copy of
a copy of each
copy of each object
it may be possible
may be possible to
be possible to send
possible to send an
to send an invalidation
and the relative simplicity
but tracking the state
the relative simplicity of
tracking the state of
relative simplicity of cleaning
the state of caches
simplicity of cleaning up
state of caches is
of cleaning up a
of caches is complicated
cleaning up a database
caches is complicated and
up a database after
is complicated and hence
a database after a
complicated and hence if
database after a crash
and hence if they
hence if they are
if they are used
they are used at
are used at all
yet the transactional programming
the transactional programming model
transactional programming model also
driven overlay network for
programming model also brings
such systems view invalidations
model also brings constraints
overlay network for efficient
also brings constraints and
network for efficient live
brings constraints and overheads
for efficient live media
systems view invalidations as
efficient live media streaming
view invalidations as a
invalidations as a kind
as a kind of
were this not the
a kind of hint
this not the case
they could be delayed
the transactional model would
transactional model would long
model would long ago
would long ago have
long ago have become
ago have become universal
th conference on computer
conference on computer communications
on computer communications and
computer communications and networking
some of these constraints
of these constraints relate
these constraints relate to
constraints relate to the
due to buffering or
relate to the challenges
to buffering or retransmissions
to the challenges of
buffering or retransmissions after
the challenges of maintaining
or retransmissions after message
challenges of maintaining a
retransmissions after message loss
of maintaining a clean
maintaining a clean separation
a clean separation of
clean separation of code
separation of code and
of code and data
not all applications can
all applications can be
applications can be structured
can be structured in
be structured in this
structured in this manner
transactional rollback and restart
rollback and restart can
and restart can be
due to an inaccurate
restart can be costly
to an inaccurate list
an inaccurate list of
inaccurate list of locations
and restarting a database
restarting a database after
a database after a
database after a crash
after a crash incurs
a crash incurs delays
crash incurs delays while
incurs delays while cleanup
delays while cleanup code
while cleanup code runs
high availability is difficult
availability is difficult to
is difficult to acheive
difficult to acheive in
defense against intrusion in
to acheive in the
against intrusion in a
acheive in the transactional
intrusion in a live
in the transactional model
in a live streaming
due to a system
a live streaming multicast
to a system configuration
live streaming multicast system
a system configuration change
the fastest database replication
fastest database replication schemes
or because of races
because of races between
of races between reads
th ieee international conference
suffer from failure scenarios
ieee international conference on
from failure scenarios that
international conference on peer
failure scenarios that can
scenarios that can require
that can require intervention
can require intervention by
require intervention by a
intervention by a human
by a human operator
yet the higher fidelity
a missing invalidation obviously
the higher fidelity schemes
missing invalidation obviously leaves
higher fidelity schemes require
invalidation obviously leaves the
fidelity schemes require expensive
obviously leaves the corresponding
schemes require expensive multi
leaves the corresponding cache
the corresponding cache entry
corresponding cache entry stale
phase commit protocols and
commit protocols and hence
protocols and hence may
pitfalls of such invalidation
and hence may not
of such invalidation schemes
hence may not give
such invalidation schemes are
may not give adequate
invalidation schemes are described
not give adequate performance
schemes are described in
are described in detail
described in detail by
in detail by nishita
detail by nishita et
by nishita et al
clustered threetier database products
threetier database products are
database products are powerful
products are powerful solutions
but they negotiate these
they negotiate these potential
negotiate these potential pitfalls
these potential pitfalls in
potential pitfalls in ways
pitfalls in ways that
in ways that preclude
and by bronson et
ways that preclude important
by bronson et al
that preclude important classes
preclude important classes of
important classes of applications
our motivation is to
motivation is to show
is to show that
to show that a
show that a simple
that a simple and
a simple and remarkably
simple and remarkably inexpensive
and remarkably inexpensive infrastructure
but forgoing transactional consistency
remarkably inexpensive infrastructure can
forgoing transactional consistency can
inexpensive infrastructure can support
transactional consistency can result
infrastructure can support clustered
consistency can result in
can support clustered execution
can result in undesired
support clustered execution of
result in undesired behavior
clustered execution of a
in undesired behavior of
execution of a significant
undesired behavior of a
of a significant class
behavior of a service
a significant class of
significant class of non
consider a buyer at
a buyer at an
buyer at an online
th conference on computer
at an online site
the work reported here
an online site who
conference on computer communications
work reported here focuses
online site who looks
reported here focuses on
site who looks for
here focuses on services
who looks for a
focuses on services that
looks for a toy
on services that don
for a toy train
services that don t
a toy train with
that don t fit
toy train with its
don t fit the
train with its matching
t fit the transactional
with its matching tracks
fit the transactional paradigm
its matching tracks just
matching tracks just as
tracks just as the
just as the vendor
typically for reasons of
as the vendor is
for reasons of performance
the vendor is adding
vendor is adding them
is adding them to
adding them to the
them to the database
ones that operate directly
that operate directly on
operate directly on in
the client may see
memory data structures or
client may see only
data structures or simple
structures or simple non
may see only the
see only the train
only the train in
the train in stock
train in stock but
in stock but not
to simplify our task
stock but not the
but not the tracks
not the tracks because
we assume that these
the tracks because the
assume that these services
tracks because the product
that these services are
because the product insertion
these services are capable
the product insertion transaction
services are capable of
product insertion transaction would
are capable of handling
insertion transaction would often
capable of handling outof
transaction would often be
would often be broken
often be broken into
be broken into two
broken into two or
into two or more
two or more atomic
or more atomic but
more atomic but independent
and that processes implementing
atomic but independent subtransactions
that processes implementing them
processes implementing them experience
implementing them experience only
them experience only crash
experience only crash failures
in a social network
as will be shown
will be shown below
an inconsistency with unexpected
inconsistency with unexpected results
with unexpected results can
unexpected results can occur
our assumptions hold for
results can occur if
assumptions hold for a
can occur if a
hold for a very
occur if a user
for a very large
if a user x
a very large group
a user x s
very large group of
user x s record
large group of applications
x s record says
s record says it
record says it belongs
says it belongs to
it belongs to a
the ssa was built
belongs to a certain
ssa was built using
to a certain group
was built using epidemic
but that group s
that group s record
group s record does
s record does not
record does not include
communication protocols in conjunction
does not include x
protocols in conjunction with
in conjunction with a
conjunction with a novel
web albums maintain picture
with a novel variant
albums maintain picture data
a novel variant of
maintain picture data and
novel variant of the
picture data and access
variant of the chain
data and access control
of the chain replication
and access control lists
the chain replication scheme
chain replication scheme which
replication scheme which has
scheme which has evolved
which has evolved from
has evolved from the
evolved from the mechanism
from the mechanism first
and it is important
the mechanism first proposed
it is important that
mechanism first proposed in
is important that acl
important that acl and
that acl and album
acl and album updates
and album updates are
album updates are consistent
the classical example involves
classical example involves removing
th symposium on operating
example involves removing one
symposium on operating systems
involves removing one s
on operating systems design
removing one s boss
operating systems design and
one s boss from
systems design and implementation
gossip based infrastructures are
s boss from the
based infrastructures are beneficial
boss from the album
infrastructures are beneficial because
from the album acl
are beneficial because they
the album acl and
beneficial because they are
album acl and then
acl and then adding
and then adding unflattering
then adding unflattering pictures
simple to implement rapidly
to implement rapidly self
stabilizing after disruptions analytically
while many of these
after disruptions analytically appealing
many of these systems
disruptions analytically appealing this
of these systems make
analytically appealing this paper
these systems make do
appealing this paper reports
systems make do with
this paper reports on
make do with weak
paper reports on the
do with weak consistency
reports on the architecture
on the architecture and
the architecture and performance
architecture and performance of
and performance of the
their utility is reduced
performance of the platform
utility is reduced when
is reduced when their
reduced when their clients
when their clients observe
their clients observe inconsistencies
and explores the limitations
explores the limitations of
the limitations of its
limitations of its underlying
of its underlying techniques
there has been a
has been a wave
been a wave of
a wave of recent
wave of recent innovations
of recent innovations within
recent innovations within the
innovations within the backend
the experiments are designed
experiments are designed to
offering scalable object stores
are designed to help
scalable object stores that
designed to help us
object stores that can
to help us fully
stores that can efficiently
help us fully understand
that can efficiently support
us fully understand the
can efficiently support transactions
fully understand the fundamental
efficiently support transactions through
understand the fundamental properties
support transactions through snapshot
the fundamental properties of
transactions through snapshot isolation
fundamental properties of a
through snapshot isolation and
properties of a single
snapshot isolation and even
of a single partitioned
isolation and even full
a single partitioned replicated
and even full atomicity
single partitioned replicated service
partitioned replicated service and
replicated service and thus
service and thus gain
high bandwidth data dissemination
and thus gain a
bandwidth data dissemination using
thus gain a firm
data dissemination using an
gain a firm grasp
dissemination using an overlay
a firm grasp on
using an overlay mesh
firm grasp on the
grasp on the behavior
on the behavior of
the behavior of the
behavior of the ssa
of the ssa s
the ssa s building
ssa s building blocks
th acm symposium on
acm symposium on operating
symposium on operating systems
we defer for future
on operating systems principles
defer for future work
for future work the
future work the full
work the full scale
the full scale evaluation
full scale evaluation of
scale evaluation of multiple
evaluation of multiple services
of multiple services deployed
multiple services deployed and
services deployed and running
deployed and running at
and running at the
running at the same
at the same time
the ssa currently runs
ssa currently runs on
currently runs on a
runs on a tightly
on a tightly coupled
a tightly coupled cluster
our challenge is to
tightly coupled cluster of
challenge is to improve
coupled cluster of blade
is to improve transaction
cluster of blade servers
to improve transaction consistency
improve transaction consistency at
transaction consistency at the
consistency at the cache
at the cache layer
we show that developers
show that developers can
that developers can tune
even when the cache
developers can tune parameters
when the cache cannot
can tune parameters to
the cache cannot access
tune parameters to trade
cache cannot access the
parameters to trade overhead
cannot access the backend
to trade overhead for
access the backend on
trade overhead for speed
the backend on each
overhead for speed of
backend on each read
for speed of repair
speed of repair and
of repair and we
repair and we believe
and we believe that
we believe that our
believe that our results
that our results validate
our results validate the
results validate the approach
today s consistency solutions
s consistency solutions are
consistency solutions are limited
solutions are limited to
are limited to the
application model our work
limited to the database
model our work focuses
to the database backend
our work focuses on
work focuses on datacenters
focuses on datacenters supporting
even when the database
on datacenters supporting one
when the database itself
a comparative study of
the database itself is
comparative study of live
database itself is consistent
study of live p
datacenters supporting one or
supporting one or more
one or more services
or more services deployed
the vast majority of
more services deployed within
vast majority of operations
services deployed within a
majority of operations are
deployed within a cluster
of operations are read
within a cluster of
a cluster of compute
cluster of compute nodes
only transactions issued by
transactions issued by edge
issued by edge clients
by edge clients and
edge clients and are
th conference on computer
clients and are at
conference on computer communications
and are at high
are at high risk
tailer might implement a
at high risk of
might implement a front
high risk of observing
risk of observing inconsistent
of observing inconsistent state
observing inconsistent state in
inconsistent state in the
end service that builds
state in the cache
service that builds web
that builds web pages
the outright loss of
parallelizing the task by
outright loss of cache
the task by dispatching
loss of cache invalidations
task by dispatching sub
of cache invalidations emerges
cache invalidations emerges as
invalidations emerges as an
emerges as an especially
tasks to services to
as an especially significant
to services to rank
an especially significant problem
services to rank product
especially significant problem if
to rank product popularity
significant problem if transactional
problem if transactional consistency
if transactional consistency is
transactional consistency is required
an acceptable solution for
acceptable solution for a
solution for a consistent
for a consistent cache
a consistent cache must
consistent cache must maintain
cache must maintain the
must maintain the performance
maintain the performance properties
the performance properties of
performance properties of the
properties of the existing
of the existing caching
the existing caching tier
end service would probably
service would probably just
would probably just be
probably just be cloned
we need to maintain
need to maintain the
to maintain the shielding
with identical replicas that
maintain the shielding role
identical replicas that build
the shielding role of
replicas that build pages
shielding role of the
role of the cache
preventing dos attacks in
the cache hit ratio
dos attacks in peer
cache hit ratio should
end services might be
hit ratio should be
services might be partitioned
ratio should be high
might be partitioned into
be partitioned into subservices
partitioned into subservices for
into subservices for scalability
peer media streaming systems
subservices for scalability using
for scalability using some
scalability using some key
only cache access should
cache access should complete
access should complete with
should complete with a
complete with a single
with a single client
th annual multimedia computing
annual multimedia computing and
multimedia computing and networking
computing and networking conference
and subservices cloned for
subservices cloned for faulttolerance
cloned for faulttolerance and
for faulttolerance and load
trip on cache hits
this prohibits coherent cache
prohibits coherent cache solutions
this is a common
coherent cache solutions such
is a common model
cache solutions such as
jim gray and others
gray and others have
and others have suggested
others have suggested that
have suggested that such
suggested that such a
that such a system
such a system be
a system be termed
system be termed a
be termed a farm
termed a farm consisting
a farm consisting of
farm consisting of raps
a rchitecture since the
rchitecture since the cache
since the cache is
the cache is required
cache is required to
reliable array of partitioned
is required to respond
array of partitioned services
required to respond immediately
to respond immediately to
respond immediately to the
immediately to the client
to the client on
the client on hits
reliable array of cloned
array of cloned server
of cloned server processes
cache channel is asynchronous
we decided to employ
decided to employ a
to employ a transactional
employ a transactional consistency
a transactional consistency that
transactional consistency that is
consistency that is weaker
that is weaker than
is weaker than the
weaker than the full
than the full acid
the full acid model
up to the present
this structure has arisen
structure has arisen mostly
has arisen mostly in
arisen mostly in very
mostly in very large
only transactions and update
in very large datacenters
transactions and update transactions
very large datacenters and
and update transactions that
large datacenters and is
update transactions that access
datacenters and is supported
transactions that access the
and is supported primarily
that access the same
is supported primarily in
access the same cache
supported primarily in the
the same cache are
primarily in the context
same cache are guaranteed
in the context of
cache are guaranteed an
the context of three
are guaranteed an atomic
nd workshop on the
guaranteed an atomic execution
workshop on the economics
on the economics of
the economics of peer
only transactions that access
we believe that similar
transactions that access different
believe that similar architectures
that access different caches
that similar architectures will
access different caches may
similar architectures will be
different caches may observe
architectures will be needed
caches may observe different
will be needed more
may observe different orderings
be needed more widely
observe different orderings for
different orderings for independent
orderings for independent update
for independent update transactions
because the need to
the need to tolerate
need to tolerate heavy
to tolerate heavy loads
tolerate heavy loads is
heavy loads is increasingly
loads is increasingly ubiquitous
and economic considerations favor
economic considerations favor clustered
considerations favor clustered solutions
game servers require scalability
every partial execution that
servers require scalability for
partial execution that includes
require scalability for situations
execution that includes all
scalability for situations in
that includes all update
for situations in which
includes all update transactions
situations in which there
all update transactions in
in which there are
update transactions in and
which there are many
transactions in and all
there are many users
in and all read
military systems require scalability
only transactions that go
systems require scalability to
transactions that go through
require scalability to support
that go through a
scalability to support new
go through a single
to support new generations
through a single cache
support new generations of
improving robustness of peer
new generations of integrated
a single cache server
generations of integrated applications
hospital automation is putting
automation is putting new
peer streaming with incentives
is putting new demands
putting new demands on
our solution seeks to
new demands on medical
solution seeks to approximate
demands on medical information
seeks to approximate cache
on medical information subsystems
to approximate cache serializability
approximate cache serializability with
cache serializability with bounded
serializability with bounded caches
st workshop on the
with bounded caches and
workshop on the economics
bounded caches and asynchronous
on the economics of
in a wide range
the economics of networked
caches and asynchronous communication
a wide range of
and asynchronous communication with
wide range of everyday
economics of networked systems
range of everyday settings
asynchronous communication with the
communication with the db
the rollout of soas
our idea starts with
rollout of soas and
idea starts with an
of soas and the
starts with an observation
soas and the ease
and the ease of
the ease of application
ease of application integration
of application integration they
application integration they support
integration they support will
they support will place
objects form clusters with
support will place services
form clusters with strong
will place services under
clusters with strong locality
place services under growing
with strong locality properties
services under growing load
transactions are likely to
our goal is to
are likely to access
goal is to make
likely to access objects
is to make it
to access objects that
to make it easy
access objects that are
make it easy to
it easy to build
easy to build raps
to build raps and
build raps and racs
raps and racs from
and racs from traditional
close to each other
for retailers this might
retailers this might involve
this might involve related
might involve related products
web service applications designed
service applications designed for
for social networks the
applications designed for quick
social networks the set
designed for quick responsiveness
networks the set of
the set of friends
for geographical services physical
geographical services physical proximity
we also want to
also want to build
want to build the
and for web albums
to build the simplest
for web albums the
build the simplest platform
web albums the acl
the simplest platform capable
albums the acl objects
simplest platform capable of
the acl objects and
platform capable of accomplishing
acl objects and the
capable of accomplishing this
objects and the pictures
of accomplishing this task
and the pictures assigned
the pictures assigned to
pictures assigned to them
p live streaming system
in some cases applications
of the ninth ieee
a set of racs
the ninth ieee global
some cases applications explicitly
ninth ieee global internet
cases applications explicitly cluster
ieee global internet workshop
applications explicitly cluster their
explicitly cluster their data
cluster their data accesses
their data accesses to
data accesses to benefit
accesses to benefit from
to benefit from improved
benefit from improved parallelism
the resulting transactions access
resulting transactions access objects
transactions access objects from
access objects from a
objects from a single
from a single cluster
although there will also
there will also be
will also be some
also be some frequency
be some frequency of
some frequency of transactions
frequency of transactions that
of transactions that access
transactions that access unrelated
that access unrelated objects
access unrelated objects in
unrelated objects in different
objects in different clusters
our solution requires minor
solution requires minor changes
requires minor changes to
minor changes to the
changes to the database
to the database object
the database object representation
database object representation format
gossip traffic chain figure
imposing a small and
a small and constant
small and constant memory
and constant memory overhead
independent of the database
of the database size
the database size and
database size and the
size and the transaction
and the transaction rate
elements of the model
of the model a
the model a service
this overhead involves tracking
model a service is
overhead involves tracking and
a service is simply
involves tracking and caching
service is simply an
tracking and caching what
is simply an application
and caching what we
simply an application that
caching what we refer
an application that provides
what we refer to
application that provides interfaces
we refer to as
that provides interfaces that
refer to as dependency
provides interfaces that manipulate
to as dependency lists
interfaces that manipulate objects
that manipulate objects of
manipulate objects of unspecified
objects of unspecified nature
a query operation reads
query operation reads some
operation reads some object
length lists of object
reads some object and
lists of object identifiers
some object and returns
of object identifiers and
object and returns a
object identifiers and the
and returns a computed
identifiers and the associated
returns a computed value
and the associated version
the associated version numbers
an update operation modifies
update operation modifies one
each representing some recently
operation modifies one or
representing some recently updated
modifies one or more
some recently updated objects
one or more objects
recently updated objects upon
updated objects upon which
objects upon which the
upon which the cached
which the cached object
one unusual assumption made
the cached object depends
unusual assumption made in
assumption made in our
made in our work
in our work is
our work is that
work is that many
is that many services
that many services can
sized list can omit
many services can process
list can omit dependency
services can process updates
can omit dependency information
can process updates out
omit dependency information required
process updates out of
dependency information required to
updates out of order
information required to detect
required to detect inconsistencies
hence it is important
it is important to
is important to use
we focus on services
important to use a
focus on services that
to use a bound
on services that can
use a bound large
services that can respond
a bound large enough
that can respond correctly
bound large enough to
can respond correctly to
large enough to capture
respond correctly to queries
enough to capture most
correctly to queries even
to capture most of
to queries even if
capture most of the
queries even if some
most of the relevant
even if some updates
of the relevant dependencies
if some updates are
some updates are temporarily
updates are temporarily missing
at present we lack
present we lack an
we lack an automated
converge into a state
lack an automated way
into a state determined
an automated way to
a state determined entirely
automated way to do
state determined entirely by
way to do this
determined entirely by the
entirely by the set
by the set of
the set of updates
we require the developer
require the developer to
the developer to tune
so that if two
developer to tune the
that if two members
to tune the length
if two members of
tune the length so
two members of some
the length so that
members of some subservice
length so that the
of some subservice receive
so that the frequency
some subservice receive the
that the frequency of
subservice receive the same
the frequency of errors
receive the same updates
frequency of errors is
the same updates they
of errors is reduced
same updates they will
errors is reduced to
updates they will be
is reduced to an
they will be in
reduced to an acceptable
will be in equivalent
to an acceptable level
be in equivalent states
reasoning about the trade
even if those updates
if those updates were
those updates were delivered
updates were delivered in
were delivered in different
delivered in different orders
in a manner we
a manner we discuss
a reissued query or
manner we discuss further
reissued query or update
we discuss further below
query or update returns
or update returns an
update returns an equivalent
returns an equivalent result
what this amounts to
dependency lists should be
this amounts to is
lists should be roughly
amounts to is that
should be roughly the
to is that the
be roughly the same
is that the ssa
roughly the same size
that the ssa should
the same size as
the ssa should deliver
same size as the
ssa should deliver updates
size as the size
should deliver updates as
as the size of
deliver updates as soon
the size of the
updates as soon as
size of the workload
as soon as it
of the workload s
soon as it can
the workload s clusters
as it can even
it can even if
can even if they
even if they are
if they are not
they are not in
our extensions offer a
are not in order
extensions offer a transactional
offer a transactional interface
a transactional interface to
transactional interface to the
interface to the cache
to the cache in
the cache in addition
cache in addition to
in addition to the
one way that an
addition to the standard
way that an application
to the standard read
that an application might
an application might process
application might process out
might process out of
process out of order
out of order updates
of order updates is
order updates is simply
updates is simply to
is simply to delay
our algorithm detects and
simply to delay processing
algorithm detects and fixes
to delay processing them
detects and fixes inconsistent
delay processing them until
and fixes inconsistent read
processing them until it
them until it can
until it can sort
it can sort them
can sort them into
sort them into order
only transactions at the
transactions at the cache
at the cache with
the cache with constant
cache with constant complexity
but we believe that
we believe that for
believe that for many
that for many uses
it does so by
does so by either
so by either aborting
by either aborting the
either aborting the transaction
it will be possible
will be possible to
be possible to act
possible to act on
which can then be
to act on an
can then be retried
act on an update
on an update or
an update or query
update or query immediately
or query immediately upon
query immediately upon receiving
immediately upon receiving it
or invalidating a cached
invalidating a cached object
a cached object which
the ssa can support
cached object which can
ssa can support raps
object which can then
which can then force
can then force a
then force a read
force a read from
a read from the
read from the database
a raps of racs
similar to handling cache
to handling cache misses
a service that can
service that can be
that can be structured
can be structured as
be structured as a
when the dependency lists
structured as a raps
the dependency lists fail
as a raps must
dependency lists fail to
a raps must have
lists fail to document
raps must have a
fail to document a
must have a partitioning
to document a necessary
have a partitioning function
document a necessary dependency
a partitioning function that
partitioning function that can
function that can be
that can be used
an application might be
can be used to
application might be exposed
be used to map
might be exposed to
used to map each
be exposed to stale
to map each operation
exposed to stale values
map each operation to
each operation to the
operation to the subservice
to the subservice that
the subservice that should
because we have in
subservice that should execute
we have in mind
that should execute it
have in mind client
existing systems typically implement
side applications that are
systems typically implement partitioning
applications that are unlikely
typically implement partitioning functions
that are unlikely to
implement partitioning functions in
are unlikely to validate
partitioning functions in one
unlikely to validate against
functions in one of
to validate against the
in one of two
validate against the back
one of two ways
for many of our
the service exports its
many of our intended
service exports its partitioning
of our intended uses
exports its partitioning function
our intended uses some
intended uses some level
uses some level of
some level of undetected
level of undetected inconsistency
so that clients are
of undetected inconsistency can
that clients are able
undetected inconsistency can slip
clients are able to
inconsistency can slip past
are able to locally
able to locally implement
to locally implement the
locally implement the logic
implement the logic mapping
the logic mapping requests
logic mapping requests to
mapping requests to subservices
because the developer would
the developer would often
building collaboration applications that
developer would often be
collaboration applications that mix
would often be able
applications that mix web
often be able to
that mix web services
be able to tune
mix web services hosted
able to tune the
web services hosted content
to tune the mechanism
services hosted content with
the cluster might control
hosted content with p
cluster might control the
might control the dns
state operation of large
or could influence the
operation of large applications
could influence the creation
influence the creation of
the creation of web
creation of web pages
of web pages by
the rate of unnoticed
web pages by modifying
rate of unnoticed inconsistencies
pages by modifying urls
of unnoticed inconsistencies could
unnoticed inconsistencies could be
inconsistencies could be extremely
could be extremely low
so that clients will
that clients will be
clients will be directed
will be directed to
with clustered workloads we
be directed to an
clustered workloads we will
directed to an appropriate
workloads we will demonstrate
to an appropriate subservice
we will demonstrate that
will demonstrate that it
demonstrate that it is
krzysztof ostrowski cornell university
that it is sufficient
it is sufficient to
is sufficient to store
the servers might export
dept of computer science
servers might export actual
sufficient to store a
might export actual code
to store a small
export actual code that
store a small set
actual code that the
a small set of
code that the client
small set of dependencies
that the client runs
set of dependencies to
of dependencies to detect
dependencies to detect most
to detect most inconsistencies
we also investigate workloads
the partitioning logic is
also investigate workloads where
partitioning logic is situated
investigate workloads where the
logic is situated on
workloads where the clustered
is situated on a
where the clustered access
situated on a load
the clustered access pattern
on a load balancing
clustered access pattern is
a load balancing component
access pattern is less
load balancing component resident
pattern is less strongly
balancing component resident in
is less strongly evident
component resident in the
resident in the server
in the server cluster
the load balancer sprays
load balancer sprays requests
our approach is less
balancer sprays requests over
approach is less effective
sprays requests over the
is less effective even
requests over the subservices
less effective even with
over the subservices in
effective even with longer
the subservices in accordance
even with longer dependency
subservices in accordance with
with longer dependency list
in accordance with server
longer dependency list lengths
accordance with server logic
thus our solution is
our solution is not
solution is not a
is not a panacea
the ssa supports the
ssa supports the latter
supports the latter approach
offering a mechanism that
for applications matched to
a mechanism that assists
applications matched to our
mechanism that assists the
matched to our assumptions
that assists the load
can be highly effective
balancing component in tracking
component in tracking membership
in tracking membership so
tracking membership so that
membership so that it
so that it can
that it can appropriately
it can appropriately route
database we assume that
can appropriately route queries
we assume that the
edu abstract the most
assume that the database
appropriately route queries and
abstract the most commonly
route queries and updates
that the database tags
the most commonly deployed
the database tags each
most commonly deployed web
database tags each object
commonly deployed web service
tags each object with
deployed web service applications
each object with a
web service applications employ
object with a version
service applications employ client
we assume that processes
with a version number
assume that processes are
a version number specific
that processes are fail
version number specific to
number specific to the
specific to the transaction
to the transaction that
with clients running remotely
the transaction that most
clients running remotely and
transaction that most recently
running remotely and services
that most recently updated
remotely and services hosted
most recently updated it
and services hosted in
should a failure occur
services hosted in data
hosted in data centers
and that there is
that there is a
and will eventually be
there is a total
will eventually be detected
is a total ordering
eventually be detected as
a total ordering on
be detected as faulty
we make the case
total ordering on version
make the case for
ordering on version numbers
the case for service
a failure may be
the version of a
failure may be transient
version of a transaction
of a transaction is
a transaction is chosen
a process can become
transaction is chosen to
applications that combine service
is chosen to be
process can become temporarily
chosen to be larger
can become temporarily unavailable
to be larger than
be larger than the
hosted data with collaboration
larger than the versions
data with collaboration features
than the versions of
with collaboration features implemented
the versions of all
collaboration features implemented using
but then restart and
versions of all objects
then restart and recover
of all objects accessed
restart and recover any
features implemented using peerto
all objects accessed by
and recover any missing
objects accessed by the
recover any missing updates
accessed by the transaction
collaboration features are awkward
the database stores for
features are awkward to
database stores for each
are awkward to support
stores for each object
awkward to support solely
for each object o
to support solely based
each object o a
support solely based on
object o a list
solely based on the
o a list of
based on the existing
a list of k
on the existing web
discussion our model is
the existing web services
our model is not
list of k dependencies
model is not completely
existing web services technologies
is not completely general
indirection through the data
and for this reason
through the data center
for this reason some
the data center introduces
this reason some discussion
data center introduces high
reason some discussion is
center introduces high latencies
some discussion is needed
introduces high latencies and
high latencies and limits
latencies and limits scalability
consider the following example
and precludes collaboration between
precludes collaboration between clients
collaboration between clients connected
we wish to support
between clients connected to
wish to support a
clients connected to one
to support a scalable
support a scalable inventory
a scalable inventory service
scalable inventory service that
another but lacking connectivity
inventory service that receives
but lacking connectivity to
service that receives updates
lacking connectivity to the
that receives updates corresponding
connectivity to the data
receives updates corresponding to
to the data center
updates corresponding to inventory
corresponding to inventory consumption
to inventory consumption and
inventory consumption and re
cornell s live distributed
s live distributed objects
live distributed objects platform
distributed objects platform combines
objects platform combines web
platform combines web services
combines web services with
web services with direct
queries against such a
services with direct peerto
against such a service
such a service would
a service would compute
service would compute and
peer communication to eliminate
would compute and return
communication to eliminate these
compute and return an
to eliminate these issues
and return an inventory
return an inventory count
an inventory count as
inventory count as of
count as of the
as of the time
of the time the
the time the query
time the query was
this is a list
the query was processed
is a list of
introduction there is a
a list of identifiers
there is a growing
list of identifiers and
is a growing opportunity
but inventory can change
a growing opportunity to
inventory can change in
of identifiers and versions
growing opportunity to use
identifiers and versions of
can change in real
and versions of other
opportunity to use service
versions of other objects
of other objects that
other objects that the
objects that the current
that the current version
the current version of
current version of o
version of o depends
of o depends on
reissued a moment later
applications in ways that
in ways that can
ways that can slash
that can slash health
might yield a different
yield a different result
only transaction that sees
a different result and
transaction that sees the
different result and yet
that sees the current
result and yet both
sees the current version
and yet both would
the current version of
yet both would be
current version of o
both would be correct
version of o must
permit more effective search
of o must not
more effective search and
o must not see
effective search and rescue
must not see object
search and rescue after
not see object di
and rescue after a
see object di with
rescue after a disaster
responses reflecting a reasonably
object di with version
reflecting a reasonably current
di with version smaller
a reasonably current server
with version smaller than
reasonably current server state
enable a more nimble
current server state are
a more nimble information
server state are acceptable
version smaller than vi
on the other hand
when a transaction t
a transaction t with
or make possible a
transaction t with version
make possible a world
a response reflecting a
possible a world of
response reflecting a very
a world of professional
reflecting a very stale
world of professional dialog
a very stale state
t with version vt
very stale state would
of professional dialog and
with version vt touches
professional dialog and collaboration
version vt touches objects
dialog and collaboration without
stale state would be
vt touches objects o
and collaboration without travel
state would be incorrect
soc applications will need
a client should not
applications will need to
client should not be
will need to combine
should not be offered
need to combine two
not be offered a
it updates both their
be offered a promotional
updates both their versions
to combine two types
both their versions and
offered a promotional price
their versions and their
combine two types of
versions and their dependency
two types of content
and their dependency lists
a promotional price on
promotional price on a
price on a plasma
on a plasma tv
traditional web service hosted
subsequent accesses to object
web service hosted content
accesses to object o
a plasma tv if
plasma tv if the
tv if the last
if the last unit
such as data from
the last unit was
as data from databases
last unit was actually
must see object o
unit was actually sold
was actually sold hours
actually sold hours ago
with a version not
a version not smaller
version not smaller than
not smaller than vt
and weather prediction systems
the inventory service should
inventory service should reflect
service should reflect as
should reflect as many
with a variety of
it inherits all of
a variety of collaboration
inherits all of the
variety of collaboration features
all of the l
reflect as many updates
of the l dependencies
as many updates as
the l dependencies of
many updates as possible
l dependencies of o
updates as possible in
such as chat windows
as possible in the
possible in the replies
in the replies it
the replies it gives
replies it gives to
it gives to requests
where l is the
l is the length
is the length of
the length of o
but any reply is
peer video and other
any reply is correct
video and other media
reply is correct provided
and other media streams
is correct provided that
correct provided that it
provided that it was
that it was based
it was based on
was based on a
based on a recent
so the dependency list
on a recent state
the dependency list of
dependency list of o
existing web service technologies
web service technologies make
service technologies make it
technologies make it easy
we shall see that
make it easy to
it easy to build
shall see that the
easy to build applications
see that the ssa
to build applications in
that the ssa allows
build applications in which
the ssa allows brief
applications in which all
ssa allows brief inconsistencies
in which all data
allows brief inconsistencies but
which all data travels
brief inconsistencies but that
all data travels through
inconsistencies but that they
data travels through a
but that they can
travels through a data
that they can be
through a data center
they can be limited
can be limited to
be limited to a
limited to a few
to a few seconds
implementing collaboration features using
collaboration features using these
features using these technologies
operations against the inventory
using these technologies is
against the inventory service
these technologies is problematic
the inventory service happen
technologies is problematic because
inventory service happen to
is problematic because collaborative
service happen to be
problematic because collaborative applications
happen to be commutative
because collaborative applications can
collaborative applications can generate
applications can generate high
hence the service can
the service can process
service can process updates
bursty update rates and
can process updates out
update rates and yet
process updates out of
rates and yet often
updates out of order
and yet often require
yet often require low
often require low latencies
require low latencies and
but many kinds of
low latencies and tight
many kinds of services
latencies and tight synchronization
kinds of services can
and tight synchronization between
of services can handle
tight synchronization between collaborating
services can handle out
synchronization between collaborating users
can handle out of
handle out of order
out of order updates
one can often achieve
can often achieve better
if for no other
often achieve better performance
for no other reason
achieve better performance using
no other reason than
better performance using direct
other reason than that
performance using direct client
reason than that in
than that in many
that in many settings
each update is uniquely
update is uniquely sequenced
is uniquely sequenced by
uniquely sequenced by its
sequenced by its source
permitting the service to
the service to sort
service to sort updates
to sort updates and
sort updates and to
updates and to process
and to process queries
to process queries against
process queries against the
queries against the sorted
against the sorted database
but in today s
in today s soa
our group has held
today s soa plat
group has held discussions
has held discussions with
held discussions with operators
discussions with operators of
with operators of several
operators of several large
of several large datacenters
and concluded that many
band communication is hard
concluded that many services
communication is hard to
that many services have
is hard to integrate
many services have the
hard to integrate with
services have the kinds
to integrate with hosted
have the kinds of
integrate with hosted content
the kinds of properties
kinds of properties just
of properties just cited
this problem is reflected
problem is reflected by
ability to respond based
is reflected by a
to respond based on
reflected by a growing
respond based on a
by a growing number
based on a reasonable
a growing number of
on a reasonable current
growing number of publications
a reasonable current state
number of publications on
of publications on the
publications on the integration
on the integration of
and to handle out
the integration of web
integration of web services
of web services with
web services with peer
the ssa is a
ssa is a good
is a good match
a good match for
good match for personalization
match for personalization services
when a transaction is
a transaction is committed
this update is done
update is done for
is done for all
done for all objects
for all objects in
all objects in the
objects in the transaction
in the transaction at
the transaction at once
given a read set
a read set readset
and a write set
a write set writeset
these deal primarily with
deal primarily with weakly
containing tuples comprised of
primarily with weakly consistent
tuples comprised of the
with weakly consistent data
comprised of the keys
of the keys accessed
their versions and their
versions and their dependency
and their dependency lists
and all sorts of
the database aggregates them
all sorts of services
database aggregates them to
sorts of services in
aggregates them to a
of services in which
them to a single
services in which replies
to a single full
in which replies are
a single full dependency
which replies are intrinsically
single full dependency list
replies are intrinsically noisy
full dependency list as
dependency list as follows
such as services that
as services that report
services that report data
that report data gathered
report data gathered from
data gathered from remote
gathered from remote sensors
a datacenter would also
datacenter would also host
would also host some
also host some kinds
host some kinds of
some kinds of services
kinds of services ill
matched to our model
but because we are
because we are working
we are working with
are working with web
working with web services
services running on the
running on the ssa
on the ssa can
the ssa can easily
ssa can easily interact
can easily interact with
easily interact with services
readset writeset this list
interact with services that
writeset this list is
with services that employ
this list is pruned
services that employ other
list is pruned to
that employ other solutions
is pruned to match
pruned to match the
to match the target
match the target size
the target size using
target size using lru
and stored with each
stored with each write
consistency semantics the ssa
semantics the ssa implements
the ssa implements stochastic
ssa implements stochastic consistency
a list entry can
implements stochastic consistency semantics
list entry can be
entry can be discarded
can be discarded if
yet the issue remains
be discarded if the
the issue remains unresolved
an application will only
discarded if the same
application will only observe
if the same entry
will only observe an
the same entry s
only observe an inconsistency
same entry s object
observe an inconsistency if
entry s object appears
an inconsistency if a
s object appears in
inconsistency if a fault
object appears in another
if a fault occurs
appears in another entry
in another entry with
another entry with a
entry with a larger
with a larger version
and even then only
cornell s live distributed
even then only for
s live distributed objects
then only for a
live distributed objects platform
only for a period
for a period of
a period of time
period of time associated
were their lengths not
of time associated with
their lengths not bounded
time associated with our
associated with our repair
with our repair protocol
dependency lists could quickly
lists could quickly grow
could quickly grow to
and only if it
quickly grow to include
only if it has
grow to include all
if it has the
to include all objects
it has the bad
include all objects in
has the bad luck
live objects for short
the bad luck to
all objects in the
bad luck to query
objects in the database
luck to query a
to query a node
allow even a non
query a node impacted
a node impacted by
node impacted by the
impacted by the failure
programmer to construct content
cache in our scheme
this window can be
window can be made
rich solutions that blend
can be made small
the cache interacts with
solutions that blend traditional
cache interacts with the
that blend traditional web
interacts with the database
blend traditional web services
with the database in
traditional web services and
so that applications are
web services and peer
the database in essentially
that applications are unlikely
database in essentially the
applications are unlikely to
in essentially the same
are unlikely to observe
essentially the same manner
unlikely to observe a
the same manner as
to observe a problem
same manner as for
manner as for a
as for a consistency
or permitted to grow
and to share them
permitted to grow somewhat
to share them with
to grow somewhat larger
share them with others
depending upon the cost
this is like creating
upon the cost of
is like creating a
the cost of inconsistency
like creating a slide
cost of inconsistency and
creating a slide show
of inconsistency and the
inconsistency and the relative
and the relative value
and receiving invalidations as
receiving invalidations as the
invalidations as the database
as the database updates
the database updates objects
after which the solution
which the solution can
of faster response time
the solution can be
faster response time versus
solution can be shared
response time versus lower
can be shared in
time versus lower risk
be shared in a
versus lower risk of
shared in a file
lower risk of an
in a file or
the caches read from
a file or via
risk of an observed
file or via email
of an observed fault
or via email and
caches read from the
via email and opened
read from the database
email and opened on
from the database not
and opened on other
in the experimental work
opened on other machines
the database not only
the experimental work that
database not only the
experimental work that follows
not only the object
only the object s
the object s value
the users are immersed
users are immersed in
are immersed in the
we measure these windows
immersed in the resulting
measure these windows for
in the resulting collaborative
these windows for scenarios
the resulting collaborative application
but also its version
windows for scenarios representative
also its version and
for scenarios representative of
its version and the
scenarios representative of conditions
version and the dependency
representative of conditions that
and the dependency list
of conditions that arise
they can interact with
conditions that arise in
can interact with the
that arise in realistic
interact with the application
arise in realistic settings
with the application and
the application and peers
application and peers see
and peers see the
the extended cache exports
peers see the results
extended cache exports a
see the results instantly
cache exports a transactional
exports a transactional read
the ssa framework the
ssa framework the basic
framework the basic operation
updates are applied to
the basic operation of
are applied to all
basic operation of the
applied to all replicas
operation of the ssa
to all replicas in
client read requests are
of the ssa is
all replicas in a
read requests are extended
the ssa is as
requests are extended with
ssa is as follows
replicas in a consistent
are extended with a
in a consistent manner
extended with a transaction
with a transaction identifier
a transaction identifier and
as queries or updates
transaction identifier and a
queries or updates are
identifier and a last
or updates are received
updates are received in
are received in the
in contrast to today
received in the cluster
contrast to today s
to today s web
today s web service
s web service platforms
they are passed through
are passed through a
passed through a partition
through a partition mapping
a partition mapping component
p communication can coexist
which directs the request
communication can coexist with
directs the request to
can coexist with more
the request to an
coexist with more standard
request to an appropriate
the transaction identifier txnid
to an appropriate racs
with more standard solutions
transaction identifier txnid allows
more standard solutions that
identifier txnid allows the
standard solutions that reach
txnid allows the cache
solutions that reach back
allows the cache to
we will use the
the cache to recognize
that reach back to
cache to recognize reads
will use the term
to recognize reads belonging
reach back to the
recognize reads belonging to
use the term subservice
reads belonging to the
back to the hosted
belonging to the same
the term subservice rather
to the hosted content
term subservice rather than
the hosted content and
subservice rather than racs
to the same transaction
rather than racs in
hosted content and trigger
than racs in the
content and trigger updates
racs in the remainder
and trigger updates at
in the remainder of
trigger updates at the
the cache responds with
updates at the associated
the remainder of the
at the associated data
remainder of the paper
the associated data centers
cache responds with either
responds with either the
with either the value
either the value of
the value of the
to create a subservice
value of the requested
create a subservice the
of the requested object
a subservice the developer
subservice the developer must
when an application needs
the developer must first
an application needs high
developer must first implement
application needs high data
or with an abort
must first implement a
needs high data rates
with an abort if
first implement a non
an abort if it
abort if it detects
if it detects an
it detects an inconsistency
detects an inconsistency between
an inconsistency between this
inconsistency between this read
between this read and
this read and any
it can use protocols
read and any of
this is then cloned
and any of the
can use protocols that
any of the previous
is then cloned using
of the previous reads
then cloned using the
the previous reads with
cloned using the ssa
use protocols that bypass
previous reads with the
protocols that bypass the
reads with the same
using the ssa platform
that bypass the data
with the same transaction
bypass the data center
the same transaction id
the data center to
data center to achieve
each replica is placed
center to achieve the
replica is placed on
to achieve the full
is placed on a
achieve the full performance
placed on a separate
we do not guarantee
the full performance of
do not guarantee that
on a separate node
not guarantee that inconsistencies
full performance of the
guarantee that inconsistencies will
performance of the network
that inconsistencies will be
inconsistencies will be detected
and the replicas are
the replicas are then
replicas are then linked
this paper makes the
are then linked using
paper makes the following
then linked using tcp
the lastop allows the
linked using tcp to
lastop allows the cache
using tcp to create
allows the cache to
makes the following contributions
tcp to create a
the cache to garbage
to create a chain
we describe a new
describe a new class
collect its transaction record
a new class of
its transaction record after
new class of service
transaction record after responding
record after responding to
after responding to the
responding to the last
to the last read
the last read operation
last read operation of
read operation of the
we therefore have a
operation of the transaction
applications that integrate service
that integrate service hosted
integrate service hosted content
the cache will treat
service hosted content with
cache will treat subsequent
hosted content with peer
will treat subsequent accesses
mapping between a subservice
treat subsequent accesses with
between a subservice and
subsequent accesses with the
a subservice and a
accesses with the same
subservice and a chain
with the same transaction
the same transaction id
same transaction id as
transaction id as new
id as new transactions
we analyze two important
analyze two important examples
two important examples of
to implement this interface
important examples of soc
examples of soc applications
the cache maintains a
gossip based chain replication
cache maintains a record
search and rescue mission
maintains a record of
and rescue mission and
a record of each
rescue mission and virtual
record of each transaction
mission and virtual worlds
based chain replication the
of each transaction with
chain replication the replication
each transaction with its
replication the replication scheme
transaction with its read
the replication scheme has
with its read values
replication scheme has evolved
scheme has evolved out
has evolved out of
evolved out of the
out of the chain
we list the key
of the chain replication
list the key challenges
the chain replication mechanism
the key challenges that
and their dependency lists
key challenges that soc
chain replication mechanism first
challenges that soc applications
replication mechanism first introduced
that soc applications place
mechanism first introduced in
soc applications place on
on a read of
applications place on their
a read of keycurr
place on their runtime
on their runtime environments
the cache first obtains
we describe a new
cache first obtains the
describe a new class
first obtains the requested
a new class of
obtains the requested entry
new class of multi
the requested entry from
requested entry from memory
layered mashups and contrast
mashups and contrast them
and contrast them with
the original scheme was
contrast them with more
them with more traditional
original scheme was developed
scheme was developed as
was developed as a
developed as a means
as a means of
a means of obtaining
based approach to building
means of obtaining high
approach to building mashups
of obtaining high throughput
obtaining high throughput and
high throughput and availability
the entry includes the
throughput and availability for
characteristic of today s
and availability for query
of today s web
entry includes the value
availability for query and
today s web development
for query and update
query and update requests
and update requests without
version vercurr and dependency
update requests without sacrificing
vercurr and dependency list
requests without sacrificing strong
and dependency list deplistcurr
we discuss the relative
without sacrificing strong consistency
discuss the relative advantages
sacrificing strong consistency guarantees
the relative advantages of
relative advantages of these
the cache checks the
advantages of these two
cache checks the currently
of these two approaches
checks the currently read
these two approaches for
the currently read object
two approaches for building
currently read object against
approaches for building soc
read object against each
for building soc applications
the gossip based chain
object against each of
gossip based chain replication
against each of the
based chain replication behaves
each of the previously
we discuss the advantages
of the previously read
chain replication behaves in
the previously read objects
discuss the advantages of
replication behaves in the
the advantages of decoupling
behaves in the following
advantages of decoupling transport
in the following manner
of decoupling transport and
the following manner during
if a previously read
decoupling transport and information
following manner during normal
transport and information layers
a previously read version
and information layers as
manner during normal operation
information layers as a
previously read version v
during normal operation when
layers as a means
normal operation when nodes
as a means of
read version v is
a means of achieving
operation when nodes aren
means of achieving reusability
when nodes aren t
version v is older
nodes aren t failing
v is older than
aren t failing or
is older than expected
t failing or restarting
older than expected by
than expected by the
expected by the current
by the current read
ability to rapidly deploy
update operations are forwarded
the current read s
operations are forwarded to
to rapidly deploy soc
are forwarded to the
current read s dependencies
forwarded to the head
read s dependencies v
to the head of
rapidly deploy soc applications
s dependencies v k
the head of the
deploy soc applications in
head of the chain
soc applications in new
applications in new environments
in new environments and
new environments and adapt
where the request is
environments and adapt them
the request is processed
and adapt them dynamically
request is processed using
adapt them dynamically this
is processed using the
them dynamically this work
processed using the local
dynamically this work was
using the local replica
this work was supported
the state changes are
state changes are passed
changes are passed along
are passed along down
passed along down the
along down the chain
down the chain to
the chain to the
chain to the next
to the next element
which in turn updates
qi huang is a
in turn updates it
huang is a visiting
turn updates it s
is a visiting scientist
updates it s state
a visiting scientist from
it s state and
visiting scientist from the
s state and performs
scientist from the school
state and performs the
from the school of
and performs the same
the school of computer
performs the same operation
school of computer sci
the same operation until
same operation until the
operation until the tail
until the tail is
the tail is reached
or the current read
huazhong university of sci
the current read vcurr
queries can either be
current read vcurr is
can either be directed
read vcurr is older
either be directed towards
vcurr is older than
be directed towards a
is older than expected
directed towards a randomly
older than expected by
towards a randomly selected
than expected by the
supported by the chinese
expected by the dependencies
by the chinese nsfc
by the dependencies of
a randomly selected process
the dependencies of a
randomly selected process in
dependencies of a previous
selected process in the
of a previous read
process in the group
a previous read v
in the group or
previous read v v
the group or to
group or to a
or to a specific
to a specific one
the strongest consistency guarantee
strongest consistency guarantee is
consistency guarantee is acheived
guarantee is acheived if
is acheived if all
acheived if all query
if all query operations
all query operations are
query operations are targeted
operations are targeted at
are targeted at the
targeted at the tail
at the tail of
the tail of the
tail of the chain
of the chain node
which is the case
is the case for
the case for the
an inconsistency is detected
case for the vanilla
for the vanilla chain
the vanilla chain replication
vanilla chain replication scheme
otherwise the cache returns
the cache returns the
cache returns the read
returns the read value
however this eliminates the
the read value to
this eliminates the opportunity
read value to the
eliminates the opportunity to
value to the client
the opportunity to load
upon detecting an inconsistency
faults and node restarts
the cache can take
and node restarts can
cache can take one
node restarts can disrupt
can take one of
restarts can disrupt the
take one of three
can disrupt the primary
layered mashup to the
disrupt the primary communication
mashup to the changing
one of three paths
to the changing needs
the primary communication pattern
primary communication pattern of
communication pattern of the
pattern of the ssa
we discuss the resulting
discuss the resulting objectoriented
the resulting objectoriented perspective
if the head of
the head of a
head of a chain
of a chain fails
in which instances of
which instances of distributed
abort the current transaction
update sources will need
instances of distributed communication
sources will need to
of distributed communication protocols
will need to discover
distributed communication protocols are
need to discover a
communication protocols are modeled
compared to the other
protocols are modeled uniformly
to discover a new
are modeled uniformly as
discover a new head
modeled uniformly as objects
to the other approaches
uniformly as objects similar
as objects similar to
objects similar to those
similar to those in
if an inner node
to those in java
this has the benefit
an inner node crashes
has the benefit of
inner node crashes the
the benefit of affecting
node crashes the chain
benefit of affecting only
crashes the chain may
of affecting only the
the chain may break
affecting only the running
only the running transaction
the running transaction and
and if the tail
running transaction and limiting
if the tail crashes
transaction and limiting collateral
and limiting collateral damage
the embedded script is
embedded script is often
script is often tightly
acks might not be
is often tightly integrated
might not be sent
often tightly integrated with
not be sent back
tightly integrated with backend
integrated with backend services
with backend services in
backend services in the
services in the data
in the data center
abort the current transaction
the current transaction and
making it awkward to
current transaction and evict
it awkward to access
or some of its
awkward to access the
transaction and evict the
to access the underlying
and evict the violating
some of its members
access the underlying services
the underlying services directly
underlying services directly from
services directly from a
directly from a different
from a different script
a different script or
different script or a
processes will miss updates
script or a standalone
will miss updates and
or a standalone client
miss updates and hence
object from the cache
updates and hence queries
and hence queries will
hence queries will return
queries will return outdated
will return outdated results
this approach guesses that
approach guesses that future
guesses that future transactions
that future transactions are
to repair these inconsistencies
future transactions are likely
transactions are likely to
the only way such
are likely to abort
only way such services
the ssa implements a
likely to abort because
ssa implements a secondary
to abort because of
implements a secondary update
abort because of this
way such services can
a secondary update propagation
because of this object
secondary update propagation mechanism
such services can be
services can be mashed
can be mashed up
be mashed up with
it uses gossip protocols
mashed up with other
uses gossip protocols to
up with other web
gossip protocols to rapidly
with other web content
protocols to rapidly detect
other web content is
to rapidly detect and
web content is by
rapidly detect and repair
content is by either
detect and repair inconsistencies
is by either having
by either having the
check which is the
either having the data
which is the violating
having the data center
is the violating object
the data center compute
while simultaneously orchestrating repair
data center compute the
simultaneously orchestrating repair of
center compute the mashup
if it is the
orchestrating repair of the
it is the currently
repair of the chain
is the currently accessed
the currently accessed object
so that it can
that it can be
the gossip rate can
it can be accessed
gossip rate can be
can be accessed via
rate can be tuned
be accessed via the
accessed via the minibrowser
with a higher rate
a higher rate overheads
higher rate overheads rise
rate overheads rise but
overheads rise but repair
treat this access as
or by embedding the
rise but repair occurs
this access as a
but repair occurs more
by embedding the entire
repair occurs more rapidly
embedding the entire minibrowser
access as a miss
the entire minibrowser window
as a miss and
entire minibrowser window in
a miss and respond
minibrowser window in a
miss and respond to
window in a web
and respond to it
repair is slower but
in a web page
is slower but overheads
respond to it with
slower but overheads drop
to it with a
it with a value
with a value read
but an embedded minibrowser
a value read from
an embedded minibrowser can
value read from the
embedded minibrowser can t
read from the database
the subsections that follow
minibrowser can t seamlessly
subsections that follow discuss
can t seamlessly blend
that follow discuss the
t seamlessly blend with
follow discuss the two
seamlessly blend with the
discuss the two core
blend with the surrounding
the two core mechanisms
with the surrounding content
two core mechanisms in
if the violating object
core mechanisms in greater
the violating object was
mechanisms in greater detail
violating object was returned
it is like a
object was returned to
is like a standalone
was returned to the
like a standalone browser
returned to the user
a standalone browser within
a second class of
standalone browser within its
to the user as
browser within its own
second class of faults
the user as the
within its own frame
user as the result
class of faults are
as the result of
of faults are transient
the result of a
faults are transient and
result of a read
and runs independent of
of a read earlier
are transient and relate
a read earlier in
runs independent of the
read earlier in the
transient and relate to
earlier in the transaction
independent of the rest
and relate to the
of the rest of
relate to the behavior
the rest of the
to the behavior of
rest of the page
the behavior of tcp
behavior of tcp when
of tcp when a
tcp when a node
when a node is
to illustrate this point
a node is subjected
node is subjected to
is subjected to stress
evict the stale object
the stale object and
stale object and abort
such as a burst
object and abort the
as a burst of
and abort the transaction
a burst of traffic
the figures are screenshots
figures are screenshots of
are screenshots of web
consistency with unbounded resources
screenshots of web applications
the os tends to
os tends to lose
tends to lose packets
to lose packets and
with content from multiple
lose packets and the
content from multiple sources
packets and the effect
cache detects all inconsistencies
from multiple sources mashed
and the effect is
the effect is that
effect is that tcp
as stated in the
is that tcp will
stated in the following
that tcp will impose
in the following theorem
tcp will impose congestion
will impose congestion control
impose congestion control mechanisms
congestion control mechanisms and
control mechanisms and choke
mechanisms and choke back
was constructed using a
constructed using a standard
using a standard web
a standard web services
standard web services approach
updates will cease to
pulling content from the
will cease to propagate
content from the yahoo
cache with unbounded cache
cease to propagate down
with unbounded cache size
to propagate down the
unbounded cache size and
propagate down the chain
cache size and unbounded
maps and weather web
size and unbounded dependency
and weather web services
and unbounded dependency lists
weather web services and
unbounded dependency lists implements
even though most of
dependency lists implements cache
web services and assembling
though most of the
services and assembling it
most of the nodes
and assembling it into
of the nodes involved
assembling it into a
the nodes involved could
it into a web
nodes involved could still
into a web page
involved could still have
a web page as
could still have ample
web page as a
still have ample capacity
page as a set
as a set of
deferred to appendix a
a set of tiled
set of tiled frames
is by constructing a
we will show that
by constructing a serialization
will show that when
constructing a serialization of
each frame is a
a serialization of the
frame is a minibrowser
show that when such
is a minibrowser with
that when such a
a minibrowser with its
when such a problem
minibrowser with its own
such a problem arises
with its own interactive
serialization of the transactions
its own interactive controls
of the transactions in
the transactions in the
gossip will route data
transactions in the database
will route data around
in the database and
route data around the
and comes from a
the database and in
data around the congested
comes from a single
database and in one
around the congested nodes
from a single content
and in one cache
a single content source
and will also deliver
will also deliver missed
based on the fact
to illustrate one of
on the fact that
illustrate one of the
the fact that the
one of the many
also deliver missed updates
fact that the transactions
of the many restrictions
that the transactions in
deliver missed updates to
the transactions in the
missed updates to the
transactions in the database
updates to the overloaded
in the database are
to the overloaded nodes
the database are serializable
if the user pans
database are serializable by
the overloaded nodes when
the user pans or
overloaded nodes when the
are serializable by definition
nodes when the problem
user pans or zooms
when the problem ends
pans or zooms in
or zooms in the
zooms in the map
in the map frame
the implications of theorem
in the original chain
the original chain replication
original chain replication scheme
will be seen in
chain replication scheme the
be seen in section
the associated map will
replication scheme the queries
associated map will shift
scheme the queries are
seen in section v
the queries are directed
map will shift or
queries are directed to
will shift or zoom
are directed to the
directed to the tail
to the tail of
the tail of the
tail of the chain
but the other frames
the other frames remain
other frames remain as
frames remain as they
since there is no
remain as they were
there is no additional
as they were the
is no additional epidemic
they were the frames
no additional epidemic communication
cache converges to perfect
were the frames are
converges to perfect detection
the frames are not
to perfect detection when
frames are not synchronized
perfect detection when stable
any update known to
detection when stable clusters
update known to the
when stable clusters are
known to the tail
stable clusters are as
to the tail is
clusters are as large
the tail is stable
are as large as
tail is stable because
as large as its
is stable because it
large as its dependency
stable because it must
here we see a
as its dependency lists
we see a similar
because it must first
see a similar application
it must first have
a similar application constructed
must first have been
in such a scenario
first have been seen
similar application constructed using
have been seen by
application constructed using live
been seen by all
constructed using live objects
seen by all the
the dependency lists are
by all the members
dependency lists are large
all the members of
lists are large enough
the members of the
are large enough to
members of the chain
large enough to describe
enough to describe all
to describe all relevant
content from different sources
describe all relevant dependencies
from different sources is
to maintain such an
different sources is overlaid
maintain such an invariant
sources is overlaid in
is overlaid in the
overlaid in the same
in the same window
the same window and
the original paper includes
same window and synchronized
e xperimental s etup
original paper includes mechanisms
xperimental s etup to
paper includes mechanisms to
s etup to evaluate
includes mechanisms to ensure
etup to evaluate the
mechanisms to ensure that
to evaluate the effectiveness
to ensure that a
we used white backgrounds
ensure that a request
evaluate the effectiveness of
that a request really
the effectiveness of our
a request really reaches
effectiveness of our scheme
request really reaches the
used white backgrounds to
really reaches the head
white backgrounds to highlight
reaches the head of
backgrounds to highlight the
the head of the
we implemented a prototype
head of the chain
to highlight the contributions
highlight the contributions of
the contributions of different
contributions of different sources
to study the properties
study the properties of
that updates are passed
the properties of the
updates are passed down
properties of the cache
but there are no
are passed down the
there are no frame
passed down the chain
are no frame boundaries
down the chain and
we only need a
the chain and applied
only need a single
chain and applied in
need a single column
elements of this mashup
and applied in a
applied in a strictly
in a strictly fifo
a strictly fifo manner
which can include map
strictly fifo manner even
can include map layers
fifo manner even when
manner even when nodes
even when nodes fail
when nodes fail and
namely a single cache
tables showing buildings or
a single cache backed
showing buildings or points
single cache backed by
buildings or points of
nodes fail and the
cache backed by a
or points of interest
backed by a single
fail and the chain
by a single database
and the chain is
a single database server
the chain is restructured
icons representing severe weather
representing severe weather reports
and that queries are
that queries are sent
queries are sent to
illustrates the structure of
are sent to the
the structure of our
sent to the tail
structure of our experimental
to the tail of
of our experimental setup
the tail of the
tail of the chain
a single database implements
single database implements a
strong consistency follows easily
database implements a transactional
consistency follows easily because
implements a transactional key
exist layers within which
follows easily because query
layers within which the
easily because query requests
within which the end
because query requests and
which the end user
query requests and update
the end user can
requests and update requests
end user can easily
and update requests are
user can easily navigate
update requests are processed
requests are processed serially
are processed serially at
processed serially at the
serially at the tail
data can come from
at the tail element
can come from many
come from many kinds
update clients access database
from many kinds of
the gossip based chain
many kinds of we
gossip based chain replication
kinds of we discuss
based chain replication weakens
which sends invalidations to
chain replication weakens the
sends invalidations to the
replication weakens the model
invalidations to the cache
weakens the model in
of we discuss our
the model in two
we discuss our live
model in two key
discuss our live distributed
in two key respects
our live distributed objects
live distributed objects platform
only clients access cache
distributed objects platform as
objects platform as an
platform as an example
as an example of
an example of a
our solution might sometimes
example of a technology
solution might sometimes use
of a technology that
might sometimes use the
a technology that fits
sometimes use the wrong
technology that fits well
use the wrong head
that fits well with
the wrong head of
fits well with the
wrong head of the
well with the layered
head of the chain
receives all transactions and
all transactions and rigorously
transactions and rigorously detects
and rigorously detects inconsistencies
componentized model we derived
rigorously detects inconsistencies for
model we derived through
for example if an
detects inconsistencies for statistics
example if an update
we derived through our
if an update source
derived through our analysis
an update source is
update source is operating
source is operating with
is operating with inaccurate
we compare performance of
operating with inaccurate membership
compare performance of hosted
with inaccurate membership information
performance of hosted enterprise
of hosted enterprise service
a set of cache
hosted enterprise service bus
set of cache clients
of cache clients perform
cache clients perform readonly
clients perform readonly transactions
perform readonly transactions through
updates might sometimes arrive
readonly transactions through a
might sometimes arrive out
transactions through a single
sometimes arrive out of
through a single cache
arrive out of order
a single cache server
for example if the
the cache serves the
example if the chain
cache serves the requests
peer communication protocols as
serves the requests from
if the chain is
the requests from its
communication protocols as an
requests from its local
the chain is disrupted
protocols as an underlying
chain is disrupted by
as an underlying communication
from its local storage
an underlying communication substrate
its local storage if
underlying communication substrate for
local storage if possible
communication substrate for soc
is disrupted by a
substrate for soc applications
disrupted by a failure
by a failure and
a failure and some
or reads from the
failure and some updates
reads from the database
and some updates arrive
from the database otherwise
some updates arrive via
the relative strengths of
updates arrive via the
arrive via the gossip
relative strengths of each
via the gossip protocol
strengths of each of
of each of the
each of the solutions
the cache registers an
these changes substantially simplify
cache registers an upcall
of the solutions tested
registers an upcall that
changes substantially simplify the
an upcall that can
the solutions tested and
upcall that can be
solutions tested and the
that can be used
substantially simplify the algorithm
can be used by
tested and the lack
be used by the
simplify the algorithm but
used by the database
and the lack of
the algorithm but they
the lack of a
algorithm but they also
by the database to
but they also weaken
lack of a clear
they also weaken the
the database to report
also weaken the properties
of a clear winner
weaken the properties of
database to report invalidations
the properties of the
a clear winner serve
properties of the solution
clear winner serve as
winner serve as a
serve as a further
after each update transaction
as a further justification
each update transaction the
a further justification for
a less significant change
update transaction the database
less significant change is
further justification for the
significant change is that
transaction the database asynchronously
justification for the decoupling
the database asynchronously sends
for the decoupling of
change is that we
the decoupling of information
is that we load
decoupling of information and
database asynchronously sends invalidations
of information and transport
asynchronously sends invalidations to
information and transport layers
sends invalidations to the
and transport layers advocated
invalidations to the cache
transport layers advocated above
to the cache for
balance queries over the
the cache for all
queries over the members
cache for all objects
over the members of
for all objects that
the members of the
all objects that were
members of the chain
objects that were modified
but in ways that
limitations of the existing
in ways that seem
of the existing model
ways that seem to
the existing model there
that seem to match
existing model there are
seem to match the
model there are two
to match the class
there are two important
match the class of
are two important reasons
the class of applications
two important reasons why
class of applications of
important reasons why integrating
of applications of interest
reasons why integrating peerto
chosen uniformly at random
and has the potential
peer collaboration with server
are dropped by the
has the potential to
dropped by the experiment
the potential to greatly
potential to greatly improve
hosted content is difficult
to greatly improve query
this is extreme and
greatly improve query performance
is extreme and would
the first is not
extreme and would only
first is not strictly
and would only be
is not strictly limited
would only be seen
not strictly limited to
only be seen in
strictly limited to collaboration
be seen in the
limited to collaboration and
seen in the real
to collaboration and peer
in the real world
the real world under
real world under conditions
world under conditions of
epidemic dissemination as noted
under conditions of overload
dissemination as noted earlier
conditions of overload or
of overload or when
overload or when the
or when the system
when the system configuration
ssa uses gossip to
the system configuration is
uses gossip to detect
system configuration is changed
gossip to detect and
it is a general
to detect and repair
is a general weakness
detect and repair the
both the database and
and repair the inconsistencies
a general weakness of
repair the inconsistencies that
the database and the
the inconsistencies that can
general weakness of the
inconsistencies that can arise
database and the cache
that can arise after
weakness of the current
can arise after a
and the cache report
arise after a failure
of the current web
the cache report all
after a failure or
cache report all completed
a failure or when
report all completed transactions
failure or when a
the current web mashup
all completed transactions to
or when a node
completed transactions to a
when a node joins
transactions to a consistency
current web mashup technologies
to a consistency monitor
web mashup technologies that
mashup technologies that makes
the basic idea is
technologies that makes it
basic idea is simple
created in order to
that makes it hard
in order to gather
makes it hard to
order to gather statistics
it hard to seamlessly
to gather statistics for
each process in the
gather statistics for our
process in the system
statistics for our evaluation
in the system runs
hard to seamlessly integrate
the system runs a
to seamlessly integrate data
system runs a periodic
seamlessly integrate data from
runs a periodic local
integrate data from several
a periodic local timer
data from several different
this server collects both
from several different sources
server collects both committed
collects both committed and
without synchronization across processes
both committed and aborted
committed and aborted transactions
the web developers community
and aborted transactions and
web developers community has
aborted transactions and it
when a timer expires
transactions and it maintains
developers community has slowly
and it maintains the
community has slowly converged
it maintains the full
has slowly converged towards
a process computes a
maintains the full dependency
process computes a summary
slowly converged towards service
the full dependency graph
converged towards service platforms
towards service platforms that
service platforms that export
also called a digest
platforms that export autonomous
it performs full serialization
that export autonomous interactive
performs full serialization graph
export autonomous interactive components
full serialization graph testing
autonomous interactive components to
interactive components to their
components to their clients
in the form of
a list of things
the form of what
list of things that
form of what we
of things that it
of what we ll
things that it knows
what we ll call
and calculates the rate
we ll call minibrowser
calculates the rate of
ll call minibrowser interfaces
the rate of inconsistent
this summary is sent
rate of inconsistent transactions
summary is sent to
of inconsistent transactions that
is sent to a
a minibrowser is an
inconsistent transactions that committed
minibrowser is an interactive
sent to a randomly
is an interactive web
to a randomly selected
an interactive web page
a randomly selected peer
interactive web page with
transactions that committed and
web page with embedded
that committed and the
page with embedded script
committed and the rate
or subset of peers
and the rate of
the rate of consistent
rate of consistent transactions
of consistent transactions that
consistent transactions that were
transactions that were unnecessarily
that were unnecessarily aborted
quick delivery is more
delivery is more important
is more important than
more important than reliability
important than reliability for
than reliability for gossip
reliability for gossip messages
our prototype does not
prototype does not address
does not address the
optimized for displaying a
not address the issue
for displaying a single
hence we favor udp
displaying a single type
address the issue of
we favor udp datagrams
the issue of cache
favor udp datagrams over
issue of cache eviction
udp datagrams over tcp
of cache eviction when
datagrams over tcp for
cache eviction when running
over tcp for this
a single type of
tcp for this kind
single type of content
for this kind of
eviction when running out
this kind of communication
when running out of
running out of memory
for example interactive maps
example interactive maps from
the recipient compares the
interactive maps from google
recipient compares the gossiped
maps from google earth
compares the gossiped information
from google earth or
the gossiped information with
google earth or virtual
gossiped information with its
earth or virtual earth
information with its own
all objects in the
with its own state
objects in the workload
in the workload fit
the workload fit in
workload fit in the
fit in the cache
identifying information known to
information known to the
known to the sender
our example actually overlays
to the sender but
and eviction is only
the sender but unknown
eviction is only done
sender but unknown to
is only done if
but unknown to itself
only done if there
example actually overlays weather
done if there is
if there is a
actually overlays weather from
there is a direct
or known to it
is a direct reason
overlays weather from google
known to it but
weather from google on
to it but apparently
from google on terrain
it but apparently unknown
google on terrain maps
but apparently unknown to
on terrain maps from
apparently unknown to the
had we modeled them
terrain maps from microsoft
unknown to the sender
maps from microsoft s
from microsoft s virtual
microsoft s virtual earth
evictions would reduce the
s virtual earth platform
it then sends back
virtual earth platform and
then sends back a
would reduce the cache
sends back a gossip
earth platform and extracts
reduce the cache hit
platform and extracts census
the cache hit rate
back a gossip reply
and extracts census data
extracts census data from
census data from the
data from the us
but could not cause
from the us census
could not cause new
the us census bureau
not cause new inconsistencies
using an unreliable datagram
an unreliable datagram protocol
the lion coexists with
we evaluate the effectiveness
lion coexists with the
coexists with the lamb
evaluate the effectiveness of
containing information the sender
the effectiveness of our
information the sender might
effectiveness of our transactional
the sender might find
the second problem is
sender might find useful
of our transactional cache
might find useful and
second problem is that
our transactional cache using
problem is that with
transactional cache using various
find useful and requesting
cache using various workloads
useful and requesting information
is that with the
using various workloads and
that with the traditional
and requesting information it
with the traditional style
requesting information it lacks
the traditional style of
various workloads and varying
traditional style of web
workloads and varying the
style of web development
and varying the size
varying the size of
the size of the
size of the dependency
content is assumed to
the originator of the
of the dependency lists
originator of the exchange
the dependency lists maintained
is assumed to be
dependency lists maintained by
assumed to be fetched
lists maintained by the
to be fetched from
maintained by the cache
be fetched from a
by the cache and
fetched from a server
the cache and the
of the exchange will
cache and the database
the exchange will send
exchange will send a
either directly over http
will send a final
send a final message
for the cases considered
a final message containing
final message containing any
or by interacting with
message containing any data
by interacting with a
containing any data that
interacting with a web
any data that was
with a web service
data that was solicited
short dependency lists suffice
that was solicited by
was solicited by the
solicited by the receiver
web pages downloaded by
pages downloaded by clients
downloaded by clients browsers
by clients browsers contain
gossip messages are bounded
clients browsers contain embedded
messages are bounded in
browsers contain embedded addresses
are bounded in size
contain embedded addresses of
embedded addresses of specific
addresses of specific servers
thus during a round
an open question for
during a round each
technologies such as ajax
a round each process
such as ajax allow
round each process will
as ajax allow for
each process will send
ajax allow for asynchronous
process will send a
open question for further
will send a message
question for further study
for further study is
further study is whether
study is whether there
perhaps eliciting a reply
is whether there are
whether there are workloads
there are workloads that
are workloads that might
and perhaps will respond
workloads that might require
perhaps will respond to
that might require limited
will respond to that
might require limited but
respond to that reply
require limited but larger
but traffic is still
limited but larger values
traffic is still always
is still always routed
in the worst case
still always routed through
always routed through a
note that dependencies arise
routed through a data
that dependencies arise from
a round results in
dependencies arise from the
through a data center
arise from the topology
from the topology of
the topology of the
topology of the object
of the object graph
the clients don t
clients don t talk
don t talk to
the load imposed on
t talk to one
load imposed on the
talk to one another
and not from the
imposed on the network
not from the size
on the network will
from the size of
the network will thus
the size of the
network will thus be
size of the transactions
will thus be linear
of the transactions read
thus be linear in
live objects allow visual
be linear in the
the transactions read and
linear in the number
objects allow visual content
in the number of
transactions read and write
the number of processes
allow visual content and
read and write sets
visual content and update
content and update events
and update events to
but any individual process
update events to be
as a baseline for
events to be communicated
a baseline for comparison
any individual process will
to be communicated using
individual process will see
be communicated using any
process will see a
communicated using any sort
will see a constant
we also implemented a
using any sort of
also implemented a timeout
any sort of protocol
see a constant load
independent of system size
it reduces the probability
reduces the probability of
the probability of inconsistency
probability of inconsistency by
but also overlay multicast
the ssa gossips about
of inconsistency by limiting
ssa gossips about membership
inconsistency by limiting the
by limiting the life
limiting the life span
the life span of
life span of cache
span of cache entries
recoveries and application state
we compare this method
compare this method against
even a custom protocol
this method against our
a custom protocol designed
using this information to
custom protocol designed by
this information to initiate
method against our transactional
protocol designed by the
information to initiate repairs
against our transactional cache
designed by the content
our transactional cache by
by the content provider
transactional cache by measuring
cache by measuring its
one form of repair
by measuring its effectiveness
form of repair involves
measuring its effectiveness with
of repair involves disruption
its effectiveness with a
repair involves disruption to
effectiveness with a varying
involves disruption to a
with a varying time
this makes it possible
disruption to a chain
makes it possible to
it possible to achieve
possible to achieve extremely
to achieve extremely high
achieve extremely high levels
if a fault breaks
extremely high levels of
a fault breaks a
high levels of throughput
fault breaks a chain
levels of throughput and
breaks a chain or
of throughput and latency
a chain or disables
chain or disables the
or disables the head
disables the head of
the head of a
head of a chain
it also enhances security
the data center server
both read and update
data center server can
read and update transactions
gossip is used to
and update transactions access
center server can t
is used to detect
server can t see
used to detect the
can t see data
to detect the problem
t see data exchanged
our experiment satisfies all
detect the problem and
experiment satisfies all read
see data exchanged directly
the problem and repair
data exchanged directly between
problem and repair involves
exchanged directly between peers
only transactions from the
and repair involves designating
transactions from the cache
repair involves designating a
involves designating a new
the above discussion motivates
designating a new head
above discussion motivates our
while passing all update
a new head for
passing all update transactions
discussion motivates our problem
all update transactions directly
motivates our problem statement
new head for the
update transactions directly to
head for the chain
transactions directly to the
for the chain or
directly to the backend
the chain or establishing
to the backend database
allow web applications to
chain or establishing a
web applications to overlay
or establishing a new
applications to overlay content
establishing a new tcp
to overlay content from
a new tcp connection
overlay content from multiple
new tcp connection bridging
each cache server is
tcp connection bridging the
content from multiple sources
connection bridging the gap
from multiple sources in
cache server is unaware
multiple sources in a
server is unaware of
sources in a layered
is unaware of the
in a layered fashion
unaware of the other
a second form of
of the other servers
second form of repair
the other servers it
form of repair involves
other servers it has
of repair involves lost
such that the distinct
repair involves lost updates
servers it has its
that the distinct content
it has its own
the distinct content layers
has its own clients
distinct content layers share
its own clients and
if subservice a has
own clients and communicates
subservice a has a
content layers share a
a has a member
clients and communicates directly
has a member m
layers share a single
and communicates directly with
share a single view
communicates directly with the
a single view and
a member m that
single view and remain
directly with the backend
view and remain well
with the backend database
and remain well synchronized
member m that knows
the percentage of read
we assume that all
assume that all forms
that all forms of
only transactions can be
all forms of information
transactions can be arbitrarily
forms of information are
can be arbitrarily high
or panning should cause
be arbitrarily high or
panning should cause all
arbitrarily high or low
of information are uniquely
high or low in
should cause all layers
or low in this
information are uniquely named
cause all layers to
low in this situation
are uniquely named and
all layers to respond
uniquely named and that
layers to respond simultaneously
named and that updates
and that updates are
that updates are ordered
updates are ordered separately
are ordered separately by
and an update in
ordered separately by each
we can push the
separately by each update
an update in any
by each update source
can push the percentage
update in any of
push the percentage up
in any of the
any of the layers
of the layers should
of update x and
the layers should be
update x and a
layers should be reflected
our simulation focuses on
should be reflected in
x and a member
be reflected in all
and a member m
reflected in all other
a member m that
in all other layers
simulation focuses on just
member m that lacks
focuses on just a
m that lacks x
on just a single
just a single cache
allow updates to be
a single cache it
updates to be carried
single cache it would
to be carried by
cache it would behave
gossip can be used
it would behave the
be carried by the
can be used to
would behave the same
be used to detect
behave the same had
used to detect this
carried by the protocol
to detect this and
the same had there
detect this and m
same had there been
this and m can
had there been many
and m can then
there been many cache
m can then send
been many cache servers
can then send x
by the protocol best
then send x to
the protocol best matched
send x to m
protocol best matched to
x to m directly
best matched to the
matched to the setting
to the setting in
the setting in which
setting in which the
without waiting for the
in which the application
waiting for the chain
which the application is
cache can be used
the application is used
for the chain to
can be used with
the chain to be
be used with any
chain to be repaired
used with any transactional
with any transactional backend
any transactional backend and
transactional backend and any
backend and any transactional
and any transactional workload
the solutions discussed here
solutions discussed here are
gossip is not a
discussed here are based
is not a particularly
here are based on
not a particularly fast
are based on live
a particularly fast protocol
based on live objects
only transactions will be
transactions will be similar
will be similar to
be similar to non
the underlying database is
underlying database is only
rounds of the protocol
database is only accessed
of the protocol to
is only accessed on
the protocol to reach
only accessed on cache
protocol to reach n
new types of components
to reach n processes
accessed on cache misses
types of components must
of components must be
components must be created
must be created for
on the other hand
be created for each
created for each type
for each type of
each type of content
inconsistencies may be observed
if rounds occur frequently
but the existing collection
the delay before information
the existing collection of
delay before information spreads
existing collection of components
before information spreads to
collection of components provides
information spreads to all
we will use synthetic
spreads to all members
of components provides access
will use synthetic workloads
components provides access to
to all members of
use synthetic workloads so
provides access to several
all members of a
access to several different
members of a system
synthetic workloads so we
of a system may
to several different types
workloads so we can
several different types of
a system may still
so we can evaluate
system may still be
different types of web
we can evaluate how
types of web services
may still be small
of web services hosted
can evaluate how much
web services hosted content
evaluate how much inconsistency
how much inconsistency can
even in a large
much inconsistency can be
in a large system
inconsistency can be observed
including all the examples
can be observed as
all the examples given
be observed as a
the examples given above
observed as a function
as a function of
a function of the
function of the amount
gossip is astonishingly robust
of the amount of
the amount of clustering
amount of clustering in
of clustering in the
clustering in the workload
there are exponentially many
are exponentially many paths
the resulting live application
exponentially many paths by
resulting live application is
many paths by which
live application is stored
this also allows us
application is stored as
paths by which information
also allows us to
by which information can
allows us to look
is stored as an
us to look at
stored as an xml
to look at the
which information can pass
look at the dynamic
information can pass from
at the dynamic behavior
can pass from point
the dynamic behavior of
pass from point a
dynamic behavior of the
from point a to
behavior of the system
point a to point
as an xml file
a to point b
when the amount of
the file can be
the amount of clustering
file can be moved
hence almost any imaginable
can be moved about
amount of clustering and
be moved about and
almost any imaginable disruption
moved about and even
of clustering and the
about and even embedded
any imaginable disruption short
and even embedded in
clustering and the clustering
imaginable disruption short of
and the clustering formation
disruption short of a
the clustering formation change
short of a lasting
clustering formation change over
of a lasting partitioning
formation change over time
even embedded in email
a lasting partitioning failure
lasting partitioning failure can
partitioning failure can be
failure can be overcome
users that open it
that open it find
open it find themselves
we will look at
the gossip protocols implemented
will look at workloads
it find themselves immersed
look at workloads based
gossip protocols implemented in
at workloads based on
find themselves immersed into
workloads based on amazon
protocols implemented in the
based on amazon s
themselves immersed into the
on amazon s product
implemented in the ssa
amazon s product co
immersed into the application
in the ssa have
the ssa have been
ssa have been designed
have been designed specifically
purchasing and orkut s
several transport protocols optimized
and orkut s social
been designed specifically for
orkut s social network
transport protocols optimized for
s social network to
designed specifically for use
social network to see
protocols optimized for various
network to see how
optimized for various settings
to see how much
for various settings are
see how much inconsistency
specifically for use in
how much inconsistency t
for use in our
various settings are or
use in our modified
settings are or will
in our modified version
are or will be
our modified version of
or will be available
modified version of chain
will be available in
version of chain replication
be available in a
cache can detect as
available in a near
can detect as a
in a near future
detect as a function
and with the goal
as a function of
with the goal of
a function of dependency
the goal of running
function of dependency list
goal of running in
of dependency list length
including support for wan
of running in large
support for wan networks
running in large clusters
for wan networks with
in large clusters or
wan networks with nats
and compare this with
networks with nats and
compare this with a
with nats and firewalls
this with a ttl
large clusters or datacenters
let be a group
be a group of
a group of processes
we are also interested
are also interested in
also interested in overhead
and let p be
let p be a
p be a process
be a process in
particularly the additional load
a process in that
the additional load on
process in that group
additional load on the
in that group p
load on the backend
on the backend database
the backend database that
backend database that could
database that could form
that could form if
could form if the
form if the the
each process has its
if the the rate
process has its own
the the rate of
has its own view
the rate of cache
its own view of
rate of cache misses
own view of the
of cache misses increases
view of the group
high throughput and very
throughput and very large
and very large numbers
b presented three strategies
very large numbers of
presented three strategies for
large numbers of nodes
three strategies for responding
strategies for responding to
for responding to inconsistency
responding to inconsistency detection
these views can lag
for both the synthetic
views can lag reality
both the synthetic and
the synthetic and realistic
synthetic and realistic workloads
for example if a
example if a process
we compare the efficacy
if a process joins
compare the efficacy of
a process joins or
the efficacy of the
process joins or leaves
efficacy of the three
of the three strategies
large numbers of irregularly
numbers of irregularly overlapping
of irregularly overlapping multicast
irregularly overlapping multicast groups
and different members might
different members might not
synthetic workloads synthetic workloads
members might not have
workloads synthetic workloads allow
might not have consistent
synthetic workloads allow us
not have consistent views
workloads allow us to
allow us to understand
us to understand the
to understand the efficacy
understand the efficacy of
our work assumes that
the efficacy of t
work assumes that the
assumes that the network
that the network within
the network within a
network within a cluster
cache as a function
within a cluster does
as a function of
a cluster does not
a function of clustering
cluster does not partition
and strong reliability properties
for the experiments described
although there are low
the experiments described here
probability failure patterns that
failure patterns that could
patterns that could temporarily
that could temporarily partition
cache with a maximum
could temporarily partition some
with a maximum of
temporarily partition some subservice
partition some subservice in
some subservice in a
subservice in a logical
in a logical sense
elements per dependency list
describes synthetic workload generation
process p chooses a
p chooses a random
chooses a random subset
a random subset of
random subset of a
before saying more about
subset of a particular
saying more about our
of a particular size
more about our approach
a particular size view
measures how many inconsistencies
how many inconsistencies we
many inconsistencies we can
we analyze a concrete
inconsistencies we can detect
analyze a concrete example
we can detect as
a concrete example of
can detect as a
concrete example of a
detect as a function
example of a soc
and commences a dialog
as a function of
commences a dialog with
a function of clustering
a dialog with each
function of clustering and
dialog with each process
of clustering and section
with each process in
clustering and section v
each process in the
of a soc application
process in the set
a soc application more
soc application more carefully
application more carefully to
more carefully to expose
the initial message is
carefully to expose the
initial message is a
to expose the full
message is a compact
expose the full range
is a compact state
the full range of
considers clustering changes over
a compact state digest
clustering changes over time
full range of needs
compact state digest summarizing
range of needs and
state digest summarizing the
of needs and issues
digest summarizing the state
needs and issues that
summarizing the state of
and issues that arise
the state of the
state of the sender
consider a rescue mission
a rescue mission coordinator
the follow up dialog
compares the efficacy of
follow up dialog consists
the efficacy of various
up dialog consists of
efficacy of various approaches
a police or fire
dialog consists of an
police or fire chief
consists of an explicit
of various approaches to
of an explicit request
or fire chief coordinating
an explicit request of
various approaches to dealing
fire chief coordinating teams
approaches to dealing with
explicit request of missing
chief coordinating teams who
request of missing update
to dealing with detected
of missing update operations
coordinating teams who will
dealing with detected inconsistencies
teams who will enter
who will enter a
will enter a disaster
enter a disaster zone
several details of the
a disaster zone in
details of the epidemic
disaster zone in the
of the epidemic protocols
zone in the wake
the epidemic protocols employed
in the wake of
epidemic protocols employed in
the wake of a
protocols employed in the
wake of a catastrophe
employed in the framework
of a catastrophe to
in the framework turned
a catastrophe to help
our basic synthetic workload
catastrophe to help survivors
the framework turned out
basic synthetic workload is
framework turned out to
synthetic workload is constructed
turned out to be
workload is constructed as
out to be important
is constructed as follows
to be important determinants
be important determinants of
important determinants of system
determinants of system performance
of system performance and
system performance and behavior
suppose that a process
that a process disseminates
a process disseminates information
process disseminates information via
disseminates information via epidemics
information via epidemics about
via epidemics about a
epidemics about a subject
about a subject s
process p gossips about
p gossips about subject
and move supplies as
gossips about subject s
move supplies as needed
about subject s a
subject s a finite
s a finite number
a finite number of
finite number of times
as long as subject
long as subject s
as subject s is
subject s is hot
the objects are divided
objects are divided into
would arrive on the
are divided into clusters
arrive on the scene
divided into clusters of
after which subject s
into clusters of size
which subject s is
build a new collaboration
subject s is no
a new collaboration tool
s is no longer
is no longer gossiped
no longer gossiped about
and distribute it to
distribute it to his
explicit requests for copies
requests for copies of
for copies of missed
copies of missed messages
of missed messages are
missed messages are limited
messages are limited in
each team member would
are limited in size
team member would carry
member would carry a
would carry a tablet
to prevent a process
prevent a process that
style device with wireless
a process that lagged
device with wireless communication
process that lagged behind
with wireless communication capabilities
that lagged behind or
lagged behind or just
behind or just joined
or just joined from
just joined from trying
the application built by
joined from trying to
application built by the
from trying to catch
built by the coordinator
trying to catch up
by the coordinator would
to catch up all
the coordinator would be
catch up all at
coordinator would be installed
up all at once
would be installed on
be installed on each
installed on each team
on each team member
each team member s
team member s mobile
which would result in
member s mobile device
would result in enormous
result in enormous messages
in enormous messages and
enormous messages and serious
messages and serious fluctuations
and in the offices
and serious fluctuations in
in the offices in
serious fluctuations in system
the offices in mission
fluctuations in system load
offices in mission headquarters
and there are two
there are two types
are two types of
two types of workloads
the coordinator would then
coordinator would then deploy
would then deploy teams
then deploy teams in
deploy teams in the
teams in the field
such a process may
a process may need
clustering is perfect and
process may need to
is perfect and each
our rescue workers now
perfect and each transaction
may need to catch
and each transaction chooses
need to catch up
rescue workers now use
to catch up over
each transaction chooses a
workers now use the
transaction chooses a single
now use the solution
catch up over many
chooses a single cluster
use the solution to
up over many seconds
a single cluster and
the solution to coordinate
single cluster and chooses
solution to coordinate and
to coordinate and prioritize
coordinate and prioritize actions
explicit message requests are
message requests are honored
times with repetitions within
requests are honored if
with repetitions within this
are honored if the
inform each other of
honored if the requested
each other of the
if the requested messages
repetitions within this cluster
the requested messages are
within this cluster to
requested messages are still
this cluster to establish
messages are still in
other of the evolving
cluster to establish its
are still in the
of the evolving situation
to establish its access
still in the bounded
establish its access set
in the bounded buffers
steer clear of hazards
in the second type
once a message has
the second type of
a message has been
second type of workloads
message has been delivered
type of workloads access
has been delivered to
of workloads access is
been delivered to the
workloads access is not
delivered to the upper
as new events occur
to the upper levels
access is not fully
is not fully contained
not fully contained within
fully contained within each
the situational status would
contained within each cluster
situational status would evolve
and it has been
it has been expunged
has been expunged from
been expunged from the
when a transaction starts
expunged from the buffers
and the team member
from the buffers located
the team member who
the buffers located at
team member who causes
it chooses a cluster
buffers located at the
chooses a cluster uniformly
member who causes or
a cluster uniformly at
located at the gossiper
cluster uniformly at random
at the gossiper level
who causes or observes
causes or observes these
or observes these status
observes these status changes
requests are simply ignored
these status changes would
status changes would need
changes would need to
would need to report
need to report them
the requesting process would
to report them to
requesting process would have
report them to the
process would have to
them to the others
each object is chosen
would have to try
object is chosen using
have to try to
is chosen using a
to try to find
chosen using a bounded
try to find the
using a bounded pareto
to find the missing
a bounded pareto distribution
find the missing data
removing debris blocking access
the missing data elsewhere
bounded pareto distribution starting
debris blocking access to
pareto distribution starting at
blocking access to a
distribution starting at detected
access to a building
starting at detected inconsistencies
to a building may
a building may enable
if data cannot be
building may enable the
data cannot be recovered
may enable the team
enable the team to
the team to check
team to check it
to check it for
we signal this to
check it for victims
signal this to the
this to the application
to the application by
the application by delivering
application by delivering an
and fire that breaks
by delivering an exception
update clients access the
delivering an exception upcall
fire that breaks out
clients access the database
that breaks out in
access the database at
breaks out in a
the database at a
out in a chemical
database at a rate
in a chemical storage
at a rate of
a chemical storage warehouse
chemical storage warehouse may
and leave it to
storage warehouse may force
leave it to the
warehouse may force diversion
it to the application
may force diversion of
to the application to
force diversion of resources
the application to decide
application to decide how
to decide how to
decide how to handle
how to handle the
as rescue workers capture
to handle the problem
rescue workers capture information
the size of the
their mobile devices send
size of the buffers
only clients access the
of the buffers is
mobile devices send updates
the buffers is configurable
clients access the cache
devices send updates that
access the cache at
send updates that must
the cache at a
updates that must be
cache at a rate
that must be propagated
but this rule implies
must be propagated in
at a rate of
this rule implies that
be propagated in real
rule implies that certain
implies that certain kinds
that certain kinds of
certain kinds of failures
kinds of failures may
of failures may be
failures may be unrecoverable
may be unrecoverable within
having defined the scenario
be unrecoverable within the
unrecoverable within the ssa
now let s analyze
let s analyze in
digests are bounded in
s analyze in more
are bounded in the
analyze in more detail
bounded in the number
in more detail the
in the number of
more detail the requirements
the number of messages
detail the requirements it
number of messages they
the requirements it places
of messages they advertise
requirements it places on
messages they advertise about
it places on our
they advertise about in
places on our collaboration
advertise about in one
on our collaboration tool
about in one single
in one single datagram
one single datagram packet
and each round only
each round only a
round only a single
only a single digest
a single digest is
the collaboration tool pulls
single digest is disseminated
collaboration tool pulls data
tool pulls data from
pulls data from many
data from many kinds
from many kinds of
even if the subset
many kinds of sources
if the subset view
the subset view selected
it makes far more
makes far more sense
far more sense to
more sense to imagine
sense to imagine that
has cardinality greater than
to imagine that weather
cardinality greater than one
imagine that weather information
messages that are potentially
that are potentially in
are potentially in transit
potentially in transit are
in transit are not
transit are not retransmitted
are not retransmitted to
not retransmitted to requesting
retransmitted to requesting processes
for example if a
example if a process
if a process p
messages and alerts come
a process p makes
and alerts come from
process p makes an
alerts come from a
p makes an explicit
come from a dozen
makes an explicit request
from a dozen providers
an explicit request for
a dozen providers than
explicit request for a
dozen providers than to
request for a message
providers than to assume
for a message m
than to assume that
a message m and
to assume that one
message m and the
assume that one organization
m and the request
that one organization would
and the request lands
one organization would be
the request lands at
organization would be hosting
request lands at process
would be hosting services
lands at process q
be hosting services with
at process q that
hosting services with everything
process q that has
services with everything we
q that has already
with everything we need
that has already sent
everything we need in
has already sent p
we need in one
already sent p a
need in one place
sent p a copy
p a copy of
a copy of m
copy of m in
of m in the
m in the recent
data from distinct sources
in the recent past
from distinct sources could
the recent past then
distinct sources could have
recent past then m
sources could have different
past then m will
could have different format
then m will not
have different format and
m will not be
different format and one
will not be retransmitted
format and one will
and one will often
one will often need
will often need to
often need to interface
a process creates a
need to interface to
process creates a digest
to interface to each
creates a digest based
interface to each using
a digest based upon
to each using its
digest based upon all
each using its own
based upon all the
using its own protocols
upon all the messages
its own protocols and
all the messages received
own protocols and interfaces
the messages received by
messages received by means
received by means of
by means of any
means of any communication
of any communication channels
not just the epidemics
as conditions evolve the
conditions evolve the team
evolve the team might
the team might need
team might need to
might need to be
need to be modify
to be modify the
be modify the application
for example adding new
example adding new types
the messages received by
adding new types of
messages received by fifo
new types of information
received by fifo chained
by fifo chained channels
changing the way it
the way it is
way it is represented
the message buffers are
message buffers are bounded
or even modifying the
even modifying the way
modifying the way team
the way team members
way team members communicate
and once a message
once a message has
a message has been
message has been delivered
has been delivered by
been delivered by means
delivered by means of
by means of an
means of an upcall
of an upcall it
back network links fail
an upcall it is
upcall it is prone
it is prone to
is prone to be
prone to be replaced
to be replaced by
be replaced by the
replaced by the replacement
by the replacement policy
whereas a minibrowser would
a minibrowser would typically
minibrowser would typically be
would typically be prebuilt
typically be prebuilt with
the ssa implements several
be prebuilt with all
ssa implements several replacement
prebuilt with all the
implements several replacement policies
with all the available
all the available features
the available features in
available features in place
most advertised message in
our scenario demands a
advertised message in digests
scenario demands a much
demands a much more
a much more flexible
much more flexible kind
more flexible kind of
flexible kind of tool
kind of tool that
of tool that can
tool that can be
that can be redesigned
can be redesigned while
although the ssa should
be redesigned while in
the ssa should work
redesigned while in use
ssa should work well
should work well on
work well on clusters
well on clusters with
on clusters with as
clusters with as many
with as many as
as many as thousands
many as thousands of
depending on the location
as thousands of nodes
on the location and
the location and other
location and other factors
companies like google and
like google and amazon
the best networking protocols
google and amazon reportedly
best networking protocols and
and amazon reportedly operate
networking protocols and connectivity
amazon reportedly operate centers
protocols and connectivity options
reportedly operate centers with
and connectivity options may
operate centers with tens
connectivity options may vary
centers with tens of
with tens of thousands
tens of thousands of
of thousands of machines
in our rescue scenario
thousands of machines in
of machines in them
the workers may have
workers may have to
may have to use
and are said to
have to use wireless
are said to deploy
to use wireless p
said to deploy some
to deploy some popular
deploy some popular services
some popular services on
popular services on huge
p protocols much of
services on huge numbers
protocols much of the
on huge numbers of
much of the time
huge numbers of nodes
reaching back to hosted
were we to use
back to hosted services
we to use the
to hosted services only
to use the ssa
hosted services only intermittently
use the ssa in
services only intermittently when
the ssa in such
only intermittently when a
ssa in such settings
intermittently when a drone
when a drone aircraft
a drone aircraft passes
drone aircraft passes within
aircraft passes within radio
our gossip protocol might
passes within radio range
gossip protocol might need
protocol might need to
might need to be
need to be revisited
to be revisited to
be revisited to ensure
revisited to ensure that
to ensure that messages
the right choice of
ensure that messages do
right choice of protocol
that messages do not
choice of protocol should
messages do not become
of protocol should reflect
do not become excessively
protocol should reflect the
not become excessively large
should reflect the operating
reflect the operating conditions
one way to accomplish
and if these change
way to accomplish this
to accomplish this might
accomplish this might be
this might be to
the platform should be
might be to modify
platform should be capable
be to modify the
should be capable of
to modify the epidemic
be capable of swapping
modify the epidemic protocol
capable of swapping in
the epidemic protocol using
of swapping in a
epidemic protocol using spatial
swapping in a different
protocol using spatial distributions
in a different protocol
using spatial distributions to
a different protocol without
spatial distributions to improve
different protocol without disrupting
distributions to improve the
protocol without disrupting the
to improve the performance
without disrupting the end
disrupting the end user
this argues for a
argues for a decoupling
for a decoupling of
a decoupling of functionality
whereas a minibrowser packages
a minibrowser packages it
minibrowser packages it all
packages it all into
it all into one
such an approach would
all into one object
an approach would let
approach would let us
would let us restrict
let us restrict information
better is a design
us restrict information to
is a design in
restrict information to the
a design in which
information to the vicinity
design in which the
to the vicinity of
in which the presentation
the vicinity of the
which the presentation object
vicinity of the nodes
the presentation object is
of the nodes where
presentation object is distinct
the nodes where it
object is distinct from
nodes where it might
is distinct from objects
where it might be
distinct from objects representing
it might be needed
from objects representing information
objects representing information sources
representing information sources and
information sources and objects
sources and objects representing
in effect adding an
and objects representing transport
effect adding an additional
objects representing transport protocols
adding an additional layer
an additional layer of
additional layer of hierarchy
layer of hierarchy to
of hierarchy to the
hierarchy to the architecture
decoupling makes it possible
makes it possible to
it possible to dynamically
possible to dynamically modify
we believe the required
to dynamically modify or
believe the required changes
dynamically modify or even
the required changes would
modify or even replace
required changes would be
or even replace a
changes would be relatively
even replace a component
would be relatively minor
replace a component with
a component with some
component with some other
option when changing conditions
when changing conditions require
changing conditions require it
ratio of inconsistencies as
we have posed what
epidemic analytical model one
have posed what may
of inconsistencies as a
analytical model one benefit
posed what may sound
model one benefit of
inconsistencies as a function
what may sound like
one benefit of using
as a function of
may sound like a
benefit of using gossip
sound like a very
of using gossip in
like a very specialized
using gossip in the
a very specialized problem
gossip in the ssa
in the ssa is
the ssa is that
ssa is that we
is that we can
but in fact we
that we can use
in fact we see
we can use analytical
fact we see this
we see this as
can use analytical methods
the head of its
see this as a
use analytical methods to
this as a good
analytical methods to predict
methods to predict the
head of its cluster
as a good example
to predict the behavior
of its cluster i
a good example of
predict the behavior of
good example of a
the behavior of a
example of a more
behavior of a cluster
of a more general
a more general kind
more general kind of
general kind of need
kind of need that
complementing our experimental work
of need that could
need that could arise
that could arise in
could arise in many
arise in many kinds
a basic result of
in many kinds of
basic result of epidemic
many kinds of settings
result of epidemic theory
of epidemic theory states
epidemic theory states that
theory states that simple
states that simple epidemics
that simple epidemics eventually
simple epidemics eventually infect
consider a physician treating
epidemics eventually infect the
a physician treating a
eventually infect the entire
physician treating a patient
infect the entire population
treating a patient with
the entire population with
a patient with a
entire population with probability
patient with a complex
with a complex condition
who needs collaboration help
needs collaboration help from
collaboration help from specialists
moreover starting with a
starting with a single
with a single infected
a single infected site
and who might even
single infected site this
who might even be
infected site this is
might even be working
site this is achieved
even be working in
this is achieved in
be working in a
is achieved in expected
working in a remote
achieved in expected time
in expected time proportional
if the pareto variable
in a remote location
expected time proportional to
a remote location under
time proportional to the
remote location under conditions
proportional to the log
location under conditions demanding
to the log of
the pareto variable plus
under conditions demanding urgent
the log of the
conditions demanding urgent action
log of the population
pareto variable plus the
of the population size
the mixture of patient
variable plus the offset
mixture of patient data
plus the offset results
the offset results in
offset results in a
the protocol roughly falls
protocol roughly falls under
results in a number
roughly falls under the
falls under the category
in a number outside
under the category of
may be just as
the category of a
be just as rich
category of a push
just as rich and
a number outside the
as rich and dynamic
number outside the range
rich and dynamic as
and the exact formula
and dynamic as in
the exact formula for
dynamic as in our
exact formula for it
as in our search
formula for it can
in our search and
for it can be
our search and rescue
it can be expressed
search and rescue scenario
can be expressed as
be expressed as log
and the underlying communication
the underlying communication options
underlying communication options equally
communication options equally heterogeneous
options equally heterogeneous and
equally heterogeneous and unpredictable
designed for a wired
for a wired environment
a wired environment might
wired environment might perform
environment might perform poorly
might perform poorly or
perform poorly or fail
poorly or fail under
or fail under such
fail under such conditions
if there is a
for large values of
there is a way
large values of n
is a way to
a way to solve
way to solve the
to solve the problem
where n the number
n the number of
the number of sites
there is a way
number of sites participating
is a way to
of sites participating in
a way to build
sites participating in the
way to build the
participating in the epidemic
to build the desired
in the epidemic spread
build the desired mashup
let pi be the
throughout the above we
pi be the probability
the above we noted
be the probability that
above we noted requirements
the probability that a
probability that a site
that a site remains
a site remains susceptible
not touched by the
we now summarize them
touched by the epidemic
now summarize them below
after the ith round
the ith round of
ith round of the
round of the protocol
these needs are seen
needs are seen in
are seen in many
a site remains susceptible
seen in many settings
site remains susceptible after
remains susceptible after the
susceptible after the i
we believe them to
believe them to be
them to be typical
th round if it
to be typical of
round if it was
be typical of most
if it was susceptible
typical of most soc
it was susceptible after
of most soc applications
was susceptible after the
susceptible after the ith
after the ith cycle
the ith cycle and
we would like to
ith cycle and it
would like to enable
cycle and it is
like to enable a
and it is not
to enable a non
it is not contacted
is not contacted by
not contacted by any
the count wraps back
programmer to rapidly develop
contacted by any infectious
to rapidly develop a
by any infectious site
any infectious site in
count wraps back to
rapidly develop a new
infectious site in the
develop a new collaborative
site in the i
a new collaborative application
new collaborative application by
collaborative application by composing
application by composing together
by composing together and
composing together and customizing
together and customizing preexisting
and customizing preexisting components
we would like to
would like to be
like to be able
to be able to
be able to overlay
able to overlay data
to overlay data from
relation that we obtain
overlay data from multiple
that we obtain is
data from multiple sources
potentially in different formats
obtained using different protocols
using different protocols and
different protocols and inconsistent
protocols and inconsistent interfaces
we would like to
would like to be
like to be able
to be able to
be able to dynamically
able to dynamically customize
to dynamically customize the
dynamically customize the application
customize the application at
since infection starts with
the application at runtime
infection starts with one
starts with one site
for any randomly chosen
any randomly chosen site
randomly chosen site p
inconsistency detection as a
detection as a function
by incorporating new data
incorporating new data sources
as a function of
new data sources or
data sources or changing
sources or changing the
or changing the way
changing the way data
the way data is
way data is presented
as a function of
a function of the
function of the rate
of the rate of
the rate of gossip
and without disrupting system
without disrupting system operation
we start by exploring
we can predict the
we would like to
can predict the delay
start by exploring the
would like to be
predict the delay before
like to be able
the delay before a
to be able to
delay before a typical
by exploring the importance
be able to accommodate
before a typical process
able to accommodate new
exploring the importance of
a typical process that
to accommodate new types
typical process that has
accommodate new types of
process that has been
new types of data
that has been disrupted
the importance of the
types of data sources
has been disrupted by
been disrupted by a
importance of the cluster
disrupted by a failure
new formats or protocols
by a failure will
formats or protocols that
a failure will learn
of the cluster structure
or protocols that we
failure will learn about
protocols that we may
will learn about inconsistency
that we may not
the cluster structure by
learn about inconsistency introduced
we may not have
about inconsistency introduced by
may not have anticipated
inconsistency introduced by the
cluster structure by varying
not have anticipated at
introduced by the failure
have anticipated at the
by the failure and
anticipated at the time
structure by varying the
the failure and can
at the time the
failure and can initiate
the time the system
time the system was
by varying the parameter
and can initiate repair
the system was released
varying the parameter of
data might be published
the parameter of the
if the model predicts
might be published by
the model predicts that
parameter of the pareto
be published by the
model predicts that for
published by the individual
by the individual users
predicts that for a
that for a given
for a given gossip
a given gossip rate
and it might be
of the pareto distribution
a broken chain should
it might be necessary
broken chain should be
might be necessary for
chain should be repaired
be necessary for the
should be repaired within
necessary for the users
for the users to
the users to exchange
users to exchange their
to exchange their data
exchange their data without
their data without access
data without access to
without access to a
access to a centralized
to a centralized repository
we vary the pareto
vary the pareto parameter
one can anticipate that
data may be obtained
can anticipate that the
may be obtained using
anticipate that the disruption
the pareto parameter from
be obtained using different
that the disruption associated
obtained using different types
using different types of
the disruption associated with
different types of network
types of network protocols
disruption associated with a
associated with a failure
with a failure should
a failure should be
and the type of
failure should be limited
the type of the
should be limited to
type of the physical
be limited to the
of the physical network
limited to the maximum
the physical network or
to the maximum number
physical network or protocols
the maximum number of
network or protocols may
maximum number of updates
or protocols may not
number of updates that
protocols may not be
of updates that would
may not be known
updates that would be
not be known in
that would be sent
be known in advance
would be sent to
be sent to a
sent to a given
to a given subservice
a given subservice during
given subservice during a
it should be possible
should be possible to
be possible to rapidly
possible to rapidly compose
to rapidly compose the
rapidly compose the application
compose the application using
the application using whatever
application using whatever communication
using whatever communication infrastructure
whatever communication infrastructure is
communication infrastructure is currently
infrastructure is currently available
users may be mobile
may be mobile or
be mobile or temporarily
mobile or temporarily disconnected
if we know how
we know how large
know how large the
how large the typical
large the typical update
the typical update is
and the topology of
the topology of the
topology of the network
of the network and
the network and its
network and its characteristics
and we know the
and its characteristics might
we know the size
its characteristics might change
know the size limit
characteristics might change over
the size limit on
might change over time
size limit on data
limit on data sent
on data sent in
data sent in response
sent in response to
the system should be
system should be easily
in response to explicit
should be easily reconfigurable
response to explicit requests
in this experiment we
the requirements outlined above
we can predict the
requirements outlined above might
can predict the amount
this experiment we are
outlined above might seem
predict the amount of
above might seem hard
the amount of time
might seem hard to
amount of time that
seem hard to satisfy
experiment we are only
of time that will
time that will be
we are only interested
that will be needed
the solution is surprisingly
will be needed to
solution is surprisingly simple
be needed to repair
are only interested in
needed to repair the
to repair the resulting
only interested in detection
our analysis motivates a
repair the resulting data
analysis motivates a component
the resulting data inconsistency
these capabilities should help
capabilities should help the
in which the web
should help the developer
which the web services
help the developer parameterize
the web services and
the developer parameterize the
web services and hosted
so we choose the
developer parameterize the cluster
services and hosted content
we choose the abort
parameterize the cluster to
and hosted content are
choose the abort strategy
the cluster to balance
hosted content are modeled
cluster to balance overhead
content are modeled as
to balance overhead for
are modeled as reusable
balance overhead for gossip
modeled as reusable overlayed
overhead for gossip against
as reusable overlayed information
for gossip against repair
reusable overlayed information layers
gossip against repair times
overlayed information layers backed
against repair times desired
information layers backed by
repair times desired by
layers backed by customizable
times desired by the
backed by customizable transport
desired by the application
by customizable transport layers
a graph of components
membership some readers may
a collaborative application is
some readers may be
collaborative application is a
readers may be curious
application is a forest
shows the ratio of
may be curious about
be curious about what
a set of such
curious about what will
set of such graphs
the ratio of inconsistencies
about what will seem
what will seem to
our vision demands a
ratio of inconsistencies detected
will seem to be
vision demands a new
seem to be a
demands a new kind
to be a chicken
of inconsistencies detected by
a new kind of
new kind of soc
inconsistencies detected by t
kind of soc standard
on the one hand
in order to facilitate
order to facilitate the
to facilitate the side
we use gossip epidemics
use gossip epidemics to
gossip epidemics to propagate
epidemics to propagate information
to propagate information about
propagate information about membership
side coexistence of components
cache compared to the
information about membership changes
coexistence of components that
compared to the total
of components that might
yet the gossip protocol
components that might today
that might today be
the gossip protocol uses
might today be implemented
to the total number
gossip protocol uses membership
today be implemented as
protocol uses membership information
the total number of
be implemented as proprietary
uses membership information to
implemented as proprietary minibrowsers
membership information to select
total number of potential
information to select gossip
number of potential inconsistencies
to select gossip peers
if we enable components
we enable components to
enable components to talk
components to talk to
to talk to oneanother
our solution starts with
we need to agree
solution starts with approximate
need to agree on
starts with approximate membership
to agree on the
with approximate membership information
agree on the events
on the events and
the events and representation
events and representation that
and representation that the
extracted from a group
representation that the dialog
from a group management
that the dialog will
a group management service
the dialog will employ
group management service component
management service component that
service component that list
component that list the
the decoupling of functionality
that list the nodes
decoupling of functionality into
list the nodes in
of functionality into layers
the nodes in the
functionality into layers also
nodes in the cluster
into layers also suggests
in the cluster and
layers also suggests a
the cluster and the
also suggests a need
cluster and the rough
suggests a need for
and the rough mapping
a need for a
the rough mapping of
need for a standardized
rough mapping of services
for a standardized layering
mapping of services to
of services to those
services to those nodes
in the examples above
and then refines this
then refines this with
refines this with incremental
one can identify at
this with incremental updates
can identify at least
identify at least four
a different concern relates
different concern relates to
concern relates to behavior
relates to behavior when
the linkage layer that
to behavior when membership
linkage layer that talks
behavior when membership information
layer that talks to
when membership information is
that talks to the
membership information is perceived
talks to the underlying
information is perceived differently
to the underlying data
is perceived differently at
the underlying data source
perceived differently at different
differently at different nodes
the update generating and
although such a condition
update generating and interpreting
such a condition may
generating and interpreting layer
a condition may arise
condition may arise during
may arise during transitional
arise during transitional periods
and the transport protocol
these quickly resolve as
quickly resolve as additional
resolve as additional rounds
as additional rounds of
the distribution is almost
we propose that this
additional rounds of gossip
propose that this decoupling
distribution is almost uniform
rounds of gossip replace
that this decoupling be
of gossip replace stale
is almost uniform across
this decoupling be done
gossip replace stale data
almost uniform across the
decoupling be done using
replace stale data with
uniform across the object
be done using event
stale data with more
data with more accurate
across the object set
a natural way of
natural way of thinking
way of thinking about
of thinking about components
thinking about components that
about components that dates
we have never observed
components that dates back
have never observed a
that dates back to
never observed a membership
dates back to smalltalk
observed a membership inconsistency
a membership inconsistency that
membership inconsistency that persisted
and the inconsistency detection
inconsistency that persisted for
that persisted for longer
rather than having the
persisted for longer than
than having the data
for longer than a
the inconsistency detection ratio
having the data center
longer than a few
the data center developer
than a few hundred
data center developer offer
a few hundred milliseconds
inconsistency detection ratio is
center developer offer content
developer offer content through
the ssa is quite
offer content through proprietary
ssa is quite tolerant
content through proprietary minibrowser
detection ratio is low
is quite tolerant of
through proprietary minibrowser interface
quite tolerant of short
ratio is low the
is low the dependency
she would define an
customuserserviceapp heartbeatmonitor gossiper subserviceprocess
would define an event
heartbeatmonitor gossiper subserviceprocess chainlink
low the dependency lists
gossiper subserviceprocess chainlink subservicecontrol
based interface between transport
subserviceprocess chainlink subservicecontrol nonblockingtransport
interface between transport and
the dependency lists are
between transport and information
transport and information layers
dependency lists are too
the visual events delivered
lists are too small
visual events delivered by
events delivered by the
are too small to
delivered by the transport
the component stack of
by the transport could
component stack of one
too small to hold
stack of one subservice
the transport could then
of one subservice process
small to hold all
transport could then be
could then be delivered
to hold all relevant
then be delivered to
be delivered to an
hold all relevant information
delivered to an information
failure and recovery process
to an information layer
and recovery process failure
an information layer responsible
recovery process failure detection
information layer responsible for
process failure detection is
layer responsible for visualizing
failure detection is accomplished
responsible for visualizing them
detection is accomplished by
is accomplished by means
accomplished by means of
by means of two
means of two mechanisms
at the other extreme
detecting fifo channels that
fifo channels that break
user mouse and keyboard
in our case they
mouse and keyboard events
our case they are
and keyboard events and
case they are tcp
keyboard events and pass
they are tcp channels
events and pass them
are tcp channels with
and pass them down
tcp channels with low
channels with low value
with low value for
low value for the
value for the so
for the so timeout
the so timeout property
with this type of
this type of event
either layer could easily
based heartbeat detection mechanism
layer could easily be
could easily be replaced
easily be replaced with
be replaced with a
replaced with a different
once a process is
with a different one
a process is deceased
the information is propagated
information is propagated within
is propagated within the
propagated within the group
within the group in
the group in two
group in two ways
peer protocols would also
protocols would also be
the distribution is so
would also be encapsulated
the process that has
also be encapsulated within
distribution is so spiked
process that has detected
be encapsulated within their
that has detected the
encapsulated within their respective
has detected the membership
within their respective transport
detected the membership change
their respective transport layers
the membership change feeds
is so spiked that
membership change feeds the
change feeds the event
so spiked that almost
feeds the event description
the event description into
one version of a
event description into the
spiked that almost all
description into the chain
version of a transport
into the chain itself
that almost all accesses
of a transport layer
this is delivered in
almost all accesses of
a transport layer could
is delivered in chain
transport layer could fetch
delivered in chain order
layer could fetch data
all accesses of a
in chain order to
could fetch data directly
accesses of a transaction
fetch data directly from
chain order to every
data directly from a
order to every non
of a transaction are
directly from a server
a transaction are within
faulty process and where
from a server in
transaction are within a
process and where necessary
are within a cluster
a server in a
server in a data
in a data center
chain repair procedure is
repair procedure is undertaken
whereas a different version
allowing for perfect inconsistency
the same detector process
a different version might
same detector process starts
different version might use
for perfect inconsistency detection
detector process starts up
version might use a
process starts up a
might use a peer
starts up a backup
up a backup gossip
a backup gossip notification
backup gossip notification stream
this is a fast
is a fast dying
we note that the
a fast dying epidemic
a reliable multicast protocol
note that the rate
it spreads rapidly but
that the rate of
it could leverage different
spreads rapidly but also
could leverage different type
rapidly but also dies
the rate of detected
leverage different type of
but also dies out
different type of hardware
also dies out rapidly
type of hardware or
rate of detected inconsistencies
of hardware or be
the fifo channels are
hardware or be optimized
of detected inconsistencies is
fifo channels are rebuilt
or be optimized for
channels are rebuilt appropriately
detected inconsistencies is so
be optimized for different
are rebuilt appropriately by
optimized for different types
rebuilt appropriately by the
inconsistencies is so high
for different types of
appropriately by the processes
is so high at
different types of workloads
by the processes that
so high at this
the processes that identify
processes that identify themselves
provided that the different
high at this point
that identify themselves to
that the different versions
identify themselves to be
the different versions of
themselves to be affected
at this point that
different versions of the
to be affected by
versions of the transport
be affected by the
this point that much
of the transport layer
affected by the membership
point that much of
the transport layer conform
by the membership change
transport layer conform to
that much of the
layer conform to the
conform to the same
much of the load
to the same standardized
and the group converges
the same standardized event
of the load goes
the group converges to
group converges to a
the load goes to
converges to a stable
load goes to the
to a stable configuration
the application could then
goes to the backend
application could then switch
to the backend database
could then switch between
the backend database and
then switch between them
update sources can use
switch between them as
backend database and saturates
between them as conditions
sources can use this
database and saturates it
them as conditions demand
can use this update
use this update to
this update to reconnect
update to reconnect to
to reconnect to a
reconnect to a new
to a new head
a new head of
new head of any
head of any chain
of any chain that
any chain that may
chain that may have
users interact through live
that may have lost
interact through live objects
reducing the overall throughput
may have lost its
through live objects that
have lost its previous
live objects that transform
lost its previous head
objects that transform actions
its previous head as
that transform actions into
previous head as a
transform actions into updates
head as a consequence
actions into updates that
as a consequence of
into updates that are
a consequence of the
updates that are communicated
consequence of the crash
that are communicated in
are communicated in the
communicated in the form
in the form of
the form of events
form of events that
of events that are
events that are shared
that are shared via
are shared via the
shared via the transport
via the transport layer
if a process wants
a process wants to
process wants to join
the protocol implemented by
protocol implemented by the
implemented by the transport
it starts by sending
by the transport layer
so far we have
starts by sending a
the transport layer might
by sending a request
transport layer might replicate
far we have considered
sending a request to
layer might replicate the
we have considered behavior
a request to a
might replicate the event
request to a random
have considered behavior with
to a random member
considered behavior with static
deliver it to the
a random member of
behavior with static clusters
it to the tablets
random member of the
to the tablets of
member of the group
the tablets of our
tablets of our rescue
of our rescue workers
and report it through
report it through the
it through the event
the group member will
group member will commence
member will commence a
will commence a membership
commence a membership change
based interface back to
a membership change protocol
interface back to the
over the entire run
membership change protocol as
back to the information
change protocol as described
the entire run of
to the information layer
protocol as described above
the information layer at
entire run of each
information layer at which
layer at which the
run of each experiment
at which the event
again once all the
of each experiment accesses
which the event has
once all the nodes
the event has originated
all the nodes receive
each experiment accesses are
the nodes receive the
experiment accesses are confined
nodes receive the membership
accesses are confined to
the transport layer with
receive the membership event
transport layer with the
the membership event and
are confined to the
layer with the embedded
confined to the same
membership event and update
with the embedded distributed
event and update their
the embedded distributed protocol
and update their view
embedded distributed protocol would
distributed protocol would behave
protocol would behave very
would behave very much
behave very much like
very much like an
much like an object
like an object in
an object in smalltalk
implementation details the framework
it would consume events
details the framework was
would consume events and
the framework was implemented
consume events and respond
framework was implemented using
events and respond with
was implemented using the
and respond with events
implemented using the java
using the java language
the java language and
java language and its
language and its non
this motivates thinking about
motivates thinking about communication
thinking about communication protocols
about communication protocols as
communication protocols as objects
in a real system
and indeed in treating
the system design was
indeed in treating them
system design was strongly
in treating them as
design was strongly influenced
treating them as objects
was strongly influenced by
them as objects much
strongly influenced by prior
as objects much as
influenced by prior work
objects much as we
by prior work on
much as we treat
prior work on highperformance
as we treat any
work on highperformance services
we treat any other
on highperformance services platforms
treat any other kind
and so if t
any other kind of
other kind of object
notably welsh s seda
kind of object in
welsh s seda architecture
of object in a
object in a language
in a language like
a language like java
language like java or
like java or in
java or in a
cache converges to maintain
or in a runtime
converges to maintain the
in a runtime environment
to maintain the correct
a runtime environment like
maintain the correct dependency
components are highly autonomous
runtime environment like jini
the correct dependency lists
environment like jini or
correct dependency lists as
dependency lists as clusters
lists as clusters change
there are only four
doing so unifies apparently
are only four distinct
so unifies apparently distinct
only four distinct control
unifies apparently distinct approaches
four distinct control threads
distinct control threads in
control threads in the
threads in the component
in the component stack
just as a remotely
our setup serves as
the component stack of
setup serves as a
as a remotely hosted
serves as a valid
a remotely hosted form
component stack of a
remotely hosted form of
as a valid quasi
stack of a process
hosted form of content
form of content such
of content such as
content such as a
such as a map
as a map or
a map or an
map or an image
or an image of
an image of a
image of a raincloud
of a raincloud can
a raincloud can be
raincloud can be modeled
namely one for the
can be modeled as
one for the non
be modeled as an
for the non blocking
modeled as an object
the non blocking transport
so can network protocols
can network protocols be
network protocols be treated
protocols be treated as
we investigate the convergence
the tcp chain and
investigate the convergence of
be treated as objects
the convergence of t
tcp chain and for
chain and for the
and for the heartbeat
for the heartbeat component
p systems try to
systems try to make
try to make everything
to make everything a
make everything a p
cache when clusters change
the ssa is roughly
when clusters change over
clusters change over time
but in the examples
in the examples we
the examples we ve
examples we ve seen
several kinds of content
kinds of content would
of content would more
since the dependency lists
content would more naturally
the dependency lists of
would more naturally be
dependency lists of the
more naturally be hosted
lists of the objects
of the objects are
the objects are updated
objects are updated using
are updated using lru
d images of terrain
images of terrain and
of terrain and buildings
the dependency list of
dependency list of an
list of an object
on the other hand
of an object o
an object o tends
soc applications are likely
applications are likely to
object o tends to
are likely to embody
likely to embody quite
o tends to include
to embody quite a
embody quite a range
tends to include those
quite a range of
a range of p
to include those objects
include those objects that
those objects that are
each separate video object
objects that are frequently
that are frequently accessed
are frequently accessed together
frequently accessed together with
accessed together with o
may have its own
have its own associated
its own associated update
own associated update stream
dependencies in a new
if one thinks of
one thinks of these
in a new cluster
thinks of these as
of these as topics
a new cluster automatically
these as topics in
as topics in publish
new cluster automatically push
cluster automatically push out
automatically push out dependencies
an application could have
push out dependencies that
application could have many
out dependencies that are
could have many such
dependencies that are now
have many such topics
that are now outside
are now outside the
and the application instance
now outside the cluster
the application instance running
application instance running on
instance running on a
running on a given
on a given user
a given user s
given user s machine
user s machine could
s machine could simultaneously
machine could simultaneously display
could simultaneously display data
simultaneously display data from
display data from several
data from several topics
we have previously said
have previously said that
previously said that we
said that we d
that we d like
we d like to
d like to think
like to think of
to think of protocols
think of protocols as
we perform an experiment
of protocols as objects
perform an experiment where
an experiment where accesses
it now becomes clear
now becomes clear that
experiment where accesses suddenly
becomes clear that further
where accesses suddenly become
clear that further precision
accesses suddenly become clustered
that further precision is
further precision is needed
the objects aren t
objects aren t merely
aren t merely protocols
initially accesses are uniformly
but in fact are
accesses are uniformly at
in fact are individual
are uniformly at random
fact are individual protocol
uniformly at random from
are individual protocol instances
at random from the
random from the entire
our system will need
from the entire set
system will need to
will need to simultaneously
need to simultaneously support
to simultaneously support potentially
simultaneously support potentially large
support potentially large numbers
potentially large numbers of
large numbers of transport
numbers of transport objects
of transport objects running
transport objects running concurrently
objects running concurrently in
running concurrently in the
concurrently in the end
in support of a
support of a variety
of a variety of
a variety of applications
variety of applications and
of applications and uses
all of this leads
of this leads to
this leads to new
leads to new challenges
the obvious one was
obvious one was mentioned
one was mentioned earlier
today s web services
s web services don
web services don t
services don t support
don t support p
then at a single
at a single moment
a single moment they
contemporary web services solutions
single moment they become
web services solutions presume
services solutions presume a
moment they become perfectly
solutions presume a client
they become perfectly clustered
become perfectly clustered into
server style of interaction
perfectly clustered into clusters
clustered into clusters of
with data relayed through
into clusters of size
data relayed through a
relayed through a message
even if clients are
if clients are connected
clients are connected to
are connected to one
transactions are aborted on
are aborted on detecting
if they lose connectivity
aborted on detecting an
they lose connectivity to
on detecting an inconsistency
lose connectivity to the
connectivity to the broker
they can t collaborate
we use a transaction
another serious issue arises
use a transaction rate
serious issue arises if
a transaction rate of
issue arises if the
transaction rate of approximately
arises if the clients
if the clients don
the clients don t
clients don t trust
don t trust the
t trust the data
trust the data center
sensitive data will need
data will need to
will need to be
need to be encrypted
the problem here is
problem here is that
here is that web
is that web services
that web services security
web services security standards
services security standards tend
security standards tend to
standards tend to trust
tend to trust the
to trust the web
trust the web services
the web services platform
web services platform itself
the standards offer no
standards offer no help
offer no help at
no help at all
help at all if
at all if we
all if we need
if we need to
we need to provide
need to provide end
end encryption mechanisms while
encryption mechanisms while also
mechanisms while also preventing
while also preventing the
also preventing the hosted
preventing the hosted services
the hosted services from
hosted services from seeing
services from seeing the
from seeing the keys
we encounter debilitating latency
encounter debilitating latency and
debilitating latency and throughput
latency and throughput issues
hosted services will be
services will be performance
limiting bottlenecks when used
bottlenecks when used in
shows the percentage of
when used in settings
the percentage of transactions
used in settings with
percentage of transactions that
in settings with large
of transactions that commit
settings with large numbers
transactions that commit and
with large numbers of
that commit and are
large numbers of clients
commit and are consistent
as we will see
we will see in
will see in our
see in our experimental
in our experimental section
we are left with
are left with a
left with a mixture
with a mixture of
a mixture of good
mixture of good and
of good and bad
good and bad news
web services standardize client
services standardize client access
standardize client access to
client access to hosted
access to hosted services
to hosted services and
the percentage of transactions
hosted services and data
percentage of transactions that
of transactions that commit
we can easily build
transactions that commit but
can easily build some
that commit but are
easily build some form
commit but are inconsistent
build some form of
some form of multiframed
form of multiframed web
of multiframed web page
multiframed web page that
web page that could
page that could host
that could host each
could host each kind
host each kind of
each kind of information
kind of information in
of information in its
information in its own
in its own minibrowser
when connectivity is adequate
relaying data via a
data via a hosted
via a hosted service
and the percentage of
a hosted service has
the percentage of transactions
hosted service has many
percentage of transactions that
service has many of
of transactions that abort
has many of the
many of the benefits
of the benefits of
the benefits of a
benefits of a publishsubscribe
of a publishsubscribe architecture
such as robustness as
as robustness as the
robustness as the set
as the set of
the set of clients
set of clients changes
the natural way to
natural way to think
way to think of
to think of our
think of our application
of our application is
our application is as
application is as an
is as an object
but web services provide
web services provide no
services provide no support
provide no support for
no support for this
support for this kind
for this kind of
this kind of client
kind of client application
of client application development
our solution may perform
solution may perform very
as seen by the
may perform very poorly
seen by the entire
by the entire chain
or fail if the
fail if the hosted
if the hosted services
the hosted services are
hosted services are inaccessible
all data will probably
data will probably be
will probably be visible
probably be visible to
be visible to the
visible to the hosted
to the hosted services
the hosted services unless
hosted services unless the
services unless the developer
unless the developer uses
the developer uses some
developer uses some sort
uses some sort of
some sort of non
using live objects for
live objects for soc
objects for soc applications
for soc applications cornell
soc applications cornell s
applications cornell s live
cornell s live objects
s live objects platform
live objects platform supports
objects platform supports componentized
layered mashup creation and
mashup creation and sharing
and overcomes limitations of
overcomes limitations of existing
limitations of existing web
of existing web technologies
experimental results and validation
the major design aspects
major design aspects are
design aspects are as
aspects are as follows
the developer starts by
developer starts by creating
or gaining access to
a collection of components
each component is an
component is an object
is an object that
an object that supports
object that supports live
that supports live functionality
and exposes eventbased interfaces
exposes eventbased interfaces by
eventbased interfaces by which
interfaces by which it
the tests reported here
by which it interacts
tests reported here employ
which it interacts with
reported here employ a
it interacts with other
here employ a hard
interacts with other components
components representing hosted content
the ssa is a
representing hosted content sensors
abort evict retry behavior
hosted content sensors and
evict retry behavior on
content sensors and actuators
retry behavior on inconsistency
ssa is a work
sensors and actuators renderers
behavior on inconsistency detection
and actuators renderers that
is a work in
a work in progress
actuators renderers that graphically
renderers that graphically depict
that graphically depict events
graphically depict events replication
depict events replication protocols
events replication protocols synchronization
fledged system will use
replication protocols synchronization protocols
system will use a
protocols synchronization protocols folders
will use a software
synchronization protocols folders containing
use a software partitioning
protocols folders containing sets
a software partitioning mechanism
folders containing sets of
software partitioning mechanism based
containing sets of objects
partitioning mechanism based on
sets of objects display
mechanism based on the
of objects display interfaces
based on the web
objects display interfaces that
on the web services
display interfaces that visualize
the web services request
interfaces that visualize folders
web services request invocation
services request invocation model
mashups of components are
of components are represented
although extracting the partitioning
components are represented as
extracting the partitioning key
are represented as a
the partitioning key from
represented as a kind
partitioning key from incoming
as a kind of
key from incoming requests
a kind of xml
from incoming requests will
kind of xml web
incoming requests will impose
of xml web pages
requests will impose some
will impose some overhead
each describing a recipe
we do not expect
describing a recipe for
do not expect performance
a recipe for obtaining
not expect performance of
recipe for obtaining and
expect performance of the
for obtaining and parameterizing
performance of the full
obtaining and parameterizing components
and parameterizing components that
parameterizing components that will
components that will serve
fledged system to deviate
that will serve as
system to deviate significantly
will serve as layers
to deviate significantly from
serve as layers of
deviate significantly from what
as layers of the
significantly from what is
layers of the composed
from what is reported
of the composed mashup
what is reported below
we call such an
call such an xml
such an xml page
an xml page a
xml page a live
page a live object
a live object reference
references can be distributed
can be distributed as
be distributed as files
http or other means
an soc application is
soc application is created
application is created by
is created by building
created by building a
by building a forest
building a forest consisting
a forest consisting of
forest consisting of graphs
consisting of graphs of
of graphs of references
graphs of references that
of references that are
references that are mashed
that are mashed together
an automated tool lets
automated tool lets the
tool lets the developer
lets the developer drag
the developer drag and
developer drag and drop
drag and drop to
and drop to combine
drop to combine references
to combine references for
combine references for individual
references for individual objects
for individual objects into
individual objects into an
objects into an xml
into an xml mashup
an xml mashup of
xml mashup of references
mashup of references describing
of references describing a
references describing a graph
describing a graph of
a graph of objects
update injection time against
injection time against delivery
checks mashups to verify
time against delivery time
mashups to verify that
against delivery time at
to verify that they
delivery time at node
verify that they compose
that they compose correctly
s accesses are uniformly
accesses are uniformly at
are uniformly at random
d visualization of an
visualization of an airplane
of an airplane may
an airplane may need
airplane may need to
may need to be
need to be connected
to be connected to
be connected to a
connected to a source
to a source of
a source of gps
source of gps and
of gps and other
gps and other orientation
and other orientation data
which in turn needs
in turn needs to
turn needs to run
needs to run over
to run over a
run over a data
over a data replication
a data replication protocol
data replication protocol with
the efficacy of t
replication protocol with specific
protocol with specific reliability
ordering or security properties
cache as a function
as a function of
a function of the
when activated on a
function of the strategy
activated on a user
of the strategy taken
on a user s
the strategy taken for
a user s machine
strategy taken for handling
taken for handling detected
for handling detected inconsistencies
an xml mashup yields
xml mashup yields a
mashup yields a graph
yields a graph of
a graph of interconnected
graph of interconnected proxies
a proxy is a
proxy is a piece
is a piece of
a piece of running
piece of running code
of running code that
running code that may
code that may render
of the uncommitable tranasctions
or transform visual content
encapsulate a protocol stack
and evict and retry
evict and retry reduce
and retry reduce the
retry reduce the rate
reduce the rate of
the rate of uncommitable
component in the xml
rate of uncommitable transactions
in the xml mashup
of uncommitable transactions to
the xml mashup produces
uncommitable transactions to about
xml mashup produces an
mashup produces an associated
produces an associated proxy
the hierarchy of proxies
hierarchy of proxies reflects
of proxies reflects the
proxies reflects the hierarchical
reflects the hierarchical structure
the hierarchical structure of
hierarchical structure of the
structure of the xml
of the xml mashup
update delay as seen
an object proxy can
delay as seen by
object proxy can initialize
as seen by individual
proxy can initialize itself
seen by individual processes
can initialize itself by
the middle portion is
initialize itself by copying
middle portion is committed
itself by copying the
portion is committed transactions
by copying the state
is committed transactions that
copying the state from
committed transactions that are
the state from some
transactions that are inconsistent
state from some active
from some active proxy
our platform assists with
and the top portion
platform assists with this
the top portion is
assists with this sort
top portion is aborted
with this sort of
portion is aborted transactions
this sort of state
sort of state transfer
the object proxies then
object proxies then become
proxies then become active
for example by relaying
example by relaying events
by relaying events from
relaying events from sensors
events from sensors into
from sensors into a
sensors into a replica
or by receiving events
by receiving events and
receiving events and reacting
events and reacting to
and reacting to them
our experiments were conducted
experiments were conducted using
were conducted using the
conducted using the ssa
using the ssa framework
the ssa framework deployed
ssa framework deployed on
by redisplaying an aircraft
framework deployed on a
deployed on a tightly
on a tightly coupled
a tightly coupled homogeneous
tightly coupled homogeneous cluster
coupled homogeneous cluster of
our approach shares certain
approach shares certain similarities
shares certain similarities with
certain similarities with the
similarities with the existing
with the existing web
the existing web development
existing web development model
the nodes are connected
nodes are connected by
are connected by two
in the sense that
connected by two separate
the sense that it
by two separate high
sense that it uses
two separate high speed
that it uses hierarchical
separate high speed ethernet
it uses hierarchical xml
high speed ethernet backbone
uses hierarchical xml documents
speed ethernet backbone planes
hierarchical xml documents to
xml documents to define
documents to define the
to define the content
we experimented with several
experimented with several configurations
on the other hand
some placed the control
placed the control traffic
we depart from some
depart from some of
the control traffic on
from some of the
control traffic on a
some of the de
traffic on a different
on a different switched
a different switched ethernet
facto stylistic standards that
different switched ethernet segment
stylistic standards that have
switched ethernet segment while
standards that have emerged
ethernet segment while others
segment while others aggregated
while others aggregated both
others aggregated both the
for example if one
aggregated both the control
example if one pulls
both the control traffic
if one pulls a
the control traffic and
one pulls a minibrowser
control traffic and the
pulls a minibrowser from
traffic and the data
a minibrowser from google
and the data traffic
minibrowser from google earth
the data traffic on
data traffic on the
traffic on the same
on the same segment
it expects to interact
expects to interact directly
to interact directly with
interact directly with the
directly with the end
no significant differences were
with the end user
significant differences were observed
and includes embedded javascript
but this may be
includes embedded javascript that
this may be because
embedded javascript that handles
may be because our
javascript that handles such
be because our control
that handles such interactions
because our control traffic
our control traffic consisted
control traffic consisted mainly
traffic consisted mainly of
consisted mainly of fast
the same functionality would
same functionality would be
functionality would be represented
which put little stress
would be represented as
put little stress on
be represented as a
little stress on the
represented as a mashup
stress on the communication
as a mashup of
on the communication channels
a mashup of a
mashup of a component
of a component that
a component that fetches
in the future we
component that fetches maps
the future we hope
that fetches maps and
future we hope to
fetches maps and similar
we hope to explore
maps and similar content
hope to explore scenarios
and similar content with
to explore scenarios that
similar content with a
explore scenarios that generate
content with a second
scenarios that generate exceptionally
with a second component
that generate exceptionally heavy
a second component that
generate exceptionally heavy control
second component that provides
exceptionally heavy control traffic
component that provides the
that provides the visualization
provides the visualization interface
which would allow us
would allow us to
although the term mashup
allow us to explore
the term mashup may
us to explore the
term mashup may sound
to explore the benefits
mashup may sound static
explore the benefits of
the benefits of isolation
benefits of isolation of
of isolation of that
in the sense of
isolation of that traffic
the sense of having
of that traffic with
sense of having its
that traffic with respect
of having its components
traffic with respect to
having its components predetermined
with respect to data
respect to data traffic
this is not necessarily
is not necessarily the
not necessarily the case
in the interest of
the interest of brevity
interest of brevity we
one kind of live
of brevity we did
kind of live object
brevity we did not
of live object could
we did not perform
live object could be
did not perform any
object could be a
not perform any experiments
could be a folder
perform any experiments to
be a folder including
any experiments to evaluate
a folder including a
folder including a set
experiments to evaluate the
including a set of
to evaluate the load
a set of objects
evaluate the load balancing
the load balancing component
load balancing component but
balancing component but we
component but we plan
for example extracted from
but we plan to
example extracted from a
we plan to do
extracted from a directory
plan to do so
from a directory in
to do so in
a directory in a
do so in the
directory in a file
so in the future
in a file system
a file system or
file system or pulled
system or pulled from
or pulled from a
pulled from a database
all the experiments involved
from a database in
the experiments involved a
a database in response
experiments involved a single
database in response to
involved a single partitioned
in response to a
a single partitioned and
response to a query
single partitioned and replicated
partitioned and replicated service
when the folder contents
the folder contents change
for ease of exposition
the mashup is dynamically
this service implements a
mashup is dynamically updated
service implements a simple
implements a simple wall
as might occur when
might occur when a
occur when a rescue
when a rescue worker
a rescue worker enters
the service itself maintains
rescue worker enters a
service itself maintains the
worker enters a building
itself maintains the time
enters a building or
a building or turns
building or turns a
or turns a corner
with updates coming from
updates coming from client
coming from client applications
from client applications that
client applications that read
applications that read a
that read a high
live objects can easily
objects can easily support
can easily support applications
easily support applications that
quality clock and send
support applications that dynamically
clock and send the
applications that dynamically recompute
and send the current
that dynamically recompute the
send the current value
dynamically recompute the set
recompute the set of
the set of visible
set of visible objects
as processes forward updates
processes forward updates along
forward updates along the
updates along the chain
as a function of
a function of location
function of location and
they will track the
of location and orientation
will track the clock
track the clock themselves
and dynamically add or
dynamically add or remove
all of our partitioning
add or remove them
of our partitioning scenarios
perfectly clustered synthetic workload
or remove them from
our partitioning scenarios included
clustered synthetic workload where
remove them from the
partitioning scenarios included at
synthetic workload where the
them from the mashup
workload where the clusters
scenarios included at least
where the clusters shift
included at least four
the clusters shift by
a rescuer would automatically
at least four subservices
rescuer would automatically and
would automatically and instantly
automatically and instantly be
and instantly be shown
and each subservice included
instantly be shown the
each subservice included between
be shown the avatars
shown the avatars of
the avatars of others
avatars of others who
of others who are
others who are already
who are already working
are already working at
already working at that
working at that site
marked by vertical lines
and be able to
we expect these to
be able to participate
expect these to be
able to participate in
these to be typical
to participate in conference
to be typical cases
be typical cases for
typical cases for real
cases for real deployments
for real deployments of
real deployments of the
deployments of the ssa
it should be noted
point dialog with them
should be noted that
be noted that small
s access is unclustered
noted that small subservice
through chat objects that
that small subservice sizes
chat objects that run
objects that run over
that run over multicast
run over multicast protocol
and as a result
over multicast protocol objects
as a result the
a result the dependency
result the dependency lists
this model can support
the dependency lists are
can result in degenerate
model can support a
result in degenerate behavior
can support a wide
dependency lists are useless
in degenerate behavior and
support a wide variety
degenerate behavior and are
a wide variety of
behavior and are not
wide variety of collaboration
and are not appropriate
variety of collaboration and
only few inconsistencies are
are not appropriate configurations
of collaboration and coordination
not appropriate configurations for
few inconsistencies are detected
collaboration and coordination paradigms
appropriate configurations for the
configurations for the ssa
for the ssa architecture
the live objects platform
live objects platform makes
objects platform makes it
platform makes it easy
makes it easy for
it easy for a
easy for a non
mapping between service processes
between service processes and
programmer to create the
service processes and physical
to create the needed
processes and physical nodes
create the needed soc
the needed soc application
in order to avoid
of the transactions that
the rescue coordinator pulls
the transactions that commit
order to avoid os
rescue coordinator pulls prebuilt
to avoid os resource
coordinator pulls prebuilt object
transactions that commit have
avoid os resource contention
pulls prebuilt object references
that commit have witnessed
prebuilt object references from
commit have witnessed inconsistent
we experimented with groups
have witnessed inconsistent data
object references from a
experimented with groups of
references from a folder
each corresponding to a
corresponding to a desired
to a desired kind
a desired kind of
desired kind of information
accesses become perfectly clustered
would correspond to objects
correspond to objects that
to objects that point
objects that point to
that point to a
point to a web
to a web service
a web service over
web service over the
service over the network
we see fast improvement
by convention the head
see fast improvement of
convention the head of
fast improvement of inconsistency
the head of the
improvement of inconsistency detection
head of the chain
of the chain for
peer objects would implement
the chain for each
objects would implement chat
chain for each group
would implement chat windows
for each group was
each group was called
the inconsistency rate drops
group was called node
inconsistency rate drops as
rate drops as the
drops as the abort
as the abort rate
the abort rate rises
event interfaces allow such
abort rate rises this
and all update requests
interfaces allow such objects
all update requests for
rate rises this is
allow such objects to
update requests for a
rises this is desired
such objects to coexist
requests for a partition
objects to coexist in
for a partition were
to coexist in a
a partition were routed
coexist in a shared
partition were routed towards
in a shared display
were routed towards this
a shared display window
routed towards this node
shared display window that
this is desired as
display window that can
is desired as well
since delivery delays in
window that can pan
delivery delays in the
delays in the chain
in the chain were
the chain were measured
the overall rate of
chain were measured relative
overall rate of consistent
jump to new locations
rate of consistent committed
were measured relative to
of consistent committed transactions
measured relative to node
consistent committed transactions drops
committed transactions drops because
transactions drops because the
the relative advantages and
drops because the probability
relative advantages and disadvantages
because the probability of
all the statistics pertaining
advantages and disadvantages of
the statistics pertaining to
and disadvantages of our
statistics pertaining to the
disadvantages of our model
pertaining to the group
of our model can
to the group disregarded
our model can be
the group disregarded node
the probability of conflicts
model can be summarized
probability of conflicts in
can be summarized as
of conflicts in the
be summarized as follows
we simulated two classes
conflicts in the clustered
simulated two classes of
in the clustered scenario
like other modern web
two classes of failures
the clustered scenario is
other modern web development
clustered scenario is higher
modern web development tools
at some time t
some time t one
our platform supports drag
time t one process
to illustrate more realistic
illustrate more realistic behavior
drop style of development
we use clustered accesses
use clustered accesses that
clustered accesses that slowly
accesses that slowly drift
the system must detect
easy creation of content
system must detect the
transactions are perfectly clustered
must detect the failure
as in the previous
repair the broken fifo
the resulting solutions are
in the previous experiment
the broken fifo channel
resulting solutions are easy
solutions are easy to
are easy to share
minutes the cluster structure
by selecting appropriate transport
the cluster structure shifts
selecting appropriate transport layers
cluster structure shifts by
the failed process recovers
failed process recovers and
process recovers and rejoins
recovers and rejoins the
functionality such as coordination
and rejoins the chain
such as coordination between
as coordination between searchers
coordination between searchers can
between searchers can remain
the join protocol would
searchers can remain active
join protocol would run
can remain active even
remain active even if
active even if connectivity
even if connectivity to
if connectivity to the
and the previously failed
connectivity to the data
the previously failed node
to the data center
previously failed node would
the data center is
failed node would become
data center is disrupted
node would become the
would become the new
become the new tail
the new tail of
new tail of the
tail of the chain
streams of video or
of video or sensor
video or sensor data
or sensor data can
the scenario is intended
sensor data can travel
scenario is intended to
data can travel directly
is intended to model
can travel directly and
intended to model a
travel directly and won
to model a common
directly and won t
model a common case
and won t be
a common case in
won t be delayed
common case in which
t be delayed by
case in which the
be delayed by the
in which the failure
delayed by the need
which the failure detection
by the need to
the failure detection mechanism
the need to ricochet
failure detection mechanism senses
need to ricochet off
detection mechanism senses a
to ricochet off a
mechanism senses a transient
ricochet off a remote
senses a transient problem
off a remote and
a remote and potentially
remote and potentially inaccessible
and potentially inaccessible server
a node that has
node that has become
that has become overloaded
based interoperability standards are
has become overloaded or
interoperability standards are needed
become overloaded or is
overloaded or is unresponsive
or is unresponsive for
is unresponsive for some
unresponsive for some other
for some other reason
we could lose access
such as garbage collection
could lose access to
lose access to some
access to some of
and wrapping back to
to some of the
wrapping back to zero
some of the sophisticated
and does not respond
of the sophisticated proprietary
does not respond to
the sophisticated proprietary interactive
not respond to the
back to zero after
sophisticated proprietary interactive functionality
respond to the heartbeat
proprietary interactive functionality optimized
to the heartbeat within
interactive functionality optimized for
the heartbeat within the
functionality optimized for proprietary
heartbeat within the accepted
optimized for proprietary minibrowser
within the accepted window
based solutions with an
solutions with an embedded
with an embedded javascript
by reconfiguring the chain
the load on node
load on node drops
and the problem will
peer communication can be
the problem will eventually
communication can be much
problem will eventually resolve
can be much harder
be much harder to
much harder to use
harder to use than
it then requests a
to use than relaying
the objects dependency lists
use than relaying data
objects dependency lists are
than relaying data through
then requests a rejoin
dependency lists are outdated
relaying data through a
data through a hosted
through a hosted service
a node crash that
a hosted service that
node crash that results
hosted service that uses
this leads to a
crash that results in
service that uses an
that results in a
that uses an enterprise
results in a reboot
uses an enterprise service
in a reboot would
an enterprise service bus
a reboot would result
leads to a sudden
reboot would result in
to a sudden increased
would result in similar
a sudden increased inconsistency
result in similar behavior
sudden increased inconsistency rate
increased inconsistency rate that
inconsistency rate that converges
rate that converges back
that converges back to
the lack of a
converges back to zero
lack of a one
of a one size
all the nodes in
a one size fits
the nodes in the
one size fits all
nodes in the subservice
size fits all publish
in the subservice remain
until this convergence is
the subservice remain operational
this convergence is interrupted
subscribe substrate forces the
convergence is interrupted by
substrate forces the developers
is interrupted by the
but one of them
interrupted by the next
forces the developers to
one of them becomes
the developers to become
of them becomes overloaded
by the next shift
developers to become familiar
to become familiar with
become familiar with and
causing the tcp link
familiar with and choose
the tcp link to
with and choose between
tcp link to the
and choose between a
link to the upstream
choose between a range
to the upstream node
between a range of
the upstream node to
a range of different
upstream node to become
range of different and
node to become congested
of different and incompatible
to become congested and
different and incompatible options
become congested and starving
congested and starving downstream
and starving downstream nodes
an wrong choice of
wrong choice of transport
choice of transport could
which begin to miss
of transport could result
begin to miss updates
transport could result in
b presented three possible
could result in degraded
presented three possible strategies
result in degraded qos
this scenario models a
three possible strategies for
scenario models a behavior
possible strategies for the
models a behavior common
strategies for the cache
or even data loss
a behavior common in
for the cache to
behavior common in experiments
the cache to deal
common in experiments on
cache to deal with
in experiments on our
to deal with inconsistency
second life as a
deal with inconsistency detection
life as a soc
experiments on our cluster
as a soc application
a soc application up
soc application up to
application up to now
when a node becomes
a node becomes very
node becomes very busy
we have focused on
becomes very busy or
have focused on a
very busy or the
focused on a small
busy or the communication
or the communication subsystem
the communication subsystem becomes
communication subsystem becomes heavily
subsystem becomes heavily loaded
but our longer term
our longer term goal
tcp at the node
longer term goal is
at the node upstream
term goal is to
the node upstream from
goal is to support
node upstream from it
is to support a
upstream from it will
to support a large
from it will sense
it will sense congestion
will sense congestion and
sense congestion and reduce
congestion and reduce its
scale nextgeneration collaboration system
and reduce its window
nextgeneration collaboration system similar
reduce its window size
collaboration system similar to
aborting and evicting value
system similar to second
similar to second life
if the impacted node
the impacted node is
impacted node is in
node is in the
is in the middle
a virtual reality immersion
in the middle of
virtual reality immersion system
the middle of the
reality immersion system created
middle of the chain
immersion system created by
system created by linden
created by linden labs
it ceases to relay
ceases to relay updates
or does so after
does so after long
second life is implemented
so after long delays
life is implemented with
is implemented with a
implemented with a data
through when possible as
with a data center
when possible as in
a data center including
hence downstream nodes fall
data center including a
downstream nodes fall behind
possible as in cache
center including a large
as in cache miss
including a large number
a large number of
large number of servers
number of servers storing
the chain replication scheme
of servers storing the
chain replication scheme slows
servers storing the state
replication scheme slows to
storing the state of
scheme slows to a
the state of the
slows to a crawl
state of the virtual
of the virtual world
we will now compare
the locations of all
will now compare their
the ssa benefits from
locations of all users
now compare their efficacies
ssa benefits from its
benefits from its gossip
from its gossip repair
its gossip repair mechanisms
we use the approximate
use the approximate clusters
the approximate clusters workload
which route missing updates
approximate clusters workload with
route missing updates around
missing updates around the
updates around the slow
around the slow node
then move about and
move about and interact
about and interact with
and interact with others
route them to that
them to that node
one can create a
when it recovers and
can create a cybercaf
it recovers and needs
a window size of
recovers and needs to
and needs to repair
needs to repair its
to repair its state
a pareto parameter of
knowing that gossip will
as other second life
that gossip will kick
other second life users
gossip will kick in
second life users enter
life users enter the
users enter the room
and the maximum dependency
an upstream node can
they can interact with
the maximum dependency list
upstream node can deliberately
can interact with the
node can deliberately drop
interact with the environment
can deliberately drop updates
maximum dependency list size
with the environment and
deliberately drop updates on
dependency list size is
the environment and one
drop updates on congested
list size is set
updates on congested tcp
size is set to
on congested tcp connections
in the second life
the second life architecture
we used our wall
whenever an avatar moves
an avatar moves or
clock service to evaluate
avatar moves or performs
service to evaluate the
moves or performs some
to evaluate the behavior
or performs some action
evaluate the behavior of
performs some action in
the behavior of the
some action in the
behavior of the overall
action in the virtual
of the overall system
in the virtual world
the overall system in
the lower portion of
overall system in various
lower portion of the
system in various scenarios
portion of the graph
in various scenarios and
of the graph is
a request describing this
various scenarios and with
request describing this event
scenarios and with different
describing this event is
and with different parameters
the graph is the
this event is passed
graph is the ratio
event is passed to
is the ratio of
a stream of updates
the ratio of committed
stream of updates of
ratio of committed transactions
of updates of various
of committed transactions that
updates of various rates
committed transactions that the
is passed to the
of various rates is
passed to the hosting
various rates is injected
to the hosting data
rates is injected into
the hosting data center
is injected into the
hosting data center and
injected into the head
transactions that the abort
data center and processed
into the head of
that the abort strategy
center and processed by
the head of the
and processed by servers
the abort strategy provides
head of the chain
processed by servers running
abort strategy provides a
by servers running there
strategy provides a significant
provides a significant improvement
a significant improvement over
significant improvement over a
clients do perform a
improvement over a normal
do perform a variety
for groups of nodes
perform a variety of
a variety of decoding
variety of decoding and
of decoding and rendering
decoding and rendering functions
and rendering functions locally
established point in time
but the data center
as the strategy detects
the data center must
a victim node receives
data center must be
victim node receives a
center must be in
node receives a command
must be in the
receives a command that
be in the loop
a command that forces
the strategy detects and
in the loop to
command that forces it
the loop to ensure
that forces it to
loop to ensure that
forces it to halt
to ensure that all
strategy detects and aborts
ensure that all users
detects and aborts over
the node continues to
that all users observe
node continues to listen
all users observe consistent
continues to listen for
users observe consistent state
to listen for commands
listen for commands that
for commands that would
commands that would restart
that would restart it
when the number of
the number of users
of all inconsistent transactions
number of users in
all inconsistent transactions that
of users in a
inconsistent transactions that would
this is accomplished by
users in a scenario
is accomplished by having
transactions that would have
in a scenario isn
accomplished by having node
a scenario isn t
that would have been
scenario isn t huge
would have been committed
send a crash command
a crash command to
second life can easily
crash command to the
but the other strategies
life can easily keep
command to the victim
can easily keep up
to the victim node
the other strategies make
easily keep up using
the victim node once
keep up using a
victim node once a
other strategies make further
node once a certain
strategies make further improvements
once a certain number
up using a standard
a certain number of
using a standard workload
certain number of updates
a standard workload partitioning
evict reduces uncommittable transactions
standard workload partitioning scheme
reduces uncommittable transactions to
number of updates were
workload partitioning scheme in
of updates were injected
partitioning scheme in which
updates were injected into
scheme in which different
were injected into the
in which different servers
injected into the chain
which different servers handle
different servers handle different
servers handle different portions
handle different portions of
different portions of the
of its value with
portions of the virtual
its value with abort
of the virtual world
this indicates that violating
the victim node will
victim node will stop
node will stop participating
will stop participating in
stop participating in the
participating in the normal
in the normal protocol
for example because large
the normal protocol and
example because large numbers
normal protocol and will
because large numbers of
protocol and will handle
large numbers of users
and will handle only
numbers of users want
will handle only wakeup
of users want to
handle only wakeup commands
users want to enter
cache entries are likely
only wakeup commands from
want to enter the
wakeup commands from this
entries are likely to
to enter the same
commands from this moment
are likely to be
enter the same virtual
from this moment onwards
likely to be repeat
the same virtual discotheque
to be repeat offenders
the chain detects the
chain detects the failure
the servers can become
servers can become overwhelmed
they are too old
repairs and announces the
can become overwhelmed and
are too old for
and announces the membership
become overwhelmed and are
too old for objects
announces the membership change
overwhelmed and are forced
old for objects that
and are forced to
for objects that are
are forced to reject
after a number of
objects that are likely
forced to reject some
a number of updates
to reject some of
number of updates have
reject some of the
that are likely to
of updates have been
some of the users
updates have been injected
of the users or
have been injected since
the users or reduce
been injected since the
users or reduce their
are likely to be
injected since the crash
or reduce their frame
likely to be accessed
since the crash command
to be accessed together
rendering rates and resolution
the crash command was
be accessed together with
crash command was issued
accessed together with them
together with them in
with them in future
second life might seem
them in future transactions
life might seem jumpy
sends a wakeup command
might seem jumpy and
a wakeup command to
seem jumpy and unrealistic
wakeup command to the
and so it is
command to the victim
so it is better
second life as a
it is better to
life as a live
to the victim node
as a live objects
is better to evict
a live objects application
better to evict them
live objects application poses
objects application poses some
application poses some new
poses some new challenges
retry reduces uncommittable transactions
reduces uncommittable transactions further
uncommittable transactions further to
on the one hand
transactions further to about
the victim node rejoins
victim node rejoins the
node rejoins the group
many aspects of the
aspects of the application
of the application can
the application can be
it has to catch
application can be addressed
has to catch up
can be addressed in
to catch up by
be addressed in the
catch up by obtaining
addressed in the same
up by obtaining copies
in the same manner
by obtaining copies of
of its value with
obtaining copies of updates
the same manner we
its value with abort
copies of updates that
same manner we ve
of updates that it
manner we ve outlined
updates that it has
we ve outlined for
that it has missed
ve outlined for the
outlined for the search
for the search and
the search and rescue
realistic workloads we now
search and rescue application
we experimentally determined that
workloads we now evaluate
we now evaluate the
now evaluate the efficacy
one could use microsoft
evaluate the efficacy of
repetitions of each experiment
could use microsoft virtual
of each experiment were
use microsoft virtual earth
each experiment were enough
the efficacy of t
experiment were enough to
were enough to yield
enough to yield accurate
to yield accurate measurements
yield accurate measurements with
cache with workloads based
as a source of
accurate measurements with low
with workloads based on
measurements with low variance
workloads based on two
d textures representing landscapes
based on two sampled
on two sampled topologies
two sampled topologies from
sampled topologies from the
topologies from the online
shows the update delivery
from the online retailer
the update delivery delay
the online retailer amazon
update delivery delay for
online retailer amazon and
delivery delay for a
in standards for creating
delay for a set
retailer amazon and the
standards for creating mashups
for a set of
for creating mashups could
a set of four
creating mashups could be
amazon and the social
set of four consecutive
mashups could be used
of four consecutive nodes
and the social network
could be used to
four consecutive nodes in
the social network orkut
be used to identify
consecutive nodes in a
used to identify sensors
nodes in a chain
to identify sensors and
identify sensors and other
sensors and other data
and other data sources
starting with the victim
with the victim node
which could then be
could then be wrapped
describes how we generated
then be wrapped as
how we generated these
be wrapped as live
we generated these workloads
wrapped as live objects
the chain length is
as live objects and
live objects and incorporated
objects and incorporated into
and incorporated into live
incorporated into live scenes
and we report on
we report on a
report on a gossip
measures the efficacy of
on top of this
on a gossip rate
the efficacy of t
a gossip rate of
streaming media sources such
media sources such as
cache on these workloads
sources such as video
on these workloads as
such as video cameras
these workloads as a
as video cameras mounted
workloads as a function
video cameras mounted at
as a function of
cameras mounted at street
a function of maximum
milliseconds at a steady
mounted at street level
function of maximum dependency
at a steady update
at street level in
a steady update injection
of maximum dependency list
street level in places
steady update injection rate
level in places such
update injection rate of
in places such as
maximum dependency list size
places such as tokyo
such as tokyo s
as tokyo s ginza
tokyo s ginza can
s ginza can be
and compares this to
ginza can be added
compares this to a
can be added to
this to a strategy
there are three anomalies
be added to create
are three anomalies that
to a strategy based
added to create realistic
three anomalies that can
to create realistic experience
a strategy based on
anomalies that can be
strategy based on ttls
that can be seen
the more complex issue
can be seen on
more complex issue is
be seen on the
complex issue is that
seen on the graphs
issue is that a
is that a search
that a search and
a search and rescue
the first one is
search and rescue application
first one is experienced
and rescue application can
compares the efficacy of
one is experienced by
rescue application can be
is experienced by the
application can be imagined
the efficacy of the
experienced by the victim
can be imagined as
efficacy of the three
by the victim node
be imagined as a
the victim node for
of the three strategies
imagined as a situational
victim node for updates
as a situational state
the three strategies of
node for updates injected
a situational state fully
for updates injected between
three strategies of dealing
situational state fully replicated
strategies of dealing with
state fully replicated across
of dealing with detected
fully replicated across all
dealing with detected inconsistencies
replicated across all of
across all of its
all of its users
seconds after the start
after the start of
the start of the
start of the experiment
all machines would see
machines would see all
the second is experienced
would see all the
second is experienced by
see all the state
is experienced by all
all the state updates
experienced by all the
we generated two workloads
by all the other
generated two workloads based
even if the user
all the other nodes
if the user is
the other nodes for
two workloads based on
the user is zoomed
other nodes for update
user is zoomed into
workloads based on real
nodes for update messages
is zoomed into some
for update messages injected
zoomed into some particular
update messages injected at
into some particular spot
messages injected at around
some particular spot within
based on real data
particular spot within the
spot within the overall
within the overall scene
seconds after the start
after the start of
the start of the
start of the experiment
one can contemplate such
can contemplate such an
while the third one
contemplate such an approach
the third one is
such an approach because
third one is a
an approach because the
one is a smaller
approach because the aggregate
is a smaller mixed
we started from a
because the aggregate amount
a smaller mixed burst
the aggregate amount of
smaller mixed burst for
aggregate amount of information
mixed burst for updates
amount of information might
burst for updates injected
of information might not
started from a snapshot
for updates injected at
information might not be
from a snapshot of
might not be that
a snapshot of amazon
not be that large
snapshot of amazon s
seconds into the experiment
of amazon s product
amazon s product co
note that the y
second life conceptually is
purchasing graph taken early
life conceptually is a
conceptually is a whole
axes have different scales
is a whole universe
have different scales to
different scales to observe
scales to observe how
unbounded in size and
to observe how the
in size and hence
observe how the system
size and hence with
how the system handles
and hence with different
the system handles the
hence with different users
system handles the transient
with different users in
handles the transient failure
different users in very
the transient failure better
users in very distinct
in very distinct parts
very distinct parts of
distinct parts of the
parts of the space
therefore the third anomaly
the third anomaly appears
third anomaly appears to
anomaly appears to grow
it would make no
appears to grow with
would make no sense
to grow with the
make no sense for
grow with the chain
no sense for every
with the chain distance
sense for every user
the chain distance from
for every user to
chain distance from the
every user to see
each product sold by
user to see every
product sold by the
distance from the victim
to see every event
sold by the online
from the victim node
by the online retailer
the online retailer is
online retailer is a
retailer is a node
the growth is not
we would solve this
is a node and
growth is not significant
would solve this problem
a node and each
solve this problem using
node and each pair
since the cause of
this problem using the
the cause of this
problem using the dynamic
cause of this anomaly
using the dynamic database
of this anomaly is
the dynamic database querying
this anomaly is an
dynamic database querying approach
and each pair of
anomaly is an artifact
database querying approach outlined
is an artifact of
querying approach outlined in
an artifact of java
approach outlined in section
artifact of java s
each pair of products
of java s garbage
pair of products purchased
java s garbage collection
of products purchased in
s garbage collection mechanism
each user would see
garbage collection mechanism kicking
user would see only
products purchased in a
collection mechanism kicking in
would see only the
purchased in a single
see only the objects
in a single user
as can be noted
only the objects within
a single user session
the objects within some
single user session is
objects within some range
user session is an
session is an edge
performed recovery for the
or within line of
recovery for the updates
within line of sight
for the updates it
the original graph contains
the updates it has
original graph contains more
updates it has missed
as a user moves
it has missed during
graph contains more than
a user moves about
has missed during the
missed during the period
during the period it
the period it was
period it was down
the platform would recompute
platform would recompute the
would recompute the query
recompute the query result
because the chain delivers
the chain delivers new
chain delivers new updates
and then update the
delivers new updates at
then update the display
new updates at the
update the display accordingly
updates at the moment
at the moment of
the moment of rejoin
all past updates were
past updates were solely
updates were solely recovered
were solely recovered by
solely recovered by means
that since some live
recovered by means of
since some live objects
by means of epidemics
some live objects uses
live objects uses p
the second anomaly that
p protocols that might
second anomaly that shows
protocols that might organize
anomaly that shows up
that might organize user
that shows up in
might organize user s
we used a snapshot
organize user s machines
used a snapshot of
shows up in the
user s machines into
up in the update
s machines into groups
a snapshot of the
in the update delivery
machines into groups forwarding
the update delivery delay
into groups forwarding streams
snapshot of the friendship
update delivery delay for
groups forwarding streams of
delivery delay for the
forwarding streams of data
delay for the nodes
of the friendship relations
streams of data to
for the nodes downstream
of data to one
the friendship relations graph
the nodes downstream from
data to one another
nodes downstream from the
friendship relations graph in
downstream from the victim
relations graph in the
we end up in
from the victim node
end up in a
the victim node reflects
up in a situation
victim node reflects the
in a situation where
node reflects the period
a situation where each
reflects the period when
graph in the orkut
situation where each user
the period when the
where each user belongs
period when the chain
each user belongs to
in the orkut social
when the chain is
user belongs to a
the orkut social network
the chain is broken
belongs to a potentially
to a potentially large
a potentially large number
potentially large number of
large number of such
number of such groups
during the time it
the time it took
time it took for
it took for the
took for the failure
and the groups that
for the failure detection
the groups that one
the failure detection mechanism
groups that one user
failure detection mechanism to
that one user is
detection mechanism to declare
one user is a
mechanism to declare the
user is a part
to declare the node
is a part of
declare the node deceased
a part of might
part of might be
of might be very
might be very different
to start up the
be very different from
start up the membership
very different from the
up the membership change
different from the groups
the membership change protocol
from the groups that
the groups that other
groups that other users
that other users belong
other users belong to
and for the membership
for the membership information
each user is a
the membership information to
user is a node
to support such a
membership information to propagate
is a node and
support such a model
a node and each
the chain is interrupted
node and each pair
chain is interrupted between
we need to be
and each pair of
is interrupted between node
need to be able
each pair of users
to be able to
pair of users with
be able to support
of users with a
able to support very
users with a friend
to support very large
and hence the updates
support very large numbers
with a friend relationship
hence the updates circumvent
very large numbers of
the updates circumvent the
large numbers of publish
updates circumvent the gap
a friend relationship is
circumvent the gap by
friend relationship is an
the gap by means
relationship is an edge
and with different users
gap by means of
with different users subscribed
by means of gossip
different users subscribed to
the original graph contains
users subscribed to very
original graph contains more
updates can bypass nodes
subscribed to very different
can bypass nodes in
to very different sets
bypass nodes in the
very different sets of
nodes in the chain
different sets of topics
in the chain using
graph contains more than
the chain using the
chain using the gossip
using the gossip as
up to now we
the gossip as it
gossip as it can
to now we have
as it can be
it can be seen
now we have been
can be seen in
be seen in the
we have been fairly
seen in the figure
have been fairly negative
been fairly negative about
fairly negative about the
but this phenomenon is
negative about the trend
this phenomenon is less
about the trend to
phenomenon is less likely
the trend to standardize
is less likely as
trend to standardize client
less likely as the
to standardize client access
likely as the node
standardize client access to
as the node receiving
client access to hosted
the node receiving the
access to hosted content
node receiving the update
to hosted content through
receiving the update is
hosted content through web
the update is farther
content through web minibrowsers
because the sampled topologies
through web minibrowsers that
update is farther away
the sampled topologies are
is farther away downstream
web minibrowsers that make
farther away downstream from
sampled topologies are large
minibrowsers that make the
topologies are large and
that make the javascript
are large and we
make the javascript running
large and we only
the javascript running on
away downstream from the
javascript running on a
downstream from the victim
running on a user
and we only need
from the victim node
we only need to
on a user s
only need to simulate
a user s machine
need to simulate a
user s machine virtually
to simulate a single
s machine virtually inseparable
contains an aggregated view
machine virtually inseparable from
an aggregated view of
virtually inseparable from the
simulate a single column
aggregated view of the
inseparable from the data
a single column of
view of the data
from the data center
single column of the
of the data in
column of the system
the data in figure
our core criticism was
of the system for
core criticism was that
the system for our
for the entire chain
criticism was that for
system for our purposes
was that for most
for our purposes one
that for most soc
at gossip rates of
our purposes one database
for most soc applications
purposes one database server
one database server and
database server and one
server and one cache
and one cache server
one cache server we
a minibrowser approach would
cache server we down
minibrowser approach would lack
approach would lack the
would lack the flexibility
lack the flexibility to
sample both graphs to
the flexibility to seamlessly
flexibility to seamlessly combine
to seamlessly combine content
seamlessly combine content from
combine content from different
milliseconds showing that the
content from different sources
showing that the behavior
that the behavior of
the behavior of the
behavior of the scheme
of the scheme is
and to customize the
the scheme is not
to customize the underlying
scheme is not a
customize the underlying communication
is not a fluke
the underlying communication substrate
we use a technique
use a technique based
note that the delay
a technique based on
that the delay of
our earlier concerns carry
the delay of the
earlier concerns carry over
technique based on random
concerns carry over to
based on random walks
carry over to the
on random walks that
delay of the updates
over to the second
of the updates delivered
to the second life
random walks that maintains
the second life scenario
the updates delivered at
walks that maintains important
updates delivered at the
that maintains important properties
delivered at the victim
maintains important properties of
at the victim node
important properties of the
the victim node is
d texture representing terrain
victim node is significantly
texture representing terrain in
node is significantly larger
properties of the original
is significantly larger than
representing terrain in some
significantly larger than that
of the original graph
terrain in some region
larger than that of
than that of the
that of the nodes
of the nodes downstream
the nodes downstream of
nodes downstream of it
downstream of it in
of it in the
it in the chain
in a minibrowser approach
we observed that even
observed that even with
that even with sufficiently
specifically clustering which is
even with sufficiently high
the minibrowser generates the
with sufficiently high gossip
clustering which is central
minibrowser generates the texture
sufficiently high gossip rate
which is central to
generates the texture from
is central to our
the texture from hosted
the only node to
central to our experiment
texture from hosted data
only node to experience
node to experience any
to experience any significant
we start by choosing
experience any significant inconsistency
start by choosing a
any significant inconsistency window
by choosing a node
significant inconsistency window is
choosing a node uniformly
inconsistency window is the
a node uniformly and
window is the node
this model makes it
node uniformly and random
is the node that
model makes it difficult
uniformly and random and
the node that failed
and random and start
random and start a
and start a random
start a random walk
note that when the
a random walk from
to superimpose other content
that when the failed
random walk from that
superimpose other content over
when the failed node
walk from that location
other content over the
the failed node rejoins
content over the texture
queries are performed against
are performed against its
performed against its data
against its data before
we would need to
its data before it
would need to rely
data before it has
need to rely on
before it has time
to rely on a
it has time to
rely on a hosting
has time to fully
on a hosting system
time to fully recover
a hosting system s
hosting system s mashup
the walk reverts back
system s mashup technology
walk reverts back to
once the chain is
s mashup technology to
reverts back to the
the chain is restored
mashup technology to do
back to the first
technology to do this
to the first node
all new updates are
the first node and
new updates are received
first node and start
node and start again
if we wanted to
we wanted to blend
there were rare cases
wanted to blend weather
were rare cases when
to blend weather information
this is repeated until
blend weather information from
is repeated until the
weather information from the
repeated until the target
information from the national
rare cases when gossip
from the national hurricane
cases when gossip circumvented
the national hurricane center
when gossip circumvented the
national hurricane center with
until the target number
gossip circumvented the chain
hurricane center with a
circumvented the chain replication
center with a google
the chain replication even
the target number of
with a google map
chain replication even though
target number of nodes
replication even though the
number of nodes have
the google map service
even though the chain
google map service would
though the chain was
map service would need
the chain was not
of nodes have been
service would need to
chain was not broken
would need to explicitly
nodes have been visited
need to explicitly support
to explicitly support this
but this happened only
explicitly support this sort
this happened only for
support this sort of
happened only for gossip
this sort of embedding
only for gossip rates
for gossip rates close
gossip rates close to
rates close to the
close to the update
to the update injection
the update injection rate
later in this section
in our second life
in this section we
our second life scenario
this section we will
section we will show
show a further down
we will show that
the visible portion of
will show that even
visible portion of the
show that even with
portion of the scene
that even with these
of the scene the
even with these rapid
with these rapid repairs
the scene the part
scene the part of
the part of the
the gossip overhead is
nodes to provide some
part of the texture
gossip overhead is actually
of the texture being
to provide some perception
the texture being displayed
provide some perception of
overhead is actually low
texture being displayed will
some perception of the
being displayed will often
perception of the topologies
displayed will often be
will often be controlled
often be controlled by
the graphs are visibly
be controlled by events
graphs are visibly clustered
controlled by events generated
by events generated by
events generated by other
generated by other live
the amazon topology more
by other live objects
amazon topology more so
other live objects that
of the messages were
live objects that share
topology more so than
the messages were delivered
objects that share the
messages were delivered by
that share the display
more so than the
share the display window
were delivered by gossip
so than the orkut
delivered by gossip ahead
than the orkut one
by gossip ahead of
perhaps under control of
gossip ahead of the
under control of users
ahead of the chain
control of users running
of the chain for
of users running on
the chain for gossip
users running on machines
chain for gossip rate
running on machines elsewhere
for gossip rate identical
on machines elsewhere in
gossip rate identical to
machines elsewhere in the
rate identical to the
elsewhere in the network
identical to the update
to the update injection
the update injection rate
its topology has a
topology has a more
has a more clustered
these remote sources won
a more clustered structure
remote sources won t
sources won t fit
won t fit into
t fit into the
and so the dependency
fit into the interaction
so the dependency lists
into the interaction model
contains a plot of
the interaction model expected
a plot of update
interaction model expected by
plot of update injection
model expected by the
the dependency lists hold
of update injection time
expected by the minibrowser
update injection time against
dependency lists hold more
injection time against update
lists hold more relevant
time against update delivery
hold more relevant information
against update delivery time
update delivery time for
delivery time for the
time for the victim
treating nodes of the
the size and shape
for the victim node
nodes of the graphs
size and shape of
of the graphs as
and shape of the
the graphs as database
shape of the display
ideally this is a
graphs as database objects
of the display window
this is a straight
the display window and
is a straight line
display window and other
a straight line because
window and other elements
transactions are likely to
straight line because of
and other elements of
are likely to access
other elements of the
likely to access objects
line because of chain
elements of the runtime
to access objects that
because of chain replication
of the runtime environment
access objects that are
the runtime environment should
note that once the
runtime environment should be
that once the victim
objects that are topologically
environment should be inherited
once the victim node
should be inherited from
the victim node recovers
that are topologically close
be inherited from the
are topologically close to
inherited from the hierarchy
topologically close to one
it gracefully catches up
from the hierarchy structure
gracefully catches up and
the hierarchy structure of
catches up and does
hierarchy structure of the
close to one another
up and does so
structure of the object
and does so quickly
of the object mashup
does so quickly for
for the online retailer
so quickly for both
the object mashup used
quickly for both gossip
object mashup used to
for both gossip rates
mashup used to create
it is likely that
both gossip rates identical
used to create the
gossip rates identical and
is likely that objects
to create the application
rates identical and half
likely that objects bought
identical and half the
that objects bought together
and half the update
objects bought together are
thus our texture should
half the update injection
bought together are also
our texture should learn
the update injection rate
texture should learn its
together are also viewed
should learn its size
are also viewed and
now consider the link
learn its size and
also viewed and updated
consider the link congestion
its size and orientation
viewed and updated together
the link congestion case
size and orientation and
and orientation and even
orientation and even the
and even the gps
even the gps coordinates
the gps coordinates on
gps coordinates on which
coordinates on which to
on which to center
which to center from
to center from the
center from the parent
viewing and buying a
from the parent object
and buying a toy
the parent object that
buying a toy train
parent object that hosts
a toy train and
object that hosts it
toy train and matching
train and matching rails
and similarly until we
similarly until we reach
until we reach the
we reach the root
reach the root object
for the social network
the root object hosting
root object hosting the
object hosting the display
hosting the display window
it is likely that
is likely that data
likely that data of
that data of befriended
a minibrowser isn t
data of befriended users
minibrowser isn t a
of befriended users are
isn t a component
befriended users are viewed
users are viewed and
are viewed and updated
viewed and updated together
it runs the show
despite all of the
all of the above
of the above criticism
minibrowsers retain one potential
retain one potential advantage
one potential advantage over
tagging a person in
potential advantage over the
a person in a
advantage over the layered
person in a picture
over the layered architecture
the layered architecture we
layered architecture we proposed
architecture we proposed earlier
commenting on a post
on a post by
a post by a
post by a friend
since all aspects of
by a friend s
all aspects of the
a friend s friend
aspects of the view
of the view are
the view are optimized
view are optimized to
or viewing one s
are optimized to run
viewing one s neighborhood
optimized to run together
the interaction controls might
we run a set
interaction controls might be
run a set of
controls might be far
a set of experiments
might be far more
be far more sophisticated
set of experiments similar
far more sophisticated and
of experiments similar to
more sophisticated and perform
experiments similar to the
sophisticated and perform potentially
similar to the t
and perform potentially much
perform potentially much better
potentially much better than
much better than a
better than a solution
than a solution resulting
a solution resulting from
varying cache entry ttl
solution resulting from mashing
cache entry ttl to
resulting from mashing up
entry ttl to evaluate
from mashing up together
ttl to evaluate the
mashing up together multiple
to evaluate the efficacy
up together multiple layers
evaluate the efficacy of
together multiple layers developed
the efficacy of this
multiple layers developed independently
efficacy of this method
of this method in
this method in reducing
method in reducing inconsistencies
in reducing inconsistencies and
reducing inconsistencies and the
inconsistencies and the corresponding
and the corresponding overhead
in many realistic examples
many realistic examples event
based interfaces could get
interfaces could get fairly
could get fairly complex
limiting ttl has detrimental
ttl has detrimental effects
and difficult for most
has detrimental effects on
difficult for most developers
detrimental effects on cache
for most developers to
effects on cache hit
most developers to work
on cache hit ratio
developers to work with
quickly increasing the database
increasing the database workload
this observation highlights the
observation highlights the importance
highlights the importance of
the importance of developing
by increasing database access
importance of developing component
increasing database access rate
of developing component interface
database access rate to
developing component interface and
access rate to more
component interface and event
rate to more than
interface and event standards
to more than twice
and event standards for
more than twice its
event standards for the
than twice its original
standards for the layered
twice its original load
for the layered architecture
its original load we
the layered architecture we
original load we only
layered architecture we ve
load we only observe
architecture we ve outlined
we only observe a
only observe a reduction
observe a reduction of
a reduction of inconsistencies
the task isn t
reduction of inconsistencies of
task isn t really
of inconsistencies of about
isn t really all
t really all that
really all that daunting
the designers of microsoft
designers of microsoft s
of microsoft s object
microsoft s object linking
s object linking and
object linking and embedding
this is more than
is more than twice
more than twice the
standard faced similar challenges
than twice the rate
twice the rate of
the rate of inconsistencies
rate of inconsistencies achieved
of inconsistencies achieved by
inconsistencies achieved by t
their ole interfaces are
ole interfaces are pervasively
cache for the retailer
interfaces are pervasively used
for the retailer workload
are pervasively used to
the retailer workload and
pervasively used to support
retailer workload and only
used to support thousands
workload and only slightly
to support thousands of
and only slightly better
support thousands of plugins
only slightly better than
thousands of plugins that
slightly better than the
of plugins that implement
better than the rate
plugins that implement context
than the rate of
that implement context menus
the rate of inconsistencies
rate of inconsistencies achieved
of inconsistencies achieved by
inconsistencies achieved by t
virtual folders and various
folders and various namespace
and various namespace extensions
cache for the social
for the social network
the social network workload
and drag and drop
drag and drop technologies
and with twice the
with twice the additional
twice the additional load
lacking the needed standards
the additional load on
additional load on the
load on the database
the live objects platform
we generate a transactional
live objects platform supports
generate a transactional workload
objects platform supports both
a transactional workload that
platform supports both options
transactional workload that accesses
supports both options today
workload that accesses products
that accesses products that
accesses products that are
products that are topologically
in addition to allowing
that are topologically close
addition to allowing hosted
to allowing hosted content
allowing hosted content to
hosted content to be
content to be pulled
to be pulled in
be pulled in and
we use random walks
pulled in and exposed
in and exposed via
and exposed via event
exposed via event interfaces
each transaction starts by
transaction starts by picking
starts by picking a
by picking a node
components developed by some
picking a node uniformly
developed by some of
a node uniformly at
by some of our
node uniformly at random
some of our users
uniformly at random and
of our users also
at random and takes
our users also use
users also use embedded
also use embedded minibrowsers
steps of a random
use embedded minibrowsers to
of a random walk
embedded minibrowsers to gain
minibrowsers to gain access
to gain access to
gain access to a
access to a wide
the nodes visited by
to a wide range
nodes visited by the
a wide range of
visited by the random
wide range of platforms
by the random walk
the random walk are
random walk are the
walk are the objects
are the objects the
the objects the transaction
objects the transaction accesses
update transactions first read
transactions first read all
first read all objects
read all objects from
all objects from the
objects from the database
and then update all
then update all objects
update all objects at
all objects at the
objects at the database
read transactions read the
transactions read the objects
read the objects directly
the objects directly from
performance evaluation central to
objects directly from the
evaluation central to our
directly from the cache
central to our argument
to our argument is
our argument is the
argument is the assertion
is the assertion that
the assertion that hosted
assertion that hosted event
that hosted event notification
hosted event notification solutions
event notification solutions scale
notification solutions scale poorly
solutions scale poorly and
in this section we
scale poorly and stand
this section we evaluate
poorly and stand as
section we evaluate t
and stand as a
stand as a barrier
as a barrier to
a barrier to collaboration
cache using the workloads
barrier to collaboration applications
using the workloads described
the workloads described above
and that developers will
we found that the
that developers will want
found that the abort
developers will want to
that the abort rate
will want to combine
the abort rate is
want to combine hosted
abort rate is negligible
to combine hosted content
rate is negligible in
combine hosted content with
is negligible in all
hosted content with p
negligible in all runs
p protocols to overcome
protocols to overcome these
efficacy is therefore defined
to overcome these problems
is therefore defined to
therefore defined to be
defined to be the
to be the ratio
in this section we
be the ratio of
the ratio of inconsistent
this section we present
ratio of inconsistent transactions
section we present data
of inconsistent transactions out
we present data to
inconsistent transactions out of
present data to support
transactions out of all
data to support our
out of all commits
to support our claims
the overhead of the
some of the results
overhead of the system
of the system is
the system is twofold
dependency list maintenance implies
list maintenance implies storage
maintenance implies storage and
implies storage and bandwidth
storage and bandwidth overhead
and bandwidth overhead at
are drawn from a
bandwidth overhead at both
drawn from a widely
overhead at both the
from a widely cited
at both the database
a widely cited industry
both the database and
widely cited industry whitepaper
the database and the
database and the cache
as well as compute
well as compute overhead
as compute overhead for
compute overhead for dependency
overhead for dependency list
for dependency list merging
dependency list merging at
list merging at the
merging at the server
at the server and
and were obtained using
the server and consistency
were obtained using a
server and consistency checks
obtained using a testing
and consistency checks at
using a testing methodology
consistency checks at the
a testing methodology and
checks at the cache
testing methodology and setup
methodology and setup developed
and setup developed and
setup developed and published
developed and published by
and published by sonic
published by sonic software
the storage required is
storage required is only
required is only for
is only for object
only for object ids
for object ids and
object ids and versions
and both updates and
both updates and checks
updates and checks are
and checks are o
update delay as seen
the remainder was produced
delay as seen by
remainder was produced in
as seen by individual
was produced in our
seen by individual processes
produced in our own
by individual processes during
in the number of
in our own experiments
individual processes during persistent
the number of objects
processes during persistent link
number of objects in
during persistent link congestion
of objects in the
persistent link congestion node
objects in the system
in the system and
the system and o
from the industry white
the industry white paper
analyzes the performance of
updates on upstream and
the performance of several
on upstream and downstream
performance of several commercial
upstream and downstream fifo
in the size of
of several commercial enterprise
and downstream fifo channels
several commercial enterprise service
the size of the
commercial enterprise service bus
size of the dependency
of the dependency lists
which is limited to
shown is the maximum
is the maximum throughput
the second and potentially
second and potentially more
and potentially more significant
potentially more significant overhead
more significant overhead is
significant overhead is the
overhead is the effect
is the effect on
the effect on cache
effect on cache hit
on cache hit ratio
cache hit ratio due
hit ratio due to
ratio due to evictions
due to evictions and
to evictions and hence
evictions and hence the
and hence the database
hence the database load
the experiment varies the
since cache load is
experiment varies the number
cache load is significantly
varies the number of
load is significantly larger
the number of subscribers
is significantly larger than
number of subscribers while
significantly larger than database
of subscribers while using
larger than database load
subscribers while using a
while using a single
using a single publisher
a single publisher that
single publisher that communicates
publisher that communicates through
that communicates through a
orders of magnitude for
communicates through a single
of magnitude for facebook
through a single hosted
a single hosted message
single hosted message broker
hosted message broker on
message broker on a
broker on a single
on a single topic
figured for message durability
even a minor deterioration
a minor deterioration in
even if a subscriber
minor deterioration in hit
if a subscriber experiences
deterioration in hit ratio
a subscriber experiences a
in hit ratio can
subscriber experiences a transient
hit ratio can yield
experiences a transient loss
ratio can yield a
a transient loss of
can yield a prohibitive
transient loss of connectivity
yield a prohibitive load
a prohibitive load on
prohibitive load on the
load on the backend
the publisher retains and
on the backend database
publisher retains and hence
retains and hence can
and hence can replay
hence can replay all
can replay all messages
c shows the experiment
as the number of
shows the experiment results
the number of subscribers
number of subscribers increases
each data point is
data point is the
point is the result
is the result of
the result of a
result of a single
of a single run
latency will also soars
we vary the dependency
will also soars because
vary the dependency list
also soars because the
the dependency list size
soars because the amount
dependency list size and
because the amount of
list size and for
the amount of time
size and for each
amount of time the
and for each value
of time the broker
for each value run
time the broker needs
inconsistency window against gossip
the broker needs to
window against gossip rate
broker needs to spend
against gossip rate at
each value run the
needs to spend sending
gossip rate at the
to spend sending a
rate at the failed
spend sending a single
value run the experiment
at the failed node
sending a single message
run the experiment for
a single message increases
the experiment for the
single message increases linearly
experiment for the two
message increases linearly with
for the two workloads
increases linearly with the
the two workloads and
linearly with the number
two workloads and measure
with the number of
workloads and measure the
the number of subscribers
and measure the average
measure the average values
the average values of
average values of these
values of these metrics
durability is often not
is often not required
cache is able to
is able to reduce
able to reduce inconsistencies
to reduce inconsistencies significantly
for the retailer workload
time between node failure
shows throughput in an
between node failure and
throughput in an experiment
node failure and rejoin
in an experiment in
failure and rejoin as
an experiment in which
and rejoin as number
experiment in which the
rejoin as number of
in which the publisher
as number of consecutive
which the publisher does
number of consecutive updates
the publisher does not
of consecutive updates missed
a single dependency reduces
publisher does not log
consecutive updates missed by
single dependency reduces inconsistencies
does not log data
updates missed by the
dependency reduces inconsistencies to
missed by the victim
by the victim node
a disconnected subscriber would
disconnected subscriber would experience
subscriber would experience a
would experience a loss
of their original value
we find that while
find that while the
that while the maximum
two dependencies reduce inconsistencies
while the maximum throughput
dependencies reduce inconsistencies to
the maximum throughput is
maximum throughput is much
throughput is much higher
the degradation of performance
degradation of performance is
of performance is even
performance is even more
of their original value
is even more dramatic
and three to less
three to less than
developers of collaboration applications
of collaboration applications that
collaboration applications that need
applications that need good
that need good scalability
need good scalability might
for the social network
good scalability might discover
the social network workload
scalability might discover that
might discover that hosted
discover that hosted esb
that hosted esb options
hosted esb options won
esb options won t
options won t achieve
won t achieve this
t achieve this goal
of the inconsistencies remain
we report on some
report on some experiments
in both workloads there
on some experiments we
both workloads there is
some experiments we conducted
workloads there is no
experiments we conducted on
there is no visible
we conducted on our
is no visible effect
conducted on our own
no visible effect on
on our own at
visible effect on cache
our own at cornell
effect on cache hit
on cache hit ratio
focusing on scalability of
on scalability of event
and hence no increased
scalability of event notification
hence no increased access
of event notification platforms
no increased access rate
event notification platforms that
increased access rate at
notification platforms that leverage
access rate at the
platforms that leverage peer
rate at the database
the reduction in inconsistency
peer techniques for dissemination
reduction in inconsistency ratio
in inconsistency ratio is
techniques for dissemination and
inconsistency ratio is significantly
for dissemination and recovery
ratio is significantly better
is significantly better for
significantly better for the
on the first graph
better for the next
for the next we
the next we compared
next we compared our
we compared our technique
compared our technique with
our technique with a
technique with a simple
with a simple approach
a simple approach in
simple approach in which
approach in which we
we compare the maximum
in which we limited
compare the maximum throughput
which we limited the
the maximum throughput of
we limited the life
maximum throughput of two
limited the life span
throughput of two decentralized
of two decentralized reliable
two decentralized reliable multicast
decentralized reliable multicast protocols
here inconsistencies are not
inconsistencies are not detected
but their probability of
their probability of being
probability of being witnessed
of being witnessed is
being witnessed is reduced
witnessed is reduced by
is reduced by having
a single topic and
reduced by having the
single topic and a
by having the cache
topic and a single
having the cache evict
and a single publisher
the cache evict entries
cache evict entries after
evict entries after a
unlike in the previous
entries after a certain
in the previous tests
after a certain period
a certain period even
certain period even if
period even if the
even if the database
if the database did
the database did not
database did not indicate
did not indicate they
not indicate they are
indicate they are invalid
these experiments used a
this limits the peak
limits the peak performance
the peak performance to
compares the efficacy of
the efficacy of the
efficacy of the abort
evict and retry policies
and retry policies with
retry policies with the
policies with the amazon
with the amazon and
the amazon and orkut
amazon and orkut workloads
in these experiments we
gossip chain inconsistency window
these experiments we use
experiments we use dependency
we use dependency lists
use dependency lists of
dependency lists of length
just as with the
as with the synthetic
with the synthetic workload
evicting conflicting transactions is
achieves stable high throughput
conflicting transactions is an
transactions is an effective
is an effective way
an effective way of
effective way of invalidating
way of invalidating stale
of invalidating stale objects
invalidating stale objects that
stale objects that might
objects that might cause
that might cause problems
might cause problems for
cause problems for future
problems for future transactions
runs at about a
at about a fifth
about a fifth that
a fifth that speed
the effects are more
effects are more pronounced
are more pronounced for
more pronounced for the
collapsing as the number
pronounced for the well
as the number of
the number of subscribers
number of subscribers increases
with the amazon workload
at small loss rates
abort is able to
is able to detect
latency in qsm is
in qsm is at
qsm is at the
is at the level
at the level of
of the inconsistent transactions
whereas with the less
clustered orkut workload it
orkut workload it only
workload it only detects
ms irrespectively of the
irrespectively of the number
of the number of
the number of subscribers
when the number of
the number of topics
number of topics is
of topics is varied
in both cases evict
qsm maintains its high
both cases evict reduces
maintains its high performance
cases evict reduces uncommittable
evict reduces uncommittable transactions
reduces uncommittable transactions considerably
on the second graph
relative to their value
to their value with
their value with abort
we report performance for
inconsistency window against gossip
with the amazon workload
window against gossip rate
the amazon workload and
against gossip rate for
gossip rate for the
rate for the whole
for the whole chain
but performance for other
performance for other group
for other group sizes
other group sizes is
group sizes is similar
in the amazon workload
jgroups performance was higher
performance was higher with
was higher with smaller
retry further reduces this
higher with smaller group
further reduces this value
with smaller group sizes
reduces this value to
but erodes as the
erodes as the number
as the number of
the number of topics
number of topics increases
of its value with
its value with abort
jgroups failed when we
failed when we attempted
when we attempted to
we attempted to configure
attempted to configure it
to configure it with
configure it with more
it with more than
r elated w ork
elated w ork a
time between node failure
between node failure and
node failure and rejoin
failure and rejoin as
and rejoin as number
rejoin as number of
as number of consecutive
recent years have seen
number of consecutive updates
years have seen a
of consecutive updates missed
have seen a surge
consecutive updates missed by
we look at two
updates missed by the
look at two scalable
seen a surge of
missed by the victim
at two scalable protocols
a surge of progress
by the victim node
two scalable protocols under
surge of progress in
scalable protocols under conditions
of progress in the
protocols under conditions of
progress in the development
under conditions of stress
in the development of
the development of scalable
development of scalable object
of scalable object stores
with a focus on
scalable object stores that
a focus on delivery
object stores that support
focus on delivery latency
stores that support transactions
some systems such as
as a fixed message
a fixed message rate
fixed message rate is
message rate is spread
rate is spread over
is spread over varying
spread over varying numbers
over varying numbers of
varying numbers of topics
subscribers each join some
each join some number
join some number of
some number of topics
a publisher sends data
publisher sends data at
sends data at a
data at a rate
at a rate of
inconsistency window against the
window against the ratio
against the ratio between
the ratio between injection
ratio between injection rate
between injection rate and
injection rate and gossip
rate and gossip rate
selecting the topic in
the topic in which
topic in which to
in which to send
which to send at
to send at random
different update injection delay
export novel consistency definitions
novel consistency definitions that
consistency definitions that allow
definitions that allow for
that allow for effective
allow for effective optimizations
s overload by dropping
several recent systems implement
overload by dropping updates
recent systems implement full
by dropping updates on
systems implement full fledged
dropping updates on its
implement full fledged atomicity
we see that ricochet
full fledged atomicity while
updates on its inbound
fledged atomicity while preserving
on its inbound and
atomicity while preserving the
its inbound and outbound
while preserving the system
inbound and outbound fifo
preserving the system s
and outbound fifo channels
the system s scalability
outbound fifo channels according
system s scalability with
fifo channels according to
a cornelldeveloped protocol for
channels according to a
cornelldeveloped protocol for low
s scalability with a
according to a random
scalability with a wide
to a random distribution
with a wide variety
a random distribution throughout
a wide variety of
random distribution throughout the
wide variety of workloads
distribution throughout the first
throughout the first three
the first three quarters
first three quarters of
three quarters of the
google s spanner utilizes
quarters of the experiment
s spanner utilizes accurate
spanner utilizes accurate clock
utilizes accurate clock synchronization
as the number of
the number of topics
number of topics increases
of topics increases to
by balakrishnan et al
is constructed on top
constructed on top of
on top of the
top of the scalable
of the scalable corfu
latency soars when we
soars when we repeat
when we repeat this
we repeat this with
repeat this with the
this with the industrystandard
with the industrystandard scalable
utilize a large set
the industrystandard scalable reliable
a large set of
industrystandard scalable reliable multicast
large set of independent
set of independent logs
and we report on
widely used for event
used for event notification
for event notification in
event notification in their
notification in their datacenters
as can be seen
can be seen in
be seen in the
seen in the graph
updates that were initially
srm s recovery latency
that were initially dropped
s recovery latency rises
were initially dropped and
recovery latency rises linearly
initially dropped and eventually
latency rises linearly in
dropped and eventually made
rises linearly in the
linearly in the figure
and eventually made their
eventually made their way
made their way through
use lock chains and
their way through gossip
lock chains and assume
way through gossip could
chains and assume transactions
scalability of commercial esbs
through gossip could later
of commercial esbs figure
and assume transactions are
gossip could later be
assume transactions are known
could later be sent
transactions are known in
later be sent via
are known in advance
be sent via fifo
scalability of commercial esbs
sent via fifo channels
of commercial esbs number
via fifo channels as
commercial esbs number of
fifo channels as shown
esbs number of topics
channels as shown by
these methods all scale
as shown by the
methods all scale well
shown by the increasingly
all scale well and
by the increasingly large
scale well and in
the increasingly large density
well and in many
increasingly large density of
and in many cases
large density of dark
in many cases allow
many cases allow databases
cases allow databases to
allow databases to accept
databases to accept loads
to accept loads similar
accept loads similar to
loads similar to those
similar to those handled
our experiments confirm that
to those handled by
plots closer to the
those handled by non
closer to the tail
hosted enterprise service bus
to the tail of
enterprise service bus architectures
the tail of the
service bus architectures can
tail of the chain
bus architectures can achieve
architectures can achieve high
can achieve high levels
achieve high levels of
high levels of publish
as before note that
they are not expected
before note that the
are not expected to
note that the yaxes
subscribe performance for small
that the yaxes have
not expected to disrupt
the yaxes have different
expected to disrupt the
yaxes have different scales
performance for small numbers
have different scales to
to disrupt the prevailing
for small numbers of
different scales to observe
small numbers of subscribers
disrupt the prevailing two
scales to observe the
to observe the delays
observe the delays better
but performance degrades very
performance degrades very sharply
degrades very sharply as
very sharply as the
sharply as the number
the figures show that
as the number of
figures show that even
the number of subscribers
note that we are
number of subscribers or
that we are addressing
of subscribers or topics
we are addressing the
show that even for
subscribers or topics grows
that even for a
are addressing the problem
even for a gossip
addressing the problem of
the jgroups and srm
for a gossip rate
the problem of read
jgroups and srm platforms
a gossip rate half
gossip rate half the
rate half the injection
half the injection rate
which don t leverage
only incoherent caches that
don t leverage peer
incoherent caches that respond
recall that this is
caches that respond to
that this is the
that respond to queries
this is the rate
respond to queries without
is the rate at
scale poorly in the
to queries without access
the rate at which
poorly in the number
queries without access to
rate at which digests
in the number of
without access to the
the number of subscribers
access to the backend
number of subscribers or
to the backend database
of subscribers or topics
are exchanged between two
exchanged between two or
between two or more
two or more processes
previous work on coherent
work on coherent caches
the epidemics could deliver
epidemics could deliver messages
could deliver messages with
scale well in these
deliver messages with a
well in these dimensions
messages with a delay
with a delay of
a delay of about
ricochet achieved the best
achieved the best recovery
the best recovery latency
best recovery latency when
recovery latency when message
latency when message loss
when message loss is
message loss is an
loss is an issue
but at relatively high
at relatively high overhead
not shown on these
shown on these graphs
s for the rest
qsm at small loss
for the rest of
at small loss rates
the rest of the
small loss rates achieves
rest of the chain
loss rates achieves similar
of the chain during
rates achieves similar average
the chain during a
achieves similar average latency
chain during a congestion
similar average latency with
during a congestion that
average latency with considerably
a congestion that took
latency with considerably lower
with considerably lower network
considerably lower network overheads
but if a packet
if a packet is
a packet is lost
supports transactions using locks
transactions using locks or
the plot also shows
it may take several
using locks or communication
plot also shows that
may take several seconds
locks or communication with
also shows that delays
take several seconds to
or communication with the
shows that delays increased
several seconds to recover
communication with the database
that delays increased with
with the database on
seconds to recover it
delays increased with time
the database on each
database on each transaction
making it less appropriate
therefore if congestion may
it less appropriate for
if congestion may span
less appropriate for time
congestion may span large
may span large periods
span large periods of
these techniques are not
large periods of time
techniques are not applicable
are not applicable in
we don t see
not applicable in our
don t see any
the gossip rate must
applicable in our scenario
t see any single
gossip rate must be
see any single winner
rate must be carefully
any single winner here
must be carefully tuned
be carefully tuned to
carefully tuned to compensate
tuned to compensate for
each of the solutions
to compensate for the
of the solutions tested
compensate for the losses
the solutions tested has
for the losses induced
solutions tested has some
the losses induced by
tested has some advantages
losses induced by the
has some advantages that
induced by the congested
some advantages that its
by the congested tcp
advantages that its competitors
the congested tcp channels
that its competitors lack
the second round of
second round of experiments
round of experiments quantified
we re currently developing
of experiments quantified the
re currently developing new
experiments quantified the average
currently developing new p
quantified the average and
the average and maximum
average and maximum inconsistency
and maximum inconsistency window
maximum inconsistency window for
inconsistency window for a
window for a service
it builds an overlay
under various update injection
builds an overlay multicast
various update injection rates
an overlay multicast tree
update injection rates and
overlay multicast tree within
injection rates and gossip
multicast tree within which
rates and gossip rates
tree within which events
and gossip rates respectively
within which events travel
we define the inconsistency
and is capable of
define the inconsistency window
is capable of selforganizing
the inconsistency window as
capable of selforganizing in
inconsistency window as the
of selforganizing in the
window as the time
selforganizing in the presence
as the time interval
in the presence of
the time interval during
the presence of firewalls
time interval during which
interval during which queries
during which queries against
which queries against the
queries against the service
against the service return
the service return a
service return a stale
return a stale value
a separate project is
shows that the inconsistency
separate project is creating
that the inconsistency window
project is creating a
the inconsistency window grows
is creating a protocol
inconsistency window grows slowly
creating a protocol suite
window grows slowly as
a protocol suite that
grows slowly as the
protocol suite that we
slowly as the gap
suite that we call
as the gap between
that we call the
the gap between the
we call the properties
gap between the update
call the properties framework
between the update injection
the update injection rate
update injection rate and
injection rate and the
rate and the gossip
and the gossip rate
the gossip rate widens
the graph s x
graph s x axis
s x axis represents
x axis represents the
axis represents the ratio
represents the ratio between
the goal is to
the ratio between the
goal is to offer
ratio between the update
is to offer strong
between the update injection
to offer strong forms
the update injection rate
offer strong forms of
update injection rate and
strong forms of reliability
injection rate and gossip
forms of reliability that
rate and gossip rate
of reliability that can
reliability that can be
that can be customized
can be customized for
be customized for special
customized for special needs
this confirms that epidemics
confirms that epidemics are
that epidemics are a
epidemics are a robust
are a robust tunable
speed and scalability are
a robust tunable mechanism
and scalability are only
robust tunable mechanism providing
scalability are only elements
tunable mechanism providing graceful
are only elements of
mechanism providing graceful degradation
only elements of a
elements of a broader
of a broader story
developers will need different
the inconsistency window shifts
will need different solutions
inconsistency window shifts in
need different solutions for
window shifts in accordance
different solutions for different
shifts in accordance with
solutions for different purposes
in accordance with the
accordance with the update
with the update injection
the update injection rate
by offering a flexible
offering a flexible yet
a flexible yet structured
flexible yet structured component
yet structured component mashup
structured component mashup environment
notice that the difference
that the difference between
the difference between the
live objects makes it
difference between the maximum
objects makes it possible
between the maximum inconsistency
makes it possible to
the maximum inconsistency window
it possible to create
maximum inconsistency window and
possible to create applications
inconsistency window and the
to create applications that
window and the average
create applications that mix
and the average inconsistency
applications that mix hosted
the average inconsistency window
that mix hosted with
average inconsistency window is
mix hosted with p
inconsistency window is two
window is two orders
is two orders of
two orders of magnitude
and that can adapt
that can adapt their
this reflects the degree
can adapt their behavior
reflects the degree to
the degree to which
degree to which the
to which the victim
which the victim node
the victim node lags
to achieve desired properties
victim node lags the
achieve desired properties in
node lags the other
desired properties in a
lags the other nodes
properties in a way
the other nodes during
in a way matched
other nodes during the
a way matched to
nodes during the period
way matched to the
during the period before
matched to the environment
the period before it
period before it has
before it has fully
it has fully caught
has fully caught up
next we evaluated the
we evaluated the inconsistency
evaluated the inconsistency window
scalability of qsm and
the inconsistency window of
of qsm and jgroups
inconsistency window of a
window of a service
of a service running
a service running at
throughput for various group
service running at a
for various group sizes
running at a particular
at a particular update
a particular update rate
and for three different
for three different intervals
three different intervals in
different intervals in which
intervals in which the
prior work the idea
in which the victim
work the idea of
which the victim node
the idea of integrating
the victim node is
idea of integrating web
victim node is halted
of integrating web services
integrating web services with
web services with peer
peer platforms is certainly
show average and maximum
platforms is certainly not
average and maximum inconsistency
is certainly not new
and maximum inconsistency windows
maximum inconsistency windows for
inconsistency windows for both
windows for both the
for both the victim
both the victim and
the victim and for
victim and for the
and for the other
for the other processes
the other processes of
other processes of one
processes of one subservice
the more messages the
more messages the victim
messages the victim node
the victim node needs
victim node needs to
node needs to recover
the larger the inconsistency
larger the inconsistency window
db access rate normed
again the difference between
the difference between the
difference between the average
between the average and
the average and maximum
average and maximum in
db access rate normed
hit ratio hit ratio
the existing work falls
existing work falls roughly
work falls roughly into
falls roughly into two
roughly into two categories
product a nity social
the first line of
a nity social network
first line of research
line of research is
of research is focused
research is focused on
is focused on the
focused on the use
on the use of
the use of peer
as a basis for
a basis for scalable
basis for scalable web
for scalable web service
scalable web service discovery
the second line of
second line of research
line of research concentrates
of research concentrates on
research concentrates on the
concentrates on the use
on the use of
the use of replication
use of replication protocols
of replication protocols at
replication protocols at the
protocols at the web
at the web service
the web service backend
web service backend to
service backend to achieve
backend to achieve fault
p platforms such as
platforms such as jxta
such as jxta are
as jxta are treated
jxta are treated not
are treated not as
treated not as means
not as means of
as means of collaboration
means of collaboration or
of collaboration or media
collaboration or media carrying
or media carrying live
media carrying live content
but rather as a
rather as a supporting
as a supporting infrastructure
a supporting infrastructure at
supporting infrastructure at the
infrastructure at the data
at the data center
the data center backend
our work is focused
work is focused on
is focused on blending
focused on blending the
on blending the content
blending the content available
the content available through
content available through p
p and web service
and web service protocols
neither technology is subordinate
technology is subordinate with
is subordinate with respect
subordinate with respect to
with respect to the
respect to the other
technologies that use peer
peer protocols to support
protocols to support live
to support live and
support live and interactive
live and interactive content
and interactive content have
interactive content have existed
content have existed earlier
an excellent example of
excellent example of such
example of such technology
of such technology is
such technology is the
technology is the croquet
delivery distribution for a
distribution for a chain
in which the entire
which the entire state
product a nity social
the entire state of
a nity social network
entire state of a
gossip rate left figure
state of a virtual
d world is stored
world is stored in
is stored in a
stored in a peer
peer fashion and updated
fashion and updated using
and updated using a
updated using a two
other work in this
work in this direction
in this direction includes
none of these systems
of these systems supports
these systems supports the
systems supports the sorts
on each graph left
supports the sorts of
each graph left bars
the sorts of componentized
graph left bars denote
left bars denote transient
bars denote transient failure
layered architectures that we
architectures that we have
that we have advocated
we have advocated here
the types of peer
right bars denote a
bars denote a transient
denote a transient failure
a transient failure corroborated
transient failure corroborated with
peer protocols these systems
failure corroborated with a
protocols these systems can
corroborated with a link
these systems can leverage
with a link congestion
a link congestion phenomenon
link congestion phenomenon modeled
congestion phenomenon modeled by
and the types of
the types of a
types of a traditional
of a traditional hosted
a traditional hosted content
traditional hosted content they
hosted content they can
content they can blend
they can blend with
can blend with their
blend with their p
message drop on the
drop on the adjacent
on the adjacent fifo
the adjacent fifo channels
adjacent fifo channels of
fifo channels of node
our platform is designed
platform is designed from
is designed from ground
designed from ground up
from ground up with
ground up with extensibility
up with extensibility in
with extensibility in mind
every part of it
part of it can
of it can be
it can be replaced
can be replaced and
be replaced and customized
and different components within
different components within a
components within a single
within a single mashup
a single mashup application
single mashup application can
mashup application can leverage
application can leverage different
can leverage different transport
leverage different transport protocols
prior work on typed
work on typed component
on typed component architectures
typed component architectures includes
component architectures includes a
architectures includes a tremendous
includes a tremendous variety
a tremendous variety of
limited cache entry ttl
tremendous variety of programming
cache entry ttl fig
variety of programming languages
of programming languages and
programming languages and platforms
including early languages such
early languages such as
languages such as smalltalk
such as smalltalk alongside
experiments with workloads based
as smalltalk alongside modern
with workloads based on
smalltalk alongside modern component
workloads based on a
based on a web
on a web retailer
based environments such as
a web retailer product
environments such as java
web retailer product affinity
retailer product affinity topology
product affinity topology and
affinity topology and a
topology and a social
and a social network
a social network topology
social network topology illustrated
network topology illustrated in
specialized component architectures such
component architectures such figure
scalability qsm and jgroups
throughput for various numbers
for various numbers of
various numbers of topics
compared against the alternative
against the alternative of
the alternative of reducing
alternative of reducing cache
of reducing cache entry
reducing cache entry time
for srm and ricochet
srm and ricochet with
and ricochet with varying
ricochet with varying numbers
with varying numbers of
varying numbers of topics
as mit s argus
data points are medians
mit s argus system
points are medians and
are medians and error
medians and error bars
and error bars bound
flexible protocol composition stacks
error bars bound the
protocol composition stacks such
composition stacks such as
stacks such as bast
oriented architectures such as
architectures such as juni
this could work well
could work well if
work well if a
well if a system
if a system has
a system has multiple
system has multiple classes
has multiple classes of
has been used in
multiple classes of objects
been used in the
used in the context
in the context of
the context of integrating
all clustered but with
context of integrating service
clustered but with different
but with different associated
with different associated clustering
different associated clustering properties
discussion of component integration
of component integration systems
component integration systems and
integration systems and their
systems and their relation
and their relation to
their relation to live
relation to live objects
is beyond the scope
beyond the scope of
the scope of this
scope of this paper
more details can be
details can be found
can be found in
consistent inconsistent aborted ab
inconsistent aborted ab ev
we found that less
aborted ab ev re
found that less than
ab ev re ab
much relevant prior work
ev re ab ev
relevant prior work consists
re ab ev re
prior work consists of
ab ev re i
work consists of the
ev re i i
consists of the scripting
re i i tr
of the scripting languages
i i tr tr
the scripting languages mentioned
i tr tr o
of the messages were
scripting languages mentioned in
the messages were delivered
languages mentioned in the
tr tr o o
messages were delivered by
mentioned in the discussion
were delivered by gossip
tr o o rt
in the discussion above
delivered by gossip for
o o rt ct
by gossip for the
o rt ct rt
gossip for the nodes
rt ct rt ct
for the nodes to
ct rt ct y
the nodes to the
rt ct y y
nodes to the left
ct y y amazon
to the left of
y y amazon orkut
the left of the
y amazon orkut fig
left of the victim
our belief is that
belief is that even
is that even though
that even though these
even though these languages
this confirms that gossip
though these languages are
confirms that gossip rarely
these languages are intended
that gossip rarely is
languages are intended for
the efficacy of t
gossip rarely is used
are intended for fairly
rarely is used to
intended for fairly general
is used to circumvent
for fairly general use
cache as a function
used to circumvent chain
as a function of
to circumvent chain replication
they have evolved to
circumvent chain replication in
a function of the
have evolved to focus
chain replication in the
evolved to focus on
replication in the normal
function of the inconsistency
to focus on minibrowser
in the normal case
focus on minibrowser situations
of the inconsistency handling
on minibrowser situations in
the inconsistency handling strategy
minibrowser situations in which
inconsistency handling strategy for
a peculiar effect is
situations in which the
handling strategy for realistic
peculiar effect is noticeable
in which the application
strategy for realistic workloads
effect is noticeable in
which the application lives
is noticeable in figure
the application lives within
application lives within a
lives within a dedicated
within a dedicated browser
a dedicated browser frame
much work has been
interacts directly with the
in that more messages
directly with the user
work has been done
that more messages are
has been done on
more messages are delivered
and cannot be mixed
been done on creating
messages are delivered via
cannot be mixed with
are delivered via gossip
be mixed with content
done on creating consistent
mixed with content from
on creating consistent caches
even in the prefix
with content from other
creating consistent caches for
in the prefix part
content from other sources
the prefix part of
consistent caches for web
from other sources in
prefix part of the
other sources in a
part of the chain
sources in a layered
caches for web servers
in a layered fashion
although the effect is
the effect is also
effect is also evident
is also evident in
live objects can support
also evident in the
objects can support minibrowsers
evident in the suffix
can support minibrowsers as
support minibrowsers as objects
it is more significant
is more significant on
but we ve argued
more significant on the
we ve argued that
significant on the left
ve argued that by
on the left hand
argued that by modeling
the left hand side
that by modeling hosted
left hand side figure
by modeling hosted content
modeling hosted content at
hosted content at a
where the gossip rate
content at a lower
the gossip rate is
at a lower level
gossip rate is higher
a lower level as
lower level as components
level as components that
as components that interact
because we observed this
components that interact via
we observed this phenomenon
that interact via events
observed this phenomenon only
interact via events and
this phenomenon only with
via events and focusing
phenomenon only with update
events and focusing on
only with update rates
and focusing on the
with update rates of
focusing on the multi
layered style of mashups
style of mashups as
of mashups as opposed
mashups as opposed to
as opposed to the
opposed to the standard
to the standard tiled
the standard tiled model
we suspect that the
suspect that the network
that the network stack
the network stack is
network stack is more
stack is more efficient
is more efficient in
more efficient in dealing
efficient in dealing with
in dealing with udp
dealing with udp packets
conclusions to build ambitious
with udp packets then
to build ambitious collaboration
udp packets then with
build ambitious collaboration application
packets then with tcp
then with tcp ones
with tcp ones under
tcp ones under heavy
ones under heavy load
the web services community
web services community will
services community will need
community will need ways
will need ways to
need ways to combine
content from multiple sources
these include hosted sources
include hosted sources that
hosted sources that run
sources that run in
that run in data
run in data centers
in data centers and
data centers and support
centers and support web
and support web services
support web services interfaces
but also direct peer
peer protocols capable of
protocols capable of transporting
capable of transporting audio
whiteboard data and other
data and other content
and other content at
delivery distribution for a
other content at high
distribution for a chain
content at high data
at high data rates
a further need is
further need is to
need is to allow
is to allow disconnected
to allow disconnected collaboration
back to data centers
and higher level objects
our review of the
review of the performance
of the performance of
the performance of enterprise
performance of enterprise service
of enterprise service bus
enterprise service bus eventing
service bus eventing solutions
bus eventing solutions in
eventing solutions in the
solutions in the standard
in the standard hosted
the standard hosted web
standard hosted web services
hosted web services model
web services model made
services model made it
model made it clear
made it clear that
it clear that hosted
clear that hosted event
such systems consider only
that hosted event channels
systems consider only one
hosted event channels won
consider only one object
event channels won t
only one object at
channels won t have
one object at a
won t have the
consistency windows is slightly
t have the scalability
windows is slightly more
object at a time
have the scalability and
is slightly more than
the scalability and latency
slightly more than an
scalability and latency properties
more than an order
and latency properties needed
than an order of
and only individual read
latency properties needed by
an order of magnitude
only individual read and
properties needed by many
individual read and write
needed by many applications
and this is attributable
read and write operations
this is attributable to
is attributable to the
attributable to the victim
as they do not
to the victim node
p alternatives often achieve
they do not support
alternatives often achieve far
the victim node observe
do not support a
often achieve far better
victim node observe that
not support a transactional
node observe that the
support a transactional interface
observe that the two
achieve far better scalability
that the two graphs
the two graphs denoting
there are few if
two graphs denoting the
are few if any
graphs denoting the maximum
few if any multi
denoting the maximum inconsistency
they also have security
the maximum inconsistency windows
also have security advantages
maximum inconsistency windows for
inconsistency windows for the
windows for the victim
for the victim node
the data center doesn
the victim node and
data center doesn t
victim node and for
center doesn t get
node and for the
doesn t get a
and for the entire
t get a chance
these systems generally try
for the entire chain
get a chance to
systems generally try to
the entire chain are
a chance to see
generally try to avoid
entire chain are identical
try to avoid staleness
to avoid staleness through
avoid staleness through techniques
staleness through techniques such
through techniques such as
which means that clients
techniques such as time
the live objects platform
means that clients perceiving
live objects platform can
that clients perceiving significant
objects platform can seamlessly
clients perceiving significant inconsistency
platform can seamlessly support
perceiving significant inconsistency are
can seamlessly support applications
significant inconsistency are the
seamlessly support applications that
inconsistency are the ones
support applications that require
are the ones that
applications that require a
the ones that are
that require a mixture
ones that are querying
require a mixture of
that are querying the
a mixture of data
are querying the victim
mixture of data sources
querying the victim node
the victim node while
victim node while it
node while it is
while it is still
including both hosted and
it is still recovering
both hosted and direct
is still recovering state
hosted and direct p
our work considers multi
finally we performed a
object transactional consistency of
we performed a set
transactional consistency of cache
performed a set of
consistency of cache access
further benefits include an
a set of experiments
benefits include an easy
set of experiments to
include an easy to
of experiments to determine
an easy to use
experiments to determine the
easy to use drag
to determine the distribution
determine the distribution of
the distribution of messages
distribution of messages delivered
early work on scalable
of messages delivered by
drop programming style that
messages delivered by the
programming style that yields
delivered by the chain
style that yields applications
by the chain vs
work on scalable database
that yields applications represented
the chain vs delivered
yields applications represented as
on scalable database caching
chain vs delivered by
applications represented as xml
vs delivered by gossip
scalable database caching mostly
represented as xml files
database caching mostly ignored
caching mostly ignored transactional
mostly ignored transactional consistency
which can be shared
one transient failure affects
can be shared as
transient failure affects the
be shared as files
failure affects the wall
shared as files or
as files or even
files or even via
or even via email
the runs are eight
users that open such
runs are eight times
that open such files
are eight times longer
open such files find
eight times longer than
such files find themselves
times longer than the
files find themselves immersed
longer than the runs
find themselves immersed in
than the runs before
work has been done
themselves immersed in a
has been done on
immersed in a mediarich
both in total experiment
in a mediarich collaborative
in total experiment time
a mediarich collaborative environment
total experiment time and
mediarich collaborative environment that
experiment time and time
collaborative environment that also
been done on creating
time and time the
environment that also offers
and time the victim
that also offers strong
done on creating consistent
time the victim node
also offers strong reliability
on creating consistent caches
the victim node is
creating consistent caches for
victim node is halted
consistent caches for databases
in the near future
extends a centralized database
a centralized database with
most important of all
centralized database with support
show the number of
database with support for
the number of messages
live objects are real
number of messages delivered
with support for caches
of messages delivered by
support for caches that
messages delivered by the
the platform is available
for caches that provide
delivered by the chain
platform is available for
by the chain replication
caches that provide snapshot
is available for free
the chain replication mechanism
that provide snapshot isolation
available for free download
chain replication mechanism and
provide snapshot isolation semantics
for free download from
replication mechanism and the
free download from cornell
mechanism and the ones
and the ones delivered
albeit the snapshots seen
the ones delivered by
the snapshots seen may
ones delivered by the
snapshots seen may be
delivered by the epidemics
seen may be stale
for each of the
to improve the commit
each of the nodes
improve the commit rate
of the nodes in
the commit rate for
the nodes in a
commit rate for read
nodes in a chain
again we omitted the
we omitted the head
omitted the head of
the head of the
head of the chain
of the chain node
where the cache holds
the chain node because
the cache holds several
chain node because its
cache holds several versions
lateral error correction for
node because its behavior
holds several versions of
error correction for time
because its behavior is
several versions of an
its behavior is not
versions of an object
behavior is not representative
of an object and
an object and enables
object and enables the
and enables the cache
and in this experiment
enables the cache to
in this experiment we
the cache to choose
this experiment we have
cache to choose a
experiment we have chains
to choose a version
we have chains of
choose a version that
have chains of length
a version that allows
version that allows a
that allows a transaction
allows a transaction to
a transaction to commit
this technique could also
technique could also be
could also be used
also be used with
be used with our
used with our solution
delivered updates by means
updates by means of
by means of the
means of the gossip
of the gossip repair
the gossip repair mechanism
as the nodes get
the nodes get further
nodes get further away
get further away from
further away from the
away from the victim
from the victim node
more of the messages
of the messages were
the messages were delivered
messages were delivered by
were delivered by means
delivered by means of
by means of the
means of the chain
also support snapshot isolation
because the repair mechanism
the repair mechanism relinked
repair mechanism relinked the
but can be used
mechanism relinked the chain
can be used with
relinked the chain and
be used with any
the chain and chain
used with any backend
chain and chain replication
with any backend database
and chain replication began
chain replication began to
replication began to function
began to function normally
including ones that are
ones that are sharded
that are sharded and
the speed with which
speed with which the
with which the chain
which the chain is
the chain is restored
chain is restored depends
exploiting gossip for self
is restored depends on
restored depends on the
depends on the rate
on the rate of
the rate of the
management in scalable event
rate of the fast
in scalable event notification
scalable event notification systems
provides a transactionally consistent
and on the responsiveness
a transactionally consistent cache
on the responsiveness of
transactionally consistent cache for
the responsiveness of the
consistent cache for the
responsiveness of the failure
cache for the jboss
of the failure detection
for the jboss middleware
the failure detection mechanism
future development the current
development the current ssa
the current ssa implementation
current ssa implementation uses
ssa implementation uses gossip
implementation uses gossip in
uses gossip in situations
gossip in situations where
semantic integration of web
in situations where faster
integration of web services
situations where faster notifications
of web services and
where faster notifications might
web services and peer
faster notifications might be
support transactions on cached
notifications might be helpful
transactions on cached enterprise
on cached enterprise javabeans
peer networks to achieve
networks to achieve fault
we believe that when
believe that when a
that when a node
when a node fails
a node fails or
node fails or joins
it would be useful
would be useful to
be useful to spread
allows update transactions to
useful to spread the
update transactions to read
to spread the news
transactions to read stale
spread the news as
to read stale data
the news as quickly
read stale data out
news as quickly as
stale data out of
as quickly as possible
data out of caches
out of caches and
of caches and provide
caches and provide bounds
and provide bounds on
we realize that for
provide bounds on how
realize that for some
bounds on how much
that for some particular
flexible protocol composition in
for some particular tasks
protocol composition in bast
some particular tasks gossip
on how much staleness
particular tasks gossip could
how much staleness is
tasks gossip could be
much staleness is allowed
gossip could be done
could be done more
be done more efficiently
these techniques require fast
techniques require fast communication
we are therefore exploring
require fast communication between
are therefore exploring the
fast communication between the
therefore exploring the use
communication between the cache
exploring the use of
between the cache and
the use of ip
the cache and the
use of ip multicast
cache and the database
of ip multicast for
and the database for
ip multicast for dissemination
the database for good
multicast for dissemination of
database for good performance
for dissemination of urgent
self organizing live objects
dissemination of urgent information
of urgent information as
urgent information as long
information as long as
as long as the
in our work caches
long as the physical
our work caches are
as the physical nodes
work caches are asynchronously
the physical nodes are
caches are asynchronously updated
physical nodes are not
nodes are not on
are not on a
not on a public
on a public network
a public network segment
which is how caches
is how caches currently
how caches currently work
we plan to include
caches currently work in
plan to include support
currently work in large
to include support for
work in large multi
include support for the
support for the partitioning
for the partitioning of
the partitioning of the
partitioning of the services
of the services by
the services by means
services by means of
by means of registering
means of registering partition
f uture d irections
of registering partition function
uture d irections the
registering partition function handlers
jms performance comparison for
partition function handlers with
d irections the dependency
performance comparison for publish
function handlers with a
comparison for publish subscribe
irections the dependency list
handlers with a global
for publish subscribe messaging
the dependency list sizes
with a global data
dependency list sizes for
fiorano software technologies pvt
list sizes for all
sizes for all objects
for all objects in
all objects in t
cache are currently all
are currently all of
currently all of the
all of the same
of the same maximum
we have implemented only
the same maximum length
have implemented only the
implemented only the server
only the server side
the server side load
this may not be
server side load balancing
may not be optimal
side load balancing scheme
we are considering ways
are considering ways to
if the workload accesses
considering ways to extend
the workload accesses objects
ways to extend our
workload accesses objects in
to extend our approach
accesses objects in clusters
extend our approach for
objects in clusters of
our approach for use
in clusters of different
approach for use in
clusters of different sizes
for use in settings
use in settings where
in settings where partitioning
settings where partitioning is
objects of larger clusters
where partitioning is done
leveraging collaboration of peer
of larger clusters call
partitioning is done on
larger clusters call for
is done on the
clusters call for longer
done on the client
peer and web services
call for longer dependency
on the client side
for longer dependency lists
once appropriate real workloads
appropriate real workloads are
real workloads are available
side access to subservice
access to subservice membership
to subservice membership information
it may be possible
subservice membership information is
may be possible to
membership information is needed
be possible to improve
possible to improve performance
to improve performance by
improve performance by dynamically
we are also developing
performance by dynamically changing
are also developing a
by dynamically changing per
also developing a gui
developing a gui assisted
a gui assisted automated
gui assisted automated web
object dependency list sizes
assisted automated web service
automated web service deployment
web service deployment tool
balancing between objects to
between objects to maintain
based web service composition
objects to maintain the
focused on web service
web service composition with
to maintain the same
on web service applications
service composition with jade
maintain the same overall
composition with jade and
the same overall space
with jade and jxta
developers could simply drop
same overall space overhead
could simply drop a
simply drop a wsdl
drop a wsdl service
a wsdl service description
another option is to
option is to explore
is to explore an
to explore an approach
explore an approach in
an approach in which
approach in which each
in which each type
which each type of
and the system will
each type of object
the system will generate
type of object would
system will generate a
of object would have
will generate a xml
object would have its
generate a xml description
would have its own
a xml description that
have its own dependency
xml description that can
its own dependency list
description that can be
own dependency list bound
that can be used
can be used later
be used later on
used later on to
later on to actually
on to actually deploy
to actually deploy the
actually deploy the service
deploy the service automatically
based architecture for semanticweb
architecture for semanticweb service
for semanticweb service automatic
the service will be
agnostic and treats all
semanticweb service automatic composition
service will be partitioned
and treats all objects
treats all objects and
all objects and object
objects and object relations
and object relations as
object relations as equal
and deployed on the
deployed on the fly
using an lru policy
on the fly on
an lru policy to
the fly on top
lru policy to trim
fly on top of
policy to trim the
on top of the
to trim the list
top of the processing
trim the list of
of the processing nodes
the list of dependencies
there may be cases
may be cases in
be cases in which
cases in which the
scaling up to turn
in which the application
up to turn the
which the application could
to turn the ssa
the application could explicitly
turn the ssa into
application could explicitly inform
the ssa into a
could explicitly inform the
ssa into a full
explicitly inform the cache
into a full scale
inform the cache of
a full scale platform
the cache of relevant
cache of relevant object
of relevant object dependencies
one of the immediate
of the immediate future
and those could then
the immediate future challenges
those could then be
immediate future challenges is
could then be treated
future challenges is the
then be treated as
challenges is the necessity
be treated as more
is the necessity of
treated as more important
the necessity of evaluating
as more important and
necessity of evaluating a
more important and retained
of evaluating a full
evaluating a full raps
a full raps of
full raps of racs
raps of racs deployment
while other less important
and jong hoon ahnn
other less important ones
less important ones are
multiple partitioned and cloned
important ones are managed
partitioned and cloned services
ones are managed by
programming with live distributed
and cloned services running
are managed by some
with live distributed objects
cloned services running on
managed by some other
services running on our
by some other policy
running on our tightly
some other policy such
on our tightly coupled
other policy such as
our tightly coupled cluster
policy such as lru
tightly coupled cluster would
coupled cluster would lead
cluster would lead to
would lead to a
lead to a series
to a series of
a series of other
series of other issues
in a web album
of other issues that
a web album the
other issues that should
web album the set
issues that should be
album the set of
that should be investigated
the set of pictures
set of pictures and
of pictures and their
pictures and their acl
and their acl is
their acl is an
placement given a set
acl is an important
given a set of
is an important dependency
a set of services
an important dependency whereas
achieving reliability through distributed
important dependency whereas occasional
reliability through distributed data
how to place the
through distributed data flows
dependency whereas occasional tagging
to place the clones
distributed data flows and
place the clones on
data flows and recursive
the clones on physical
flows and recursive delegation
whereas occasional tagging operations
clones on physical nodes
occasional tagging operations that
on physical nodes in
tagging operations that relate
physical nodes in order
operations that relate pictures
nodes in order to
that relate pictures to
in order to satisfy
relate pictures to users
order to satisfy certain
pictures to users may
to satisfy certain constraints
to users may be
users may be less
may be less important
it may be straightforward
may be straightforward to
be straightforward to extend
straightforward to extend the
to extend the cache
extend the cache api
the cache api to
cache api to allow
caching placement deciding if
api to allow the
placement deciding if some
to allow the application
deciding if some services
allow the application to
if some services would
the application to specify
some services would benefit
application to specify such
services would benefit if
to specify such dependencies
would benefit if they
specify such dependencies and
benefit if they are
such dependencies and to
if they are fitted
dependencies and to modify
they are fitted with
and to modify t
are fitted with response
fitted with response caches
cache to respect them
and ultimately placing the
ultimately placing the cache
placing the cache components
the cache components in
cache components in a
components in a smart
in a smart way
c onclusion existing large
scale computing frameworks make
computing frameworks make heavy
frameworks make heavy use
location placing multiple service
make heavy use of
placing multiple service clones
heavy use of edge
multiple service clones on
use of edge caches
service clones on the
of edge caches to
clones on the same
edge caches to reduce
on the same physical
caches to reduce client
the same physical node
to reduce client latency
same physical node to
changtao qu and wolfgang
physical node to exploit
qu and wolfgang nejdl
node to exploit fast
but this form of
to exploit fast ipc
this form of caching
exploit fast ipc communication
form of caching has
fast ipc communication as
of caching has not
ipc communication as opposed
caching has not been
communication as opposed to
has not been available
as opposed to network
peer network with web
opposed to network messages
network with web services
not been available for
to network messages if
been available for transactional
network messages if the
available for transactional applications
messages if the benefits
if the benefits overweigh
the benefits overweigh the
benefits overweigh the cost
we believe this is
overweigh the cost incurred
believe this is one
the cost incurred by
this is one reason
cost incurred by resource
is one reason that
incurred by resource contention
one reason that transactions
by resource contention on
reason that transactions are
resource contention on the
that transactions are generally
contention on the shared
transactions are generally not
on the shared host
are generally not considered
generally not considered to
not considered to be
considered to be a
to be a viable
be a viable option
management tools developing tools
a viable option in
tools developing tools that
viable option in extremely
developing tools that monitor
option in extremely large
tools that monitor service
in extremely large systems
that monitor service properties
a scalable and ontology
monitor service properties such
service properties such as
properties such as response
such as response time
p infrastructure for semantic
infrastructure for semantic web
for semantic web services
a variant of serializability
variant of serializability that
of serializability that is
serializability that is suitable
that is suitable for
is suitable for incoherent
suitable for incoherent caches
by restarting new clones
which cannot communicate with
cannot communicate with the
communicate with the backend
with the backend database
the backend database on
using vmm tricks virtual
backend database on every
vmm tricks virtual machines
database on every read
tricks virtual machines can
on every read access
virtual machines can be
machines can be used
can be used to
we then presented t
be used to migrate
used to migrate transparently
to migrate transparently a
migrate transparently a collection
transparently a collection of
a collection of services
collection of services on
an architecture for controlling
of services on a
architecture for controlling transaction
services on a different
for controlling transaction consistency
on a different physical
controlling transaction consistency with
a different physical processor
transaction consistency with caches
or provide isolation guarantees
a collaboration system architecture
provide isolation guarantees between
the system extends the
isolation guarantees between co
system extends the edge
extends the edge cache
the edge cache by
edge cache by allowing
cache by allowing it
by allowing it to
allowing it to offer
it to offer a
to offer a transactional
offer a transactional interface
we believe that t
the ssa can be
ssa can be seen
can be seen as
be seen as a
cache is the first
seen as a platform
is the first transaction
as a platform that
a platform that leverages
platform that leverages tradeoffs
aware caching architecture in
that leverages tradeoffs between
sonic performance test suite
caching architecture in which
leverages tradeoffs between weaker
architecture in which caches
tradeoffs between weaker consistency
in which caches are
which caches are updated
caches are updated asynchronously
with a compensating gossip
a compensating gossip repair
compensating gossip repair mechanism
a lookup request only
for higher availability and
lookup request only requires
higher availability and simplicity
request only requires a
only requires a round
this is an old
is an old idea
an old idea first
trip to the database
old idea first explored
to the database in
idea first explored in
the database in case
first explored in the
database in case there
explored in the grapevine
in case there is
case there is a
there is a cache
is a cache miss
a cache miss there
cache miss there is
miss there is no
there is no additional
is no additional traffic
no additional traffic and
additional traffic and delays
traffic and delays to
and delays to ensure
and later in systems
delays to ensure cache
later in systems like
to ensure cache coherence
in systems like bayou
cache associates dependency information
associates dependency information with
dependency information with cached
information with cached database
which offer a broad
with cached database objects
offer a broad operational
a broad operational spectrum
broad operational spectrum between
operational spectrum between strong
while leaving the interaction
leaving the interaction between
the interaction between the
acid in the distributed
interaction between the backend
in the distributed database
between the backend systems
the distributed database cases
the backend systems and
backend systems and the
systems and the cache
and the cache otherwise
the cache otherwise unchanged
several database and distributed
database and distributed systems
this information includes version
and distributed systems take
information includes version identifiers
distributed systems take advantage
includes version identifiers and
systems take advantage of
version identifiers and bounded
take advantage of the
advantage of the same
of the same tradeoff
with this modest amount
for example allowing multiple
this modest amount of
example allowing multiple updates
modest amount of additional
allowing multiple updates to
a demonstration of collaborative
multiple updates to occur
demonstration of collaborative web
amount of additional information
updates to occur simultaneously
of collaborative web services
to occur simultaneously at
collaborative web services and
occur simultaneously at distinct
we show that inconsistency
simultaneously at distinct replicas
show that inconsistency can
at distinct replicas by
that inconsistency can be
distinct replicas by specifying
web services and peer
inconsistency can be greatly
replicas by specifying a
can be greatly reduced
by specifying a maximum
be greatly reduced or
specifying a maximum accepted
greatly reduced or even
a maximum accepted deviation
reduced or even completely
maximum accepted deviation from
or even completely eliminated
accepted deviation from strong
even completely eliminated in
deviation from strong consistency
completely eliminated in some
eliminated in some cases
cache is intended for
is intended for clustered
intended for clustered workloads
and those arise naturally
those arise naturally in
arise naturally in social
naturally in social networks
mobile applications with spatial
applications with spatial locality
p network based architecture
network based architecture for
based architecture for web
architecture for web service
our experiments demonstrate t
tolerating a bounded number
a bounded number of
bounded number of consistency
cache to be effective
number of consistency violations
to be effective in
of consistency violations to
be effective in realistic
consistency violations to increase
effective in realistic workloads
violations to increase concurrency
in realistic workloads based
to increase concurrency of
realistic workloads based on
increase concurrency of transactions
workloads based on datasets
based on datasets from
on datasets from amazon
datasets from amazon and
from amazon and orkut
using dependency lists of
dependency lists of size
or replication according to
replication according to the
according to the need
our work on the
work on the ssa
on the ssa is
the ssa is the
ssa is the first
and was also able
is the first to
was also able to
the first to apply
also able to increase
first to apply such
able to increase consistent
to apply such thinking
to increase consistent transaction
apply such thinking to
increase consistent transaction rate
such thinking to a
consistent transaction rate by
thinking to a cluster
to a cluster computing
a cluster computing environment
with only nominal overhead
platform was designed to
only nominal overhead on
was designed to provide
nominal overhead on the
designed to provide a
overhead on the database
to provide a cluster
provide a cluster based
a cluster based environment
our experiments with synthetic
cluster based environment for
experiments with synthetic workloads
based environment for scalable
with synthetic workloads showed
environment for scalable internet
synthetic workloads showed that
for scalable internet services
workloads showed that t
scalable internet services of
internet services of the
services of the sort
of the sort used
the sort used in
cache s efficacy depends
sort used in web
s efficacy depends on
used in web servers
efficacy depends on the
depends on the clustering
on the clustering level
the clustering level of
caching proxies and transformation
clustering level of the
proxies and transformation proxies
level of the workload
service components are controlled
components are controlled by
are controlled by a
cache adapts to dynamically
controlled by a front
adapts to dynamically changing
by a front end
to dynamically changing workloads
a front end machine
dynamically changing workloads where
front end machine that
changing workloads where clusters
end machine that acts
workloads where clusters change
machine that acts as
where clusters change over
that acts as a
clusters change over time
acts as a request
as a request dispatcher
a request dispatcher and
request dispatcher and incorporates
due to resource limitations
dispatcher and incorporates the
to resource limitations t
and incorporates the load
incorporates the load balancing
the load balancing and
load balancing and restart
cache maintains only a
balancing and restart logics
maintains only a short
only a short dependency
a short dependency list
which is naturally imperfect
end processes are detected
is naturally imperfect and
processes are detected to
naturally imperfect and does
are detected to have
imperfect and does not
detected to have failed
and does not include
does not include all
not include all dependencies
new processes are forked
processes are forked to
are forked to take
we proved that when
forked to take over
proved that when resources
to take over the
that when resources are
take over the load
when resources are unbounded
tacc workers can be
workers can be composed
can be composed to
be composed to address
cache s algorithm implements
composed to address more
s algorithm implements cache
to address more complex
address more complex tasks
tacc stands for transformation
ssa can be seen
can be seen as
be seen as revisiting
seen as revisiting these
as revisiting these architectural
revisiting these architectural ideas
these architectural ideas in
architectural ideas in conjunction
ideas in conjunction with
in conjunction with chain
conjunction with chain replication
have long supported clustered
long supported clustered architectures
and were the first
were the first systems
the first systems to
first systems to exploit
systems to exploit the
to exploit the style
exploit the style of
the style of partitioning
style of partitioning that
of partitioning that leads
partitioning that leads to
that leads to a
leads to a raps
to a raps of
a raps of racs
raps of racs solution
most database systems adhere
database systems adhere closely
systems adhere closely to
adhere closely to the
closely to the acid
to the acid model
at potentially high cost
potentially high cost in
high cost in terms
cost in terms of
in terms of reduced
terms of reduced availability
of reduced availability during
reduced availability during faults
discuss this problem in
ultimately arguing for precisely
arguing for precisely the
for precisely the weak
precisely the weak update
the weak update model
weak update model that
update model that we
model that we adopted
that we adopted here
application servers like the
servers like the j
offer persistent state support
persistent state support by
state support by wrapping
support by wrapping soft
by wrapping soft state
wrapping soft state business
soft state business logic
state business logic components
business logic components on
logic components on top
components on top of
on top of a
top of a relational
of a relational or
a relational or object
they also target large
scale highly available services
and hence we believe
hence we believe they
we believe they could
believe they could benefit
they could benefit from
could benefit from ssa
in a similar vein
framework makes it easy
makes it easy to
it easy to create
easy to create robust
to create robust scalable
create robust scalable services
ninja is arguably more
research edition where the
is arguably more flexible
edition where the academic
arguably more flexible than
where the academic knights
more flexible than application
the academic knights meet
flexible than application servers
academic knights meet the
than application servers in
knights meet the evil
application servers in that
meet the evil empire
servers in that it
the evil empire werner
in that it performs
evil empire werner vogels
that it performs connection
empire werner vogels the
it performs connection management
werner vogels the rivalry
performs connection management and
vogels the rivalry in
connection management and automatically
the rivalry in the
management and automatically partitions
rivalry in the operating
and automatically partitions and
in the operating system
automatically partitions and replicates
the operating system market
partitions and replicates persistent
operating system market place
and replicates persistent state
system market place has
market place has a
place has a severe
has a severe impact
but the framework takes
a severe impact on
the framework takes a
severe impact on the
framework takes a different
impact on the academic
takes a different tiered
on the academic world
a different tiered approach
different tiered approach to
tiered approach to services
approach to services based
to services based on
services based on bases
where in the old
in the old days
the old days intellection
old days intellection quality
active proxies and units
days intellection quality and
intellection quality and careful
quality and careful deliberation
and careful deliberation would
and represents shared state
careful deliberation would prevail
represents shared state by
shared state by means
state by means of
by means of distributed
means of distributed data
of distributed data structures
nowadays discussions about operating
discussions about operating systems
about operating systems research
operating systems research appear
systems research appear to
research appear to be
appear to be more
conclusion our paper presents
to be more like
our paper presents the
be more like the
paper presents the scalable
more like the battlefield
presents the scalable services
like the battlefield of
the scalable services architecture
the battlefield of a
battlefield of a holy
of a holy war
a new platform for
new platform for porting
with objectivity as its
platform for porting a
objectivity as its main
for porting a large
as its main victim
porting a large class
a large class of
large class of service
we have tried to
have tried to side
oriented applications onto clusters
tried to side step
to side step the
side step the emotional
step the emotional current
the ssa was designed
ssa was designed to
was designed to be
designed to be as
and select an operating
to be as simple
select an operating system
be as simple as
an operating system that
as simple as possible
operating system that could
system that could bring
that could bring our
could bring our research
bring our research into
and at the core
our research into the
at the core uses
research into the next
the core uses just
into the next century
core uses just two
uses just two primitive
just two primitive mechanisms
based on objective technical
on objective technical and
objective technical and organizational
tcp chains that support
technical and organizational criteria
chains that support a
that support a variant
support a variant of
a variant of chain
variant of chain replication
this paper describes how
paper describes how this
describes how this evaluation
and gossip epidemics which
how this evaluation lead
gossip epidemics which are
this evaluation lead to
epidemics which are used
evaluation lead to the
which are used to
lead to the insight
are used to manage
to the insight that
used to manage configuration
the insight that microsoft
to manage configuration data
insight that microsoft s
manage configuration data and
that microsoft s windows
configuration data and initiate
microsoft s windows nt
data and initiate repair
s windows nt is
and initiate repair after
windows nt is the
initiate repair after failures
nt is the operating
is the operating system
the operating system that
operating system that is
system that is best
with appropriate parameter settings
that is best prepared
is best prepared for
best prepared for the
prepared for the future
given a gossip rate
google s globally distributed
a gossip rate that
introduction until recently there
gossip rate that is
until recently there was
rate that is sufficiently
s globally distributed database
recently there was no
that is sufficiently fast
there was no doubt
is sufficiently fast relative
was no doubt in
sufficiently fast relative to
acm transactions on computer
fast relative to the
no doubt in academia
relative to the update
transactions on computer systems
doubt in academia which
to the update rates
in academia which operating
the update rates seen
academia which operating system
update rates seen in
which operating system to
rates seen in the
operating system to use
seen in the cluster
system to use for
to use for systems
use for systems research
we find that the
whether it was a
find that the ssa
it was a bsd
was a bsd or
that the ssa can
a bsd or system
bsd or system v
the ssa can rapidly
or system v derivative
ssa can rapidly and
can rapidly and automatically
rapidly and automatically reconfigure
was the predominant choice
and automatically reconfigure itself
automatically reconfigure itself after
reconfigure itself after a
itself after a failure
after a failure and
which had its roots
a failure and can
had its roots in
failure and can rapidly
its roots in research
and can rapidly repair
can rapidly repair data
rapidly repair data inconsistencies
repair data inconsistencies that
was used since its
data inconsistencies that arise
used since its inception
inconsistencies that arise during
since its inception to
that arise during the
its inception to investigate
arise during the period
inception to investigate fundamental
during the period when
to investigate fundamental system
the period when the
investigate fundamental system research
period when the cluster
when the cluster configuration
the cluster configuration was
cluster configuration was still
configuration was still disrupted
and the accumulated knowledge
the accumulated knowledge in
accumulated knowledge in academia
knowledge in academia about
in academia about its
our goal is to
academia about its internals
goal is to make
about its internals and
is to make the
its internals and operations
to make the software
internals and operations was
make the software available
and operations was significant
the software available to
software available to a
available to a general
to a general user
other available operating systems
a general user community
available operating systems such
general user community in
operating systems such as
systems such as vms
such as vms and
as vms and mvs
had their roots in
their roots in the
roots in the commercial
in the commercial world
the commercial world and
commercial world and knowledge
world and knowledge about
and knowledge about these
knowledge about these systems
about these systems never
these systems never accumulated
systems never accumulated to
acknowledgments the authors are
never accumulated to the
the authors are grateful
accumulated to the critical
authors are grateful to
to the critical mass
are grateful to the
the critical mass were
grateful to the research
critical mass were these
to the research team
mass were these systems
the research team at
were these systems could
research team at afrl
these systems could be
team at afrl in
systems could be considered
at afrl in rome
could be considered for
be considered for widespread
considered for widespread research
for widespread research tasks
for their help in
their help in understanding
although new research operating
help in understanding the
new research operating systems
in understanding the challenges
research operating systems have
understanding the challenges of
distributed data structures over
the challenges of using
operating systems have been
challenges of using service
data structures over a
systems have been developed
of using service oriented
structures over a shared
using service oriented architectures
over a shared log
none have found the
service oriented architectures in
have found the following
oriented architectures in large
found the following that
architectures in large scale
the following that the
in large scale settings
in proceedings of the
following that the established
that the established unix
the established unix s
and to the researchers
established unix s received
to the researchers at
the researchers at amazon
th acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
freebsd and others continue
and others continue to
for helping us understand
others continue to dominate
helping us understand the
continue to dominate the
us understand the architectures
to dominate the academic
understand the architectures employed
dominate the academic landscape
the architectures employed in
architectures employed in very
employed in very large
in very large data
very large data centers
but slowly but surely
slowly but surely windows
but surely windows nt
surely windows nt is
windows nt is now
nt is now entering
is now entering the
now entering the academic
entering the academic world
the academic world as
academic world as a
world as a viable
alternative platform for research
although academia looked with
academia looked with fascination
looked with fascination at
with fascination at dave
fascination at dave cutler
at dave cutler s
dave cutler s attempt
cutler s attempt to
s attempt to build
attempt to build a
to build a new
build a new operating
a new operating system
new operating system from
operating system from the
system from the ground
from the ground up
an exercise in distributed
exercise in distributed computing
all expected that windows
ordering transactions with prediction
communications of the acm
expected that windows nt
transactions with prediction in
that windows nt would
with prediction in distributed
windows nt would go
prediction in distributed object
nt would go the
in distributed object stores
would go the same
go the same way
the same way as
same way as the
way as the other
as the other commercially
the other commercially designed
other commercially designed operating
commercially designed operating systems
th workshop on large
designed operating systems before
operating systems before it
systems before it and
before it and remain
scale distributed systems and
it and remain in
distributed systems and middleware
and remain in the
remain in the dark
in the dark corner
the dark corner from
dark corner from a
corner from a research
from a research use
a research use point
research use point of
use point of view
about four years ago
not long after the
long after the final
after the final major
the final major release
final major release of
major release of academic
release of academic version
of academic version of
academic version of the
version of the unix
of the unix operating
the unix operating system
key transactions for key
the farewell of the
farewell of the berkeley
of the berkeley systems
the berkeley systems werner
an architecture to support
berkeley systems werner vogels
architecture to support scalable
systems werner vogels is
to support scalable online
werner vogels is a
support scalable online personalization
vogels is a research
scalable online personalization in
is a research scientist
online personalization in the
a research scientist at
personalization in the web
research scientist at the
scientist at the department
at the department of
the department of computer
the international journal on
department of computer science
international journal on very
of computer science of
journal on very large
computer science of cornell
on very large data
science of cornell university
very large data bases
his research targets high
availability in distributed systems
with a particular focus
a particular focus on
particular focus on enterprise
focus on enterprise cluster
on enterprise cluster systems
president of reliable network
of reliable network solutions
which specializes in building
specializes in building solutions
in building solutions for
building solutions for very
solutions for very large
scale reliable distributed systems
usenix windows nt symposium
his personal homepage is
personal homepage is at
homepage is at http
facebook s distributed data
s distributed data store
distributed data store for
data store for the
store for the social
for the social graph
in usenix annual technical
usenix annual technical conference
group and the early
and the early demise
the early demise of
early demise of mach
epidemic algorithms for replicated
demise of mach as
algorithms for replicated database
of mach as the
for replicated database maintenance
mach as the last
as the last of
the last of the
last of the research
of the research operating
in proceedings of the
the research operating systems
proceedings of the sixth
of the sixth annual
the sixth annual acm
sixth annual acm symposium
annual acm symposium on
the operating system research
acm symposium on principles
operating system research world
symposium on principles of
system research world was
on principles of distributed
research world was at
principles of distributed computing
world was at a
was at a crossroads
intel based personal computers
based personal computers were
personal computers were becoming
computers were becoming ubiquitous
and a myriad of
a myriad of unix
myriad of unix operating
of unix operating systems
unix operating systems was
operating systems was available
systems was available for
was available for this
available for this platform
eventually many moved to
many moved to use
moved to use linux
a popular architectural clone
popular architectural clone of
architectural clone of the
clone of the traditional
of the traditional unix
at the computer science
the computer science department
computer science department at
science department at cornell
department at cornell university
at cornell university we
cornell university we made
university we made the
we made the decision
made the decision to
the decision to conduct
decision to conduct our
to conduct our research
conduct our research on
our research on windows
research on windows nt
by that time we
that time we had
time we had learned
we had learned enough
had learned enough from
learned enough from the
enough from the early
from the early design
the early design of
early design of windows
design of windows nt
of windows nt to
windows nt to realize
nt to realize that
to realize that it
realize that it was
that it was a
it was a major
was a major step
a major step forward
major step forward in
step forward in operating
forward in operating system
in operating system design
support for data sharing
for data sharing among
it would provide us
data sharing among mobile
sharing among mobile users
would provide us with
provide us with a
us with a platform
in ieee workshop on
scaling memcache at facebook
with a platform on
ieee workshop on mobile
workshop on mobile computing
a platform on which
on mobile computing systems
platform on which we
on which we could
which we could perform
we could perform research
th usenix symposium on
could perform research more
usenix symposium on networked
perform research more effectively
symposium on networked systems
research more effectively and
on networked systems design
more effectively and it
networked systems design and
effectively and it would
systems design and implementation
and it would allows
it would allows us
would allows us to
allows us to focus
us to focus on
to focus on the
focus on the future
on the future directions
the future directions without
future directions without having
directions without having to
without having to worry
having to worry whether
to worry whether the
worry whether the operating
whether the operating system
the operating system was
operating system was capable
system was capable of
was capable of supporting
capable of supporting innovation
by now our complete
now our complete educational
our complete educational operation
complete educational operation and
educational operation and the
operation and the majority
and the majority of
the majority of our
majority of our research
of our research projects
our research projects have
research projects have switched
projects have switched to
have switched to using
switched to using windows
to using windows nt
as it now officially
it now officially has
now officially has been
officially has been christened
the ride has been
ride has been rocky
has been rocky and
been rocky and fascinating
in this article i
this article i want
article i want to
i want to share
want to share some
to share some of
share some of the
some of the reasoning
of the reasoning behind
the reasoning behind our
reasoning behind our choice
behind our choice for
our choice for windows
choice for windows nt
for windows nt and
windows nt and to
nt and to share
and to share some
to share some our
share some our experiences
some our experiences with
our experiences with windows
experiences with windows nt
with windows nt as
windows nt as a
nt as a research
as a research platform
os research as religion
research as religion the
as religion the biggest
religion the biggest hurdle
the biggest hurdle in
biggest hurdle in starting
hurdle in starting research
in starting research on
starting research on windows
research on windows nt
on windows nt was
windows nt was not
nt was not technical
it was to overcome
was to overcome the
to overcome the skepticism
overcome the skepticism of
the skepticism of our
skepticism of our colleagues
of our colleagues who
our colleagues who were
transactional consistency and automatic
colleagues who were convinced
based scalable network services
who were convinced that
consistency and automatic management
were convinced that it
and automatic management in
convinced that it would
automatic management in an
that it would not
management in an application
it would not be
in an application data
would not be possible
an application data cache
proceedings of the sixteenth
not be possible to
of the sixteenth acm
be possible to use
the sixteenth acm symposium
possible to use windows
sixteenth acm symposium on
to use windows nt
acm symposium on operating
use windows nt as
th usenix symposium on
windows nt as a
usenix symposium on operating
symposium on operating systems
nt as a good
symposium on operating systems
on operating systems principles
as a good platform
on operating systems design
a good platform for
operating systems design and
good platform for research
systems design and implementation
the predictions were fascinating
we would turn into
would turn into a
turn into a bug
microsoft would sue the
would sue the department
sue the department for
the department for every
department for every technical
for every technical publication
microsoft would hide the
would hide the pieces
hide the pieces of
the pieces of buggy
pieces of buggy code
of buggy code from
buggy code from us
code from us or
from us or bill
us or bill gates
or bill gates would
bill gates would personally
gates would personally tell
would personally tell us
personally tell us where
tell us where and
us where and how
where and how we
and how we should
how we should do
we should do our
should do our research
the operating systems research
operating systems research community
systems research community has
research community has not
community has not remained
has not remained untouched
not remained untouched by
remained untouched by the
untouched by the market
by the market place
the market place rivalry
market place rivalry between
place rivalry between microsoft
rivalry between microsoft and
between microsoft and the
microsoft and the group
and the group lead
the group lead by
group lead by sun
fast iterative graph computation
lead by sun microsystems
iterative graph computation with
graph computation with block
computation with block updates
it is even more
is even more unfortunate
even more unfortunate that
more unfortunate that the
unfortunate that the positions
of the vldb endowment
that the positions taken
the positions taken are
positions taken are not
taken are not based
are not based on
not based on intellectual
based on intellectual deliberation
on intellectual deliberation but
intellectual deliberation but purely
deliberation but purely on
but purely on emotional
purely on emotional grounds
many see microsoft operating
see microsoft operating systems
microsoft operating systems as
operating systems as the
systems as the evil
as the evil empire
out to squash every
to squash every attempt
squash every attempt at
every attempt at innovation
and working with them
working with them is
with them is seen
them is seen as
is seen as collaboration
seen as collaboration with
as collaboration with the
collaboration with the enemy
with the enemy of
the enemy of free
enemy of free academic
of free academic speech
the pros and cons
pros and cons are
and cons are often
cons are often discussed
are often discussed with
the ninja architecture for
often discussed with a
ninja architecture for robust
discussed with a righteous
architecture for robust internet
with a righteous zeal
a righteous zeal that
righteous zeal that is
zeal that is frightening
scale systems and services
our own experiences with
own experiences with microsoft
experiences with microsoft can
with microsoft can only
microsoft can only be
can only be described
only be described as
be described as extremely
described as extremely positive
never before have we
before have we had
have we had such
we had such a
had such a positive
concurrency control and recovery
such a positive relation
control and recovery in
a positive relation with
and recovery in database
positive relation with a
recovery in database systems
relation with a vendor
without any pressure from
any pressure from their
pressure from their side
we can only conclude
can only conclude that
only conclude that the
conclude that the reasons
that the reasons for
the reasons for the
reasons for the controversy
for the controversy must
the controversy must be
controversy must be found
must be found in
be found in a
found in a sort
in a sort of
a sort of traditional
sort of traditional emotional
of traditional emotional bonding
traditional emotional bonding of
emotional bonding of academia
bonding of academia with
of academia with the
academia with the underdog
with the underdog and
the underdog and that
underdog and that no
and that no real
that no real experiences
no real experiences drive
real experiences drive the
experiences drive the discussion
gaining knowledge the foremost
knowledge the foremost reasons
the foremost reasons why
foremost reasons why unix
reasons why unix was
why unix was such
unix was such a
was such a powerhouse
spatial gossip and resource
such a powerhouse in
gossip and resource location
and resource location protocols
a powerhouse in operating
the dynamics of viral
powerhouse in operating system
dynamics of viral marketing
in proceedings of the
in operating system research
proceedings of the thirty
operating system research was
acm transactions on the
system research was the
transactions on the web
third annual acm symposium
research was the great
annual acm symposium on
was the great amount
acm symposium on theory
the great amount of
symposium on theory of
great amount of knowledge
on theory of computing
amount of knowledge accumulated
of knowledge accumulated over
knowledge accumulated over the
accumulated over the years
over the years about
the years about the
years about the internal
about the internal operation
the internal operation of
internal operation of the
operation of the operating
of the operating system
many of us had
of us had become
us had become gurus
had become gurus about
become gurus about some
gurus about some part
about some part of
some part of the
part of the os
of the os kernel
the os kernel and
os kernel and could
kernel and could recite
and could recite the
could recite the fields
recite the fields of
the fields of an
fields of an i
node structure at late
structure at late night
at late night meetings
late night meetings or
night meetings or discuss
meetings or discuss which
or discuss which data
discuss which data structures
which data structures to
data structures to modify
structures to modify to
to modify to add
modify to add a
to add a new
add a new protocol
a new protocol at
new protocol at runtime
protocol at runtime over
at runtime over an
runtime over an early
over an early morning
an early morning cappuccino
many of us were
of us were and
us were and still
were and still are
a technique for increasing
and still are afraid
technique for increasing concurrency
still are afraid to
for increasing concurrency in
are afraid to leave
increasing concurrency in a
concurrency in a replicated
afraid to leave this
in a replicated system
measurement and analysis of
to leave this bastion
and analysis of online
leave this bastion of
acm transactions on database
analysis of online social
this bastion of safety
transactions on database systems
of online social networks
bastion of safety behind
of safety behind and
safety behind and trade
in proceedings of the
behind and trade it
and trade it in
trade it in for
th acm sigcomm conference
it in for working
acm sigcomm conference on
in for working on
sigcomm conference on internet
for working on an
conference on internet measurement
working on an operating
on an operating system
an operating system that
operating system that at
system that at first
that at first sight
at first sight had
first sight had nothing
sight had nothing in
had nothing in common
nothing in common with
in common with our
common with our beloved
with our beloved unix
and our annotated version
our annotated version of
annotated version of the
version of the unix
of the unix version
wouldn t be of
t be of much
be of much help
of much help any
much help any more
help any more either
any more either it
more either it took
either it took more
it took more then
took more then a
more then a year
then a year of
a year of immersion
year of immersion in
of immersion in the
immersion in the technology
sampling from large graphs
in the technology to
adaptive distributed data management
the technology to get
distributed data management with
technology to get a
in proceedings of the
to get a level
data management with weak
get a level where
management with weak consistent
a level where i
with weak consistent replicated
level where i felt
weak consistent replicated data
where i felt confident
i felt confident again
th acm sigkdd international
felt confident again to
in proceedings of the
confident again to direct
acm sigkdd international conference
again to direct others
sigkdd international conference on
to direct others in
international conference on knowledge
direct others in our
conference on knowledge discovery
others in our research
on knowledge discovery and
in our research group
knowledge discovery and data
acm symposium on applied
discovery and data mining
symposium on applied computing
together with the overall
with the overall organizational
the overall organizational issues
overall organizational issues i
organizational issues i think
issues i think we
i think we lost
think we lost one
we lost one and
lost one and a
one and a half
and a half year
a half year worth
half year worth of
year worth of research
worth of research time
of research time to
research time to make
time to make the
to make the switch
make the switch in
the switch in the
switch in the most
in the most fundamental
the most fundamental way
others are making the
are making the switch
making the switch more
the switch more gradually
switch more gradually and
more gradually and are
gradually and are experiencing
and are experiencing a
are experiencing a more
experiencing a more smooth
a more smooth transition
all operation systems are
operation systems are created
systems are created equal
are created equal our
created equal our experiences
equal our experiences with
our experiences with switching
experiences with switching to
with switching to windows
switching to windows nt
to windows nt have
windows nt have made
nt have made us
have made us somewhat
made us somewhat more
us somewhat more philosophical
somewhat more philosophical about
more philosophical about the
philosophical about the nature
about the nature of
the nature of operation
nature of operation systems
the most fundamental observation
aware adaptable web services
most fundamental observation is
fundamental observation is that
don t settle for
t settle for eventual
in proceedings of the
when stripped to their
stripped to their core
scalable causal consistency for
causal consistency for wide
all operating systems are
operating systems are equal
th international world wide
area storage with cops
international world wide web
world wide web conference
the functionality of the
wide web conference on
functionality of the windows
web conference on alternate
of the windows nt
conference on alternate track
the windows nt kernel
on alternate track papers
windows nt kernel is
alternate track papers and
nt kernel is just
track papers and posters
kernel is just as
is just as all
just as all other
as all other kernels
rd acm symposium on
acm symposium on operating
symposium on operating systems
it abstracts the hardware
on operating systems principles
abstracts the hardware in
the hardware in the
hardware in the usual
in the usual sense
process and threads hide
and threads hide the
threads hide the cpu
hide the cpu complexity
file systems and files
systems and files hide
and files hide the
files hide the storage
hide the storage devices
protocols hide the network
shared memory and messages
memory and messages are
and messages are used
messages are used to
are used to allow
used to allow sharing
to allow sharing of
allow sharing of resources
what we often call
we often call operating
often call operating systems
call operating systems has
operating systems has nothing
systems has nothing to
has nothing to do
nothing to do with
to do with the
do with the real
with the real core
the real core of
real core of the
core of the system
unix for most of
for most of us
transactional storage for geo
most of us is
of us is a
us is a collection
is a collection of
a collection of shell
collection of shell commands
of shell commands and
shell commands and development
commands and development libraries
david korn s uwin
rd acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
and softway s interix
both show that you
show that you can
that you can give
you can give users
can give users and
give users and developers
users and developers a
unix experience including x
profiles for the situated
for the situated web
while running on an
running on an windows
on an windows nt
in proceedings of the
an windows nt kernel
proceedings of the eleventh
of the eleventh international
the eleventh international conference
eleventh international conference on
international conference on world
windows nt for most
conference on world wide
nt for most of
on world wide web
for most of us
most of us is
of us is the
us is the windows
is the windows explorer
the windows explorer and
windows explorer and point
replicated systems fast as
systems fast as possible
and according to microsoft
according to microsoft it
to microsoft it includes
microsoft it includes a
it includes a web
includes a web browser
although i have not
th usenix symposium on
i have not seen
usenix symposium on operating
have not seen a
symposium on operating systems
not seen a complete
on operating systems design
seen a complete re
operating systems design and
systems design and implementation
implementation of the explorer
of the explorer for
the explorer for unix
compatible libraries from mainsoft
used in the port
in the port of
the port of internet
port of internet explorer
van renesse and f
of internet explorer show
internet explorer show that
explorer show that you
show that you do
that you do not
you do not need
do not need a
not need a windows
need a windows nt
a windows nt kernel
chain replication for supporting
windows nt kernel to
replication for supporting high
nt kernel to get
for supporting high throughput
kernel to get to
supporting high throughput and
to get to the
high throughput and availability
get to the same
to the same user
the same user experience
in sixth symposium on
sixth symposium on operating
many see the rich
symposium on operating systems
see the rich win
on operating systems design
operating systems design and
systems design and implementation
programming interface as the
interface as the native
as the native programming
the native programming model
native programming model for
programming model for windows
model for windows nt
and although most windows
although most windows applications
most windows applications are
windows applications are designed
applications are designed using
are designed using this
designed using this interface
combining acid and base
acid and base in
and base in a
it is not the
base in a distributed
is not the windows
in a distributed database
not the windows nt
the windows nt kernel
windows nt kernel interface
almost no applications are
no applications are built
applications are built using
are built using the
built using the kernel
th usenix symposium on
using the kernel interface
usenix symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
and you would have
systems design and implementation
you would have a
would have a hard
have a hard time
a hard time finding
hard time finding the
time finding the complete
finding the complete documentation
the complete documentation for
complete documentation for all
documentation for all the
for all the system
all the system calls
describing windows nt as
windows nt as a
nt as a micro
as the kernel is
the kernel is certainly
kernel is certainly not
is certainly not small
enabling scalable online personalization
scalable online personalization on
but it is does
online personalization on the
personalization on the web
it is does describe
is does describe the
does describe the abstraction
in proceedings of the
describe the abstraction correctly
the abstraction correctly in
abstraction correctly in which
nd acm conference on
correctly in which the
acm conference on electronic
in which the kernel
conference on electronic commerce
which the kernel provides
the kernel provides base
kernel provides base services
provides base services and
base services and the
services and the specific
and the specific application
the specific application context
specific application context is
application context is provided
context is provided through
is provided through subsystem
provided through subsystem servers
through subsystem servers or
subsystem servers or personalities
a shared log design
shared log design for
log design for flash
design for flash clusters
is one of the
one of the personalities
of the personalities running
the personalities running on
personalities running on top
running on top of
th usenix symposium on
on top of windows
usenix symposium on networked
top of windows nt
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
and posix are others
posix are others delivered
are others delivered by
others delivered by microsoft
one can run windows
can run windows nt
run windows nt without
windows nt without these
nt without these standard
without these standard personalities
these standard personalities and
standard personalities and build
personalities and build your
and build your own
what is an operating
is an operating system
this question seems to
question seems to be
seems to be on
to be on the
be on the mind
on the mind of
the mind of many
mind of many people
of many people these
many people these days
infused by the microsoft
by the microsoft trial
academics in general have
an architecture for well
in general have taken
general have taken a
have taken a very
taken a very narrow
a very narrow view
very narrow view of
narrow view of what
view of what an
of what an operating
what an operating system
an operating system is
in symposium on operating
symposium on operating systems
on operating systems principles
david faber at microsoft
faber at microsoft trial
at microsoft trial defined
microsoft trial defined an
trial defined an operating
defined an operating system
an operating system as
operating system as the
system as the software
as the software that
the software that controls
software that controls the
that controls the execution
controls the execution of
the execution of programs
execution of programs on
of programs on computer
programs on computer systems
on computer systems and
computer systems and may
systems and may provide
and may provide low
level services such as
services such as resource
such as resource allocation
output control in a
control in a form
in a form which
a form which is
form which is sufficiently
which is sufficiently simple
is sufficiently simple and
sufficiently simple and general
simple and general so
and general so that
general so that these
so that these services
that these services are
these services are broadly
services are broadly useful
are broadly useful to
broadly useful to software
useful to software developers
the costs and limits
costs and limits of
and limits of availability
limits of availability for
of availability for replicated
availability for replicated services
in proceedings of the
proceedings of the eighteenth
of the eighteenth acm
the eighteenth acm symposium
in research community this
eighteenth acm symposium on
research community this strict
acm symposium on operating
community this strict distinction
symposium on operating systems
this strict distinction serves
on operating systems principles
strict distinction serves to
distinction serves to distinguish
serves to distinguish the
to distinguish the real
distinguish the real men
the real men from
real men from the
men from the boys
researchers and hackers that
and hackers that work
hackers that work in
that work in the
work in the area
in the area defined
the area defined by
area defined by this
defined by this narrow
by this narrow definition
this narrow definition of
narrow definition of operating
definition of operating systems
consider themselves part of
themselves part of the
part of the select
of the select circle
the select circle of
select circle of people
circle of people working
of people working on
people working on the
working on the core
on the core of
the core of the
core of the systems
of the systems area
the systems area of
systems area of computer
area of computer science
once you are in
you are in this
are in this circle
in this circle you
this circle you will
circle you will become
you will become part
will become part of
become part of the
design and evaluation of
part of the secret
and evaluation of a
of the secret society
evaluation of a conitbased
the secret society that
of a conitbased continuous
secret society that practices
a conitbased continuous consistency
society that practices the
conitbased continuous consistency model
that practices the black
continuous consistency model for
practices the black art
consistency model for replicated
the black art of
model for replicated services
black art of os
art of os research
of os research and
acm transactions on computer
os research and will
transactions on computer systems
research and will start
and will start to
will start to regard
start to regard any
to regard any other
regard any other activity
any other activity of
other activity of systems
activity of systems development
of systems development as
systems development as irrelevant
development as irrelevant to
as irrelevant to the
irrelevant to the future
to the future of
the future of computer
future of computer science
for a long time
a long time the
long time the line
time the line was
the line was drawn
line was drawn at
was drawn at the
drawn at the kernel
and one could only
one could only consider
could only consider himself
only consider himself a
consider himself a true
himself a true os
a true os researcher
true os researcher after
os researcher after having
researcher after having developed
after having developed at
having developed at least
developed at least two
at least two device
least two device drivers
two device drivers and
device drivers and hacked
drivers and hacked on
and hacked on the
hacked on the terminal
on the terminal driver
the terminal driver of
terminal driver of the
driver of the bsd
in modern operating systems
modern operating systems such
operating systems such as
systems such as windows
such as windows nt
the notion of where
notion of where exactly
of where exactly operating
where exactly operating systems
exactly operating systems services
operating systems services are
systems services are located
services are located is
are located is not
located is not that
is not that simple
not that simple any
that simple any more
achieving serializability with low
fundamental services are split
serializability with low latency
services are split between
with low latency in
are split between kernel
low latency in geodistributed
split between kernel and
latency in geodistributed storage
between kernel and user
in geodistributed storage systems
kernel and user space
and user space in
user space in attempts
space in attempts to
in proceedings of the
in attempts to optimise
attempts to optimise their
to optimise their efficiency
optimise their efficiency and
their efficiency and avoid
efficiency and avoid uncontrolled
th acm symposium on
and avoid uncontrolled growth
acm symposium on operating
avoid uncontrolled growth of
symposium on operating systems
uncontrolled growth of kernel
on operating systems principles
growth of kernel services
the pervasiveness of distributed
pervasiveness of distributed services
of distributed services in
distributed services in modern
services in modern systems
in modern systems can
modern systems can be
systems can be considered
can be considered a
be considered a threat
considered a threat to
a threat to the
threat to the traditional
to the traditional notion
the traditional notion of
traditional notion of operating
notion of operating systems
many support services are
support services are required
services are required to
are required to make
required to make distributed
to make distributed systems
make distributed systems work
distributed systems work efficiently
systems work efficiently and
work efficiently and effectively
efficiently and effectively and
and effectively and these
effectively and these services
such as security and
as security and directory
security and directory services
and directory services or
directory services or distributed
services or distributed object
or distributed object support
distributed object support and
object support and cluster
support and cluster management
are not part of
not part of a
part of a traditional
of a traditional view
a traditional view of
traditional view of operating
view of operating systems
but they are essential
they are essential to
are essential to the
essential to the operation
to the operation of
the operation of modern
operation of modern operating
of modern operating systems
this results in that
results in that an
acm transactions on database
transactions on database systems
in that an operating
that an operating system
an operating system no
operating system no longer
system no longer is
no longer is a
longer is a simple
is a simple division
a simple division between
simple division between kernel
division between kernel and
between kernel and user
kernel and user space
but consist of a
consist of a myriad
of a myriad of
a myriad of services
of which some are
which some are kernilized
some are local and
are local and others
local and others are
and others are remote
operating systems that address
systems that address the
that address the needs
address the needs of
the needs of current
needs of current and
of current and future
current and future clients
and future clients and
future clients and informatik
clients and informatik informatique
operating systems servers no
systems servers no longer
servers no longer span
no longer span a
longer span a single
span a single computer
a single computer and
single computer and they
computer and they abstract
and they abstract services
they abstract services away
abstract services away from
services away from physical
away from physical nodes
from physical nodes allowing
physical nodes allowing user
nodes allowing user to
allowing user to be
user to be part
to be part of
be part of a
part of a larger
potential global operating environment
will the real dinosaur
the real dinosaur please
real dinosaur please come
dinosaur please come forward
until the spring of
we were deeply committed
were deeply committed to
deeply committed to sunos
and other bsd derivatives
at that moment its
that moment its vendor
moment its vendor was
its vendor was discontinuing
vendor was discontinuing the
was discontinuing the operating
discontinuing the operating system
and had designated solaris
which had its root
had its root in
its root in at
t s system v
s system v as
system v as the
v as the successor
this event forced us
event forced us to
forced us to take
us to take a
to take a step
take a step back
a step back and
step back and evaluate
back and evaluate our
and evaluate our research
evaluate our research directions
our research directions and
research directions and our
directions and our expectations
shoring up persistent applications
and our expectations with
our expectations with respect
expectations with respect to
in proceedings of the
with respect to the
respect to the operating
to the operating systems
the operating systems to
operating systems to use
if one issue in
one issue in our
issue in our discussions
in our discussions was
our discussions was dominant
acm sigmod international conference
sigmod international conference on
international conference on management
conference on management of
on management of data
it was the fact
was the fact that
the fact that most
fact that most of
that most of the
most of the operating
of the operating systems
the operating systems we
operating systems we were
systems we were looking
we were looking at
were looking at were
looking at were actually
at were actually very
were actually very old
actually very old fashioned
in structure and in
structure and in implementation
most of these operating
of these operating systems
these operating systems had
operating systems had their
systems had their conception
had their conception in
their conception in the
s and did not
and did not change
did not change much
not change much in
change much in structure
much in structure since
in structure since then
linux could be seen
could be seen as
be seen as an
seen as an exception
as an exception since
an exception since it
exception since it was
since it was developed
it was developed in
was developed in the
developed in the second
in the second half
the second half of
second half of the
live network streaming with
network streaming with utilities
streaming with utilities and
with utilities and cost
utilities and cost ymir
and cost ymir vigfusson
but its structure mirrored
its structure mirrored that
structure mirrored that of
mirrored that of the
that of the traditional
of the traditional unix
the traditional unix systems
and as such it
as such it could
such it could be
it could be considered
could be considered one
be considered one of
considered one of them
the significant advances made
significant advances made in
advances made in academic
made in academic computer
in academic computer science
in os research and
os research and in
research and in system
and in system software
in system software engineering
freedman school of computer
have had only minimal
school of computer science
had only minimal impact
only minimal impact on
minimal impact on the
impact on the design
on the design and
the design and implementation
design and implementation of
and implementation of commercial
implementation of commercial operating
of commercial operating systems
iceland of computer science
the design of all
design of all unix
of all unix systems
all unix systems violates
unix systems violates almost
systems violates almost all
violates almost all of
almost all of the
all of the software
usa school of electronics
of the software engineering
school of electronics engineering
the software engineering principles
of electronics engineering and
software engineering principles presented
electronics engineering and computer
engineering principles presented to
engineering and computer science
principles presented to first
presented to first year
to first year s
first year s computer
year s computer science
s computer science students
the design is monolithic
design is monolithic with
is monolithic with almost
monolithic with almost no
with almost no modular
almost no modular structure
and the internal kernel
the internal kernel interfaces
internal kernel interfaces are
kernel interfaces are not
interfaces are not strictly
are not strictly enforced
not strictly enforced which
strictly enforced which introduces
enforced which introduces dependencies
which introduces dependencies on
introduces dependencies on the
efficient optimistic concurrency control
dependencies on the actual
optimistic concurrency control using
on the actual implementation
concurrency control using loosely
the actual implementation of
control using loosely synchronized
actual implementation of data
using loosely synchronized clocks
implementation of data structures
making it impossible to
it impossible to upgrade
impossible to upgrade or
to upgrade or replace
upgrade or replace modules
or replace modules without
replace modules without also
modules without also redesigning
without also redesigning several
also redesigning several other
redesigning several other modules
department abstract the growth
for example to replace
abstract the growth in
example to replace the
the growth in internet
to replace the scheduler
growth in internet traffic
replace the scheduler in
in internet traffic associated
the scheduler in any
internet traffic associated with
scheduler in any of
traffic associated with video
in any of the
associated with video streaming
any of the bsd
with video streaming and
of the bsd s
video streaming and sharing
the bsd s one
streaming and sharing of
bsd s one needs
and sharing of videos
s one needs to
sharing of videos is
one needs to spend
of videos is so
needs to spend two
videos is so rapid
to spend two weeks
is so rapid that
spend two weeks searching
so rapid that it
two weeks searching for
rapid that it may
weeks searching for all
that it may soon
searching for all dependencies
it may soon dwarf
for all dependencies and
may soon dwarf all
all dependencies and fixing
soon dwarf all other
dependencies and fixing other
dwarf all other forms
and fixing other sources
all other forms of
other forms of internet
forms of internet content
at the top of
the top of our
one reason for this
top of our long
reason for this is
of our long wish
for this is that
our long wish list
this is that only
long wish list for
is that only some
wish list for an
that only some forms
list for an ideal
only some forms of
for an ideal research
some forms of content
an ideal research operating
forms of content can
ideal research operating system
of content can be
content can be cached
were three important general
three important general points
a scalable system for
scalable system for consistently
data generated in real
system for consistently caching
generated in real time
for consistently caching dynamic
the design and implementation
in real time such
design and implementation of
real time such as
consistently caching dynamic web
and implementation of the
time such as by
implementation of the operating
such as by live
caching dynamic web data
of the operating system
as by live video
the operating system should
by live video broadcasts
operating system should comply
system should comply with
should comply with modern
comply with modern software
with modern software engineering
modern software engineering principles
allowing researchers to introduce
researchers to introduce new
to introduce new components
iptv or new episodes
or new episodes of
new episodes of popular
and replace core components
episodes of popular tv
replace core components without
of popular tv shows
core components without redesigning
components without redesigning the
without redesigning the complete
redesigning the complete system
immersive virtual reality applications
virtual reality applications and
reality applications and games
the overall structure of
applications and games typically
overall structure of the
and games typically can
structure of the operating
games typically can t
of the operating system
typically can t be
can t be cached
t be cached at
be cached at all
user and kernel space
and kernel space components
and in today s
in today s systems
should be designed towards
be designed towards the
designed towards the future
each client may pull
a scalable web cache
client may pull such
scalable web cache consistency
may pull such information
web cache consistency architecture
pull such information on
such information on its
information on its own
on its own point
sigcomm computer communications review
should be pervasive throughout
be pervasive throughout the
pervasive throughout the whole
throughout the whole system
stream directly from the
directly from the data
from the data center
the operating system vendor
operating system vendor should
system vendor should be
vendor should be open
should be open to
even if large numbers
be open to innovation
if large numbers of
large numbers of clients
numbers of clients share
of clients share interest
our experiences in the
clients share interest in
experiences in the past
share interest in at
in the past had
interest in at least
the past had been
in at least some
past had been that
at least some aspects
had been that vendors
least some aspects of
been that vendors always
some aspects of the
that vendors always ignored
aspects of the data
vendors always ignored important
always ignored important research
ignored important research results
important research results and
we propose a new
research results and only
propose a new system
results and only followed
a new system called
and only followed very
new system called g
only followed very narrow
system called g radient
followed very narrow paths
called g radient aimed
very narrow paths of
g radient aimed at
narrow paths of incremental
radient aimed at reducing
paths of incremental improvements
aimed at reducing the
at reducing the load
reducing the load on
the load on providers
load on providers of
windows nt was the
on providers of such
nt was the only
providers of such and
was the only operating
of such and enabling
the only operating system
such and enabling scalable
only operating system that
operating system that came
system that came close
that came close to
came close to matching
bandwidthsensitive streaming service for
close to matching most
streaming service for heterogeneous
to matching most of
service for heterogeneous consumers
matching most of our
most of our requirements
the core of the
with a handful of
core of the system
a handful of operating
based cache management for
of the system is
handful of operating systems
the system is an
cache management for dynamic
of operating systems such
system is an overlay
operating systems such as
is an overlay networking
management for dynamic web
systems such as qnx
an overlay networking architecture
for dynamic web content
such as qnx and
overlay networking architecture intended
as qnx and utah
networking architecture intended to
qnx and utah s
architecture intended to run
and utah s os
intended to run directly
to run directly on
run directly on a
directly on a content
on a content hosting
a content hosting platform
none of the unix
of the unix based
the unix based operating
and which optimizes aggregate
unix based operating systems
which optimizes aggregate bandwidth
based operating systems came
optimizes aggregate bandwidth use
operating systems came close
aggregate bandwidth use by
systems came close to
bandwidth use by transforming
came close to fulfilling
use by transforming in
close to fulfilling our
to fulfilling our requirements
flight data to match
as noted before the
data to match the
noted before the core
to match the ideal
before the core of
match the ideal stream
the core of those
the ideal stream quality
core of those operating
ideal stream quality expressed
of those operating systems
stream quality expressed as
those operating systems is
quality expressed as an
operating systems is based
expressed as an economic
systems is based on
as an economic utility
alternative architectures and protocols
an economic utility of
architectures and protocols for
economic utility of the
and protocols for providing
utility of the consuming
protocols for providing strong
of the consuming client
for providing strong consistency
providing strong consistency in
strong consistency in dynamic
year old designs and
consistency in dynamic web
old designs and these
in dynamic web applications
designs and these operating
and these operating systems
introduction recent years have
these operating systems still
recent years have seen
operating systems still treat
years have seen skyrocketing
systems still treat computers
have seen skyrocketing demand
still treat computers as
seen skyrocketing demand for
treat computers as single
skyrocketing demand for internet
world wide web journal
computers as single entities
demand for internet bandwidth
as single entities without
single entities without a
entities without a coherent
increasingly dominated by real
time streaming of short
but in many forms
if trends continue then
trends continue then internet
continue then internet video
then internet video alone
internet video alone will
video alone will generate
alone will generate almost
exabytes per month by
per month by the
month by the end
by the end of
feet high windows nt
high windows nt looked
windows nt looked like
nt looked like the
looked like the proverbial
like the proverbial dinosaur
a closer look revealed
closer look revealed a
look revealed a truly
revealed a truly modern
a truly modern operating
truly modern operating system
percent of all internet
of all internet traffic
object oriented design is
oriented design is pervasive
design is pervasive through
is pervasive through the
pervasive through the system
through the system including
the system including the
system including the kernel
there is a complete
is a complete distributed
faced with a competitive
with a competitive landscape
a complete distributed strategy
complete distributed strategy with
distributed strategy with at
strategy with at its
isps and content providers
with at its core
and content providers are
at its core a
content providers are exploring
its core a distributed
providers are exploring technologies
core a distributed object
are exploring technologies to
a distributed object technology
exploring technologies to help
distributed object technology and
technologies to help satisfy
object technology and includes
to help satisfy the
technology and includes a
help satisfy the growing
and includes a complete
satisfy the growing demand
includes a complete integration
the growing demand alongside
a complete integration of
growing demand alongside the
cache coherence in distributed
complete integration of distributed
demand alongside the purchase
coherence in distributed systems
integration of distributed services
alongside the purchase of
of distributed services such
the purchase of expensive
distributed services such as
purchase of expensive infrastructure
services such as security
reducing the bandwidth consumption
the bandwidth consumption of
bandwidth consumption of simultaneous
consumption of simultaneous replicated
of simultaneous replicated content
simultaneous replicated content is
replicated content is a
content is a challenge
is a challenge which
a challenge which usually
challenge which usually leverages
and last no but
which usually leverages two
last no but least
usually leverages two main
leverages two main tools
there is a real
caching of content and
is a real desire
of content and multicasting
a real desire by
real desire by the
desire by the vendor
by the vendor to
some forms of video
the vendor to continuously
forms of video content
vendor to continuously innovate
to continuously innovate its
continuously innovate its operating
innovate its operating system
such as downloads of
its operating system and
as downloads of unencrypted
operating system and the
downloads of unencrypted movies
system and the overall
of unencrypted movies or
and the overall services
unencrypted movies or films
movies or films where
or films where many
films where many users
where many users will
microsoft doesn t hesitate
many users will share
doesn t hesitate to
users will share the
t hesitate to incorporate
will share the same
hesitate to incorporate academic
share the same encryption
to incorporate academic results
the same encryption key
incorporate academic results into
academic results into operating
results into operating system
and is open for
a global cache coherent
is open for new
global cache coherent file
a wide variety of
cache coherent file system
wide variety of caching
open for new directions
variety of caching options
of caching options exist
innovation as a life
as a life style
a life style microsoft
life style microsoft is
style microsoft is not
microsoft is not conservative
is not conservative in
not conservative in its
conservative in its os
in its os development
while most vendors only
most vendors only consider
vendors only consider changes
only consider changes to
of which is the
consider changes to their
which is the akamai
changes to their core
is the akamai content
to their core os
the akamai content distribution
their core os services
akamai content distribution network
core os services under
os services under extreme
services under extreme market
under extreme market pressure
is arguably the most
the core of windows
arguably the most famous
core of windows nt
of windows nt has
windows nt has changed
a distributed memory object
nt has changed significantly
distributed memory object caching
has changed significantly over
memory object caching system
changed significantly over the
significantly over the past
over the past years
the past years to
past years to accommodate
years to accommodate the
to accommodate the demands
multicast techniques can reduce
accommodate the demands of
techniques can reduce the
the demands of modern
can reduce the overall
demands of modern computing
reduce the overall network
the overall network traffic
overall network traffic by
network traffic by taking
especially the upcoming release
traffic by taking advantage
the upcoming release of
by taking advantage of
upcoming release of windows
taking advantage of the
advantage of the packet
of the packet replication
the packet replication and
packet replication and forwarding
replication and forwarding within
and forwarding within the
forwarding within the network
within the network infrastructure
the deployment of the
deployment of the efficient
formerly known as windows
of the efficient network
known as windows nt
makes that the microsoft
that the microsoft takes
the microsoft takes the
microsoft takes the operating
takes the operating system
the operating system functionality
operating system functionality to
system functionality to the
functionality to the next
to the next level
distributed data structures for
data structures for internet
the advances in windows
structures for internet service
area internet has failed
for internet service construction
in proceedings of the
th conference on symposium
are too numerous to
conference on symposium on
too numerous to enumerate
and so more expensive
on symposium on operating
numerous to enumerate here
so more expensive application
symposium on operating system
on operating system design
they range from a
level overlays are generally
range from a file
overlays are generally used
from a file system
a file system cache
file system cache for
system cache for disconnected
cache for disconnected operation
which was originally developed
was originally developed at
originally developed at cmu
developed at cmu in
at cmu in the
cmu in the coda
in the coda project
the devices used by
devices used by content
used by content subscribers
by content subscribers have
to a remote storage
content subscribers have become
a remote storage service
subscribers have become increasingly
remote storage service that
have become increasingly heterogeneous
storage service that automatically
become increasingly heterogeneous mobile
service that automatically moves
increasingly heterogeneous mobile devices
that automatically moves old
automatically moves old data
moves old data from
old data from your
data from your hard
from your hard disk
your hard disk to
are projected to consume
hard disk to remote
projected to consume over
disk to remote servers
to remote servers if
remote servers if you
servers if you are
if you are running
you are running out
are running out of
running out of disk
out of disk space
exabytes of video per
of video per month
from tight security integration
video per month in
as the dominant security
the dominant security provider
to a complete integration
a complete integration of
complete integration of network
integration of network quality
of network quality of
network quality of services
quality of services tools
of services tools including
services tools including data
tools including data transmission
implying that a range
including data transmission shapers
that a range of
data transmission shapers and
a range of subscription
transmission shapers and priority
range of subscription rates
shapers and priority scheduling
of subscription rates and
and priority scheduling and
subscription rates and policies
priority scheduling and queuing
rates and policies must
and policies must be
policies must be applied
must be applied over
be applied over the
and from attributed based
applied over the user
from attributed based distributed
over the user base
attributed based distributed component
based distributed component programming
distributed component programming to
component programming to indexing
programming to indexing support
to indexing support integrated
indexing support integrated in
support integrated in the
integrated in the file
in the file system
even if multiple users
if multiple users are
multiple users are streaming
users are streaming the
are streaming the same
streaming the same event
we are witnesses of
are witnesses of a
such as watching the
witnesses of a unique
as watching the opening
of a unique process
watching the opening ceremony
the opening ceremony of
opening ceremony of the
ceremony of the olympics
never before have we
before have we seen
have we seen such
a smartphone user will
we seen such a
smartphone user will need
seen such a radical
user will need a
such a radical overhaul
will need a differently
a radical overhaul of
need a differently transcoded
radical overhaul of an
a differently transcoded version
overhaul of an operating
differently transcoded version than
of an operating system
transcoded version than the
an operating system targeted
version than the people
operating system targeted for
than the people watching
system targeted for the
the people watching via
targeted for the enterprise
people watching via internet
for the enterprise market
watching via internet television
in general this market
general this market is
this market is very
or on their laptops
market is very conservative
is very conservative and
very conservative and not
conservative and not interested
and not interested in
not interested in taking
interested in taking risks
different consumer groups may
consumer groups may desire
groups may desire different
may desire different local
however the problems of
desire different local ads
the problems of scale
different local ads or
local ads or sub
management and distribution are
titles to be embedded
and distribution are asking
to be embedded into
distribution are asking for
be embedded into their
are asking for radical
embedded into their video
asking for radical solutions
into their video streams
for radical solutions to
radical solutions to get
solutions to get to
to get to a
get to a computing
to a computing base
a computing base that
computing base that can
avatars in a virtual
base that can bring
in a virtual world
that can bring us
a virtual world can
can bring us into
virtual world can be
bring us into the
world can be viewed
us into the next
can be viewed as
into the next century
be viewed as subscribers
viewed as subscribers to
as subscribers to updates
subscribers to updates about
to updates about objects
one of the markets
updates about objects in
about objects in their
of the markets where
objects in their vicinity
the markets where we
tier database caching for
markets where we will
database caching for e
and may want more
where we will see
may want more detailed
we will see the
want more detailed updates
will see the main
more detailed updates for
see the main competitive
detailed updates for objects
the main competitive battle
updates for objects that
main competitive battle between
in international conference on
for objects that are
competitive battle between microsoft
international conference on management
objects that are closer
battle between microsoft and
conference on management of
that are closer to
between microsoft and others
on management of data
are closer to them
microsoft and others will
closer to them in
and others will be
to them in this
others will be that
them in this world
will be that of
be that of the
that of the e
while this growing heterogeneity
this growing heterogeneity of
growing heterogeneity of device
heterogeneity of device types
web farms with hundreds
farms with hundreds of
with hundreds of nodes
research on cdns has
on cdns has generally
cdns has generally assumed
has generally assumed a
with support services for
generally assumed a homogeneous
support services for load
assumed a homogeneous population
services for load balancing
a homogeneous population of
homogeneous population of end
distributed and single image
and single image management
are really pushing the
really pushing the envelope
pushing the envelope of
the envelope of all
envelope of all operating
of all operating systems
thus most current systems
all operating systems that
operating systems that are
most current systems assume
systems that are currently
that are currently on
current systems assume multiple
are currently on the
currently on the market
systems assume multiple video
assume multiple video streams
multiple video streams to
windows nt is still
video streams to be
nt is still considered
streams to be sent
is still considered to
to be sent from
still considered to be
be sent from the
considered to be the
sent from the source
consistent and scalable cache
from the source at
to be the new
and scalable cache replication
the source at different
be the new kid
scalable cache replication for
source at different resolutions
the new kid on
at different resolutions or
cache replication for multi
new kid on the
different resolutions or that
kid on the block
resolutions or that a
on the block in
or that a single
the block in the
that a single highquality
block in the internet
a single highquality stream
in the internet services
single highquality stream is
the internet services world
highquality stream is transcoded
stream is transcoded by
is transcoded by the
transcoded by the receiver
but it is clear
by the receiver who
it is clear that
the receiver who then
is clear that the
receiver who then incurs
clear that the risks
who then incurs cost
that the risks that
then incurs cost for
the risks that are
incurs cost for last
risks that are taken
that are taken now
are taken now are
taken now are the
now are the right
mile traffic owing to
are the right moves
traffic owing to unnecessarily
the right moves to
owing to unnecessarily detailed
right moves to prepare
to unnecessarily detailed video
moves to prepare the
to prepare the operating
prepare the operating system
the operating system for
we pose the following
operating system for operation
pose the following question
system for operation in
for operation in these
operation in these emerging
in these emerging massive
these emerging massive computing
how can we deliver
emerging massive computing environments
can we deliver live
we deliver live dynamic
deliver live dynamic content
the bugs innovation comes
bugs innovation comes at
such as video broadcasts
innovation comes at a
comes at a price
or financial stock data
one of the costs
of the costs of
over the internet to
the costs of introducing
the internet to large
costs of introducing a
internet to large number
of introducing a significant
to large number of
introducing a significant amount
large number of heterogeneous
a significant amount of
number of heterogeneous users
significant amount of new
of heterogeneous users simultaneously
amount of new code
heterogeneous users simultaneously while
of new code is
users simultaneously while balancing
new code is the
consistent and scalable caching
code is the number
simultaneously while balancing bandwidth
is the number of
while balancing bandwidth costs
the number of software
and scalable caching in
number of software defects
scalable caching in multitier
traffic rates and end
of software defects per
caching in multitier architectures
software defects per lines
defects per lines of
per lines of codes
lines of codes increases
the international journal on
international journal on very
journal on very large
on very large data
very large data bases
while measurements actually let
live content refers to
measurements actually let us
content refers to content
actually let us believe
refers to content streams
let us believe that
to content streams that
us believe that microsoft
content streams that must
believe that microsoft products
streams that must be
that microsoft products are
that must be transmitted
microsoft products are quite
must be transmitted to
products are quite reliable
be transmitted to multiple
are quite reliable at
transmitted to multiple receivers
quite reliable at operating
to multiple receivers simultaneously
reliable at operating systems
such as a live
as a live broadcast
thousand lines of code
ticker updates for financial
updates for financial stocks
for financial stocks or
financial stocks or object
stocks or object updates
or object updates in
object updates in a
updates in a virtual
in a virtual world
fresh code has a
code has a disastrous
has a disastrous effect
a disastrous effect on
disastrous effect on this
effect on this number
we are not focused
are not focused on
not focused on streams
focused on streams with
the outlook becomes even
on streams with a
outlook becomes even more
streams with a pause
becomes even more worrisome
with a pause or
even more worrisome when
a pause or rewind
more worrisome when we
pause or rewind functions
worrisome when we realize
or rewind functions or
when we realize that
rewind functions or the
we realize that microsoft
functions or the video
realize that microsoft is
that microsoft is not
microsoft is not only
is not only introducing
not only introducing new
only introducing new code
but is also changing
is also changing all
also changing all of
changing all of its
all of its old
of its old code
the gradient cdn to
gradient cdn to make
cdn to make progress
an automated process is
to make progress towards
automated process is converting
make progress towards the
process is converting all
progress towards the research
is converting all of
towards the research question
converting all of the
all of the windows
of the windows nt
the windows nt code
windows nt code to
nt code to be
we propose a novel
propose a novel networked
a novel networked content
novel networked content delivery
networked content delivery system
content delivery system called
delivery system called g
system called g radient
called g radient to
g radient to address
radient to address the
to address the complex
thousand lines of code
address the complex caching
lines of code per
the complex caching and
of code per day
complex caching and multicasting
code per day and
caching and multicasting issues
per day and is
and multicasting issues associated
day and is believed
multicasting issues associated with
and is believed to
issues associated with live
is believed to catch
associated with live streaming
believed to catch all
improving application throughput with
with live streaming of
to catch all pointer
live streaming of dynamic
catch all pointer arithmetic
streaming of dynamic content
all pointer arithmetic cases
of dynamic content to
application throughput with enterprise
dynamic content to a
throughput with enterprise javabeans
content to a heterogeneous
with enterprise javabeans caching
an important question is
to a heterogeneous user
important question is whether
a heterogeneous user population
question is whether the
in international conference on
is whether the introduced
international conference on distributed
whether the introduced functionality
conference on distributed computing
the systems architecture consists
the introduced functionality is
systems architecture consists of
introduced functionality is worth
architecture consists of one
functionality is worth the
on distributed computing systems
consists of one or
is worth the unavoidable
of one or more
worth the unavoidable initial
one or more content
the unavoidable initial instability
or more content providers
unavoidable initial instability that
more content providers which
initial instability that is
content providers which together
instability that is bound
providers which together form
that is bound to
which together form a
is bound to occur
together form a cooperative
form a cooperative network
a cooperative network of
cooperative network of g
network of g radient
whenever taking risks to
of g radient cdn
taking risks to achieve
g radient cdn nodes
risks to achieve major
to achieve major improvements
the cdn nodes form
cdn nodes form a
there is always the
nodes form a dynamic
form a dynamic overlay
is always the down
a dynamic overlay over
dynamic overlay over which
always the down side
overlay over which the
over which the content
the down side that
which the content is
the content is delivered
down side that there
side that there is
that there is some
and for our initial
there is some change
for our initial prototypes
is some change of
our initial prototypes we
some change of failure
initial prototypes we will
change of failure and
prototypes we will look
of failure and it
we will look at
failure and it is
will look at spanning
and it is likely
look at spanning trees
it is likely that
is likely that we
likely that we will
the concept of cdn
that we will see
concept of cdn nodes
we will see a
of cdn nodes is
will see a number
cdn nodes is general
see a number of
a number of components
number of components of
of components of nt
components of nt coming
an architecture in which
of nt coming under
architecture in which cdn
currency serializability for middle
nt coming under intense
in which cdn servers
coming under intense scrutiny
which cdn servers are
under intense scrutiny from
tier caching and replication
cdn servers are hosted
servers are hosted by
are hosted by isps
hosted by isps to
in international conference on
by isps to reduce
international conference on management
isps to reduce redundant
conference on management of
to reduce redundant incoming
on management of data
reduce redundant incoming bandwidth
redundant incoming bandwidth is
incoming bandwidth is a
bandwidth is a logical
is a logical scenario
and another example is
another example is that
example is that g
is that g radient
that g radient nodes
g radient nodes may
radient nodes may as
nodes may as well
may as well be
as well be integrated
well be integrated into
be integrated into set
intense scrutiny from industry
scrutiny from industry and
from industry and academia
our approach to the
approach to the problem
to the problem resembles
such as the directory
the problem resembles content
as the directory services
may become a performance
a ppendix we now
become a performance bottleneck
ppendix we now prove
and in fact the
a performance bottleneck in
we now prove theorem
in fact the expected
performance bottleneck in the
fact the expected deployment
bottleneck in the overall
the expected deployment model
in the overall distributed
expected deployment model would
the overall distributed operation
deployment model would employ
model would employ a
would employ a geographically
employ a geographically distributed
or the wide spread
a geographically distributed set
the wide spread security
geographically distributed set of
wide spread security integration
cache with unbounded cache
spread security integration could
with unbounded cache size
security integration could introduce
distributed set of isps
integration could introduce a
unbounded cache size and
could introduce a critical
cache size and unbounded
introduce a critical dependency
size and unbounded dependency
set of isps or
a critical dependency on
of isps or small
critical dependency on the
and unbounded dependency lists
isps or small data
dependency on the high
or small data centers
unbounded dependency lists implements
small data centers of
dependency lists implements cache
availability of the security
data centers of the
of the security servers
centers of the kind
of the kind operated
the kind operated by
kind operated by today
from a research point
operated by today s
a research point of
since we assume that
by today s cdn
research point of view
we assume that the
today s cdn providers
assume that the transactional
that the transactional db
these problems do not
the transactional db is
problems do not really
transactional db is serializable
do not really bother
not really bother us
whereas today s content
the operations in an
operations in an execution
the advantage of performing
hosting sites cache objects
advantage of performing research
in an execution of
of performing research on
an execution of update
performing research on a
research on a system
execution of update transactions
of update transactions update
update transactions update can
transactions update can be
which has distribution at
update can be serialized
has distribution at its
can be serialized as
be serialized as some
distribution at its core
serialized as some serial
at its core greatly
as some serial execution
its core greatly outweighs
our focus is on
core greatly outweighs the
focus is on content
greatly outweighs the consequences
is on content that
outweighs the consequences of
on content that cannot
the consequences of working
content that cannot be
the next claim trivially
consequences of working with
that cannot be usefully
of working with a
next claim trivially follows
cannot be usefully cached
working with a cutting
claim trivially follows from
with a cutting edge
the g radient project
a cutting edge operating
trivially follows from the
g radient project aims
cutting edge operating system
radient project aims to
follows from the definition
project aims to exploit
from the definition of
aims to exploit and
however i must admit
to exploit and develop
the definition of the
exploit and develop two
i must admit that
and develop two techniques
definition of the database
must admit that at
of the database dependency
develop two techniques that
the database dependency list
admit that at more
two techniques that improve
database dependency list specification
techniques that improve on
that at more then
that improve on existing
improve on existing cdns
at more then one
more then one occasion
then one occasion my
one occasion my students
and algorithms to balance
occasion my students had
if is a serialization
my students had to
algorithms to balance bandwidth
is a serialization of
to balance bandwidth costs
students had to control
balance bandwidth costs with
a serialization of the
had to control their
bandwidth costs with end
serialization of the update
to control their murderous
of the update transactions
control their murderous intentions
the update transactions of
their murderous intentions towards
our design is focused
update transactions of an
design is focused on
murderous intentions towards the
is focused on modularity
transactions of an execution
focused on modularity and
intentions towards the iis
on modularity and incremental
of an execution update
modularity and incremental deployment
towards the iis or
the iis or mts
iis or mts developers
or mts developers or
at every step in
mts developers or were
developers or were they
or were they kept
the version dependencies of
were they kept their
version dependencies of every
they kept their good
dependencies of every object
kept their good spirits
of every object match
their good spirits by
every object match those
good spirits by contemplating
object match those stored
dynamic content has substantial
spirits by contemplating the
content has substantial levels
match those stored in
by contemplating the horrible
has substantial levels of
contemplating the horrible tortures
substantial levels of redundancy
those stored in its
the horrible tortures one
stored in its dependency
horrible tortures one could
even when user interests
tortures one could perform
when user interests are
in its dependency list
one could perform on
user interests are relatively
could perform on the
interests are relatively heterogeneous
perform on the person
on the person that
the person that had
person that had designed
widespread use of streaming
that had designed the
use of streaming video
had designed the com
of streaming video occurs
we first describe a
designed the com security
streaming video occurs when
the com security architecture
video occurs when internet
first describe a routine
occurs when internet users
describe a routine for
when internet users watch
windows research there are
internet users watch major
research there are some
a routine for placing
users watch major events
there are some properties
routine for placing a
watch major events online
are some properties of
for placing a read
some properties of windows
properties of windows nt
such as superbowl or
of windows nt that
as superbowl or the
windows nt that make
superbowl or the olympics
only transaction from a
nt that make it
transaction from a cache
that make it particularly
from a cache server
make it particularly suitable
and like television users
it particularly suitable for
a cache server in
particularly suitable for research
cache server in a
such clients have little
suitable for research purposes
clients have little tolerance
server in a serialization
have little tolerance for
in a serialization of
little tolerance for lagged
the operating system kernel
a serialization of a
tolerance for lagged data
operating system kernel for
serialization of a subset
system kernel for example
of a subset of
kernel for example is
for example is designed
large numbers of users
example is designed with
numbers of users have
is designed with extensibility
to form a serialization
of users have essentially
designed with extensibility in
form a serialization of
users have essentially the
with extensibility in mind
a serialization of both
have essentially the same
serialization of both the
essentially the same needs
to allow developers of
of both the update
allow developers of hardware
both the update transaction
developers of hardware based
but since they may
the update transaction and
of hardware based services
since they may access
update transaction and the
they may access the
transaction and the read
may access the streams
new protocols and file
access the streams from
protocols and file systems
the streams from a
and file systems to
streams from a variety
file systems to add
from a variety of
systems to add their
a variety of devices
to add their functionality
add their functionality to
their functionality to the
functionality to the system
with different screen sizes
to the system without
different screen sizes and
the system without much
screen sizes and resolutions
system without much effort
or different connectivity properties
all kernel code is
kernel code is developed
code is developed following
is developed following a
developed following a strict
following a strict object
the current solution is
a strict object oriented
current solution is to
strict object oriented paradigm
solution is to provide
object oriented paradigm and
is to provide each
oriented paradigm and its
to provide each user
paradigm and its functionality
provide each user with
and its functionality can
each user with a
its functionality can only
user with a direct
functionality can only be
with a direct connection
can only be accessed
a direct connection to
only be accessed through
direct connection to a
be accessed through interfaces
connection to a content
none of its implementation
server due to the
of its implementation is
due to the lack
its implementation is visible
to the lack of
the lack of robust
lack of robust multicast
of robust multicast technologies
one of the designs
of the designs abstractions
similar issues arise for
the designs abstractions of
issues arise for newscasts
arise for newscasts of
designs abstractions of the
for newscasts of fast
abstractions of the windows
performing this permutation is
of the windows nt
this permutation is one
the windows nt kernel
permutation is one step
windows nt kernel i
transmission of financial data
nt kernel i find
of financial data and
kernel i find it
financial data and virtual
i find it particularly
is one step of
data and virtual on
find it particularly fascinating
one step of the
it particularly fascinating to
step of the routine
particularly fascinating to work
fascinating to work with
our insight is that
to work with is
insight is that a
work with is the
we repeat this step
is that a data
with is the device
repeat this step forming
is the device object
this step forming a
rich channel can be
step forming a series
channel can be transformed
a device object in
forming a series of
can be transformed on
device object in an
a series of permutations
object in an instance
in an instance created
an instance created by
instance created by driver
each permutation is a
network to create the
created by driver objects
to create the dynamic
permutation is a serialization
create the dynamic content
is a serialization of
the dynamic content for
which encapsulates a unit
a serialization of update
dynamic content for end
encapsulates a unit of
a unit of kernel
unit of kernel based
of kernel based software
and each permutes a
each permutes a range
permutes a range of
a range of the
whether this is a
range of the transactions
we could add personalized
of the transactions with
could add personalized advertisements
the transactions with respect
this is a device
transactions with respect to
is a device driver
with respect to the
subtitles or encryption keys
respect to the previous
a network protocol or
or encryption keys to
to the previous step
network protocol or a
encryption keys to iptv
protocol or a file
keys to iptv broadcasts
or a file system
in each step the
a file system filter
each step the right
filters or aggregates to
step the right end
or aggregates to financial
the right end of
these objects have the
aggregates to financial stock
objects have the interesting
to financial stock updates
right end of the
have the interesting property
end of the range
the interesting property that
or reduce the update
interesting property that they
reduce the update rate
property that they can
of the range is
the update rate for
that they can be
update rate for distant
they can be attached
rate for distant objects
the range is earlier
can be attached to
for distant objects in
range is earlier than
be attached to other
distant objects in the
attached to other device
is earlier than in
objects in the virtual
to other device objects
in the virtual world
earlier than in the
the virtual world to
than in the previous
virtual world to which
in the previous step
and as such can
world to which the
as such can intercept
to which the user
such can intercept and
can intercept and manipulate
as one or more
which the user has
intercept and manipulate all
the user has subscribed
and manipulate all requests
one or more of
manipulate all requests flowing
or more of the
all requests flowing to
more of the objects
the same mechanism will
requests flowing to and
same mechanism will also
flowing to and from
mechanism will also allow
to and from the
of the objects is
will also allow the
and from the original
also allow the system
from the original device
the objects is closer
allow the system to
the original device object
the system to tailor
objects is closer to
system to tailor to
is closer to the
to tailor to heterogeneous
this way it is
closer to the value
way it is relatively
tailor to heterogeneous devices
it is relatively simple
to the value read
is relatively simple to
the value read by
relatively simple to add
value read by t
simple to add for
to add for example
add for example a
eventually we therefore reach
for example a file
transcoding a high definition
example a file system
we therefore reach a
a high definition broadcast
a file system object
therefore reach a permutation
high definition broadcast to
file system object that
reach a permutation where
definition broadcast to adapt
system object that compresses
a permutation where at
broadcast to adapt its
object that compresses or
permutation where at the
to adapt its resolution
that compresses or encrypts
where at the chosen
adapt its resolution to
compresses or encrypts data
at the chosen time
its resolution to serve
or encrypts data before
resolution to serve a
the chosen time all
to serve a population
chosen time all read
serve a population of
encrypts data before the
a population of heterogeneous
data before the data
time all read objects
population of heterogeneous devices
all read objects are
before the data reaches
of heterogeneous devices from
the data reaches the
read objects are at
data reaches the under
heterogeneous devices from cell
reaches the under laying
objects are at their
devices from cell phones
the under laying file
from cell phones to
under laying file system
are at their correct
cell phones to tablets
at their correct versions
phones to tablets to
to redirect disk requests
to tablets to iptv
redirect disk requests to
tablets to iptv lowering
we place t there
to iptv lowering overall
disk requests to a
iptv lowering overall bandwidth
requests to a replication
place t there to
lowering overall bandwidth costs
to a replication volume
overall bandwidth costs without
t there to obtain
bandwidth costs without affecting
there to obtain the
or to trace device
to obtain the desired
to trace device object
obtain the desired serialization
trace device object interaction
costs without affecting viewing
device object interaction during
the desired serialization of
without affecting viewing experience
object interaction during development
desired serialization of the
interaction during development phases
serialization of the update
of the update transactions
the update transactions and
update transactions and t
the strict object oriented
strict object oriented approach
object oriented approach is
oriented approach is very
network transformations will be
approach is very well
transformations will be applied
permutation routine let be
is very well done
will be applied with
routine let be an
very well done from
be applied with pluggable
well done from a
let be an execution
done from a design
applied with pluggable serverlets
be an execution of
from a design point
with pluggable serverlets designed
an execution of the
a design point of
pluggable serverlets designed to
execution of the t
design point of view
serverlets designed to execute
designed to execute within
to execute within the
execute within the cdn
and denote by update
style hacker s heart
denote by update the
hacker s heart starts
by update the projection
s heart starts bleeding
update the projection of
heart starts bleeding when
the projection of on
starts bleeding when he
projection of on the
bleeding when he or
of on the set
when he or she
on the set of
he or she realizes
the set of database
or she realizes that
set of database update
she realizes that he
of database update transactions
realizes that he can
that he can no
he can no longer
can no longer do
transaction t reads objects
no longer do a
t reads objects o
longer do a quick
do a quick fix
inspect a few data
within the cdn nodes
a few data structures
the cdn nodes of
few data structures and
cdn nodes of g
data structures and secretly
nodes of g radient
structures and secretly swivel
and secretly swivel some
secretly swivel some pointers
swivel some pointers to
the serverlets encapsulate application
some pointers to make
pointers to make things
to make things work
make things work better
speci n ac details
things work better or
n ac details such
work better or make
ac details such as
better or make more
details such as the
or make more informed
such as the stream
on with versions v
make more informed decisions
as the stream data
the stream data format
the internal kernel interfaces
internal kernel interfaces are
kernel interfaces are elaborate
and the ways to
the ways to transform
ways to transform a
but it appears there
to transform a the
it appears there are
transform a the data
appears there are always
there are always some
are always some things
always some things one
rich objects into more
some things one cannot
objects into more specialized
things one cannot do
into more specialized ones
one cannot do as
cannot do as efficient
do as efficient as
as efficient as possible
open issues include understanding
issues include understanding what
include understanding what kinds
understanding what kinds of
what kinds of content
take any serialization of
kinds of content may
in four years of
of content may be
any serialization of update
four years of nt
content may be subject
years of nt kernel
may be subject to
of nt kernel hacking
one exists according to
nt kernel hacking only
be subject to such
kernel hacking only on
subject to such transformation
hacking only on one
exists according to claim
to such transformation and
only on one occasion
such transformation and which
on one occasion we
transformation and which dynamic
one occasion we needed
and which dynamic content
occasion we needed to
which dynamic content is
we needed to break
dynamic content is not
needed to break through
and consider the first
to break through the
consider the first time
break through the standard
to assess the effect
through the standard kernel
assess the effect of
the first time when
the standard kernel interface
the effect of the
first time when all
effect of the transformation
time when all the
of the transformation on
we wanted to add
the transformation on quality
when all the objects
wanted to add a
transformation on quality and
to add a fast
all the objects the
on quality and traffic
add a fast trap
quality and traffic rates
the objects the transaction
a fast trap into
objects the transaction reads
fast trap into the
how transformation should be
the transaction reads are
trap into the kernel
transformation should be meaningfully
transaction reads are at
into the kernel for
should be meaningfully expressed
reads are at a
the kernel for fast
be meaningfully expressed and
are at a version
kernel for fast user
meaningfully expressed and used
at a version at
expressed and used by
a version at least
and used by content
version at least as
used by content providers
and the pages which
at least as large
the pages which hold
least as large as
pages which hold the
and to learn how
which hold the trap
as large as the
to learn how computationally
hold the trap dispatch
learn how computationally intensive
the trap dispatch tables
how computationally intensive such
trap dispatch tables were
large as the versions
computationally intensive such transformation
as the versions that
intensive such transformation methods
dispatch tables were protected
such transformation methods can
tables were protected after
the versions that t
transformation methods can be
were protected after the
methods can be without
protected after the system
can be without overloading
after the system boot
be without overloading the
versions that t reads
without overloading the nodes
another example of what
at this time at
example of what makes
balancing bandwidth costs with
of what makes windows
this time at least
what makes windows nt
time at least one
makes windows nt particular
bandwidth costs with end
windows nt particular suitable
at least one object
nt particular suitable for
least one object read
particular suitable for research
one object read by
the g radi ent
suitable for research is
g radi ent content
for research is the
object read by t
radi ent content delivery
research is the fundamental
ent content delivery system
is the fundamental manner
content delivery system is
the fundamental manner in
delivery system is currently
the last written according
fundamental manner in which
system is currently designed
manner in which advanced
is currently designed to
in which advanced distributed
currently designed to use
which advanced distributed services
designed to use a
last written according to
advanced distributed services are
to use a spanningtree
distributed services are integrated
use a spanningtree overlay
services are integrated into
are integrated into windows
has the correct version
integrated into windows nt
similar to most multicast
to most multicast network
most multicast network architectures
but others might not
it allows us to
with virtual links connecting
allows us to rely
virtual links connecting g
assume without loss of
links connecting g radient
us to rely on
connecting g radient cdn
without loss of generality
g radient cdn nodes
to rely on ubiquitous
loss of generality that
rely on ubiquitous support
of generality that the
the question is to
on ubiquitous support services
generality that the last
question is to determine
ubiquitous support services and
is to determine what
that the last version
support services and concentrate
the last version written
services and concentrate on
to determine what nodes
and concentrate on advancing
last version written is
determine what nodes the
version written is vn
concentrate on advancing the
what nodes the in
on advancing the state
written is vn of
advancing the state of
is vn of object
network processing and connecting
the state of the
processing and connecting to
vn of object on
state of the art
and connecting to the
of the art where
of object on at
connecting to the diverse
the art where it
object on at step
to the diverse end
art where it is
on at step t
where it is really
at step t of
it is really needed
users should be done
denote by t the
by t the latest
windows nt security provides
t the latest time
nt security provides a
we need to optimize
security provides a complete
need to optimize the
provides a complete set
the latest time at
to optimize the overlay
a complete set of
optimize the overlay to
complete set of services
latest time at which
the overlay to deliver
set of services integrated
overlay to deliver the
of services integrated into
to deliver the exact
services integrated into all
deliver the exact stream
integrated into all sections
the exact stream quality
into all sections of
time at which a
exact stream quality demanded
all sections of the
stream quality demanded by
sections of the operating
quality demanded by users
of the operating system
demanded by users while
at which a wrong
by users while minimizing
which a wrong version
users while minimizing bandwidth
researchers who are developing
while minimizing bandwidth costs
who are developing an
are developing an advanced
not the one read
developing an advanced multi
the one read by
one read by t
we propose to apply
node replicated transaction server
propose to apply an
replicated transaction server can
to apply an economics
transaction server can use
apply an economics framework
server can use off
and assume wlog it
assume wlog it is
wlog it is version
it is version vn
considering two primary inputs
two primary inputs in
primary inputs in determining
inputs in determining the
in determining the optimal
determining the optimal network
the optimal network overlay
k of object on
on the one hand
rather than the desired
than the desired version
we consider the cost
the desired version vn
and encryption mechanisms into
consider the cost for
encryption mechanisms into their
the cost for network
mechanisms into their system
cost for network edges
into their system without
for network edges to
their system without much
network edges to carry
system without much pain
edges to carry traffic
we now describe a
the use of the
similar to standard bandwidth
now describe a single
use of the com
to standard bandwidth pricing
of the com object
describe a single step
the com object model
a single step of
com object model in
single step of the
we leverage the perceived
object model in all
leverage the perceived utility
step of the routine
the perceived utility by
model in all the
perceived utility by end
in all the windows
consider the transactions between
all the windows nt
the transactions between t
users for receiving the
the windows nt services
for receiving the stream
transactions between t and
windows nt services allows
receiving the stream at
between t and t
nt services allows research
the stream at a
services allows research projects
stream at a given
allows research projects to
at a given quality
research projects to import
projects to import these
to import these services
import these services in
these services in a
divide these transactions into
services in a very
these transactions into three
the exact solution for
in a very simple
exact solution for this
a very simple manner
transactions into three sets
solution for this optimization
for this optimization problem
this optimization problem is
optimization problem is intractable
the existence of com
problem is intractable it
existence of com makes
is intractable it is
of com makes it
intractable it is np
com makes it trivial
transactions dependent on the
makes it trivial for
dependent on the transaction
it trivial for research
on the transaction at
trivial for research projects
the transaction at t
for research projects to
research projects to export
we have developed algorithms
projects to export their
have developed algorithms that
to export their interfaces
developed algorithms that give
export their interfaces in
algorithms that give an
their interfaces in a
that give an approximate
interfaces in a language
give an approximate optimal
in a language independent
an approximate optimal solution
a language independent manner
transactions on which t
on which t is
which t is dependent
the ensemble project for
ensemble project for example
in the case of
project for example has
the case of video
for example has developed
case of video streams
example has developed a
of video streams whose
has developed a protocol
video streams whose quality
developed a protocol environment
streams whose quality and
a protocol environment for
whose quality and traffic
protocol environment for distributed
transactions that do not
environment for distributed operations
that do not belong
for distributed operations in
quality and traffic rates
distributed operations in the
do not belong to
and traffic rates can
operations in the ml
not belong to either
traffic rates can be
in the ml programming
rates can be downgraded
the ml programming language
can be downgraded by
belong to either group
be downgraded by g
downgraded by g radient
by g radient cdn
and by using a
g radient cdn nodes
the following lemma states
by using a com
following lemma states that
using a com interface
we have derived a
a com interface are
lemma states that there
have derived a primaldual
com interface are the
derived a primaldual approximation
interface are the services
a primaldual approximation algorithm
are the services offered
primaldual approximation algorithm which
states that there is
approximation algorithm which produces
that there is no
algorithm which produces a
the services offered by
there is no dependency
which produces a solution
services offered by ensemble
is no dependency among
produces a solution whose
offered by ensemble available
no dependency among objects
a solution whose total
by ensemble available to
dependency among objects in
solution whose total cost
ensemble available to c
among objects in sets
the difference between total
difference between total network
between total network traffic
total network traffic costs
network traffic costs and
traffic costs and aggregate
costs and aggregate end
and hence there is
java and vb programmers
hence there is no
there is no intersection
is no intersection between
no intersection between the
this allowed the researchers
is within a factor
intersection between the sets
allowed the researchers to
within a factor of
the researchers to side
step the time consuming
the time consuming development
time consuming development of
consuming development of native
development of native language
of native language interfaces
it helps of course
helps of course to
of course to have
course to have all
of the optimal in
to have all the
the optimal in the
have all the tools
optimal in the worst
in the worst case
if they were dependent
then version vn of
version vn of object
operating system versions and
vn of object on
system versions and their
of object on depends
versions and their source
object on depends on
and their source code
on depends on version
their source code available
depends on version vn
we see that the
see that the algorithm
microsoft is very generous
that the algorithm has
is very generous to
the algorithm has lower
very generous to academia
k of object on
generous to academia and
algorithm has lower total
to academia and makes
has lower total cost
academia and makes all
lower total cost compared
and makes all their
total cost compared to
and this dependency is
makes all their tools
cost compared to a
all their tools from
this dependency is reflected
compared to a single
their tools from operating
to a single stream
dependency is reflected in
tools from operating systems
a single stream source
from operating systems to
is reflected in their
single stream source and
operating systems to compilers
stream source and a
reflected in their t
source and a minimum
and a minimum spanning
including tons of documentation
a minimum spanning tree
tons of documentation as
of documentation as well
minimum spanning tree streaming
documentation as well as
spanning tree streaming protocol
as well as subscriptions
because they are unbounded
tree streaming protocol in
well as subscriptions to
streaming protocol in a
as subscriptions to the
protocol in a simulation
subscriptions to the developer
in a simulation based
to the developer network
a simulation based on
simulation based on a
transaction t has read
based on a collection
available to the departments
on a collection of
to the departments free
a collection of as
the departments free of
t has read version
departments free of charge
has read version vn
source code availability turned
code availability turned out
availability turned out to
turned out to be
out to be not
to be not crucial
gradient mst naive broadcast
which is older than
mst naive broadcast total
is older than vn
and was only once
naive broadcast total cost
was only once used
only once used to
once used to make
used to make actual
to make actual changes
make actual changes to
actual changes to the
changes to the operating
to the operating systems
the read of the
read of the stale
of the stale version
the stale version vn
von eicken et al
would have been detected
have been detected by
been detected by t
cache and the transaction
and the transaction would
the transaction would have
transaction would have been
the source is extremely
would have been aborted
source is extremely useful
is extremely useful as
extremely useful as additional
useful as additional documentation
therefore the assumption is
the assumption is wrong
to examine unexpected behaviour
examine unexpected behaviour or
unexpected behaviour or to
and the sets are
behaviour or to provide
the sets are indeed
or to provide templates
sets are indeed independent
to provide templates for
provide templates for similar
templates for similar projects
as one can perform
one can perform complete
perhaps an empty set
can perform complete source
perform complete source code
complete source code level
is unrelated to sets
source code level debugging
code level debugging of
level debugging of all
debugging of all parts
of all parts of
all parts of the
parts of the operating
of the operating system
the operating system including
we therefore switch sets
operating system including the
system including the kernel
source codes helps us
codes helps us to
helps us to develop
us to develop experimental
to develop experimental services
develop experimental services faster
experimental services faster and
services faster and in
faster and in tune
maintaining a serialization of
and in tune with
a serialization of update
in tune with existing
tune with existing functionality
students are free to
consider the following serialization
are free to work
free to work with
to work with the
work with the source
with the source code
xi denotes a transaction
the source code and
denotes a transaction x
source code and are
a transaction x in
code and are not
transaction x in set
and are not prohibited
x in set i
are not prohibited in
not prohibited in any
prohibited in any way
in any way from
any way from applying
way from applying the
from applying the knowledge
applying the knowledge they
the knowledge they gained
knowledge they gained in
they gained in their
gained in their later
cache consistency we proceed
in their later careers
consistency we proceed to
we proceed to prove
proceed to prove theorem
interactions with the evil
with the evil empire
the evil empire microsoft
evil empire microsoft realizes
let be an execution
empire microsoft realizes the
the g radient optimization
be an execution of
microsoft realizes the potential
g radient optimization is
an execution of the
realizes the potential of
radient optimization is effective
execution of the t
the potential of widespread
optimization is effective compared
potential of widespread adoption
is effective compared to
of widespread adoption of
effective compared to a
widespread adoption of windows
compared to a centralized
adoption of windows nt
and denote by update
to a centralized source
of windows nt for
denote by update the
windows nt for research
by update the projection
a centralized source and
nt for research purposes
centralized source and a
update the projection of
for research purposes and
the projection of on
source and a minimum
research purposes and there
projection of on the
purposes and there is
of on the set
and a minimum spanning
and there is dedicated
on the set of
a minimum spanning tree
there is dedicated academic
the set of database
is dedicated academic relations
set of database update
dedicated academic relations team
of database update transactions
academic relations team whose
protocol even as system
relations team whose single
even as system sizes
as system sizes scale
team whose single task
system sizes scale up
whose single task it
single task it is
task it is to
it is to facilitate
error bars represent one
is to facilitate the
bars represent one standard
represent one standard deviation
to facilitate the technology
one standard deviation over
facilitate the technology transfer
the technology transfer between
technology transfer between microsoft
transfer between microsoft and
between microsoft and academia
microsoft and academia and
and academia and vice
academia and vice versa
source licensing is very
licensing is very liberal
tm a set of
is very liberal compared
the details are deferred
very liberal compared to
details are deferred to
a set of readonly
are deferred to a
liberal compared to other
set of readonly transactions
deferred to a full
compared to other os
of readonly transactions performed
to a full report
to other os vendors
readonly transactions performed through
a full report on
other os vendors and
transactions performed through a
full report on g
os vendors and several
performed through a single
report on g radient
vendors and several institutions
through a single t
and several institutions are
several institutions are involved
institutions are involved in
are involved in active
involved in active exchanges
in active exchanges with
active exchanges with product
if the read sets
exchanges with product and
conclusion a number of
the read sets of
with product and research
a number of interesting
read sets of two
product and research groups
number of interesting open
sets of two transactions
of interesting open questions
of two transactions include
interesting open questions remain
and research groups within
open questions remain the
two transactions include the
research groups within microsoft
questions remain the focus
transactions include the same
remain the focus of
include the same object
the focus of our
joint projects are in
the same object o
focus of our continued
projects are in progress
of our continued investigation
we say the one
joint papers are starting
how diverse are the
say the one that
papers are starting to
diverse are the classes
are starting to appear
the one that read
starting to appear and
one that read a
to appear and academics
are the classes of
appear and academics frequently
that read a larger
and academics frequently present
the classes of content
academics frequently present cutting
classes of content that
frequently present cutting edge
of content that are
present cutting edge result
content that are amenable
cutting edge result to
that are amenable to
edge result to microsoft
are amenable to our
result to microsoft developers
read a larger version
amenable to our in
to microsoft developers and
a larger version of
microsoft developers and researchers
larger version of o
version of o depends
of o depends on
o depends on the
depends on the other
how do we best
do we best assess
we best assess the
best assess the effect
all transactions access the
assess the effect of
transactions access the same
the effect of such
access the same cache
effect of such transformations
of such transformations on
such transformations on stream
and the cache is
transformations on stream quality
the cache is unbounded
how should these transformations
should these transformations be
operating systems there is
these transformations be expressed
systems there is a
values are only replaced
there is a direct
are only replaced by
is a direct impact
only replaced by newer
a direct impact of
replaced by newer versions
and utilized by the
direct impact of academia
utilized by the originating
impact of academia on
by the originating content
of academia on microsoft
the originating content providers
academia on microsoft products
originating content providers to
so it is easy
content providers to best
it is easy to
through involvement in the
is easy to see
involvement in the strategy
providers to best balance
in the strategy phases
to best balance content
easy to see that
the strategy phases of
to see that there
strategy phases of products
domain specificity with ease
phases of products as
specificity with ease of
see that there are
of products as well
with ease of development
products as well as
that there are no
as well as through
there are no cycles
well as through academic
are no cycles such
how can our overlay
as through academic knowledge
can our overlay respond
through academic knowledge transfer
no cycles such that
our overlay respond to
academic knowledge transfer into
overlay respond to churn
knowledge transfer into products
cycles such that two
respond to churn among
transfer into products and
to churn among g
into products and design
churn among g radient
such that two transactions
products and design groups
among g radient nodes
that two transactions depend
g radient nodes realistically
two transactions depend on
microsoft also provides research
transactions depend on one
also provides research funding
radient nodes realistically low
provides research funding for
nodes realistically low in
research funding for some
realistically low in many
funding for some relevant
low in many common
for some relevant groups
in many common cases
depend on one another
some relevant groups and
many common cases such
relevant groups and fellowship
common cases such as
groups and fellowship and
cases such as video
the dependency graph therefore
such as video streaming
dependency graph therefore describes
and fellowship and research
graph therefore describes a
fellowship and research internships
therefore describes a partial
but higher in alternative
and research internships for
higher in alternative deployment
describes a partial order
in alternative deployment scenarios
a partial order of
research internships for students
partial order of the
order of the read
summary four years of
four years of research
years of research on
of research on windows
how do we ensure
and we choose an
do we ensure that
research on windows nt
we choose an arbitrary
we ensure that the
on windows nt have
ensure that the computational
windows nt have taught
choose an arbitrary total
that the computational intensity
nt have taught us
the computational intensity of
have taught us that
an arbitrary total ordering
computational intensity of our
taught us that we
intensity of our transformations
us that we made
of our transformations do
that we made the
our transformations do not
we made the right
transformations do not place
do not place too
arbitrary total ordering that
made the right choice
not place too much
the right choice in
total ordering that respects
place too much load
right choice in leaving
too much load on
ordering that respects this
choice in leaving the
much load on our
that respects this partial
in leaving the unix
load on our g
respects this partial order
leaving the unix behind
on our g radient
our g radient overlay
g radient overlay nodes
assume wlog the order
windows nt is an
wlog the order is
nt is an exiting
the order is t
g radient contributes a
radient contributes a novel
contributes a novel platform
a novel platform for
years ahead of its
novel platform for continued
ahead of its competition
platform for continued study
for continued study and
continued study and progress
study and progress to
and progress to ever
progress to ever more
to ever more effective
ever more effective delivery
more effective delivery mechanisms
in its implementation and
its implementation and in
implementation and in the
and in the actual
in the actual services
the actual services offered
it took quite some
took quite some time
we take an initial
quite some time to
take an initial arbitrary
some time to reach
an initial arbitrary serialization
time to reach the
to reach the same
reach the same level
the same level of
of and permute it
same level of knowledge
and permute it according
level of knowledge and
permute it according to
of knowledge and insight
it according to the
knowledge and insight we
according to the route
and insight we used
to the route above
insight we used to
the route above to
we used to have
route above to place
used to have of
above to place t
to have of unix
have of unix systems
but now that we
now that we have
that we have arrived
we have arrived at
have arrived at that
arrived at that same
at that same knowledge
that same knowledge point
bandwidth multicast in cooperative
the result is a
multicast in cooperative environments
result is a permutation
is it clear that
it clear that our
clear that our research
that our research is
our research is making
research is making progress
is making progress faster
making progress faster than
progress faster than ever
faster than ever before
we take all transactions
working with windows nt
take all transactions that
with windows nt requires
all transactions that precede
windows nt requires certain
transactions that precede t
nt requires certain level
requires certain level of
certain level of resilience
not because of flaws
because of flaws in
of flaws in the
flaws in the operating
does not depend on
in the operating system
not depend on them
but because of the
and place them after
because of the zealous
place them after t
of the zealous attacks
the zealous attacks by
zealous attacks by colleagues
attacks by colleagues and
by colleagues and other
colleagues and other researchers
approaching the zettabyte era
we call this permutation
cisco visual networking index
publishing papers about research
papers about research performed
about research performed on
next we place t
research performed on windows
performed on windows nt
on windows nt is
windows nt is still
nt is still quite
is still quite difficult
still quite difficult as
quite difficult as many
difficult as many of
as many of our
many of our peer
can be placed immediately
of our peer still
be placed immediately after
our peer still believe
placed immediately after t
peer still believe that
still believe that no
believe that no good
that no good research
no good research can
good research can be
research can be performed
we place it there
can be performed on
place it there to
be performed on windows
it there to form
performed on windows nt
global mobile data traffic
mobile data traffic forecast
data traffic forecast update
we hope that eventually
hope that eventually the
that eventually the advanced
eventually the advanced technical
is independent of t
the advanced technical nature
advanced technical nature of
technical nature of the
then all its preceding
nature of the operating
all its preceding transactions
of the operating system
the operating system will
operating system will prevail
system will prevail in
according to the dependency
will prevail in the
to the dependency graph
prevail in the discussion
are unrelated to t
and that we can
that we can have
and are therefore located
we can have a
are therefore located after
can have a community
therefore located after it
have a community where
a community where research
community where research results
the permutations required are
where research results can
permutations required are therefore
research results can be
required are therefore after
results can be shared
are therefore after t
can be shared without
be shared without sarcasm
shared without sarcasm or
without sarcasm or the
sarcasm or the risk
or the risk of
the risk of igniting
risk of igniting yet
of igniting yet another
igniting yet another holy
yet another holy war
all relevant update transactions
relevant update transactions are
update transactions are located
transactions are located after
are located after t
multicast routing in datagram
routing in datagram internetworks
and therefore the permutations
in datagram internetworks and
therefore the permutations required
datagram internetworks and extended
the permutations required are
internetworks and extended lans
permutations required are all
required are all after
are all after t
acm transactions on computer
transactions on computer systems
since in all cases
in all cases the
all cases the permutations
cases the permutations are
the permutations are after
permutations are after t
they do not affect
do not affect the
not affect the correctness
affect the correctness of
the correctness of t
we take the resulting
take the resulting permutation
the resulting permutation that
resulting permutation that we
permutation that we call
and move all transactions
move all transactions that
all transactions that neither
transactions that neither t
depend on to right
on to right after
to right after t
the resulting permutation is
expert testimony of professor
testimony of professor david
of professor david j
we repeat this process
repeat this process until
this process until we
process until we place
until we place all
we place all read
this is a serialization
is a serialization of
a serialization of the
serialization of the update
of the update transactions
the update transactions in
update transactions in and
transactions in and all
in and all read
only transactions that accessed
transactions that accessed the
that accessed the same
accessed the same cache
we have therefore shown
have therefore shown that
therefore shown that in
shown that in any
that in any execution
in any execution of
any execution of t
cache the update transactions
the update transactions can
update transactions can be
transactions can be serialized
can be serialized with
be serialized with readonly
serialized with readonly transactions
with readonly transactions that
readonly transactions that accessed
transactions that accessed a
and analysis of a
that accessed a single
analysis of a peer
accessed a single cache
which means that t
cache implements cache serializability
uwin unix for windows
the usenix windows nt
usenix windows nt workshop
scaling virtual worlds with
virtual worlds with a
worlds with a physical
with a physical metaphor
th edition with source
edition with source code
a platform for distributed
platform for distributed service
for distributed service deployment
distributed service deployment in
service deployment in end
deployment in end user
in end user homes
the design and implementation
design and implementation of
and implementation of the
what s new in
s new in windows
ordering transactions with prediction
transactions with prediction in
with prediction in distributed
prediction in distributed object
in distributed object stores
distributed object stores ittay
object stores ittay eyal
department of computer science
department of electrical engineering
israel abstract numbers of
abstract numbers of storage
numbers of storage nodes
when client transactions access
client transactions access data
transactions access data on
access data on multiple
data on multiple shards
the issue of consistency
issue of consistency arises
nick vasilatos and werner
vasilatos and werner vogels
do you need source
you need source with
we would use a
need source with that
would use a system
use a system with
a system with acid
system with acid transactions
panel at the usenix
at the usenix windows
the usenix windows nt
usenix windows nt workshop
rx for data center
for data center communication
data center communication scalability
because this model facilitates
this model facilitates reasoning
model facilitates reasoning about
facilitates reasoning about system
reasoning about system properties
about system properties and
system properties and makes
properties and makes possible
and makes possible a
makes possible a variety
possible a variety of
a variety of highassurance
variety of highassurance guarantees
the acid model is
acid model is often
model is often avoided
is often avoided in
often avoided in today
avoided in today s
summary in usenix login
in today s large
scale systems due to
systems due to efficiency
due to efficiency concerns
existing approaches typically run
approaches typically run transactions
typically run transactions speculatively
run transactions speculatively and
transactions speculatively and perform
speculatively and perform certification
and perform certification after
perform certification after they
certification after they complete
after they complete to
they complete to preserve
complete to preserve consistency
unix application portability to
application portability to windows
either committing or aborting
portability to windows nt
committing or aborting each
to windows nt via
or aborting each transaction
windows nt via an
aborting each transaction depending
nt via an alternative
each transaction depending on
via an alternative environment
transaction depending on conflicts
an alternative environment subsystem
the usenix windows nt
usenix windows nt workshop
rain an architecture for
an architecture for acid
architecture for acid transactions
for acid transactions in
acid transactions in a
transactions in a resilient
in a resilient archive
a resilient archive with
resilient archive with independent
archive with independent nodes
the system orders transactions
system orders transactions before
orders transactions before they
transactions before they begin
before they begin by
live streaming with utilities
they begin by employing
begin by employing predictors
by employing predictors that
employing predictors that estimate
predictors that estimate the
that estimate the set
estimate the set of
the set of objects
set of objects each
of objects each transaction
objects each transaction will
each transaction will access
such predictors can be
predictors can be implemented
can be implemented with
be implemented with machine
implemented with machine learning
with machine learning tools
a transaction reserves a
transaction reserves a version
reserves a version of
a version of each
version of each object
of each object it
each object it will
object it will use
when later accessing the
later accessing the objects
it will see these
will see these reserved
see these reserved versions
protect the future of
the future of computing
future of computing technology
leases for future object
an architecture for scalable
for future object versions
architecture for scalable and
for scalable and fault
leases are issued for
are issued for a
issued for a predefined
for a predefined time
a predefined time period
not the lease holder
may unilaterally decide to
unilaterally decide to ignore
decide to ignore a
to ignore a reservation
to run effectively at
run effectively at large
effectively at large scale
rain must tolerate performance
must tolerate performance hiccups
all of which are
of which are common
which are common in
are common in such
common in such settings
progress should never depend
should never depend on
never depend on the
depend on the responsiveness
on the responsiveness of
the responsiveness of any
responsiveness of any single
of any single machine
rain requires reliable entities
requires reliable entities in
reliable entities in cloud
it is common to
is common to shard
data across large numbers
across large numbers of
large numbers of nodes
atomic transactions are typically
transactions are typically implemented
are typically implemented by
typically implemented by running
implemented by running transactions
by running transactions speculatively
and then certifying them
aborting ones that cause
ones that cause conflicts
in high contention scenarios
this approach has drawbacks
rather than achieving any
than achieving any substantial
achieving any substantial level
any substantial level of
substantial level of concurrency
it prevents concurrency by
prevents concurrency by aborting
concurrency by aborting all
by aborting all but
aborting all but one
all but one of
but one of the
one of the contending
of the contending transactions
our work explores a
work explores a new
explores a new option
ordering transactions in advance
transactions in advance based
in advance based on
advance based on the
based on the objects
on the objects they
the objects they are
objects they are likely
they are likely to
are likely to access
providing acid transactions in
acid transactions in a
transactions in a resilient
in a resilient archive
a resilient archive with
resilient archive with independent
archive with independent nodes
this preliminary ordering decreases
preliminary ordering decreases abort
ordering decreases abort rate
and eliminates aborts in
eliminates aborts in error
to allow fast recovery
allow fast recovery from
fast recovery from failures
recovery from failures our
from failures our scheme
failures our scheme does
our scheme does not
scheme does not introduce
does not introduce any
not introduce any locks
the system consistency and
system consistency and durability
consistency and durability rely
and durability rely on
durability rely on a
rely on a single
on a single scalable
a single scalable tier
single scalable tier of
scalable tier of highly
simulations using the transactional
transparent error correction for
error correction for lambda
correction for lambda networks
ycsb workloads show the
for lambda networks mahesh
workloads show the scalability
lambda networks mahesh balakrishnan
show the scalability and
the scalability and benefits
scalability and benefits of
and benefits of acidrain
center computing systems often
computing systems often maintain
systems often maintain massive
often maintain massive data
maintain massive data sets
sharded over large this
over large this work
large this work was
this work was funded
process communication primitives for
by grants from darpa
communication primitives for programming
primitives for programming distributed
for programming distributed systems
programming distributed systems robbert
distributed systems robbert van
systems robbert van renesse
and the elkin research
the elkin research fund
department of computer science
of computer science cornell
computer science cornell university
science cornell university category
only at a single
at a single tier
representation the following position
a single tier of
the following position paper
single tier of the
following position paper describes
tier of the system
position paper describes a
of the system a
paper describes a new
the system a set
describes a new interprocess
system a set of
a new interprocess communication
abstract the global network
a set of independent
the global network of
set of independent highly
global network of datacenters
of independent highly available
primitive that is designed
network of datacenters is
independent highly available logs
that is designed to
of datacenters is emerging
is designed to make
datacenters is emerging as
designed to make it
used in a novel
is emerging as an
to make it easier
emerging as an important
make it easier to
as an important distributed
in a novel manner
it easier to program
an important distributed systems
easier to program distributed
important distributed systems paradigm
to program distributed algorithms
all other entities may
distributed systems paradigm commodity
other entities may fail
systems paradigm commodity clusters
it is largely based
paradigm commodity clusters running
is largely based on
commodity clusters running high
entities may fail and
largely based on my
may fail and can
based on my experience
fail and can be
on my experience in
and can be replaced
my experience in implementing
can be replaced instantly
experience in implementing algorithms
speed lambda networks across
in implementing algorithms such
be replaced instantly on
lambda networks across hundreds
implementing algorithms such as
networks across hundreds of
algorithms such as distributed
across hundreds of milliseconds
such as distributed consensus
hundreds of milliseconds of
of milliseconds of network
replaced instantly on failure
milliseconds of network latency
packet loss on long
the architecture maintains consistency
architecture maintains consistency even
maintains consistency even in
consistency even in the
haul networks can cripple
subject to your evaluation
networks can cripple application
to your evaluation of
can cripple application performance
your evaluation of my
cripple application performance a
even in the event
evaluation of my proposal
application performance a loss
in the event of
performance a loss rate
the event of false
a loss rate of
i would be happy
event of false suspicion
would be happy to
be happy to present
happy to present this
to present this idea
present this idea at
this idea at the
idea at the workshop
reservations serve as suggestions
serve as suggestions a
ipc allows processes to
as suggestions a reservation
is sufficient to reduce
allows processes to share
suggestions a reservation that
sufficient to reduce tcp
processes to share information
a reservation that is
to share information and
reservation that is not
share information and to
ip throughput by an
information and to synchronize
that is not used
throughput by an order
and to synchronize actions
by an order of
is not used because
an order of magnitude
not used because of
order of magnitude on
used because of a
of magnitude on a
because of a sluggish
there are two classes
of a sluggish or
are two classes of
a sluggish or dead
two classes of ipc
sluggish or dead owner
or dead owner is
dead owner is ignored
maelstrom is an edge
the independence of system
is an edge appliance
independence of system elements
an edge appliance that
of system elements allows
edge appliance that masks
system elements allows for
appliance that masks packet
elements allows for good
that masks packet loss
allows for good scalability
mc has processes communicate
masks packet loss transparently
has processes communicate send
packet loss transparently and
processes communicate send and
loss transparently and quickly
communicate send and receive
transparently and quickly from
send and receive messages
and quickly from inter
due to the interdependence
to the interdependence of
the interdependence of the
while sm allows processes
interdependence of the log
sm allows processes to
aggregating traffic for high
allows processes to share
of the log contents
processes to share data
to share data directly
speed encoding and using
share data directly while
encoding and using a
data directly while synchronizing
and using a new
directly while synchronizing using
using a new forward
while synchronizing using such
a new forward error
synchronizing using such primitives
new forward error correction
using such primitives as
forward error correction scheme
such primitives as mutexes
error correction scheme to
primitives as mutexes and
correction scheme to handle
as mutexes and condition
scheme to handle bursty
mutexes and condition variables
to handle bursty loss
has to be carefully
to be carefully coordinated
be carefully coordinated to
carefully coordinated to maintain
coordinated to maintain consistency
where processes are physically
processes are physically separated
introduction the emergence of
we evaluate our architecture
the emergence of commodity
evaluate our architecture by
emergence of commodity clusters
our architecture by simulation
mc is dominant as
of commodity clusters and
is dominant as e
commodity clusters and datacenters
dominant as e orts
architecture by simulation with
clusters and datacenters has
as e orts to
and datacenters has enabled
e orts to support
datacenters has enabled a
orts to support the
by simulation with the
has enabled a new
to support the sm
enabled a new class
support the sm paradigm
a new class of
the sm paradigm have
simulation with the transactional
new class of globally
sm paradigm have not
class of globally distributed
paradigm have not been
of globally distributed highperformance
have not been successful
globally distributed highperformance applications
distributed highperformance applications that
highperformance applications that coordinate
applications that coordinate over
examples of sm include
that coordinate over vast
of sm include tcp
coordinate over vast geographical
sm include tcp connections
over vast geographical distances
we contrast the effectiveness
a financial firm s
contrast the effectiveness of
financial firm s new
the effectiveness of employing
firm s new york
the mc and sm
s new york city
effectiveness of employing prediction
mc and sm paradigms
new york city datacenter
and sm paradigms are
york city datacenter may
sm paradigms are duals
of employing prediction and
city datacenter may receive
paradigms are duals in
employing prediction and the
datacenter may receive real
are duals in that
prediction and the scalability
duals in that one
and the scalability of
time updates from a
in that one can
updates from a stock
that one can be
from a stock exchange
one can be implememted
a stock exchange in
the scalability of acid
can be implememted using
stock exchange in switzerland
be implememted using the
implememted using the other
rain with other approaches
conduct financial transactions with
but they also each
financial transactions with banks
they also each have
transactions with banks in
also each have their
with banks in asia
each have their advantages
have their advantages and
their advantages and disadvantages
tm m om i
advantages and disadvantages when
cache data in london
and disadvantages when compared
data in london for
disadvantages when compared with
in london for locality
when compared with one
london for locality and
compared with one another
for locality and mirror
locality and mirror it
and mirror it to
mirror it to kansas
it to kansas for
it is useful to
to kansas for disaster
is useful to consider
useful to consider how
om n om i
to consider how distributed
consider how distributed algorithms
how distributed algorithms such
distributed algorithms such as
to interconnect these bandwidth
algorithms such as replication
hungry datacenters across the
datacenters across the globe
log i log n
i log n figure
organizations are increasingly deploying
are increasingly deploying private
increasingly deploying private lambda
deploying private lambda networks
typically it has much
schematic structure of acid
it has much to
has much to do
much to do with
to do with progress
tms access multiple objects
in order for some
access multiple objects per
order for some process
multiple objects per transaction
for some process to
some process to be
process to be able
to be able to
objects are managed by
be able to make
are managed by oms
able to make a
to make a transition
raw bandwidth is ubiquitous
it needs to know
bandwidth is ubiquitous and
needs to know that
is ubiquitous and cheaply
to know that one
ubiquitous and cheaply available
know that one or
and cheaply available in
that one or more
cheaply available in the
one or more other
available in the form
is falsely suspected to
or more other processes
in the form of
more other processes have
falsely suspected to have
other processes have reached
the form of existing
suspected to have failed
processes have reached a
form of existing dark
have reached a particular
of existing dark fiber
reached a particular milestone
and replaced by omi
and some data associated
some data associated with
data associated with that
running and maintaining high
associated with that milestone
causing them to concurrently
free networks over this
a new leader in
them to concurrently serve
networks over this fiber
new leader in paxos
to concurrently serve the
leader in paxos needs
over this fiber is
concurrently serve the same
in paxos needs to
this fiber is difficult
paxos needs to know
fiber is difficult and
serve the same objects
is difficult and expensive
needs to know that
to know that a
oms are backed by
know that a quorum
are backed by highlyavailable
that a quorum of
backed by highlyavailable logs
capacity optical links are
a quorum of acceptors
optical links are almost
links are almost never
quorum of acceptors have
are almost never congested
of acceptors have progressed
where they store tentative
acceptors have progressed to
they drop packets for
have progressed to its
drop packets for numerous
they store tentative transaction
packets for numerous reasons
progressed to its proposed
for numerous reasons dirty
to its proposed ballot
store tentative transaction entries
its proposed ballot and
tentative transaction entries for
proposed ballot and it
transaction entries for serialization
ballot and it needs
and it needs to
it needs to know
needs to know what
to know what the
know what the highest
what the highest accepted
the highest accepted proposals
highest accepted proposals from
accepted proposals from those
proposals from those acceptors
from those acceptors are
many if not all
if not all distributed
not all distributed algorithms
all distributed algorithms can
distributed algorithms can be
algorithms can be cleanly
system structure the structure
can be cleanly expressed
structure the structure of
be cleanly expressed this
the structure of the
cleanly expressed this way
structure of the system
of the system is
the system is illustrated
system is illustrated in
is illustrated in figure
as a collection of
a collection of transition
collection of transition specifications
of transition specifications that
transition specifications that specify
specifications that specify under
at the base of
that specify under which
the base of acid
specify under which conditions
under which conditions they
which conditions they are
rain are a set
conditions they are enabled
are a set of
they are enabled and
for example and in
are enabled and what
a set of independent
example and in different
enabled and what state
set of independent highly
and in different patterns
and what state they
what state they need
state they need from
they need from other
ranging from singleton drops
need from other processes
available logs that together
from singleton drops to
logs that together describe
singleton drops to extended
note the similarity to
that together describe the
drops to extended bursts
the similarity to knowledge
together describe the state
describe the state of
the state of the
state of the entire
of the entire system
while the sm paradigm
each log is accessed
the sm paradigm seems
log is accessed through
sm paradigm seems the
is accessed through an
paradigm seems the best
accessed through an object
seems the best fit
through an object manager
the best fit for
best fit for this
fit for this model
for this model of
this model of distributed
model of distributed algorithms
congestion loss has been
the paradigm is hard
that caches the data
paradigm is hard to
caches the data and
is hard to make
the data and provides
loss has been observed
hard to make efficient
has been observed on
data and provides the
been observed on long
and provides the data
provides the data structure
the data structure abstraction
data structure abstraction exporting
and scalable in a
structure abstraction exporting read
scalable in a physically
haul networks as well
abstraction exporting read and
in a physically distributed
exporting read and write
a physically distributed system
read and write operations
it is notoriously errorprone
which are managed by
is notoriously errorprone as
are managed by transaction
notoriously errorprone as programmers
managed by transaction managers
errorprone as programmers are
as programmers are having
programmers are having difficulty
are having difficulty utilizing
having difficulty utilizing the
difficulty utilizing the synchronization
utilizing the synchronization primitives
the synchronization primitives correctly
tms provide the atomic
provide the atomic transaction
the mc paradigm can
the atomic transaction abstraction
mc paradigm can be
paradigm can be used
can be used instead
be used instead but
they receive instructions from
used instead but is
receive instructions from clients
instead but is awkward
instructions from clients to
but is awkward and
from clients to start
is awkward and error
clients to start and
to start and end
start and end a
and end a transaction
prone as well it
as well it requires
and operations to perform
well it requires the
operations to perform on
it requires the programmer
to perform on individual
requires the programmer to
perform on individual objects
the programmer to figure
on individual objects within
programmer to figure out
individual objects within the
to figure out which
objects within the transaction
figure out which processes
out which processes should
which processes should send
processes should send which
should send which data
send which data to
the tms predict which
which data to which
tms predict which objects
data to which destinations
predict which objects it
to which destinations at
which objects it is
which destinations at which
ms w n s
destinations at which times
w n s e
objects it is likely
n s e figure
at which times in
it is likely to
which times in order
is likely to access
times in order to
in order to ensure
and reserve these object
example lambda network tional
order to ensure that
lambda network tional lambdarail
reserve these object versions
to ensure that recipients
ensure that recipients of
that recipients of this
recipients of this data
of this data can
this data can make
data can make progress
they speculatively perform each
speculatively perform each operation
perform each operation with
each operation with the
sometimes messages are lost
operation with the help
messages are lost if
with the help of
are lost if the
the help of the
lost if the receiver
help of the appropriate
if the receiver starts
of the appropriate oms
the receiver starts execution
the appropriate oms and
receiver starts execution after
appropriate oms and according
starts execution after the
oms and according to
execution after the sender
and according to the
after the sender has
according to the order
the sender has started
to the order set
sender has started sending
the order set by
has started sending messages
order set by the
as has its crippling
started sending messages to
set by the reservations
has its crippling effect
sending messages to it
its crippling effect on
crippling effect on commodity
effect on commodity protocols
they certify the transaction
motivating research into loss
certify the transaction by
the transaction by checking
transaction by checking for
by checking for conflicts
resistant data transfer protocols
checking for conflicts in
pray semantics of connectionless
for conflicts in each
semantics of connectionless or
conflicts in each log
of connectionless or non
blocking messaging primitives is
messaging primitives is one
primitives is one example
membership monitors are in
monitors are in charge
are in charge of
in charge of deciding
often needless information is
charge of deciding and
needless information is sent
of deciding and publishing
information is sent as
deciding and publishing which
is sent as more
and publishing which machines
sent as more recent
publishing which machines perform
as more recent information
which machines perform which
more recent information makes
machines perform which roles
recent information makes old
information makes old messages
makes old messages obsolete
namely which machines run
which machines run the
using paxos again as
machines run the log
paxos again as an
run the log and
again as an example
the log and model
log and model and
and model and goal
model and goal we
in the stream of
conservative flow control mechanisms
the stream of values
and goal we assume
flow control mechanisms designed
goal we assume unreliable
control mechanisms designed to
stream of values that
mechanisms designed to deal
of values that acceptors
we assume unreliable servers
designed to deal with
values that acceptors accept
to deal with the
assume unreliable servers that
deal with the systematic
unreliable servers that may
with the systematic congestion
only the most recent
the systematic congestion of
the most recent one
servers that may crash
systematic congestion of the
most recent one is
congestion of the commodity
recent one is of
that may crash or
of the commodity internet
one is of interest
the commodity internet react
may crash or hang
commodity internet react too
internet react too sharply
but most mc implementations
react too sharply to
most mc implementations will
too sharply to ephemeral
mc implementations will carefully
sharply to ephemeral loss
implementations will carefully deliver
to ephemeral loss on
will carefully deliver each
ephemeral loss on over
carefully deliver each and
deliver each and every
each and every one
provisioned links a single
links a single packet
delaying delivery of the
a single packet loss
delivery of the important
single packet loss in
of the important information
to accommodate reliable storage
packet loss in ten
the important information until
loss in ten thousand
important information until all
in ten thousand is
information until all obsoleted
ten thousand is enough
until all obsoleted information
thousand is enough to
all obsoleted information has
is enough to reduce
obsoleted information has been
enough to reduce tcp
information has been delivered
has been delivered as
been delivered as well
as explained in section
ip throughput to a
throughput to a third
this leads to wasting
to a third over
leads to wasting resources
a third over a
potential deadlock situations due
deadlock situations due to
situations due to flow
due to flow control
to flow control leading
flow control leading to
the system exposes a
control leading to deadly
and one in a
system exposes a transactional
leading to deadly embrace
one in a thousand
exposes a transactional data
in a thousand drops
a transactional data store
a thousand drops it
and also obfuscates how
transactional data store supporting
thousand drops it by
also obfuscates how the
data store supporting serializable
drops it by an
obfuscates how the algorithms
store supporting serializable transactions
it by an order
how the algorithms work
by an order of
an order of magnitude
a client invokes a
client invokes a begin
time applications are impacted
a new class of
applications are impacted by
new class of ipc
are impacted by the
impacted by the reliance
by the reliance of
the reliance of reliability
that that tries to
reliance of reliability mechanisms
that tries to combine
of reliability mechanisms on
tries to combine the
reliability mechanisms on acknowledgments
to combine the best
mechanisms on acknowledgments and
combine the best features
on acknowledgments and retransmissions
the best features of
a field from a
best features of sm
field from a table
features of sm and
limiting the latency of
of sm and mc
the latency of packet
latency of packet recovery
of packet recovery to
packet recovery to at
from sm it inherits
recovery to at least
sm it inherits direct
to at least the
it inherits direct access
at least the round
inherits direct access to
least the round trip
direct access to and
the round trip time
access to and synchro
setting the value of
the value of a
nization on state rather
value of a field
on state rather than
of a field in
if delivery is sequenced
state rather than providing
a field in a
rather than providing a
field in a table
than providing a stream
each lost packet acts
providing a stream of
lost packet acts as
a stream of state
packet acts as a
stream of state updates
acts as a virtual
as a virtual road
finally the client invokes
the client invokes the
client invokes the endtransaction
while from mc it
block in the fifo
from mc it inherits
invokes the endtransaction command
mc it inherits an
in the fifo channel
it inherits an efficient
the fifo channel until
inherits an efficient implementation
fifo channel until it
and the system responds
an efficient implementation over
channel until it is
efficient implementation over the
until it is recovered
implementation over the existing
the system responds with
over the existing physical
system responds with either
the existing physical infrastructure
responds with either a
with either a commit
resistant protocols is not
either a commit or
the concept is that
protocols is not an
a commit or an
concept is that processes
is not an alternative
commit or an abort
is that processes publish
not an alternative in
that processes publish facts
an alternative in corporate
committed transactions form a
alternative in corporate datacenters
transactions form a serializable
which are information about
form a serializable execution
are information about milestones
where standardization is the
information about milestones they
standardization is the key
about milestones they have
is the key to
milestones they have reached
the key to low
tms are equipped with
key to low and
are equipped with predictors
to low and predictable
and subscribe to new
low and predictable maintenance
subscribe to new facts
and predictable maintenance costs
equipped with predictors that
with predictors that foresee
the ipc interface is
nei this work was
ipc interface is similar
predictors that foresee which
this work was supported
interface is similar to
work was supported in
is similar to topic
was supported in part
that foresee which objects
supported in part by
foresee which objects a
in part by grants
which objects a transaction
part by grants from
objects a transaction is
by grants from afosr
a transaction is likely
transaction is likely to
but there are several
is likely to access
there are several important
likely to access on
are several important semantic
ther is eliminating loss
several important semantic differences
to access on its
is eliminating loss events
access on its initiation
eliminating loss events on
loss events on a
events on a network
on a network that
a network that could
network that could nsf
that could nsf and
interface is as follows
could nsf and intel
nsf and intel corporation
span thousands of miles
it will be the
in an implementation of
will be the publishers
an implementation of the
be the publishers that
implementation of the system
there is a need
the publishers that actively
is a need to
of the system one
publishers that actively try
a need to link
that actively try to
the system one may
need to link loss
actively try to push
system one may use
try to push new
one may use multiple
to push new facts
may use multiple oms
push new facts to
use multiple oms per
new facts to the
side appliance locations of
facts to the subscribers
multiple oms per log
appliance locations of packet
locations of packet loss
of packet loss receive
dividing the log s
the log s object
log s object set
side appliance receiver buffer
paxos leaders publish new
appliance receiver buffer overflow
or the other way
leaders publish new ballots
the other way around
publish new ballots and
local recovery receiving end
new ballots and push
have multiple logs report
ballots and push these
multiple logs report to
and push these to
logs report to a
push these to acceptors
report to a single
these to acceptors as
to a single om
to acceptors as acceptors
acceptors as acceptors do
kernel code no dropped
as acceptors do not
code no dropped packets
acceptors do not necessarily
no dropped packets figure
do not necessarily know
the choice depends on
not necessarily know what
choice depends on the
necessarily know what the
depends on the throughput
know what the set
on the throughput of
maelstrom communication path mask
what the set of
communication path mask loss
the throughput of the
the set of leaders
path mask loss on
throughput of the specific
set of leaders is
mask loss on the
of the specific implementations
loss on the link
the specific implementations chosen
old ballots are automatically
specific implementations chosen for
ballots are automatically dropped
implementations chosen for each
are automatically dropped from
chosen for each service
automatically dropped from the
dropped from the transmission
because recovery delays for
from the transmission queue
recovery delays for lost
in this paper we
delays for lost packets
this paper we use
for lost packets translate
paper we use a
it will be the
lost packets translate into
will be the subscribers
packets translate into dramatic
be the subscribers that
translate into dramatic reductions
the subscribers that actively
into dramatic reductions in
subscribers that actively poll
dramatic reductions in application
that actively poll the
actively poll the publishers
mapping for simplicity of
for simplicity of presentation
leaders and learners both
we now describe the
and learners both subscribe
now describe the operation
because applications and os
learners both subscribe to
describe the operation of
applications and os networking
both subscribe to acceptors
and os networking stacks
the operation of acid
os networking stacks in
subscribe to acceptors accepting
networking stacks in commodity
to acceptors accepting pvalues
stacks in commodity datacenters
acceptors accepting pvalues and
in commodity datacenters cannot
accepting pvalues and poll
commodity datacenters cannot be
pvalues and poll for
datacenters cannot be rewritten
we start with an
cannot be rewritten from
start with an overview
be rewritten from scratch
with an overview of
and poll for these
an overview of the
poll for these facts
overview of the system
of the system s
the system s structure
system s structure in
s structure in section
is a promising solution
a promising solution for
promising solution for reliability
solution for reliability over
for reliability over long
as subscribers that su
subscribers that su ered
and proceed to describe
that su ered communication
proceed to describe the
su ered communication loss
to describe the algorithm
ered communication loss due
describe the algorithm in
packet recovery latency is
communication loss due to
recovery latency is independent
the algorithm in section
loss due to a
latency is independent of
due to a network
is independent of the
to a network partition
independent of the rtt
a network partition or
of the rtt of
network partition or having
the rtt of the
partition or having been
rtt of the link
or having been temporarily
having been temporarily subscribe
while fec codes have
fec codes have been
om for each shard
codes have been used
have been used for
been used for decades
used for decades within
and which tms are
for decades within link
which tms are available
any client can access
client can access any
can access any tm
access any tm for
faster commodity processors have
any tm for any
due to a user
commodity processors have enabled
tm for any given
to a user closing
processors have enabled packet
for any given transaction
a user closing a
user closing a laptop
level fec at end
other than the logs
server role assignment may
role assignment may be
will the interface requires
assignment may be inconsistent
the interface requires that
interface requires that the
requires that the fact
that the fact type
the fact type for
fact type for a
type for a par
is supposed to be
continue to poll publishers
supposed to be managed
to poll publishers to
to be managed by
poll publishers to receive
be managed by a
publishers to receive facts
managed by a single
to receive facts they
by a single om
receive facts they have
facts they have ticular
end fec is very
they have ticular topic
fec is very attractive
have ticular topic is
is very attractive for
ticular topic is totally
very attractive for inter
topic is totally ordered
and those facts will
those facts will missed
at a given time
all this is invisible
easy to deploy and
this is invisible to
but this may change
to deploy and customize
is invisible to the
this may change due
invisible to the core
may change due to
and does not require
change due to an
does not require specialized
to the core application
not require specialized equipment
the core application be
require specialized equipment in
core application be delivered
specialized equipment in the
application be delivered in
due to an unjustified
equipment in the network
be delivered in order
in the network linking
to an unjustified crash
the network linking the
an unjustified crash suspicion
network linking the datacenters
unjustified crash suspicion whereupon
crash suspicion whereupon an
any data can be
suspicion whereupon an object
data can be made
can be made to
host fec has two
fec has two major
has two major issues
two major issues first
but can be managed
can be managed through
be managed through the
managed through the contally
it s not transparent
through the contally ordered
may temporarily be managed
the contally ordered by
temporarily be managed by
contally ordered by tagging
requiring modification of the
ordered by tagging it
modification of the end
by tagging it with
be managed by two
tagging it with a
managed by two oms
it with a sequence
with a sequence number
it s not necessarily
the hope is that
s not necessarily rapid
hope is that fact
that do not know
do not know of
not know of one
fec works best over
know of one another
based ipc will simplify
works best over high
ipc will simplify disbut
will simplify disbut often
simplify disbut often times
disbut often times facts
stable traffic rates and
rain uses log servers
traffic rates and performs
often times facts such
rates and performs poorly
times facts such as
and performs poorly if
facts such as ballots
performs poorly if the
uses log servers for
poorly if the data
log servers for reliable
if the data rate
such as ballots are
the data rate in
servers for reliable storage
as ballots are totally
data rate in the
ballots are totally ortributed
rate in the channel
are totally ortributed programming
each log server provides
in the channel is
totally ortributed programming and
log server provides a
the channel is low
ortributed programming and make
server provides a sequentially
channel is low and
programming and make it
provides a sequentially consistent
is low and sporadic
and make it easier
a sequentially consistent log
make it easier to
sequentially consistent log object
it easier to reason
easier to reason dered
to reason dered already
as in a single
given a stream of
in a single end
a stream of facts
stream of facts on
of facts on some
update operations are linearizable
facts on some topic
but reads may return
about safety and liveness
reads may return outdated
may return outdated results
the argument for this
we present the maelstrom
argument for this is
for this is only
present the maelstrom error
this is only the
the maelstrom error correction
is only the highest
multiple machines may append
maelstrom error correction appliance
machines may append entries
error correction appliance a
may append entries to
correction appliance a rack
append entries to a
most recent fact need
appliance a rack of
entries to a log
recent fact need be
a rack of proxies
fact need be delivered
rack of proxies residing
machines may register to
need be delivered that
of proxies residing between
may register to the
be delivered that the
proxies residing between a
delivered that the paradigm
register to the log
that the paradigm allows
residing between a datacenter
the paradigm allows the
between a datacenter and
the log then sends
paradigm allows the programmer
a datacenter and its
allows the programmer to
datacenter and its wan
the programmer to clearly
log then sends to
and its wan link
programmer to clearly eventually
then sends to each
sends to each all
to each all entries
while older facts can
older facts can be
facts can be dropped
from the first one
the first one in
first one in the
one in the log
also specify transitions and
specify transitions and under
maelstrom encodes fec packets
transitions and under which
encodes fec packets over
and under which conditions
fec packets over traffic
and then new entries
under which conditions they
packets over traffic flowing
which conditions they di
then new entries as
over traffic flowing through
conditions they di erent
traffic flowing through it
new entries as they
flowing through it and
entries as they arrive
through it and routes
they di erent from
it and routes them
di erent from pub
and routes them to
an om may instruct
routes them to a
om may instruct the
them to a corresponding
may instruct the log
to a corresponding appliance
instruct the log to
a corresponding appliance at
the log to truncate
if no more facts
corresponding appliance at the
no more facts are
appliance at the destination
log to truncate its
at the destination datacenter
more facts are enabled
to truncate its prefix
facts are enabled without
are enabled without having
which decodes them and
enabled without having to
decodes them and recovers
without having to worry
them and recovers lost
having to worry much
and recovers lost data
to worry much about
worry much about how
much about how are
about how are published
how are published but
maelstrom is completely transparent
are published but some
is completely transparent it
published but some process
algorithm we now describe
completely transparent it does
but some process later
we now describe the
transparent it does not
some process later subscribes
now describe the acid
it does not require
does not require modification
not require modification of
it these conditions are
require modification of end
these conditions are discovered
we explain the reservation
host software and is
will eventually receive the
software and is agnostic
eventually receive the most
and is agnostic to
receive the most recent
is agnostic to the
the most recent fact
explain the reservation and
agnostic to the network
the reservation and certification
to the network connecting
assuming both publisher and
the network connecting the
both publisher and subscriber
network connecting the datacenter
publisher and subscriber are
reservation and certification protocol
and subscriber are correct
it eliminates the dependence
eliminates the dependence of
these semantics are similar
the dependence of fec
semantics are similar to
dependence of fec recovery
are similar to the
of fec recovery latency
similar to the anti
fec recovery latency on
then discuss prediction errors
recovery latency on the
latency on the data
entropy style of gossip
on the data rate
style of gossip protocols
the data rate in
data rate in any
rate in any single
in any single node
but the underlying implementation
the underlying implementation can
underlying implementation can be
a transaction begins with
implementation can be anything
transaction begins with the
node channel by encoding
begins with the tm
channel by encoding over
there is also a
by encoding over the
with the tm receiving
is also a control
encoding over the aggregated
also a control interface
over the aggregated traffic
a control interface that
the aggregated traffic leaving
the tm receiving a
control interface that controls
aggregated traffic leaving the
interface that controls routing
traffic leaving the datacenter
that controls routing of
tm receiving a begin
controls routing of facts
routing of facts for
of facts for a
facts for a particular
transaction instruction from the
for a particular topic
maelstrom uses a new
instruction from the client
uses a new encoding
a new encoding scheme
new encoding scheme called
encoding scheme called layered
the tm assigns it
scheme called layered interleaving
tm assigns it a
paxos acceptors subscribe to
assigns it a unique
acceptors subscribe to ballots
designed especially for time
it a unique txnid
subscribe to ballots and
to ballots and to
ballots and to new
sensitive packet recovery in
and predicts which objects
packet recovery in the
and to new proposals
predicts which objects the
recovery in the presence
to new proposals from
which objects the transaction
in the presence of
new proposals from leaders
the presence of bursty
objects the transaction will
presence of bursty loss
the transaction will access
when the leader publishes
the leader publishes one
the contributions of this
leader publishes one of
contributions of this paper
publishes one of these
of this paper are
it interrogates the oms
this paper are as
interrogates the oms about
paper are as follows
it is transmitted to
the oms about all
is transmitted to all
oms about all these
transmitted to all subscribers
about all these objects
end fec for long
and they respond with
and the underlying communication
they respond with the
the underlying communication layer
respond with the latest
underlying communication layer will
distance communication between datacenters
communication layer will continue
with the latest unreserved
layer will continue retransmission
the latest unreserved timestamp
will continue retransmission until
and argue that the
continue retransmission until either
latest unreserved timestamp of
argue that the rate
retransmission until either acknowledged
that the rate sensitivity
until either acknowledged or
unreserved timestamp of each
the rate sensitivity of
either acknowledged or another
rate sensitivity of fec
acknowledged or another fact
sensitivity of fec codes
or another fact renders
of fec codes and
another fact renders it
timestamp of each object
fec codes and the
fact renders it obsolete
codes and the opacity
and the opacity of
the tm chooses a
the opacity of their
tm chooses a timestamp
opacity of their implementations
chooses a timestamp larger
of their implementations present
a timestamp larger than
their implementations present major
timestamp larger than maximum
implementations present major obstacles
larger than maximum among
present major obstacles to
than maximum among the
major obstacles to their
maximum among the responses
obstacles to their usage
and asks the oms
asks the oms to
the oms to reserve
oms to reserve the
to reserve the objects
reserve the objects with
the objects with this
objects with this timestamp
a gateway appliance that
with this timestamp to
gateway appliance that transparently
this timestamp to txnid
appliance that transparently aggregates
that transparently aggregates traffic
transparently aggregates traffic and
aggregates traffic and encodes
the oms confirm the
traffic and encodes over
oms confirm the reservation
and encodes over the
confirm the reservation if
encodes over the resulting
the reservation if no
over the resulting high
reservation if no concurrent
if no concurrent tm
no concurrent tm has
concurrent tm has reserved
tm has reserved a
has reserved a larger
reserved a larger timestamp
a larger timestamp in
we describe layered interleaving
larger timestamp in the
timestamp in the meantime
a new fec scheme
new fec scheme used
the tm then proceeds
fec scheme used by
tm then proceeds to
scheme used by maelstrom
then proceeds to serve
used by maelstrom where
proceeds to serve transaction
by maelstrom where for
to serve transaction operations
maelstrom where for constant
serve transaction operations by
where for constant encoding
transaction operations by routing
for constant encoding overhead
operations by routing them
constant encoding overhead the
by routing them to
encoding overhead the latency
routing them to the
overhead the latency of
them to the appropriate
the latency of packet
to the appropriate oms
latency of packet recovery
of packet recovery degrades
packet recovery degrades gracefully
recovery degrades gracefully as
degrades gracefully as losses
each operation is sent
gracefully as losses get
operation is sent to
as losses get burstier
is sent to the
sent to the om
to the om in
the om in charge
om in charge of
we discuss implementation considerations
in charge of the
charge of the object
we built two versions
built two versions of
two versions of maelstrom
one runs in user
runs in user mode
an example flow of
example flow of the
flow of the algorithm
while the other runs
swift institute swift institute
the other runs within
along with the txnid
institute swift institute working
other runs within the
swift institute working paper
runs within the linux
institute working paper no
the oms order accesses
within the linux kernel
oms order accesses based
order accesses based on
accesses based on timestamp
based on timestamp reservations
we evaluate maelstrom on
evaluate maelstrom on emulab
and respond only when
respond only when the
only when the correct
when the correct version
the correct version is
correct version is available
each committed transaction is
committed transaction is assigned
transaction is assigned a
is assigned a timestamp
and show that it
show that it provides
that it provides near
it provides near lossless
when reading an object
provides near lossless tcp
the timestamp of the
ip throughput and latency
timestamp of the latest
throughput and latency over
of the latest transaction
and latency over lossy
the latest transaction that
latency over lossy links
latest transaction that wrote
s dilemma ittay eyal
transaction that wrote this
dilemma ittay eyal publication
and recovers packets with
ittay eyal publication date
that wrote this object
recovers packets with latency
wrote this object is
packets with latency independent
this object is returned
with latency independent of
object is returned to
latency independent of the
is returned to the
independent of the rtt
returned to the tm
of the rtt of
the rtt of the
rtt of the link
of the link and
the link and the
the transaction s timestamp
link and the rate
transaction s timestamp is
and the rate in
s timestamp is chosen
the rate in any
timestamp is chosen to
rate in any single
electronic copy available at
is chosen to be
in any single channel
chosen to be larger
to be larger than
be larger than the
larger than the largest
than the largest timestamp
the largest timestamp returned
largest timestamp returned by
timestamp returned by its
returned by its operations
model our focus is
our focus is on
and not larger than
focus is on pairs
not larger than its
is on pairs of
larger than its reserved
on pairs of geographically
than its reserved timestamp
pairs of geographically distant
of geographically distant datacenters
geographically distant datacenters that
distant datacenters that coordinate
datacenters that coordinate with
that coordinate with each
coordinate with each other
with each other in
each other in real
once a tm receives
a tm receives an
tm receives an end
transaction instruction from a
instruction from a client
this has long been
has long been a
long been a critical
it notifies the transaction
been a critical distributed
notifies the transaction s
a critical distributed computing
the transaction s oms
the miner s dilemma
critical distributed computing paradigm
miner s dilemma ittay
distributed computing paradigm in
s dilemma ittay eyal
detailing the transaction s
dilemma ittay eyal cornell
the transaction s timestamp
computing paradigm in application
ittay eyal cornell university
paradigm in application domains
transaction s timestamp and
eyal cornell university abstract
in application domains such
s timestamp and log
cornell university abstract an
application domains such as
university abstract an open
domains such as finance
abstract an open distributed
such as finance and
an open distributed system
as finance and aerospace
the logs in charge
open distributed system can
logs in charge of
distributed system can be
in charge of the
system can be secured
charge of the shards
similar requirements are arising
can be secured by
requirements are arising across
be secured by requiring
are arising across the
secured by requiring participants
arising across the board
of the shards it
by requiring participants to
across the board as
requiring participants to present
the board as globalized
participants to present proof
board as globalized enterprises
to present proof of
as globalized enterprises rely
present proof of work
globalized enterprises rely on
the shards it touched
proof of work and
enterprises rely on networks
of work and rewarding
rely on networks for
work and rewarding them
on networks for high
and rewarding them for
rewarding them for participation
when it receives such
speed communication and collaboration
it receives such a
the bitcoin digital currency
receives such a notification
bitcoin digital currency introduced
digital currency introduced this
currency introduced this mechanism
the most general case
an om appends to
most general case of
om appends to its
which is adopted by
general case of inter
appends to its log
is adopted by almost
to its log an
adopted by almost all
its log an entry
cluster communication is one
by almost all contemporary
communication is one where
almost all contemporary digital
is one where any
all contemporary digital currencies
one where any node
log an entry consisting
where any node in
an entry consisting of
any node in one
contemporary digital currencies and
node in one cluster
digital currencies and related
in one cluster can
entry consisting of the
currencies and related services
one cluster can communicate
consisting of the txnid
cluster can communicate with
can communicate with any
a natural process leads
communicate with any node
natural process leads participants
with any node in
process leads participants of
any node in the
leads participants of such
node in the other
participants of such systems
in the other cluster
of such systems to
such systems to form
systems to form pools
such logs may be
we make no assumptions
logs may be implemented
where members aggregate their
make no assumptions about
members aggregate their power
no assumptions about the
aggregate their power and
assumptions about the type
may be implemented with
their power and share
about the type of
be implemented with various
power and share the
the type of traffic
implemented with various techniques
and share the rewards
type of traffic flowing
of traffic flowing through
traffic flowing through the
from smr to log
flowing through the link
smr to log chains
experience with bitcoin shows
with bitcoin shows that
bitcoin shows that the
shows that the largest
that the largest pools
the largest pools are
largest pools are often
critical applications could send
pools are often open
applications could send dynamically
could send dynamically generated
send dynamically generated real
allowing anyone to join
time data such as
data such as stock
it has long been
such as stock quotes
has long been known
long been known that
been known that a
financial transactions and battleground
known that a member
transactions and battleground location
that a member can
and battleground location updates
a member can sabotage
member can sabotage an
can sabotage an open
we abstract this write
sabotage an open pool
while enterprise applications could
an open pool by
enterprise applications could send
open pool by seemingly
applications could send voip
pool by seemingly joining
could send voip streams
by seemingly joining it
seemingly joining it but
joining it but never
it but never sharing
set with the read
ssh sessions and synchronous
but never sharing its
sessions and synchronous file
with the read timestamps
and synchronous file updates
never sharing its proofs
synchronous file updates between
sharing its proofs of
file updates between offices
its proofs of work
and assume highly available
the pool shares its
assume highly available logs
pool shares its revenue
packet loss typically occurs
shares its revenue with
loss typically occurs at
its revenue with the
typically occurs at two
revenue with the attacker
occurs at two points
set with written values
at two points in
two points in an
and so each of
points in an end
so each of its
each of its participants
of its participants earns
its participants earns less
end communication path between
we define and analyze
communication path between two
path between two datacenters
define and analyze a
and analyze a game
analyze a game where
action should be either
as shown in figure
a game where pools
should be either committed
game where pools use
be either committed or
where pools use some
either committed or aborted
pools use some of
committed or aborted in
area network connecting them
use some of their
network connecting them and
some of their participants
connecting them and at
of their participants to
or aborted in all
them and at the
their participants to infiltrate
aborted in all its
and at the receiving
participants to infiltrate other
in all its logs
at the receiving end
to infiltrate other pools
infiltrate other pools and
other pools and perform
pools and perform such
and therefore cannot be
and perform such an
therefore cannot be removed
loss in the lambda
cannot be removed from
in the lambda link
perform such an attack
the lambda link can
be removed from any
lambda link can occur
removed from any of
link can occur for
with any number of
from any of them
can occur for many
any number of pools
any of them before
occur for many reasons
of them before the
them before the result
before the result is
the result is published
attacks is not a
is not a nash
not a nash equilibrium
dirty or degraded fiber
the committing tm appends
committing tm appends a
tm appends a gc
malfunctioning or misconfigured equipment
appends a gc entry
we study the special
a gc entry to
study the special cases
gc entry to all
low receiver power and
the special cases where
receiver power and burst
entry to all the
special cases where either
power and burst switching
cases where either two
to all the transaction
and burst switching contention
where either two pools
burst switching contention are
all the transaction s
either two pools or
switching contention are some
two pools or any
the transaction s logs
contention are some reasons
pools or any number
transaction s logs after
or any number of
s logs after receiving
any number of identical
logs after receiving an
number of identical pools
after receiving an acknowledgement
of identical pools play
receiving an acknowledgement that
identical pools play the
an acknowledgement that they
pools play the game
acknowledgement that they all
play the game and
that they all registered
the game and the
they all registered the
game and the rest
all registered the transaction
and the rest of
registered the transaction s
the rest of the
the transaction s result
rest of the participants
of the participants are
the participants are uninvolved
an om can invoke
om can invoke log
can invoke log prefix
invoke log prefix truncation
log prefix truncation if
in both of these
prefix truncation if the
both of these cases
truncation if the prefix
of these cases there
if the prefix was
these cases there exists
the prefix was summarized
cases there exists an
there exists an equilibrium
exists an equilibrium that
and all its transactions
an equilibrium that constitutes
all its transactions have
equilibrium that constitutes a
loss can also occur
its transactions have corresponding
that constitutes a tragedy
can also occur at
transactions have corresponding gc
constitutes a tragedy of
also occur at receiving
a tragedy of the
occur at receiving endhosts
have corresponding gc entries
at receiving endhosts within
tragedy of the commons
receiving endhosts within the
of the commons where
endhosts within the destination
the commons where the
within the destination datacenter
then waits for the
commons where the participating
waits for the entry
where the participating pools
these are usually cheap
the participating pools attack
are usually cheap commodity
participating pools attack one
for the entry to
usually cheap commodity machines
pools attack one another
cheap commodity machines prone
attack one another and
commodity machines prone to
one another and earn
the entry to appear
another and earn less
machines prone to temporary
and earn less than
prone to temporary overloads
earn less than they
entry to appear in
to temporary overloads that
less than they would
temporary overloads that cause
than they would have
overloads that cause packets
they would have if
that cause packets to
would have if none
cause packets to be
to appear in the
have if none had
packets to be dropped
appear in the log
if none had attacked
to be dropped by
be dropped by the
dropped by the kernel
by the kernel in
a transaction is committed
the kernel in bursts
transaction is committed if
is committed if and
the decision whether or
committed if and only
decision whether or not
if and only if
whether or not to
and only if it
or not to attack
this loss mode occurs
not to attack is
loss mode occurs with
to attack is the
mode occurs with udp
attack is the miner
only if it is
is the miner s
if it is written
based traffic but not
the miner s dilemma
it is written to
traffic but not with
is written to all
but not with tcp
an instance of the
written to all logs
instance of the iterative
of the iterative prisoner
the iterative prisoner s
iterative prisoner s dilemma
and it does not
it does not conflict
which advertises receiver windows
does not conflict with
advertises receiver windows to
the game is played
not conflict with previous
receiver windows to prevent
game is played daily
windows to prevent end
conflict with previous transactions
is played daily by
with previous transactions on
played daily by the
previous transactions on any
daily by the active
transactions on any of
what are typical loss
by the active bitcoin
on any of them
are typical loss rates
the active bitcoin pools
typical loss rates on
loss rates on long
conflicts are violations of
are violations of read
which apparently choose not
apparently choose not to
choose not to attack
one source of information
source of information is
if this balance breaks
of information is teragrid
read or writewrite order
the revenue of open
revenue of open pools
of open pools might
each om checks for
open pools might diminish
om checks for local
checks for local conflicts
for local conflicts by
making them unattractive to
an optical network interconnecting
them unattractive to participants
local conflicts by checking
optical network interconnecting major
conflicts by checking timestamps
network interconnecting major supercomputing
by checking timestamps in
interconnecting major supercomputing sites
checking timestamps in the
major supercomputing sites in
timestamps in the prefix
supercomputing sites in the
in the prefix of
sites in the us
the prefix of the
prefix of the log
of the log up
is a digital currency
the log up to
teragrid has a monitoring
a digital currency that
has a monitoring framework
digital currency that is
log up to the
a monitoring framework within
currency that is gaining
monitoring framework within which
that is gaining acceptance
framework within which ten
up to the transaction
within which ten sites
to the transaction entry
which ten sites periodically
ten sites periodically send
sites periodically send each
periodically send each other
and sends its local
sends its local result
gbps streams of udp
streams of udp packets
of udp packets and
udp packets and measure
packets and measure the
and measure the resulting
measure the resulting loss
the resulting loss rate
to the calling tm
with an estimated market
an estimated market capitalization
estimated market capitalization of
if all return success
market capitalization of over
then the transaction has
the transaction has committed
each site measures the
otherwise it has aborted
site measures the loss
measures the loss rate
the loss rate to
loss rate to every
the tm notifies the
rate to every other
tm notifies the client
to every other site
notifies the client of
every other site once
the client of the
other site once an
client of the transaction
site once an hour
of the transaction result
the transaction result and
transaction result and instructs
result and instructs the
resulting in a total
and instructs the oms
in a total of
instructs the oms to
the oms to place
oms to place this
to place this result
place this result in
this result in the
result in the logs
loss rate measurements collected
bitcoin s security stems
rate measurements collected across
s security stems from
measurements collected across the
security stems from a
collected across the network
the oms notify the
stems from a robust
across the network every
from a robust incentive
the network every hour
a robust incentive system
oms notify the tm
notify the tm once
the tm once the
tm once the results
once the results are
participants are required to
the results are logged
are required to provide
required to provide expensive
to provide expensive proofs
provide expensive proofs of
expensive proofs of work
robustness in case of
in case of a
case of a tm
of a tm or
a tm or om
and they are rewarded
tm or om crash
they are rewarded according
are rewarded according to
rewarded according to their
or a missing result
according to their efforts
a missing result or
missing result or gc
result or gc entry
this architecture has proved
architecture has proved both
due to message loss
has proved both stable
proved both stable and
both stable and scalable
and it is used
another tm may read
it is used by
tm may read the
is used by most
may read the transaction
used by most contemporary
read the transaction entry
by most contemporary digital
the transaction entry in
most contemporary digital currencies
transaction entry in one
contemporary digital currencies and
entry in one of
digital currencies and related
in one of the
currencies and related services
of all such measurements
one of the logs
all such measurements were
such measurements were over
and continue the certification
continue the certification and
the certification and gc
certification and gc process
if a tm places
a tm places a
tm places a transaction
places a transaction entry
a transaction entry in
transaction entry in a
entry in a strict
in a strict subset
a strict subset of
strict subset of the
subset of the transaction
of them were over
of the transaction s
the transaction s log
transaction s log set
when another tm is
another tm is instructed
tm is instructed to
is instructed to fix
instructed to fix this
it cannot tell whether
cannot tell whether the
after eliminating a single
tell whether the original
eliminating a single site
whether the original tm
the original tm is
original tm is crashed
tm is crashed or
is crashed or slow
that dropped incoming packets
dropped incoming packets steadily
incoming packets steadily at
packets steadily at a
steadily at a rate
we introduce poison entries
at a rate of
the fixing tm places
fixing tm places a
tm places a poison
places a poison entry
a poison entry in
poison entry in the
our results apply to
entry in the logs
results apply to all
in the logs that
apply to all such
the logs that miss
to all such incentive
logs that miss the
all such incentive systems
that miss the original
miss the original entry
but we use bitcoin
we use bitcoin terminology
use bitcoin terminology and
a poison is interpreted
bitcoin terminology and examples
of the remainder were
terminology and examples since
the remainder were over
and examples since it
poison is interpreted as
examples since it serves
is interpreted as a
since it serves as
interpreted as a transaction
it serves as an
as a transaction entry
serves as an active
a transaction entry with
as an active and
transaction entry with a
an active and archetypal
entry with a conflict
active and archetypal example
the original entry may
original entry may either
entry may either arrive
bitcoin implements its incentive
may either arrive eventually
implements its incentive systems
either arrive eventually or
its incentive systems with
arrive eventually or not
incentive systems with a
systems with a data
with a data structure
a data structure called
data structure called the
structure called the blockchain
and the following are
the blockchain is a
the following are ignored
these numbers reflect the
blockchain is a serialization
numbers reflect the loss
is a serialization of
reflect the loss rate
a serialization of all
any tm can therefore
the loss rate experienced
serialization of all bitcoin
loss rate experienced for
tm can therefore observe
of all bitcoin transactions
rate experienced for udp
can therefore observe the
experienced for udp traffic
therefore observe the log
it is a single
observe the log and
is a single global
for udp traffic on
a single global ledger
udp traffic on an
single global ledger maintained
the log and consistently
traffic on an end
global ledger maintained by
log and consistently determine
ledger maintained by an
and consistently determine the
maintained by an open
consistently determine the state
by an open distributed
determine the state of
end path and may
an open distributed system
the state of the
path and may not
state of the transaction
and may not generalize
since anyone can join
may not generalize to
anyone can join the
not generalize to tcp
without a race hazard
can join the open
generalize to tcp packets
join the open system
the open system and
prediction errors if there
open system and participate
errors if there are
system and participate in
if there are no
we do not know
and participate in maintaining
do not know if
participate in maintaining the
there are no prediction
not know if packets
in maintaining the blockchain
know if packets were
are no prediction errors
if packets were dropped
packets were dropped within
bitcoin uses a proof
were dropped within the
uses a proof of
dropped within the optical
a proof of work
within the optical network
proof of work mechanism
the optical network or
of work mechanism to
optical network or at
work mechanism to deter
network or at intermediate
mechanism to deter attacks
or at intermediate devices
there are no aborts
at intermediate devices within
intermediate devices within either
devices within either datacenter
participation requires exerting significant
if the transaction accesses
requires exerting significant computational
the transaction accesses an
though it s unlikely
exerting significant computational resources
it s unlikely that
transaction accesses an object
s unlikely that they
accesses an object that
unlikely that they were
an object that was
a participant who proves
that they were dropped
object that was not
participant who proves she
they were dropped at
that was not predicted
who proves she has
were dropped at the
proves she has exerted
dropped at the end
she has exerted enough
this object has no
has exerted enough resources
object has no reserved
exerted enough resources with
has no reserved version
enough resources with a
no reserved version for
many of the mea
resources with a proof
reserved version for it
with a proof of
a proof of work
surements lost just one
proof of work is
accessing it can therefore
lost just one or
of work is allowed
just one or two
it can therefore result
work is allowed to
one or two packets
is allowed to take
or two packets whereas
allowed to take a
two packets whereas kernel
to take a step
can therefore result in
take a step in
therefore result in a
a step in the
nic losses are known
result in a conflict
step in the protocol
losses are known to
in the protocol by
in a conflict of
are known to be
the protocol by generating
a conflict of the
known to be bursty
protocol by generating a
conflict of the transaction
by generating a block
of the transaction or
the transaction or of
transaction or of the
or of the following
participants are compensated for
of the following ones
are compensated for their
compensated for their efforts
for their efforts with
their efforts with newly
efforts with newly minted
with newly minted bitcoins
loss occurred on paths
occurred on paths where
on paths where levels
paths where levels of
the process of creating
no conflict would occur
where levels of optical
process of creating a
levels of optical link
of creating a block
of optical link utilization
creating a block is
but if one does
a block is called
if one does it
block is called mining
one does it will
does it will be
it will be detected
will be detected at
and the participants miners
be detected at certification
detected at certification time
in order to win
order to win the
and result in an
to win the reward
result in an abort
were consistently lower than
in an abort of
many miners try to
an abort of a
miners try to generate
abort of a transaction
try to generate blocks
performance may be slightly
may be slightly reduced
the system automatically adjusts
ruling out congestion as
system automatically adjusts the
out congestion as a
automatically adjusts the difficulty
but consistency is maintained
congestion as a possible
adjusts the difficulty of
as a possible cause
the difficulty of block
difficulty of block generation
if a transaction does
a transaction does not
transaction does not access
a conclusion supported by
such that one block
does not access an
conclusion supported by dialogue
that one block is
supported by dialogue with
one block is added
by dialogue with the
block is added every
dialogue with the network
not access an object
with the network administrators
access an object that
an object that was
object that was predicted
minutes to the blockchain
the tm must still
tm must still release
this means that each
must still release the
means that each miner
still release the reservation
that each miner seldom
release the reservation when
each miner seldom generates
the reservation when the
miner seldom generates a
points are provided by
reservation when the transaction
seldom generates a block
are provided by the
when the transaction ends
provided by the back
although its revenue may
its revenue may be
revenue may be positive
may be positive in
this reservation might slow
bone networks of tier
be positive in expectation
reservation might slow the
might slow the processing
slow the processing of
the processing of other
a miner may have
processing of other transactions
miner may have to
of other transactions that
may have to wait
global crossing reports average
have to wait for
crossing reports average loss
to wait for an
other transactions that wait
reports average loss rates
wait for an extended
transactions that wait for
average loss rates between
for an extended period
that wait for its
an extended period to
wait for its release
extended period to create
period to create a
to create a block
create a block and
but would not break
a block and earn
would not break consistency
block and earn the
and earn the actual
earn the actual bitcoins
if a tm is
a tm is suspected
tm is suspected as
is suspected as failed
miners form mining pools
its reservations are revoked
where all members mine
this may harm performance
all members mine concurrently
members mine concurrently and
mine concurrently and they
on four of its
concurrently and they share
but cannot break consistency
four of its six
and they share their
of its six inter
they share their revenue
share their revenue whenever
their revenue whenever one
revenue whenever one of
whenever one of them
evaluation we evaluate acid
one of them creates
haul links for the
of them creates a
links for the month
them creates a block
for the month of
rain by comparing its
the month of december
by comparing its performance
comparing its performance to
its performance to the
performance to the classical
to the classical approach
pools are typically implemented
the classical approach that
are typically implemented as
classical approach that does
typically implemented as a
approach that does not
implemented as a pool
that does not use
as a pool manager
does not use prediction
a pool manager and
not use prediction and
pool manager and a
use prediction and compare
manager and a cohort
qwest reports loss rates
prediction and compare its
and a cohort of
reports loss rates of
and compare its certification
a cohort of miners
compare its certification protocol
its certification protocol with
certification protocol with other
protocol with other certification
with other certification schemes
the pool manager joins
pool manager joins the
manager joins the bitcoin
joins the bitcoin system
we use a custom
the bitcoin system as
bitcoin system as a
system as a single
as a single miner
instead of generating proof
of generating proof of
generating proof of work
simulating each of the
each of the agents
of the agents in
the agents in the
it outsources the work
agents in the system
outsources the work to
in the system clients
the work to the
in either direction on
work to the miners
either direction on its
direction on its trans
in order to evaluate
order to evaluate the
pacific link for the
to evaluate the miners
link for the same
evaluate the miners efforts
for the same month
our workloads are an
workloads are an adaptation
are an adaptation of
an adaptation of the
the pool manager accepts
adaptation of the transactional
pool manager accepts partial
of the transactional ycsb
manager accepts partial proof
the transactional ycsb specification
accepts partial proof of
partial proof of work
we expect privately managed
proof of work and
expect privately managed lambdas
of work and estimates
privately managed lambdas to
work and estimates each
managed lambdas to exhibit
and estimates each miner
lambdas to exhibit higher
estimates each miner s
to exhibit higher loss
each miner s power
exhibit higher loss rates
miner s power according
higher loss rates due
s power according to
loss rates due to
power according to the
rates due to the
according to the rate
due to the inherent
to the rate with
to the inherent trade
based on the original
the rate with which
rate with which it
with which it submits
which it submits such
it submits such partial
submits such partial proof
such partial proof of
equipment quality and cost
partial proof of work
when a miner generates
a miner generates a
miner generates a full
generates a full proof
a full proof of
full proof of work
each transaction has a
it sends it to
transaction has a set
sends it to the
has a set of
as well as the
it to the pool
well as the difficulty
a set of read
to the pool manager
as the difficulty of
the pool manager which
the difficulty of performing
pool manager which publishes
update operations spread along
difficulty of performing routine
manager which publishes this
of performing routine maintenance
which publishes this proof
performing routine maintenance on
operations spread along its
publishes this proof of
routine maintenance on longdistance
spread along its execution
this proof of work
maintenance on longdistance links
proof of work to
of work to the
work to the bitcoin
object accesses follow one
to the bitcoin system
accesses follow one of
follow one of two
one of two different
of two different random
two different random distributions
the pool manager thus
pool manager thus receives
manager thus receives the
thus receives the full
end paths as dropping
receives the full revenue
paths as dropping packets
the full revenue of
as dropping packets at
full revenue of the
dropping packets at rates
revenue of the block
packets at rates of
of the block and
the block and distributes
where each object is
block and distributes it
each object is chosen
and distributes it fairly
object is chosen uniformly
distributes it fairly according
is chosen uniformly at
it fairly according to
chosen uniformly at random
fairly according to its
according to its members
to its members power
many of the pools
of the pools are
the pools are open
pools are open they
are open they allow
gc logs are truncated
open they allow any
logs are truncated to
to capture a wide
they allow any miner
capture a wide range
are truncated to conserve
allow any miner to
a wide range of
any miner to join
truncated to conserve resources
wide range of deployed
miner to join them
to conserve resources and
range of deployed networks
to join them using
conserve resources and to
join them using a
resources and to reduce
them using a public
and to reduce log
using a public internet
existing reliability options tcp
to reduce log replay
a public internet interface
reduce log replay time
ip is the default
log replay time on
is the default reliable
such open pools are
the default reliable communication
open pools are susceptible
default reliable communication option
pools are susceptible to
replay time on om
reliable communication option for
are susceptible to the
communication option for contemporary
susceptible to the classical
option for contemporary networked
to the classical block
for contemporary networked applications
the classical block withholding
time on om recovery
classical block withholding attack
each om occasionally summarizes
om occasionally summarizes the
exclusive embeddings in commodity
occasionally summarizes the log
embeddings in commodity operating
summarizes the log prefix
in commodity operating systems
commodity operating systems and
operating systems and networking
systems and networking apis
and places this summary
places this summary in
this summary in the
summary in the log
where a miner sends
a miner sends only
miner sends only partial
most applications requiring reliable
sends only partial proof
applications requiring reliable communication
only partial proof of
requiring reliable communication over
the presence of a
reliable communication over any
partial proof of work
communication over any form
proof of work to
over any form of
of work to the
any form of network
work to the pool
form of network use
to the pool manager
of network use tcp
the pool manager and
pool manager and discards
manager and discards full
and discards full proof
discards full proof of
full proof of work
due to the partial
to the partial proof
the partial proof of
partial proof of work
proof of work it
of work it sends
work it sends to
it sends to the
sends to the pool
the problem with commodity
problem with commodity tcp
the miner is considered
miner is considered a
is considered a regular
considered a regular pool
a regular pool member
regular pool member and
pool member and the
member and the pool
and the pool can
the pool can estimate
pool can estimate its
presence of a summary
can estimate its power
of a summary of
a summary of the
ip uses positive acknowledgments
summary of the log
uses positive acknowledgments and
of the log up
positive acknowledgments and retransmissions
the log up to
acknowledgments and retransmissions to
the attacker shares the
and retransmissions to ensure
attacker shares the revenue
log up to a
shares the revenue obtained
up to a certain
the revenue obtained by
to a certain entry
retransmissions to ensure reliability
revenue obtained by the
a certain entry is
to ensure reliability the
obtained by the other
ensure reliability the sender
by the other pool
reliability the sender buffers
certain entry is not
the other pool members
the sender buffers packets
entry is not sufficient
sender buffers packets until
is not sufficient to
buffers packets until their
but does not contribute
not sufficient to allow
packets until their receipt
sufficient to allow truncation
until their receipt is
it reduces the revenue
their receipt is acknowledged
reduces the revenue of
receipt is acknowledged by
to allow truncation at
the revenue of the
is acknowledged by the
allow truncation at that
revenue of the other
acknowledged by the receiver
truncation at that entry
of the other members
and resends if an
resends if an acknowledgment
this reason is that
but also its own
if an acknowledgment is
reason is that truncation
an acknowledgment is not
is that truncation must
we provide necessary background
that truncation must not
provide necessary background on
acknowledgment is not received
truncation must not break
necessary background on the
is not received within
must not break transaction
background on the bitcoin
not received within some
not break transaction certification
on the bitcoin protocol
received within some time
within some time period
pools and the classical
and the classical block
the classical block withholding
prediction our first test
classical block withholding attack
a lost packet is
our first test scenario
lost packet is received
first test scenario imposes
packet is received in
test scenario imposes a
is received in the
block withholding attack in
received in the form
withholding attack in section
scenario imposes a load
in the form of
attack in section ii
the form of a
imposes a load substantially
form of a retransmission
a load substantially below
and specify our model
load substantially below the
of a retransmission that
specify our model in
substantially below the system
a retransmission that arrives
our model in section
below the system s
retransmission that arrives no
model in section iii
that arrives no earlier
the system s capacity
arrives no earlier than
system s capacity with
for a broader view
a broader view of
broader view of the
view of the protocol
of the protocol and
the protocol and ecosystem
protocol and ecosystem the
and ecosystem the reader
rtts after the original
ecosystem the reader may
after the original send
the reader may refer
each transaction reads and
the original send event
reader may refer to
transaction reads and writes
may refer to the
refer to the survey
the sender has to
to the survey by
sender has to buffer
the survey by bonneau
has to buffer each
survey by bonneau et
to buffer each packet
by bonneau et al
buffer each packet until
each packet until it
packet until it s
until it s acknowledged
the simulation is faithful
simulation is faithful to
is faithful to the
faithful to the algorithm
rtt in lossless operation
with the exception of
the exception of a
exception of a small
of a small shortcut
and it has to
a small shortcut oms
it has to perform
small shortcut oms grant
in this work we
has to perform additional
shortcut oms grant reservations
this work we analyze
to perform additional work
work we analyze block
perform additional work to
we analyze block withholding
oms grant reservations by
additional work to retransmit
analyze block withholding attacks
work to retransmit the
block withholding attacks among
to retransmit the packet
grant reservations by arrival
withholding attacks among pools
retransmit the packet if
reservations by arrival time
the packet if it
by arrival time rather
a pool that employs
packet if it does
pool that employs the
if it does not
arrival time rather than
that employs the pool
it does not receive
employs the pool block
does not receive the
time rather than by
the pool block withholding
not receive the acknowledgment
pool block withholding attack
rather than by timestamp
block withholding attack registers
withholding attack registers with
attack registers with the
registers with the victim
this results in deadlocks
with the victim pool
any packets that arrive
the victim pool as
results in deadlocks in
packets that arrive with
victim pool as a
that arrive with higher
pool as a regular
arrive with higher sequence
in deadlocks in high
with higher sequence numbers
deadlocks in high contention
as a regular miner
higher sequence numbers than
in high contention scenarios
sequence numbers than that
numbers than that of
and these are resolved
than that of a
it receives tasks from
that of a lost
receives tasks from the
of a lost packet
tasks from the victim
these are resolved with
a lost packet must
from the victim pool
lost packet must be
the victim pool and
packet must be queued
victim pool and transfers
must be queued while
pool and transfers them
be queued while the
are resolved with timeouts
and transfers them to
queued while the receiver
transfers them to some
while the receiver waits
them to some of
the receiver waits for
first we vary prediction
to some of its
receiver waits for the
we vary prediction accuracy
some of its own
waits for the lost
of its own miners
for the lost packet
the lost packet to
lost packet to arrive
we call these infiltrating
call these infiltrating miners
the average ratio of
and the mining power
throughput financial banking application
the mining power spent
average ratio of objects
financial banking application running
mining power spent by
banking application running in
power spent by a
application running in a
spent by a pool
ratio of objects the
running in a datacenter
by a pool the
in a datacenter in
of objects the predictor
a pool the infiltration
a datacenter in new
objects the predictor guesses
pool the infiltration rate
datacenter in new york
the predictor guesses out
in new york city
predictor guesses out of
when electronic copy available
guesses out of the
electronic copy available at
sending updates to a
out of the set
updates to a sister
of the set the
to a sister site
the set the transaction
a sister site in
set the transaction eventually
sister site in switzerland
the transaction eventually accesses
the rtt value between
rtt value between these
value between these two
between these two centers
is equivalent to no
these two centers is
equivalent to no prediction
two centers is typically
to no prediction and
no prediction and no
prediction and no reservation
and an accuracy of
in the case of
the attacking pool s
means predicting all accesses
the case of a
attacking pool s infiltrating
case of a lost
pool s infiltrating miners
of a lost packet
s infiltrating miners deliver
infiltrating miners deliver partial
miners deliver partial proofs
deliver partial proofs of
partial proofs of work
all packets received within
packets received within the
the attacker transfers them
attacker transfers them to
transfers them to the
them to the victim
to the victim pool
milliseconds between the original
letting the attacked pool
between the original packet
the attacked pool estimate
the original packet send
attacked pool estimate their
original packet send and
pool estimate their power
packet send and the
increasing contention by decreasing
send and the a
contention by decreasing the
when the infiltrating miners
by decreasing the number
the infiltrating miners deliver
decreasing the number of
infiltrating miners deliver a
the number of objects
miners deliver a full
deliver a full proof
a full proof of
full proof of work
the attacking pool discards
attacking pool discards it
h ets are generated
ets are generated from
load with a hot
this attack affects the
are generated from alternate
attack affects the revenues
generated from alternate disjoint
affects the revenues of
from alternate disjoint sub
the revenues of the
revenues of the pools
of the pools in
the pools in several
pools in several ways
streams of data rather
of data rather than
data rather than from
rather than from consecutive
the victim pool s
than from consecutive packets
victim pool s effective
pool s effective mining
s effective mining rate
effective mining rate is
mining rate is unchanged
with an interleave index
but its total revenue
an interleave index of
its total revenue is
total revenue is divided
revenue is divided among
is divided among more
divided among more miners
the encoder would a
the attacker s mining
attacker s mining power
s mining power is
mining power is reduced
increasing contention by increasing
contention by increasing the
by increasing the hot
since some of its
some of its miners
g create correction packets
of its miners are
create correction packets separately
its miners are used
correction packets separately from
miners are used for
packets separately from three
are used for block
separately from three disjoint
used for block withholding
from three disjoint sub
commit rate drops as
rate drops as contention
drops as contention rises
but it earns additional
it earns additional revenue
earns additional revenue through
additional revenue through its
accurate prediction reduces or
revenue through its infiltration
the first containing data
prediction reduces or even
through its infiltration of
first containing data packets
reduces or even eliminates
its infiltration of the
containing data packets numbered
or even eliminates this
infiltration of the other
data packets numbered a
even eliminates this drop
of the other pool
packets numbered a c
numbered a c e
a c e g
c e g x
e g x x
in highest contention scenarios
the total effective mining
total effective mining power
effective mining power in
even with moderate prediction
mining power in the
with moderate prediction accuracy
power in the system
in the system is
the system is reduced
we obtain significant improvement
obtain significant improvement over
significant improvement over the
causing the bitcoin protocol
improvement over the classical
the bitcoin protocol to
over the classical approach
bitcoin protocol to reduce
protocol to reduce the
to reduce the difficulty
taking all these factors
all these factors into
these factors into account
we observe that a
observe that a pool
that a pool might
a pool might be
we define slack to
pool might be able
define slack to be
might be able to
slack to be the
be able to increase
to be the average
able to increase its
be the average ratio
to increase its revenue
the average ratio between
increase its revenue by
average ratio between the
the second with data
its revenue by attacking
second with data packets
revenue by attacking other
ratio between the number
with data packets numb
by attacking other pools
data packets numb d
between the number of
packets numb d f
the number of accesses
numb d f h
each pool therefore makes
number of accesses predicted
d f h x
pool therefore makes a
of accesses predicted and
f h x x
therefore makes a choice
accesses predicted and the
h x x bered
makes a choice of
predicted and the number
a choice of whether
and the number of
choice of whether to
the number of objects
of whether to attack
number of objects accessed
whether to attack each
of objects accessed by
to attack each of
objects accessed by the
attack each of the
accessed by the transaction
each of the other
of the other pools
the other pools in
other pools in the
pools in the system
if a transaction accesses
and with what infiltration
with what infiltration rate
this gives rise to
gives rise to the
then with a slack
rise to the pool
with a slack of
to the pool game
we specify this game
specify this game and
this game and provide
game and provide initial
and provide initial analysis
provide initial analysis in
initial analysis in section
analysis in section iv
it would reserve another
in section v we
and the third with
section v we analyze
the third with data
third with data b
v we analyze the
we analyze the scenario
analyze the scenario where
the scenario where exactly
scenario where exactly two
where exactly two of
now with uniform random
exactly two of the
with uniform random load
two of the pools
uniform random load and
of the pools take
random load and a
the pools take part
load and a variable
pools take part in
and a variable number
take part in the
a variable number of
part in the game
variable number of objects
in the game and
the game and only
game and only one
and only one can
the effect of using
only one can attack
effect of using a
one can attack the
of using a perfect
can attack the other
using a perfect predictor
the attacker can always
attacker can always increase
can always increase its
always increase its revenue
increase its revenue by
its revenue by attacking
with predictors that overpredict
predictors that overpredict by
that overpredict by factors
we conclude that in
overpredict by factors of
conclude that in the
that in the general
in the general case
with any number of
any number of pools
the impact of overprediction
impact of overprediction is
interleaving adds burst tolerance
of overprediction is surprisingly
adds burst tolerance to
overprediction is surprisingly minor
burst tolerance to fec
attacks is not a
tolerance to fec but
is not a nash
a finding that should
to fec but exacerbates
not a nash equilibrium
fec but exacerbates its
but exacerbates its sensitivfigure
section vi deals with
vi deals with the
deals with the case
with the case of
the case of two
case of two pools
separate encoding for ity
where each can attack
encoding for ity to
each can attack the
for ity to sending
can attack the other
ity to sending rate
to sending rate with
sending rate with an
ordering transactions in advance
rate with an interleave
transactions in advance reduces
with an interleave index
analysis becomes more complicated
an interleave index of
becomes more complicated in
interleave index of i
more complicated in two
index of i and
complicated in two ways
of i and an
in advance reduces conflicts
i and an encoding
advance reduces conflicts and
reduces conflicts and increases
and an encoding rate
conflicts and increases commit
an encoding rate of
the revenue of each
and increases commit ratio
revenue of each pool
of each pool affects
each pool affects the
pool affects the revenue
high conflict rates occur
affects the revenue of
conflict rates occur without
the revenue of the
rates occur without with
revenue of the other
occur without with uniform
of the other through
the sender would have
without with uniform access
the other through the
sender would have to
with uniform access to
other through the infiltrating
would have to wait
through the infiltrating miners
uniform access to a
have to wait for
access to a small
to wait for odd
to a small number
we prove that for
wait for odd and
prove that for a
for odd and even
that for a static
odd and even packets
a small number of
for a static choice
and even packets i
a static choice of
small number of objects
static choice of infiltration
choice of infiltration rates
of infiltration rates the
infiltration rates the pool
rates the pool revenues
the pool revenues converge
and high probability of
high probability of accessing
probability of accessing a
of accessing a hotzone
once one pool changes
one pool changes its
packets before sending any
pool changes its infiltration
before sending any redundancy
changes its infiltration rate
sending any redundancy information
its infiltration rate of
infiltration rate of the
rate of the other
even inaccurate prediction is
inaccurate prediction is significant
receipt of its retransmission
prediction is significant in
of its retransmission have
is significant in high
the latter may prefer
its retransmission have to
latter may prefer to
retransmission have to be
may prefer to change
have to be buffered
prefer to change its
to be buffered at
to change its infiltration
significant in high contention
be buffered at the
change its infiltration rate
buffered at the rethese
its infiltration rate of
at the rethese two
compared to the the
the rethese two obstacles
to the the classical
rethese two obstacles to
infiltration rate of the
the the classical approach
two obstacles to using
rate of the former
obstacles to using fec
to using fec in
using fec in time
therefore the game itself
the game itself takes
game itself takes multiple
itself takes multiple rounds
takes multiple rounds to
multiple rounds to converge
tings rate sensitivity and
rate sensitivity and burst
sensitivity and burst susceptibility
and burst susceptibility are
we show analytically that
burst susceptibility are innotice
commit ratio is affected
show analytically that the
susceptibility are innotice that
analytically that the game
are innotice that for
ratio is affected if
that the game has
innotice that for this
the game has a
that for this commonplace
is affected if the
game has a single
for this commonplace scenario
has a single nash
affected if the predictor
a single nash equilibrium
if the predictor reserves
the loss of terlinked
the predictor reserves unnecessary
loss of terlinked through
predictor reserves unnecessary objects
of terlinked through the
reserves unnecessary objects by
terlinked through the tuning
unnecessary objects by a
through the tuning knobs
single nash equilibrium and
objects by a factor
nash equilibrium and numerically
by a factor of
an interleave of i
equilibrium and numerically study
interleave of i and
and numerically study the
of i and a
numerically study the equilibrium
i and a single
study the equilibrium points
a factor of slack
and a single packet
the equilibrium points for
a single packet stops
equilibrium points for different
single packet stops all
points for different pool
packet stops all traffic
for different pool sizes
stops all traffic in
all traffic in the
traffic in the channel
in the channel to
for pools smaller than
the channel to the
channel to the apa
to the apa rate
note that when all
the apa rate of
that when all accesses
when all accesses are
all accesses are to
accesses are to the
are to the hot
to the hot zone
at the equilibrium point
the equilibrium point both
provides tolerance to a
equilibrium point both pools
tolerance to a burst
point both pools earn
to a burst of
both pools earn less
a burst of up
pools earn less than
burst of up to
earn less than they
of up to c
less than they would
up to c i
than they would have
to c i plication
they would have in
c i plication for
would have in the
i plication for a
have in the nonequilibrium
plication for a seventh
in the nonequilibrium no
for a seventh of
a seventh of a
seventh of a second
commit rates are lower
rates are lower with
are lower with imperfect
lower with imperfect prediction
with imperfect prediction than
imperfect prediction than in
prediction than in the
than in the uniform
a sequence of such
since pools can decide
in the uniform random
sequence of such consecutive
pools can decide to
of such consecutive packets
the uniform random case
can decide to start
uniform random case with
decide to start or
to start or stop
start or stop attacking
or stop attacking at
the burst tolerance of
stop attacking at any
burst tolerance of blocks
attacking at any point
tolerance of blocks can
of blocks can have
blocks can have devastating
can have devastating effect
have devastating effect on
this can be modeled
devastating effect on a
can be modeled as
effect on a high
be modeled as the
modeled as the miner
as the miner s
the miner s dilemma
throughput an fec code
miner s dilemma an
an fec code can
s dilemma an instance
fec code can be
dilemma an instance of
code can be changed
an instance of the
can be changed by
instance of the iterative
be changed by modulating
of the iterative prisoner
changed by modulating either
the iterative prisoner s
by modulating either the
iterative prisoner s dilemma
modulating either the c
either the c system
the c system where
c system where every
system where every spare
this is because all
where every spare cycle
is because all accesses
every spare cycle counts
attacking is the dominant
because all accesses to
is the dominant strategy
all accesses to the
the dominant strategy in
accesses to the hot
dominant strategy in each
in applior the i
strategy in each iteration
applior the i parameters
zone go through a
go through a single
through a single om
but if the pools
increasing c enhances burst
a single om that
if the pools can
c enhances burst tolercations
single om that becomes
the pools can agree
enhances burst tolercations with
om that becomes a
pools can agree not
burst tolercations with many
that becomes a bottleneck
can agree not to
tolercations with many fine
agree not to attack
on the bright side
both benefit in the
benefit in the long
since object access conflicts
in the long run
a lost packet ance
object access conflicts occur
lost packet ance at
access conflicts occur only
packet ance at the
conflicts occur only at
we address in section
ance at the cost
address in section vii
at the cost of
in section vii the
occur only at a
the cost of network
section vii the case
cost of network and
only at a single
vii the case where
of network and encoding
the case where the
network and encoding overhead
case where the participants
at a single shard
where the participants are
the participants are an
potencan potentially trigger a
participants are an arbitrary
the reservations prevent deadlocks
potentially trigger a butterfly
are an arbitrary number
trigger a butterfly effect
an arbitrary number of
reservations prevent deadlocks and
a butterfly effect of
arbitrary number of identical
butterfly effect of missed
prevent deadlocks and result
effect of missed deadtially
deadlocks and result in
of missed deadtially worsening
number of identical pools
and result in perfect
missed deadtially worsening the
result in perfect commit
deadtially worsening the packet
there exists a symmetric
in perfect commit ratio
exists a symmetric equilibrium
worsening the packet loss
a symmetric equilibrium in
the packet loss experienced
perfect commit ratio with
packet loss experienced and
commit ratio with perfect
loss experienced and reducing
symmetric equilibrium in which
experienced and reducing lines
equilibrium in which each
and reducing lines along
in which each participating
reducing lines along a
ratio with perfect prediction
which each participating pool
lines along a distributed
each participating pool attacks
along a distributed workflow
participating pool attacks each
pool attacks each of
attacks each of the
each of the other
of the other participating
the other participating pools
where some of the
some of the objects
as in the minority
of the objects belong
in the minority two
the objects belong to
increasing i trades off
objects belong to a
i trades off recovery
belong to a so
trades off recovery periods
here too at equilibrium
off recovery periods market
to a so called
recovery periods market crashes
a so called hot
periods market crashes at
too at equilibrium all
market crashes at stock
at equilibrium all pools
crashes at stock exchanges
equilibrium all pools earn
all pools earn less
pools earn less than
earn less than with
less than with the
and each access is
christmas latency for better
than with the no
latency for better burst
each access is either
for better burst tolerance
access is either to
better burst tolerance without
is either to the
burst tolerance without adding
either to the hot
tolerance without adding overhead
our results imply that
without adding overhead sales
results imply that block
adding overhead sales at
imply that block withholding
overhead sales at online
that block withholding by
sales at online stores
block withholding by pools
or outside of it
withholding by pools leads
by pools leads to
winter storms at air
pools leads to an
chosen uniformly within each
leads to an unfavorable
uniformly within each zone
to an unfavorable equilibrium
traffic control as mentioned
for higher values of
higher values of i
due to the anonymity
to the anonymity of
we set an average
the encoder has to
the anonymity of miners
set an average transaction
encoder has to centers
an average transaction per
a single pool might
has to centers overloaded
average transaction per unit
single pool might be
to centers overloaded networks
pool might be tempted
centers overloaded networks and
might be tempted to
overloaded networks and end
be tempted to attack
hosts can exhibit wait
leading the other pools
can exhibit wait for
the other pools to
exhibit wait for more
other pools to attack
and transactions arrivals are
wait for more data
transactions arrivals are governed
for more data packets
pools to attack as
more data packets to
to attack as well
data packets to be
packets to be transmitted
to be transmitted before
arrivals are governed by
be transmitted before it
the implications might be
transmitted before it can
are governed by a
implications might be devastating
before it can continuous
might be devastating for
governed by a poisson
it can continuous packet
be devastating for open
can continuous packet loss
by a poisson process
devastating for open pools
a poisson process with
poisson process with the
with each lost packet
if their revenues are
each lost packet driving
process with the required
lost packet driving the
their revenues are reduced
packet driving the send
with the required tput
driving the send error
the send error correction
send error correction packets
miners will prefer to
will prefer to form
prefer to form closed
to form closed pools
form closed pools that
system further and further
closed pools that cannot
further and further out
pools that cannot be
and further out of
that cannot be attacked
further out of sync
cannot be attacked in
we are unaware of
out of sync with
be attacked in this
are unaware of work
of sync with respect
attacked in this manner
sync with respect to
unaware of work that
with respect to its
of work that uses
respect to its importantly
though this may be
work that uses prediction
this may be conceived
that uses prediction to
may be conceived as
once the fec encoding
be conceived as bad
uses prediction to order
the fec encoding is
conceived as bad news
fec encoding is parameterized
prediction to order distributed
as bad news for
encoding is parameterized real
to order distributed transactions
bad news for public
order distributed transactions before
news for public mining
distributed transactions before certification
for public mining pools
with a rate and
a rate and an
rate and an interleave
and an interleave to
on the whole it
an interleave to tolerate
the whole it may
interleave to tolerate a
whole it may be
to tolerate a certain
it may be good
tolerate a certain burst
may be good news
a certain burst sensitive
be good news to
certain burst sensitive flow
good news to the
burst sensitive flow control
news to the bitcoin
uses static analysis to
to the bitcoin system
static analysis to allow
analysis to allow separate
to allow separate workers
ip is unable to
which prefers small pools
allow separate workers to
is unable to distinguish
separate workers to process
unable to distinguish length
workers to process independent
we examine the practicality
to distinguish length b
examine the practicality of
to process independent transactions
the practicality of the
process independent transactions without
practicality of the attack
independent transactions without synchronization
of the attack in
the attack in section
attack in section viii
in section viii and
section viii and discuss
viii and discuss implications
and discuss implications and
rain s suggestive prediction
discuss implications and model
implications and model extensions
and model extensions in
model extensions in section
gargamel determines the final
extensions in section ix
determines the final transaction
the final transaction order
and does not tolerate
does not tolerate false
our contributions are the
not tolerate false positive
contributions are the following
tolerate false positive prediction
to between ephemeral loss
false positive prediction errors
between ephemeral loss modes
ephemeral loss modes due
loss modes due to
modes due to transient
due to transient contolerate
to transient contolerate a
transient contolerate a burst
it targets a different
definition of the pool
contolerate a burst of
of the pool game
a burst of length
the pool game where
targets a different setting
pool game where pools
a different setting than
game where pools in
different setting than acid
where pools in a
pools in a proof
ofwork secured system attack
it is a fully
secured system attack one
is a fully replicated
system attack one another
a fully replicated data
attack one another with
fully replicated data store
one another with a
another with a pool
with a pool block
a pool block withholding
all losses occurring gestion
pool block withholding attack
with a centralized scheduler
or dirty fiber and
dirty fiber and persistent
fiber and persistent in
in the general case
and persistent in bursts
for an increasing number
persistent in bursts of
an increasing number of
in bursts of size
increasing number of shards
bursts of size less
of size less than
size less than or
attacks is not an
less than or equal
is not an equilibrium
we run multiple simulations
than or equal to
run multiple simulations to
or equal to b
multiple simulations to find
equal to b are
simulations to find the
to b are recovered
to find the maximal
b are recovered with
with two minority pools
are recovered with congestion
find the maximal tput
two minority pools participating
the maximal tput the
maximal tput the system
the loss of one
tput the system can
loss of one packet
the only nash equilibrium
of one packet out
only nash equilibrium is
one packet out of
the system can handle
nash equilibrium is when
packet out of ten
equilibrium is when the
out of ten thousand
is when the pools
of ten thousand is
a global log forms
when the pools attack
ten thousand is sufficient
global log forms a
the pools attack one
thousand is sufficient to
log forms a bottleneck
pools attack one another
is sufficient to reduce
sufficient to reduce tcp
and both earn less
both earn less than
pc with smr tms
ip throughput to a
earn less than if
throughput to a third
less than if none
with smr tms is
to a third of
than if none had
a third of its
if none had attacked
third of its the
smr tms is blocked
of its the same
tms is blocked by
its the same latency
miners therefore face the
the same latency and
therefore face the miner
same latency and this
is blocked by contention
face the miner s
latency and this latency
blocked by contention much
the miner s dilemma
and this latency depends
by contention much earlier
this latency depends on
contention much earlier than
latency depends on the
an instance of the
depends on the i
much earlier than acid
instance of the iterative
on the i palossless
of the iterative prisoner
the i palossless maximum
the iterative prisoner s
iterative prisoner s dilemma
rain due to its
due to its longer
to its longer certification
if one packet is
repeatedly choosing between attack
one packet is lost
choosing between attack and
packet is lost out
between attack and no
its longer certification time
is lost out of
lost out of a
out of a thousand
we briefly review here
briefly review here work
review here work related
here work related to
work related to acidrain
related to acidrain s
to acidrain s certification
acidrain s certification protocol
with multiple pools of
multiple pools of equal
we d like to
pools of equal size
d like to parameterize
of equal size there
one approach for certification
like to parameterize the
equal size there is
to parameterize the encoding
approach for certification is
parameterize the encoding to
for certification is to
the encoding to tolerate
size there is a
encoding to tolerate a
certification is to use
there is a symmetric
to tolerate a maximum
is a symmetric nash
is to use a
tolerate a maximum burst
a symmetric nash equilibrium
a maximum burst length
to use a single
maximum burst length and
use a single highly
burst length and then
where all pools earn
length and then have
all pools earn less
and then have recovthroughput
pools earn less than
then have recovthroughput collapses
earn less than if
available service that orders
have recovthroughput collapses to
less than if none
recovthroughput collapses to a
service that orders all
than if none had
collapses to a thirtieth
that orders all transactions
if none had attacked
to a thirtieth of
orders all transactions in
a thirtieth of the
all transactions in the
thirtieth of the maximum
transactions in the system
ery latency depend on
latency depend on the
depend on the actual
on the actual burstiness
inefficient equilibria for open
the actual burstiness of
equilibria for open pools
actual burstiness of the
for open pools may
burstiness of the loss
open pools may serve
pools may serve the
may serve the system
serve the system by
at the same time
the system by reducing
system by reducing their
by reducing their attraction
reducing their attraction and
we would like the
their attraction and pushing
would like the encoding
attraction and pushing miners
like the encoding to
and pushing miners towards
the encoding to have
pushing miners towards smaller
encoding to have a
miners towards smaller closed
towards smaller closed pools
a transaction commits if
transaction commits if and
the classical block withholding
commits if and only
classical block withholding attack
if and only if
block withholding attack is
and only if it
withholding attack is as
only if it has
attack is as old
fec constant rate for
if it has no
is as old as
constant rate for network
it has no conflicts
as old as pools
rate for network provisioning
has no conflicts with
old as pools themselves
for network provisioning and
no conflicts with previous
network provisioning and stability
conflicts with previous committed
but its use by
with previous committed transactions
its use by pools
use by pools has
by pools has not
an fec scheme is
pools has not been
fec scheme is required
has not been suggested
scheme is required where
not been suggested until
is required where latency
been suggested until recently
required where latency of
where latency of fec
latency of fec encoders
of fec encoders are
fec encoders are typically
we overview related attacks
encoders are typically parameterized
transaction rate is high
overview related attacks and
are typically parameterized with
related attacks and prior
typically parameterized with an
attacks and prior work
such a global service
and prior work in
a global service becomes
prior work in section
global service becomes a
work in section x
service becomes a bottleneck
recovery degrades gracefully as
degrades gracefully as losses
and conclude with final
gracefully as losses get
conclude with final remarks
as losses get burstier
with final remarks in
final remarks in section
our system has no
remarks in section xi
system has no such
even tuple for each
has no such bottleneck
tuple for each outgoing
for each outgoing sequence
each outgoing sequence of
outgoing sequence of r
p reliminaries b itcoin
sequence of r data
reliminaries b itcoin and
of r data packets
b itcoin and p
itcoin and p ooled
and p ooled m
p ooled m ining
ooled m ining bitcoin
a as the encoding
m ining bitcoin is
as the encoding overhead
ining bitcoin is a
the encoding overhead stays
bitcoin is a distributed
encoding overhead stays constant
serialized all transactions when
all transactions when they
transactions when they enter
when they enter the
they enter the system
enter the system to
the system to achieve
c data and error
system to achieve a
data and error correction
to achieve a deterministic
and error correction packets
achieve a deterministic order
error correction packets are
correction packets are sent
despite nondeterministic operations the
nondeterministic operations the transactions
operations the transactions take
redundancy information cannot be
they consider only stored
information cannot be generated
consider only stored procedures
cannot be generated and
be generated and sent
generated and sent until
and sent until all
which enable this approach
sent until all r
until all r data
all r data packets
r data packets are
whereas we address long
data packets are available
packets are available for
we address long running
are available for sending
address long running transactions
long running transactions and
running transactions and use
transactions and use prediction
and use prediction to
use prediction to infer
prediction to infer an
to infer an order
the latency of packet
latency of packet recovery
of packet recovery is
packet recovery is determined
recovery is determined by
is determined by the
determined by the rate
by the rate at
the rate at which
rate at which the
clients use the system
at which the sender
use the system by
which the sender transmits
the system by issuing
the sender transmits data
system by issuing transactions
transactions are also serialized
are also serialized by
also serialized by a
serialized by a central
generating error correction packets
by a central service
and the system s
the system s only
maelstrom design and implemenfrom
system s only task
design and implemenfrom less
s only task is
and then scheduled according
only task is to
then scheduled according to
and implemenfrom less than
task is to serialize
scheduled according to this
is to serialize transactions
according to this global
implemenfrom less than r
to serialize transactions in
less than r data
serialize transactions in a
than r data packets
transactions in a single
to this global order
in a single ledger
r data packets at
a single ledger and
data packets at the
single ledger and reject
packets at the sender
ledger and reject transactions
at the sender is
and reject transactions that
the sender is not
reject transactions that cannot
sender is not a
transactions that cannot be
is not a viable
that cannot be serialized
rain avoids a central
not a viable tation
cannot be serialized due
a viable tation option
be serialized due to
avoids a central service
viable tation option even
serialized due to conflicts
tation option even though
due to conflicts with
option even though the
to conflicts with previous
even though the data
conflicts with previous transactions
though the data rate
the data rate in
data rate in this
rate in this channel
in this channel is
this channel is low
bitcoin transactions are protected
transactions are protected with
are protected with cryptographic
protected with cryptographic techniques
targets a different problem
with cryptographic techniques that
cryptographic techniques that ensure
techniques that ensure that
that ensure that only
or network could be
ensure that only the
network could be operating
that only the rightful
could be operating at
only the rightful owner
be operating at near
the rightful owner of
operating at near full
rightful owner of a
where it embraces non
at near full capacity
owner of a bitcoin
near full capacity with
of a bitcoin can
full capacity with data
a bitcoin can transfer
determinism and separates execution
capacity with data from
bitcoin can transfer it
and separates execution from
with data from other
separates execution from verification
data from other senders
the transaction ledger is
transaction ledger is stored
ledger is stored by
the result is somewhat
is stored by a
we describe the maelstrom
stored by a network
result is somewhat analogous
describe the maelstrom appliance
by a network of
the maelstrom appliance as
a network of miners
is somewhat analogous to
maelstrom appliance as a
network of miners in
appliance as a single
of miners in a
as a single machine
somewhat analogous to our
miners in a data
a single machine fec
in a data structure
single machine fec is
a data structure caller
analogous to our separation
machine fec is also
data structure caller the
to our separation of
fec is also very
structure caller the blockchain
is also very susceptible
our separation of optimistic
also very susceptible to
separation of optimistic ordering
very susceptible to bursty
of optimistic ordering and
susceptible to bursty losses
optimistic ordering and conservative
revenue for proof of
ordering and conservative certification
for proof of work
proof of work the
of work the blockchain
work the blockchain records
make it easier to
the blockchain records the
it easier to create
blockchain records the transactions
easier to create a
records the transactions in
to create a practical
the transactions in units
create a practical predictor
transactions in units of
in units of blocks
certification scalability to evaluate
we will show how
scalability to evaluate the
will show how more
to evaluate the scalability
show how more machines
dubbed the genesis block
evaluate the scalability of
how more machines can
the scalability of acid
is defined as part
more machines can be
defined as part of
machines can be added
as part of the
can be added to
rain s certification mechanism
part of the protocol
be added to terleaving
we avoid prediction and
a valid block contains
avoid prediction and measure
valid block contains the
prediction and measure the
block contains the hash
and measure the maximal
contains the hash of
measure the maximal commit
the hash of the
the maximal commit rate
is a standard encoding
hash of the previous
a standard encoding technique
of the previous block
standard encoding technique used
maximal commit rate it
encoding technique used the
commit rate it can
technique used the appliance
the hash of the
used the appliance to
hash of the transactions
the appliance to balance
of the transactions in
appliance to balance encoding
the transactions in the
rate it can accommodate
to balance encoding load
transactions in the current
balance encoding load and
in the current block
encoding load and scale
it can accommodate with
load and scale to
can accommodate with an
and a bitcoin address
and scale to multo
a bitcoin address which
scale to multo combat
bitcoin address which is
accommodate with an increasing
to multo combat bursty
address which is to
multo combat bursty loss
which is to be
with an increasing number
is to be credited
an increasing number of
where error correction pack
to be credited with
increasing number of shards
be credited with a
credited with a reward
tiple gigabits per second
with a reward for
gigabits per second of
a reward for generating
per second of traffic
reward for generating the
for generating the block
a b c d
b c d x
any miner may add
c d x x
writes of objects chosen
miner may add a
d x x e
may add a valid
x x e f
add a valid block
x e f g
a valid block to
e f g h
valid block to the
f g h x
of objects chosen uniformly
block to the chain
g h x x
objects chosen uniformly at
to the chain by
h x x appliance
chosen uniformly at random
uniformly at random from
at random from a
random from a small
from a small set
a small set of
proving that it has
that it has spent
it has spent a
has spent a certain
spent a certain amount
a certain amount of
certain amount of work
amount of work and
of work and publishing
work and publishing the
and publishing the block
publishing the block with
the block with the
block with the proof
with the proof over
the proof over an
proof over an overlay
over an overlay network
an overlay network to
overlay network to all
acidrain against two approaches
network to all other
to all other miners
more details in section
when a miner creates
a miner creates a
miner creates a block
it is compensated for
is compensated for its
compensated for its efforts
smr tms is two
for its efforts with
its efforts with bitcoins
phase commit with reliable
commit with reliable coordinators
lan mtu lambda jumbo
this compensation includes a
mtu lambda jumbo mtu
compensation includes a per
lambda jumbo mtu recipe
jumbo mtu recipe list
transaction fee paid by
fee paid by the
paid by the users
by the users electronic
global log is an
the users electronic copy
log is an architecture
users electronic copy available
is an architecture where
electronic copy available at
an architecture where tms
architecture where tms submit
where tms submit all
tms submit all transactions
submit all transactions to
all transactions to a
transactions to a single
to a single global
a single global log
single global log and
global log and check
log and check conflicts
and check conflicts on
check conflicts on that
conflicts on that single
on that single log
has lower latency for
lower latency for a
latency for a given
for a given throughput
whose transactions are included
pc since its faster
since its faster certification
its faster certification reduces
faster certification reduces contention
and an amount of
an amount of minted
amount of minted bitcoins
it has no bottleneck
of minted bitcoins that
has no bottleneck as
minted bitcoins that are
no bottleneck as with
bitcoins that are thus
bottleneck as with a
that are thus introduced
as with a global
are thus introduced into
with a global log
thus introduced into the
introduced into the system
that has less overhead
has less overhead in
less overhead in small
the work which a
overhead in small scale
work which a miner
which a miner is
a miner is required
miner is required to
is required to do
required to do is
while the parameters we
to do is to
the parameters we choose
do is to repeatedly
parameters we choose are
is to repeatedly calculate
we choose are arbitrary
to repeatedly calculate a
repeatedly calculate a a
calculate a a hash
a a hash function
repair packets are injected
a hash function specifically
packets are injected into
hash function specifically the
are injected into stream
function specifically the sha
the trends are robust
injected into stream transparently
choosing other parameters would
other parameters would provide
parameters would provide similar
would provide similar trends
basic mechanism the basic
mechanism the basic operation
the basic operation of
basic operation of maelstrom
operation of maelstrom is
of maelstrom is shown
maelstrom is shown in
is shown in figure
of a block header
to indicate that he
it intercepts outgoing data
indicate that he has
intercepts outgoing data packets
that he has performed
outgoing data packets and
he has performed this
data packets and routes
has performed this work
packets and routes them
and routes them to
routes them to the
them to the destination
to the destination datacenter
the miner provides a
miner provides a probabilistic
provides a probabilistic proof
a probabilistic proof as
probabilistic proof as follows
generating and injecting fec
and injecting fec repair
injecting fec repair packets
fec repair packets into
the generated block has
repair packets into the
phase commit for transaction
generated block has a
block has a nonce
packets into the stream
commit for transaction certification
has a nonce field
into the stream in
the stream in their
stream in their wake
the downside of these
which can contain any
downside of these approaches
can contain any value
of these approaches compared
a repair packet consists
these approaches compared to
repair packet consists of
the miner places different
packet consists of a
miner places different values
consists of a recipe
places different values in
of a recipe list
different values in this
a recipe list of
values in this field
approaches compared to acid
recipe list of data
in this field and
list of data packet
this field and calculates
of data packet identifiers
field and calculates the
rain is that they
data packet identifiers and
and calculates the hash
packet identifiers and fec
is that they require
calculates the hash for
identifiers and fec information
that they require a
the hash for each
and fec information generated
they require a coordinator
hash for each value
fec information generated from
require a coordinator that
information generated from these
a coordinator that performs
generated from these packets
coordinator that performs transactions
that performs transactions to
if the result of
in the example in
performs transactions to be
the result of the
the example in figure
result of the hash
transactions to be highly
of the hash is
to be highly available
the hash is smaller
hash is smaller than
is smaller than a
this information is a
smaller than a target
information is a simple
this requires another consensus
than a target value
is a simple xor
in addition to the
addition to the one
the nonce is considered
to the one at
the size of the
nonce is considered a
size of the xor
is considered a solution
of the xor is
the one at the
the xor is equal
one at the shard
xor is equal to
and the block is
is equal to the
at the shard itself
the block is valid
equal to the mtu
to the mtu of
the mtu of the
mtu of the datacenter
of the datacenter network
the number of attempts
number of attempts to
of attempts to find
attempts to find a
and to avoid fragmentation
to find a single
to avoid fragmentation of
find a single hash
avoid fragmentation of repair
related work our transaction
fragmentation of repair packets
work our transaction ordering
of repair packets we
a single hash is
repair packets we require
single hash is therefore
packets we require that
our transaction ordering protocol
hash is therefore random
transaction ordering protocol is
is therefore random with
we require that the
ordering protocol is inspired
therefore random with a
require that the mtu
random with a geometric
protocol is inspired by
that the mtu of
with a geometric distribution
is inspired by a
the mtu of the
inspired by a state
mtu of the long
as each attempt is
each attempt is a
attempt is a bernoulli
machine ordering mechanism suggested
is a bernoulli trial
haul network be set
a bernoulli trial with
network be set to
bernoulli trial with a
be set to a
ordering mechanism suggested by
trial with a success
set to a slightly
with a success probability
mechanism suggested by lamport
to a slightly larger
a success probability determined
a slightly larger value
success probability determined by
probability determined by the
determined by the target
by the target value
this requirement is usually
requirement is usually satisfied
is usually satisfied in
usually satisfied in practical
at the existing huge
satisfied in practical deployments
the existing huge hashing
existing huge hashing rates
huge hashing rates and
hashing rates and small
but we have generalized
rates and small target
since gigabit links very
we have generalized the
and small target values
gigabit links very often
have generalized the protocol
links very often use
generalized the protocol to
very often use jumbo
the time to find
often use jumbo frames
the protocol to work
time to find a
use jumbo frames of
to find a single
jumbo frames of up
find a single hash
frames of up to
protocol to work with
a single hash can
to work with arbitrary
single hash can be
work with arbitrary overlapping
hash can be approximated
with arbitrary overlapping par
can be approximated by
be approximated by an
approximated by an exponential
by an exponential distribution
references the approaches of
the approaches of mdcc
the average time for
average time for a
time for a miner
for a miner to
a miner to find
miner to find a
to find a solution
find a solution is
a solution is therefore
while lan networks have
solution is therefore proportional
lan networks have standard
is therefore proportional to
networks have standard mtus
therefore proportional to its
have standard mtus of
proportional to its hashing
to its hashing rate
its hashing rate or
hashing rate or mining
rate or mining power
to maintain a constant
maintain a constant rate
a constant rate of
constant rate of bitcoin
are close to acid
rate of bitcoin generation
at the receiving datacenter
rain s certification mechanism
and as part of
as part of its
part of its defense
the appliance examines incoming
of its defense against
appliance examines incoming repair
its defense against denial
examines incoming repair packets
defense against denial of
incoming repair packets and
against denial of service
repair packets and uses
denial of service and
packets and uses them
of service and other
rain separates the om
and uses them to
service and other attacks
uses them to recover
separates the om abstraction
them to recover missing
the om abstraction from
to recover missing data
the system normalizes the
om abstraction from the
recover missing data packets
system normalizes the rate
abstraction from the highly
normalizes the rate of
the rate of block
rate of block generation
the data packet is
data packet is injected
packet is injected transparently
is injected transparently into
injected transparently into the
leasing mechanism and fast
transparently into the stream
the protocol deterministically defines
mechanism and fast recovery
protocol deterministically defines the
into the stream to
deterministically defines the target
the stream to the
defines the target value
stream to the receiving
the target value for
we also address garbage
to the receiving end
target value for each
also address garbage collection
value for each block
for each block according
each block according to
block according to the
according to the time
which cannot be done
recovered data packets will
to the time required
data packets will typically
cannot be done independently
the time required to
packets will typically arrive
be done independently at
time required to generate
will typically arrive out
done independently at the
required to generate recent
independently at the logs
to generate recent blocks
but this behavior is
this behavior is expected
behavior is expected by
is expected by communication
expected by communication stacks
is updated once every
by communication stacks designed
communication stacks designed for
stacks designed for the
designed for the commodity
for the commodity internet
flow control while relaying
control while relaying tcp
blocks such that the
such that the average
that the average time
the average time for
maelstrom has two flow
average time for each
has two flow control
time for each block
two flow control modes
for each block to
each block to be
block to be found
to be found is
note that the exponential
that the exponential distribution
the exponential distribution is
exponential distribution is memoryless
if all miners mine
all miners mine for
miners mine for block
the appliance routes packets
mine for block number
appliance routes packets through
for block number b
routes packets through without
packets through without modification
a new paradigm for
new paradigm for building
once the block is
paradigm for building scalable
the block is found
for building scalable distributed
block is found at
control between the endhosts
building scalable distributed systems
is found at time
found at time t
the appliance acts as
all miners switch to
appliance acts as a
miners switch to mine
acts as a tcp
switch to mine for
to mine for the
mine for the subsequent
for the subsequent block
the subsequent block b
terminating connections and sending
connections and sending back
and sending back acks
sending back acks immediately
at t without changing
back acks immediately before
t without changing their
acks immediately before relaying
without changing their probability
immediately before relaying data
changing their probability distribution
before relaying data on
their probability distribution of
relaying data on appliance
probability distribution of finding
distribution of finding a
of finding a block
finding a block after
a block after t
uses an architecture similar
this is particularly useful
an architecture similar to
is particularly useful for
the probability that a
architecture similar to our
probability that a miner
particularly useful for applications
that a miner i
useful for applications with
similar to our certification
for applications with short
a miner i with
to our certification mechanism
miner i with mining
i with mining power
lived flows that need
with mining power mi
flows that need to
mining power mi finds
that need to ramp
power mi finds the
need to ramp up
mi finds the next
but addresses minitransactions that
to ramp up throughput
finds the next block
ramp up throughput quickly
addresses minitransactions that are
the next block is
up throughput quickly and
next block is its
throughput quickly and avoid
block is its ratio
quickly and avoid the
is its ratio out
minitransactions that are submitted
and avoid the slow
its ratio out of
that are submitted as
ratio out of the
are submitted as a
out of the total
start effects of tcp
submitted as a whole
of the total mining
the total mining power
total mining power m
ip on a long
mining power m in
with no attempt to
on a long link
power m in the
no attempt to order
m in the system
attempt to order potentially
the performance advantages of
to order potentially conflicting
performance advantages of splitting
order potentially conflicting transactions
advantages of splitting longdistance
miner miner miner pool
of splitting longdistance connections
splitting longdistance connections into
we address full transactions
longdistance connections into multiple
miner miner miner pool
connections into multiple hops
into multiple hops are
multiple hops are well
where the clients sequentially
hops are well known
the clients sequentially access
clients sequentially access objects
sequentially access objects before
access objects before ending
objects before ending a
before ending a transaction
and use prediction to
and orthogonal to this
use prediction to order
orthogonal to this work
prediction to order them
to order them in
order them in advance
we are primarily interested
are primarily interested in
we believe our techniques
primarily interested in isolating
believe our techniques could
interested in isolating the
our techniques could be
in isolating the impact
techniques could be used
isolating the impact of
could be used to
the impact of rapid
be used to reduce
impact of rapid and
used to reduce abort
of rapid and transparent
to reduce abort rates
rapid and transparent recovery
reduce abort rates of
and transparent recovery of
and one miner mines
transparent recovery of lost
one miner mines solo
recovery of lost packets
abort rates of systems
of lost packets by
rates of systems using
lost packets by maelstrom
of systems using sinfonia
packets by maelstrom on
pools datacenters are built
by maelstrom on tcp
systems using sinfonia or
datacenters are built around
using sinfonia or a
are built around the
sinfonia or a similar
built around the world
rather than the buffering
or a similar certification
than the buffering and
a similar certification mechanism
the buffering and slow
start avoidance benefits of
avoidance benefits of generic
benefits of generic performance
mining is only profitable
is only profitable using
in the remainder of
only profitable using dedicated
the remainder of the
profitable using dedicated hardware
remainder of the paper
using dedicated hardware in
dedicated hardware in cutting
hardware in cutting edge
in cutting edge mining
cutting edge mining rigs
we describe maelstrom with
describe maelstrom with end
otherwise the energy costs
the energy costs exceed
energy costs exceed the
costs exceed the expected
exceed the expected revenue
although expected revenue from
expected revenue from mining
revenue from mining is
from mining is proportional
mining is proportional to
while maelstrom respects end
is proportional to the
proportional to the power
to the power of
the power of the
power of the mining
of the mining rigs
the mining rigs used
end flow control connections
a single home miner
or splits them and
single home miner using
splits them and implements
home miner using a
them and implements its
miner using a small
and implements its own
using a small rig
implements its own proxy
a small rig is
small rig is unlikely
rig is unlikely to
is unlikely to mine
unlikely to mine a
to mine a block
mine a block for
a block for years
proxy flow control as
flow control as described
control as described above
it is not designed
is not designed for
not designed for routinely
designed for routinely congested
for routinely congested networks
the addition of fec
addition of fec under
of fec under tcp
miners often organize themselves
often organize themselves into
organize themselves into mining
themselves into mining pools
ip flow control allows
flow control allows it
control allows it to
allows it to steal
it to steal bandwidth
to steal bandwidth from
steal bandwidth from other
a pool is a
bandwidth from other competing
pool is a group
from other competing flows
is a group of
other competing flows running
a group of miners
competing flows running without
group of miners that
flows running without fec
of miners that share
running without fec in
miners that share their
without fec in the
that share their revenues
fec in the link
share their revenues when
their revenues when one
revenues when one of
when one of them
though maintaining fairness versus
highly available storage for
one of them successfully
maintaining fairness versus similarly
of them successfully mines
available storage for interactive
fairness versus similarly fec
them successfully mines a
storage for interactive services
successfully mines a block
for each block found
the revenue is distributed
revenue is distributed among
is distributed among the
distributed among the pool
among the pool members
the pool members in
pool members in proportion
members in proportion to
in proportion to their
proportion to their mining
to their mining power
friendliness with conventional tcp
ip flows is not
flows is not a
the expected revenue of
is not a primary
expected revenue of a
not a primary protocol
revenue of a pool
a primary protocol design
of a pool member
primary protocol design goal
a pool member is
protocol design goal on
pool member is therefore
design goal on over
member is therefore the
is therefore the same
therefore the same as
the same as its
same as its revenue
as its revenue had
its revenue had it
revenue had it mined
had it mined solo
which are often dedicated
are often dedicated to
often dedicated to specific
dedicated to specific highvalue
to specific highvalue applications
due to the large
to the large power
we see evidence for
the large power of
see evidence for this
large power of the
evidence for this assertion
power of the pool
for this assertion in
this assertion in the
assertion in the routine
in the routine use
the routine use of
it finds blocks at
routine use of parallel
finds blocks at a
use of parallel flows
blocks at a much
at a much higher
a much higher rate
a transactional record manager
transactional record manager for
and so the frequency
record manager for shared
so the frequency of
manager for shared flash
the frequency of revenue
frequency of revenue collection
and udp blast protocols
of revenue collection is
revenue collection is higher
allowing for a stable
for a stable daily
a stable daily or
stable daily or weekly
daily or weekly income
most pools are controlled
pools are controlled by
are controlled by a
controlled by a centralized
by a centralized pool
a centralized pool manager
both in commercial deployments
in commercial deployments and
commercial deployments and by
deployments and by researchers
and by researchers seeking
miners register with the
by researchers seeking to
register with the pool
researchers seeking to transfer
with the pool manager
seeking to transfer large
the pool manager and
to transfer large amounts
pool manager and mine
transfer large amounts of
manager and mine on
large amounts of data
and mine on its
amounts of data over
mine on its behalf
of data over high
the pool manager generates
pool manager generates tasks
manager generates tasks and
generates tasks and the
tasks and the miners
and the miners search
the miners search for
miners search for solutions
search for solutions based
for solutions based on
solutions based on these
based on these tasks
on these tasks that
layered interleaving in layered
these tasks that can
interleaving in layered interleaving
tasks that can serve
a middleware for highperformance
that can serve as
middleware for highperformance transaction
an fec protocol with
can serve as proof
fec protocol with rate
for highperformance transaction processing
serve as proof of
as proof of work
once they find a
they find a solution
is produced by running
produced by running c
they send it to
by running c multiple
send it to the
running c multiple instances
it to the pool
c multiple instances of
to the pool manager
multiple instances of an
the pool manager behaves
pool manager behaves as
manager behaves as a
behaves as a single
as a single miner
a single miner in
single miner in the
miner in the bitcoin
in the bitcoin system
fec protocol simultaneously with
protocol simultaneously with increasing
once it obtains a
simultaneously with increasing interleave
it obtains a legitimate
with increasing interleave indices
obtains a legitimate block
increasing interleave indices i
a legitimate block from
legitimate block from one
block from one of
from one of its
one of its miners
the block transfers the
block transfers the revenue
transfers the revenue to
the revenue to the
revenue to the control
to the control of
the control of the
control of the pool
of the pool manager
the pool manager then
pool manager then distributes
manager then distributes the
then distributes the revenue
boosting dbms performance by
distributes the revenue among
dbms performance by parallelising
the revenue among the
performance by parallelising write
revenue among the miners
by parallelising write transactions
among the miners according
the miners according to
miners according to their
according to their mining
to their mining power
the architecture is illustrated
architecture is illustrated in
is illustrated in figure
in order to estimate
order to estimate the
to estimate the mining
estimate the mining power
the mining power of
mining power of a
power of a miner
the pool manager sets
pool manager sets a
manager sets a partial
sets a partial target
a partial target for
prediction of transaction behavior
partial target for each
of transaction behavior has
target for each member
transaction behavior has the
behavior has the potential
has the potential to
the potential to significantly
potential to significantly decrease
to significantly decrease abort
significantly decrease abort rates
decrease abort rates in
abort rates in large
rates in large scale
in large scale transactional
large scale transactional systems
scale transactional systems with
transactional systems with high
systems with high contention
than the target of
the target of the
target of the bitcoin
of the bitcoin system
rain we employ prediction
we employ prediction to
employ prediction to obtain
each miner is required
prediction to obtain soft
miner is required to
to obtain soft reservations
is required to send
obtain soft reservations and
required to send the
soft reservations and implement
to send the pool
reservations and implement atomic
send the pool manager
and implement atomic transactions
the pool manager blocks
implement atomic transactions while
pool manager blocks that
atomic transactions while requiring
manager blocks that are
transactions while requiring high
blocks that are correct
while requiring high availability
three instances of an
that are correct according
requiring high availability only
are correct according to
high availability only in
correct according to the
availability only in a
according to the partial
only in a single
to the partial target
in a single tier
a single tier of
single tier of independent
tier of independent logs
the partial target is
this allows for low
the first instance with
partial target is chosen
first instance with interleave
target is chosen to
instance with interleave i
is chosen to be
chosen to be large
such that partial solutions
that partial solutions arrive
partial solutions arrive frequently
rain s operations never
solutions arrive frequently enough
s operations never depend
arrive frequently enough for
the second with interleave
frequently enough for the
operations never depend on
second with interleave i
enough for the manager
never depend on a
for the manager to
depend on a single
the manager to accurately
on a single machine
manager to accurately estimate
a single machine by
to accurately estimate the
single machine by allowing
accurately estimate the power
machine by allowing fast
estimate the power of
and the third with
by allowing fast recovery
the power of the
the third with interleave
allowing fast recovery from
power of the miner
third with interleave i
fast recovery from failures
recovery from failures and
from failures and performance
failures and performance hiccups
to reduce management overhead
as the value of
the value of bitcoin
value of bitcoin rose
bitcoin mining has become
mining has become a
has become a rapidly
become a rapidly advancing
a rapidly advancing industry
technological advancements lead to
advancements lead to ever
lead to ever more
to ever more efficient
ever more efficient hashing
more efficient hashing asics
fec encoding is simply
encoding is simply an
is simply an xor
simply an xor of
an xor of the
xor of the r
of the r data
the r data packets
r data packets hence
in layered interleaving each
layered interleaving each data
interleaving each data packet
each data packet is
data packet is included
packet is included in
is included in c
included in c xors
this is a simplification
is a simplification that
a simplification that is
simplification that is sufficient
that is sufficient for
each of which is
is sufficient for our
benchmarking cloud serving systems
of which is generated
sufficient for our analysis
which is generated at
cloud serving systems with
is generated at different
serving systems with ycsb
the intricacies of reward
generated at different interleaves
intricacies of reward systems
at different interleaves from
of reward systems are
different interleaves from the
reward systems are explained
interleaves from the original
systems are explained in
from the original data
the original data stream
as we shall describe
we shall describe shortly
ensures that the c
that the c xors
a notable exception is
the c xors containing
notable exception is p
c xors containing a
xors containing a data
containing a data packet
a data packet do
data packet do not
packet do not have
do not have any
not have any other
which we discuss in
we discuss in section
discuss in section ix
forks block propagation in
block propagation in the
propagation in the overlay
in the overlay network
the overlay network takes
overlay network takes seconds
therefore it is possible
it is possible for
is possible for two
possible for two distant
for two distant miners
two distant miners to
distant miners to generate
miners to generate competing
to generate competing blocks
both of which name
of which name the
which name the same
we plan to build
name the same block
plan to build on
the same block as
to build on our
same block as their
build on our simulation
block as their predecessor
on our simulation results
our simulation results by
simulation results by implementing
results by implementing acid
rain and exploring the
and exploring the different
exploring the different aspects
are rare since the
the different aspects of
rare since the average
different aspects of its
since the average mining
aspects of its performance
the average mining interval
of its performance in
average mining interval is
its performance in realistic
performance in realistic settings
of particular interest are
and they occur on
they occur on average
occur on average once
on average once every
different network topologies with
network topologies with a
topologies with a single
with a single datacenter
a single datacenter and
single datacenter and with
datacenter and with multiple
and with multiple datacenters
behavior in face of
the system has a
in face of high
system has a mechanism
face of high contention
has a mechanism to
a mechanism to solve
mechanism to solve forks
to solve forks when
solve forks when they
forks when they do
when they do occur
rain should prove efficient
data packet in common
causing one of the
one of the blocks
of the blocks to
the blocks to be
blocks to be discarded
the resulting protocol effectively
where its overhead may
resulting protocol effectively has
its overhead may be
protocol effectively has a
we ignore bifurcations for
overhead may be wasteful
effectively has a rate
ignore bifurcations for the
has a rate of
bifurcations for the sake
for the sake of
the sake of simplicity
since the choice of
the choice of the
choice of the discarded
of the discarded block
the discarded block on
discarded block on bifurcation
block on bifurcation is
on bifurcation is random
behavior in error prone
with each xor generated
in error prone scenarios
each xor generated from
one may incorporate this
xor generated from r
may incorporate this event
generated from r data
incorporate this event into
from r data packets
this event into the
r data packets and
event into the probability
data packets and each
into the probability of
packets and each data
the probability of finding
and each data packet
probability of finding a
each data packet included
of finding a block
data packet included in
packet included in c
performance with predictors of
included in c xors
with predictors of different
and consider instead the
predictors of different qualities
consider instead the probability
instead the probability of
the probability of finding
probability of finding a
illustrates layered interleaving for
of finding a block
layered interleaving for a
finding a block that
a block that is
block that is not
that is not discarded
pools often charge a
often charge a small
charge a small percentage
a small percentage of
small percentage of the
percentage of the revenue
of the revenue as
the revenue as fee
we discuss in section
discuss in section ix
in section ix the
section ix the implications
ix the implications of
the implications of such
implications of such fees
of such fees to
such fees to our
fees to our analysis
many pools are open
pools are open and
are open and accept
open and accept any
and accept any interested
accept any interested miner
a pool interface is
pool interface is typically
interface is typically comprised
is typically comprised of
lightweight elasticity in shared
typically comprised of a
elasticity in shared storage
comprised of a web
in shared storage databases
of a web interface
shared storage databases for
a web interface for
storage databases for the
web interface for registration
databases for the cloud
interface for registration and
for the cloud using
for registration and a
the cloud using live
registration and a miner
cloud using live data
and a miner interface
standard fec schemes can
a miner interface for
using live data migration
fec schemes can be
miner interface for the
schemes can be made
interface for the mining
can be made resistant
for the mining software
be made resistant to
made resistant to a
resistant to a certain
to a certain loss
in order to mine
a certain loss burst
order to mine for
to mine for a
certain loss burst length
mine for a pool
loss burst length at
burst length at the
length at the cost
at the cost of
a miner registers with
the cost of increased
miner registers with the
cost of increased recovery
registers with the web
of increased recovery latency
with the web interface
increased recovery latency for
recovery latency for all
latency for all lost
for all lost packets
supplies a bitcoin address
a bitcoin address to
bitcoin address to receive
including smaller bursts and
address to receive its
smaller bursts and singleton
to receive its future
bursts and singleton drops
receive its future shares
its future shares of
future shares of the
shares of the revenue
and receives from the
layered interleaving provides graceful
receives from the pool
from the pool credentials
interleaving provides graceful degradation
the pool credentials for
pool credentials for mining
provides graceful degradation in
graceful degradation in the
degradation in the face
then he feeds his
in the face of
he feeds his credentials
the face of bursty
feeds his credentials and
face of bursty loss
his credentials and the
of bursty loss for
credentials and the pool
bursty loss for constant
and the pool s
loss for constant encoding
the pool s address
for constant encoding overhead
pool s address to
constant encoding overhead singleton
s address to its
encoding overhead singleton random
address to its mining
overhead singleton random losses
to its mining rig
singleton random losses are
random losses are recovered
losses are recovered as
are recovered as quickly
recovered as quickly as
as quickly as possible
live migration in shared
the mining rig obtains
migration in shared nothing
mining rig obtains its
by xors generated with
rig obtains its tasks
in shared nothing databases
obtains its tasks from
shared nothing databases for
its tasks from the
nothing databases for elastic
tasks from the pool
xors generated with an
databases for elastic cloud
from the pool and
generated with an interleave
the pool and sends
for elastic cloud platforms
with an interleave of
pool and sends partial
and sends partial and
sends partial and full
partial and full proof
and full proof of
full proof of work
and each successive layer
typically with the stratum
each successive layer of
with the stratum protocol
successive layer of xors
layer of xors generated
of xors generated at
xors generated at a
generated at a higher
at a higher interleave
a higher interleave catches
higher interleave catches larger
interleave catches larger bursts
catches larger bursts missed
larger bursts missed by
bursts missed by the
missed by the previous
by the previous layer
as it finds blocks
the implementation of this
implementation of this algorithm
of this algorithm is
this algorithm is simple
the pool manager credits
algorithm is simple and
pool manager credits the
is simple and shown
manager credits the miner
simple and shown in
credits the miner s
and shown in figure
the miner s account
miner s account according
s account according to
account according to its
according to its share
to its share of
its share of the
share of the work
a set of repair
and transfers these funds
set of repair bins
transfers these funds either
of repair bins is
these funds either on
repair bins is maintained
funds either on request
bins is maintained for
either on request or
is maintained for each
on request or automatically
maintained for each layer
request or automatically to
or automatically to the
automatically to the aforementioned
to the aforementioned bitcoin
the aforementioned bitcoin address
with i bins for
i bins for a
bins for a layer
for a layer with
too big pools despite
a layer with interleave
big pools despite their
layer with interleave i
pools despite their important
despite their important role
their important role of
important role of enabling
role of enabling small
a repair bin consists
repair bin consists of
bin consists of a
consists of a partially
of a partially constructed
a partially constructed repair
partially constructed repair packet
pools can constitute a
can constitute a threat
constitute a threat to
an xor and the
a threat to the
xor and the recipe
threat to the bitcoin
and the recipe list
to the bitcoin system
the recipe list of
the bitcoin system if
recipe list of identifiers
bitcoin system if their
list of identifiers of
system if their size
of identifiers of data
if their size is
identifiers of data packets
their size is too
of data packets that
size is too large
data packets that compose
packets that compose the
that compose the xor
if one pool controls
one pool controls the
pool controls the majority
each intercepted data packet
controls the majority of
intercepted data packet is
the majority of mining
data packet is added
majority of mining power
packet is added to
is added to each
added to each layer
to each layer where
the system becomes unstable
each layer where adding
layer where adding to
where adding to a
adding to a layer
to a layer simply
a layer simply means
layer simply means choosing
simply means choosing a
means choosing a repair
choosing a repair bin
a repair bin from
repair bin from the
bin from the layer
from the layer s
the layer s set
incrementally updating the xor
updating the xor with
the xor with the
xor with the new
with the new data
the new data packet
and adding the data
the dangers of replication
adding the data packet
dangers of replication and
the data packet s
of replication and d
data packet s header
packet s header to
s header to the
header to the recipe
to the recipe list
a counter is incremented
counter is incremented as
fast distributed transactions a
warns that the system
is incremented as each
that the system is
incremented as each data
the system is unstable
as each data packet
system is unstable with
each data packet arrives
is unstable with even
data packet arrives at
unstable with even smaller
distributed transactions a solution
packet arrives at the
with even smaller pools
arrives at the appliance
and choosing the repair
choosing the repair bin
the repair bin from
repair bin from the
bin from the layer
in realistic scenarios of
from the layer s
realistic scenarios of the
the layer s set
scenarios of the bitcoin
layer s set is
of the bitcoin system
s set is done
the bitcoin system no
set is done by
bitcoin system no pool
is done by taking
system no pool controls
done by taking the
no pool controls a
by taking the modulo
pool controls a majority
taking the modulo of
controls a majority of
for partitioned database systems
the modulo of the
a majority of the
modulo of the counter
majority of the mining
of the counter with
of the mining power
the counter with the
counter with the number
with the number of
the number of bins
number of bins in
of bins in each
bins in each layer
for one day in
one day in june
for a layer with
a layer with interleave
the xth intercepted packet
a single pool called
xth intercepted packet is
single pool called ghash
intercepted packet is added
packet is added to
is added to the
of the blocks in
the blocks in the
blocks in the bitcoin
in the bitcoin main
the bitcoin main chain
when a repair bin
a repair bin fills
the bitcoin community backlashed
repair bin fills up
bitcoin community backlashed at
bin fills up its
community backlashed at the
fills up its recipe
backlashed at the pool
up its recipe list
its recipe list contains
recipe list contains r
list contains r data
contains r data packets
which has done nothing
r data packets it
distributed main memory transaction
has done nothing worse
data packets it fires
done nothing worse than
main memory transaction processing
nothing worse than being
memory transaction processing system
a repair packet is
worse than being extremely
repair packet is generated
than being extremely successful
packet is generated consisting
is generated consisting of
generated consisting of the
consisting of the xor
of the xor and
the xor and the
xor and the recipe
and the recipe list
the recipe list and
recipe list and is
list and is scheduled
and is scheduled for
io reduced its relative
is scheduled for sending
reduced its relative mining
its relative mining power
relative mining power and
mining power and publicly
while the repair bin
power and publicly committed
the repair bin is
and publicly committed to
repair bin is re
publicly committed to stay
committed to stay away
to stay away from
stay away from the
initialized with an empty
with an empty recipe
an empty recipe list
empty recipe list and
recipe list and blank
list and blank xor
incoming repair packets are
block withholding and its
repair packets are processed
withholding and its detection
packets are processed as
and its detection classical
are processed as follows
its detection classical block
detection classical block withholding
if all the data
all the data packets
the data packets contained
data packets contained in
packets contained in the
contained in the repair
in the repair s
the repair s recipe
repair s recipe list
s recipe list have
recipe list have been
list have been received
is an attack performed
have been received successfully
an attack performed by
attack performed by a
performed by a pool
by a pool member
a pool member against
the repair packet is
pool member against the
repair packet is discarded
member against the other
against the other pool
the other pool members
if the repair s
the repair s recipe
repair s recipe list
the attacking miner registers
s recipe list contains
attacking miner registers with
recipe list contains a
miner registers with the
list contains a single
registers with the pool
contains a single missing
with the pool and
a single missing data
the pool and apparently
single missing data packet
pool and apparently starts
and apparently starts mining
apparently starts mining honestly
starts mining honestly it
recovery can occur immediately
mining honestly it regularly
can occur immediately by
honestly it regularly sends
occur immediately by combining
it regularly sends the
verify replication for multi
immediately by combining the
regularly sends the pool
by combining the xor
sends the pool partial
combining the xor in
the pool partial proof
the xor in the
pool partial proof of
xor in the repair
partial proof of work
in the repair with
the repair with layer
the attacking miner sends
attacking miner sends only
miner sends only partial
sends only partial proof
only partial proof of
partial proof of work
if it finds a
it finds a full
finds a full solution
a full solution that
full solution that constitutes
solution that constitutes a
that constitutes a full
constitutes a full proof
a full proof of
full proof of work
proof of work it
of work it discards
work it discards the
it discards the solution
reducing the pool s
the pool s total
pool s total revenue
this attack is illustrated
attack is illustrated in
is illustrated in figure
the attacker does not
attacker does not change
does not change the
not change the pool
change the pool s
the pool s effective
pool s effective mining
s effective mining power
and does not affect
does not affect directly
not affect directly the
affect directly the revenue
directly the revenue of
the revenue of other
revenue of other pools
the attacked pool shares
attacked pool shares its
pool shares its revenue
shares its revenue with
its revenue with the
revenue with the attacker
therefore each miner earns
each miner earns less
as the same revenue
the same revenue is
same revenue is distributed
revenue is distributed among
is distributed among more
distributed among more miners
recall that the proof
that the proof of
the proof of work
proof of work is
of work is only
work is only valid
is only valid for
only valid for a
valid for a specific
for a specific block
as it is the
it is the nonce
is the nonce with
the nonce with which
nonce with which the
with which the block
which the block s
the block s hash
block s hash is
s hash is smaller
hash is smaller than
is smaller than its
layer with interleave of
smaller than its target
the attacking miner cannot
attacking miner cannot use
miner cannot use it
using time instead of
time instead of timeout
instead of timeout for
of timeout for fault
although the term block
the term block withholding
term block withholding has
block withholding has become
withholding has become canonical
note that the block
that the block is
the block is discarded
block is discarded and
is discarded and never
discarded and never introduced
and never introduced into
never introduced into the
introduced into the system
into the system as
the system as the
system as the name
as the name block
the name block withholding
name block withholding implies
miners miners miners pool
classical block withholding attack
a group of miners
group of miners attack
of miners attack pool
with a block withholding
a block withholding attack
denoted by a dashed
by a dashed red
a dashed red arrow
this attack reduces the
attack reduces the attacker
reduces the attacker s
the attacker s revenue
attacker s revenue compared
s revenue compared to
revenue compared to solo
compared to solo mining
to solo mining or
solo mining or honest
mining or honest pool
or honest pool participation
it suffers from the
suffers from the reduced
from the reduced revenue
the reduced revenue like
reduced revenue like the
revenue like the other
like the other pool
the other pool participants
and its revenue is
its revenue is less
revenue is less than
is less than its
less than its share
than its share of
its share of the
share of the total
of the total mining
the total mining power
total mining power in
mining power in the
power in the system
the classical block withholding
classical block withholding attack
block withholding attack can
withholding attack can therefore
attack can therefore only
can therefore only be
therefore only be used
only be used for
be used for sabotage
at a cost to
a cost to the
cost to the attacker
from paxos to corfu
the other successfully received
other successfully received data
successfully received data packets
even if a pool
if a pool detects
if the repair contains
a pool detects that
the repair contains multiple
pool detects that it
repair contains multiple missing
detects that it is
contains multiple missing data
that it is under
multiple missing data packets
it is under a
is under a block
under a block withholding
a block withholding attack
it cannot be used
cannot be used immediately
it might not be
be used immediately for
might not be able
used immediately for recovery
not be able to
immediately for recovery it
be able to detect
for recovery it is
able to detect which
recovery it is instead
to detect which of
it is instead stored
detect which of its
is instead stored in
which of its registered
instead stored in a
of its registered miners
stored in a table
its registered miners are
in a table that
registered miners are the
a table that maps
miners are the perpetrators
table that maps missing
that maps missing data
maps missing data packets
missing data packets to
data packets to repair
a pool can estimate
packets to repair packets
pool can estimate its
can estimate its expected
estimate its expected mining
whenever a data packet
its expected mining power
a data packet is
expected mining power and
data packet is subsequently
mining power and its
packet is subsequently received
power and its actual
is subsequently received or
and its actual mining
subsequently received or recovered
its actual mining power
actual mining power by
mining power by the
power by the rates
by the rates of
this table is checked
the rates of partial
table is checked to
rates of partial proofs
is checked to see
of partial proofs of
checked to see if
partial proofs of work
to see if any
proofs of work and
see if any xors
of work and full
if any xors now
work and full proofs
any xors now have
and full proofs of
xors now have singleton
full proofs of work
now have singleton losses
have singleton losses due
singleton losses due to
losses due to the
due to the presence
to the presence of
supplied by its miners
the presence of the
presence of the new
of the new packet
the new packet and
a difference above a
new packet and can
difference above a set
packet and can be
above a set confidence
and can be used
a set confidence interval
can be used for
set confidence interval indicates
be used for recovering
concurrency control and availability
confidence interval indicates an
used for recovering other
interval indicates an attack
control and availability in
for recovering other missing
and availability in multi
to detect whether a
recovering other missing packets
detect whether a single
whether a single miner
a single miner is
single miner is attacking
miner is attacking it
the pool must use
xors received from different
pool must use a
received from different layers
must use a similar
from different layers interact
use a similar technique
different layers interact to
layers interact to recover
interact to recover missing
to recover missing data
recover missing data packets
comparing the estimated mining
the estimated mining power
estimated mining power of
mining power of the
since an xor received
power of the attacker
an xor received at
of the attacker based
xor received at a
the attacker based on
received at a higher
attacker based on its
at a higher interleave
based on its partial
a higher interleave can
on its partial proof
higher interleave can recover
its partial proof of
interleave can recover a
partial proof of work
can recover a packet
proof of work with
recover a packet that
of work with the
a packet that makes
work with the fact
packet that makes an
with the fact it
that makes an earlier
the fact it never
makes an earlier xor
fact it never supplies
an earlier xor at
it never supplies a
earlier xor at a
never supplies a full
xor at a lower
supplies a full proof
at a lower interleave
a full proof of
a lower interleave usable
full proof of work
lower interleave usable hence
if the attacker has
the attacker has a
attacker has a small
has a small mining
though layered interleaving is
a small mining power
layered interleaving is equivalent
interleaving is equivalent to
is equivalent to c
equivalent to c different
it will send frequent
will send frequent partial
send frequent partial proofs
frequent partial proofs of
on predictive modeling for
partial proofs of work
predictive modeling for optimizing
modeling for optimizing transaction
for optimizing transaction execution
optimizing transaction execution in
but the pool will
transaction execution in parallel
instances in terms of
execution in parallel oltp
in terms of overhead
the pool will only
in parallel oltp systems
terms of overhead and
pool will only expect
of overhead and design
will only expect to
only expect to see
expect to see a
to see a full
its recovery power is
see a full proof
recovery power is much
a full proof of
power is much higher
full proof of work
is much higher and
proof of work at
much higher and comes
of work at very
higher and comes close
work at very low
and comes close to
at very low frequency
comes close to standard
it cannot obtain statistically
cannot obtain statistically significant
obtain statistically significant results
statistically significant results that
significant results that would
results that would indicate
that would indicate an
would indicate an attack
an attacker can use
attacker can use multiple
can use multiple small
use multiple small block
multiple small block withholding
small block withholding miners
block withholding miners and
withholding miners and replace
miners and replace them
and replace them frequently
a small miner is
a miner whose expected
miner whose expected full
whose expected full proof
scalable deferred update replication
expected full proof of
full proof of work
proof of work frequency
of work frequency is
work frequency is yearly
such a miner will
a miner will see
miner will see a
will see a non
negligible average daily revenue
the case for determinism
case for determinism in
for determinism in database
if the attacker replaces
second set of rsized
the attacker replaces such
determinism in database systems
set of rsized xors
attacker replaces such a
of rsized xors staggered
replaces such a small
rsized xors staggered start
such a small miner
xors staggered start xors
a small miner every
small miner every month
he will collect about
will collect about b
at the end of
the end of each
end of each month
the pool must decide
pool must decide within
must decide within this
decide within this month
within this month whether
this month whether the
month whether the miner
whether the miner is
the miner is an
miner is an attacker
and revoke its earnings
or just an unlucky
just an unlucky honest
an unlucky honest miner
since an honest miner
an honest miner of
honest miner of this
miner of this power
of this power is
this power is unlikely
power is unlikely to
is unlikely to find
unlikely to find a
to find a full
find a full proof
a full proof of
full proof of work
proof of work within
of work within a
work within a month
according to the exponential
to the exponential distribution
a pool that rejects
pool that rejects miners
that rejects miners based
rejects miners based on
miners based on this
based on this criterion
on this criterion would
this criterion would reject
criterion would reject the
would reject the majority
reject the majority of
the majority of its
majority of its honest
of its honest miners
the alternative of rejecting
alternative of rejecting small
of rejecting small miners
rejecting small miners in
small miners in general
miners in general or
in general or distributing
general or distributing revenue
or distributing revenue on
distributing revenue on a
revenue on a yearly
on a yearly basis
a yearly basis contradicts
yearly basis contradicts the
basis contradicts the goal
contradicts the goal of
the goal of pooled
goal of pooled mining
m odel and s
odel and s tandard
and s tandard o
s tandard o peration
tandard o peration we
o peration we specify
peration we specify the
we specify the basic
specify the basic model
the basic model in
basic model in which
model in which participants
in which participants operate
which participants operate in
participants operate in section
operate in section iii
proceed to describe how
to describe how honest
describe how honest miners
how honest miners operate
honest miners operate in
miners operate in this
operate in this environment
in this environment in
this environment in sections
environment in sections iii
and how the classical
how the classical block
the classical block withholding
classical block withholding attack
block withholding attack is
withholding attack is implemented
attack is implemented with
is implemented with our
implemented with our model
with our model in
our model in section
model in section iii
model the system is
the system is comprised
system is comprised of
is comprised of the
comprised of the bitcoin
of the bitcoin network
the bitcoin network and
bitcoin network and nodes
network and nodes with
and nodes with unique
nodes with unique ids
and progresses in steps
a node i generates
node i generates tasks
i generates tasks which
generates tasks which are
tasks which are associated
which are associated with
are associated with its
associated with its id
with its id i
a node can work
node can work on
can work on a
work on a task
on a task for
a task for the
task for the duration
for the duration of
the duration of a
duration of a step
the result of this
result of this work
of this work is
this work is a
work is a set
is a set of
a set of partial
set of partial proofs
of partial proofs of
partial proofs of work
proofs of work and
of work and a
work and a set
and a set of
a set of full
set of full proofs
of full proofs of
full proofs of work
the number of proofs
number of proofs in
of proofs in each
proofs in each set
in each set has
each set has a
set has a poisson
has a poisson distribution
partial proofs with a
proofs with a large
with a large mean
a large mean and
large mean and full
mean and full proofs
and full proofs with
full proofs with a
proofs with a small
with a small mean
nodes that work on
that work on tasks
work on tasks are
on tasks are called
tasks are called a
are called a miners
miners have identical power
and hence identical probabilities
hence identical probabilities to
identical probabilities to generate
probabilities to generate proofs
to generate proofs of
generate proofs of work
the bitcoin network pays
bitcoin network pays for
network pays for full
pays for full proofs
for full proofs of
full proofs of work
to acquire this payoff
acquire this payoff an
this payoff an entity
payoff an entity publishes
an entity publishes a
entity publishes a task
publishes a task task
a task task and
task task and its
task and its corresponding
and its corresponding proof
its corresponding proof of
corresponding proof of work
proof of work to
of work to the
work to the network
the payoff goes to
payoff goes to the
goes to the id
to the id associated
the id associated with
id associated with task
the bitcoin protocol normalizes
bitcoin protocol normalizes revenue
protocol normalizes revenue such
normalizes revenue such that
revenue such that the
such that the average
that the average total
the average total revenue
average total revenue distributed
total revenue distributed in
revenue distributed in each
distributed in each step
in each step is
each step is a
step is a constant
is a constant throughout
a constant throughout the
constant throughout the execution
throughout the execution of
the execution of the
execution of the system
any node can transact
node can transact bitcoins
can transact bitcoins to
transact bitcoins to another
bitcoins to another node
to another node by
another node by issuing
node by issuing a
by issuing a bitcoin
issuing a bitcoin transaction
nodes that generate tasks
that generate tasks but
generate tasks but outsource
tasks but outsource the
but outsource the work
outsource the work are
the work are called
work are called pools
pools send tasks to
send tasks to miners
tasks to miners over
to miners over the
miners over the network
the miners receive the
miners receive the tasks
and send the partial
send the partial and
the partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work to
of work to the
work to the pool
apart from working on
from working on tasks
and receipt are instantaneous
we assume that the
assume that the number
that the number of
the number of miners
number of miners is
of miners is large
miners is large enough
is large enough such
large enough such that
enough such that mining
such that mining power
that mining power can
mining power can be
power can be split
can be split arbitrarily
be split arbitrarily without
split arbitrarily without resolution
arbitrarily without resolution constraints
denote the number of
the number of pools
number of pools with
of pools with p
the total number of
total number of mining
number of mining power
of mining power in
mining power in the
power in the system
in the system with
the system with m
system with m and
with m and the
m and the miners
and the miners participating
the miners participating in
miners participating in pool
participating in pool i
we use a quasistatic
use a quasistatic analysis
a quasistatic analysis where
quasistatic analysis where miner
analysis where miner participation
where miner participation in
miner participation in a
participation in a pool
in a pool does
a pool does not
pool does not change
does not change over
not change over time
solo mining a solo
mining a solo miner
a solo miner is
solo miner is a
miner is a node
is a node that
a node that generates
node that generates its
that generates its own
generates its own tasks
in every step it
every step it generates
step it generates a
it generates a task
works on it for
on it for the
it for the duration
for the duration of
the duration of the
duration of the step
of the step and
the step and if
step and if it
and if it finds
if it finds a
it finds a full
finds a full proof
a full proof of
full proof of work
it publishes this proof
publishes this proof of
this proof of work
proof of work to
of work to earn
work to earn the
to earn the payoff
pools a pool is
a pool is a
pool is a node
is a node that
a node that serves
node that serves as
that serves as a
serves as a coordinator
as a coordinator and
a coordinator and multiple
coordinator and multiple miners
and multiple miners can
multiple miners can register
miners can register to
can register to a
register to a pool
to a pool and
a pool and work
pool and work for
and work for it
in every step it
every step it generates
step it generates a
it generates a task
generates a task for
a task for each
task for each registered
for each registered miner
each registered miner and
registered miner and sends
miner and sends it
and sends it over
sends it over the
it over the network
each miner receives its
miner receives its task
receives its task and
its task and works
task and works on
comparison of packet recovery
and works on it
of packet recovery probability
works on it for
on it for the
it for the duration
for the duration of
the duration of the
duration of the step
at the end of
the end of the
end of the step
the miner sends the
miner sends the pool
sends the pool the
the pool the full
pool the full and
the full and the
full and the partial
and the partial proofs
the partial proofs of
partial proofs of work
proofs of work it
of work it has
work it has found
the pool receives the
pool receives the proofs
receives the proofs of
the proofs of work
proofs of work of
of work of all
work of all its
of all its miners
registers the partial proofs
optimizations staggered start for
the partial proofs of
staggered start for rate
partial proofs of work
proofs of work and
of work and publishes
work and publishes the
and publishes the full
limiting in the naive
publishes the full proofs
in the naive implementation
the naive implementation of
naive implementation of the
implementation of the layered
of the layered interleaving
it calculates its overall
the layered interleaving algorithm
calculates its overall revenue
repair packets are transmitted
and proceeds to distribute
packets are transmitted as
proceeds to distribute it
are transmitted as soon
to distribute it among
transmitted as soon as
distribute it among its
as soon as repair
it among its miners
soon as repair bins
as repair bins fill
repair bins fill and
bins fill and allow
fill and allow them
each miner receives revenue
and allow them to
miner receives revenue proportional
allow them to be
receives revenue proportional to
them to be constructed
revenue proportional to its
proportional to its success
to its success in
its success in the
success in the current
in the current step
all the repair bins
the repair bins in
namely the ratio of
repair bins in a
the ratio of its
bins in a layer
ratio of its partial
in a layer fill
of its partial proofs
a layer fill in
its partial proofs of
layer fill in quick
partial proofs of work
fill in quick succession
proofs of work out
of work out of
work out of all
out of all partial
of all partial proofs
all partial proofs of
partial proofs of work
proofs of work the
of work the pool
work the pool received
the arrival of packets
we assume that pools
assume that pools do
that pools do not
pools do not collect
do not collect fees
not collect fees of
collect fees of the
fees of the revenue
pool fees and their
fees and their implications
and their implications on
their implications on our
implications on our analysis
on our analysis are
our analysis are discussed
analysis are discussed in
are discussed in section
discussed in section ix
block withholding miner a
withholding miner a miner
miner a miner registered
a miner registered at
will successively fill the
miner registered at a
successively fill the four
registered at a pool
fill the four repair
at a pool can
the four repair bins
a pool can perform
four repair bins in
pool can perform the
repair bins in layer
can perform the classical
perform the classical block
the classical block withholding
classical block withholding attack
an attacker miner operates
this behavior leads to
attacker miner operates as
behavior leads to a
miner operates as if
leads to a large
operates as if it
to a large number
as if it worked
a large number of
if it worked for
large number of repair
it worked for the
number of repair packets
worked for the pool
of repair packets being
repair packets being generated
packets being generated and
being generated and sent
it receives its tasks
generated and sent within
receives its tasks and
and sent within a
its tasks and works
sent within a short
tasks and works on
within a short period
and works on them
a short period of
short period of time
only at the end
at the end of
which results in undesirable
the end of each
results in undesirable overhead
end of each round
in undesirable overhead and
of each round it
undesirable overhead and traffic
each round it sends
overhead and traffic spikes
round it sends only
it sends only its
sends only its partial
only its partial proofs
its partial proofs of
partial proofs of work
we would like to
would like to rate
and omits full proofs
omits full proofs of
full proofs of work
proofs of work if
of work if it
limit transmissions of repair
work if it had
transmissions of repair packets
if it had found
of repair packets to
it had found any
repair packets to one
packets to one for
to one for every
one for every r
for every r data
the pool registers the
every r data packets
pool registers the miner
registers the miner s
the miner s partial
miner s partial proofs
this problem is fixed
problem is fixed by
is fixed by staggering
but cannot distinguish between
fixed by staggering the
cannot distinguish between miners
by staggering the starting
distinguish between miners running
staggering the starting sizes
between miners running honestly
the starting sizes of
miners running honestly and
starting sizes of the
running honestly and block
sizes of the bins
honestly and block withholding
and block withholding miners
analogous to the starting
to the starting positions
the implications are that
the starting positions of
implications are that a
starting positions of runners
are that a miner
positions of runners in
that a miner that
of runners in a
a miner that engages
runners in a sprint
miner that engages in
that engages in block
engages in block withholding
in block withholding does
the very first time
block withholding does not
very first time bin
withholding does not contribute
first time bin number
does not contribute to
time bin number x
not contribute to the
bin number x in
contribute to the pool
number x in a
to the pool s
x in a layer
the pool s overall
in a layer of
pool s overall mining
a layer of interleave
s overall mining power
layer of interleave i
of interleave i fires
but still shares the
it does so at
still shares the pool
does so at size
shares the pool s
so at size x
the pool s revenue
at size x mod
pool s revenue according
size x mod r
s revenue according to
revenue according to its
according to its sent
to its sent partial
its sent partial proofs
sent partial proofs of
partial proofs of work
to reason about a
reason about a pool
about a pool s
a pool s efficiency
pool s efficiency we
the first repair bin
s efficiency we define
first repair bin in
efficiency we define its
repair bin in the
we define its per
bin in the second
in the second layer
the second layer with
second layer with interleave
miner revenue as follows
would fire at size
the second would fire
second would fire at
would fire at size
the revenue density of
revenue density of a
density of a pool
of a pool is
a pool is the
pool is the ratio
is the ratio between
for the first i
the ratio between the
the first i data
ratio between the average
first i data packets
between the average revenue
i data packets added
the average revenue a
data packets added to
average revenue a pool
packets added to a
revenue a pool member
added to a layer
a pool member earns
to a layer with
pool member earns and
a layer with interleave
member earns and the
layer with interleave i
earns and the average
and the average revenue
the average revenue it
average revenue it would
revenue it would have
it would have earned
would have earned as
have earned as a
r fire immediately with
earned as a solo
fire immediately with just
as a solo miner
immediately with just one
with just one packet
just one packet in
one packet in them
the revenue density of
revenue density of a
density of a solo
of a solo miner
for the next i
the next i data
next i data packets
i data packets added
and that of a
that of a miner
of a miner working
a miner working with
miner working with an
working with an unattacked
with an unattacked pool
an unattacked pool are
r fire immediately with
unattacked pool are one
fire immediately with two
immediately with two data
with two data packets
two data packets in
data packets in them
if a pool is
a pool is attacked
pool is attacked with
is attacked with block
attacked with block withholding
and so on until
so on until r
on until r i
its revenue density decreases
until r i data
r i data packets
i data packets have
data packets have been
packets have been added
have been added to
been added to the
continuous analysis because our
added to the layer
analysis because our analysis
to the layer and
because our analysis will
the layer and all
our analysis will be
layer and all bins
analysis will be of
and all bins have
will be of the
all bins have fired
be of the average
bins have fired exactly
of the average revenue
have fired exactly once
we will consider proofs
will consider proofs of
consider proofs of work
all bins fire at
bins fire at size
fire at size r
both full and partial
as continuous deterministic sizes
now that they have
that they have been
they have been staggered
according to their probability
have been staggered at
been staggered at the
staggered at the start
work on a task
on a task therefore
a task therefore results
task therefore results in
therefore results in a
r fire for any
results in a deterministic
fire for any i
in a deterministic fraction
for any i data
a deterministic fraction of
any i data packets
deterministic fraction of proof
fraction of proof of
of proof of work
the outlined scheme works
outlined scheme works when
scheme works when i
works when i is
when i is greater
i is greater than
t he p ool
is greater than or
he p ool g
greater than or equal
p ool g ame
than or equal to
ool g ame a
or equal to r
the pool block withholding
as is usually the
pool block withholding attack
is usually the case
block withholding attack just
withholding attack just as
attack just as a
just as a miner
if i is smaller
as a miner can
i is smaller than
a miner can perform
is smaller than r
miner can perform block
can perform block withholding
perform block withholding on
block withholding on a
withholding on a pool
the bin with index
on a pool j
bin with index x
with index x fires
index x fires at
a pool i can
pool i can use
i can use some
can use some of
use some of its
some of its mining
of its mining power
its mining power to
mining power to infiltrate
power to infiltrate a
to infiltrate a pool
infiltrate a pool j
a pool j and
pool j and perform
j and perform a
and perform a block
perform a block withholding
a block withholding attack
block withholding attack on
withholding attack on j
denote the amount of
the amount of such
amount of such infiltrating
of such infiltrating mining
such infiltrating mining power
infiltrating mining power at
mining power at step
the initial firing sizes
power at step t
initial firing sizes would
at step t by
firing sizes would be
step t by xi
for the first bin
the first bin and
for the second bin
if r and i
r and i are
miners working for pool
and i are not
working for pool i
i are not integral
are not integral multiples
not integral multiples of
integral multiples of each
multiples of each other
either mining honestly or
mining honestly or used
honestly or used for
or used for infiltrating
used for infiltrating pool
for infiltrating pool j
limiting still works but
still works but is
are loyal to pool
works but is slightly
loyal to pool i
but is slightly less
is slightly less effective
slightly less effective due
less effective due to
effective due to rounding
at the end of
due to rounding errors
the end of a
end of a round
delaying xors in the
xors in the naive
pool i aggregates its
in the naive implementation
i aggregates its revenue
aggregates its revenue from
its revenue from mining
revenue from mining in
repair packets are transmitted
from mining in the
packets are transmitted as
mining in the current
are transmitted as soon
in the current round
transmitted as soon as
the current round and
as soon as they
current round and from
soon as they are
round and from its
as they are generated
and from its infiltration
from its infiltration in
its infiltration in the
infiltration in the previous
in the previous round
this results in the
results in the repair
in the repair packet
the repair packet leaving
it distributes the revenue
repair packet leaving immediately
distributes the revenue evenly
packet leaving immediately after
the revenue evenly among
leaving immediately after the
revenue evenly among all
immediately after the last
evenly among all its
after the last data
among all its loyal
the last data packet
all its loyal miners
last data packet that
its loyal miners according
data packet that was
loyal miners according to
packet that was added
miners according to their
that was added to
according to their partial
was added to it
to their partial proofs
their partial proofs of
partial proofs of work
which lowers burst tolerance
lowers burst tolerance if
burst tolerance if the
the pool s miners
tolerance if the repair
pool s miners are
if the repair packet
s miners are oblivious
the repair packet was
miners are oblivious to
repair packet was generated
are oblivious to their
packet was generated at
oblivious to their role
was generated at interleave
to their role and
generated at interleave i
their role and they
role and they operate
and they operate as
they operate as regular
operate as regular honest
the resulting protocol can
as regular honest miners
resulting protocol can tolerate
protocol can tolerate a
can tolerate a burst
tolerate a burst of
a burst of i
burst of i lost
of i lost data
i lost data packets
lost data packets excluding
data packets excluding the
packets excluding the repair
but the burst could
the burst could swallow
burst could swallow both
could swallow both the
swallow both the repair
revenue convergence note that
both the repair and
convergence note that pool
the repair and the
note that pool j
repair and the last
that pool j sends
and the last data
pool j sends its
the last data packet
j sends its revenue
last data packet in
sends its revenue to
data packet in it
its revenue to infiltrators
packet in it as
revenue to infiltrators from
in it as they
to infiltrators from pool
it as they are
infiltrators from pool i
as they are not
from pool i at
they are not separated
pool i at the
are not separated by
i at the end
not separated by the
at the end of
separated by the requisite
the end of the
by the requisite interleave
end of the step
the solution to this
and this revenue is
solution to this is
this revenue is calculated
to this is simple
revenue is calculated in
this is simple delay
is calculated in pool
is simple delay sending
calculated in pool i
simple delay sending the
in pool i at
delay sending the repair
pool i at the
sending the repair packet
i at the beginning
the repair packet generated
at the beginning of
repair packet generated by
the beginning of the
packet generated by a
beginning of the subsequent
generated by a repair
of the subsequent step
by a repair bin
a repair bin until
repair bin until the
bin until the next
if there is a
until the next time
there is a chain
the next time a
is a chain of
next time a data
a chain of pools
time a data packet
a data packet is
data packet is added
packet is added to
is added to the
added to the now
to the now empty
the now empty bin
which happens i packets
happens i packets later
i packets later and
packets later and introduces
later and introduces the
and introduces the required
introduces the required interleave
the required interleave between
required interleave between the
interleave between the repair
between the repair packet
the repair packet and
repair packet and the
packet and the last
where each pool infiltrates
and the last data
each pool infiltrates the
the last data packet
pool infiltrates the previous
last data packet included
infiltrates the previous one
data packet included in
packet included in it
the pool revenue will
pool revenue will not
revenue will not be
notice that although transmitting
will not be static
that although transmitting the
although transmitting the xor
transmitting the xor immediately
the xor immediately results
since the revenue from
xor immediately results in
the revenue from infiltration
immediately results in faster
revenue from infiltration takes
results in faster recovery
from infiltration takes one
infiltration takes one step
takes one step to
one step to take
step to take each
doing so also reduces
to take each hop
so also reduces the
also reduces the probability
reduces the probability of
the probability of a
from the first step
probability of a lost
of a lost packet
a lost packet being
lost packet being recovered
the revenue of pool
off results in a
since it is only
results in a minor
it is only infiltrated
in a minor control
is only infiltrated and
a minor control knob
only infiltrated and loses
minor control knob permitting
infiltrated and loses some
control knob permitting us
and loses some of
knob permitting us to
loses some of its
permitting us to balance
some of its revenue
us to balance speed
of its revenue for
to balance speed against
its revenue for pool
balance speed against burst
speed against burst tolerance
our default configuration is
default configuration is to
starting from the second
configuration is to transmit
from the second step
is to transmit the
to transmit the xor
transmit the xor immediately
the revenue of pool
comprised of its own
of its own mining
its own mining and
own mining and its
mining and its revenue
and its revenue from
its revenue from the
revenue from the infiltration
from the infiltration of
the infiltration of pool
envelope analysis to start
analysis to start with
with some revenue lost
some revenue lost due
revenue lost due to
lost due to its
we note that no
due to its infiltration
note that no two
to its infiltration by
that no two repair
its infiltration by pool
no two repair packets
two repair packets generated
repair packets generated at
packets generated at different
generated at different interleaves
at different interleaves i
starting from the third
from the third step
the revenue of pool
max is the longest
is the longest chain
the longest chain in
will have more than
longest chain in the
have more than one
chain in the system
more than one data
than one data packet
one data packet in
data packet in common
the revenue stabilizes after
packet in common as
in common as long
common as long as
as long as the
long as the least
as the least common
the least common multiple
if there are loops
there are loops in
are loops in the
loops in the infiltration
in the infiltration graph
of the interleaves is
the interleaves is greater
the system will converge
interleaves is greater than
system will converge to
is greater than r
will converge to a
greater than r i
converge to a certain
to a certain revenue
as stated in the
stated in the following
in the following lemma
pairings of repair bins
of repair bins in
repair bins in two
bins in two different
in two different layers
two different layers with
different layers with interleaves
layers with interleaves i
if infiltration rates are
infiltration rates are constant
the pool revenues converge
pool revenues converge to
revenues converge to a
converge to a limit
to a limit as
a limit as time
limit as time progresses
denote the revenue density
the revenue density of
revenue density of pool
a good rule of
density of pool i
good rule of thumb
of pool i at
rule of thumb is
pool i at the
of thumb is to
i at the end
thumb is to select
at the end of
is to select interleaves
the end of step
to select interleaves that
end of step t
select interleaves that are
of step t by
interleaves that are relatively
step t by ri
that are relatively prime
are relatively prime to
relatively prime to maximize
prime to maximize their
to maximize their lcm
and also ensure that
also ensure that the
and define the revenue
ensure that the larger
define the revenue density
that the larger interleave
the revenue density vector
the larger interleave is
revenue density vector r
larger interleave is greater
interleave is greater than
is greater than r
let us assume that
us assume that packets
assume that packets are
that packets are dropped
packets are dropped with
are dropped with uniform
given a lost data
a lost data packet
what is the probability
is the probability that
the probability that we
probability that we can
that we can recover
we can recover it
we can recover a
can recover a data
recover a data packet
a data packet if
data packet if at
packet if at least
if at least one
at least one of
least one of the
one of the c
of the c xors
the c xors containing
c xors containing it
xors containing it is
containing it is re
the revenues at all
revenues at all pools
at all pools converge
all pools converge as
local recovery for receiver
pools converge as follows
recovery for receiver loss
for receiver loss ceived
receiver loss ceived correctly
loss ceived correctly and
ceived correctly and usable
all the other data
the other data packets
other data packets in
data packets in it
packets in it have
in it have also
it have also been
have also been received
also been received correctly
the probability of in
probability of in the
of in the absence
in the absence of
the absence of intelligent
absence of intelligent flow
of intelligent flow control
intelligent flow control mechanisms
flow control mechanisms like
control mechanisms like which
mechanisms like which is
like which is simply
the probability of a
probability of a received
of a received tcp
p in every round
inexpensive xor being unusable
pool i uses its
xor being unusable is
i uses its mining
being unusable is the
uses its mining power
unusable is the complement
its mining power of
mining power of m
j used for direct
used for direct mining
for direct mining p
and shares it among
shares it among its
it among its m
hosts can be easily
can be easily overwhelmed
be easily overwhelmed and
easily overwhelmed and drop
overwhelmed and drop packets
and drop packets during
drop packets during traffic
packets during traffic spikes
during traffic spikes or
traffic spikes or cpu
all sums are over
sums are over the
are over the range
the probability x of
probability x of a
x of a sent
of a sent xor
a sent xor being
sent xor being nance
xor being nance tasks
being nance tasks like
nance tasks like garbage
tasks like garbage collection
reliable applicationdropped or unusable
applicationdropped or unusable is
or unusable is the
unusable is the sum
is the sum of
the sum of the
sum of the probability
of the probability that
the probability that it
denote the direct mining
probability that it level
the direct mining revenue
that it level protocols
direct mining revenue density
it level protocols layered
mining revenue density of
level protocols layered over
revenue density of each
protocols layered over udp
density of each pool
layered over udp for
over udp for reliable
udp for reliable multiwas
for reliable multiwas dropped
reliable multiwas dropped and
multiwas dropped and the
dropped and the probability
which is a constant
and the probability that
is a constant factor
the probability that it
probability that it was
that it was received
it was received and
was received and cast
or high speed data
high speed data transfer
the pool game in
pool game in the
game in the pool
in the pool game
the pool game pools
pool game pools try
game pools try to
pools try to optimize
try to optimize their
to optimize their infiltration
optimize their infiltration rates
their infiltration rates of
infiltration rates of other
rates of other pools
of other pools to
other pools to maximize
pools to maximize their
to maximize their revenue
the overall number of
overall number of miners
number of miners and
of miners and the
miners and the number
and the number of
the number of miners
number of miners loyal
of miners loyal to
miners loyal to each
loyal to each pool
to each pool remain
each pool remain constant
would ordinarily go back
pool remain constant throughout
ordinarily go back to
remain constant throughout the
go back to the
constant throughout the game
back to the sender
to the sender to
the sender to retrieve
sender to retrieve the
to retrieve the lost
time progresses in rounds
retrieve the lost packet
let s be a
even though it was
s be a constant
though it was dropped
be a constant integer
it was dropped at
a constant integer large
was dropped at the
constant integer large enough
dropped at the receiver
integer large enough that
at the receiver after
large enough that revenue
the receiver after since
enough that revenue can
receiver after since it
that revenue can be
after since it is
revenue can be approximated
since it is easy
can be approximated as
it is easy to
be approximated as its
is easy to ensure
approximated as its convergence
easy to ensure that
as its convergence limit
to ensure that no
ensure that no two
that no two xors
no two xors share
two xors share covering
in each round the
xors share covering the
each round the system
share covering the entire
round the system takes
covering the entire geographical
the system takes s
the entire geographical distance
system takes s steps
takes s steps and
s steps and then
steps and then a
and then a single
more than one data
then a single pool
than one data packet
picked with a round
the usability probabilities of
usability probabilities of the
probabilities of the maelstrom
of the maelstrom proxy
the maelstrom proxy acts
maelstrom proxy acts as
proxy acts as a
acts as a local
may change its infiltration
as a local packet
change its infiltration rates
a local packet cache
its infiltration rates of
infiltration rates of all
rates of all other
of all other pools
stordifferent xors are independent
the total revenue of
total revenue of each
revenue of each step
the probability of all
of each step is
probability of all ing
each step is normalized
of all ing incoming
step is normalized to
all ing incoming packets
ing incoming packets for
incoming packets for a
packets for a short
for a short period
a short period of
short period of time
period of time and
of time and prothe
so the revenue per
time and prothe c
the revenue per round
and prothe c xors
revenue per round is
prothe c xors being
per round is one
c xors being dropped
xors being dropped or
being dropped or unusable
dropped or unusable is
or unusable is xc
the pool taking a
pool taking a step
taking a step knows
a step knows the
step knows the rate
knows the rate of
the rate of infiltrators
rate of infiltrators attacking
of infiltrators attacking it
viding hooks that allow
hooks that allow protocols
that allow protocols to
though not their identity
allow protocols to first
protocols to first query
to first query the
and the revenue rates
first query the cache
the revenue rates of
revenue rates of each
query the cache the
rates of each of
of each of the
the cache the probability
each of the other
cache the probability of
of the other pools
the probability of correctly
probability of correctly receiving
of correctly receiving at
correctly receiving at least
this knowledge is required
receiving at least one
knowledge is required to
at least one usable
is required to optimize
least one usable to
required to optimize a
one usable to locate
to optimize a pool
usable to locate missing
optimize a pool s
to locate missing packets
a pool s revenue
locate missing packets before
missing packets before sending
packets before sending retransmission
before sending retransmission xor
sending retransmission xor is
as we see next
we explain in section
explain in section viii
in section viii how
section viii how a
viii how a pool
how a pool can
a pool can technically
pool can technically obtain
can technically obtain this
the probability of recovrequests
technically obtain this knowledge
probability of recovrequests back
of recovrequests back to
recovrequests back to the
back to the sender
general analysis recall that
future versions of maelstrom
analysis recall that mi
versions of maelstrom ering
recall that mi is
of maelstrom ering the
that mi is the
maelstrom ering the lost
mi is the number
ering the lost data
is the number of
the lost data packet
the number of miners
lost data packet is
number of miners loyal
of miners loyal to
miners loyal to pool
loyal to pool i
which expands to could
expands to could potentially
to could potentially use
could potentially use knowledge
potentially use knowledge of
use knowledge of protocol
knowledge of protocol internals
of protocol internals to
is the number of
the number of miners
number of miners used
of miners used by
miners used by pool
used by pool i
by pool i to
pool i to infiltrate
i to infiltrate pool
to infiltrate pool j
infiltrate pool j at
pool j at step
j at step t
the mining rate of
mining rate of pool
rate of pool i
of pool i is
pool i is therefore
i is therefore the
is therefore the number
therefore the number of
the number of its
number of its loyal
of its loyal miners
its loyal miners minus
loyal miners minus the
miners minus the miners
by intercepting and this
minus the miners it
intercepting and this closed
the miners it uses
miners it uses for
it uses for infiltration
form formula only gives
formula only gives us
only gives us a
gives us a lower
this effective mining rate
us a lower bound
effective mining rate is
a lower bound satisfying
mining rate is divided
lower bound satisfying retransmission
rate is divided by
bound satisfying retransmission requests
is divided by the
satisfying retransmission requests sent
divided by the total
retransmission requests sent by
by the total mining
requests sent by the
the total mining rate
sent by the receiver
total mining rate in
by the receiver in
mining rate in the
the receiver in on
rate in the system
receiver in on the
in on the recovery
on the recovery probability
namely the number of
the number of all
since the xor usability
number of all miners
the xor usability for
of all miners that
all miners that do
miners that do not
that do not engage
do not engage in
not engage in block
engage in block withholding
or by resending packets
by resending packets when
denote the direct mining
resending packets when acmula
the direct mining rate
packets when acmula does
direct mining rate of
when acmula does not
mining rate of pool
acmula does not factor
rate of pool i
does not factor in
of pool i at
not factor in the
pool i at step
factor in the probability
i at step t
in the probability of
at step t by
the probability of the
step t by pp
probability of the other
t by pp mi
of the other data
by pp mi j
the other data knowledgments
other data knowledgments are
data knowledgments are not
knowledgments are not observed
are not observed within
not observed within a
observed within a certain
within a certain time
a certain time period
certain time period in
time period in an
period in an ack
packets in the xor
in the xor being
the xor being dropped
xor being dropped and
being dropped and recovered
we extend the analysis
extend the analysis to
the analysis to bursty
analysis to bursty losses
k the revenue of
the revenue of pool
if the lost data
revenue of pool i
the lost data packet
of pool i in
lost data packet was
pool i in step
data packet was part
i in step t
packet was part of
in step t taken
was part of a
step t taken through
part of a loss
t taken through infiltration
of a loss burst
taken through infiltration from
a loss burst of
through infiltration from pool
loss burst of size
infiltration from pool j
burst of size b
from pool j s
pool j s revenue
j s revenue in
s revenue in step
revenue in step t
repair packets generated at
packets generated at interleaves
generated at interleaves less
at interleaves less than
interleaves less than b
less than b are
than b are dropped
b are dropped or
are dropped or useless
dropped or useless with
or useless with high
useless with high probability
and we can discount
we can discount them
pool i distributes this
i distributes this revenue
distributes this revenue among
this revenue among its
probability of recovering the
revenue among its mi
of recovering the data
recovering the data packet
the data packet is
data packet is then
i members loyal and
members loyal and infiltrators
define the p p
is the number of
the p p infiltration
the number of xors
p p infiltration matrix
number of xors generated
p infiltration matrix by
of xors generated at
infiltration matrix by its
xors generated at interleaves
matrix by its i
generated at interleaves greater
at interleaves greater than
interleaves greater than b
the formulae derived for
formulae derived for xor
derived for xor usability
for xor usability still
xor usability still hold
since packet losses with
packet losses with more
losses with more than
with more than b
more than b intervening
than b intervening packets
b intervening packets between
i ij the revenue
intervening packets between them
packets between them have
ij the revenue density
between them have independent
the revenue density of
them have independent probability
revenue density of pool
density of pool i
of pool i at
pool i at the
there is only correlation
i at the end
is only correlation within
at the end of
only correlation within the
the end of step
correlation within the bursts
end of step t
of step t is
step t is its
t is its revenue
is its revenue from
its revenue from direct
revenue from direct mining
how does this compare
from direct mining together
does this compare to
direct mining together with
this compare to traditional
mining together with its
together with its revenue
with its revenue from
its revenue from infiltrated
revenue from infiltrated pools
divided by the number
by the number of
codes such as reed
the number of its
number of its loyal
of its loyal miners
its loyal miners together
loyal miners together with
miners together with block
withholding infiltrators that attack
infiltrators that attack it
c repair packets are
repair packets are generated
packets are generated and
are generated and sent
generated and sent for
and sent for every
sent for every r
for every r data
every r data packets
and the correct delivery
the correct delivery of
correct delivery of any
delivery of any r
of any r of
any r of the
r of the r
c packets transmitted is
packets transmitted is sufficient
transmitted is sufficient to
is sufficient to reconstruct
sufficient to reconstruct the
to reconstruct the original
reconstruct the original r
the original r data
original r data packets
given a lost data
a lost data packet
we can recover it
can recover it if
recover it if at
it if at least
if at least r
at least r packets
least r packets are
r packets are received
packets are received correctly
are received correctly in
received correctly in the
correctly in the encoding
in the encoding set
the encoding set of
encoding set of r
c data and repair
and the revenue vector
data and repair packets
the revenue vector at
and repair packets that
revenue vector at step
repair packets that the
vector at step t
packets that the lost
at step t is
that the lost packet
step t is hereinafter
the lost packet belongs
t is hereinafter we
lost packet belongs to
is hereinafter we move
hereinafter we move to
we move to a
move to a static
to a static state
a static state analysis
static state analysis and
state analysis and omit
the probability of recovering
analysis and omit the
probability of recovering a
and omit the t
of recovering a lost
omit the t argument
recovering a lost packet
the t argument in
a lost packet is
t argument in the
lost packet is equivalent
argument in the expressions
packet is equivalent to
is equivalent to the
equivalent to the probability
to the probability of
the probability of losing
probability of losing c
or less packets from
less packets from the
packets from the total
from the total r
since the number of
the number of other
number of other lost
of other lost packets
other lost packets in
lost packets in the
packets in the xor
in the xor is
the xor is a
xor is a random
is a random variable
a random variable y
random variable y and
variable y and has
y and has a
and has a binomial
has a binomial distribution
a binomial distribution with
binomial distribution with parameters
since the row sums
the row sums of
row sums of the
sums of the infiltration
of the infiltration matrix
the infiltration matrix are
infiltration matrix are smaller
matrix are smaller than
are smaller than one
its largest eigenvalue is
largest eigenvalue is smaller
eigenvalue is smaller than
recall that difficulty is
that difficulty is only
difficulty is only adjusted
is only adjusted periodically
is the summation z
the summation z c
and there are transient
there are transient effects
are transient effects that
transient effects that are
effects that are not
that are not covered
are not covered by
not covered by this
covered by this stable
we discuss this in
discuss this in section
this in section viii
miners miners miners the
miners miners the revenue
miners the revenue its
we plot the recovery
the revenue its infiltrators
plot the recovery probability
revenue its infiltrators obtained
the recovery probability curves
its infiltrators obtained from
recovery probability curves for
infiltrators obtained from pool
probability curves for layered
curves for layered interleaving
for layered interleaving and
layered interleaving and reed
solomon against uniformly random
against uniformly random loss
uniformly random loss rate
the revenue per loyal
revenue per loyal pool
miner is therefore r
note that the curves
that the curves are
the curves are very
curves are very close
are very close to
very close to each
close to each other
especially in the loss
in the loss range
the loss range of
loss range of interest
range of interest between
controls its infiltration rate
its infiltration rate of
infiltration rate of pool
and will choose the
will choose the value
choose the value that
implementation details we initially
the value that maximizes
details we initially implemented
value that maximizes the
we initially implemented and
that maximizes the revenue
initially implemented and evaluated
maximizes the revenue density
implemented and evaluated maelstrom
and evaluated maelstrom as
evaluated maelstrom as a
maelstrom as a user
performance turned out to
turned out to be
out to be limited
to be limited by
on the first round
be limited by copying
the first round of
limited by copying and
first round of the
by copying and context
round of the pool
of the pool game
the value of r
and we subsequently reimplemented
we subsequently reimplemented the
is maximized at a
subsequently reimplemented the system
maximized at a single
reimplemented the system as
at a single point
the system as a
a single point in
system as a module
single point in the
as a module that
point in the feasible
a module that runs
in the feasible range
module that runs within
that runs within the
runs within the linux
cannot not react to
not react to pool
at an encoding rate
an encoding rate of
this point is the
point is the stable
is the stable state
the stable state of
stable state of the
state of the system
and we denote the
we denote the value
denote the value of
the value of x
the experimental prototype of
experimental prototype of the
prototype of the kernel
of the kernel version
the kernel version reaches
kernel version reaches output
version reaches output speeds
reaches output speeds close
output speeds close to
gigabit per second of
per second of combined
second of combined data
of combined data and
combined data and fec
data and fec traffic
limited only by the
only by the capacity
by the capacity of
the capacity of the
capacity of the outbound
of the outbound network
the outbound network card
lambda networks are already
networks are already reaching
and the values of
are already reaching speeds
the values of the
already reaching speeds of
values of the corresponding
of the corresponding revenues
the corresponding revenues of
corresponding revenues of the
revenues of the pools
of the pools with
the pools with r
and higher speeds are
higher speeds are a
speeds are a certainty
are a certainty down
a certainty down the
certainty down the road
substituting the stable value
the stable value x
we envision maelstrom as
envision maelstrom as a
maelstrom as a small
we obtain the revenues
as a small rack
obtain the revenues of
the revenues of the
revenues of the two
of the two pools
style cluster of blade
all are given in
are given in figure
each acting as an
acting as an individual
as an individual proxy
traffic would be distributed
would be distributed over
to simplify the expressions
be distributed over such
distributed over such a
over such a rack
such a rack by
a rack by partitioning
rack by partitioning the
by partitioning the address
partitioning the address space
the address space of
address space of the
space of the remote
of the remote datacenter
the remote datacenter and
remote datacenter and routing
datacenter and routing different
and routing different segments
no attack if no
routing different segments of
attack if no pool
different segments of the
if no pool engages
segments of the space
no pool engages in
of the space through
pool engages in block
the space through distinct
engages in block withholding
space through distinct maelstrom
through distinct maelstrom appliance
distinct maelstrom appliance pairs
we plan to experiment
plan to experiment with
to experiment with such
experiment with such configurations
which would also permit
would also permit us
also permit us to
permit us to explore
us to explore faulttolerance
and we have i
to explore faulttolerance issues
if a maelstrom blade
a maelstrom blade fails
and to support load
each miner s revenue
balancing schemes that might
miner s revenue is
schemes that might vary
s revenue is proportional
that might vary the
revenue is proportional to
might vary the ip
is proportional to its
vary the ip address
proportional to its power
the ip address space
ip address space partitioning
address space partitioning dynamically
space partitioning dynamically to
be it in a
partitioning dynamically to spread
it in a pool
dynamically to spread the
in a pool or
to spread the encoding
a pool or working
spread the encoding load
pool or working solo
the encoding load over
encoding load over multiple
load over multiple machines
o ne attacker we
ne attacker we begin
attacker we begin our
we begin our analysis
begin our analysis with
our analysis with a
analysis with a simplified
we present the implementation
with a simplified game
present the implementation and
a simplified game of
the implementation and performance
simplified game of two
implementation and performance of
game of two pools
and performance of a
performance of a single
the kernel implementation is
kernel implementation is a
implementation is a module
is a module for
a module for linux
with hooks into the
hooks into the kernel
into the kernel packet
the kernel packet filter
miners outside both pools
outside both pools mine
both pools mine solo
or with closed pools
with closed pools that
closed pools that do
pools that do not
that do not attack
maelstrom proxies work in
do not attack and
proxies work in pairs
not attack and cannot
attack and cannot be
and cannot be attacked
one on each side
on each side of
each side of the
side of the long
of the long haul
the long haul link
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
each proxy acts both
proxy acts both as
acts both as an
both as an ingress
as an ingress and
an ingress and egress
ingress and egress temporarily
the dashed red arrow
dashed red arrow indicates
red arrow indicates that
arrow indicates that x
in case all but
case all but one
all but one of
but one of the
one of the missing
of the missing packets
the missing packets are
missing packets are router
packets are router at
s mining power infiltrates
are router at the
mining power infiltrates pool
router at the same
at the same time
the same time since
same time since they
with a block withholding
time since they handle
a block withholding attack
since they handle duplex
they handle duplex traffic
handle duplex traffic in
duplex traffic in received
traffic in received later
in received later or
received later or recovered
later or recovered through
does not engage in
or recovered through other
not engage in block
recovered through other xors
engage in block withholding
all of its m
allowing the following manner
loyal miners work on
the recovery of the
miners work on its
recovery of the remaining
work on its behalf
of the remaining missing
the remaining missing packet
remaining missing packet from
missing packet from this
packet from this xor
in practice we stored
practice we stored data
on the other hand
we stored data and
the other hand does
stored data and xor
other hand does not
data and xor packets
hand does not employ
and xor packets in
does not employ x
xor packets in dou
packets in dou the
in dou the egress
dou the egress router
the egress router captures
egress router captures ip
router captures ip packets
captures ip packets and
ip packets and creates
packets and creates re
of its loyal miners
ble buffered red black
buffered red black trees
and its direct mining
red black trees for
its direct mining power
direct mining power is
mining power is only
power is only m
byte packets and dundant
packets and dundant fec
and dundant fec packets
the original ip packets
the bitcoin system normalizes
original ip packets are
bitcoin system normalizes these
system normalizes these rates
normalizes these rates by
these rates by the
rates by the total
by the total number
the total number of
total number of miners
number of miners that
of miners that publish
miners that publish full
that publish full proofs
entries this occupies around
namely all miners but
all miners but x
routed through unaltered as
through unaltered as they
unaltered as they would
as they would have
they would have been
would have been at
have been at the
been at the send
the pools direct revenues
pools direct revenues are
direct revenues are therefore
the repair bins in
revenues are therefore m
repair bins in the
bins in the layered
in the layered interoriginally
the redundant packets are
redundant packets are then
packets are then forwarded
are then forwarded leaving
then forwarded leaving scheme
forwarded leaving scheme store
leaving scheme store incrementally
scheme store incrementally computed
store incrementally computed xors
incrementally computed xors and
computed xors and to
xors and to the
and to the remote
to the remote ingress
the remote ingress router
remote ingress router via
ingress router via a
router via a udp
via a udp channel
lists of data packet
of data packet headers
without the data packet
the data packet payloads
resulting in low storage
in low storage overheads
low storage overheads for
storage overheads for each
overheads for each layer
for each layer the
each layer the ingress
layer the ingress router
the ingress router captures
ingress router captures and
router captures and stores
captures and stores ip
and stores ip packets
stores ip packets that
ip packets that rise
packets that rise linearly
that rise linearly with
rise linearly with the
linearly with the value
with the value of
the value of the
value of the interleave
divides its revenue among
its revenue among its
revenue among its loyal
among its loyal miners
its loyal miners and
loyal miners and the
miners and the miners
and the miners that
the coming from the
the miners that infiltrated
coming from the direction
miners that infiltrated it
from the direction of
the direction of the
direction of the egress
of the egress router
its revenue density is
revenue density is therefore
density is therefore r
upon memory footprint for
memory footprint for a
footprint for a long
running proxy was around
proxy was around receipt
was around receipt of
around receipt of a
receipt of a redundant
of a redundant packet
an ip packet is
ip packet is recov
mb in our experiments
ered if there is
if there is an
there is an opportunity
is an opportunity to
an opportunity to do
opportunity to do so
redundant packets that can
packets that can be
that can be used
can be used at
be used at a
used at a later
at a later time
a later time are
later time are stored
if the redundant packet
the redundant packet is
redundant packet is useless
packet is useless it
is useless it is
useless it is immediately
it is immediately dis
other performance enhancing roles
performance enhancing roles carded
upon recovery the ip
recovery the ip packet
the ip packet is
ip packet is sent
packet is sent through
is sent through maelstrom
sent through maelstrom appliances
through maelstrom appliances can
maelstrom appliances can optionally
appliances can optionally aggregate
can optionally aggregate small
optionally aggregate small suba
aggregate small suba raw
small suba raw socket
suba raw socket to
raw socket to its
socket to its intended
to its intended destination
kilobyte packets from different
packets from different flows
from different flows into
different flows into larger
flows into larger ones
into larger ones for
larger ones for using
ones for using fec
for using fec requires
using fec requires that
fec requires that each
requires that each data
that each data packet
each data packet have
game progress bitcoin network
data packet have a
progress bitcoin network figure
packet have a unique
have a unique better
a unique better communication
unique better communication efficiency
better communication efficiency over
communication efficiency over the
efficiency over the long
distance identifier that the
identifier that the receiver
that the receiver can
the receiver can use
receiver can use to
can use to keep
use to keep track
we obtain the expression
to keep track of
obtain the expression for
keep track of re
the expression for r
in split flow control
split flow control mode
flow control mode they
control mode they can
mode they can ceived
they can ceived data
can ceived data packets
ceived data packets and
data packets and to
packets and to identify
and to identify missing
to identify missing data
identify missing data packets
missing data packets perform
data packets perform send
side buffering of in
flight data for multiin
data for multiin a
for multiin a repair
multiin a repair packet
if we had access
we had access to
had access to end
we gigabyte flows that
gigabyte flows that exceed
flows that exceed the
that exceed the sending
exceed the sending end
host s buffercould have
s buffercould have added
buffercould have added a
have added a header
added a header to
a header to each
header to each packet
to each packet with
each packet with a
packet with a unique
with a unique ing
a unique ing capacity
divides its revenue among
its revenue among its
revenue among its registered
among its registered miners
maelstrom appliances can act
appliances can act as
can act as mulsequence
act as mulsequence number
the revenue includes both
revenue includes both its
includes both its direct
both its direct mining
its direct mining revenue
direct mining revenue and
mining revenue and b
numerical analysis we analyze
analysis we analyze this
we analyze this game
analyze this game numerically
this game numerically by
game numerically by finding
numerically by finding the
by finding the x
we intercept traffic trans
appliances send multicast packparently
send multicast packparently and
and substituting this value
multicast packparently and need
substituting this value for
packparently and need to
this value for r
and need to route
need to route it
to route it without
route it without modification
it without modification or
without modification or addi
ets to each other
to each other across
each other across the
we vary the sizes
other across the long
vary the sizes of
the sizes of the
sizes of the pools
of the pools through
the pools through the
pools through the entire
through the entire feasible
the entire feasible range
entire feasible range and
feasible range and depict
range and depict the
and depict the optimal
depict the optimal x
we identify ip multicast
and the corresponding revenues
the corresponding revenues in
corresponding revenues in figure
to spread them within
spread them within their
each point in each
them within their datacenters
point in each graph
in each graph represents
each graph represents the
graph represents the equilibrium
ip packets by a
represents the equilibrium point
packets by a tuple
the equilibrium point of
by a tuple consisting
equilibrium point of a
a tuple consisting of
point of a game
tuple consisting of the
of a game with
consisting of the source
a game with the
of the source and
game with the corresponding
the source and des
with the corresponding m
appliances can take on
can take on other
take on other existing
on other existing roles
where we normalize m
other existing roles in
existing roles in the
roles in the tination
in the tination ip
the tination ip address
the top right half
size of the ip
top right half of
of the ip datacenter
right half of the
half of the range
of the range in
the range in all
range in all graphs
acting as security and
in all graphs is
as security and vpn
all graphs is not
security and vpn gateways
graphs is not feasible
and vpn gateways and
vpn gateways and as
gateways and as header
and as header plus
as header plus data
as the sum of
the sum of m
and a checksum over
a checksum over the
checksum over the ip
over the ip data
the ip data pay
conventional performance enhancing proxies
we use this range
use this range as
this range as a
range as a reference
as a reference color
and we use a
we use a dashed
use a dashed line
a dashed line to
dashed line to show
line to show the
to show the bound
show the bound between
the bound between this
bound between this value
between this value within
this value within the
the checksum over the
value within the feasible
checksum over the payload
within the feasible range
over the payload is
the payload is necessary
payload is necessary since
is necessary since the
necessary since the ip
since the ip identification
the ip identification field
ip identification field is
a shows the optimal
identification field is only
shows the optimal infiltration
the optimal infiltration rate
in the entire feasible
the entire feasible range
bits long and a
entire feasible range we
long and a single
feasible range we see
and a single pair
range we see that
a single pair of
we see that pool
single pair of end
chooses a strictly positive
hosts communicating at high
a strictly positive value
communicating at high speeds
strictly positive value for
at high speeds will
positive value for x
evaluation use the same
use the same identifier
the same identifier for
same identifier for different
identifier for different data
for different data packets
different data packets within
data packets within a
packets within a fairly
the revenue of pool
within a fairly short
a fairly short interval
fairly short interval unless
is depicted in figure
short interval unless the
interval unless the checksum
unless the checksum is
the checksum is added
b and in the
checksum is added to
and in the entire
is added to we
in the entire feasible
added to we evaluated
the entire feasible region
to we evaluated maelstrom
entire feasible region it
we evaluated maelstrom on
feasible region it is
evaluated maelstrom on the
region it is strictly
maelstrom on the emulab
it is strictly larger
on the emulab testbed
is strictly larger than
the emulab testbed at
emulab testbed at utah
testbed at utah differentiate
at utah differentiate between
utah differentiate between them
which the pool would
the pool would have
pool would have gotten
would have gotten without
have gotten without attacking
for all the experiments
we used a dumbbell
used a dumbbell topoltifiers
a dumbbell topoltifiers result
dumbbell topoltifiers result in
topoltifiers result in garbled
c depicts the revenue
result in garbled recovery
depicts the revenue of
in garbled recovery by
the revenue of pool
garbled recovery by maelstrom
an event ogy of
event ogy of two
which is strictly smaller
ogy of two clusters
is strictly smaller than
of two clusters of
two clusters of nodes
clusters of nodes connected
of nodes connected via
in the entire range
nodes connected via routing
connected via routing nodes
via routing nodes which
routing nodes which will
nodes which will be
which will be caught
will be caught by
note that the total
be caught by higher
that the total system
caught by higher level
the total system mining
by higher level checksums
total system mining power
higher level checksums designed
system mining power is
level checksums designed with
mining power is reduced
checksums designed with a
power is reduced when
designed with a high
is reduced when pool
latency link in between
chooses to infiltrate pool
link in between them
designed to emto deal
to emto deal with
emto deal with tranmission
deal with tranmission errors
with tranmission errors on
tranmission errors on commodity
the revenue of third
errors on commodity networks
revenue of third parties
on commodity networks ulate
commodity networks ulate the
networks ulate the setup
ulate the setup in
the setup in figure
miners not in either
not in either pool
and ran the proxy
ran the proxy code
the proxy code on
proxy code on and
code on and hence
on and hence does
and hence does not
hence does not have
does not have significant
not have significant consequences
have significant consequences unless
significant consequences unless the
consequences unless the routers
shows the performance of
the performance of the
performance of the kernel
of the kernel version
the kernel version at
kernel version at gigabit
version at gigabit speeds
therefore pays for the
the remainder of the
pays for the increased
remainder of the graphs
for the increased revenue
of the graphs it
the increased revenue of
the graphs it occurs
increased revenue of its
graphs it occurs frequently
revenue of its attacker
of its attacker and
its attacker and everyone
attacker and everyone else
and everyone else in
the kernel version of
everyone else in the
kernel version of maelstrom
else in the system
version of maelstrom can
of maelstrom can generate
maelstrom can generate up
can generate up to
generate up to a
up to a show
to a show the
a show the performance
implications to the general
show the performance of
to the general case
the performance of the
the general case consider
performance of the user
general case consider the
case consider the case
consider the case of
the case of p
case of p pools
space version at slower
version at slower gigabit
for any choice of
at slower gigabit per
any choice of the
slower gigabit per second
choice of the pools
gigabit per second of
of the pools sizes
per second of data
the pools sizes m
second of data and
of data and fec
data and fec traffic
to emulate the mtu
emulate the mtu difference
the mtu difference between
mtu difference between the
difference between the longput
between the longput data
the longput data rate
longput data rate depending
data rate depending on
rate depending on the
depending on the encoding
at least one pool
on the encoding rate
least one pool will
one pool will choose
pool will choose to
will choose to perform
choose to perform block
to perform block withholding
haul link and the
link and the datacenter
and the datacenter network
we were able to
were able to saturate
able to saturate the
to saturate the outgoing
saturate the outgoing card
the outgoing card at
outgoing card at set
card at set an
at set an mtu
set an mtu of
bytes on the network
on the network connecting
the network connecting the
network connecting the rates
connecting the rates as
the rates as high
rates as high as
with cpu overload occurring
cpu overload occurring at
overload occurring at end
hosts to the proxy
to the proxy and
the proxy and an
proxy and an mtu
and an mtu of
where each incoming data
each incoming data packet
incoming data packet had
data packet had to
packet had to be
had to be xored
to be xored long
haul link between proxies
the only exception is
only exception is figure
where we maintained equal
we maintained equal mtus
maintained equal mtus of
throughput metrics at the
metrics at the receive
incoming data packets are
data packets are buffered
packets are buffered so
are buffered so that
buffered so that they
so that they can
that they can be
they can be used
can be used in
be used in conjunction
used in conjunction with
in conjunction with figures
show that commodity tcp
ip throughxors to recover
throughxors to recover missing
to recover missing data
recover missing data packets
any received put collapses
received put collapses in
put collapses in the
collapses in the presence
in the presence of
the presence of non
and xor that is
xor that is missing
that is missing more
is missing more than
missing more than one
more than one data
than one data packet
one data packet is
data packet is stored
packet is stored that
is stored that maelstrom
stored that maelstrom successfully
that maelstrom successfully masks
maelstrom successfully masks loss
successfully masks loss and
masks loss and prevents
loss and prevents this
stable state where only
state where only pool
two pools where one
pools where one infiltrates
where one infiltrates the
one infiltrates the other
ip no loss maelstrom
no loss maelstrom no
optimal infiltration rate x
loss maelstrom no loss
maelstrom no loss maelstrom
as a function of
a function of pool
function of pool sizes
and the lines in
show the revenue density
the revenue density of
in a system with
a system with p
system with p pools
is not an equilibrium
assume towards negation this
towards negation this is
negation this is not
this is not the
is not the case
is an equilibrium point
now consider a setting
consider a setting with
a setting with only
setting with only pools
and treat the other
treat the other pools
the other pools as
other pools as independent
pools as independent miners
this is the setting
is the setting analyzed
the setting analyzed above
setting analyzed above and
analyzed above and we
above and we have
and we have seen
we have seen there
have seen there that
seen there that pool
can increase its revenue
increase its revenue by
its revenue by performing
revenue by performing a
by performing a block
performing a block withholding
a block withholding attack
block withholding attack on
withholding attack on pool
s infiltration rate by
infiltration rate by x
take this values back
this values back to
values back to the
back to the setting
to the setting at
the setting at hand
setting at hand with
at hand with p
hand with p pools
the revenue of pool
is better when x
name size discusfish antpool
size discusfish antpool ghash
io btchine btcguild eligius
btchine btcguild eligius others
tcp no loss maelstrom
no loss maelstrom no
loss maelstrom no loss
maelstrom no loss maelstrom
one way link latency
the six largest open
six largest open pool
largest open pool sizes
open pool sizes as
pool sizes as of
sizes as of january
way latency collapse from
latency collapse from occurring
shows the performance of
the performance of the
performance of the user
space version on a
mbps link and figure
shows the kernel version
the kernel version on
their optimal infiltration rates
kernel version on a
of each pool as
each pool as a
pool as a fraction
as a fraction of
a fraction of its
the experiment in each
fraction of its size
experiment in each case
in each case involves
each case involves running
case involves running iperf
if it attacked all
it attacked all others
attacked all others without
all others without reciprocation
and their revenue density
their revenue density when
revenue density when attacking
flows from one node
from one node to
one node to another
node to another across
to another across the
another across the long
distance link with and
link with and without
can improve its revenue
with and without intermediary
improve its revenue by
and without intermediary maelstrom
its revenue by attacking
without intermediary maelstrom proxies
revenue by attacking pool
intermediary maelstrom proxies and
maelstrom proxies and measuring
proxies and measuring obtained
and measuring obtained throughput
measuring obtained throughput while
obtained throughput while varying
throughput while varying loss
while varying loss rate
left graph on each
graph on each figure
attacks is not an
is not an equilibrium
not an equilibrium point
case as a test
as a test case
the error bars on
error bars on the
we take the pool
bars on the graphs
take the pool distribution
on the graphs to
the pool distribution in
the graphs to the
pool distribution in january
graphs to the left
to the left are
the left are standard
left are standard errors
are standard errors of
standard errors of the
errors of the throughput
of the throughput over
the throughput over ten
throughput over ten runs
ip s cache of
s cache of tuning
cache of tuning parameters
of tuning parameters to
tuning parameters to allow
parameters to allow for
to allow for repeatable
allow for repeatable results
the clients in the
clients in the experiment
in the experiment are
the experiment are running
experiment are running tcp
ip reno on a
reno on a linux
we analyze the cases
analyze the cases where
the cases where each
cases where each of
where each of the
each of the pools
of the pools attacks
the pools attacks all
pools attacks all other
attacks all other open
all other open pools
all of which behave
of which behave honestly
the maelstrom parameters used
maelstrom parameters used are
parameters used are r
note that attacking all
that attacking all pools
attacking all pools with
all pools with force
pools with force proportional
with force proportional to
force proportional to their
proportional to their size
to their size yields
their size yields the
size yields the same
yields the same results
the same results as
same results as attacking
results as attacking a
as attacking a single
attacking a single pool
a single pool of
single pool of their
pool of their aggregate
of their aggregate size
plugging in the numbers
in the numbers into
the numbers into the
numbers into the analysis
into the analysis above
the analysis above shows
analysis above shows that
above shows that a
shows that a larger
that a larger pool
a larger pool needs
larger pool needs to
pool needs to use
needs to use a
to use a smaller
use a smaller ratio
a smaller ratio of
smaller ratio of its
ratio of its mining
of its mining power
its mining power for
space version involved running
mining power for infiltration
version involved running a
power for infiltration and
involved running a single
for infiltration and can
infiltration and can increase
and can increase its
can increase its revenue
increase its revenue density
its revenue density more
revenue density more than
density more than a
more than a small
second iperf flow from
than a small pool
iperf flow from one
flow from one node
from one node to
one node to another
node to another with
to another with and
another with and without
with and without maelstrom
and without maelstrom running
achieves its optimum attack
without maelstrom running on
its optimum attack rate
maelstrom running on the
optimum attack rate at
running on the routers
on the routers and
the routers and measuring
routers and measuring throughput
and measuring throughput while
measuring throughput while varying
throughput while varying the
while varying the random
varying the random loss
of the pool s
the random loss rate
the pool s mining
random loss rate on
pool s mining power
loss rate on the
rate on the link
on the link and
the link and the
link and the one
increasing its revenue by
its revenue by almost
to test the kernel
test the kernel version
the kernel version at
kernel version at gigabit
this amounts to a
version at gigabit speeds
amounts to a daily
to a daily revenue
a daily revenue increase
daily revenue increase of
revenue increase of b
we ran eight parallel
ran eight parallel iperf
eight parallel iperf flows
parallel iperf flows from
iperf flows from one
flows from one node
from one node to
one node to another
node to another for
the curves obtained from
curves obtained from the
usd at the exchange
obtained from the two
at the exchange rate
from the two versions
the exchange rate on
the two versions are
exchange rate on that
two versions are almost
rate on that date
versions are almost identical
this represents a considerable
we present both to
represents a considerable increase
present both to show
a considerable increase of
both to show that
considerable increase of the
to show that the
increase of the pools
show that the kernel
of the pools net
that the kernel version
the pools net revenue
the kernel version successfully
kernel version successfully scales
version successfully scales up
successfully scales up the
scales up the performance
up the performance of
the performance of the
for the smallest pool
performance of the user
space version to hundreds
version to hundreds of
to hundreds of megabits
the attack is much
hundreds of megabits of
attack is much less
of megabits of traffic
is much less profitable
megabits of traffic per
of traffic per second
to reach the optimum
reach the optimum it
the optimum it needs
optimum it needs almost
it needs almost a
needs almost a third
almost a third of
a third of its
third of its power
of its power for
its power for attacking
power for attacking but
for attacking but increases
attacking but increases its
but increases its revenue
increases its revenue density
its revenue density by
revenue density by merely
we show how tcp
ip performance degrades on
performance degrades on a
ms link as the
link as the loss
as the loss rate
the loss rate is
loss rate is increased
rate is increased from
maelstrom masks loss up
masks loss up to
without significant throughput degradation
with the kernel version
the kernel version achieving
kernel version achieving two
version achieving two orders
achieving two orders of
two orders of magnitude
orders of magnitude higher
of magnitude higher throughput
magnitude higher throughput that
higher throughput that conventional
throughput that conventional tcp
the graphs on the
graphs on the right
on the right side
two attacking pools system
the right side of
right side of figures
ip throughput declining on
throughput declining on a
declining on a link
on a link of
a link of increasing
link of increasing length
of increasing length when
increasing length when subjected
length when subjected to
when subjected to uniform
subjected to uniform loss
to uniform loss rates
uniform loss rates of
as a function of
a function of pool
function of pool sizes
the top line in
top line in the
line in the graphs
in the graphs is
the graphs is the
graphs is the performance
is the performance of
the performance of tcp
ip without loss and
without loss and provides
loss and provides an
and provides an upper
provides an upper bound
an upper bound for
upper bound for performance
bound for performance on
for performance on the
performance on the link
space and kernel versions
maelstrom masks packet loss
masks packet loss and
packet loss and tracks
loss and tracks the
and tracks the lossless
tracks the lossless line
the lossless line closely
lagging only when the
only when the link
when the link latency
the link latency is
link latency is low
latency is low and
is low and tcp
ip s throughput is
s throughput is very
throughput is very high
ip to attain very
to attain very high
attain very high speeds
very high speeds on
high speeds on the
speeds on the gi
t wo p ools
wo p ools we
p ools we proceed
ools we proceed to
we proceed to analyze
proceed to analyze the
to analyze the case
analyze the case where
the case where two
case where two pools
where two pools may
two pools may attack
pools may attack each
may attack each other
attack each other and
each other and the
other and the other
and the other miners
the other miners mine
other miners mine solo
again we have pool
controls its infiltration rate
its infiltration rate x
also controls its infiltration
controls its infiltration rate
its infiltration rate x
this scenario is illustrated
scenario is illustrated in
is illustrated in figure
the total mining power
total mining power in
mining power in the
power in the system
in the system is
the system is m
system is m x
the direct revenues r
of the pools from
the pools from mining
pools from mining are
from mining are their
mining are their effective
are their effective mining
their effective mining rates
without infiltrating mining power
divided by the total
by the total mining
the total mining rate
the total revenue of
total revenue of each
revenue of each pool
of each pool is
each pool is its
pool is its direct
is its direct mining
its direct mining revenue
two pools infiltrating each
pools infiltrating each other
and the infiltration revenue
the infiltration revenue from
infiltration revenue from the
revenue from the previous
from the previous round
which is the attacked
is the attacked pool
the attacked pool s
attacked pool s total
pool s total revenue
s total revenue multiplied
total revenue multiplied by
revenue multiplied by its
multiplied by its infiltration
by its infiltration rate
the pool s total
pool s total revenue
s total revenue is
total revenue is divided
revenue is divided among
is divided among its
divided among its loyal
among its loyal miners
its loyal miners and
loyal miners and miners
miners and miners that
and miners that infiltrated
miners that infiltrated it
way delivery latency against
at stable state this
delivery latency against loss
stable state this is
latency against loss rate
state this is r
we obtain the following
obtain the following closed
the following closed expressions
following closed expressions for
closed expressions for each
we express the revenues
express the revenues as
the revenues as functions
revenues as functions of
as functions of x
each pool controls only
pool controls only its
controls only its own
only its own infiltration
its own infiltration rate
in each round of
each round of the
round of the pool
of the pool game
packet delivery latencies gabit
delivery latencies gabit link
each pool will optimize
pool will optimize its
will optimize its infiltration
we had to set
optimize its infiltration rate
had to set the
its infiltration rate of
to set the mtu
infiltration rate of the
set the mtu of
rate of the other
the mtu of the
mtu of the entire
of the entire path
the entire path to
entire path to be
path to be the
to be the maximum
acts at step t
it optimizes its revenue
optimizes its revenue with
its revenue with r
which meant that the
meant that the longhaul
that the longhaul link
the longhaul link had
longhaul link had the
link had the same
had the same mtu
the same mtu as
same mtu as the
mtu as the inter
this resulted in the
resulted in the fragmentation
in the fragmentation of
the fragmentation of repair
fragmentation of repair packets
of repair packets sent
repair packets sent over
packets sent over udp
sent over udp on
over udp on the
udp on the long
haul link into two
link into two ip
into two ip packet
two ip packet fragments
since the loss of
the loss of a
loss of a single
of a single fragment
a single fragment resulted
single fragment resulted in
fragment resulted in the
resulted in the loss
in the loss of
the loss of the
loss of the repair
we observed a higher
observed a higher loss
a higher loss rate
higher loss rate for
loss rate for repairs
rate for repairs than
for repairs than for
repairs than for data
than for data packets
we expect performance to
expect performance to be
performance to be better
to be better on
be better on a
better on a network
on a network where
a network where the
network where the mtu
where the mtu of
the mtu of the
mtu of the long
haul link is truly
link is truly larger
is truly larger than
truly larger than the
larger than the mtu
than the mtu within
the mtu within each
mtu within each cluster
acts at step t
latency metrics to measure
metrics to measure the
to measure the latency
it optimizes its revenue
measure the latency effects
optimizes its revenue with
the latency effects of
its revenue with x
latency effects of tcp
mbps stream between two
stream between two nodes
between two nodes over
two nodes over a
and simultaneously ran a
mbps flow alongside on
flow alongside on the
alongside on the same
on the same link
the same link to
same link to simulate
link to simulate a
to simulate a real
time stream combined with
stream combined with other
combined with other intercluster
with other intercluster traffic
an equilibrium exists where
equilibrium exists where neither
exists where neither pool
can improve its revenue
shows the average delivery
improve its revenue by
the average delivery latency
its revenue by changing
average delivery latency of
revenue by changing its
by changing its infiltration
changing its infiltration rate
level packets in the
any pair of values
pair of values x
as loss rates go
loss rates go up
such that arg maxx
shows the same scenario
the same scenario with
same scenario with a
scenario with a constant
with a constant uniformly
a constant uniformly random
constant uniformly random loss
uniformly random loss rate
random loss rate of
and varying oneway latency
maelstrom s delivery latency
s delivery latency is
delivery latency is almost
latency is almost exactly
is almost exactly equal
almost exactly equal to
exactly equal to the
equal to the one
way latency on the
latency on the link
ip takes more than
takes more than twice
more than twice as
than twice as long
twice as long once
as long once one
way latencies go past
plots delivery latency against
delivery latency against message
latency against message identifier
the spikes in latency
spikes in latency are
in latency are triggered
latency are triggered by
are triggered by losses
triggered by losses that
by losses that lead
losses that lead to
that lead to packets
lead to packets piling
to packets piling up
packets piling up at
piling up at the
up at the receiver
a key point is
key point is that
point is that we
is that we are
that we are plotting
we are plotting the
are plotting the delivery
plotting the delivery latency
the delivery latency of
delivery latency of all
latency of all packets
not just lost ones
ip delays correctly received
delays correctly received packets
correctly received packets while
received packets while waiting
packets while waiting for
while waiting for missing
waiting for missing packets
for missing packets sequenced
missing packets sequenced earlier
packets sequenced earlier by
sequenced earlier by the
earlier by the sender
by the sender the
the sender the effect
sender the effect of
the effect of this
effect of this is
of this is shown
this is shown in
is shown in figure
where single packet losses
single packet losses cause
packet losses cause spikes
losses cause spikes in
cause spikes in delivery
spikes in delivery latency
in delivery latency that
delivery latency that last
latency that last for
that last for hundreds
last for hundreds of
for hundreds of packets
the low data rate
low data rate in
data rate in the
rate in the flow
in the flow of
the flow of roughly
the feasible region for
feasible region for the
region for the pool
for the pool sizes
the pool sizes is
pool sizes is m
kb packets per rtt
packets per rtt makes
per rtt makes tcp
ip flow control delays
flow control delays at
control delays at the
delays at the sender
at the sender unlikely
given that the congestion
that the congestion control
the congestion control algorithm
congestion control algorithm is
control algorithm is reno
which implements fast recovery
implements fast recovery and
fast recovery and halves
recovery and halves the
and halves the congestion
halves the congestion window
the congestion window on
congestion window on packet
window on packet loss
on packet loss rather
the revenue function for
packet loss rather than
revenue function for ri
loss rather than resetting
function for ri is
rather than resetting it
for ri is concave
than resetting it completely
ri is concave in
is concave in xi
concave in xi for
in xi for all
xi for all feasible
for all feasible values
all feasible values of
feasible values of the
values of the variables
the maelstrom configuration used
maelstrom configuration used is
therefore the solutions for
the solutions for equations
are unique and are
unique and are either
and are either at
are either at the
either at the borders
at the borders of
the borders of the
borders of the feasible
of the feasible region
the feasible region or
feasible region or where
region or where ri
from section v we
section v we know
v we know that
we know that no
attack is not an
is not an equilibrium
not an equilibrium point
since each pool can
each pool can increase
pool can increase its
can increase its revenue
increase its revenue by
its revenue by choosing
revenue by choosing a
by choosing a strictly
choosing a strictly positive
a strictly positive infiltration
strictly positive infiltration rate
is not a solution
not a solution to
a solution to equations
nash equilibrium therefore exists
equilibrium therefore exists with
therefore exists with x
relatively prime interleaves offer
prime interleaves offer better
interleaves offer better performance
offer better performance r
using symbolic computation tools
we see that there
layered interleaving and bursty
see that there is
interleaving and bursty loss
that there is a
and bursty loss thus
there is a single
bursty loss thus far
is a single pair
loss thus far we
a single pair of
thus far we have
single pair of values
far we have shown
pair of values for
we have shown how
of values for which
have shown how maelstrom
values for which equation
shown how maelstrom effectively
how maelstrom effectively hides
maelstrom effectively hides loss
effectively hides loss from
hides loss from tcp
holds for any feasible
for any feasible choice
ip for packets dropped
any feasible choice of
for packets dropped with
feasible choice of m
packets dropped with uniform
dropped with uniform randomness
we examine the performance
examine the performance of
the performance of the
performance of the layered
of the layered interleaving
the layered interleaving algorithm
numerical analysis a numerical
analysis a numerical analysis
a numerical analysis confirms
numerical analysis confirms these
showing how different parameterizations
analysis confirms these observations
how different parameterizations handle
different parameterizations handle bursty
parameterizations handle bursty loss
handle bursty loss patterns
we simulate the pool
simulate the pool game
the pool game for
pool game for a
we use a loss
game for a range
use a loss model
for a range of
a loss model where
a range of pool
loss model where packets
range of pool sizes
model where packets are
where packets are dropped
packets are dropped in
are dropped in bursts
for each choice of
dropped in bursts of
each choice of pool
in bursts of fixed
choice of pool sizes
bursts of fixed length
we start the simulation
start the simulation when
allowing us to study
the simulation when both
us to study the
simulation when both pools
to study the impact
when both pools do
study the impact of
both pools do not
the impact of burst
pools do not infiltrate
impact of burst length
do not infiltrate each
of burst length on
not infiltrate each other
burst length on performance
the link has a
link has a one
ms and a loss
and a loss rate
a loss rate of
and the revenue densities
the revenue densities are
revenue densities are r
where it is varied
mbps flow of udp
at each round one
flow of udp packets
each round one pool
of udp packets is
round one pool chooses
udp packets is sent
one pool chooses its
packets is sent over
pool chooses its optimal
is sent over it
chooses its optimal infiltration
its optimal infiltration rate
optimal infiltration rate based
infiltration rate based on
rate based on the
based on the pool
on the pool sizes
the pool sizes and
pool sizes and the
sizes and the rate
we show that our
and the rate with
show that our observation
the rate with which
that our observation in
rate with which it
our observation in section
with which it is
which it is infiltrated
and we calculate the
we calculate the revenue
calculate the revenue after
the revenue after convergence
revenue after convergence with
is correct for high
after convergence with equation
correct for high loss
for high loss rates
high loss rates if
loss rates if the
rates if the interleaves
if the interleaves are
the interleaves are relatively
interleaves are relatively prime
recall the players in
performance improves substantially when
the players in the
improves substantially when loss
players in the pool
substantially when loss rates
in the pool game
when loss rates are
the pool game are
loss rates are high
pool game are chosen
rates are high and
game are chosen with
are high and losses
are chosen with the
high and losses are
chosen with the round
and losses are bursty
with the round robin
the round robin policy
the graph plots the
so the pools take
graph plots the percentage
the pools take turns
plots the percentage of
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
and we let the
packets successfully recovered on
we let the game
successfully recovered on the
let the game run
recovered on the y
the game run until
game run until convergence
axis against an x
the results are illustrated
results are illustrated in
are illustrated in figure
axis of loss rates
of loss rates on
loss rates on a
rates on a log
on a log scale
each run with some
the maelstrom configuration used
run with some m
maelstrom configuration used is
configuration used is r
values results in a
results in a single
in a single point
a single point in
single point in each
point in each graph
in each graph in
each graph in figure
we depict the infiltration
depict the infiltration rates
the infiltration rates of
infiltration rates of both
rates of both pools
of both pools x
b and the pools
and the pools revenue
the pools revenue densities
pools revenue densities r
for each choice of
each choice of m
we show the ability
show the ability of
the ability of layered
ability of layered interleaving
of layered interleaving to
layered interleaving to provide
interleaving to provide gracefully
to provide gracefully degrading
the values of x
provide gracefully degrading performance
gracefully degrading performance in
degrading performance in the
performance in the face
in the face of
the face of bursty
face of bursty loss
we plot the percentage
plot the percentage of
the percentage of lost
percentage of lost packets
of lost packets successfully
lost packets successfully recovered
packets successfully recovered against
successfully recovered against the
recovered against the length
against the length of
the length of loss
length of loss bursts
of loss bursts for
loss bursts for two
bursts for two different
for two different sets
two different sets of
different sets of interleaves
are the points in
the points in each
points in each of
in each of the
each of the graphs
of the graphs with
and in the bottom
the graphs with the
in the bottom graph
graphs with the respective
the bottom graph we
with the respective coordinates
bottom graph we plot
graph we plot the
we plot the average
plot the average latency
the average latency at
average latency at which
latency at which the
at which the packets
j graphs we draw
which the packets were
graphs we draw a
the packets were recovered
we draw a border
draw a border around
a border around the
border around the region
around the region where
recovery latency is defined
the region where there
latency is defined as
region where there is
is defined as the
where there is no
defined as the difference
as the difference between
the difference between the
difference between the eventual
between the eventual delivery
the eventual delivery time
attack by i in
eventual delivery time of
by i in equilibrium
delivery time of the
time of the recovered
of the recovered packet
the recovered packet and
recovered packet and the
for the ri graphs
packet and the one
the ri graphs we
ri graphs we draw
graphs we draw a
we draw a line
way latency of the
draw a line around
latency of the link
a line around the
line around the region
around the region where
the region where the
region where the revenue
we confirmed that the
where the revenue is
confirmed that the emulab
the revenue is the
that the emulab link
revenue is the same
the emulab link had
is the same as
emulab link had almost
the same as in
link had almost no
same as in the
had almost no jitter
as in the no
almost no jitter on
no jitter on correctly
jitter on correctly delivered
on correctly delivered packets
way latency an accurate
latency an accurate estimate
an accurate estimate of
accurate estimate of expected
we first observe that
estimate of expected lossless
first observe that only
of expected lossless delivery
observe that only in
expected lossless delivery time
that only in extreme
only in extreme cases
in extreme cases a
extreme cases a pool
cases a pool does
a pool does not
pool does not attack
does not attack its
not attack its counterpart
increasing the interleaves results
the interleaves results in
interleaves results in much
results in much higher
in much higher recovery
much higher recovery percentages
at equilibrium a pool
higher recovery percentages at
equilibrium a pool will
recovery percentages at large
a pool will refrain
percentages at large burst
pool will refrain from
at large burst sizes
will refrain from attacking
refrain from attacking only
from attacking only if
attacking only if the
but percentage of packets
only if the other
percentage of packets recovered
if the other pool
the other pool is
other pool is larger
pool is larger than
is larger than about
of the total mining
the total mining power
percentage of packets recovered
we observe that a
observe that a pool
that a pool improves
a pool improves its
pool improves its revenue
improves its revenue compared
its revenue compared to
revenue compared to the
compared to the no
attacks scenario only when
scenario only when it
only when it controls
when it controls a
it controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the total
of the total mining
the total mining power
these are the small
are the small triangular
the small triangular regions
small triangular regions in
triangular regions in figures
in the rest of
the rest of the
rest of the space
the trapezoids in the
trapezoids in the figures
the revenue of the
revenue of the pool
of the pool is
the pool is inferior
pool is inferior compared
is inferior compared to
inferior compared to the
compared to the no
the prisoner s dilemma
prisoner s dilemma in
s dilemma in a
dilemma in a healthy
in a healthy bitcoin
a healthy bitcoin environment
where neither pool controls
neither pool controls a
pool controls a strict
controls a strict majority
a strict majority of
strict majority of the
majority of the mining
of the mining power
both pools will earn
pools will earn less
will earn less at
earn less at equilibrium
less at equilibrium than
at equilibrium than if
equilibrium than if both
than if both pools
if both pools ran
both pools ran without
pools ran without attacking
we can analyze in
can analyze in this
analyze in this case
in this case a
this case a game
case a game where
a game where each
game where each pool
where each pool chooses
each pool chooses either
pool chooses either to
chooses either to attack
either to attack and
to attack and optimize
attack and optimize its
and optimize its revenue
or to refrain from
to refrain from attacking
without loss of generality
as we have seen
we have seen in
have seen in section
seen in section v
can increase its revenue
increase its revenue above
does attack but pool
we denote the revenue
denote the revenue of
the revenue of pool
the exact value of
exact value of r
depends on the values
on the values of
the values of m
but it is always
it is always smaller
is always smaller than
always smaller than one
as we have seen
we have seen above
does choose to attack
but does not surpass
does not surpass one
the game is summarized
game is summarized in
is summarized in figure
this is the classical
is the classical prisoner
the classical prisoner s
classical prisoner s dilemma
attack is the dominant
is the dominant strategy
chooses to attack or
to attack or not
the revenue of pool
is larger when attacking
larger when attacking than
when attacking than when
attacking than when refraining
than when refraining from
when refraining from attack
and the same for
the same for xxx
same for xxx xxx
for xxx xxx pool
no attack xxx pool
layered interleaving recovery percentage
interleaving recovery percentage and
recovery percentage and latency
percentage and latency comes
and latency comes at
latency comes at the
comes at the cost
at the cost of
the cost of higher
cost of higher recovery
of higher recovery latency
set of interleaves catches
of interleaves catches almost
interleaves catches almost all
catches almost all packets
almost all packets in
all packets in an
packets in an extended
in an extended burst
an extended burst of
packets at an average
at an average latency
an average latency of
average latency of around
while repairing all random
repairing all random singleton
all random singleton losses
random singleton losses within
the graphs also show
graphs also show recovery
also show recovery latency
show recovery latency rising
recovery latency rising gracefully
latency rising gracefully with
rising gracefully with the
gracefully with the increase
with the increase in
the increase in loss
increase in loss burst
in loss burst length
the longer the burst
the longer it takes
longer it takes to
it takes to recover
takes to recover the
to recover the lost
recover the lost packets
the maelstrom configuration used
maelstrom configuration used is
configuration used is r
prisoner s dilemma for
s dilemma for two
dilemma for two pools
the revenue density of
revenue density of each
density of each pool
of each pool is
each pool is determined
pool is determined by
is determined by the
determined by the decision
by the decision of
the decision of both
decision of both pools
of both pools whether
both pools whether to
pools whether to attack
whether to attack or
to attack or not
the dominant strategy of
dominant strategy of each
strategy of each player
of each player is
each player is to
player is to attack
however the payoff of
the payoff of both
payoff of both would
of both would be
both would be larger
would be larger if
be larger if they
larger if they both
if they both refrain
they both refrain from
both refrain from attacking
at equilibrium of this
equilibrium of this attack
when both pools attack
the revenue of each
revenue of each pool
of each pool is
each pool is smaller
pool is smaller than
is smaller than its
smaller than its revenue
than its revenue if
its revenue if neither
revenue if neither pool
if neither pool attacked
we show histograms of
show histograms of recovery
histograms of recovery latencies
of recovery latencies for
recovery latencies for the
latencies for the two
for the two interleave
the game is not
the two interleave configurations
game is not played
two interleave configurations under
is not played once
interleave configurations under different
configurations under different burst
under different burst lengths
the histograms confirm the
histograms confirm the trends
confirm the trends described
the trends described above
packet recoveries take longer
where each pool can
recoveries take longer from
each pool can change
take longer from left
pool can change its
longer from left to
can change its strategy
from left to right
change its strategy between
left to right as
its strategy between attack
to right as we
strategy between attack and
right as we increase
between attack and no
as we increase loss
we increase loss burst
increase loss burst length
and from top to
the pools can agree
from top to bottom
top to bottom as
to bottom as we
bottom as we increase
as we increase the
we increase the interleave
increase the interleave values
to refrain from attacking
and in each round
in each round a
each round a pool
round a pool can
illustrates the difference between
a pool can detect
the difference between a
pool can detect whether
difference between a traditional
can detect whether it
between a traditional fec
detect whether it is
a traditional fec code
whether it is being
traditional fec code and
it is being attacked
fec code and layered
is being attacked and
code and layered interleaving
being attacked and deduce
and layered interleaving by
attacked and deduce that
layered interleaving by plotting
and deduce that the
interleaving by plotting a
deduce that the other
that the other pool
the other pool is
other pool is violating
pool is violating the
is violating the agreement
element moving average of
cooperation where neither pool
moving average of recovery
where neither pool attacks
average of recovery latencies
neither pool attacks is
of recovery latencies for
pool attacks is a
recovery latencies for both
attacks is a possible
latencies for both codes
is a possible stable
a possible stable state
the channel is configured
channel is configured to
is configured to lose
configured to lose singleton
to lose singleton packets
lose singleton packets randomly
singleton packets randomly at
packets randomly at a
randomly at a loss
at a loss rate
a loss rate of
and additionally lose long
additionally lose long bursts
lose long bursts of
despite the fact that
the fact that the
fact that the single
that the single nash
the single nash equilibrium
single nash equilibrium in
nash equilibrium in every
packets at occasional intervals
equilibrium in every round
in every round is
every round is to
round is to attack
both codes recovery latency
case as an example
as an example we
an example we take
example we take again
we take again the
take again the pool
again the pool sizes
reed solomon layered interleaving
the pool sizes shown
pool sizes shown in
sizes shown in figure
and study the case
study the case where
the case where the
case where the two
where the two largest
the two largest pools
the optimal infiltration rates
out of the total
of the total system
the total system mining
total system mining power
and the pools would
the pools would lose
compared to the no
q i dentical p
i dentical p ools
dentical p ools let
solomon versus layered interleaving
p ools let there
versus layered interleaving are
ools let there be
layered interleaving are configured
let there be q
interleaving are configured with
there be q pools
are configured with r
be q pools of
q pools of identical
pools of identical size
of identical size that
identical size that engage
size that engage in
that engage in block
engage in block withholding
in block withholding against
block withholding against one
withholding against one another
other miners neither attack
miners neither attack nor
and recover all lost
neither attack nor are
recover all lost packets
attack nor are being
all lost packets reed
nor are being attacked
solomon uses an interleave
in this case there
uses an interleave of
this case there exists
case there exists a
there exists a symmetric
exists a symmetric equilibrium
and layered interleaving uses
layered interleaving uses interleaves
interleaving uses interleaves of
without loss of generality
a step of pool
it controls its attack
controls its attack rates
its attack rates each
attack rates each of
rates each of the
each of the other
of the other pools
and consequently both have
consequently both have a
both have a maximum
and due to symmetry
have a maximum tolerable
due to symmetry they
a maximum tolerable burst
to symmetry they are
maximum tolerable burst length
symmetry they are all
tolerable burst length of
they are all the
are all the same
we use a publicly
use a publicly available
a publicly available implementation
publicly available implementation of
the attack rate of
available implementation of a
attack rate of pool
implementation of a reed
against any other pool
solomon code based on
code based on vandermonde
based on vandermonde matrices
each of the other
of the other pools
the other pools can
other pools can attack
pools can attack its
can attack its peers
attack its peers as
its peers as well
all attack rates by
attack rates by all
rates by all attackers
by all attackers are
all attackers are identical
the code is plugged
code is plugged into
is plugged into maelstrom
plugged into maelstrom instead
into maelstrom instead of
maelstrom instead of layered
instead of layered interleaving
the attack rate of
showing that we can
attack rate of any
that we can use
rate of any pool
we can use new
of any pool other
can use new encodings
any pool other than
use new encodings within
new encodings within the
encodings within the same
within the same framework
against any other pool
the same framework seamlessly
solomon code recovers all
code recovers all lost
recovers all lost packets
all lost packets with
lost packets with roughly
packets with roughly the
with roughly the same
roughly the same latency
the same latency whereas
same latency whereas layered
latency whereas layered interleaving
whereas layered interleaving recovers
layered interleaving recovers singleton
the direct revenue of
interleaving recovers singleton losses
direct revenue of each
recovers singleton losses almost
revenue of each of
singleton losses almost immediately
of each of the
losses almost immediately and
each of the other
almost immediately and exhibits
of the other pools
immediately and exhibits latency
and exhibits latency spikes
exhibits latency spikes whenever
latency spikes whenever the
similarly denote by r
spikes whenever the longer
whenever the longer loss
the longer loss burst
longer loss burst occurs
the revenue densities of
revenue densities of pool
related work a significant
work a significant body
a significant body of
significant body of work
body of work on
of work on application
work on application and
on application and tcp
ip performance over high
are instantiated to mi
distance networks exists in
networks exists in the
exists in the context
in the context of
the context of high
the use of parallel
use of parallel sockets
of parallel sockets for
parallel sockets for higher
sockets for higher throughput
for higher throughput in
higher throughput in the
throughput in the face
in the face of
the face of non
congestion loss was proposed
loss was proposed in
was proposed in psockets
a number of protocols
number of protocols have
of protocols have been
protocols have been suggested
have been suggested as
been suggested as replacements
suggested as replacements for
as replacements for tcp
ip in such settings
in such settings xcp
are a few but
a few but all
few but all require
but all require modifications
all require modifications to
require modifications to end
or the intervening network
some approaches seek to
approaches seek to differentiate
seek to differentiate between
to differentiate between congestion
differentiate between congestion and
between congestion and non
maelstrom is a transparent
is a transparent performance
a transparent performance enhancing
transparent performance enhancing proxy
as defined in rfc
numerous implementations of peps
implementations of peps exist
of peps exist for
peps exist for improving
exist for improving tcp
for improving tcp performance
improving tcp performance on
tcp performance on satellite
but we are not
we are not aware
are not aware of
not aware of any
aware of any peps
of any peps that
any peps that use
peps that use fec
that use fec to
use fec to mask
fec to mask errors
to mask errors on
mask errors on long
based fec for reliable
fec for reliable communication
for reliable communication was
reliable communication was first
communication was first explored
was first explored by
first explored by rizzo
suggested the use of
the use of fec
use of fec for
of fec for tcp
ip retransmissions over aggregated
retransmissions over aggregated traffic
over aggregated traffic within
aggregated traffic within an
traffic within an overlay
and solving we obtain
within an overlay network
solving we obtain a
an overlay network in
we obtain a single
overlay network in the
obtain a single expression
network in the commodity
a single expression for
in the commodity internet
single expression for any
expression for any ri
since in the symmetric
in the symmetric case
the symmetric case we
symmetric case we have
case we have r
uses fec for real
the expression is shown
expression is shown in
modulating the rate of
is shown in equation
the rate of encoding
rate of encoding adaptively
the use of end
host fec under tcp
ip has been explored
has been explored in
given any value of
any value of q
value of q and
of q and mi
a multitude of different
multitude of different fec
of different fec encodings
different fec encodings exist
fec encodings exist in
encodings exist in literature
they can broadly be
can broadly be categorized
the feasible range of
broadly be categorized into
feasible range of the
be categorized into optimal
range of the infiltration
categorized into optimal erasure
of the infiltration rates
into optimal erasure codes
the infiltration rates is
optimal erasure codes and
erasure codes and near
known optimal code is
optimal code is reed
within this range ri
this range ri is
range ri is continuous
which we described previously
we described previously as
described previously as generating
and concave in x
previously as generating c
as generating c repair
generating c repair packets
c repair packets from
repair packets from r
packets from r source
from r source packets
any r of the
r of the resulting
of the resulting r
c packets can be
the optimal point for
packets can be used
optimal point for pool
can be used to
be used to reconstruct
used to reconstruct the
to reconstruct the r
reconstruct the r source
the r source packets
optimal codes such as
codes such as tornado
such as tornado and
as tornado and lt
since the function is
the function is concave
function is concave the
off encoding speed for
is concave the equation
concave the equation yields
encoding speed for large
the equation yields a
equation yields a single
speed for large data
yields a single feasible
a single feasible solution
for large data sizes
large data sizes against
data sizes against a
which is a function
sizes against a loss
is a function of
against a loss of
a function of the
a loss of optimality
function of the attack
loss of optimality the
of the attack rates
of optimality the receiver
the attack rates of
optimality the receiver needs
attack rates of the
the receiver needs to
rates of the other
receiver needs to receive
of the other pools
needs to receive slightly
to receive slightly more
receive slightly more than
slightly more than r
more than r source
than r source or
r source or repair
source or repair packets
or repair packets to
repair packets to regenerate
packets to regenerate the
to regenerate the original
regenerate the original r
the original r data
original r data packets
to find a symmetric
optimal codes are extremely
find a symmetric equilibrium
codes are extremely fast
are extremely fast for
extremely fast for encoding
fast for encoding over
for encoding over large
encoding over large sets
over large sets of
large sets of data
sets of data but
of data but not
data but not of
but not of significant
not of significant importance
of significant importance for
significant importance for real
since optimal codes perform
optimal codes perform equally
codes perform equally well
perform equally well with
equally well with small
well with small data
with small data sizes
of particular relevance are
particular relevance are growth
relevance are growth codes
and obtain a single
obtain a single feasible
a single feasible solution
the equilibrium infiltration rate
equilibrium infiltration rate and
infiltration rate and the
rate and the matching
and the matching revenues
the matching revenues are
matching revenues are shown
revenues are shown in
are shown in equation
which use multiple encoding
use multiple encoding rates
multiple encoding rates for
encoding rates for different
rates for different overhead
for different overhead levels
layered interleaving uses multiple
interleaving uses multiple interleaves
uses multiple interleaves for
multiple interleaves for different
interleaves for different burst
for different burst resilience
different burst resilience levels
burst resilience levels without
resilience levels without modulating
as in the two
levels without modulating the
without modulating the encoding
modulating the encoding rate
the effect of random
the revenue at the
effect of random losses
revenue at the symmetric
of random losses on
at the symmetric equilibrium
random losses on tcp
the symmetric equilibrium is
symmetric equilibrium is inferior
equilibrium is inferior to
is inferior to the
inferior to the no
ip has been studied
has been studied in
been studied in depth
studied in depth by
in depth by lakshman
padhye s analytical model
up our analysis addresses
our analysis addresses the
analysis addresses the eventual
addresses the eventual revenue
the eventual revenue of
eventual revenue of the
revenue of the pools
provides a means to
a means to gauge
assuming the mining difficulty
means to gauge the
the mining difficulty is
to gauge the impact
mining difficulty is set
gauge the impact of
difficulty is set based
the impact of packet
is set based on
impact of packet loss
set based on the
of packet loss on
based on the effective
packet loss on tcp
on the effective mining
the effective mining power
not including mining power
including mining power used
while most published studies
mining power used for
most published studies of
power used for withholding
published studies of packet
studies of packet loss
of packet loss are
packet loss are based
loss are based on
are based on the
based on the commodity
on the commodity internet
difficulty is updated only
the commodity internet rather
is updated only periodically
commodity internet rather than
updated only periodically every
internet rather than highspeed
rather than highspeed lambda
than highspeed lambda links
when mining power in
mining power in the
power in the system
in the system is
the system is regularly
system is regularly increasing
study the sprint backbone
the sprint backbone and
sprint backbone and make
which has been true
backbone and make two
has been true for
and make two observations
been true for the
make two observations that
true for the majority
two observations that could
for the majority of
observations that could be
the majority of bitcoin
that could be explained
majority of bitcoin s
could be explained by
of bitcoin s history
be explained by non
links are rarely loaded
are rarely loaded at
rarely loaded at more
loaded at more than
no adjustment may be
adjustment may be necessary
of capacity and b
if an attacker purchases
an attacker purchases new
attacker purchases new mining
packet reordering events occur
purchases new mining hardware
reordering events occur for
new mining hardware and
events occur for some
mining hardware and employs
occur for some flows
hardware and employs it
and employs it directly
employs it directly for
it directly for block
directly for block withholding
possibly indicating packet loss
indicating packet loss followed
packet loss followed by
loss followed by retransmissions
this mining power is
mining power is never
power is never included
is never included in
never included in the
included in the difficulty
future work scaling maelstrom
in the difficulty calculation
work scaling maelstrom to
the difficulty calculation the
scaling maelstrom to multiple
difficulty calculation the system
maelstrom to multiple gigabits
calculation the system is
to multiple gigabits per
the system is never
multiple gigabits per second
system is never aware
gigabits per second of
is never aware of
per second of traffic
never aware of it
second of traffic will
of traffic will require
traffic will require small
will require small rack
the difficulty is therefore
difficulty is therefore already
style clusters of tens
is therefore already correctly
clusters of tens of
therefore already correctly calculated
of tens of machines
already correctly calculated and
tens of machines to
correctly calculated and the
of machines to distribute
calculated and the attack
machines to distribute encoding
and the attack is
to distribute encoding load
the attack is profitable
distribute encoding load over
attack is profitable immediately
we need to design
need to design intelligent
to design intelligent load
if the mining power
the mining power is
mining power is static
over mechanisms for such
mechanisms for such a
the attack becomes profitable
for such a scheme
attack becomes profitable only
becomes profitable only after
profitable only after the
only after the bitcoin
after the bitcoin system
the bitcoin system has
bitcoin system has normalized
we have described layered
system has normalized the
have described layered interleaving
has normalized the revenues
described layered interleaving with
normalized the revenues by
layered interleaving with fixed
the revenues by adjusting
revenues by adjusting difficulty
the revenue of an
and the next step
revenue of an attacking
the next step in
of an attacking pool
next step in extending
an attacking pool is
step in extending this
attacking pool is reduced
in extending this protocol
pool is reduced due
extending this protocol is
is reduced due to
this protocol is to
reduced due to the
protocol is to make
due to the reduction
is to make it
to the reduction in
to make it adaptive
the reduction in block
reduction in block generation
in block generation of
block generation of both
generation of both the
changing interleaves and rate
of both the attacking
interleaves and rate as
both the attacking and
and rate as loss
the attacking and attacked
rate as loss patterns
attacking and attacked pools
as loss patterns in
loss patterns in the
patterns in the link
in the link change
conclusion modern distributed systems
modern distributed systems are
distributed systems are compelled
systems are compelled by
are compelled by real
world imperatives to coordinate
imperatives to coordinate across
to coordinate across datacenters
coordinate across datacenters separated
across datacenters separated by
expression for ri in
for ri in a
ri in a system
in a system with
a system with pools
system with pools of
with pools of equal
pools of equal size
q mi q mi
latency histograms for i
q symmetric equilibrium values
symmetric equilibrium values for
equilibrium values for a
values for a system
for a system of
a system of q
system of q pools
of q pools of
q pools of equal
pools of equal sizes
countermeasures in order to
in order to choose
order to choose its
to choose its optimal
choose its optimal infiltration
its optimal infiltration rate
a pool has to
pool has to know
has to know the
to know the rate
know the rate at
the rate at which
rate at which it
at which it is
which it is attacked
and the revenue density
the revenue density of
revenue density of potential
density of potential victim
of potential victim pools
a pool can estimate
pool can estimate the
can estimate the rate
estimate the rate with
the rate with which
rate with which it
with which it is
which it is attacked
it is attacked by
is attacked by comparing
attacked by comparing the
by comparing the rates
comparing the rates of
the rates of partial
rates of partial and
of partial and full
partial and full proofs
and full proofs of
full proofs of work
proofs of work it
of work it receives
work it receives from
it receives from its
receives from its miners
as explained in section
explained in section ii
in order to estimate
order to estimate the
to estimate the revenue
estimate the revenue densities
the revenue densities of
revenue densities of the
densities of the other
of the other pools
a pool can use
pool can use one
can use one of
use one of two
one of two methods
pools often publish this
often publish this data
publish this data to
this data to demonstrate
data to demonstrate their
to demonstrate their honesty
demonstrate their honesty to
their honesty to their
honesty to their miners
a pool can infiltrate
pool can infiltrate each
can infiltrate each of
infiltrate each of the
each of the other
of the other pools
the other pools with
other pools with some
pools with some nominal
with some nominal probing
some nominal probing mining
nominal probing mining power
probing mining power and
mining power and measure
power and measure the
and measure the revenue
measure the revenue density
the revenue density directly
revenue density directly by
density directly by monitoring
directly by monitoring the
by monitoring the probe
monitoring the probe s
the probe s rewards
probe s rewards from
s rewards from the
rewards from the pool
latency histograms for i
as in the case
in the case of
the case of classical
case of classical block
of classical block withholding
classical block withholding explained
block withholding explained in
withholding explained in section
explained in section ii
a pool might detect
pool might detect that
might detect that it
detect that it is
that it is being
it is being attacked
but cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners is
its miners is the
miners is the attacker
therefore a pool cannot
a pool cannot block
pool cannot block or
cannot block or punish
block or punish withholding
or punish withholding miners
various techniques can be
techniques can be used
can be used to
be used to encourage
used to encourage miners
to encourage miners to
encourage miners to submit
miners to submit full
to submit full blocks
a pool can pay
pool can pay a
can pay a bonus
pay a bonus for
a bonus for submitting
bonus for submitting a
for submitting a full
submitting a full proof
a full proof of
full proof of work
packet loss cripples the
loss cripples the performance
this would increase the
cripples the performance notes
would increase the revenue
the performance notes of
increase the revenue of
performance notes of such
the revenue of the
notes of such systems
revenue of the miner
of the miner that
the miner that found
miner that found a
and reliability and flow
that found a block
found a block while
a block while reducing
block while reducing the
while reducing the revenue
reducing the revenue of
the revenue of the
revenue of the other
of the other miners
the other miners from
other miners from this
miners from this block
while the average revenue
the average revenue of
average revenue of each
revenue of each miner
of each miner would
each miner would stay
miner would stay the
would stay the same
small miners will suffer
miners will suffer from
will suffer from higher
suffer from higher variance
from higher variance in
higher variance in revenue
are increasingly popular and
another approach is to
increasingly popular and designed
popular and designed for
approach is to introduce
and designed for lans
is to introduce a
designed for lans and
to introduce a joining
introduce a joining fee
a joining fee by
joining fee by paying
or the commodity internet
fee by paying new
the commodity internet fail
by paying new miners
commodity internet fail to
paying new miners less
internet fail to used
new miners less for
fail to used for
miners less for their
to used for applications
less for their work
used for applications such
for their work until
for applications such as
their work until they
applications such as efficiently
work until they have
such as efficiently distributing
until they have established
as efficiently distributing bulk
they have established a
efficiently distributing bulk data
have established a reputation
established a reputation with
a reputation with the
reputation with the pool
miners that seek flexibility
that seek flexibility may
seek flexibility may not
flexibility may not accept
may not accept this
not accept this policy
achieve optimal performance on
accept this policy and
optimal performance on the
this policy and choose
performance on the high
policy and choose another
and choose another pool
the pool can use
it is not obvious
pool can use a
is not obvious that
can use a honeypot
not obvious that these
use a honeypot trap
obvious that these have
a honeypot trap by
that these have utility
honeypot trap by sending
these have utility in
trap by sending the
have utility in real
by sending the miners
sending the miners tasks
the miners tasks which
miners tasks which it
time communi lambda networks
tasks which it knows
communi lambda networks linking
which it knows will
lambda networks linking datacenters
it knows will result
knows will result in
will result in a
result in a full
in a full proof
a full proof of
full proof of work
protocols is not an
is not an option
not an option for
an option for commodity
option for commodity clusters
for commodity clusters where
commodity clusters where standardization
clusters where standardization is
where standardization is critical
standardization is critical for
is critical for cost
critical for cost mitigation
if a miner fails
maelstrom is an edge
a miner fails to
is an edge appliance
miner fails to submit
an edge appliance that
fails to submit the
edge appliance that uses
to submit the full
appliance that uses forward
submit the full proof
that uses forward error
the full proof of
uses forward error correction
full proof of work
forward error correction references
proof of work it
error correction references to
of work it is
correction references to mask
work it is tagged
references to mask packet
it is tagged as
to mask packet loss
is tagged as an
mask packet loss from
tagged as an attacker
packet loss from end
to prevent the attacker
prevent the attacker from
the attacker from learning
attacker from learning them
the honeypot tasks have
honeypot tasks have to
tasks have to be
have to be regularly
to be regularly refreshed
pools can also incorporate
can also incorporate out
global crossing current network
also incorporate out of
crossing current network performance
incorporate out of band
out of band mechanisms
of band mechanisms to
band mechanisms to deter
mechanisms to deter attacks
such as verifying the
as verifying the identity
verifying the identity of
the identity of miners
identity of miners or
of miners or using
miners or using trusted
or using trusted computing
using trusted computing technologies
ip throughput and latency
that assure no block
throughput and latency by
assure no block withholding
and latency by orders
no block withholding is
latency by orders of
block withholding is taking
by orders of magninetwork
withholding is taking place
this would require miners
would require miners to
require miners to use
miners to use specialized
to use specialized hardware
use specialized hardware and
specialized hardware and software
last tude when loss
tude when loss occurs
an overhead miners may
overhead miners may not
miners may not accept
maelstrom is easy to
is easy to install
easy to install and
to install and accessed
install and accessed feb
there is no known
is no known silver
no known silver bullet
all these techniques reduce
these techniques reduce the
techniques reduce the pool
reduce the pool s
the pool s attractiveness
pool s attractiveness and
s attractiveness and deter
attractiveness and deter miners
and is completely transparent
block withholding recycling we
is completely transparent to
withholding recycling we assume
completely transparent to applications
recycling we assume that
transparent to applications and
we assume that the
assume that the infiltrating
that the infiltrating miners
the infiltrating miners are
infiltrating miners are loyal
miners are loyal to
are loyal to the
loyal to the attacker
qwest ip network statistics
some of the pool
of the pool s
the pool s members
pool s members may
s members may be
members may be disloyal
may be disloyal infiltrators
when sending disloyal miners
sending disloyal miners to
disloyal miners to perform
miners to perform block
to perform block withholding
perform block withholding at
protocols literally providing reliability
block withholding at other
literally providing reliability in
withholding at other pools
providing reliability in an
reliability in an inexpennet
an attacker takes a
attacker takes a significant
takes a significant risk
can use a loyal
use a loyal miner
a loyal miner w
loyal miner w to
miner w to infiltrate
w to infiltrate pool
thinking the miner is
the miner is loyal
miner is loyal to
is loyal to it
acknowledgments we would like
we would like to
might use it to
use it to attack
would like to thank
it to attack pool
like to thank our
to thank our shepherd
thank our shepherd robert
our shepherd robert morris
shepherd robert morris and
robert morris and the
the miner m can
morris and the other
miner m can perform
and the other reviewers
m can perform honest
the other reviewers for
can perform honest mining
other reviewers for extensive
perform honest mining for
reviewers for extensive comments
honest mining for pool
for extensive comments that
extensive comments that significantly
comments that significantly shaped
that significantly shaped the
significantly shaped the final
shaped the final version
the final version of
rather than withhold its
final version of the
than withhold its blocks
version of the paper
and not return any
not return any revenue
return any revenue to
any revenue to pool
it will take its
will take its share
take its share of
its share of pool
which thinks the miner
vidhyashankar venkataraman and vivek
thinks the miner is
venkataraman and vivek vishnumurthy
the miner is loyal
and vivek vishnumurthy provided
miner is loyal to
vivek vishnumurthy provided useful
is loyal to it
vishnumurthy provided useful comments
and deliver it back
tom boures provided valuable
deliver it back to
boures provided valuable insight
it back to pool
provided valuable insight into
valuable insight into the
insight into the quality
into the quality of
the quality of existing
quality of existing fiber
of existing fiber links
to avoid such a
avoid such a risk
stanislav shalunov provided information
shalunov provided information on
a pool needs a
provided information on loss
pool needs a sufficient
information on loss rates
needs a sufficient number
on loss rates on
a sufficient number of
loss rates on internet
sufficient number of verified
number of verified miners
of verified miners miners
verified miners miners that
miners miners that it
miners that it knows
that it knows to
it knows to be
and paul wefel gave
knows to be loyal
paul wefel gave us
wefel gave us access
gave us access to
us access to teragrid
access to teragrid loss
to teragrid loss measurements
the optimal infiltration rate
optimal infiltration rate may
infiltration rate may be
rate may be as
may be as high
be as high as
of the pool size
but this is only
this is only in
is only in extreme
only in extreme cases
in extreme cases when
extreme cases when pools
cases when pools are
when pools are large
for practical pool sizes
a pool may need
pool may need up
may need up to
of its mining power
its mining power for
mining power for infiltration
pools typically have loyal
typically have loyal mining
have loyal mining power
loyal mining power either
mining power either run
power either run directly
nat and packet mangling
either run directly by
and packet mangling for
run directly by the
packet mangling for linux
directly by the pool
by the pool owners
the pool owners or
pool owners or sold
owners or sold as
or sold as a
sold as a service
as a service but
a service but run
service but run on
but run on the
run on the pool
on the pool owners
the pool owners hardware
however the size of
the size of this
size of this mining
of this mining power
this mining power is
mining power is considered
power is considered a
is considered a trade
considered a trade secret
a trade secret and
trade secret and is
secret and is not
and is not published
block withholding in practice
withholding in practice long
in practice long term
practice long term block
long term block withholding
term block withholding attacks
block withholding attacks are
withholding attacks are difficult
attacks are difficult to
are difficult to hide
since miners using an
miners using an attacked
using an attacked pool
an attacked pool would
attacked pool would notice
pool would notice the
would notice the reduced
notice the reduced revenue
the reduced revenue density
such attacks are rarely
attacks are rarely reported
and we can therefore
we can therefore conclude
can therefore conclude that
therefore conclude that they
conclude that they are
that they are indeed
they are indeed rare
a recent exception is
recent exception is an
exception is an attack
is an attack on
an attack on the
attack on the eligius
on the eligius pool
the eligius pool performed
lateral error correction for
eligius pool performed in
error correction for timecritical
pool performed in may
correction for timecritical multicast
performed in may and
in may and june
fourth usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
bitcoin before detecting the
before detecting the attack
at which point payouts
which point payouts to
point payouts to the
payouts to the attackers
to the attackers were
the attackers were blocked
the attackers continued the
attackers continued the attack
more bitcoin before realizing
bitcoin before realizing they
before realizing they were
realizing they were not
they were not receiving
were not receiving their
not receiving their payout
the reasons the attack
reasons the attack was
the attack was so
attack was so easily
was so easily subverted
performance enhancing proxies intended
so easily subverted is
enhancing proxies intended to
easily subverted is the
proxies intended to mitigate
subverted is the limited
intended to mitigate link
is the limited efforts
the limited efforts of
limited efforts of the
efforts of the attackers
of the attackers to
the attackers to hide
attackers to hide themselves
they have only used
have only used two
only used two payout
used two payout addresses
two payout addresses to
payout addresses to collect
addresses to collect their
to collect their payouts
and so it was
so it was possible
it was possible for
was possible for the
possible for the alert
for the alert pool
the alert pool manager
alert pool manager to
pool manager to cluster
manager to cluster the
to cluster the attacking
cluster the attacking miners
the attacking miners and
attacking miners and obtain
miners and obtain a
and obtain a statistically
obtain a statistically significant
a statistically significant proof
statistically significant proof of
significant proof of their
proof of their wrongdoing
it is unknown whether
is unknown whether this
unknown whether this was
whether this was a
this was a classical
was a classical block
a classical block withholding
classical block withholding attack
with the goal of
the goal of sabotage
or a more elaborate
a more elaborate scheme
to verify the effectiveness
verify the effectiveness of
the effectiveness of block
effectiveness of block withholding
of block withholding for
enhanced loss differentiation algorithms
block withholding for profit
loss differentiation algorithms for
differentiation algorithms for use
algorithms for use in
for use in tcp
use in tcp sources
in tcp sources over
tcp sources over heterogeneous
sources over heterogeneous wireless
over heterogeneous wireless networks
implemented an experimental bitcoin
an experimental bitcoin test
experimental bitcoin test network
bitcoin test network and
test network and demonstrated
network and demonstrated the
and demonstrated the practicality
demonstrated the practicality of
the practicality of the
practicality of the attack
ieee global telecommunications conference
bitcoin s health large
s health large pools
health large pools hinder
large pools hinder bitcoin
pools hinder bitcoin s
hinder bitcoin s distributed
bitcoin s distributed nature
s distributed nature as
distributed nature as they
nature as they put
as they put a
they put a lot
put a lot of
a lot of mining
lot of mining power
of mining power in
mining power in the
power in the hands
in the hands of
the hands of a
hands of a few
of a few pool
a few pool managers
this has been mostly
has been mostly addressed
been mostly addressed by
mostly addressed by community
addressed by community pressure
by community pressure on
community pressure on miners
pressure on miners to
on miners to avoid
miners to avoid forming
to avoid forming large
avoid forming large pools
flow aggregation for enhanced
aggregation for enhanced tcp
for enhanced tcp over
enhanced tcp over wide
tcp over wide area
over wide area wireless
however such recommendations had
such recommendations had only
recommendations had only had
had only had limited
only had limited success
and mining is still
mining is still dominated
is still dominated by
still dominated by a
dominated by a small
by a small number
a small number of
small number of large
number of large pools
as a characteristic example
in the period of
the period of november
vice president of research
president of research and
of research and t
three pools generated over
of the proofs of
the proofs of work
the fact that block
fact that block withholding
that block withholding attacks
block withholding attacks are
withholding attacks are rarely
attacks are rarely observed
are rarely observed may
rarely observed may indicate
observed may indicate that
may indicate that the
indicate that the active
that the active pools
the active pools have
active pools have reached
pools have reached an
have reached an implicit
reached an implicit or
multicast routing in datagram
an implicit or explicit
routing in datagram internetworks
implicit or explicit agreement
in datagram internetworks and
or explicit agreement not
datagram internetworks and extended
explicit agreement not to
internetworks and extended lans
agreement not to attack
not to attack one
to attack one another
an attacked pool cannot
attacked pool cannot detect
pool cannot detect which
cannot detect which of
detect which of its
which of its miners
of its miners are
its miners are attacking
miners are attacking it
let alone which pool
alone which pool controls
which pool controls the
pool controls the miners
at some point a
some point a pool
point a pool might
a pool might miscalculate
pool might miscalculate and
might miscalculate and decide
miscalculate and decide to
and decide to try
decide to try to
to try to increase
try to increase its
to increase its revenue
one pool might be
pool might be enough
might be enough to
be enough to break
enough to break the
to break the agreement
possibly leading to a
leading to a constant
to a constant rate
a constant rate of
constant rate of attacks
rate of attacks among
of attacks among pools
attacks among pools and
among pools and a
pools and a reduced
and a reduced revenue
if open pools reach
open pools reach a
pools reach a state
reach a state where
a state where their
state where their revenue
where their revenue density
their revenue density is
revenue density is reduced
density is reduced due
is reduced due to
reduced due to attacks
miners will leave them
will leave them in
leave them in favor
them in favor of
in favor of other
favor of other available
of other available options
miners of sufficient size
of sufficient size can
sufficient size can mine
size can mine solo
smaller miners can form
miners can form private
can form private pools
form private pools with
private pools with closed
pools with closed access
limited to trusted participants
such a change may
a change may be
change may be in
may be in favor
be in favor of
in favor of bitcoin
favor of bitcoin as
of bitcoin as a
bitcoin as a whole
since they require such
they require such intimate
require such intimate trust
private pools are likely
pools are likely to
are likely to be
likely to be smaller
and form a fine
form a fine grained
a fine grained distribution
level traffic measurements from
fine grained distribution of
traffic measurements from the
grained distribution of mining
measurements from the sprint
distribution of mining power
from the sprint ip
of mining power with
the sprint ip backbone
mining power with many
power with many small
with many small pools
many small pools and
small pools and solo
pools and solo miners
a pool may engage
pool may engage in
may engage in an
engage in an attack
in an attack against
an attack against another
attack against another pool
against another pool not
another pool not to
pool not to increase
not to increase its
to increase its absolute
increase its absolute revenue
but rather to attract
rather to attract miners
to attract miners by
attract miners by temporarily
miners by temporarily increasing
by temporarily increasing its
temporarily increasing its revenue
increasing its revenue relative
its revenue relative to
revenue relative to a
relative to a competing
to a competing pool
recent work has investigated
work has investigated the
has investigated the motivation
investigated the motivation of
the motivation of pools
motivation of pools to
of pools to utilize
pools to utilize part
to utilize part of
utilize part of their
part of their resources
of their resources towards
their resources towards sabotage
resources towards sabotage attacks
towards sabotage attacks against
sabotage attacks against each
attacks against each other
a transport protocol for
transport protocol for grid
protocol for grid computing
journal of grid computing
the model of those
model of those works
of those works is
those works is different
works is different from
is different from the
different from the pool
from the pool game
the pool game model
pool game model in
game model in two
model in two major
in two major ways
two major ways a
major ways a sabotage
ways a sabotage attack
a sabotage attack does
sabotage attack does not
attack does not transfer
does not transfer revenue
not transfer revenue from
transfer revenue from victim
revenue from victim to
from victim to attacker
and migrating miners switch
migrating miners switch to
miners switch to less
switch to less attacked
to less attacked pools
changing pool sizes and
pool sizes and hence
sizes and hence revenues
and hence revenues until
hence revenues until convergence
the model is parametrized
model is parametrized by
is parametrized by the
parametrized by the cost
by the cost of
the cost of the
cost of the attack
of the attack and
the attack and by
attack and by the
and by the mobility
by the mobility of
the mobility of the
mobility of the miners
and the analysis demonstrates
the analysis demonstrates that
analysis demonstrates that when
demonstrates that when considering
that when considering only
when considering only sabotage
optical domain performance monitoring
considering only sabotage attacks
only sabotage attacks there
sabotage attacks there are
attacks there are regions
there are regions where
optical fiber communication conference
are regions where no
attack is the best
is the best strategy
the miner s dilemma
miner s dilemma is
s dilemma is therefore
dilemma is therefore not
is therefore not manifested
therefore not manifested in
not manifested in that
manifested in that model
pool competition for miners
competition for miners is
for miners is an
miners is an incentive
is an incentive in
an incentive in and
incentive in and of
in and of its
and of its own
of its own for
its own for mutual
own for mutual attacks
and a pool may
a pool may therefore
pool may therefore choose
may therefore choose to
therefore choose to perform
choose to perform block
to perform block withholding
perform block withholding even
block withholding even if
withholding even if its
even if its revenue
if its revenue would
its revenue would increase
revenue would increase only
would increase only after
increase only after the
only after the next
after the next difficult
end performance effects of
the next difficult adjustment
performance effects of parallel
effects of parallel tcp
of parallel tcp sockets
parallel tcp sockets on
tcp sockets on a
sockets on a lossy
the two models are
on a lossy wide
two models are therefore
models are therefore complementary
the analysis of their
analysis of their combination
of their combination is
their combination is left
combination is left for
is left for future
left for future work
we assumed in our
assumed in our analysis
in our analysis that
our analysis that pools
analysis that pools do
that pools do not
pools do not charge
do not charge fees
not charge fees from
charge fees from their
fees from their members
from their members since
their members since such
members since such fees
since such fees are
such fees are typically
fees are typically nominal
of a pool s
a pool s revenue
the effects of systemic
effects of systemic packet
of systemic packet loss
systemic packet loss on
packet loss on aggregate
loss on aggregate tcp
on aggregate tcp flows
the model can be
model can be extended
can be extended to
be extended to include
extended to include pools
to include pools fees
fees would add a
would add a friction
add a friction element
a friction element to
friction element to the
element to the flow
to the flow of
the flow of revenue
flow of revenue among
of revenue among infiltrated
revenue among infiltrated and
among infiltrated and infiltrating
infiltrated and infiltrating pools
ieee conference on supercomputing
would change to take
change to take into
to take into account
take into account a
into account a pool
account a pool fee
a pool fee of
pool fee of f
fee of f pp
of f pp ri
predictable high performance bulk
high performance bulk data
performance bulk data transfer
ieee international conference on
international conference on cluster
conference on cluster computing
a pool with a
pool with a fee
with a fee of
a fee of f
fee of f is
of f is a
f is a less
the case for packet
is a less attractive
case for packet level
a less attractive target
for packet level fec
less attractive target for
attractive target for block
target for block withholding
since the attacker s
the attacker s revenue
attacker s revenue is
s revenue is reduced
revenue is reduced by
is reduced by f
proceedings of the tc
however it is also
it is also less
is also less attractive
also less attractive for
less attractive for miners
attractive for miners in
for miners in general
trading off the two
off the two for
the two for best
two for best protection
for best protection is
best protection is left
protection is left for
is left for future
left for future work
as part of the
part of the treatment
of the treatment of
fifth international workshop on
the treatment of the
international workshop on protocols
treatment of the miner
workshop on protocols for
on protocols for high
r elated w ork
elated w ork a
the block withholding attack
block withholding attack the
withholding attack the danger
attack the danger of
the danger of a
danger of a block
of a block withholding
a block withholding attack
block withholding attack is
withholding attack is as
attack is as old
is as old as
as old as bitcoin
old as bitcoin pools
the attack was described
attack was described by
was described by rosenfeld
as pools were becoming
pools were becoming a
were becoming a dominant
becoming a dominant player
a dominant player in
dominant player in the
player in the bitcoin
in the bitcoin world
the paper described the
paper described the standard
described the standard attack
used by a miner
by a miner to
a miner to sabotage
miner to sabotage a
to sabotage a pool
sabotage a pool at
a pool at the
pool at the cost
at the cost of
the cost of reducing
cost of reducing its
of reducing its own
reducing its own revenue
a more general view
gigabit ethernet on commodity
more general view of
ethernet on commodity systems
general view of fairness
view of fairness in
of fairness in proof
fairness in proof of
in proof of work
proof of work schemes
of work schemes was
work schemes was discussed
schemes was discussed in
in the context of
the context of the
context of the hashcash
of the hashcash system
early work did not
work did not address
did not address the
not address the possibility
address the possibility of
the possibility of pools
possibility of pools infiltrating
of pools infiltrating other
pools infiltrating other pools
infiltrating other pools for
other pools for block
pools for block withholding
experimentally demonstrate that block
where did my performance
demonstrate that block withholding
did my performance go
that block withholding can
block withholding can increase
withholding can increase the
can increase the attacker
increase the attacker s
the attacker s revenue
rate limiting rears its
limiting rears its ugly
rears its ugly head
they do not address
do not address the
not address the question
address the question of
the question of mutual
question of mutual attacks
have recently noted that
recently noted that a
noted that a pool
that a pool can
a pool can increase
pool can increase its
can increase its overall
increase its overall revenue
its overall revenue with
overall revenue with block
revenue with block withholding
with block withholding if
block withholding if all
withholding if all other
if all other mining
all other mining is
other mining is performed
mining is performed by
is performed by honest
performed by honest pools
we consider the general
consider the general case
the general case where
general case where not
case where not all
where not all mining
not all mining is
all mining is performed
mining is performed through
is performed through public
performed through public pools
and analyze situations where
analyze situations where pools
situations where pools can
where pools can attack
pools can attack one
can attack one another
the discrepancy between the
discrepancy between the calculations
between the calculations of
isn t quite enough
for the special case
the special case analyzed
special case analyzed there
case analyzed there and
analyzed there and our
there and our results
and our results can
our results can be
results can be explained
can be explained by
be explained by the
explained by the strong
by the strong approximations
the strong approximations in
strong approximations in that
approximations in that work
we calculate exactly how
calculate exactly how infiltrating
exactly how infiltrating miners
how infiltrating miners reduce
infiltrating miners reduce the
miners reduce the revenue
reduce the revenue density
the revenue density of
revenue density of the
density of the infiltrated
of the infiltrated pool
temporary block withholding in
block withholding in the
withholding in the block
in the block withholding
the block withholding attack
block withholding attack discussed
withholding attack discussed in
attack discussed in this
discussed in this work
in this work the
this work the withheld
work the withheld blocks
the withheld blocks are
withheld blocks are never
blocks are never published
modified tcp congestion avoidance
tcp congestion avoidance algorithm
blocks can be withheld
can be withheld temporarily
not following the bitcoin
following the bitcoin protocol
to improve an attacker
improve an attacker s
an attacker s revenue
a miner or a
miner or a pool
or a pool can
a pool can perform
pool can perform a
can perform a selfish
perform a selfish mining
a selfish mining attack
with selfish mining the
selfish mining the attacker
mining the attacker increases
the attacker increases its
attacker increases its revenue
increases its revenue by
its revenue by temporarily
revenue by temporarily withholding
by temporarily withholding its
temporarily withholding its blocks
withholding its blocks and
its blocks and publishing
blocks and publishing them
and publishing them in
publishing them in response
them in response to
in response to block
response to block publication
to block publication by
block publication by other
publication by other pools
by other pools and
other pools and miners
physical layer impact upon
layer impact upon packet
impact upon packet errors
this attack is independent
passive and active measurement
attack is independent of
and active measurement workshop
is independent of the
independent of the block
of the block withholding
the block withholding attack
block withholding attack we
withholding attack we discuss
attack we discuss here
we discuss here and
discuss here and the
here and the two
and the two can
the two can be
two can be performed
can be performed in
be performed in concert
an attacker can also
attacker can also perform
can also perform a
also perform a double
perform a double spending
a double spending attack
double spending attack as
spending attack as follows
he intentionally generates two
intentionally generates two conflicting
generates two conflicting transactions
places one in a
one in a block
in a block it
a block it withholds
and publishes the other
publishes the other transaction
after the recipient sees
the recipient sees the
recipient sees the published
sees the published transaction
the attacker publishes the
attacker publishes the withheld
publishes the withheld block
the withheld block to
withheld block to revoke
block to revoke the
to revoke the former
revoke the former transaction
maximizing sensor network data
sensor network data persistence
this attack is performed
attack is performed by
is performed by miners
performed by miners or
in proceedings of acm
by miners or pools
proceedings of acm sigcomm
miners or pools against
or pools against service
pools against service providers
against service providers that
service providers that accept
providers that accept bitcoin
and it not directly
it not directly related
not directly related to
directly related to this
related to this work
block withholding defense most
withholding defense most crypto
currencies use a proof
work architecture similar to
architecture similar to bitcoin
where finding proof of
finding proof of work
proof of work is
of work is the
work is the result
is the result of
the result of solution
result of solution guessing
of solution guessing and
solution guessing and checking
all of the algorithms
of the algorithms we
the algorithms we are
algorithms we are aware
congestion control for high
we are aware of
control for high bandwidth
are aware of are
aware of are susceptible
of are susceptible to
are susceptible to the
susceptible to the block
to the block withholding
the block withholding attack
as in all of
in all of them
all of them the
of them the miner
them the miner can
the miner can check
miner can check whether
can check whether she
check whether she found
whether she found a
she found a full
found a full or
a full or a
full or a partial
or a partial proof
a partial proof of
partial proof of work
and protocols for computer
protocols for computer communications
prominent examples are litecoin
it is possible to
is possible to use
possible to use an
to use an alternative
use an alternative proof
an alternative proof of
alternative proof of work
proof of work mechanism
of work mechanism in
work mechanism in which
mechanism in which miners
in which miners would
which miners would not
miners would not be
would not be able
not be able to
be able to distinguish
able to distinguish partial
to distinguish partial from
distinguish partial from full
partial from full proofs
from full proofs of
full proofs of work
journal of lightwave technology
such a solution could
a solution could reduce
solution could reduce or
could reduce or remove
reduce or remove the
or remove the danger
remove the danger of
the danger of block
danger of block withholding
making such a change
such a change may
a change may not
change may not be
may not be in
not be in the
be in the interest
in the interest of
the interest of the
interest of the community
or even its potential
could lead to a
lead to a reduction
to a reduction of
a reduction of pool
reduction of pool sizes
as explained in section
explained in section ix
decentralized pools although most
pools although most pools
although most pools use
most pools use a
pools use a centralized
use a centralized manager
a prominent exception is
prominent exception is p
pool a distributed pool
a distributed pool architecture
distributed pool architecture with
pool architecture with no
architecture with no central
with no central manager
but the question of
the question of whether
a cross layer study
question of whether a
cross layer study of
of whether a pool
layer study of packet
study of packet loss
whether a pool is
of packet loss in
a pool is run
packet loss in all
pool is run by
is run by a
run by a centralized
by a centralized manager
a centralized manager or
centralized manager or with
manager or with a
or with a decentralized
with a decentralized architecture
a decentralized architecture is
decentralized architecture is almost
architecture is almost immaterial
is almost immaterial for
almost immaterial for the
immaterial for the attack
for the attack we
the attack we describe
pool group can be
group can be infiltrated
can be infiltrated and
be infiltrated and attacked
pool code can be
code can be changed
can be changed to
be changed to support
changed to support attacks
to support attacks against
support attacks against other
attacks against other pools
on the other hand
pool can be used
can be used by
be used by groups
used by groups of
by groups of miners
the performance of tcp
groups of miners to
of miners to easily
miners to easily form
to easily form closed
easily form closed pools
ip for networks with
for networks with high
networks with high bandwidth
these do not accept
do not accept untrusted
not accept untrusted miners
delay products and random
products and random loss
and are therefore protected
are therefore protected against
therefore protected against block
protected against block withholding
acm transactions on networking
c onclusion we explored
onclusion we explored a
we explored a block
explored a block withholding
a block withholding attack
block withholding attack among
withholding attack among bitcoin
attack among bitcoin mining
among bitcoin mining pools
bitcoin mining pools an
mining pools an attack
pools an attack that
an attack that is
attack that is possible
that is possible in
is possible in any
possible in any similar
in any similar system
any similar system that
similar system that rewards
system that rewards for
that rewards for proof
rewards for proof of
for proof of work
such systems are gaining
systems are gaining popularity
running most digital currencies
most digital currencies and
digital currencies and related
currencies and related services
we observe that no
attacks is not a
is not a nash
not a nash equilibrium
if none of the
none of the other
of the other pools
the other pools attack
a pool can increase
pool can increase its
can increase its revenue
increase its revenue by
its revenue by attacking
revenue by attacking the
by attacking the others
when two pools can
two pools can attack
pools can attack each
can attack each other
they face a version
face a version of
a version of the
rd annual ieee symposium
version of the prisoner
annual ieee symposium on
of the prisoner s
ieee symposium on foundations
the prisoner s dilemma
symposium on foundations of
on foundations of computer
foundations of computer science
if one pool chooses
one pool chooses to
pool chooses to attack
the victim s revenue
victim s revenue is
s revenue is reduced
and it can retaliate
it can retaliate by
can retaliate by attacking
retaliate by attacking and
by attacking and increase
attacking and increase its
and increase its revenue
at nash equilibrium both
nash equilibrium both earn
equilibrium both earn less
both earn less than
earn less than they
less than they would
than they would have
they would have if
would have if neither
have if neither attacked
with multiple pools of
multiple pools of equal
pools of equal size
of equal size a
end forward error correction
equal size a similar
size a similar situation
a similar situation arises
similar situation arises with
international zurich seminar on
situation arises with a
zurich seminar on communications
arises with a symmetric
with a symmetric equilibrium
the fact that block
fact that block withholding
that block withholding is
block withholding is not
withholding is not common
is not common may
not common may be
common may be explained
may be explained by
be explained by modeling
explained by modeling the
by modeling the attack
modeling the attack decisions
the attack decisions as
attack decisions as an
decisions as an iterative
as an iterative prisoner
an iterative prisoner s
iterative prisoner s dilemma
we argue that the
argue that the situation
that the situation is
the situation is unstable
situation is unstable since
is unstable since the
unstable since the attack
since the attack can
the attack can be
attack can be done
can be done anonymously
one pool may decide
pool may decide to
may decide to increase
decide to increase its
to increase its revenue
increase its revenue and
its revenue and drag
revenue and drag the
and drag the others
rateless codes and big
drag the others to
codes and big downloads
the others to attack
others to attack as
to attack as well
ending with a reduced
with a reduced revenue
a reduced revenue for
reduced revenue for all
the inferior revenue would
inferior revenue would push
revenue would push miners
would push miners to
push miners to join
miners to join private
to join private pools
which can verify that
can verify that their
verify that their registered
that their registered miners
their registered miners do
registered miners do not
miners do not withhold
do not withhold blocks
this would lead to
would lead to smaller
lead to smaller pools
and so ultimately to
so ultimately to a
ultimately to a better
to a better environment
a better environment for
better environment for bitcoin
environment for bitcoin as
for bitcoin as a
bitcoin as a whole
for their valuable advice
the author is grateful
paritybased loss recovery for
author is grateful to
loss recovery for reliable
is grateful to ken
recovery for reliable multicast
grateful to ken birman
for reliable multicast transmission
in proceedings of the
proceedings of the acm
of the acm sigcomm
emin gu n sirer
and the paper shepherd
the paper shepherd joseph
paper shepherd joseph bonneau
peer electronic cash system
ebay s paypal unit
s paypal unit to
paypal unit to start
unit to start accepting
to start accepting bitcoin
start accepting bitcoin payments
a simple model and
simple model and its
model and its empirical
and its empirical validation
google adds bitcoin currency
adds bitcoin currency conversion
bitcoin currency conversion to
currency conversion to search
an adaptive forward error
adaptive forward error correction
forward error correction protocol
error correction protocol for
correction protocol for end
computer communications and networks
th international conference on
businesses see the light
repurposing bitcoin work for
bitcoin work for data
work for data preservation
in proceedings of the
proceedings of the ieee
of the ieee symposium
the ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
namecoin dns dotbit project
a next generation smart
next generation smart contract
effective erasure codes for
erasure codes for reliable
codes for reliable computer
for reliable computer communication
reliable computer communication protocols
analysis of bitcoin pooled
of bitcoin pooled mining
bitcoin pooled mining reward
pooled mining reward systems
on the feasibility of
the feasibility of software
feasibility of software fec
research perspectives on bitcoin
perspectives on bitcoin and
on bitcoin and secondgeneration
bitcoin and secondgeneration cryptocurrencies
in ieee symposium on
ieee symposium on security
symposium on security and
on security and privacy
the case for application
level network striping for
network striping for data
striping for data intensive
for data intensive applications
data intensive applications using
intensive applications using high
applications using high speed
using high speed wide
high speed wide area
speed wide area networks
ieee conference on supercomputing
google s secret plans
s secret plans for
secret plans for all
plans for all that
for all that dark
all that dark fiber
information propagation in the
propagation in the bitcoin
in the bitcoin network
th ieee international conference
ieee international conference on
international conference on peer
an overlay based architecture
overlay based architecture for
based architecture for enhancing
architecture for enhancing internet
for enhancing internet qos
first usenix symposium on
usenix symposium on networked
symposium on networked systems
on networked systems design
networked systems design and
systems design and implementation
bitcoin and the age
and the age of
the age of bespoke
age of bespoke silicon
in proceedings of the
international conference on compilers
architectures and synthesis for
and synthesis for embedded
synthesis for embedded systems
udp bandwidth measurement tool
into the bitcoin mines
a tcp performance enhancing
tcp performance enhancing proxy
performance enhancing proxy for
enhancing proxy for satellite
proxy for satellite links
proceedings of the second
of the second international
the second international ifip
networking conference on networking
conference on networking technologies
performance of computer and
of computer and communication
computer and communication networks
and mobile and wireless
mobile and wireless communications
tsunami file transfer protocol
workshop on protocols for
on protocols for fast
protocols for fast longdistance
for fast longdistance networks
the university of illinois
university of illinois national
of illinois national center
illinois national center for
national center for supercomputing
center for supercomputing applications
an integrated experimental environment
integrated experimental environment for
experimental environment for distributed
environment for distributed systems
for distributed systems and
distributed systems and networks
of the fifth symposium
the fifth symposium on
fifth symposium on operating
symposium on operating systems
on operating systems design
operating systems design and
systems design and implementation
solomon codes and their
codes and their applications
how a mining monopoly
a mining monopoly can
mining monopoly can attack
monopoly can attack bitcoin
majority is not enough
bitcoin mining is vulnerable
in financial cryptography and
financial cryptography and data
cryptography and data security
cooperative equilibrium for supergames
the review of economic
review of economic studies
term competition a game
io bitcoin mining pool
kncminer bitcoin mining cloud
bitcoin mining cloud mining
an authorization architecture for
authorization architecture for trustworthy
architecture for trustworthy computing
in proceedings of the
proceedings of the twenty
third acm symposium on
acm symposium on operating
symposium on operating systems
on operating systems principles
on power splitting games
power splitting games in
splitting games in distributed
games in distributed computation
the case of bitcoin
case of bitcoin pooled
of bitcoin pooled mining
weekly bitcoin network statistics
theoretic analysis of ddos
analysis of ddos attacks
of ddos attacks against
ddos attacks against bitcoin
attacks against bitcoin mining
against bitcoin mining pools
in workshop on bitcoin
workshop on bitcoin research
when bitcoin mining pools
bitcoin mining pools run
mining pools run dry
in workshop on bitcoin
workshop on bitcoin research
comparison of mining pools
comparison of mining pools
hashcash amortizable publicly auditable
amortizable publicly auditable cost
hashcash a denial of
a denial of service
denial of service counter
on subversive miner strategies
subversive miner strategies and
miner strategies and block
strategies and block withholding
and block withholding attack
block withholding attack in
withholding attack in bitcoin
attack in bitcoin digital
in bitcoin digital currency
how to disincentivize large
to disincentivize large bitcoin
disincentivize large bitcoin mining
large bitcoin mining pools
the: 7744
of: 4121
a: 3489
to: 3267
and: 3193
in: 2417
is: 1914
for: 1353
that: 1296
with: 990
on: 965
are: 940
we: 925
as: 917
it: 771
by: 745
be: 695
this: 681
data: 659
pool: 659
s: 654
an: 631
at: 630
can: 574
system: 559
its: 497
from: 483
not: 466
or: 452
r: 429
which: 418
each: 404
file: 401
all: 377
systems: 372
m: 368
if: 362
figure: 357
x: 343
one: 338
time: 335
nodes: 332
pools: 325
revenue: 325
t: 325
packets: 320
rate: 320
other: 317
cache: 310
but: 309
our: 291
have: 289
work: 287
i: 282
performance: 281
such: 271
when: 268
loss: 258
p: 258
miners: 257
has: 252
bandwidth: 251
packet: 244
c: 243
network: 242
their: 236
will: 232
attack: 230
block: 230
mining: 230
j: 228
these: 223
than: 222
only: 221
end: 220
use: 220
they: 218
more: 216
node: 209
bitcoin: 204
no: 204
high: 203
number: 202
services: 200
latency: 197
b: 196
may: 193
transactions: 192
would: 192
server: 190
two: 188
where: 188
update: 187
power: 182
between: 180
used: 177
based: 174
d: 173
over: 171
any: 170
different: 169
distributed: 166
miner: 164
new: 164
single: 164
also: 162
client: 161
some: 161
large: 159
tcp: 159
was: 157
web: 157
since: 153
objects: 152
application: 150
ip: 150
service: 150
using: 149
updates: 146
e: 144
protocol: 144
them: 144
set: 140
read: 139
access: 138
applications: 137
process: 137
files: 134
transaction: 133
maelstrom: 132
traffic: 132
there: 131
operating: 130
gossip: 129
however: 129
into: 129
section: 129
withholding: 129
rates: 128
example: 127
mfs: 127
so: 127
communication: 124
consistency: 124
both: 122
same: 122
size: 122
object: 121
priorities: 120
repair: 120
even: 119
peer: 119
throughput: 119
chain: 118
g: 116
control: 114
failure: 114
information: 113
while: 113
first: 112
recovery: 112
were: 112
results: 111
database: 110
protocols: 110
case: 109
acm: 106
link: 106
low: 106
therefore: 106
then: 105
without: 105
rpcs: 104
small: 104
clients: 103
writes: 103
networks: 102
could: 101
second: 101
ms: 100
rpc: 99
do: 98
many: 98
asynchronous: 97
writeback: 97
log: 96
model: 96
within: 96
group: 95
send: 95
does: 94
proof: 94
most: 93
up: 93
memory: 92
state: 91
user: 91
average: 90
content: 90
version: 90
level: 89
order: 89
back: 87
been: 87
support: 87
less: 86
through: 85
windows: 85
available: 84
groups: 84
long: 84
out: 84
see: 84
after: 83
another: 83
approach: 83
fec: 83
full: 83
how: 83
against: 82
architecture: 82
infiltration: 82
message: 82
o: 82
disk: 81
k: 81
messages: 81
need: 81
qsm: 81
about: 80
kb: 80
multicast: 80
sender: 80
uses: 80
management: 79
n: 79
q: 79
way: 79
delivery: 78
total: 78
disks: 77
experiments: 77
possible: 77
write: 77
design: 76
higher: 76
delay: 75
increase: 75
layer: 75
local: 75
research: 75
scale: 75
upload: 75
computer: 74
f: 74
implementation: 74
might: 74
source: 74
analysis: 73
burst: 73
live: 73
probability: 73
workloads: 73
accesses: 72
because: 72
every: 72
lost: 72
solution: 71
cost: 70
due: 70
step: 70
v: 70
value: 70
equilibrium: 69
like: 69
multiple: 69
manager: 68
per: 68
priority: 68
well: 68
list: 67
overhead: 67
computing: 66
load: 66
running: 66
cornell: 65
http: 65
mechanism: 65
opportunistic: 65
run: 65
should: 65
under: 65
attacking: 64
cluster: 64
operations: 64
proceedings: 64
servers: 64
show: 64
shown: 64
test: 64
attacks: 63
layered: 63
much: 63
paper: 63
partial: 63
received: 63
stream: 63
attacker: 62
dependency: 62
kernel: 62
point: 62
solutions: 62
event: 61
l: 61
maximum: 61
must: 61
scheme: 61
shows: 61
sizes: 61
code: 60
game: 60
interleave: 60
prefetching: 60
proofs: 60
replication: 60
result: 60
round: 60
storage: 60
us: 60
perform: 59
sending: 59
very: 59
inconsistency: 58
once: 58
provide: 58
threshold: 58
users: 58
workload: 58
flow: 57
scalable: 57
sent: 57
similar: 57
streaming: 57
being: 56
conference: 56
symposium: 56
download: 55
nt: 55
problem: 55
random: 55
receiver: 55
reduce: 55
requests: 55
until: 55
before: 54
correct: 54
factor: 54
global: 54
graph: 54
interleaving: 54
larger: 54
open: 54
processes: 54
range: 54
retrieved: 54
among: 53
auditing: 53
caching: 53
cannot: 53
h: 53
scenario: 53
center: 52
fetch: 52
mode: 52
real: 52
synchronous: 52
take: 52
transactional: 52
according: 51
form: 51
ieee: 51
increasing: 51
internet: 51
make: 51
present: 51
reads: 51
xor: 51
able: 50
algorithm: 50
current: 50
had: 50
inconsistencies: 50
mobile: 50
store: 50
components: 49
contention: 49
either: 49
existing: 49
hence: 49
mechanisms: 49
mi: 49
now: 49
three: 49
whether: 49
encoding: 48
general: 48
host: 48
implemented: 48
own: 48
prefetch: 48
recovered: 48
reliable: 48
values: 48
although: 47
important: 47
pp: 47
side: 47
w: 47
behavior: 46
execution: 46
fixed: 46
function: 46
generated: 46
graphs: 46
operation: 46
platform: 46
request: 46
speed: 46
th: 46
consider: 45
designed: 45
shared: 45
significant: 45
university: 45
victim: 45
window: 45
attacked: 44
blocks: 44
com: 44
community: 44
delays: 44
density: 44
error: 44
future: 44
hosted: 44
kbps: 44
left: 44
pages: 44
smaller: 44
standard: 44
wide: 44
appliance: 43
changes: 43
component: 43
costs: 43
events: 43
fig: 43
here: 43
makes: 43
ratio: 43
required: 43
right: 43
thus: 43
y: 43
allows: 42
amount: 42
change: 42
developers: 42
distribution: 42
experiment: 42
just: 42
often: 42
rather: 42
scalability: 42
seen: 42
start: 42
tasks: 42
uniform: 42
what: 42
cloud: 41
effect: 41
mafs: 41
missing: 41
numbers: 41
optimal: 41
reduced: 41
simple: 41
ssa: 41
strategy: 41
across: 40
address: 40
detection: 40
down: 40
further: 40
given: 40
hosts: 40
lower: 40
next: 40
non: 40
receive: 40
sends: 40
software: 40
token: 40
typically: 40
allow: 39
caches: 39
cases: 39
congestion: 39
directly: 39
entire: 39
increases: 39
independent: 39
interface: 39
length: 39
original: 39
overheads: 39
part: 39
structure: 39
times: 39
compared: 38
described: 38
direct: 38
during: 38
microsoft: 38
region: 38
require: 38
revenues: 38
world: 38
accessed: 37
al: 37
birman: 37
centers: 37
codes: 37
effective: 37
enough: 37
et: 37
improve: 37
losses: 37
membership: 37
provides: 37
xors: 37
better: 36
clusters: 36
consistent: 36
describe: 36
expected: 36
fact: 36
fast: 36
loyal: 36
previous: 36
related: 36
relative: 36
techniques: 36
today: 36
types: 36
adaptation: 35
additional: 35
almost: 35
commodity: 35
environment: 35
https: 35
international: 35
last: 35
links: 35
longer: 35
minimum: 35
needs: 35
org: 35
performed: 35
proxy: 35
reliability: 35
still: 35
though: 35
above: 34
acid: 34
earlier: 34
evaluation: 34
factors: 34
injection: 34
interleaves: 34
ken: 34
levels: 34
managed: 34
percentage: 34
remote: 34
sets: 34
several: 34
virtual: 34
www: 34
constant: 33
denote: 33
limited: 33
note: 33
overall: 33
particular: 33
receiving: 33
top: 33
working: 33
assume: 32
become: 32
clustered: 32
detect: 32
find: 32
including: 32
period: 32
replicated: 32
scenarios: 32
seconds: 32
space: 32
stable: 32
table: 32
technologies: 32
technology: 32
those: 32
trace: 32
versions: 32
added: 31
ensure: 31
evaluate: 31
finally: 31
follows: 31
immediately: 31
invalidations: 31
least: 31
mb: 31
overlay: 31
prediction: 31
principles: 31
receivers: 31
requires: 31
runs: 31
sirp: 31
target: 31
udp: 31
achieve: 30
adaptive: 30
amazon: 30
auditors: 30
collaboration: 30
correction: 30
dropped: 30
good: 30
incoming: 30
lists: 30
members: 30
performs: 30
policy: 30
recent: 30
ri: 30
schemes: 30
security: 30
share: 30
third: 30
usenix: 30
z: 30
associated: 29
availability: 29
close: 29
commit: 29
complete: 29
delivered: 29
edu: 29
head: 29
key: 29
later: 29
platforms: 29
pull: 29
receives: 29
recover: 29
reducing: 29
science: 29
settings: 29
task: 29
varying: 29
xi: 29
best: 28
configuration: 28
core: 28
dilemma: 28
feasible: 28
implements: 28
issues: 28
making: 28
never: 28
obtain: 28
occur: 28
others: 28
repository: 28
resulting: 28
style: 28
tools: 28
transport: 28
type: 28
area: 27
async: 27
build: 27
building: 27
cached: 27
capacity: 27
collection: 27
failures: 27
following: 27
forward: 27
framework: 27
increased: 27
instance: 27
major: 27
mbps: 27
needed: 27
neighbors: 27
nov: 27
participants: 27
reader: 27
resources: 27
solo: 27
speedup: 27
stored: 27
tm: 27
vn: 27
writer: 27
abort: 26
basic: 26
becomes: 26
benefit: 26
bin: 26
bins: 26
certain: 26
channel: 26
classical: 26
common: 26
consumption: 26
controls: 26
discuss: 26
entry: 26
fault: 26
haul: 26
instead: 26
means: 26
mostly: 26
online: 26
os: 26
solomon: 26
sources: 26
tolerance: 26
vol: 26
allowing: 25
backend: 25
bursts: 25
bursty: 25
choice: 25
conditions: 25
considered: 25
contribution: 25
copy: 25
cs: 25
difficulty: 25
distance: 25
estimate: 25
figures: 25
flows: 25
found: 25
goal: 25
hardware: 25
invalidation: 25
machines: 25
observed: 25
properties: 25
queue: 25
rain: 25
reduces: 25
report: 25
spent: 25
split: 25
takes: 25
transmission: 25
abstract: 24
algorithms: 24
around: 24
blockchain: 24
cause: 24
closed: 24
committed: 24
contrast: 24
correctly: 24
corresponding: 24
critical: 24
datacenters: 24
demand: 24
developed: 24
done: 24
equal: 24
experimental: 24
front: 24
having: 24
idea: 24
individual: 24
infiltrating: 24
knowledge: 24
limit: 24
lock: 24
logs: 24
ny: 24
observe: 24
oriented: 24
peers: 24
place: 24
processing: 24
strategies: 24
streams: 24
structured: 24
too: 24
view: 24
again: 23
approaches: 23
called: 23
choose: 23
create: 23
datacenter: 23
detected: 23
duration: 23
include: 23
layers: 23
likely: 23
majority: 23
member: 23
monitoring: 23
ones: 23
powered: 23
product: 23
reed: 23
sufficient: 23
sync: 23
traditional: 23
unix: 23
ways: 23
workshop: 23
york: 23
alternative: 22
always: 22
avoid: 22
built: 22
certification: 22
connected: 22
consequently: 22
context: 22
defined: 22
dependencies: 22
development: 22
efficient: 22
generate: 22
handle: 22
he: 22
made: 22
maintain: 22
mtu: 22
net: 22
occurs: 22
off: 22
optical: 22
parameters: 22
patterns: 22
popular: 22
problems: 22
revision: 22
starts: 22
via: 22
who: 22
wireless: 22
bandwidths: 21
buffers: 21
centralized: 21
configurations: 21
contains: 21
dynamic: 21
easily: 21
easy: 21
equation: 21
etc: 21
garbage: 21
hand: 21
hash: 21
identical: 21
iii: 21
index: 21
let: 21
life: 21
line: 21
mashup: 21
milliseconds: 21
old: 21
path: 21
private: 21
project: 21
proxies: 21
reasons: 21
response: 21
short: 21
significantly: 21
social: 21
staleness: 21
video: 21
vogels: 21
wait: 21
writing: 21
aggregate: 20
analyze: 20
architectures: 20
benefits: 20
buffering: 20
changing: 20
choosing: 20
consists: 20
four: 20
generates: 20
google: 20
grep: 20
honest: 20
inter: 20
interest: 20
interfaces: 20
library: 20
machine: 20
manner: 20
minibrowser: 20
multi: 20
none: 20
potentially: 20
presence: 20
proc: 20
quality: 20
queued: 20
racs: 20
rapidly: 20
references: 20
respectively: 20
simply: 20
site: 20
stale: 20
together: 20
traces: 20
updated: 20
usa: 20
usage: 20
yet: 20
actually: 19
adding: 19
appropriate: 19
clear: 19
convergence: 19
course: 19
currently: 19
digital: 19
expect: 19
explained: 19
extended: 19
extremely: 19
faster: 19
features: 19
inconsistent: 19
investigation: 19
issue: 19
kind: 19
know: 19
mine: 19
month: 19
natural: 19
networking: 19
om: 19
partition: 19
periods: 19
potential: 19
propagation: 19
proposed: 19
query: 19
quickly: 19
re: 19
recipe: 19
reply: 19
sequence: 19
serializability: 19
soc: 19
speeds: 19
subscribers: 19
taken: 19
towards: 19
transfer: 19
transient: 19
upon: 19
whereas: 19
works: 19
active: 18
aggregation: 18
aware: 18
background: 18
bad: 18
chooses: 18
cpu: 18
databases: 18
difficult: 18
divided: 18
drop: 18
earn: 18
effectiveness: 18
employ: 18
eventually: 18
exchange: 18
failed: 18
feb: 18
fiber: 18
foreground: 18
generation: 18
get: 18
gigabit: 18
heavy: 18
history: 18
identify: 18
includes: 18
initial: 18
itself: 18
known: 18
lambda: 18
latencies: 18
logging: 18
moreover: 18
nash: 18
neither: 18
noted: 18
participating: 18
propose: 18
publish: 18
queries: 18
repositories: 18
roundtrip: 18
sigcomm: 18
specific: 18
study: 18
subversion: 18
summary: 18
switching: 18
synthetic: 18
tokens: 18
topics: 18
unique: 18
varied: 18
various: 18
vary: 18
actual: 17
automatically: 17
chosen: 17
coda: 17
communications: 17
developer: 17
device: 17
devices: 17
don: 17
early: 17
enabled: 17
environments: 17
errors: 17
experience: 17
focus: 17
fraction: 17
functionality: 17
grows: 17
highest: 17
highly: 17
hosting: 17
ii: 17
impact: 17
implement: 17
infrastructure: 17
lines: 17
maintains: 17
modified: 17
module: 17
necessary: 17
offer: 17
partitioning: 17
periodically: 17
products: 17
progress: 17
projects: 17
ran: 17
raps: 17
reach: 17
remain: 17
setting: 17
sharing: 17
simultaneous: 17
specifically: 17
standards: 17
subservice: 17
successfully: 17
supported: 17
switch: 17
symmetric: 17
term: 17
transmitted: 17
van: 17
variety: 17
years: 17
acts: 16
already: 16
axis: 16
believe: 16
buffer: 16
bytes: 16
call: 16
chainsaw: 16
clustering: 16
compare: 16
configured: 16
conflicts: 16
connectivity: 16
contents: 16
conventional: 16
created: 16
define: 16
demonstrate: 16
difference: 16
efficacy: 16
examples: 16
fees: 16
few: 16
ghash: 16
go: 16
hard: 16
illustrated: 16
implications: 16
indeed: 16
infiltrate: 16
integration: 16
io: 16
kinds: 16
lead: 16
limiting: 16
linux: 16
little: 16
main: 16
market: 16
measurements: 16
modes: 16
operate: 16
options: 16
page: 16
parallel: 16
physical: 16
points: 16
prisoner: 16
publishes: 16
registered: 16
requirements: 16
serialization: 16
simulation: 16
simultaneously: 16
status: 16
strong: 16
sub: 16
subsystem: 16
themselves: 16
timestamp: 16
topic: 16
transparently: 16
typical: 16
accessing: 15
adapt: 15
applied: 15
arrive: 15
atp: 15
attempt: 15
bar: 15
bc: 15
comparison: 15
containing: 15
contribute: 15
corba: 15
department: 15
describes: 15
diff: 15
edge: 15
effects: 15
exists: 15
fire: 15
gc: 15
greater: 15
idle: 15
included: 15
infiltrated: 15
info: 15
june: 15
latter: 15
linear: 15
maintaining: 15
namely: 15
november: 15
oms: 15
optimize: 15
outgoing: 15
paths: 15
performing: 15
practice: 15
predictable: 15
programming: 15
regions: 15
regular: 15
renesse: 15
represents: 15
respond: 15
sense: 15
sirer: 15
slightly: 15
slow: 15
statistics: 15
stores: 15
supercomputing: 15
teragrid: 15
thousands: 15
tier: 15
underlying: 15
uniformly: 15
whole: 15
accept: 14
addition: 14
arise: 14
balancing: 14
bounded: 14
channels: 14
class: 14
combined: 14
commits: 14
conclusion: 14
concurrency: 14
currency: 14
decrease: 14
deliver: 14
destination: 14
detects: 14
differentiated: 14
directory: 14
dissemination: 14
distinct: 14
drops: 14
engineering: 14
entries: 14
exactly: 14
explore: 14
fail: 14
fifo: 14
financial: 14
finding: 14
growing: 14
guarantees: 14
handling: 14
help: 14
improves: 14
infiltrators: 14
integrated: 14
interested: 14
involves: 14
malicious: 14
modern: 14
option: 14
perfect: 14
policies: 14
prevent: 14
previously: 14
prior: 14
program: 14
providing: 14
published: 14
question: 14
relatively: 14
sabotage: 14
search: 14
singleton: 14
soon: 14
spread: 14
starting: 14
temporarily: 14
thread: 14
tolerate: 14
turn: 14
useful: 14
xj: 14
zookeeper: 14
achieved: 13
add: 13
afs: 13
annual: 13
avg: 13
balance: 13
bound: 13
collaborative: 13
collect: 13
compile: 13
completely: 13
computation: 13
concurrent: 13
consisting: 13
constraints: 13
decreases: 13
depends: 13
determine: 13
determined: 13
did: 13
digests: 13
discarded: 13
dominant: 13
dynamically: 13
embedded: 13
epidemic: 13
exception: 13
eyal: 13
face: 13
far: 13
field: 13
free: 13
frequently: 13
fundamental: 13
generating: 13
gives: 13
grained: 13
growth: 13
his: 13
hit: 13
instances: 13
intended: 13
interactive: 13
interval: 13
intervals: 13
introduction: 13
join: 13
lack: 13
location: 13
magnitude: 13
measure: 13
mentioned: 13
missed: 13
modeless: 13
nfm: 13
normal: 13
notice: 13
ntfs: 13
overview: 13
paradigm: 13
positive: 13
proportional: 13
provided: 13
public: 13
radient: 13
receipt: 13
registers: 13
relevant: 13
remains: 13
researchers: 13
robust: 13
rtt: 13
semantics: 13
setup: 13
shares: 13
situations: 13
special: 13
static: 13
structures: 13
subscribe: 13
thousand: 13
tool: 13
track: 13
trade: 13
tree: 13
unbounded: 13
written: 13
aborted: 12
academic: 12
acceptable: 12
account: 12
accurate: 12
balakrishnan: 12
base: 12
below: 12
ca: 12
capable: 12
caused: 12
challenges: 12
classes: 12
conclude: 12
copies: 12
creating: 12
cumulative: 12
date: 12
decentralized: 12
decide: 12
dedicated: 12
definition: 12
delayed: 12
despite: 12
efficiency: 12
element: 12
enterprise: 12
facts: 12
fairly: 12
footprint: 12
generally: 12
half: 12
hashcash: 12
html: 12
ing: 12
interactions: 12
introduced: 12
iv: 12
ix: 12
jan: 12
java: 12
keep: 12
leads: 12
lfs: 12
li: 12
limitations: 12
locking: 12
maintained: 12
near: 12
obtained: 12
opportunity: 12
oracle: 12
ordering: 12
orders: 12
otherwise: 12
overlap: 12
particularly: 12
past: 12
practical: 12
primary: 12
purposes: 12
push: 12
reason: 12
recently: 12
redundant: 12
rescue: 12
review: 12
roles: 12
roughly: 12
sort: 12
specify: 12
spikes: 12
stack: 12
subset: 12
taking: 12
technique: 12
ten: 12
tms: 12
unif: 12
whenever: 12
you: 12
achieving: 11
acknowledgments: 11
activity: 11
advance: 11
aggregated: 11
argue: 11
authors: 11
automated: 11
basis: 11
begin: 11
callback: 11
complex: 11
converge: 11
crash: 11
deal: 11
deployed: 11
detail: 11
details: 11
detecting: 11
discussion: 11
energy: 11
ensures: 11
equivalent: 11
evict: 11
fa: 11
fee: 11
fetches: 11
fetching: 11
finds: 11
flexible: 11
focused: 11
heterogeneous: 11
hot: 11
hundreds: 11
identifiers: 11
illustrates: 11
implementing: 11
improvements: 11
incorporates: 11
increasingly: 11
indicate: 11
insufficient: 11
interact: 11
introduce: 11
involved: 11
ithaca: 11
largest: 11
layout: 11
linearly: 11
logged: 11
maintenance: 11
measurement: 11
metadata: 11
modal: 11
moving: 11
name: 11
orkut: 11
osdi: 11
pair: 11
parameter: 11
partitioned: 11
prefetches: 11
privacy: 11
processed: 11
prove: 11
providers: 11
randomly: 11
readers: 11
realistic: 11
recovers: 11
replace: 11
replicas: 11
requiring: 11
responsible: 11
retransmission: 11
role: 11
routine: 11
sample: 11
scheduling: 11
sensitive: 11
sep: 11
separate: 11
serve: 11
simplicity: 11
stock: 11
strictly: 11
subsequent: 11
supporting: 11
supports: 11
true: 11
trusted: 11
try: 11
unlikely: 11
unshared: 11
valid: 11
ve: 11
white: 11
whose: 11
xml: 11
accuracy: 10
ack: 10
additionally: 10
along: 10
appear: 10
arg: 10
assumption: 10
asynchronously: 10
becoming: 10
bitcoins: 10
bottleneck: 10
cc: 10
cdn: 10
check: 10
checks: 10
compares: 10
conflict: 10
constructed: 10
continuous: 10
dec: 10
decision: 10
decisions: 10
degenerate: 10
degree: 10
depend: 10
desired: 10
detailed: 10
discussed: 10
distinguish: 10
distributes: 10
effectively: 10
efforts: 10
elements: 10
enable: 10
enhancing: 10
epidemics: 10
especially: 10
evaluated: 10
eventual: 10
examine: 10
expensive: 10
experienced: 10
fairness: 10
false: 10
final: 10
fine: 10
forms: 10
give: 10
gracefully: 10
ideal: 10
improving: 10
infiltrates: 10
injected: 10
ipc: 10
isn: 10
journal: 10
language: 10
leverage: 10
map: 10
maps: 10
mesh: 10
methods: 10
microbenchmarks: 10
minutes: 10
miss: 10
networked: 10
nevertheless: 10
news: 10
novel: 10
overlapping: 10
paxos: 10
pending: 10
possibility: 10
presented: 10
presents: 10
proceed: 10
pushing: 10
rapid: 10
really: 10
recall: 10
remainder: 10
reported: 10
reports: 10
representing: 10
rest: 10
return: 10
rise: 10
robbert: 10
router: 10
routes: 10
routing: 10
runtime: 10
sampling: 10
scales: 10
segment: 10
situation: 10
studies: 10
subject: 10
success: 10
synchrony: 10
tail: 10
team: 10
technical: 10
tests: 10
theorem: 10
think: 10
thresholds: 10
throughout: 10
tion: 10
transparent: 10
unlike: 10
unstable: 10
usually: 10
utility: 10
variant: 10
visible: 10
volume: 10
widely: 10
zone: 10
achieves: 9
advantages: 9
alarm: 9
allowed: 9
appliances: 9
apply: 9
assigned: 9
assigns: 9
assumed: 9
attackers: 9
august: 9
behave: 9
beneficial: 9
break: 9
causing: 9
central: 9
changed: 9
co: 9
commercial: 9
companies: 9
comparing: 9
competing: 9
compute: 9
computers: 9
confidence: 9
connections: 9
continue: 9
curves: 9
daily: 9
default: 9
degradation: 9
depending: 9
deterministic: 9
developing: 9
dirty: 9
discards: 9
disconnected: 9
domain: 9
ec: 9
ee: 9
efficiently: 9
eliminate: 9
en: 9
entirely: 9
execute: 9
explicit: 9
explored: 9
expression: 9
fails: 9
fashion: 9
fd: 9
force: 9
forming: 9
forwarding: 9
frequency: 9
fully: 9
functions: 9
grant: 9
grow: 9
gw: 9
hide: 9
hierarchy: 9
hold: 9
id: 9
ideally: 9
identifier: 9
importance: 9
incentive: 9
inexpensive: 9
infocom: 9
initially: 9
intel: 9
investigate: 9
iperf: 9
iterative: 9
john: 9
kept: 9
knows: 9
leaving: 9
loads: 9
lose: 9
lossless: 9
lowest: 9
maximize: 9
media: 9
merlin: 9
middle: 9
middleware: 9
minor: 9
modifications: 9
modify: 9
modules: 9
nsdi: 9
owner: 9
pattern: 9
permutation: 9
places: 9
plan: 9
profitable: 9
programmer: 9
prone: 9
proportion: 9
quite: 9
reached: 9
reading: 9
records: 9
reflect: 9
respect: 9
retry: 9
ricochet: 9
rings: 9
risk: 9
rounds: 9
rw: 9
sampled: 9
sd: 9
sec: 9
segments: 9
selected: 9
self: 9
session: 9
shall: 9
showing: 9
sigmod: 9
sosp: 9
specialized: 9
steps: 9
susceptible: 9
terms: 9
threads: 9
tolerant: 9
topology: 9
transfers: 9
transformation: 9
transitions: 9
transmitting: 9
trip: 9
ttl: 9
unacknowledged: 9
unless: 9
upcall: 9
vi: 9
viii: 9
want: 9
werner: 9
academia: 8
accordingly: 8
activities: 8
adds: 8
advantage: 8
affect: 8
affects: 8
afrl: 8
aggregates: 8
allocation: 8
amounts: 8
api: 8
arbitrary: 8
arrays: 8
arxiv: 8
aspects: 8
attributes: 8
auditor: 8
automatic: 8
away: 8
backup: 8
behind: 8
beyond: 8
breaks: 8
buffered: 8
byte: 8
cbcb: 8
challenge: 8
charge: 8
checking: 8
clock: 8
collected: 8
combine: 8
come: 8
competition: 8
compromised: 8
concurrently: 8
confirm: 8
congested: 8
connecting: 8
consecutive: 8
contributing: 8
coordinator: 8
corresponds: 8
creates: 8
currencies: 8
dark: 8
david: 8
de: 8
degrades: 8
densities: 8
deploy: 8
deployment: 8
detectors: 8
differs: 8
dogecoin: 8
drag: 8
driven: 8
earns: 8
eligius: 8
employed: 8
engage: 8
equations: 8
equipment: 8
essentially: 8
ever: 8
exact: 8
executed: 8
exist: 8
extensions: 8
external: 8
extreme: 8
favor: 8
filesystem: 8
gib: 8
greatly: 8
header: 8
histograms: 8
honestly: 8
ideas: 8
improvement: 8
input: 8
insight: 8
interaction: 8
jgroups: 8
largely: 8
leader: 8
leading: 8
leave: 8
lemma: 8
light: 8
limits: 8
litecoin: 8
look: 8
mashups: 8
masks: 8
massive: 8
match: 8
max: 8
mc: 8
measuring: 8
method: 8
minimize: 8
misbehaving: 8
mixed: 8
modeled: 8
models: 8
modification: 8
move: 8
neighbor: 8
nominal: 8
nor: 8
notification: 8
notifications: 8
oct: 8
offers: 8
ordered: 8
papers: 8
participation: 8
payoff: 8
perhaps: 8
perturbed: 8
placed: 8
played: 8
plot: 8
portion: 8
prioritised: 8
purpose: 8
put: 8
react: 8
recovering: 8
refer: 8
refrain: 8
replaced: 8
reservation: 8
reservations: 8
retransmissions: 8
returned: 8
reward: 8
robin: 8
sdn: 8
sections: 8
senders: 8
september: 8
series: 8
serves: 8
similarly: 8
simulate: 8
sink: 8
sm: 8
solve: 8
sometimes: 8
span: 8
specification: 8
specified: 8
stacks: 8
staggered: 8
stepwise: 8
strict: 8
subsequently: 8
substituting: 8
suitable: 8
surprisingly: 8
timer: 8
turns: 8
twice: 8
unusable: 8
verify: 8
views: 8
wang: 8
weak: 8
weather: 8
weekly: 8
wiki: 8
ws: 8
xc: 8
aborting: 7
abstraction: 7
acceptors: 7
acknowledged: 7
air: 7
apache: 7
applying: 7
architectural: 7
arises: 7
array: 7
attractive: 7
belongs: 7
big: 7
broadcast: 7
bsd: 7
byzantine: 7
calculate: 7
card: 7
causes: 7
cb: 7
characteristics: 7
cisco: 7
claim: 7
cleaning: 7
cleanup: 7
clearly: 7
closer: 7
collapse: 7
communities: 7
completion: 7
complexity: 7
concept: 7
conflicting: 7
connection: 7
considering: 7
consistently: 7
construct: 7
contemporary: 7
contributions: 7
cooperative: 7
counter: 7
creation: 7
dashed: 7
december: 7
decoupling: 7
degraded: 7
delaying: 7
demers: 7
deploying: 7
dept: 7
derived: 7
designs: 7
deter: 7
determining: 7
display: 7
disrupt: 7
doesn: 7
doing: 7
dolev: 7
downstream: 7
easier: 7
elapsed: 7
electronic: 7
eliminated: 7
eliminates: 7
employs: 7
empty: 7
emulab: 7
enabling: 7
equally: 7
everything: 7
exchanges: 7
experiences: 7
exploit: 7
exponential: 7
extend: 7
feature: 7
feedback: 7
feeds: 7
fires: 7
fit: 7
follow: 7
furthermore: 7
gaining: 7
gray: 7
guarantee: 7
handles: 7
hour: 7
huge: 7
ignored: 7
image: 7
implementations: 7
importantly: 7
incoherent: 7
incorporate: 7
inferior: 7
introduces: 7
inventory: 7
isis: 7
isolation: 7
january: 7
joseph: 7
keys: 7
latest: 7
lbfs: 7
located: 7
locations: 7
ma: 7
mahesh: 7
mapping: 7
mica: 7
mines: 7
ml: 7
mod: 7
modeling: 7
modifying: 7
motivation: 7
multicasts: 7
nature: 7
negligible: 7
nothing: 7
nsf: 7
oblivious: 7
observation: 7
obvious: 7
october: 7
operator: 7
optimistic: 7
overloaded: 7
partitions: 7
percentile: 7
persistent: 7
plus: 7
poorly: 7
population: 7
pre: 7
prefer: 7
press: 7
prime: 7
programs: 7
propagated: 7
prototype: 7
publishing: 7
rack: 7
rarely: 7
rc: 7
reaches: 7
record: 7
reflects: 7
regarding: 7
register: 7
regularly: 7
relaying: 7
rely: 7
repeated: 7
represent: 7
represented: 7
requesting: 7
resistant: 7
restart: 7
retailer: 7
retrieve: 7
rich: 7
route: 7
routers: 7
san: 7
savings: 7
scaling: 7
seamlessly: 7
seek: 7
sharply: 7
she: 7
simplify: 7
simulations: 7
simulator: 7
sites: 7
socket: 7
sockets: 7
springer: 7
stop: 7
storing: 7
subservices: 7
substantially: 7
successful: 7
timeout: 7
tradeoff: 7
trans: 7
transition: 7
transmit: 7
treat: 7
treated: 7
trees: 7
trust: 7
twenty: 7
u: 7
ubiquitous: 7
unaware: 7
unchanged: 7
useless: 7
utilization: 7
validation: 7
variation: 7
vendor: 7
vendors: 7
versus: 7
vii: 7
violating: 7
wan: 7
year: 7
yield: 7
yields: 7
yu: 7
accommodate: 6
achievable: 6
acknowledgement: 6
act: 6
acting: 6
addressed: 6
addresses: 6
adjustment: 6
administrators: 6
affected: 6
afosr: 6
agreement: 6
alternatives: 6
analyzed: 6
apparently: 6
appropriately: 6
argument: 6
arrives: 6
assumptions: 6
atomic: 6
averages: 6
avoids: 6
bars: 6
begins: 6
berkeley: 6
bonneau: 6
bottom: 6
boundaries: 6
broadly: 6
bullet: 6
california: 6
calls: 6
catch: 6
checkpoint: 6
checksum: 6
chen: 6
closely: 6
clouds: 6
clr: 6
coherent: 6
combination: 6
combines: 6
comes: 6
command: 6
comprised: 6
comput: 6
concave: 6
conducted: 6
conjunction: 6
consensus: 6
conservative: 6
considerable: 6
contain: 6
controlled: 6
coordinate: 6
copying: 6
corporation: 6
costly: 6
coupled: 6
crashed: 6
cross: 6
curve: 6
customize: 6
darpa: 6
dates: 6
db: 6
debian: 6
denotes: 6
dependent: 6
deployments: 6
description: 6
detector: 6
determines: 6
develop: 6
digest: 6
discusfish: 6
disjoint: 6
disseminate: 6
divides: 6
document: 6
draw: 6
druschel: 6
durability: 6
earth: 6
ed: 6
effort: 6
egress: 6
eliminating: 6
email: 6
erasure: 6
established: 6
expressions: 6
facebook: 6
feasibility: 6
feed: 6
fifth: 6
fill: 6
focuses: 6
forced: 6
forks: 6
former: 6
foundation: 6
frame: 6
france: 6
gbps: 6
generic: 6
hashing: 6
heartbeat: 6
hidden: 6
histories: 6
hop: 6
huang: 6
imposed: 6
improved: 6
inc: 6
indicates: 6
industry: 6
ingress: 6
intensive: 6
intercepted: 6
intermediate: 6
issued: 6
issuing: 6
kncminer: 6
krzysztof: 6
lacking: 6
lamport: 6
lan: 6
lans: 6
lcm: 6
ledger: 6
loaded: 6
locally: 6
logical: 6
lt: 6
luu: 6
manage: 6
master: 6
matching: 6
maxx: 6
mean: 6
measured: 6
min: 6
mission: 6
modifies: 6
moment: 6
moves: 6
mp: 6
multicasting: 6
my: 6
naturally: 6
nd: 6
nearly: 6
necessarily: 6
noble: 6
nonce: 6
normalizes: 6
notion: 6
numbered: 6
numerical: 6
numerous: 6
occurring: 6
older: 6
operators: 6
optimized: 6
oscillatory: 6
ostrowski: 6
outlined: 6
outperforms: 6
output: 6
overload: 6
pareto: 6
parties: 6
passive: 6
pdf: 6
perfectly: 6
permit: 6
perspective: 6
phase: 6
play: 6
pooled: 6
possibly: 6
powerful: 6
predict: 6
prefix: 6
price: 6
primarily: 6
procedure: 6
produced: 6
publicly: 6
publisher: 6
pulls: 6
punish: 6
questions: 6
queuing: 6
qwest: 6
reachable: 6
red: 6
reduction: 6
redundancy: 6
reject: 6
repeatedly: 6
replay: 6
replicate: 6
resource: 6
resulted: 6
returns: 6
reveals: 6
rewards: 6
rig: 6
ring: 6
rj: 6
rules: 6
samples: 6
satyanarayanan: 6
say: 6
seattle: 6
seems: 6
select: 6
sensitivity: 6
serialized: 6
six: 6
slowly: 6
snapshot: 6
solving: 6
somewhat: 6
sorts: 6
standardized: 6
states: 6
straightforward: 6
stratum: 6
suggested: 6
summarize: 6
sun: 6
super: 6
supplies: 6
switzerland: 6
synchronization: 6
targeted: 6
tat: 6
thank: 6
theory: 6
timeouts: 6
tit: 6
toolkit: 6
tracking: 6
transmits: 6
trigger: 6
trying: 6
txnid: 6
ultimately: 6
understand: 6
unfortunately: 6
unreliable: 6
usability: 6
usable: 6
validate: 6
variability: 6
variations: 6
vast: 6
vector: 6
vldb: 6
welsh: 6
why: 6
withheld: 6
won: 6
workers: 6
worse: 6
xxx: 6
yahoo: 6
zhang: 6
zhu: 6
ability: 5
absence: 5
absolute: 5
acknowledgements: 5
acknowledgment: 5
acl: 5
adapting: 5
adjusting: 5
ago: 5
agree: 5
ahead: 5
allocated: 5
anyone: 5
append: 5
approximate: 5
arbitrarily: 5
arguably: 5
arrival: 5
assuming: 5
atkin: 5
atomicity: 5
attempts: 5
author: 5
avoiding: 5
award: 5
backed: 5
band: 5
behalf: 5
behaves: 5
belong: 5
bit: 5
bits: 5
blocking: 5
brevity: 5
brewer: 5
broken: 5
broker: 5
buildings: 5
bus: 5
calculated: 5
calculates: 5
capture: 5
carry: 5
catches: 5
caught: 5
chains: 5
cheap: 5
cheriton: 5
classified: 5
cloned: 5
collapses: 5
comments: 5
communicate: 5
communicates: 5
compose: 5
concern: 5
concerns: 5
consequence: 5
considerations: 5
constitutes: 5
constrained: 5
consume: 5
consuming: 5
contact: 5
continuously: 5
coolstreaming: 5
cope: 5
count: 5
counts: 5
crashes: 5
credentials: 5
crossing: 5
customers: 5
danny: 5
datagram: 5
day: 5
dealing: 5
defense: 5
demands: 5
demonstrated: 5
denial: 5
denoted: 5
depict: 5
describing: 5
df: 5
dialog: 5
direction: 5
division: 5
dramatic: 5
dsn: 5
edition: 5
eferences: 5
eight: 5
elaborate: 5
elated: 5
embedding: 5
emerging: 5
employing: 5
encourage: 5
encryption: 5
enforce: 5
ephemeral: 5
estimated: 5
ethernet: 5
exceed: 5
except: 5
exhibit: 5
explain: 5
explicitly: 5
exploiting: 5
exploring: 5
expressed: 5
falls: 5
faults: 5
faulty: 5
filtering: 5
firing: 5
flexibility: 5
forces: 5
forwarded: 5
frames: 5
freebsd: 5
frequent: 5
gap: 5
generality: 5
geo: 5
geographical: 5
gigabits: 5
gribble: 5
grid: 5
ground: 5
gu: 5
hacker: 5
health: 5
hierarchical: 5
highperformance: 5
hints: 5
hooks: 5
human: 5
identification: 5
illustrate: 5
imagine: 5
implicit: 5
implies: 5
inaccurate: 5
incorrect: 5
incrementally: 5
incurs: 5
independently: 5
informatik: 5
informatique: 5
innovation: 5
instantly: 5
integrating: 5
interesting: 5
interference: 5
internal: 5
interoperability: 5
invalidate: 5
investigated: 5
investigator: 5
iptv: 5
isps: 5
ittay: 5
johnson: 5
joining: 5
joins: 5
katz: 5
kleinberg: 5
lakshmi: 5
languages: 5
layouts: 5
learn: 5
leases: 5
lengths: 5
lightweight: 5
linking: 5
liu: 5
locality: 5
locks: 5
logic: 5
looking: 5
lossy: 5
mar: 5
marketing: 5
mask: 5
messaging: 5
metrics: 5
minibrowsers: 5
minority: 5
monitors: 5
monthly: 5
moved: 5
mutual: 5
national: 5
normally: 5
ntroduction: 5
observations: 5
obtains: 5
occasional: 5
occurred: 5
offered: 5
omit: 5
omitted: 5
onclusion: 5
onon: 5
optimization: 5
optimizations: 5
optimizes: 5
organization: 5
organizations: 5
organized: 5
originally: 5
orthogonal: 5
outside: 5
overcome: 5
pairs: 5
partially: 5
passed: 5
pause: 5
pay: 5
pays: 5
peerto: 5
people: 5
percentages: 5
permitting: 5
personal: 5
pf: 5
phenomenon: 5
placement: 5
plots: 5
poison: 5
positives: 5
precisely: 5
predictor: 5
predictors: 5
probabilistic: 5
proceeds: 5
progresses: 5
property: 5
proprietary: 5
protected: 5
proved: 5
punished: 5
quick: 5
raise: 5
rare: 5
raw: 5
rd: 5
reaching: 5
regardless: 5
release: 5
reliance: 5
remaining: 5
remove: 5
repairs: 5
repeat: 5
requested: 5
requirement: 5
resilience: 5
resolve: 5
respects: 5
responsiveness: 5
restrictions: 5
reveal: 5
rizzo: 5
road: 5
robustness: 5
satisfactory: 5
satisfied: 5
save: 5
saving: 5
scheduled: 5
schneider: 5
seem: 5
sees: 5
selecting: 5
sensors: 5
separated: 5
separately: 5
sequenced: 5
serializable: 5
sessions: 5
shard: 5
shards: 5
signal: 5
simulated: 5
sized: 5
slack: 5
slower: 5
sophisticated: 5
soule: 5
speculative: 5
sprint: 5
stated: 5
stay: 5
studied: 5
submit: 5
substantial: 5
subsystems: 5
suffer: 5
sum: 5
summarized: 5
suspicion: 5
switched: 5
switches: 5
tech: 5
tell: 5
temporary: 5
texture: 5
thinking: 5
tightly: 5
timely: 5
timestamps: 5
tocs: 5
topologies: 5
tracks: 5
transform: 5
transformations: 5
trap: 5
treating: 5
trend: 5
trends: 5
triggers: 5
tune: 5
tuning: 5
turned: 5
unable: 5
unexpected: 5
unit: 5
unpredictable: 5
untrusted: 5
updating: 5
upper: 5
ut: 5
utilisation: 5
verifying: 5
viewed: 5
volatile: 5
vs: 5
waiting: 5
walk: 5
wall: 5
wants: 5
win: 5
wired: 5
writers: 5
ycsb: 5
yx: 5
ab: 4
abbadi: 4
ac: 4
accepted: 4
acks: 4
action: 4
actions: 4
adopted: 4
advanced: 4
advances: 4
agrawal: 4
alone: 4
alongside: 4
alternate: 4
alvisi: 4
amir: 4
amortizable: 4
analogous: 4
andrew: 4
answer: 4
antpool: 4
applicable: 4
approximated: 4
april: 4
archive: 4
arrow: 4
aspect: 4
assign: 4
assumes: 4
athey: 4
awkward: 4
bahack: 4
ballots: 4
banking: 4
behaviour: 4
benchmark: 4
bernstein: 4
biersack: 4
bifurcations: 4
bitcointalk: 4
blade: 4
blast: 4
blend: 4
blocked: 4
blogspot: 4
border: 4
boxes: 4
brief: 4
briefly: 4
broadcasts: 4
broader: 4
bulk: 4
burstier: 4
calculator: 4
callbacks: 4
caller: 4
capitalization: 4
captures: 4
carefully: 4
certainly: 4
charts: 4
chat: 4
city: 4
clean: 4
clones: 4
closes: 4
cms: 4
collecting: 4
collector: 4
combining: 4
coming: 4
comparable: 4
compensated: 4
compiles: 4
completed: 4
complicated: 4
componentized: 4
composition: 4
comprehensive: 4
compromise: 4
conduct: 4
confirms: 4
consequences: 4
consist: 4
contained: 4
continued: 4
converges: 4
cooperation: 4
correlated: 4
correlation: 4
courtois: 4
crucial: 4
cryptography: 4
cutting: 4
cycle: 4
danger: 4
das: 4
debugging: 4
decades: 4
decided: 4
declining: 4
deep: 4
deferred: 4
defines: 4
demonstrates: 4
desktop: 4
devastating: 4
di: 4
differences: 4
differentiate: 4
differently: 4
directed: 4
directions: 4
directories: 4
disaster: 4
discovery: 4
discussions: 4
disloyal: 4
disrupted: 4
disruption: 4
distant: 4
distribute: 4
distributions: 4
double: 4
ease: 4
ebay: 4
economic: 4
editor: 4
educause: 4
elsewhere: 4
emin: 4
emulate: 4
encoder: 4
encodes: 4
endhosts: 4
enforcing: 4
engages: 4
engineer: 4
enhanced: 4
enormous: 4
enter: 4
envelope: 4
epi: 4
eprint: 4
esb: 4
evenly: 4
evicting: 4
evidence: 4
evil: 4
ex: 4
examines: 4
exchanged: 4
exclusive: 4
executing: 4
existence: 4
export: 4
exposed: 4
extensive: 4
faber: 4
faced: 4
familiar: 4
february: 4
filter: 4
firewalls: 4
five: 4
fixing: 4
flowing: 4
flush: 4
flushes: 4
focusing: 4
followed: 4
formula: 4
foster: 4
fourth: 4
fragmentation: 4
francis: 4
francisco: 4
freedman: 4
friendly: 4
gain: 4
games: 4
gateways: 4
gathered: 4
gets: 4
globally: 4
goes: 4
going: 4
graceful: 4
grants: 4
grateful: 4
grossklags: 4
hackingdistributed: 4
hakim: 4
heartbeats: 4
heavily: 4
helps: 4
hint: 4
holds: 4
home: 4
honeypot: 4
hope: 4
horus: 4
hweather: 4
identified: 4
identifying: 4
identity: 4
ids: 4
ignore: 4
images: 4
impacted: 4
impossible: 4
inaccessible: 4
incorporating: 4
incurred: 4
incurring: 4
inform: 4
initiated: 4
initiative: 4
inquiry: 4
integral: 4
integrate: 4
intelligent: 4
intend: 4
interacts: 4
interrupted: 4
intervening: 4
intrinsically: 4
introducing: 4
invalidated: 4
invalidating: 4
isbn: 4
javascript: 4
jboss: 4
jelasity: 4
joint: 4
jose: 4
july: 4
jumbo: 4
jxta: 4
kaashoek: 4
keeping: 4
keidar: 4
kermarrec: 4
kj: 4
korn: 4
lacks: 4
lakshman: 4
laszka: 4
leaders: 4
learning: 4
leaves: 4
letting: 4
leveraging: 4
libraries: 4
lies: 4
listed: 4
lived: 4
ll: 4
logsim: 4
longdistance: 4
looked: 4
lru: 4
maid: 4
malfunctioning: 4
managing: 4
marked: 4
matched: 4
matrix: 4
maximizes: 4
measures: 4
merely: 4
methodology: 4
miles: 4
military: 4
miller: 4
mind: 4
minimal: 4
minted: 4
minute: 4
misconfigured: 4
misses: 4
mix: 4
mixture: 4
mobility: 4
modulating: 4
monitor: 4
monopoly: 4
moore: 4
msg: 4
mtus: 4
naive: 4
nak: 4
namecoin: 4
narrow: 4
netfilter: 4
normalized: 4
notable: 4
notify: 4
numerically: 4
obstacles: 4
obtaining: 4
offering: 4
ools: 4
operates: 4
optimum: 4
organofcorti: 4
ork: 4
outstanding: 4
owners: 4
ownership: 4
packages: 4
parameterized: 4
participate: 4
parts: 4
patient: 4
paul: 4
payments: 4
payout: 4
payouts: 4
peak: 4
penalty: 4
peps: 4
periodic: 4
permacoin: 4
permutations: 4
person: 4
perspectives: 4
pfldnet: 4
phenomena: 4
php: 4
pi: 4
picked: 4
pictures: 4
placing: 4
player: 4
plotting: 4
podc: 4
poll: 4
polling: 4
positions: 4
practicality: 4
predicted: 4
preferred: 4
preprint: 4
pressure: 4
prevents: 4
pricing: 4
primitives: 4
principle: 4
probabilities: 4
probably: 4
prominent: 4
promising: 4
protect: 4
provisioned: 4
provisioning: 4
pub: 4
publication: 4
pulled: 4
purely: 4
qi: 4
qp: 4
quantities: 4
quantum: 4
querying: 4
readset: 4
reality: 4
realize: 4
reasonable: 4
reference: 4
reflected: 4
regional: 4
rejoin: 4
relation: 4
relations: 4
reliably: 4
removed: 4
reno: 4
repairing: 4
replacement: 4
replicating: 4
repo: 4
reserved: 4
residing: 4
resilient: 4
resolution: 4
resolved: 4
responding: 4
responses: 4
retailers: 4
retransmit: 4
rev: 4
revoke: 4
rigs: 4
rk: 4
robert: 4
root: 4
rosenfeld: 4
routed: 4
rover: 4
rowstron: 4
rule: 4
safety: 4
saturate: 4
saw: 4
scan: 4
secondary: 4
secret: 4
secure: 4
secured: 4
seeks: 4
selective: 4
selfish: 4
separates: 4
sequences: 4
sequentially: 4
sha: 4
shasha: 4
shenker: 4
shift: 4
shut: 4
silver: 4
situational: 4
sixteenth: 4
smalltalk: 4
smart: 4
smr: 4
sold: 4
spanning: 4
spun: 4
srm: 4
standardization: 4
statistically: 4
steadily: 4
steady: 4
stress: 4
stronger: 4
strongly: 4
students: 4
subjected: 4
subsection: 4
successes: 4
suffers: 4
sums: 4
suspected: 4
symmetry: 4
synchronized: 4
tackle: 4
tailored: 4
technological: 4
tens: 4
terminology: 4
terrain: 4
terry: 4
tested: 4
theoretic: 4
things: 4
threaded: 4
took: 4
tornado: 4
touched: 4
towsley: 4
traced: 4
tradeoffs: 4
trading: 4
translate: 4
travel: 4
treats: 4
tremendous: 4
trial: 4
truly: 4
tuple: 4
understanding: 4
undesirable: 4
units: 4
unknown: 4
unusual: 4
upstream: 4
usd: 4
usual: 4
utilities: 4
vahdat: 4
valuable: 4
variable: 4
variants: 4
varies: 4
vfs: 4
viable: 4
vice: 4
visual: 4
von: 4
vulnerable: 4
waits: 4
walsh: 4
washington: 4
weakly: 4
weatherspoon: 4
weight: 4
wish: 4
withhold: 4
worked: 4
worst: 4
worth: 4
writeset: 4
wrong: 4
xk: 4
xkj: 4
yearly: 4
your: 4
abadi: 3
aborts: 3
accepting: 3
accepts: 3
accountable: 3
accumulated: 3
accusations: 3
acidrain: 3
acknowledge: 3
acquire: 3
actively: 3
adapts: 3
adequate: 3
adjust: 3
advancing: 3
advantageous: 3
advertisements: 3
afec: 3
affecting: 3
aggregating: 3
agnostic: 3
aguilera: 3
aimed: 3
aircraft: 3
alan: 3
albeit: 3
alberta: 3
album: 3
alert: 3
alerts: 3
alleviate: 3
amenable: 3
analytical: 3
analytically: 3
anomaly: 3
anything: 3
app: 3
apparent: 3
appears: 3
ar: 3
areas: 3
aren: 3
argued: 3
arising: 3
arla: 3
assertion: 3
assess: 3
assigning: 3
assignment: 3
association: 3
assure: 3
attribute: 3
auditable: 3
aug: 3
authorization: 3
avatars: 3
avoided: 3
backbone: 3
balancer: 3
baltimore: 3
banks: 3
bases: 3
basically: 3
batch: 3
bayou: 3
beginning: 3
bianchini: 3
black: 3
boards: 3
bone: 3
boston: 3
boures: 3
breaking: 3
bring: 3
browser: 3
builds: 3
busy: 3
calling: 3
cambridge: 3
camera: 3
cap: 3
care: 3
carries: 3
categories: 3
chandra: 3
characteristic: 3
checked: 3
children: 3
chronous: 3
chubby: 3
churn: 3
circumvent: 3
claims: 3
clement: 3
closing: 3
colleagues: 3
colorado: 3
column: 3
combinations: 3
commands: 3
commerce: 3
commonly: 3
commun: 3
communicating: 3
company: 3
compatible: 3
compete: 3
competitive: 3
compilers: 3
compiling: 3
completes: 3
composed: 3
compound: 3
comprises: 3
compulsory: 3
computational: 3
computed: 3
con: 3
conceived: 3
concentrate: 3
concluded: 3
conclusions: 3
condition: 3
configurable: 3
confirmed: 3
conservation: 3
conserve: 3
consideration: 3
constructing: 3
construction: 3
consumed: 3
consumes: 3
continues: 3
convinced: 3
convoy: 3
cooperate: 3
coordinates: 3
coordination: 3
copper: 3
corbett: 3
corfu: 3
corporate: 3
correcting: 3
correctness: 3
correlate: 3
criterion: 3
culler: 3
culprit: 3
cumulus: 3
curious: 3
custer: 3
custom: 3
customer: 3
customized: 3
cycles: 3
dahlin: 3
dangers: 3
davis: 3
ddos: 3
deadline: 3
deadlines: 3
deals: 3
decade: 3
deciding: 3
decker: 3
decreasing: 3
deering: 3
degrade: 3
demonstrating: 3
dependable: 3
designers: 3
desire: 3
determinism: 3
deviation: 3
dialogue: 3
differentiation: 3
dis: 3
discover: 3
discrepancy: 3
disruptions: 3
disruptive: 3
disseminated: 3
distributing: 3
dns: 3
documentation: 3
documents: 3
dollars: 3
dominated: 3
dos: 3
drawn: 3
driver: 3
dropping: 3
drpm: 3
dying: 3
economics: 3
eded: 3
edward: 3
eicken: 3
el: 3
elastic: 3
elastras: 3
election: 3
electrical: 3
elegant: 3
else: 3
emergence: 3
emotional: 3
empire: 3
encodings: 3
encouraging: 3
ending: 3
endpoint: 3
endto: 3
enhances: 3
ensuring: 3
enterprises: 3
entities: 3
entity: 3
essay: 3
essential: 3
evaluates: 3
evaluating: 3
eventing: 3
evident: 3
evolution: 3
evolved: 3
exacerbates: 3
excellent: 3
excluding: 3
executes: 3
expands: 3
expelled: 3
experimentally: 3
experimented: 3
expires: 3
explorer: 3
exposes: 3
extends: 3
extension: 3
extent: 3
extra: 3
extracted: 3
fascinating: 3
fewer: 3
fg: 3
fields: 3
fifteenth: 3
finite: 3
firm: 3
flash: 3
flat: 3
fledged: 3
flight: 3
folder: 3
folders: 3
forest: 3
format: 3
formation: 3
franklin: 3
freeloaders: 3
french: 3
friend: 3
fs: 3
ganesh: 3
gargamel: 3
gather: 3
geographically: 3
gf: 3
gfgf: 3
goals: 3
gossiped: 3
government: 3
gps: 3
graphically: 3
great: 3
greatest: 3
grids: 3
grossman: 3
gt: 3
guaranteed: 3
gui: 3
gummadi: 3
guo: 3
gurumurthi: 3
hall: 3
handlers: 3
handley: 3
happen: 3
happy: 3
hauser: 3
haven: 3
heap: 3
helland: 3
helping: 3
hibernator: 3
hierarchically: 3
hierarchies: 3
highspeed: 3
homogeneous: 3
howard: 3
hypothesis: 3
ibm: 3
icdcs: 3
ics: 3
ignores: 3
ignoring: 3
il: 3
immersed: 3
implicitly: 3
impose: 3
imposes: 3
incentives: 3
income: 3
incorporated: 3
incorrectly: 3
incremental: 3
incremented: 3
incur: 3
indiana: 3
indicating: 3
informed: 3
inherits: 3
initiate: 3
innovations: 3
inside: 3
insights: 3
instability: 3
instantaneous: 3
institute: 3
intent: 3
interacting: 3
intercept: 3
intercepting: 3
intercepts: 3
interconnect: 3
interconnected: 3
internals: 3
internetworks: 3
interplay: 3
intervene: 3
inversion: 3
irregular: 3
iteration: 3
jbosscache: 3
jim: 3
jitter: 3
keeps: 3
kenneth: 3
knowing: 3
kuenning: 3
landscape: 3
laptops: 3
larson: 3
late: 3
lateral: 3
lesson: 3
linkage: 3
linked: 3
lions: 3
lloyd: 3
logically: 3
london: 3
looks: 3
loop: 3
losing: 3
lot: 3
luby: 3
mainframe: 3
mainsoft: 3
mainwin: 3
malkhi: 3
malo: 3
managers: 3
marian: 3
markets: 3
marks: 3
mashed: 3
matter: 3
mazie: 3
mckusick: 3
meanwhile: 3
memcached: 3
michael: 3
microbenchmark: 3
mid: 3
migration: 3
minimizing: 3
mirror: 3
mitigate: 3
modular: 3
montresor: 3
motivated: 3
motivates: 3
mountain: 3
movies: 3
multithreaded: 3
nat: 3
native: 3
neighborhood: 3
ninja: 3
nonetheless: 3
noticeable: 3
null: 3
observing: 3
obstruction: 3
occasionally: 3
odel: 3
oneway: 3
onto: 3
opened: 3
operational: 3
opposed: 3
optimizing: 3
optionally: 3
organize: 3
orientation: 3
ousterhout: 3
outbound: 3
outdated: 3
overflows: 3
overlapped: 3
overloads: 3
overwhelmed: 3
pacific: 3
padhye: 3
pai: 3
paid: 3
parameterize: 3
participant: 3
passing: 3
paying: 3
payload: 3
pc: 3
pedone: 3
penalties: 3
perceived: 3
percent: 3
perez: 3
personalities: 3
personalization: 3
pervasive: 3
peter: 3
phone: 3
pinheiro: 3
pisa: 3
players: 3
pleisch: 3
poisson: 3
polls: 3
poor: 3
popek: 3
popularity: 3
portions: 3
pose: 3
posed: 3
positioning: 3
prabhakaran: 3
prebuilt: 3
precedence: 3
predominate: 3
preferentially: 3
prefetched: 3
presentation: 3
preserved: 3
president: 3
preventing: 3
principal: 3
probing: 3
processor: 3
produce: 3
productivity: 3
programmers: 3
promise: 3
propagate: 3
properly: 3
protection: 3
proves: 3
provider: 3
psockets: 3
publishers: 3
punishment: 3
purchases: 3
pushed: 3
putting: 3
qpqp: 3
quanta: 3
queueing: 3
queues: 3
raises: 3
ramp: 3
ranging: 3
rao: 3
raptor: 3
reacting: 3
readonly: 3
realizing: 3
reasoning: 3
recipient: 3
recognize: 3
recommendations: 3
reconstruct: 3
recoveries: 3
reflecting: 3
rejoins: 3
relate: 3
relates: 3
released: 3
releases: 3
remarkably: 3
removing: 3
replaces: 3
replacing: 3
replayed: 3
replica: 3
replies: 3
representation: 3
representative: 3
res: 3
reserve: 3
resort: 3
resp: 3
respective: 3
responds: 3
restarting: 3
restored: 3
restricted: 3
retain: 3
retransmitted: 3
retrieves: 3
revisions: 3
rewarding: 3
rfc: 3
rises: 3
risks: 3
safely: 3
saint: 3
satisfies: 3
satisfy: 3
satisfying: 3
scaled: 3
scene: 3
school: 3
scope: 3
script: 3
semantic: 3
sensor: 3
separation: 3
sequential: 3
served: 3
seventeenth: 3
seventh: 3
severe: 3
sharded: 3
shepherd: 3
showed: 3
sight: 3
simpler: 3
simplest: 3
sinfonia: 3
situated: 3
sixth: 3
sleep: 3
slight: 3
smallest: 3
soft: 3
song: 3
sorrosal: 3
sound: 3
spanner: 3
spare: 3
spatial: 3
specifications: 3
speculatively: 3
splitstream: 3
splitting: 3
sporadic: 3
spot: 3
sprite: 3
sr: 3
ssrn: 3
stability: 3
standardize: 3
started: 3
stays: 3
stems: 3
streamed: 3
struggled: 3
subnet: 3
subscriber: 3
substrate: 3
successive: 3
suddenly: 3
sufficiently: 3
suggests: 3
suite: 3
supplied: 3
surprising: 3
suspicions: 3
symbolic: 3
symbols: 3
synchronously: 3
sys: 3
syst: 3
tables: 3
tacc: 3
tagging: 3
talk: 3
tape: 3
targets: 3
taylor: 3
teams: 3
television: 3
tends: 3
terminating: 3
testing: 3
text: 3
thin: 3
thinks: 3
thirty: 3
thomson: 3
threat: 3
tight: 3
tiled: 3
tolerable: 3
ton: 3
tput: 3
tr: 3
traditionally: 3
train: 3
transferred: 3
transferring: 3
transmissions: 3
triggered: 3
triggering: 3
trivial: 3
trouble: 3
truncation: 3
tsunami: 3
tudor: 3
tudorm: 3
turning: 3
uk: 3
unacceptable: 3
unavailable: 3
unblocks: 3
uncommittable: 3
undetected: 3
unexpectedly: 3
unfairly: 3
unmanaged: 3
unperturbed: 3
unrelated: 3
utah: 3
utilize: 3
uwin: 3
validated: 3
valuation: 3
variables: 3
variance: 3
verified: 3
verlag: 3
viewing: 3
vigfusson: 3
visualization: 3
vt: 3
wake: 3
walli: 3
wanted: 3
warns: 3
watch: 3
wefel: 3
wei: 3
whatever: 3
widespread: 3
winner: 3
wisdom: 3
wobber: 3
worlds: 3
worry: 3
wv: 3
yxyx: 3
zero: 3
zhao: 3
zurich: 3
abandon: 2
abc: 2
abilene: 2
abstractions: 2
academics: 2
acceptance: 2
accessible: 2
accomplished: 2
accordance: 2
accounting: 2
accumulating: 2
accurately: 2
accusation: 2
accused: 2
acquisition: 2
adam: 2
addison: 2
addressing: 2
adjusted: 2
adjusts: 2
administrative: 2
adopt: 2
advancements: 2
advent: 2
adversary: 2
advertises: 2
advice: 2
advocated: 2
aegis: 2
affinity: 2
aforementioned: 2
age: 2
agents: 2
aggregator: 2
aggressive: 2
aict: 2
aim: 2
ajax: 2
akamai: 2
alaska: 2
alberto: 2
albums: 2
alive: 2
alleviating: 2
allocates: 2
allocating: 2
alloscomp: 2
alternatively: 2
altruistic: 2
ame: 2
amortizes: 2
amounting: 2
analyzes: 2
anchorage: 2
anderson: 2
andresen: 2
anomalies: 2
anonymity: 2
anonymously: 2
anti: 2
anticipate: 2
antony: 2
apart: 2
apis: 2
appealing: 2
appeared: 2
appends: 2
applicationindependent: 2
approximately: 2
approximation: 2
approximations: 2
apr: 2
archetypal: 2
argues: 2
arguing: 2
arithmetic: 2
arose: 2
arraystructured: 2
arrived: 2
art: 2
article: 2
articles: 2
asia: 2
asics: 2
asks: 2
asp: 2
aspx: 2
assists: 2
assurance: 2
astonishingly: 2
asynch: 2
atm: 2
attach: 2
attached: 2
attain: 2
attempted: 2
attempting: 2
attestation: 2
attract: 2
attraction: 2
attractiveness: 2
audio: 2
aumann: 2
authentication: 2
automate: 2
autonomous: 2
autotuning: 2
avoidance: 2
ba: 2
baa: 2
babaoglu: 2
bach: 2
backlashed: 2
bailey: 2
baker: 2
ban: 2
barb: 2
barr: 2
barrier: 2
bast: 2
basu: 2
began: 2
behaved: 2
behaving: 2
belonging: 2
benjamin: 2
berlin: 2
bernoulli: 2
besides: 2
bespoke: 2
bhargava: 2
bifurcation: 2
billion: 2
binary: 2
binomial: 2
birrell: 2
bitcoinfoundation: 2
bjornstad: 2
blank: 2
bloomberg: 2
blow: 2
blumenthal: 2
boils: 2
bolton: 2
bonus: 2
borders: 2
box: 2
boycott: 2
bridge: 2
brings: 2
brokerage: 2
bronson: 2
browsers: 2
bruijn: 2
btcguild: 2
btchine: 2
buf: 2
bulpin: 2
burden: 2
burstiness: 2
business: 2
businesses: 2
buterin: 2
butterfly: 2
bypass: 2
caja: 2
calculation: 2
calculations: 2
calvin: 2
came: 2
canada: 2
candidates: 2
canonical: 2
capabilities: 2
carey: 2
carolina: 2
carrera: 2
cash: 2
castro: 2
casual: 2
casually: 2
category: 2
cation: 2
cdns: 2
cease: 2
ceases: 2
ceived: 2
census: 2
centralization: 2
century: 2
certainty: 2
cfm: 2
challenging: 2
chance: 2
characterise: 2
cheaply: 2
checkout: 2
checksums: 2
chemical: 2
chicago: 2
chief: 2
china: 2
chowdhry: 2
cidr: 2
circle: 2
circulate: 2
circulates: 2
circumstances: 2
cited: 2
clark: 2
click: 2
cloudviews: 2
coarse: 2
coexist: 2
coherence: 2
cohort: 2
colarelli: 2
colocated: 2
color: 2
combat: 2
comer: 2
committing: 2
commons: 2
communicated: 2
compelled: 2
compensate: 2
compensation: 2
complement: 2
composing: 2
computes: 2
concentrated: 2
concert: 2
conclusive: 2
confident: 2
confined: 2
connect: 2
cons: 2
considerably: 2
considers: 2
constitute: 2
constraint: 2
contacted: 2
contexts: 2
contract: 2
contradicts: 2
controlling: 2
conversion: 2
converted: 2
converting: 2
cooling: 2
cooper: 2
cording: 2
corner: 2
correspond: 2
countermeasures: 2
counterpart: 2
covered: 2
covering: 2
cox: 2
cpus: 2
credited: 2
credits: 2
cripple: 2
cripples: 2
criticism: 2
croquet: 2
crypto: 2
cryptocurrencies: 2
cryptographic: 2
cryptology: 2
ct: 2
cubic: 2
cypherspace: 2
cz: 2
damage: 2
dan: 2
dangerous: 2
daniel: 2
dast: 2
datasets: 2
datta: 2
days: 2
dbms: 2
dce: 2
dd: 2
deadlocks: 2
dealbook: 2
deceased: 2
decodes: 2
deduce: 2
deeper: 2
deeply: 2
defanti: 2
defects: 2
defer: 2
degradations: 2
degrading: 2
deleting: 2
deliberately: 2
deliberation: 2
delivering: 2
delta: 2
demanding: 2
dentical: 2
dependence: 2
depicted: 2
depicts: 2
deplist: 2
deplistcurr: 2
derive: 2
descriptor: 2
designing: 2
deterministically: 2
deviate: 2
devise: 2
dfreedman: 2
didn: 2
differentiable: 2
diminish: 2
dinosaur: 2
diot: 2
disabled: 2
disadvantage: 2
disadvantages: 2
discount: 2
disincentivize: 2
disrupting: 2
disseminates: 2
dissertation: 2
distances: 2
distinction: 2
diverse: 2
divide: 2
dividing: 2
doi: 2
dok: 2
dominate: 2
dot: 2
dotbit: 2
doubt: 2
downloaded: 2
downloads: 2
downside: 2
drives: 2
driving: 2
dry: 2
ds: 2
dubbed: 2
dugan: 2
dumbbell: 2
duplex: 2
duplicating: 2
dutta: 2
eagerly: 2
earned: 2
earnings: 2
ebling: 2
echo: 2
ecoop: 2
ecosystem: 2
eigenvalue: 2
eighteenth: 2
einar: 2
einstein: 2
elmore: 2
embeddings: 2
emphasis: 2
empirical: 2
enables: 2
encapsulate: 2
encapsulated: 2
encoders: 2
encounter: 2
encountered: 2
encrypted: 2
endhost: 2
ends: 2
ensemble: 2
ent: 2
enters: 2
envision: 2
equate: 2
equilibria: 2
era: 2
ered: 2
esbs: 2
escriva: 2
esign: 2
establishing: 2
estimates: 2
ethereum: 2
ethereumwhitepaper: 2
ets: 2
european: 2
eurosys: 2
ev: 2
eva: 2
eve: 2
eventbased: 2
everyone: 2
eviction: 2
evictions: 2
evolve: 2
exabytes: 2
exceeds: 2
exceptionally: 2
excessively: 2
executions: 2
exerted: 2
exerting: 2
exhibits: 2
expectation: 2
expectations: 2
expedite: 2
explains: 2
explores: 2
exponentially: 2
exports: 2
express: 2
expurging: 2
extensibility: 2
extremes: 2
eyes: 2
facilitate: 2
facto: 2
fair: 2
fall: 2
falling: 2
farms: 2
faulttolerance: 2
featuring: 2
fekete: 2
felser: 2
felten: 2
feng: 2
ferguson: 2
fetched: 2
fills: 2
finer: 2
finished: 2
finishes: 2
fired: 2
firewalling: 2
firoiu: 2
fits: 2
fix: 2
fl: 2
flag: 2
flexibly: 2
fluctuations: 2
fluid: 2
flushed: 2
fold: 2
forbes: 2
forcing: 2
forgo: 2
formats: 2
formulae: 2
forrestv: 2
forth: 2
foundations: 2
fox: 2
fragment: 2
fragments: 2
fraleigh: 2
frameworks: 2
fred: 2
fresh: 2
friction: 2
friedman: 2
friendliness: 2
frobenius: 2
fundamentally: 2
funded: 2
funds: 2
furman: 2
gained: 2
gaps: 2
garbled: 2
gateway: 2
gehrke: 2
generalize: 2
generations: 2
genesis: 2
geometric: 2
ghz: 2
gibbs: 2
gibson: 2
gigabyte: 2
github: 2
glick: 2
globalcrossing: 2
globe: 2
gossiper: 2
gossips: 2
gotten: 2
gr: 2
gradient: 2
gradually: 2
granted: 2
grapevine: 2
grasp: 2
greene: 2
griner: 2
guerraoui: 2
guesses: 2
guessing: 2
gupta: 2
guruprasad: 2
habel: 2
hackers: 2
halfway: 2
halted: 2
handful: 2
hands: 2
happens: 2
harder: 2
harley: 2
harm: 2
hashrate: 2
headers: 2
healthy: 2
heidelberg: 2
height: 2
held: 2
helpful: 2
hereinafter: 2
heterogenous: 2
hey: 2
hibler: 2
hiccups: 2
hides: 2
highlight: 2
highvalue: 2
hinder: 2
histogram: 2
hits: 2
hoarding: 2
hobor: 2
holy: 2
homepage: 2
honesty: 2
honeyman: 2
hops: 2
hotcloud: 2
huitema: 2
hundred: 2
hungry: 2
hurdle: 2
hurwitz: 2
huston: 2
iacr: 2
ic: 2
iciw: 2
icmp: 2
identities: 2
idit: 2
ie: 2
ifip: 2
ih: 2
ij: 2
ill: 2
illinois: 2
im: 2
imagined: 2
immaterial: 2
immediate: 2
immersion: 2
imperatives: 2
imperfect: 2
imply: 2
imposing: 2
impractical: 2
impulse: 2
incorporation: 2
indices: 2
indirection: 2
inefficiency: 2
inefficient: 2
infer: 2
influence: 2
influenced: 2
infrastructures: 2
ingrid: 2
ings: 2
inherent: 2
ining: 2
initialized: 2
initiates: 2
injecting: 2
insertion: 2
inspect: 2
install: 2
installed: 2
instantiated: 2
institutions: 2
instruction: 2
instructs: 2
integer: 2
intentionally: 2
interconnecting: 2
interconnection: 2
interconnects: 2
interix: 2
intermediary: 2
interpret: 2
intersection: 2
intervention: 2
intimate: 2
intricacies: 2
invalid: 2
investment: 2
invoke: 2
invokes: 2
ipdps: 2
iptps: 2
irish: 2
iscussion: 2
island: 2
italy: 2
itcoin: 2
ith: 2
ity: 2
izs: 2
james: 2
javabeans: 2
jimenez: 2
joglekar: 2
jonsson: 2
jsp: 2
juels: 2
justify: 2
kandemir: 2
kansas: 2
kapritsos: 2
karlsson: 2
katabi: 2
kazar: 2
kemme: 2
keycurr: 2
kharif: 2
kiawah: 2
kilper: 2
kim: 2
kimsas: 2
kjkj: 2
knob: 2
knobs: 2
kojo: 2
kroll: 2
krzys: 2
kurose: 2
labelled: 2
labs: 2
lagged: 2
lagging: 2
lake: 2
lambdarail: 2
lambdas: 2
landing: 2
landolsi: 2
laptop: 2
lastly: 2
lastop: 2
launching: 2
laying: 2
le: 2
lease: 2
legitimate: 2
leigh: 2
lepreau: 2
leskovec: 2
leslie: 2
leverages: 2
levy: 2
lightly: 2
lightwave: 2
likewise: 2
lin: 2
liskov: 2
literally: 2
literature: 2
lm: 2
locate: 2
lockstep: 2
longest: 2
longhaul: 2
loops: 2
loosely: 2
louise: 2
lowering: 2
lowers: 2
lows: 2
ltd: 2
luck: 2
lundqvist: 2
lynch: 2
lyon: 2
madden: 2
madhow: 2
magharei: 2
mance: 2
mandatory: 2
mangling: 2
manifested: 2
manipulate: 2
manually: 2
march: 2
marshaling: 2
martinez: 2
matrices: 2
matthews: 2
mature: 2
maximal: 2
maximized: 2
maya: 2
md: 2
mdcc: 2
meant: 2
megabits: 2
memoryless: 2
menees: 2
metacdn: 2
micro: 2
microsystems: 2
migrating: 2
milestone: 2
mined: 2
minimising: 2
minimizes: 2
minus: 2
mirroring: 2
miscalculate: 2
mismatched: 2
mistakenly: 2
mit: 2
mitigated: 2
mitigation: 2
mlml: 2
modem: 2
moderately: 2
modest: 2
modulo: 2
mohr: 2
montenegro: 2
monterey: 2
moshe: 2
mrc: 2
mst: 2
multigrep: 2
multiples: 2
multiplied: 2
multithreading: 2
muri: 2
muthitacharoen: 2
myriad: 2
nakamoto: 2
named: 2
names: 2
naming: 2
nandi: 2
narayanan: 2
naughton: 2
navathe: 2
ncsa: 2
ne: 2
nec: 2
needham: 2
negation: 2
neil: 2
nejdl: 2
newbold: 2
newer: 2
newly: 2
ngan: 2
nic: 2
nichols: 2
nishtala: 2
nity: 2
nlanr: 2
nonequilibrium: 2
nonnenmacher: 2
nontransactional: 2
normalization: 2
normalize: 2
normalizing: 2
normed: 2
notably: 2
notes: 2
notifies: 2
notifying: 2
noting: 2
nutshell: 2
nytimes: 2
obsolete: 2
obviously: 2
occasion: 2
occupies: 2
odd: 2
offices: 2
ofwork: 2
ole: 2
olympics: 2
omi: 2
omits: 2
ool: 2
ooled: 2
op: 2
opacity: 2
opening: 2
operated: 2
opportunities: 2
opt: 2
opted: 2
ordinarily: 2
organizational: 2
organizing: 2
originate: 2
orities: 2
oscillates: 2
ostar: 2
ourselves: 2
outages: 2
outs: 2
outsource: 2
outsources: 2
overcast: 2
overflow: 2
overlays: 2
overqos: 2
pairings: 2
pam: 2
panacea: 2
par: 2
paradigms: 2
parameshwaran: 2
parameterizations: 2
parametrized: 2
parity: 2
park: 2
parno: 2
pass: 2
pathway: 2
patterson: 2
payloads: 2
paypal: 2
pcb: 2
pdcs: 2
pdfs: 2
penalised: 2
pentium: 2
peration: 2
perfor: 2
peris: 2
permits: 2
permitted: 2
perpetrators: 2
perron: 2
petersen: 2
ph: 2
phanishayee: 2
phases: 2
physically: 2
picture: 2
piggybacked: 2
piling: 2
pipeline: 2
pipelines: 2
pitfalls: 2
plague: 2
plays: 2
plication: 2
plugged: 2
plugging: 2
poolattacks: 2
popper: 2
port: 2
porto: 2
ports: 2
poses: 2
position: 2
powersaving: 2
pplive: 2
practically: 2
preceding: 2
precise: 2
precludes: 2
predecessor: 2
predefined: 2
predetermined: 2
predictive: 2
predicts: 2
preferable: 2
prefers: 2
preiss: 2
preliminary: 2
premise: 2
presenting: 2
preservation: 2
preserve: 2
preserving: 2
prevail: 2
prevention: 2
primitive: 2
prioritising: 2
prioritization: 2
prioritize: 2
prioritizing: 2
privately: 2
probabilistically: 2
probe: 2
problematic: 2
processors: 2
produces: 2
professor: 2
profile: 2
profiler: 2
profit: 2
projection: 2
promote: 2
proper: 2
proposals: 2
pros: 2
proving: 2
pseudo: 2
pullbased: 2
pulling: 2
pulse: 2
purchase: 2
purchasing: 2
pure: 2
pursue: 2
pushes: 2
pvldb: 2
qhuang: 2
qin: 2
qmi: 2
qos: 2
quasistatic: 2
quicksilver: 2
quote: 2
race: 2
racticalities: 2
radc: 2
radical: 2
radio: 2
raised: 2
ramakrishnan: 2
ramamritham: 2
randomness: 2
ranges: 2
rank: 2
rateless: 2
rational: 2
ratios: 2
reacts: 2
readily: 2
ready: 2
realizes: 2
rears: 2
reasonably: 2
reception: 2
reciprocation: 2
recognition: 2
recompute: 2
reconciliation: 2
recycling: 2
redesigned: 2
redesigning: 2
reductions: 2
referred: 2
refraining: 2
refreshed: 2
regard: 2
registration: 2
reimplemented: 2
reissue: 2
reissued: 2
rejaie: 2
rejected: 2
rejecting: 2
rejects: 2
relaxed: 2
relay: 2
relevance: 2
relied: 2
relies: 2
reliminaries: 2
relying: 2
remarks: 2
remotely: 2
removes: 2
rendering: 2
rep: 2
repaired: 2
repeatable: 2
repetitions: 2
reporting: 2
repurposing: 2
reputation: 2
requisite: 2
resending: 2
resends: 2
reserves: 2
resident: 2
resolutions: 2
respecting: 2
responsive: 2
restarted: 2
retaliate: 2
retried: 2
retries: 2
reverse: 2
reviewers: 2
revisiting: 2
rewarded: 2
rewritten: 2
reykjavik: 2
reynolds: 2
ricci: 2
rightful: 2
rigid: 2
rigorous: 2
rigorously: 2
rimon: 2
rising: 2
rivalry: 2
roberts: 2
rohrs: 2
rome: 2
roots: 2
rose: 2
rosenblum: 2
ross: 2
rounding: 2
routinely: 2
row: 2
rp: 2
rsized: 2
rt: 2
rtts: 2
ruling: 2
runners: 2
rvr: 2
sabul: 2
safe: 2
saha: 2
said: 2
sake: 2
sales: 2
satellite: 2
saxena: 2
scans: 2
scatter: 2
scattered: 2
scheduler: 2
schedules: 2
sci: 2
scientist: 2
scratch: 2
scsi: 2
seamless: 2
secondgeneration: 2
seda: 2
seeking: 2
seemingly: 2
seldom: 2
seltzer: 2
seminar: 2
senior: 2
sensible: 2
sept: 2
serial: 2
serialize: 2
serially: 2
serious: 2
serverlets: 2
serverpull: 2
settle: 2
shape: 2
shapley: 2
sharp: 2
sheds: 2
shelby: 2
shell: 2
shi: 2
shieh: 2
shifts: 2
shokrollahi: 2
shortcut: 2
shortly: 2
sidebotham: 2
sigact: 2
signs: 2
sigops: 2
sigurbjornsson: 2
silicon: 2
silverlight: 2
simplification: 2
simplified: 2
simulating: 2
singh: 2
sinks: 2
sister: 2
sivakumar: 2
slashdot: 2
slashes: 2
slows: 2
slush: 2
smooth: 2
soar: 2
soars: 2
soas: 2
societies: 2
society: 2
solaris: 2
solely: 2
solheim: 2
solid: 2
solved: 2
something: 2
son: 2
sonic: 2
sons: 2
soper: 2
sourceforge: 2
south: 2
sovran: 2
specialists: 2
speedups: 2
spend: 2
spending: 2
splits: 2
spreads: 2
spreitzer: 2
srs: 2
st: 2
stabilizes: 2
staggering: 2
standalone: 2
stands: 2
stat: 2
statement: 2
station: 2
statqwest: 2
stats: 2
steal: 2
stefan: 2
stephen: 2
stocks: 2
stoller: 2
stops: 2
stories: 2
storms: 2
story: 2
stripe: 2
striping: 2
sturgis: 2
styles: 2
su: 2
subgroup: 2
submits: 2
submitted: 2
submitting: 2
subscribed: 2
subversive: 2
subverted: 2
succession: 2
successively: 2
sudden: 2
suffice: 2
suggest: 2
suggestions: 2
suited: 2
summation: 2
sundr: 2
supergame: 2
supergames: 2
supervisors: 2
supply: 2
suppose: 2
sure: 2
surpass: 2
surprise: 2
survey: 2
susceptibility: 2
suspect: 2
sustain: 2
swallow: 2
swanson: 2
swapping: 2
swift: 2
swinehart: 2
swiss: 2
sybil: 2
synchronize: 2
synthesis: 2
systematic: 2
systemic: 2
tablets: 2
tagged: 2
tailer: 2
tandard: 2
tango: 2
tardos: 2
tation: 2
tauber: 2
tc: 2
technically: 2
tempted: 2
tend: 2
termed: 2
testbed: 2
tgperf: 2
theimer: 2
thick: 2
thing: 2
thirtieth: 2
thumb: 2
tiered: 2
ties: 2
tional: 2
tions: 2
tirumala: 2
toappliance: 2
tock: 2
tods: 2
tolerates: 2
tolerating: 2
topeer: 2
topologically: 2
totally: 2
touch: 2
touches: 2
toueg: 2
tough: 2
toy: 2
tp: 2
tracing: 2
tracked: 2
trades: 2
tragedy: 2
tranmission: 2
transact: 2
transcoded: 2
transforming: 2
trapezoids: 2
treatment: 2
tremel: 2
triangular: 2
tricky: 2
tries: 2
trivially: 2
trol: 2
trsu: 2
trustworthy: 2
tuft: 2
tuned: 2
tv: 2
twentieth: 2
twofold: 2
ugly: 2
umich: 2
un: 2
unaltered: 2
unattacked: 2
unattractive: 2
uncommitable: 2
uncommitted: 2
unexplored: 2
unfavorable: 2
uninvolved: 2
uniquely: 2
united: 2
unlucky: 2
unnecessarily: 2
unnecessary: 2
unreachable: 2
unresponsive: 2
uploading: 2
urgent: 2
userspace: 2
validating: 2
vancouver: 2
vandermeer: 2
vandermonde: 2
vasek: 2
vcurr: 2
vein: 2
venkataramani: 2
ver: 2
verby: 2
versioned: 2
vicinity: 2
viewers: 2
violations: 2
virtualized: 2
visibility: 2
visited: 2
vko: 2
volumes: 2
vpn: 2
wakeup: 2
walks: 2
wallace: 2
war: 2
warehouse: 2
warship: 2
watching: 2
wattenhofer: 2
weakens: 2
weaker: 2
weaknesses: 2
websphere: 2
welch: 2
wesley: 2
west: 2
whereby: 2
whom: 2
wicker: 2
wider: 2
width: 2
wiley: 2
williams: 2
willing: 2
willner: 2
winter: 2
withholds: 2
witnessed: 2
wizkid: 2
wlog: 2
wo: 2
wolfgang: 2
wong: 2
words: 2
workflow: 2
worsening: 2
wrapping: 2
wrongdoing: 2
wvwv: 2
xie: 2
xored: 2
xp: 2
xth: 2
yang: 2
ymir: 2
yxxy: 2
zoom: 2
aaron: 1
abbreviations: 1
abilalso: 1
absorbs: 1
abstracts: 1
abu: 1
accompanied: 1
accomplish: 1
accomplishing: 1
accounted: 1
accumulate: 1
aceves: 1
acheive: 1
acheived: 1
acls: 1
acmula: 1
acomplish: 1
acquires: 1
acquiring: 1
acthe: 1
activated: 1
actuators: 1
acwe: 1
adamic: 1
adaptable: 1
adapted: 1
adaptively: 1
adaptivity: 1
addi: 1
addiserver: 1
additive: 1
addressable: 1
adelaide: 1
adhere: 1
adjacent: 1
administers: 1
admit: 1
admits: 1
adoption: 1
ads: 1
advertise: 1
advertised: 1
adya: 1
aelstrom: 1
aerospace: 1
af: 1
affirmative: 1
afford: 1
afforded: 1
afraid: 1
afterward: 1
agenda: 1
agent: 1
ager: 1
aggregat: 1
aggregrate: 1
aggressively: 1
aggressiveness: 1
agreements: 1
ahnn: 1
aid: 1
aims: 1
airplane: 1
ak: 1
akkus: 1
alarms: 1
albatross: 1
albrecht: 1
alegre: 1
alexander: 1
alfetching: 1
allavena: 1
allegedly: 1
alleviated: 1
alleviates: 1
allo: 1
alloc: 1
allocations: 1
allthingsdistributed: 1
alof: 1
alpha: 1
altogether: 1
altrustic: 1
am: 1
amar: 1
ambitious: 1
america: 1
amortized: 1
ample: 1
amplify: 1
amsden: 1
analogy: 1
analyse: 1
analyst: 1
analytics: 1
ance: 1
anceaume: 1
anddrop: 1
andersen: 1
andre: 1
andreas: 1
ann: 1
anne: 1
annie: 1
annotated: 1
announce: 1
announcement: 1
announces: 1
annoyingly: 1
annually: 1
anonymous: 1
answered: 1
answers: 1
anticipated: 1
antipolis: 1
antonio: 1
anytime: 1
anyway: 1
anywhere: 1
ap: 1
apa: 1
appeal: 1
appendix: 1
applaud: 1
appleton: 1
appli: 1
applicationdropped: 1
appliit: 1
applior: 1
applithe: 1
approaching: 1
approximates: 1
apps: 1
apthe: 1
arbor: 1
architects: 1
archival: 1
archives: 1
argus: 1
arisen: 1
armies: 1
arranging: 1
arrivals: 1
artifact: 1
artificial: 1
ase: 1
aside: 1
ask: 1
asking: 1
assembling: 1
assist: 1
assisted: 1
associates: 1
associating: 1
astrolabe: 1
aswhen: 1
asynbandwidth: 1
asynchrony: 1
asynmicrobenchmarks: 1
asynmobile: 1
asynqueue: 1
ata: 1
atomically: 1
atr: 1
att: 1
attaches: 1
attaching: 1
attar: 1
attention: 1
attr: 1
attracted: 1
attributable: 1
attributed: 1
atypical: 1
audit: 1
audits: 1
australia: 1
authoritative: 1
authorized: 1
autodesk: 1
automation: 1
autotion: 1
autowriteback: 1
autumn: 1
ava: 1
availto: 1
avatar: 1
awaiting: 1
awareness: 1
axes: 1
azim: 1
backgound: 1
backgrounds: 1
backlog: 1
backlogs: 1
backnt: 1
backups: 1
bakalova: 1
balancers: 1
ballance: 1
ballot: 1
banaei: 1
bandcontain: 1
bandhowever: 1
bandwhile: 1
bandwidthdelay: 1
bandwidthsensitive: 1
banff: 1
barcelona: 1
bare: 1
barracuda: 1
barriers: 1
baseline: 1
bastion: 1
batched: 1
batches: 1
batching: 1
batkin: 1
battle: 1
battlefield: 1
battleground: 1
bayeux: 1
bcc: 1
bcq: 1
became: 1
befriended: 1
behren: 1
beijing: 1
belief: 1
believed: 1
beloved: 1
benchmarking: 1
benchmarks: 1
benenational: 1
benoit: 1
bered: 1
berkeleydb: 1
bernd: 1
bershad: 1
bership: 1
bert: 1
bertier: 1
bhattacharjee: 1
biggest: 1
bile: 1
bill: 1
billed: 1
billing: 1
bills: 1
bindel: 1
binds: 1
bio: 1
bitcoinmines: 1
bk: 1
blades: 1
blame: 1
ble: 1
bleeding: 1
blending: 1
blogs: 1
boa: 1
board: 1
body: 1
bold: 1
bologna: 1
bond: 1
bonding: 1
bonn: 1
book: 1
boosting: 1
boot: 1
borisov: 1
bortnikov: 1
boss: 1
bostic: 1
bother: 1
bottlenecks: 1
bought: 1
boundary: 1
bounds: 1
boys: 1
bq: 1
br: 1
brahms: 1
brazil: 1
breakthrough: 1
bregni: 1
breslau: 1
brian: 1
bridging: 1
bright: 1
british: 1
broad: 1
broberg: 1
brokers: 1
brought: 1
bruno: 1
budget: 1
budgets: 1
buffercould: 1
bug: 1
buggy: 1
bugs: 1
builders: 1
burdens: 1
bureau: 1
burgess: 1
buried: 1
burrows: 1
busnel: 1
button: 1
buyer: 1
buying: 1
buys: 1
cabrera: 1
cacheable: 1
cacheserializability: 1
caise: 1
cal: 1
calability: 1
camargos: 1
cameras: 1
cancelled: 1
candidate: 1
cannes: 1
cantwell: 1
capability: 1
cappuccino: 1
captured: 1
caratti: 1
carded: 1
cardinality: 1
cardoso: 1
career: 1
careers: 1
careful: 1
caribbean: 1
carl: 1
carried: 1
carrier: 1
carrying: 1
cart: 1
carzaniga: 1
cas: 1
cascades: 1
cast: 1
castor: 1
catalog: 1
catastrophe: 1
catastrophic: 1
cated: 1
categorized: 1
cations: 1
causal: 1
cbb: 1
cbbc: 1
cbqpcb: 1
ccb: 1
ccdf: 1
cdf: 1
cdrom: 1
ceives: 1
cell: 1
centered: 1
ceremony: 1
certify: 1
certifying: 1
cess: 1
chained: 1
chainlink: 1
chair: 1
chakka: 1
chakravorty: 1
challenger: 1
chang: 1
changtao: 1
chapman: 1
characterised: 1
chawathe: 1
cheat: 1
checkouts: 1
chenchu: 1
cheslack: 1
chicken: 1
chiefly: 1
chien: 1
chinese: 1
ching: 1
chockler: 1
choke: 1
chose: 1
chow: 1
christened: 1
christmas: 1
chronously: 1
chrony: 1
chu: 1
chuck: 1
chunk: 1
chunks: 1
cincilla: 1
circuitous: 1
circulation: 1
circumvented: 1
circumvents: 1
citation: 1
cites: 1
cities: 1
clara: 1
clarity: 1
cleaned: 1
cleanly: 1
clearer: 1
clements: 1
clientserver: 1
clocks: 1
clone: 1
closest: 1
cloudifying: 1
clutter: 1
cmu: 1
codaniques: 1
coded: 1
coding: 1
coexistence: 1
coexists: 1
coherency: 1
coincide: 1
collaborate: 1
collaborating: 1
collapsing: 1
collateral: 1
collects: 1
collusions: 1
columbia: 1
comings: 1
comitting: 1
comm: 1
commatic: 1
commence: 1
commences: 1
commentary: 1
commenting: 1
commercially: 1
commonplace: 1
communal: 1
communi: 1
commutative: 1
comp: 1
compact: 1
comparably: 1
comparaour: 1
comparative: 1
comparisons: 1
compelling: 1
compensating: 1
competitors: 1
compiler: 1
complementary: 1
complementing: 1
complexities: 1
complimentary: 1
comply: 1
compositional: 1
compressed: 1
compresses: 1
comprising: 1
compromises: 1
compromising: 1
computationally: 1
computfits: 1
comsium: 1
concentrates: 1
concentration: 1
conception: 1
conceptually: 1
concludes: 1
concrete: 1
concurby: 1
concuruses: 1
conditioned: 1
conext: 1
configure: 1
conform: 1
conios: 1
conitbased: 1
conjecture: 1
connec: 1
connectionless: 1
conner: 1
consequent: 1
conserving: 1
consisted: 1
consisupdate: 1
consortium: 1
constantly: 1
constituent: 1
constrain: 1
constructs: 1
consulting: 1
consumer: 1
consumers: 1
contacting: 1
contally: 1
contemplate: 1
contemplated: 1
contemplating: 1
contending: 1
conthe: 1
contingencies: 1
contolerate: 1
contractors: 1
contravention: 1
contributes: 1
controller: 1
controversy: 1
convenience: 1
convention: 1
converged: 1
converging: 1
conversely: 1
converts: 1
conveyed: 1
convoys: 1
cooperating: 1
coordinated: 1
coordinating: 1
coordinators: 1
copied: 1
coping: 1
cops: 1
cornelldeveloped: 1
corr: 1
corrected: 1
corrections: 1
correspondingly: 1
corroborated: 1
corrupted: 1
cotton: 1
counters: 1
counting: 1
couple: 1
crashing: 1
crawl: 1
credit: 1
credo: 1
crete: 1
crippling: 1
criteria: 1
critically: 1
crossroads: 1
crowcroft: 1
csd: 1
cstr: 1
culled: 1
cumulatively: 1
customised: 1
customizability: 1
customizable: 1
customization: 1
customizing: 1
customuserserviceapp: 1
cutler: 1
cuts: 1
cybercaf: 1
cyrus: 1
czerwinski: 1
dallas: 1
danielsson: 1
danilov: 1
dantzig: 1
dat: 1
datagrams: 1
dataset: 1
datastores: 1
daunting: 1
dave: 1
davoli: 1
dazzling: 1
dc: 1
dead: 1
deadlock: 1
deadly: 1
deadtially: 1
dean: 1
debatable: 1
debate: 1
debated: 1
debilitating: 1
debris: 1
debugger: 1
declare: 1
declaring: 1
declines: 1
decode: 1
decoder: 1
decoding: 1
decoupled: 1
decouples: 1
decreased: 1
defend: 1
deferplications: 1
deferrable: 1
defers: 1
defgh: 1
defining: 1
definitions: 1
degrees: 1
deit: 1
delegation: 1
delete: 1
deleted: 1
delivers: 1
demanded: 1
demise: 1
demonstration: 1
denning: 1
dennis: 1
denoting: 1
dep: 1
depart: 1
departments: 1
dependalso: 1
dependenrate: 1
depsa: 1
depth: 1
dequeued: 1
der: 1
dered: 1
deregistered: 1
derivative: 1
derivatives: 1
derives: 1
deriving: 1
des: 1
descending: 1
deserver: 1
deshow: 1
designated: 1
designating: 1
designer: 1
desirability: 1
desirable: 1
desktops: 1
destabilize: 1
destinations: 1
detailing: 1
deterioration: 1
determinants: 1
detrimental: 1
dev: 1
developerhours: 1
deviations: 1
devised: 1
devlin: 1
devoted: 1
devoting: 1
dewitt: 1
dexa: 1
dhs: 1
dht: 1
diamond: 1
dictionaries: 1
diego: 1
dies: 1
differany: 1
differential: 1
differentiates: 1
differentiating: 1
differenwith: 1
differing: 1
diffs: 1
dimensions: 1
dimov: 1
ding: 1
directing: 1
directs: 1
disable: 1
disables: 1
disappearance: 1
disappeared: 1
disastrous: 1
disbut: 1
discard: 1
disconnections: 1
disconnects: 1
discontinuing: 1
discotheque: 1
discounts: 1
discovered: 1
discusses: 1
discussing: 1
disguise: 1
disinclined: 1
disjoing: 1
dislike: 1
dismiss: 1
dispatch: 1
dispatcher: 1
dispatching: 1
displayed: 1
displaying: 1
displays: 1
dispools: 1
disregarded: 1
dissatisfied: 1
disseminating: 1
distill: 1
distorted: 1
diverges: 1
diversion: 1
diversity: 1
dll: 1
dlls: 1
documented: 1
dol: 1
domains: 1
dominating: 1
donet: 1
door: 1
dou: 1
doubled: 1
douceur: 1
doug: 1
downgraded: 1
downtime: 1
dozen: 1
dr: 1
drain: 1
drained: 1
drawbacks: 1
drawing: 1
draws: 1
drift: 1
drifting: 1
drive: 1
drivers: 1
drone: 1
duals: 1
ducing: 1
dummynet: 1
dundant: 1
dunn: 1
duplicates: 1
dur: 1
durably: 1
durations: 1
dwarf: 1
dx: 1
dynamics: 1
ear: 1
eastham: 1
economies: 1
ecution: 1
edd: 1
edges: 1
edit: 1
editors: 1
edits: 1
eds: 1
eduardo: 1
educational: 1
edutella: 1
eed: 1
efficacies: 1
eg: 1
egemen: 1
egg: 1
ekin: 1
elasticity: 1
elect: 1
electric: 1
electricity: 1
electronics: 1
eleventh: 1
eliability: 1
elicit: 1
eliciting: 1
elkin: 1
embark: 1
embody: 1
embrace: 1
embraces: 1
emerged: 1
emerges: 1
emitting: 1
emmanuelle: 1
empted: 1
emto: 1
emulating: 1
encapsulates: 1
encod: 1
encode: 1
encompass: 1
encourages: 1
encrypt: 1
encrypts: 1
endeavor: 1
endowment: 1
endpoints: 1
endtransaction: 1
endtransport: 1
enemy: 1
enforced: 1
engine: 1
engineers: 1
enlarge: 1
enlarges: 1
enlarging: 1
enputing: 1
entail: 1
entering: 1
entitled: 1
entropy: 1
enumerate: 1
episodes: 1
epositories: 1
epstein: 1
equeation: 1
equipped: 1
erally: 1
erates: 1
erent: 1
ering: 1
erodes: 1
erred: 1
errorprone: 1
ery: 1
eschewing: 1
esprit: 1
establish: 1
establishes: 1
etup: 1
eugster: 1
evalappended: 1
eventoriented: 1
everyday: 1
everywhere: 1
evocative: 1
evolves: 1
evolving: 1
exacerbating: 1
exaggerated: 1
examined: 1
excellently: 1
excess: 1
exchanging: 1
excitement: 1
exclusively: 1
exec: 1
execusystem: 1
executable: 1
exemplifies: 1
exercise: 1
exhibitthe: 1
existed: 1
exited: 1
exiting: 1
expects: 1
expedited: 1
expense: 1
experiencing: 1
expert: 1
expire: 1
explanation: 1
explanatory: 1
exploits: 1
exponentiated: 1
exporting: 1
expose: 1
exposition: 1
expunged: 1
expurge: 1
exsmart: 1
exspecified: 1
extending: 1
extensible: 1
extensively: 1
extracting: 1
extracts: 1
facilitates: 1
facilitating: 1
facing: 1
factory: 1
failing: 1
failuredetectio: 1
failwhen: 1
faithful: 1
faloutsos: 1
falsely: 1
faltered: 1
famous: 1
farber: 1
farewell: 1
farm: 1
farnoush: 1
farther: 1
fascination: 1
fashioned: 1
fastest: 1
featured: 1
federal: 1
federica: 1
feel: 1
feels: 1
feet: 1
feldman: 1
fell: 1
fellow: 1
fellowship: 1
felt: 1
ferred: 1
ferris: 1
ffs: 1
fic: 1
fidelity: 1
fifteen: 1
figured: 1
fikes: 1
filing: 1
filled: 1
films: 1
filtered: 1
filters: 1
finance: 1
findings: 1
finegrained: 1
finergrained: 1
finish: 1
fiorano: 1
firewall: 1
firms: 1
fisher: 1
fitted: 1
fitting: 1
fixes: 1
flavors: 1
flaws: 1
flickr: 1
flood: 1
flooding: 1
fluctuating: 1
fluke: 1
flushing: 1
fly: 1
focs: 1
football: 1
forcibly: 1
forecast: 1
foregoing: 1
foremost: 1
foresee: 1
forgoing: 1
fork: 1
forked: 1
formal: 1
formally: 1
formed: 1
formerly: 1
fort: 1
fortune: 1
forwards: 1
founder: 1
fractions: 1
franke: 1
frans: 1
freed: 1
freenix: 1
freeze: 1
freshness: 1
fricano: 1
friends: 1
friendship: 1
frightening: 1
frontend: 1
frost: 1
ftcs: 1
fugal: 1
fulfilling: 1
fulfillment: 1
functional: 1
fund: 1
funding: 1
furniture: 1
furthest: 1
gabit: 1
gabriel: 1
gallager: 1
garbinato: 1
garcia: 1
gates: 1
gathering: 1
gauge: 1
gauthier: 1
gave: 1
gb: 1
gbit: 1
gcheap: 1
geambasu: 1
generalized: 1
genercache: 1
generous: 1
geneva: 1
genit: 1
genuinely: 1
geodistributed: 1
geoff: 1
geoffrey: 1
gershinsky: 1
gestion: 1
getting: 1
ghemawat: 1
gi: 1
gian: 1
giardullo: 1
gifford: 1
gilbert: 1
ginting: 1
ginza: 1
gis: 1
gist: 1
giving: 1
glade: 1
glance: 1
glitches: 1
globalized: 1
globecom: 1
goel: 1
gold: 1
goldberg: 1
googles: 1
gov: 1
governed: 1
governmental: 1
grade: 1
gradual: 1
grande: 1
granting: 1
granularity: 1
graphical: 1
grc: 1
gree: 1
greece: 1
grepwe: 1
griffioen: 1
grimm: 1
grips: 1
grochowski: 1
grounds: 1
groundwork: 1
grove: 1
gruber: 1
grunwald: 1
guadelope: 1
gubarev: 1
guha: 1
guis: 1
gunnar: 1
gunnars: 1
gurevich: 1
gurus: 1
guy: 1
guyadec: 1
hacked: 1
hacking: 1
hadoop: 1
haifa: 1
halem: 1
halt: 1
halts: 1
halves: 1
hampering: 1
hanan: 1
handing: 1
handled: 1
handler: 1
handoff: 1
handurukande: 1
hang: 1
hansell: 1
happened: 1
haridasan: 1
haridasana: 1
harmful: 1
harnessing: 1
harpaz: 1
hartman: 1
harwood: 1
hasn: 1
hawaii: 1
hazard: 1
hazards: 1
headquarters: 1
heard: 1
heart: 1
heartbeatmonitor: 1
heat: 1
heavyweight: 1
hegde: 1
hegedu: 1
heidemann: 1
heiser: 1
helen: 1
hellerstein: 1
helped: 1
henceforth: 1
her: 1
herein: 1
hersonissos: 1
hesitate: 1
heterogeneity: 1
heuristic: 1
heuristics: 1
hiding: 1
highassurance: 1
highbandwidth: 1
highbut: 1
highlights: 1
highlyavailable: 1
highpower: 1
highquality: 1
hik: 1
hill: 1
him: 1
himself: 1
hisgen: 1
hjelm: 1
hochschild: 1
holbrook: 1
holder: 1
holding: 1
holte: 1
homes: 1
homomorphic: 1
honolulu: 1
honored: 1
hoon: 1
hopcroft: 1
hoping: 1
horizontal: 1
horn: 1
horrible: 1
hospital: 1
hotice: 1
hotly: 1
hotnets: 1
hotzone: 1
hours: 1
howa: 1
hpca: 1
hreshold: 1
hrs: 1
hsieh: 1
htm: 1
hu: 1
huazhong: 1
huberman: 1
hungary: 1
hurricane: 1
hurting: 1
hyder: 1
hyper: 1
ically: 1
icccn: 1
iceland: 1
icomp: 1
icons: 1
icpads: 1
icsoc: 1
idempotence: 1
iden: 1
idenhigh: 1
identically: 1
idigest: 1
ied: 1
igniting: 1
ignorance: 1
ihkj: 1
iis: 1
ilability: 1
illegal: 1
illusion: 1
imaginable: 1
imation: 1
imc: 1
imlocal: 1
immature: 1
immersive: 1
impacts: 1
implememted: 1
implemenfrom: 1
implemenshared: 1
implementapackages: 1
implosion: 1
implying: 1
import: 1
imported: 1
imporwriteback: 1
imposition: 1
impossibility: 1
imprecise: 1
impressive: 1
improv: 1
inadequacy: 1
inadequate: 1
inadequately: 1
inapplicable: 1
inappropriate: 1
inbound: 1
incentivize: 1
inception: 1
inclusive: 1
incompatible: 1
incomplete: 1
incon: 1
inconsisto: 1
incorpoas: 1
increasess: 1
incredibly: 1
incrementing: 1
indefinitely: 1
independence: 1
indexing: 1
indicators: 1
indictment: 1
indirect: 1
indirectly: 1
indispensable: 1
individinterference: 1
individuals: 1
indranil: 1
induced: 1
industrystandard: 1
inefficiencies: 1
inevitable: 1
inexpennet: 1
inf: 1
infect: 1
infected: 1
infection: 1
infectious: 1
inference: 1
inferred: 1
inflate: 1
inflexibility: 1
inflight: 1
informa: 1
informatics: 1
informing: 1
informs: 1
infrequent: 1
infused: 1
inherited: 1
inhibit: 1
inhibiting: 1
inicontention: 1
initialised: 1
initialize: 1
initiating: 1
initiation: 1
inject: 1
injects: 1
inner: 1
innetwork: 1
innotice: 1
innovate: 1
inprocess: 1
inputs: 1
insecure: 1
insensitive: 1
inseparable: 1
inserted: 1
inserts: 1
inspection: 1
inspired: 1
instruct: 1
instructed: 1
instructing: 1
instructions: 1
instrument: 1
instrumented: 1
instrumenting: 1
int: 1
integers: 1
integrity: 1
intellection: 1
intellectual: 1
intelligence: 1
intem: 1
intense: 1
intensity: 1
intention: 1
intentions: 1
interadditional: 1
intercluster: 1
interdependence: 1
interests: 1
interfere: 1
interferes: 1
interject: 1
interlinked: 1
intermittent: 1
intermittently: 1
internally: 1
internships: 1
interoriginally: 1
interpreted: 1
interpreting: 1
interprocess: 1
interrogates: 1
interrupt: 1
interrupts: 1
interspersed: 1
intervenallows: 1
intra: 1
intractable: 1
intrapartition: 1
intrusion: 1
intrusions: 1
intuitively: 1
invaluable: 1
invariant: 1
invest: 1
investigations: 1
invisible: 1
invocation: 1
invocations: 1
involve: 1
involvement: 1
involving: 1
iperfthe: 1
ipto: 1
irections: 1
irregularity: 1
irregularly: 1
irrelevant: 1
irrespectively: 1
isca: 1
isola: 1
isolate: 1
isolated: 1
isolating: 1
israel: 1
istemi: 1
istva: 1
itcc: 1
items: 1
iterators: 1
ities: 1
itors: 1
iyengar: 1
jacobson: 1
jade: 1
jain: 1
janne: 1
jannotti: 1
jansch: 1
jared: 1
jari: 1
je: 1
jerian: 1
jesi: 1
jian: 1
jiang: 1
jin: 1
jini: 1
jit: 1
jiun: 1
jk: 1
jmc: 1
jms: 1
job: 1
jobs: 1
joined: 1
jones: 1
jong: 1
jorge: 1
jostling: 1
jr: 1
judicious: 1
julkunen: 1
jump: 1
jumpy: 1
juni: 1
junqueira: 1
justice: 1
justification: 1
kallman: 1
kalogeras: 1
kamilmani: 1
kaminsky: 1
kamra: 1
kanthak: 1
karamanolis: 1
karels: 1
karp: 1
kashani: 1
katti: 1
kay: 1
kde: 1
keidl: 1
keith: 1
keller: 1
kempe: 1
kent: 1
kerberos: 1
kernels: 1
kernilized: 1
kevin: 1
keyboard: 1
khan: 1
khorlin: 1
kib: 1
kick: 1
kicking: 1
kicks: 1
kid: 1
kilobyte: 1
kilobytes: 1
kirk: 1
kistler: 1
kit: 1
kk: 1
kleiman: 1
kliot: 1
kloc: 1
knights: 1
knowledgments: 1
kodali: 1
kogan: 1
korhonen: 1
koskela: 1
kostic: 1
kouznetsov: 1
kr: 1
kramer: 1
kraska: 1
krishnakumar: 1
krishnamurthy: 1
kristjan: 1
kristjanvj: 1
krohn: 1
kubiatowicz: 1
kulkarni: 1
kumar: 1
kupfer: 1
kwiatkowski: 1
la: 1
laboratories: 1
laboratory: 1
lacked: 1
ladis: 1
lafayette: 1
lag: 1
lags: 1
laid: 1
laing: 1
lamb: 1
land: 1
landlord: 1
lands: 1
landscapes: 1
lapping: 1
larry: 1
lasting: 1
lauderdale: 1
launch: 1
law: 1
lay: 1
layed: 1
layering: 1
lazy: 1
leaks: 1
learned: 1
learners: 1
leasing: 1
lecture: 1
led: 1
lee: 1
leff: 1
legends: 1
lenient: 1
lenz: 1
lesser: 1
lets: 1
lever: 1
levin: 1
libdeh: 1
liberal: 1
licensing: 1
lie: 1
lied: 1
lieu: 1
lighter: 1
likelihood: 1
limitation: 1
linden: 1
lindsay: 1
linearizable: 1
linger: 1
linkages: 1
lion: 1
listen: 1
listening: 1
littered: 1
liveness: 1
lives: 1
livestreaming: 1
livny: 1
lkjj: 1
ln: 1
lo: 1
localized: 1
localizes: 1
lockfree: 1
logarithmic: 1
logarithmically: 1
logics: 1
login: 1
logstructured: 1
lombard: 1
longput: 1
longrunning: 1
lookup: 1
loose: 1
loses: 1
loudifying: 1
louisiana: 1
lowand: 1
lowbandwidth: 1
lowerfile: 1
lowmfs: 1
lowney: 1
lowpower: 1
lpdc: 1
lr: 1
lugano: 1
luna: 1
luo: 1
lying: 1
lyles: 1
maarten: 1
mach: 1
macrobenchmarks: 1
maffeis: 1
magazine: 1
maglaris: 1
magnetic: 1
magnified: 1
magninetwork: 1
mahajan: 1
maheshwari: 1
mailing: 1
mailoth: 1
mainly: 1
mainteconsequently: 1
mak: 1
maki: 1
malloth: 1
man: 1
mandated: 1
mandreoli: 1
manipulates: 1
manm: 1
mann: 1
mao: 1
marandi: 1
marchukov: 1
marcon: 1
margo: 1
marie: 1
marin: 1
mario: 1
markoff: 1
markus: 1
marrying: 1
marshal: 1
martignon: 1
maryland: 1
marzullo: 1
mash: 1
mashing: 1
masking: 1
mass: 1
massachussetts: 1
matches: 1
materials: 1
matically: 1
matskin: 1
matt: 1
maxcontiguous: 1
maxim: 1
maximizing: 1
maymounkov: 1
mazieres: 1
mazon: 1
mbit: 1
mcauliffe: 1
mcelroy: 1
mckenney: 1
mea: 1
meaning: 1
meaningfully: 1
meantime: 1
mechacies: 1
medians: 1
mediarich: 1
mediately: 1
medical: 1
meet: 1
meetings: 1
megabytes: 1
megastore: 1
meirong: 1
melnik: 1
mem: 1
memcache: 1
memcopy: 1
memoryrelated: 1
men: 1
mendel: 1
menus: 1
mer: 1
merchant: 1
merging: 1
meta: 1
metaphor: 1
miami: 1
miao: 1
mib: 1
migrate: 1
mika: 1
mike: 1
mikhail: 1
mile: 1
milestones: 1
millions: 1
mimic: 1
mindset: 1
minh: 1
minimise: 1
minimised: 1
minimized: 1
minitransactions: 1
minjun: 1
minneapolis: 1
minnesota: 1
minobrowser: 1
mirrored: 1
mirrors: 1
misbehavior: 1
misfinally: 1
miskin: 1
mislove: 1
misra: 1
mistakes: 1
mitigates: 1
mitigating: 1
mitzenmacher: 1
mixes: 1
mmcn: 1
moderate: 1
modewell: 1
modularity: 1
mofavouring: 1
mohan: 1
moll: 1
moments: 1
monetary: 1
monin: 1
monnet: 1
mono: 1
monolithic: 1
monotonically: 1
moon: 1
morning: 1
morris: 1
mostlyreads: 1
motes: 1
motivating: 1
motivations: 1
mounted: 1
mouse: 1
movement: 1
mpi: 1
mplementation: 1
mscorwks: 1
msgs: 1
msiegen: 1
msn: 1
mts: 1
mulsequence: 1
multiframed: 1
multigigabit: 1
multiin: 1
multimedia: 1
multiplexing: 1
multispeed: 1
multitier: 1
multitude: 1
multiversioning: 1
multiwas: 1
multo: 1
mummert: 1
murderous: 1
music: 1
mutexes: 1
mvs: 1
mwaura: 1
na: 1
naaman: 1
nagle: 1
nahrstedt: 1
naively: 1
naks: 1
namespace: 1
nance: 1
napper: 1
narada: 1
nary: 1
nate: 1
nats: 1
naval: 1
navigate: 1
navy: 1
nawab: 1
nca: 1
ndi: 1
neatly: 1
necessity: 1
needing: 1
needless: 1
needlessly: 1
negative: 1
negatively: 1
negligibly: 1
negotiate: 1
nei: 1
neighboring: 1
nelson: 1
ness: 1
netecon: 1
neting: 1
neufeld: 1
newarr: 1
newscasts: 1
nextgeneration: 1
nfs: 1
ngas: 1
nicely: 1
niche: 1
nick: 1
night: 1
nikolov: 1
nimble: 1
ninth: 1
nishimura: 1
nishita: 1
nism: 1
nization: 1
noisy: 1
nomad: 1
nonblockingtransport: 1
noncongestion: 1
nondeterministic: 1
nonempty: 1
nossdav: 1
noteworthy: 1
notified: 1
notoriously: 1
nowadays: 1
np: 1
npapers: 1
nsfc: 1
ntserver: 1
num: 1
numb: 1
numeric: 1
nutanong: 1
nygren: 1
obeyed: 1
obeys: 1
obfuscates: 1
objective: 1
objectivity: 1
objectoriented: 1
obligation: 1
obliging: 1
observable: 1
observes: 1
obsessively: 1
obsoleted: 1
obstacle: 1
obstructs: 1
occurrence: 1
ofc: 1
offenders: 1
offerings: 1
officially: 1
offline: 1
offset: 1
oforder: 1
ogy: 1
oltp: 1
omitting: 1
oneanother: 1
ongoing: 1
ontology: 1
onwards: 1
opearting: 1
openafs: 1
opennt: 1
opens: 1
opensketch: 1
operafrom: 1
operamfs: 1
operat: 1
operatencies: 1
opposing: 1
opposition: 1
optimality: 1
optimally: 1
optimisation: 1
optimisations: 1
optimise: 1
optimised: 1
optimistically: 1
optional: 1
orchestrating: 1
orderings: 1
organised: 1
origin: 1
originated: 1
originating: 1
originator: 1
ority: 1
orks: 1
orleans: 1
orma: 1
ormance: 1
ortributed: 1
orts: 1
oscillate: 1
oscillating: 1
ost: 1
otivation: 1
ource: 1
ous: 1
outcontent: 1
outlook: 1
outof: 1
outperform: 1
outperformed: 1
outright: 1
outweighs: 1
overcomes: 1
overhaul: 1
overlaid: 1
overlayed: 1
overloading: 1
overpredict: 1
overprediction: 1
overreach: 1
overrequest: 1
overrequesting: 1
oversight: 1
oversold: 1
overweigh: 1
overwritten: 1
owing: 1
owned: 1
ozalp: 1
ozsu: 1
pa: 1
pack: 1
package: 1
packparently: 1
packs: 1
pain: 1
pairing: 1
paleczny: 1
pallickara: 1
palossless: 1
pan: 1
panel: 1
pang: 1
panning: 1
pans: 1
paolo: 1
papazoglou: 1
parallelising: 1
parallelism: 1
parallelized: 1
parallelizing: 1
parameterizing: 1
parent: 1
parents: 1
paritybased: 1
parliament: 1
parsa: 1
partitionable: 1
partners: 1
party: 1
passes: 1
pastry: 1
pat: 1
paterson: 1
patin: 1
patino: 1
pavlo: 1
pdc: 1
peculiar: 1
peek: 1
peep: 1
peking: 1
penalized: 1
pennsylvania: 1
penzo: 1
perceive: 1
perceiving: 1
percentiles: 1
perception: 1
perdichizzi: 1
perf: 1
performances: 1
perience: 1
periments: 1
permission: 1
permute: 1
permutes: 1
permuting: 1
perobject: 1
persisted: 1
persistence: 1
persisting: 1
personalize: 1
personalized: 1
personally: 1
pertaining: 1
perturbances: 1
perturbation: 1
perturbations: 1
perv: 1
pervasively: 1
pervasiveness: 1
petko: 1
petrov: 1
pfhsn: 1
phani: 1
philadelphia: 1
philosophical: 1
phones: 1
phpmyadmin: 1
physician: 1
pianese: 1
picconi: 1
picking: 1
picks: 1
piece: 1
pieces: 1
piles: 1
pirahesh: 1
pittsburgh: 1
pivotal: 1
plain: 1
planes: 1
planned: 1
planning: 1
plans: 1
plants: 1
plasma: 1
plat: 1
plausible: 1
please: 1
plentiful: 1
plotted: 1
pluggable: 1
plugins: 1
pn: 1
podcasts: 1
pointer: 1
pointers: 1
poirier: 1
police: 1
political: 1
portability: 1
portal: 1
porting: 1
portob: 1
portray: 1
posix: 1
post: 1
postava: 1
posted: 1
posters: 1
postponed: 1
postponing: 1
potencan: 1
potholes: 1
powell: 1
powerhouse: 1
powering: 1
powers: 1
powersavings: 1
ppendix: 1
practices: 1
pratt: 1
pray: 1
preallocating: 1
precede: 1
precious: 1
precision: 1
preclude: 1
predetermining: 1
predictability: 1
predicting: 1
predictions: 1
predominant: 1
predominantly: 1
preempted: 1
preexisting: 1
preferences: 1
prefetchthe: 1
preguica: 1
preparation: 1
prepare: 1
prepared: 1
prepares: 1
preprocessing: 1
pressing: 1
presume: 1
pretend: 1
pretending: 1
pretends: 1
prevailing: 1
prevalent: 1
previewer: 1
previwhen: 1
prices: 1
prifetched: 1
priin: 1
primaldual: 1
princehouse: 1
priorispeedup: 1
prioritized: 1
priortwo: 1
prito: 1
priviledges: 1
privileged: 1
pro: 1
probed: 1
probes: 1
procedures: 1
proceedin: 1
professional: 1
profiled: 1
profiles: 1
profiling: 1
programmed: 1
progressed: 1
prohibited: 1
prohibitive: 1
prohibitively: 1
prohibits: 1
projected: 1
proliferating: 1
prometheus: 1
prominently: 1
promised: 1
promotional: 1
promptly: 1
pronounced: 1
propagates: 1
propagating: 1
propel: 1
propgated: 1
proportionally: 1
proposal: 1
proposes: 1
prothe: 1
prototypes: 1
protruding: 1
proverbial: 1
provers: 1
provisions: 1
provoke: 1
proximity: 1
prudently: 1
pruned: 1
ptions: 1
publications: 1
publishsubscribe: 1
pubsub: 1
punishing: 1
purchased: 1
purdue: 1
putation: 1
puter: 1
puts: 1
puzar: 1
pvalues: 1
pvm: 1
pvt: 1
qnx: 1
qppq: 1
qu: 1
quadrant: 1
quadrants: 1
qualities: 1
quantified: 1
quantity: 1
quarterman: 1
quarters: 1
quasi: 1
quema: 1
questionable: 1
quinlan: 1
quired: 1
quorum: 1
quotes: 1
raab: 1
races: 1
rachid: 1
racing: 1
radar: 1
radi: 1
rago: 1
raid: 1
rails: 1
raincloud: 1
raisepriority: 1
raising: 1
rameter: 1
ramifications: 1
randomised: 1
ranks: 1
ratnasamy: 1
ratner: 1
rayfield: 1
rbudp: 1
rchitecture: 1
reaction: 1
reactive: 1
readiness: 1
readwrite: 1
realistically: 1
realities: 1
realization: 1
realtime: 1
reardon: 1
reboot: 1
rebuilt: 1
recast: 1
rechecks: 1
recipients: 1
recite: 1
reclamation: 1
recode: 1
recommendation: 1
recommended: 1
recommends: 1
reconfigurable: 1
reconfiguration: 1
reconfigure: 1
reconfiguring: 1
reconnect: 1
reconstruction: 1
recorded: 1
recov: 1
recovrequests: 1
recovthroughput: 1
recurrence: 1
recursive: 1
recursively: 1
redesign: 1
redirect: 1
redirected: 1
redirecting: 1
redisplaying: 1
reedsolomon: 1
referenced: 1
referring: 1
refers: 1
refines: 1
reflectsan: 1
refuse: 1
reg: 1
regenerate: 1
registering: 1
registry: 1
regularity: 1
reid: 1
reiher: 1
reimplementing: 1
relational: 1
relationship: 1
relationships: 1
relayed: 1
religion: 1
relinked: 1
remained: 1
removal: 1
ren: 1
rename: 1
rency: 1
render: 1
renderers: 1
renders: 1
rendezvous: 1
renessea: 1
renewed: 1
rently: 1
reordering: 1
replacements: 1
replicates: 1
reportedly: 1
repre: 1
reprefetch: 1
representa: 1
reproduced: 1
rescuer: 1
researcher: 1
resembles: 1
resend: 1
resetting: 1
reside: 1
resides: 1
resiliency: 1
resolves: 1
resolving: 1
resorting: 1
respected: 1
restarts: 1
restrict: 1
restructured: 1
resumed: 1
retained: 1
retaining: 1
retains: 1
rethese: 1
rethink: 1
retriev: 1
retrieving: 1
reusability: 1
reusable: 1
reuse: 1
reused: 1
revalidate: 1
revealed: 1
revealing: 1
reverts: 1
revisited: 1
revived: 1
revoked: 1
revolution: 1
rewind: 1
rexford: 1
rhee: 1
ricardo: 1
ride: 1
righteous: 1
rio: 1
rive: 1
rlogin: 1
ro: 1
roads: 1
rockell: 1
rocky: 1
rodrigues: 1
rodriguez: 1
rolig: 1
roll: 1
rollback: 1
rolled: 1
rollout: 1
room: 1
rooted: 1
roselli: 1
rotating: 1
rotations: 1
rough: 1
roundrobin: 1
roussel: 1
roy: 1
rss: 1
ru: 1
rubenstein: 1
ruichuan: 1
rush: 1
rushed: 1
rx: 1
saab: 1
sacrificing: 1
saikat: 1
saito: 1
sakoda: 1
salt: 1
sambamurthy: 1
samet: 1
sandber: 1
sankaran: 1
santa: 1
sarana: 1
sarcasm: 1
saroiu: 1
sata: 1
satpep: 1
saturated: 1
saturates: 1
saturating: 1
saturation: 1
savage: 1
saying: 1
says: 1
scaleable: 1
scarce: 1
scenarmobile: 1
scenes: 1
schedule: 1
schematic: 1
schiper: 1
schizophrenic: 1
schlosser: 1
schmidt: 1
schroeder: 1
schuh: 1
schultz: 1
sciascia: 1
scott: 1
screen: 1
screenshots: 1
scripting: 1
scripts: 1
scrutiny: 1
sdns: 1
seagate: 1
searchers: 1
searching: 1
searing: 1
sears: 1
secretly: 1
seeing: 1
seely: 1
seemed: 1
selec: 1
selection: 1
selectively: 1
selfinterested: 1
selforganizing: 1
semanticweb: 1
senses: 1
sensitivfigure: 1
sentative: 1
separating: 1
sequencing: 1
ser: 1
serialised: 1
sericola: 1
serverless: 1
servicing: 1
serving: 1
setceiver: 1
setups: 1
seven: 1
severely: 1
shacham: 1
shaded: 1
shah: 1
shahabi: 1
shalunov: 1
shao: 1
shaped: 1
shapers: 1
shapiro: 1
sharding: 1
shayee: 1
shed: 1
shelf: 1
shenghua: 1
shielding: 1
shim: 1
shipping: 1
shirriff: 1
shop: 1
shopping: 1
shoring: 1
shortcomings: 1
shorter: 1
shouldn: 1
shraer: 1
shrideep: 1
shtml: 1
shupp: 1
shutdown: 1
si: 1
sidebar: 1
siegenthaler: 1
siena: 1
sig: 1
sigkdd: 1
sigmetrics: 1
signature: 1
signed: 1
signers: 1
significance: 1
signing: 1
silberstein: 1
silently: 1
similarities: 1
similarity: 1
simon: 1
simulaneous: 1
simulates: 1
singhai: 1
sintek: 1
sishim: 1
sistencies: 1
sitaraman: 1
sits: 1
sivasubramaniam: 1
sive: 1
sjsu: 1
skepticism: 1
sky: 1
skyrocketing: 1
slash: 1
slay: 1
sleeps: 1
slide: 1
slip: 1
slowdowns: 1
sluggish: 1
smartphone: 1
smith: 1
smoothly: 1
snapshots: 1
snooping: 1
soa: 1
socc: 1
sock: 1
softway: 1
solicited: 1
solves: 1
somefound: 1
sonicmq: 1
sonicsoftware: 1
sooner: 1
sophia: 1
sorted: 1
sought: 1
spain: 1
spanningtree: 1
spans: 1
spared: 1
spawned: 1
speaking: 1
speaks: 1
speci: 1
specializes: 1
specificity: 1
specifies: 1
specifying: 1
spectrum: 1
speech: 1
spends: 1
spielman: 1
spiked: 1
spinning: 1
spirits: 1
spix: 1
splay: 1
splitx: 1
sponse: 1
sporting: 1
sports: 1
sprays: 1
spring: 1
squash: 1
squirrelmail: 1
sridharan: 1
srrs: 1
srsr: 1
ssh: 1
stabilizing: 1
stadrops: 1
stafford: 1
stand: 1
standardizing: 1
stanford: 1
stanislav: 1
stanton: 1
startup: 1
starved: 1
starving: 1
statemachine: 1
statems: 1
stationary: 1
statistic: 1
stead: 1
steen: 1
steep: 1
steer: 1
steere: 1
stepping: 1
stipulating: 1
sto: 1
stochastic: 1
stocking: 1
stodolsky: 1
stoica: 1
stor: 1
stordifferent: 1
straight: 1
street: 1
strengths: 1
stretagy: 1
strike: 1
strikes: 1
strikingly: 1
strings: 1
stripped: 1
strongest: 1
stronglytraces: 1
structuring: 1
studying: 1
stumbled: 1
stylistic: 1
suba: 1
subing: 1
subintervals: 1
subj: 1
subkilobyte: 1
submission: 1
subnetworks: 1
subordinate: 1
subramanian: 1
subscribes: 1
subscription: 1
subscriptions: 1
subsections: 1
subsequence: 1
subservicecontrol: 1
subserviceprocess: 1
substandard: 1
substitute: 1
substreams: 1
subtitles: 1
subtransactions: 1
succeeds: 1
successor: 1
sue: 1
suffix: 1
suggestive: 1
sul: 1
summarise: 1
summarised: 1
summarizes: 1
summarizing: 1
summer: 1
sunos: 1
sup: 1
superbowl: 1
superceded: 1
superfluous: 1
superimpose: 1
superior: 1
superlinearly: 1
supersede: 1
superseded: 1
supervisory: 1
supplementing: 1
supposed: 1
suppressing: 1
surely: 1
surements: 1
surge: 1
surplus: 1
surrounding: 1
surtani: 1
survivors: 1
suryanarayana: 1
suspended: 1
sussman: 1
sw: 1
swart: 1
swivel: 1
swws: 1
sympo: 1
syn: 1
synchro: 1
synchronise: 1
synchronizing: 1
systraditional: 1
szeged: 1
szymaniak: 1
tablet: 1
tag: 1
tags: 1
tailor: 1
tains: 1
talking: 1
talks: 1
tam: 1
tamma: 1
tan: 1
tance: 1
tanin: 1
tao: 1
tapped: 1
tapping: 1
tari: 1
taught: 1
tdi: 1
te: 1
technetwork: 1
technicalsessions: 1
technion: 1
technologists: 1
telecommunications: 1
telemetry: 1
templates: 1
tempt: 1
tems: 1
tency: 1
tended: 1
tension: 1
tent: 1
tentative: 1
tention: 1
terleaving: 1
terlinked: 1
terminal: 1
terminate: 1
terminated: 1
testimony: 1
textures: 1
thanks: 1
thefly: 1
ther: 1
thereafter: 1
thereby: 1
thorsten: 1
thrashing: 1
threading: 1
threetier: 1
throughputs: 1
throughxors: 1
tial: 1
tiate: 1
tib: 1
ticast: 1
ticipant: 1
ticker: 1
ticular: 1
tied: 1
tightrope: 1
timecritical: 1
timeframe: 1
timeline: 1
timers: 1
timescales: 1
timesharing: 1
timo: 1
tination: 1
tings: 1
tiple: 1
titles: 1
tity: 1
tively: 1
tivity: 1
todd: 1
todisincentivize: 1
toend: 1
toknow: 1
tokyo: 1
tolercations: 1
tom: 1
tone: 1
tons: 1
toplas: 1
topoltifiers: 1
tortures: 1
touted: 1
traceroute: 1
traf: 1
trafficshaping: 1
trailing: 1
tranasctions: 1
transactionally: 1
transactypes: 1
transcoding: 1
transformed: 1
transis: 1
transit: 1
transitional: 1
translated: 1
translates: 1
translation: 1
translators: 1
translucence: 1
transportation: 1
transporting: 1
travels: 1
treatments: 1
tri: 1
trials: 1
tricks: 1
tried: 1
trillion: 1
trim: 1
trips: 1
truncate: 1
truncated: 1
truong: 1
tsatalos: 1
ttls: 1
tude: 1
tudy: 1
tunable: 1
tung: 1
tuples: 1
turing: 1
tus: 1
tweb: 1
twelth: 1
twin: 1
twitter: 1
twotier: 1
tx: 1
txcache: 1
txn: 1
typed: 1
typwrite: 1
ual: 1
ubicomm: 1
ubiquitously: 1
ublcs: 1
uc: 1
ucb: 1
ufrgs: 1
ular: 1
ulate: 1
ultrareliable: 1
unacceptably: 1
unavoidable: 1
unbe: 1
uncertain: 1
unclustered: 1
unconstrained: 1
uncontrolled: 1
uncorrelated: 1
underdog: 1
undergo: 1
underlies: 1
underneath: 1
underperform: 1
understandable: 1
understanddevices: 1
understands: 1
understood: 1
undertake: 1
undertaken: 1
underutilisation: 1
underway: 1
undesired: 1
undisturbed: 1
unencrypted: 1
unflattering: 1
unfortunate: 1
unidirectional: 1
unifies: 1
uniformally: 1
unilaterally: 1
unintended: 1
uninterference: 1
unites: 1
univ: 1
univerisity: 1
universal: 1
universe: 1
universita: 1
unjustified: 1
unlink: 1
unlinking: 1
unmodified: 1
unnoticed: 1
unparalleled: 1
unrealistic: 1
unreasonable: 1
unrecoverable: 1
unreserved: 1
unresilient: 1
unresolved: 1
unresponsiveness: 1
unrpcs: 1
unspecified: 1
unsuitable: 1
untouched: 1
unusually: 1
unwilling: 1
upare: 1
upcalls: 1
upcan: 1
upcations: 1
upcoming: 1
upgrade: 1
upgrades: 1
upisting: 1
uploads: 1
upreader: 1
upson: 1
upstudies: 1
upthe: 1
upwidth: 1
ures: 1
urgently: 1
url: 1
urls: 1
usages: 1
usdoj: 1
usefully: 1
usermakes: 1
uservisible: 1
utilising: 1
utilized: 1
utilizes: 1
utilizing: 1
utrsut: 1
utt: 1
uture: 1
uut: 1
uutt: 1
validations: 1
vanilla: 1
vanishes: 1
var: 1
variances: 1
vasilatos: 1
vb: 1
vectored: 1
vehicles: 1
veitch: 1
velenis: 1
venkataraman: 1
vercurr: 1
verification: 1
versa: 1
vertical: 1
victims: 1
videos: 1
vidhyashankar: 1
viding: 1
viewer: 1
viewsynchronous: 1
violated: 1
violates: 1
viral: 1
vironment: 1
virtually: 1
virtue: 1
vishnumurthy: 1
visibly: 1
vision: 1
visit: 1
visiting: 1
vista: 1
visualize: 1
visualizing: 1
vital: 1
vivek: 1
vlo: 1
vmm: 1
vms: 1
voelker: 1
vogel: 1
voip: 1
vollset: 1
voluntary: 1
vrable: 1
wa: 1
waived: 1
wallach: 1
wans: 1
warp: 1
wasn: 1
wasteful: 1
wastes: 1
wasting: 1
watches: 1
wave: 1
wcnc: 1
weaken: 1
weakness: 1
webfs: 1
weblogs: 1
webtier: 1
weeks: 1
weighed: 1
welldefined: 1
weng: 1
wes: 1
westerlund: 1
wg: 1
whatsnew: 1
whatsoever: 1
wheeler: 1
whereupon: 1
whiteboard: 1
whitepaper: 1
whithout: 1
wholefile: 1
wicom: 1
widens: 1
wieloch: 1
wilma: 1
windowsnt: 1
winnie: 1
wires: 1
withuated: 1
witnesses: 1
wolf: 1
wonder: 1
woo: 1
woodford: 1
worker: 1
worries: 1
worrisome: 1
worthwhile: 1
wouldn: 1
wrapped: 1
wraps: 1
writclassification: 1
writeaccesses: 1
writeinvalidations: 1
writequirement: 1
writeserver: 1
writetive: 1
writewrite: 1
wrote: 1
wscompatible: 1
wsdl: 1
wspds: 1
wstransactions: 1
wu: 1
xaxis: 1
xcp: 1
xiao: 1
xisting: 1
xperimental: 1
xu: 1
xyx: 1
yaghmazadeh: 1
yann: 1
yaxes: 1
yee: 1
yielded: 1
yin: 1
ylianttila: 1
youtube: 1
yuanchao: 1
yuanyuan: 1
yum: 1
yushprakh: 1
zahorjan: 1
zdonik: 1
zeal: 1
zealous: 1
zelenka: 1
zephyr: 1
zettabyte: 1
zhen: 1
zhenqi: 1
zhou: 1
zhuang: 1
zoomed: 1
zooming: 1
zooms: 1
zou: 1
zuck: 1
zwilling: 1
